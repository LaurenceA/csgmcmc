==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.418 | Acc: 12.500% (8/64)
Loss: 2.882 | Acc: 11.665% (754/6464)
Loss: 2.578 | Acc: 13.013% (1674/12864)
Loss: 2.473 | Acc: 13.497% (2600/19264)
Loss: 2.415 | Acc: 14.226% (3651/25664)
Loss: 2.380 | Acc: 14.867% (4767/32064)
Loss: 2.355 | Acc: 15.383% (5917/38464)
Loss: 2.335 | Acc: 15.926% (7145/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2323, Accuracy: 1915/10000 (19.15%)

Epoch: 1
Loss: 2.291 | Acc: 9.375% (6/64)
Loss: 2.205 | Acc: 20.282% (1311/6464)
Loss: 2.197 | Acc: 20.748% (2669/12864)
Loss: 2.194 | Acc: 20.909% (4028/19264)
Loss: 2.192 | Acc: 20.924% (5370/25664)
Loss: 2.191 | Acc: 21.161% (6785/32064)
Loss: 2.187 | Acc: 21.420% (8239/38464)
Loss: 2.186 | Acc: 21.545% (9666/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3120, Accuracy: 1825/10000 (18.25%)

Epoch: 2
Loss: 2.149 | Acc: 23.438% (15/64)
Loss: 2.155 | Acc: 24.103% (1558/6464)
Loss: 2.159 | Acc: 23.655% (3043/12864)
Loss: 2.156 | Acc: 23.967% (4617/19264)
Loss: 2.154 | Acc: 24.108% (6187/25664)
Loss: 2.154 | Acc: 24.133% (7738/32064)
Loss: 2.152 | Acc: 24.272% (9336/38464)
Loss: 2.150 | Acc: 24.449% (10969/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1333, Accuracy: 2636/10000 (26.36%)

Epoch: 3
Loss: 2.420 | Acc: 14.062% (9/64)
Loss: 2.133 | Acc: 25.913% (1675/6464)
Loss: 2.136 | Acc: 26.057% (3352/12864)
Loss: 2.130 | Acc: 26.272% (5061/19264)
Loss: 2.129 | Acc: 26.286% (6746/25664)
Loss: 2.129 | Acc: 26.378% (8458/32064)
Loss: 2.127 | Acc: 26.448% (10173/38464)
Loss: 2.124 | Acc: 26.636% (11950/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1156, Accuracy: 2691/10000 (26.91%)

Epoch: 4
Loss: 2.040 | Acc: 35.938% (23/64)
Loss: 2.101 | Acc: 28.620% (1850/6464)
Loss: 2.094 | Acc: 28.848% (3711/12864)
Loss: 2.100 | Acc: 28.660% (5521/19264)
Loss: 2.099 | Acc: 28.655% (7354/25664)
Loss: 2.100 | Acc: 28.580% (9164/32064)
Loss: 2.098 | Acc: 28.757% (11061/38464)
Loss: 2.096 | Acc: 28.847% (12942/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1261, Accuracy: 2684/10000 (26.84%)

Epoch: 5
Loss: 2.008 | Acc: 28.125% (18/64)
Loss: 2.068 | Acc: 30.213% (1953/6464)
Loss: 2.079 | Acc: 29.781% (3831/12864)
Loss: 2.076 | Acc: 29.817% (5744/19264)
Loss: 2.072 | Acc: 30.151% (7738/25664)
Loss: 2.070 | Acc: 30.321% (9722/32064)
Loss: 2.069 | Acc: 30.366% (11680/38464)
Loss: 2.067 | Acc: 30.670% (13760/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1633, Accuracy: 2718/10000 (27.18%)

Epoch: 6
Loss: 1.985 | Acc: 37.500% (24/64)
Loss: 2.034 | Acc: 33.416% (2160/6464)
Loss: 2.040 | Acc: 33.030% (4249/12864)
Loss: 2.044 | Acc: 32.859% (6330/19264)
Loss: 2.042 | Acc: 32.945% (8455/25664)
Loss: 2.039 | Acc: 33.068% (10603/32064)
Loss: 2.040 | Acc: 33.067% (12719/38464)
Loss: 2.039 | Acc: 33.118% (14858/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1291, Accuracy: 2823/10000 (28.23%)

Epoch: 7
Loss: 2.048 | Acc: 34.375% (22/64)
Loss: 2.016 | Acc: 34.483% (2229/6464)
Loss: 2.015 | Acc: 34.266% (4408/12864)
Loss: 2.017 | Acc: 34.297% (6607/19264)
Loss: 2.017 | Acc: 34.383% (8824/25664)
Loss: 2.015 | Acc: 34.478% (11055/32064)
Loss: 2.015 | Acc: 34.479% (13262/38464)
Loss: 2.014 | Acc: 34.569% (15509/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0402, Accuracy: 3377/10000 (33.77%)

Epoch: 8
Loss: 2.084 | Acc: 34.375% (22/64)
Loss: 1.997 | Acc: 35.288% (2281/6464)
Loss: 1.992 | Acc: 35.704% (4593/12864)
Loss: 1.990 | Acc: 35.958% (6927/19264)
Loss: 1.996 | Acc: 35.723% (9168/25664)
Loss: 1.991 | Acc: 35.941% (11524/32064)
Loss: 1.993 | Acc: 35.860% (13793/38464)
Loss: 1.992 | Acc: 35.953% (16130/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1236, Accuracy: 3094/10000 (30.94%)

Epoch: 9
Loss: 2.078 | Acc: 29.688% (19/64)
Loss: 1.967 | Acc: 37.005% (2392/6464)
Loss: 1.978 | Acc: 36.645% (4714/12864)
Loss: 1.980 | Acc: 36.529% (7037/19264)
Loss: 1.979 | Acc: 36.693% (9417/25664)
Loss: 1.980 | Acc: 36.751% (11784/32064)
Loss: 1.982 | Acc: 36.741% (14132/38464)
Loss: 1.982 | Acc: 36.704% (16467/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1177, Accuracy: 2987/10000 (29.87%)

Epoch: 10
Loss: 1.926 | Acc: 45.312% (29/64)
Loss: 1.976 | Acc: 37.175% (2403/6464)
Loss: 1.976 | Acc: 37.251% (4792/12864)
Loss: 1.971 | Acc: 37.443% (7213/19264)
Loss: 1.970 | Acc: 37.418% (9603/25664)
Loss: 1.968 | Acc: 37.562% (12044/32064)
Loss: 1.967 | Acc: 37.586% (14457/38464)
Loss: 1.967 | Acc: 37.558% (16850/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1310, Accuracy: 2860/10000 (28.60%)

Epoch: 11
Loss: 1.945 | Acc: 35.938% (23/64)
Loss: 1.948 | Acc: 38.815% (2509/6464)
Loss: 1.956 | Acc: 38.410% (4941/12864)
Loss: 1.957 | Acc: 38.362% (7390/19264)
Loss: 1.957 | Acc: 38.385% (9851/25664)
Loss: 1.959 | Acc: 38.273% (12272/32064)
Loss: 1.958 | Acc: 38.355% (14753/38464)
Loss: 1.955 | Acc: 38.519% (17281/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0880, Accuracy: 3206/10000 (32.06%)

Epoch: 12
Loss: 1.863 | Acc: 42.188% (27/64)
Loss: 1.957 | Acc: 38.861% (2512/6464)
Loss: 1.949 | Acc: 39.195% (5042/12864)
Loss: 1.943 | Acc: 39.327% (7576/19264)
Loss: 1.946 | Acc: 39.121% (10040/25664)
Loss: 1.945 | Acc: 39.250% (12585/32064)
Loss: 1.942 | Acc: 39.289% (15112/38464)
Loss: 1.944 | Acc: 39.174% (17575/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9925, Accuracy: 3666/10000 (36.66%)

Epoch: 13
Loss: 2.132 | Acc: 28.125% (18/64)
Loss: 1.927 | Acc: 40.053% (2589/6464)
Loss: 1.928 | Acc: 39.925% (5136/12864)
Loss: 1.929 | Acc: 39.955% (7697/19264)
Loss: 1.930 | Acc: 39.904% (10241/25664)
Loss: 1.931 | Acc: 39.914% (12798/32064)
Loss: 1.931 | Acc: 40.006% (15388/38464)
Loss: 1.931 | Acc: 40.086% (17984/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9922, Accuracy: 3774/10000 (37.74%)

Epoch: 14
Loss: 1.949 | Acc: 39.062% (25/64)
Loss: 1.920 | Acc: 40.687% (2630/6464)
Loss: 1.917 | Acc: 40.664% (5231/12864)
Loss: 1.917 | Acc: 40.822% (7864/19264)
Loss: 1.918 | Acc: 40.847% (10483/25664)
Loss: 1.919 | Acc: 40.868% (13104/32064)
Loss: 1.918 | Acc: 40.895% (15730/38464)
Loss: 1.917 | Acc: 41.013% (18400/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0947, Accuracy: 3026/10000 (30.26%)

Epoch: 15
Loss: 1.913 | Acc: 40.625% (26/64)
Loss: 1.917 | Acc: 40.749% (2634/6464)
Loss: 1.912 | Acc: 41.332% (5317/12864)
Loss: 1.914 | Acc: 41.232% (7943/19264)
Loss: 1.912 | Acc: 41.326% (10606/25664)
Loss: 1.910 | Acc: 41.514% (13311/32064)
Loss: 1.908 | Acc: 41.543% (15979/38464)
Loss: 1.910 | Acc: 41.461% (18601/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1260, Accuracy: 3041/10000 (30.41%)

Epoch: 16
Loss: 2.191 | Acc: 29.688% (19/64)
Loss: 1.883 | Acc: 42.450% (2744/6464)
Loss: 1.897 | Acc: 41.713% (5366/12864)
Loss: 1.902 | Acc: 41.606% (8015/19264)
Loss: 1.906 | Acc: 41.545% (10662/25664)
Loss: 1.905 | Acc: 41.642% (13352/32064)
Loss: 1.903 | Acc: 41.756% (16061/38464)
Loss: 1.898 | Acc: 41.989% (18838/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1092, Accuracy: 3166/10000 (31.66%)

Epoch: 17
Loss: 1.890 | Acc: 42.188% (27/64)
Loss: 1.890 | Acc: 42.791% (2766/6464)
Loss: 1.900 | Acc: 42.094% (5415/12864)
Loss: 1.900 | Acc: 42.208% (8131/19264)
Loss: 1.896 | Acc: 42.476% (10901/25664)
Loss: 1.899 | Acc: 42.315% (13568/32064)
Loss: 1.896 | Acc: 42.401% (16309/38464)
Loss: 1.894 | Acc: 42.475% (19056/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0484, Accuracy: 3543/10000 (35.43%)

Epoch: 18
Loss: 1.993 | Acc: 40.625% (26/64)
Loss: 1.868 | Acc: 43.456% (2809/6464)
Loss: 1.883 | Acc: 42.817% (5508/12864)
Loss: 1.884 | Acc: 42.790% (8243/19264)
Loss: 1.884 | Acc: 42.830% (10992/25664)
Loss: 1.883 | Acc: 43.020% (13794/32064)
Loss: 1.883 | Acc: 43.017% (16546/38464)
Loss: 1.882 | Acc: 43.113% (19342/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9609, Accuracy: 3967/10000 (39.67%)

Epoch: 19
Loss: 2.153 | Acc: 28.125% (18/64)
Loss: 1.868 | Acc: 43.564% (2816/6464)
Loss: 1.869 | Acc: 43.649% (5615/12864)
Loss: 1.862 | Acc: 44.051% (8486/19264)
Loss: 1.866 | Acc: 43.918% (11271/25664)
Loss: 1.870 | Acc: 43.607% (13982/32064)
Loss: 1.874 | Acc: 43.485% (16726/38464)
Loss: 1.873 | Acc: 43.505% (19518/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0159, Accuracy: 3593/10000 (35.93%)

Epoch: 20
Loss: 1.817 | Acc: 42.188% (27/64)
Loss: 1.865 | Acc: 43.533% (2814/6464)
Loss: 1.859 | Acc: 43.975% (5657/12864)
Loss: 1.861 | Acc: 43.973% (8471/19264)
Loss: 1.865 | Acc: 43.750% (11228/25664)
Loss: 1.865 | Acc: 43.819% (14050/32064)
Loss: 1.866 | Acc: 43.784% (16841/38464)
Loss: 1.868 | Acc: 43.719% (19614/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9544, Accuracy: 3955/10000 (39.55%)

Epoch: 21
Loss: 1.909 | Acc: 46.875% (30/64)
Loss: 1.857 | Acc: 44.199% (2857/6464)
Loss: 1.859 | Acc: 44.007% (5661/12864)
Loss: 1.856 | Acc: 44.150% (8505/19264)
Loss: 1.860 | Acc: 44.038% (11302/25664)
Loss: 1.861 | Acc: 44.024% (14116/32064)
Loss: 1.863 | Acc: 43.888% (16881/38464)
Loss: 1.859 | Acc: 44.064% (19769/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9424, Accuracy: 3981/10000 (39.81%)

Epoch: 22
Loss: 1.731 | Acc: 48.438% (31/64)
Loss: 1.842 | Acc: 44.771% (2894/6464)
Loss: 1.854 | Acc: 44.185% (5684/12864)
Loss: 1.853 | Acc: 44.279% (8530/19264)
Loss: 1.856 | Acc: 44.245% (11355/25664)
Loss: 1.854 | Acc: 44.399% (14236/32064)
Loss: 1.854 | Acc: 44.449% (17097/38464)
Loss: 1.852 | Acc: 44.570% (19996/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9420, Accuracy: 4084/10000 (40.84%)

Epoch: 23
Loss: 1.764 | Acc: 50.000% (32/64)
Loss: 1.836 | Acc: 45.529% (2943/6464)
Loss: 1.846 | Acc: 44.963% (5784/12864)
Loss: 1.848 | Acc: 44.928% (8655/19264)
Loss: 1.851 | Acc: 44.763% (11488/25664)
Loss: 1.851 | Acc: 44.779% (14358/32064)
Loss: 1.852 | Acc: 44.657% (17177/38464)
Loss: 1.848 | Acc: 44.858% (20125/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0719, Accuracy: 3390/10000 (33.90%)

Epoch: 24
Loss: 1.773 | Acc: 50.000% (32/64)
Loss: 1.857 | Acc: 44.168% (2855/6464)
Loss: 1.846 | Acc: 44.838% (5768/12864)
Loss: 1.844 | Acc: 45.120% (8692/19264)
Loss: 1.848 | Acc: 44.966% (11540/25664)
Loss: 1.842 | Acc: 45.119% (14467/32064)
Loss: 1.841 | Acc: 45.170% (17374/38464)
Loss: 1.843 | Acc: 45.027% (20201/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9355, Accuracy: 4048/10000 (40.48%)

Epoch: 25
Loss: 1.786 | Acc: 48.438% (31/64)
Loss: 1.812 | Acc: 46.442% (3002/6464)
Loss: 1.823 | Acc: 45.810% (5893/12864)
Loss: 1.826 | Acc: 45.837% (8830/19264)
Loss: 1.827 | Acc: 45.913% (11783/25664)
Loss: 1.829 | Acc: 45.858% (14704/32064)
Loss: 1.831 | Acc: 45.747% (17596/38464)
Loss: 1.832 | Acc: 45.676% (20492/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9836, Accuracy: 3717/10000 (37.17%)

Epoch: 26
Loss: 1.960 | Acc: 40.625% (26/64)
Loss: 1.843 | Acc: 45.328% (2930/6464)
Loss: 1.844 | Acc: 45.367% (5836/12864)
Loss: 1.834 | Acc: 45.712% (8806/19264)
Loss: 1.833 | Acc: 45.628% (11710/25664)
Loss: 1.833 | Acc: 45.665% (14642/32064)
Loss: 1.830 | Acc: 45.721% (17586/38464)
Loss: 1.828 | Acc: 45.803% (20549/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9142, Accuracy: 4108/10000 (41.08%)

Epoch: 27
Loss: 1.923 | Acc: 34.375% (22/64)
Loss: 1.842 | Acc: 44.570% (2881/6464)
Loss: 1.821 | Acc: 46.012% (5919/12864)
Loss: 1.816 | Acc: 46.029% (8867/19264)
Loss: 1.820 | Acc: 45.889% (11777/25664)
Loss: 1.819 | Acc: 46.033% (14760/32064)
Loss: 1.814 | Acc: 46.277% (17800/38464)
Loss: 1.813 | Acc: 46.394% (20814/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9084, Accuracy: 4225/10000 (42.25%)

Epoch: 28
Loss: 1.740 | Acc: 53.125% (34/64)
Loss: 1.805 | Acc: 46.860% (3029/6464)
Loss: 1.813 | Acc: 46.611% (5996/12864)
Loss: 1.807 | Acc: 46.865% (9028/19264)
Loss: 1.810 | Acc: 46.575% (11953/25664)
Loss: 1.809 | Acc: 46.654% (14959/32064)
Loss: 1.810 | Acc: 46.628% (17935/38464)
Loss: 1.807 | Acc: 46.755% (20976/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8958, Accuracy: 4317/10000 (43.17%)

Epoch: 29
Loss: 1.859 | Acc: 40.625% (26/64)
Loss: 1.790 | Acc: 47.432% (3066/6464)
Loss: 1.788 | Acc: 47.652% (6130/12864)
Loss: 1.788 | Acc: 47.560% (9162/19264)
Loss: 1.793 | Acc: 47.261% (12129/25664)
Loss: 1.792 | Acc: 47.290% (15163/32064)
Loss: 1.796 | Acc: 47.182% (18148/38464)
Loss: 1.796 | Acc: 47.194% (21173/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8638, Accuracy: 4461/10000 (44.61%)

Epoch: 30
Loss: 2.022 | Acc: 42.188% (27/64)
Loss: 1.763 | Acc: 48.793% (3154/6464)
Loss: 1.768 | Acc: 48.438% (6231/12864)
Loss: 1.775 | Acc: 48.323% (9309/19264)
Loss: 1.778 | Acc: 48.184% (12366/25664)
Loss: 1.781 | Acc: 48.101% (15423/32064)
Loss: 1.787 | Acc: 47.832% (18398/38464)
Loss: 1.788 | Acc: 47.856% (21470/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9156, Accuracy: 4172/10000 (41.72%)

Epoch: 31
Loss: 1.797 | Acc: 48.438% (31/64)
Loss: 1.767 | Acc: 48.623% (3143/6464)
Loss: 1.773 | Acc: 48.259% (6208/12864)
Loss: 1.777 | Acc: 48.110% (9268/19264)
Loss: 1.778 | Acc: 48.075% (12338/25664)
Loss: 1.775 | Acc: 48.191% (15452/32064)
Loss: 1.775 | Acc: 48.206% (18542/38464)
Loss: 1.778 | Acc: 48.032% (21549/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9049, Accuracy: 4245/10000 (42.45%)

Epoch: 32
Loss: 1.620 | Acc: 50.000% (32/64)
Loss: 1.770 | Acc: 48.639% (3144/6464)
Loss: 1.772 | Acc: 48.329% (6217/12864)
Loss: 1.774 | Acc: 48.162% (9278/19264)
Loss: 1.772 | Acc: 48.309% (12398/25664)
Loss: 1.770 | Acc: 48.416% (15524/32064)
Loss: 1.771 | Acc: 48.326% (18588/38464)
Loss: 1.771 | Acc: 48.406% (21717/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9074, Accuracy: 4330/10000 (43.30%)

Epoch: 33
Loss: 1.729 | Acc: 48.438% (31/64)
Loss: 1.729 | Acc: 49.876% (3224/6464)
Loss: 1.742 | Acc: 49.456% (6362/12864)
Loss: 1.740 | Acc: 49.574% (9550/19264)
Loss: 1.748 | Acc: 49.287% (12649/25664)
Loss: 1.749 | Acc: 49.227% (15784/32064)
Loss: 1.752 | Acc: 49.072% (18875/38464)
Loss: 1.756 | Acc: 48.961% (21966/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8731, Accuracy: 4460/10000 (44.60%)

Epoch: 34
Loss: 1.728 | Acc: 51.562% (33/64)
Loss: 1.731 | Acc: 49.861% (3223/6464)
Loss: 1.731 | Acc: 49.883% (6417/12864)
Loss: 1.734 | Acc: 49.746% (9583/19264)
Loss: 1.741 | Acc: 49.556% (12718/25664)
Loss: 1.743 | Acc: 49.489% (15868/32064)
Loss: 1.744 | Acc: 49.410% (19005/38464)
Loss: 1.745 | Acc: 49.458% (22189/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9097, Accuracy: 4274/10000 (42.74%)

Epoch: 35
Loss: 1.462 | Acc: 60.938% (39/64)
Loss: 1.682 | Acc: 51.779% (3347/6464)
Loss: 1.703 | Acc: 50.925% (6551/12864)
Loss: 1.716 | Acc: 50.363% (9702/19264)
Loss: 1.719 | Acc: 50.269% (12901/25664)
Loss: 1.724 | Acc: 50.162% (16084/32064)
Loss: 1.724 | Acc: 50.088% (19266/38464)
Loss: 1.729 | Acc: 49.877% (22377/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8844, Accuracy: 4377/10000 (43.77%)

Epoch: 36
Loss: 1.742 | Acc: 53.125% (34/64)
Loss: 1.726 | Acc: 49.861% (3223/6464)
Loss: 1.713 | Acc: 50.420% (6486/12864)
Loss: 1.713 | Acc: 50.514% (9731/19264)
Loss: 1.713 | Acc: 50.409% (12937/25664)
Loss: 1.713 | Acc: 50.412% (16164/32064)
Loss: 1.714 | Acc: 50.393% (19383/38464)
Loss: 1.714 | Acc: 50.408% (22615/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8747, Accuracy: 4515/10000 (45.15%)

Epoch: 37
Loss: 1.673 | Acc: 50.000% (32/64)
Loss: 1.689 | Acc: 51.470% (3327/6464)
Loss: 1.693 | Acc: 51.322% (6602/12864)
Loss: 1.694 | Acc: 51.184% (9860/19264)
Loss: 1.696 | Acc: 51.169% (13132/25664)
Loss: 1.702 | Acc: 50.892% (16318/32064)
Loss: 1.704 | Acc: 50.861% (19563/38464)
Loss: 1.701 | Acc: 50.943% (22855/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9075, Accuracy: 4405/10000 (44.05%)

Epoch: 38
Loss: 1.796 | Acc: 45.312% (29/64)
Loss: 1.676 | Acc: 51.562% (3333/6464)
Loss: 1.675 | Acc: 51.765% (6659/12864)
Loss: 1.679 | Acc: 51.734% (9966/19264)
Loss: 1.685 | Acc: 51.477% (13211/25664)
Loss: 1.684 | Acc: 51.534% (16524/32064)
Loss: 1.679 | Acc: 51.734% (19899/38464)
Loss: 1.682 | Acc: 51.641% (23168/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9019, Accuracy: 4402/10000 (44.02%)

Epoch: 39
Loss: 1.726 | Acc: 45.312% (29/64)
Loss: 1.642 | Acc: 52.568% (3398/6464)
Loss: 1.640 | Acc: 52.830% (6796/12864)
Loss: 1.654 | Acc: 52.352% (10085/19264)
Loss: 1.649 | Acc: 52.533% (13482/25664)
Loss: 1.651 | Acc: 52.532% (16844/32064)
Loss: 1.651 | Acc: 52.540% (20209/38464)
Loss: 1.659 | Acc: 52.218% (23427/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9209, Accuracy: 4356/10000 (43.56%)

Epoch: 40
Loss: 1.616 | Acc: 54.688% (35/64)
Loss: 1.626 | Acc: 52.754% (3410/6464)
Loss: 1.627 | Acc: 53.109% (6832/12864)
Loss: 1.632 | Acc: 53.026% (10215/19264)
Loss: 1.634 | Acc: 52.950% (13589/25664)
Loss: 1.633 | Acc: 52.957% (16980/32064)
Loss: 1.636 | Acc: 52.790% (20305/38464)
Loss: 1.637 | Acc: 52.759% (23670/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8910, Accuracy: 4570/10000 (45.70%)

Epoch: 41
Loss: 1.661 | Acc: 48.438% (31/64)
Loss: 1.584 | Acc: 54.162% (3501/6464)
Loss: 1.594 | Acc: 53.724% (6911/12864)
Loss: 1.593 | Acc: 53.769% (10358/19264)
Loss: 1.597 | Acc: 53.620% (13761/25664)
Loss: 1.600 | Acc: 53.655% (17204/32064)
Loss: 1.602 | Acc: 53.606% (20619/38464)
Loss: 1.603 | Acc: 53.591% (24043/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9290, Accuracy: 4431/10000 (44.31%)

Epoch: 42
Loss: 1.445 | Acc: 59.375% (38/64)
Loss: 1.587 | Acc: 53.605% (3465/6464)
Loss: 1.585 | Acc: 53.724% (6911/12864)
Loss: 1.579 | Acc: 54.028% (10408/19264)
Loss: 1.579 | Acc: 54.072% (13877/25664)
Loss: 1.577 | Acc: 54.210% (17382/32064)
Loss: 1.575 | Acc: 54.344% (20903/38464)
Loss: 1.573 | Acc: 54.409% (24410/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9324, Accuracy: 4498/10000 (44.98%)

Epoch: 43
Loss: 1.509 | Acc: 56.250% (36/64)
Loss: 1.498 | Acc: 56.606% (3659/6464)
Loss: 1.519 | Acc: 55.698% (7165/12864)
Loss: 1.527 | Acc: 55.502% (10692/19264)
Loss: 1.528 | Acc: 55.521% (14249/25664)
Loss: 1.529 | Acc: 55.542% (17809/32064)
Loss: 1.531 | Acc: 55.540% (21363/38464)
Loss: 1.531 | Acc: 55.526% (24911/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9508, Accuracy: 4421/10000 (44.21%)

Epoch: 44
Loss: 1.352 | Acc: 62.500% (40/64)
Loss: 1.465 | Acc: 56.977% (3683/6464)
Loss: 1.477 | Acc: 56.748% (7300/12864)
Loss: 1.470 | Acc: 57.236% (11026/19264)
Loss: 1.476 | Acc: 56.990% (14626/25664)
Loss: 1.481 | Acc: 56.765% (18201/32064)
Loss: 1.483 | Acc: 56.723% (21818/38464)
Loss: 1.485 | Acc: 56.749% (25460/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9828, Accuracy: 4418/10000 (44.18%)

Epoch: 45
Loss: 1.452 | Acc: 56.250% (36/64)
Loss: 1.426 | Acc: 57.983% (3748/6464)
Loss: 1.416 | Acc: 58.318% (7502/12864)
Loss: 1.430 | Acc: 58.041% (11181/19264)
Loss: 1.436 | Acc: 57.824% (14840/25664)
Loss: 1.433 | Acc: 57.947% (18580/32064)
Loss: 1.427 | Acc: 58.169% (22374/38464)
Loss: 1.423 | Acc: 58.292% (26152/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0246, Accuracy: 4305/10000 (43.05%)

Epoch: 46
Loss: 1.315 | Acc: 65.625% (42/64)
Loss: 1.376 | Acc: 59.220% (3828/6464)
Loss: 1.371 | Acc: 59.585% (7665/12864)
Loss: 1.370 | Acc: 59.619% (11485/19264)
Loss: 1.371 | Acc: 59.663% (15312/25664)
Loss: 1.368 | Acc: 59.768% (19164/32064)
Loss: 1.372 | Acc: 59.723% (22972/38464)
Loss: 1.371 | Acc: 59.752% (26807/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0460, Accuracy: 4251/10000 (42.51%)

Epoch: 47
Loss: 1.193 | Acc: 68.750% (44/64)
Loss: 1.319 | Acc: 60.938% (3939/6464)
Loss: 1.328 | Acc: 60.798% (7821/12864)
Loss: 1.318 | Acc: 61.275% (11804/19264)
Loss: 1.314 | Acc: 61.479% (15778/25664)
Loss: 1.322 | Acc: 61.153% (19608/32064)
Loss: 1.322 | Acc: 61.114% (23507/38464)
Loss: 1.324 | Acc: 61.087% (27406/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0641, Accuracy: 4250/10000 (42.50%)
torch.Size([100, 10])
Test set: Average loss: 2.0641, Accuracy: 4250/10000 (42.50%)

Epoch: 48
Loss: 1.366 | Acc: 54.688% (35/64)
Loss: 1.278 | Acc: 61.835% (3997/6464)
Loss: 1.280 | Acc: 62.041% (7981/12864)
Loss: 1.290 | Acc: 61.851% (11915/19264)
Loss: 1.296 | Acc: 61.721% (15840/25664)
Loss: 1.292 | Acc: 61.895% (19846/32064)
Loss: 1.289 | Acc: 61.970% (23836/38464)
Loss: 1.289 | Acc: 61.938% (27788/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0781, Accuracy: 4220/10000 (42.20%)
torch.Size([100, 10])
Test set: Average loss: 2.0781, Accuracy: 4220/10000 (42.20%)

Epoch: 49
Loss: 1.307 | Acc: 64.062% (41/64)
Loss: 1.294 | Acc: 61.293% (3962/6464)
Loss: 1.287 | Acc: 61.808% (7951/12864)
Loss: 1.283 | Acc: 62.085% (11960/19264)
Loss: 1.275 | Acc: 62.352% (16002/25664)
Loss: 1.271 | Acc: 62.528% (20049/32064)
Loss: 1.272 | Acc: 62.565% (24065/38464)
Loss: 1.268 | Acc: 62.689% (28125/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0793, Accuracy: 4223/10000 (42.23%)
torch.Size([100, 10])
Test set: Average loss: 2.0793, Accuracy: 4223/10000 (42.23%)

Epoch: 50
Loss: 1.285 | Acc: 65.625% (42/64)
Loss: 2.150 | Acc: 24.598% (1590/6464)
Loss: 2.073 | Acc: 30.613% (3938/12864)
Loss: 2.028 | Acc: 33.669% (6486/19264)
Loss: 2.005 | Acc: 35.291% (9057/25664)
Loss: 1.987 | Acc: 36.518% (11709/32064)
Loss: 1.975 | Acc: 37.274% (14337/38464)
Loss: 1.965 | Acc: 37.961% (17031/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1544, Accuracy: 3014/10000 (30.14%)

Epoch: 51
Loss: 1.966 | Acc: 34.375% (22/64)
Loss: 1.895 | Acc: 42.079% (2720/6464)
Loss: 1.898 | Acc: 42.343% (5447/12864)
Loss: 1.895 | Acc: 42.431% (8174/19264)
Loss: 1.890 | Acc: 42.667% (10950/25664)
Loss: 1.888 | Acc: 42.846% (13738/32064)
Loss: 1.885 | Acc: 42.970% (16528/38464)
Loss: 1.884 | Acc: 43.003% (19293/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0391, Accuracy: 3627/10000 (36.27%)

Epoch: 52
Loss: 1.617 | Acc: 48.438% (31/64)
Loss: 1.863 | Acc: 43.889% (2837/6464)
Loss: 1.868 | Acc: 43.688% (5620/12864)
Loss: 1.867 | Acc: 43.843% (8446/19264)
Loss: 1.872 | Acc: 43.633% (11198/25664)
Loss: 1.871 | Acc: 43.709% (14015/32064)
Loss: 1.868 | Acc: 43.838% (16862/38464)
Loss: 1.871 | Acc: 43.734% (19621/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0974, Accuracy: 3194/10000 (31.94%)

Epoch: 53
Loss: 1.801 | Acc: 42.188% (27/64)
Loss: 1.854 | Acc: 44.322% (2865/6464)
Loss: 1.856 | Acc: 44.403% (5712/12864)
Loss: 1.863 | Acc: 44.155% (8506/19264)
Loss: 1.868 | Acc: 43.918% (11271/25664)
Loss: 1.871 | Acc: 43.828% (14053/32064)
Loss: 1.872 | Acc: 43.721% (16817/38464)
Loss: 1.873 | Acc: 43.719% (19614/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0248, Accuracy: 3690/10000 (36.90%)

Epoch: 54
Loss: 1.733 | Acc: 54.688% (35/64)
Loss: 1.863 | Acc: 43.781% (2830/6464)
Loss: 1.868 | Acc: 43.696% (5621/12864)
Loss: 1.867 | Acc: 43.662% (8411/19264)
Loss: 1.862 | Acc: 43.933% (11275/25664)
Loss: 1.865 | Acc: 43.837% (14056/32064)
Loss: 1.865 | Acc: 43.896% (16884/38464)
Loss: 1.865 | Acc: 43.944% (19715/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0873, Accuracy: 3274/10000 (32.74%)

Epoch: 55
Loss: 1.802 | Acc: 45.312% (29/64)
Loss: 1.855 | Acc: 44.028% (2846/6464)
Loss: 1.862 | Acc: 44.045% (5666/12864)
Loss: 1.859 | Acc: 44.233% (8521/19264)
Loss: 1.860 | Acc: 44.260% (11359/25664)
Loss: 1.860 | Acc: 44.261% (14192/32064)
Loss: 1.860 | Acc: 44.252% (17021/38464)
Loss: 1.862 | Acc: 44.120% (19794/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1408, Accuracy: 3254/10000 (32.54%)

Epoch: 56
Loss: 2.129 | Acc: 34.375% (22/64)
Loss: 1.865 | Acc: 43.796% (2831/6464)
Loss: 1.857 | Acc: 44.146% (5679/12864)
Loss: 1.858 | Acc: 44.331% (8540/19264)
Loss: 1.867 | Acc: 43.960% (11282/25664)
Loss: 1.864 | Acc: 44.106% (14142/32064)
Loss: 1.861 | Acc: 44.244% (17018/38464)
Loss: 1.862 | Acc: 44.187% (19824/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0584, Accuracy: 3541/10000 (35.41%)

Epoch: 57
Loss: 2.040 | Acc: 39.062% (25/64)
Loss: 1.837 | Acc: 45.746% (2957/6464)
Loss: 1.846 | Acc: 45.414% (5842/12864)
Loss: 1.855 | Acc: 45.032% (8675/19264)
Loss: 1.856 | Acc: 44.884% (11519/25664)
Loss: 1.857 | Acc: 44.789% (14361/32064)
Loss: 1.860 | Acc: 44.618% (17162/38464)
Loss: 1.857 | Acc: 44.682% (20046/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9784, Accuracy: 3824/10000 (38.24%)

Epoch: 58
Loss: 1.657 | Acc: 50.000% (32/64)
Loss: 1.843 | Acc: 44.663% (2887/6464)
Loss: 1.851 | Acc: 44.512% (5726/12864)
Loss: 1.853 | Acc: 44.440% (8561/19264)
Loss: 1.853 | Acc: 44.459% (11410/25664)
Loss: 1.854 | Acc: 44.514% (14273/32064)
Loss: 1.855 | Acc: 44.499% (17116/38464)
Loss: 1.854 | Acc: 44.586% (20003/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0333, Accuracy: 3537/10000 (35.37%)

Epoch: 59
Loss: 1.828 | Acc: 48.438% (31/64)
Loss: 1.860 | Acc: 44.926% (2904/6464)
Loss: 1.847 | Acc: 45.157% (5809/12864)
Loss: 1.850 | Acc: 44.970% (8663/19264)
Loss: 1.847 | Acc: 45.114% (11578/25664)
Loss: 1.850 | Acc: 44.932% (14407/32064)
Loss: 1.852 | Acc: 44.813% (17237/38464)
Loss: 1.854 | Acc: 44.691% (20050/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0405, Accuracy: 3515/10000 (35.15%)

Epoch: 60
Loss: 2.042 | Acc: 34.375% (22/64)
Loss: 1.852 | Acc: 44.756% (2893/6464)
Loss: 1.857 | Acc: 44.496% (5724/12864)
Loss: 1.858 | Acc: 44.513% (8575/19264)
Loss: 1.854 | Acc: 44.654% (11460/25664)
Loss: 1.854 | Acc: 44.729% (14342/32064)
Loss: 1.854 | Acc: 44.709% (17197/38464)
Loss: 1.855 | Acc: 44.666% (20039/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0714, Accuracy: 3480/10000 (34.80%)

Epoch: 61
Loss: 1.829 | Acc: 42.188% (27/64)
Loss: 1.835 | Acc: 45.374% (2933/6464)
Loss: 1.836 | Acc: 45.445% (5846/12864)
Loss: 1.843 | Acc: 45.032% (8675/19264)
Loss: 1.850 | Acc: 44.740% (11482/25664)
Loss: 1.850 | Acc: 44.757% (14351/32064)
Loss: 1.849 | Acc: 44.813% (17237/38464)
Loss: 1.848 | Acc: 44.811% (20104/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9379, Accuracy: 4032/10000 (40.32%)

Epoch: 62
Loss: 1.737 | Acc: 50.000% (32/64)
Loss: 1.838 | Acc: 45.606% (2948/6464)
Loss: 1.841 | Acc: 45.499% (5853/12864)
Loss: 1.841 | Acc: 45.562% (8777/19264)
Loss: 1.839 | Acc: 45.620% (11708/25664)
Loss: 1.845 | Acc: 45.350% (14541/32064)
Loss: 1.846 | Acc: 45.312% (17429/38464)
Loss: 1.846 | Acc: 45.279% (20314/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9995, Accuracy: 3771/10000 (37.71%)

Epoch: 63
Loss: 1.702 | Acc: 53.125% (34/64)
Loss: 1.829 | Acc: 45.328% (2930/6464)
Loss: 1.832 | Acc: 45.530% (5857/12864)
Loss: 1.826 | Acc: 45.946% (8851/19264)
Loss: 1.833 | Acc: 45.663% (11719/25664)
Loss: 1.838 | Acc: 45.509% (14592/32064)
Loss: 1.843 | Acc: 45.253% (17406/38464)
Loss: 1.844 | Acc: 45.263% (20307/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9799, Accuracy: 3803/10000 (38.03%)

Epoch: 64
Loss: 2.029 | Acc: 39.062% (25/64)
Loss: 1.832 | Acc: 45.668% (2952/6464)
Loss: 1.835 | Acc: 45.538% (5858/12864)
Loss: 1.831 | Acc: 45.712% (8806/19264)
Loss: 1.836 | Acc: 45.511% (11680/25664)
Loss: 1.837 | Acc: 45.490% (14586/32064)
Loss: 1.837 | Acc: 45.479% (17493/38464)
Loss: 1.841 | Acc: 45.279% (20314/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9540, Accuracy: 3941/10000 (39.41%)

Epoch: 65
Loss: 1.595 | Acc: 59.375% (38/64)
Loss: 1.824 | Acc: 46.148% (2983/6464)
Loss: 1.822 | Acc: 46.059% (5925/12864)
Loss: 1.835 | Acc: 45.447% (8755/19264)
Loss: 1.838 | Acc: 45.351% (11639/25664)
Loss: 1.839 | Acc: 45.347% (14540/32064)
Loss: 1.841 | Acc: 45.307% (17427/38464)
Loss: 1.838 | Acc: 45.484% (20406/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0659, Accuracy: 3323/10000 (33.23%)

Epoch: 66
Loss: 1.957 | Acc: 39.062% (25/64)
Loss: 1.833 | Acc: 45.962% (2971/6464)
Loss: 1.839 | Acc: 45.421% (5843/12864)
Loss: 1.843 | Acc: 45.203% (8708/19264)
Loss: 1.838 | Acc: 45.383% (11647/25664)
Loss: 1.839 | Acc: 45.381% (14551/32064)
Loss: 1.837 | Acc: 45.453% (17483/38464)
Loss: 1.833 | Acc: 45.683% (20495/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9956, Accuracy: 3731/10000 (37.31%)

Epoch: 67
Loss: 1.680 | Acc: 54.688% (35/64)
Loss: 1.829 | Acc: 46.550% (3009/6464)
Loss: 1.835 | Acc: 46.051% (5924/12864)
Loss: 1.831 | Acc: 46.200% (8900/19264)
Loss: 1.832 | Acc: 46.053% (11819/25664)
Loss: 1.829 | Acc: 46.142% (14795/32064)
Loss: 1.830 | Acc: 46.090% (17728/38464)
Loss: 1.828 | Acc: 46.106% (20685/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0523, Accuracy: 3629/10000 (36.29%)

Epoch: 68
Loss: 1.904 | Acc: 43.750% (28/64)
Loss: 1.833 | Acc: 46.101% (2980/6464)
Loss: 1.816 | Acc: 46.502% (5982/12864)
Loss: 1.823 | Acc: 46.148% (8890/19264)
Loss: 1.816 | Acc: 46.462% (11924/25664)
Loss: 1.817 | Acc: 46.401% (14878/32064)
Loss: 1.821 | Acc: 46.202% (17771/38464)
Loss: 1.822 | Acc: 46.157% (20708/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9082, Accuracy: 4295/10000 (42.95%)

Epoch: 69
Loss: 1.894 | Acc: 43.750% (28/64)
Loss: 1.790 | Acc: 47.788% (3089/6464)
Loss: 1.795 | Acc: 47.536% (6115/12864)
Loss: 1.813 | Acc: 46.709% (8998/19264)
Loss: 1.817 | Acc: 46.594% (11958/25664)
Loss: 1.818 | Acc: 46.485% (14905/32064)
Loss: 1.818 | Acc: 46.521% (17894/38464)
Loss: 1.819 | Acc: 46.494% (20859/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9237, Accuracy: 4074/10000 (40.74%)

Epoch: 70
Loss: 1.877 | Acc: 43.750% (28/64)
Loss: 1.789 | Acc: 47.772% (3088/6464)
Loss: 1.796 | Acc: 47.520% (6113/12864)
Loss: 1.808 | Acc: 46.808% (9017/19264)
Loss: 1.808 | Acc: 46.926% (12043/25664)
Loss: 1.812 | Acc: 46.707% (14976/32064)
Loss: 1.814 | Acc: 46.672% (17952/38464)
Loss: 1.814 | Acc: 46.608% (20910/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0032, Accuracy: 3677/10000 (36.77%)

Epoch: 71
Loss: 1.802 | Acc: 43.750% (28/64)
Loss: 1.776 | Acc: 48.020% (3104/6464)
Loss: 1.791 | Acc: 47.365% (6093/12864)
Loss: 1.798 | Acc: 47.337% (9119/19264)
Loss: 1.802 | Acc: 47.280% (12134/25664)
Loss: 1.805 | Acc: 47.121% (15109/32064)
Loss: 1.805 | Acc: 47.018% (18085/38464)
Loss: 1.806 | Acc: 46.931% (21055/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9296, Accuracy: 4130/10000 (41.30%)

Epoch: 72
Loss: 1.854 | Acc: 40.625% (26/64)
Loss: 1.791 | Acc: 47.803% (3090/6464)
Loss: 1.801 | Acc: 47.132% (6063/12864)
Loss: 1.809 | Acc: 46.699% (8996/19264)
Loss: 1.805 | Acc: 46.945% (12048/25664)
Loss: 1.805 | Acc: 46.987% (15066/32064)
Loss: 1.800 | Acc: 47.210% (18159/38464)
Loss: 1.802 | Acc: 47.203% (21177/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9562, Accuracy: 4056/10000 (40.56%)

Epoch: 73
Loss: 1.681 | Acc: 51.562% (33/64)
Loss: 1.804 | Acc: 47.061% (3042/6464)
Loss: 1.797 | Acc: 47.598% (6123/12864)
Loss: 1.801 | Acc: 47.384% (9128/19264)
Loss: 1.801 | Acc: 47.308% (12141/25664)
Loss: 1.801 | Acc: 47.377% (15191/32064)
Loss: 1.799 | Acc: 47.452% (18252/38464)
Loss: 1.797 | Acc: 47.481% (21302/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0104, Accuracy: 3686/10000 (36.86%)

Epoch: 74
Loss: 1.830 | Acc: 48.438% (31/64)
Loss: 1.792 | Acc: 47.401% (3064/6464)
Loss: 1.790 | Acc: 47.598% (6123/12864)
Loss: 1.790 | Acc: 47.674% (9184/19264)
Loss: 1.792 | Acc: 47.588% (12213/25664)
Loss: 1.787 | Acc: 47.851% (15343/32064)
Loss: 1.792 | Acc: 47.645% (18326/38464)
Loss: 1.792 | Acc: 47.664% (21384/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9067, Accuracy: 4235/10000 (42.35%)

Epoch: 75
Loss: 1.589 | Acc: 50.000% (32/64)
Loss: 1.752 | Acc: 48.685% (3147/6464)
Loss: 1.762 | Acc: 48.570% (6248/12864)
Loss: 1.774 | Acc: 48.194% (9284/19264)
Loss: 1.778 | Acc: 48.091% (12342/25664)
Loss: 1.779 | Acc: 47.992% (15388/32064)
Loss: 1.781 | Acc: 47.949% (18443/38464)
Loss: 1.783 | Acc: 47.900% (21490/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9006, Accuracy: 4311/10000 (43.11%)

Epoch: 76
Loss: 1.711 | Acc: 54.688% (35/64)
Loss: 1.761 | Acc: 48.902% (3161/6464)
Loss: 1.758 | Acc: 49.036% (6308/12864)
Loss: 1.771 | Acc: 48.552% (9353/19264)
Loss: 1.775 | Acc: 48.375% (12415/25664)
Loss: 1.776 | Acc: 48.235% (15466/32064)
Loss: 1.779 | Acc: 48.172% (18529/38464)
Loss: 1.776 | Acc: 48.331% (21683/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9102, Accuracy: 4213/10000 (42.13%)

Epoch: 77
Loss: 1.775 | Acc: 48.438% (31/64)
Loss: 1.780 | Acc: 47.679% (3082/6464)
Loss: 1.769 | Acc: 48.406% (6227/12864)
Loss: 1.771 | Acc: 48.349% (9314/19264)
Loss: 1.776 | Acc: 48.208% (12372/25664)
Loss: 1.773 | Acc: 48.406% (15521/32064)
Loss: 1.771 | Acc: 48.567% (18681/38464)
Loss: 1.771 | Acc: 48.518% (21767/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8993, Accuracy: 4309/10000 (43.09%)

Epoch: 78
Loss: 1.759 | Acc: 50.000% (32/64)
Loss: 1.765 | Acc: 48.360% (3126/6464)
Loss: 1.769 | Acc: 48.422% (6229/12864)
Loss: 1.765 | Acc: 48.609% (9364/19264)
Loss: 1.764 | Acc: 48.769% (12516/25664)
Loss: 1.759 | Acc: 48.871% (15670/32064)
Loss: 1.759 | Acc: 48.895% (18807/38464)
Loss: 1.762 | Acc: 48.776% (21883/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8800, Accuracy: 4456/10000 (44.56%)

Epoch: 79
Loss: 1.597 | Acc: 57.812% (37/64)
Loss: 1.748 | Acc: 49.397% (3193/6464)
Loss: 1.753 | Acc: 49.052% (6310/12864)
Loss: 1.751 | Acc: 49.206% (9479/19264)
Loss: 1.752 | Acc: 49.186% (12623/25664)
Loss: 1.753 | Acc: 49.092% (15741/32064)
Loss: 1.753 | Acc: 49.069% (18874/38464)
Loss: 1.751 | Acc: 49.171% (22060/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8705, Accuracy: 4474/10000 (44.74%)

Epoch: 80
Loss: 1.876 | Acc: 37.500% (24/64)
Loss: 1.764 | Acc: 48.577% (3140/6464)
Loss: 1.745 | Acc: 49.448% (6361/12864)
Loss: 1.741 | Acc: 49.548% (9545/19264)
Loss: 1.741 | Acc: 49.525% (12710/25664)
Loss: 1.742 | Acc: 49.507% (15874/32064)
Loss: 1.744 | Acc: 49.436% (19015/38464)
Loss: 1.746 | Acc: 49.380% (22154/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8590, Accuracy: 4596/10000 (45.96%)

Epoch: 81
Loss: 1.865 | Acc: 43.750% (28/64)
Loss: 1.721 | Acc: 50.155% (3242/6464)
Loss: 1.729 | Acc: 49.806% (6407/12864)
Loss: 1.733 | Acc: 49.595% (9554/19264)
Loss: 1.735 | Acc: 49.556% (12718/25664)
Loss: 1.734 | Acc: 49.779% (15961/32064)
Loss: 1.731 | Acc: 49.974% (19222/38464)
Loss: 1.734 | Acc: 49.833% (22357/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8815, Accuracy: 4425/10000 (44.25%)

Epoch: 82
Loss: 1.708 | Acc: 51.562% (33/64)
Loss: 1.729 | Acc: 49.845% (3222/6464)
Loss: 1.726 | Acc: 50.078% (6442/12864)
Loss: 1.722 | Acc: 50.317% (9693/19264)
Loss: 1.722 | Acc: 50.288% (12906/25664)
Loss: 1.721 | Acc: 50.303% (16129/32064)
Loss: 1.724 | Acc: 50.244% (19326/38464)
Loss: 1.723 | Acc: 50.361% (22594/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8655, Accuracy: 4563/10000 (45.63%)

Epoch: 83
Loss: 1.807 | Acc: 46.875% (30/64)
Loss: 1.682 | Acc: 51.903% (3355/6464)
Loss: 1.684 | Acc: 51.749% (6657/12864)
Loss: 1.691 | Acc: 51.531% (9927/19264)
Loss: 1.699 | Acc: 51.192% (13138/25664)
Loss: 1.700 | Acc: 51.092% (16382/32064)
Loss: 1.703 | Acc: 50.931% (19590/38464)
Loss: 1.704 | Acc: 50.950% (22858/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9022, Accuracy: 4332/10000 (43.32%)

Epoch: 84
Loss: 1.964 | Acc: 42.188% (27/64)
Loss: 1.690 | Acc: 51.315% (3317/6464)
Loss: 1.680 | Acc: 51.640% (6643/12864)
Loss: 1.691 | Acc: 51.355% (9893/19264)
Loss: 1.699 | Acc: 50.998% (13088/25664)
Loss: 1.697 | Acc: 51.095% (16383/32064)
Loss: 1.697 | Acc: 51.100% (19655/38464)
Loss: 1.695 | Acc: 51.188% (22965/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8719, Accuracy: 4487/10000 (44.87%)

Epoch: 85
Loss: 1.636 | Acc: 54.688% (35/64)
Loss: 1.682 | Acc: 51.176% (3308/6464)
Loss: 1.674 | Acc: 51.671% (6647/12864)
Loss: 1.667 | Acc: 51.905% (9999/19264)
Loss: 1.665 | Acc: 52.092% (13369/25664)
Loss: 1.667 | Acc: 52.086% (16701/32064)
Loss: 1.673 | Acc: 51.908% (19966/38464)
Loss: 1.679 | Acc: 51.685% (23188/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9032, Accuracy: 4396/10000 (43.96%)

Epoch: 86
Loss: 1.747 | Acc: 46.875% (30/64)
Loss: 1.645 | Acc: 53.001% (3426/6464)
Loss: 1.643 | Acc: 53.016% (6820/12864)
Loss: 1.640 | Acc: 53.172% (10243/19264)
Loss: 1.647 | Acc: 52.880% (13571/25664)
Loss: 1.655 | Acc: 52.573% (16857/32064)
Loss: 1.660 | Acc: 52.407% (20158/38464)
Loss: 1.659 | Acc: 52.479% (23544/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9065, Accuracy: 4380/10000 (43.80%)

Epoch: 87
Loss: 1.353 | Acc: 65.625% (42/64)
Loss: 1.626 | Acc: 52.816% (3414/6464)
Loss: 1.629 | Acc: 52.977% (6815/12864)
Loss: 1.636 | Acc: 52.710% (10154/19264)
Loss: 1.638 | Acc: 52.689% (13522/25664)
Loss: 1.636 | Acc: 52.807% (16932/32064)
Loss: 1.637 | Acc: 52.839% (20324/38464)
Loss: 1.634 | Acc: 52.971% (23765/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8909, Accuracy: 4553/10000 (45.53%)

Epoch: 88
Loss: 1.696 | Acc: 53.125% (34/64)
Loss: 1.609 | Acc: 53.682% (3470/6464)
Loss: 1.611 | Acc: 53.436% (6874/12864)
Loss: 1.614 | Acc: 53.426% (10292/19264)
Loss: 1.612 | Acc: 53.534% (13739/25664)
Loss: 1.614 | Acc: 53.452% (17139/32064)
Loss: 1.608 | Acc: 53.687% (20650/38464)
Loss: 1.609 | Acc: 53.664% (24076/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8995, Accuracy: 4484/10000 (44.84%)

Epoch: 89
Loss: 1.464 | Acc: 60.938% (39/64)
Loss: 1.581 | Acc: 54.657% (3533/6464)
Loss: 1.559 | Acc: 55.597% (7152/12864)
Loss: 1.569 | Acc: 55.186% (10631/19264)
Loss: 1.575 | Acc: 54.828% (14071/25664)
Loss: 1.574 | Acc: 54.812% (17575/32064)
Loss: 1.577 | Acc: 54.703% (21041/38464)
Loss: 1.580 | Acc: 54.581% (24487/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9053, Accuracy: 4529/10000 (45.29%)

Epoch: 90
Loss: 1.666 | Acc: 51.562% (33/64)
Loss: 1.518 | Acc: 56.606% (3659/6464)
Loss: 1.530 | Acc: 55.885% (7189/12864)
Loss: 1.541 | Acc: 55.477% (10687/19264)
Loss: 1.542 | Acc: 55.455% (14232/25664)
Loss: 1.548 | Acc: 55.202% (17700/32064)
Loss: 1.550 | Acc: 55.220% (21240/38464)
Loss: 1.549 | Acc: 55.267% (24795/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9549, Accuracy: 4465/10000 (44.65%)

Epoch: 91
Loss: 1.434 | Acc: 57.812% (37/64)
Loss: 1.498 | Acc: 56.451% (3649/6464)
Loss: 1.501 | Acc: 56.437% (7260/12864)
Loss: 1.500 | Acc: 56.307% (10847/19264)
Loss: 1.500 | Acc: 56.453% (14488/25664)
Loss: 1.504 | Acc: 56.353% (18069/32064)
Loss: 1.504 | Acc: 56.380% (21686/38464)
Loss: 1.505 | Acc: 56.386% (25297/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9601, Accuracy: 4460/10000 (44.60%)

Epoch: 92
Loss: 1.574 | Acc: 59.375% (38/64)
Loss: 1.456 | Acc: 57.843% (3739/6464)
Loss: 1.437 | Acc: 58.473% (7522/12864)
Loss: 1.445 | Acc: 58.150% (11202/19264)
Loss: 1.449 | Acc: 58.000% (14885/25664)
Loss: 1.458 | Acc: 57.597% (18468/32064)
Loss: 1.457 | Acc: 57.638% (22170/38464)
Loss: 1.459 | Acc: 57.585% (25835/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0143, Accuracy: 4290/10000 (42.90%)

Epoch: 93
Loss: 1.363 | Acc: 64.062% (41/64)
Loss: 1.394 | Acc: 59.220% (3828/6464)
Loss: 1.386 | Acc: 59.818% (7695/12864)
Loss: 1.389 | Acc: 59.702% (11501/19264)
Loss: 1.396 | Acc: 59.352% (15232/25664)
Loss: 1.395 | Acc: 59.381% (19040/32064)
Loss: 1.403 | Acc: 59.089% (22728/38464)
Loss: 1.406 | Acc: 59.021% (26479/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0136, Accuracy: 4377/10000 (43.77%)

Epoch: 94
Loss: 1.317 | Acc: 56.250% (36/64)
Loss: 1.319 | Acc: 61.603% (3982/6464)
Loss: 1.327 | Acc: 61.272% (7882/12864)
Loss: 1.338 | Acc: 61.140% (11778/19264)
Loss: 1.342 | Acc: 60.887% (15626/25664)
Loss: 1.344 | Acc: 60.719% (19469/32064)
Loss: 1.344 | Acc: 60.685% (23342/38464)
Loss: 1.343 | Acc: 60.703% (27234/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0893, Accuracy: 4254/10000 (42.54%)

Epoch: 95
Loss: 1.076 | Acc: 67.188% (43/64)
Loss: 1.254 | Acc: 62.918% (4067/6464)
Loss: 1.270 | Acc: 62.329% (8018/12864)
Loss: 1.273 | Acc: 62.355% (12012/19264)
Loss: 1.277 | Acc: 62.196% (15962/25664)
Loss: 1.283 | Acc: 62.045% (19894/32064)
Loss: 1.284 | Acc: 61.941% (23825/38464)
Loss: 1.282 | Acc: 62.092% (27857/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1690, Accuracy: 4210/10000 (42.10%)

Epoch: 96
Loss: 1.141 | Acc: 67.188% (43/64)
Loss: 1.229 | Acc: 63.413% (4099/6464)
Loss: 1.219 | Acc: 63.759% (8202/12864)
Loss: 1.219 | Acc: 63.834% (12297/19264)
Loss: 1.220 | Acc: 63.829% (16381/25664)
Loss: 1.217 | Acc: 63.969% (20511/32064)
Loss: 1.216 | Acc: 63.959% (24601/38464)
Loss: 1.215 | Acc: 64.016% (28720/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1857, Accuracy: 4213/10000 (42.13%)

Epoch: 97
Loss: 1.125 | Acc: 64.062% (41/64)
Loss: 1.148 | Acc: 66.089% (4272/6464)
Loss: 1.155 | Acc: 65.835% (8469/12864)
Loss: 1.162 | Acc: 65.428% (12604/19264)
Loss: 1.160 | Acc: 65.547% (16822/25664)
Loss: 1.159 | Acc: 65.560% (21021/32064)
Loss: 1.158 | Acc: 65.620% (25240/38464)
Loss: 1.159 | Acc: 65.527% (29398/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2051, Accuracy: 4137/10000 (41.37%)
torch.Size([100, 10])
Test set: Average loss: 2.2051, Accuracy: 4137/10000 (41.37%)

Epoch: 98
Loss: 1.020 | Acc: 67.188% (43/64)
Loss: 1.117 | Acc: 66.863% (4322/6464)
Loss: 1.133 | Acc: 66.091% (8502/12864)
Loss: 1.127 | Acc: 66.352% (12782/19264)
Loss: 1.128 | Acc: 66.330% (17023/25664)
Loss: 1.127 | Acc: 66.367% (21280/32064)
Loss: 1.123 | Acc: 66.579% (25609/38464)
Loss: 1.123 | Acc: 66.608% (29883/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2364, Accuracy: 4125/10000 (41.25%)
torch.Size([100, 10])
Test set: Average loss: 2.2364, Accuracy: 4125/10000 (41.25%)

Epoch: 99
Loss: 1.080 | Acc: 70.312% (45/64)
Loss: 1.099 | Acc: 67.373% (4355/6464)
Loss: 1.101 | Acc: 67.250% (8651/12864)
Loss: 1.098 | Acc: 67.193% (12944/19264)
Loss: 1.099 | Acc: 67.262% (17262/25664)
Loss: 1.099 | Acc: 67.269% (21569/32064)
Loss: 1.098 | Acc: 67.258% (25870/38464)
Loss: 1.100 | Acc: 67.214% (30155/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2390, Accuracy: 4128/10000 (41.28%)
torch.Size([100, 10])
Test set: Average loss: 2.2390, Accuracy: 4128/10000 (41.28%)

Epoch: 100
Loss: 1.081 | Acc: 65.625% (42/64)
Loss: 2.154 | Acc: 25.928% (1676/6464)
Loss: 2.056 | Acc: 32.121% (4132/12864)
Loss: 2.006 | Acc: 35.424% (6824/19264)
Loss: 1.974 | Acc: 37.329% (9580/25664)
Loss: 1.957 | Acc: 38.445% (12327/32064)
Loss: 1.943 | Acc: 39.216% (15084/38464)
Loss: 1.932 | Acc: 39.845% (17876/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1537, Accuracy: 2808/10000 (28.08%)

Epoch: 101
Loss: 2.131 | Acc: 29.688% (19/64)
Loss: 1.850 | Acc: 44.462% (2874/6464)
Loss: 1.852 | Acc: 44.294% (5698/12864)
Loss: 1.845 | Acc: 44.627% (8597/19264)
Loss: 1.849 | Acc: 44.549% (11433/25664)
Loss: 1.848 | Acc: 44.670% (14323/32064)
Loss: 1.848 | Acc: 44.761% (17217/38464)
Loss: 1.851 | Acc: 44.646% (20030/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0602, Accuracy: 3512/10000 (35.12%)

Epoch: 102
Loss: 1.900 | Acc: 37.500% (24/64)
Loss: 1.840 | Acc: 45.405% (2935/6464)
Loss: 1.841 | Acc: 45.110% (5803/12864)
Loss: 1.845 | Acc: 45.006% (8670/19264)
Loss: 1.841 | Acc: 45.180% (11595/25664)
Loss: 1.842 | Acc: 45.135% (14472/32064)
Loss: 1.846 | Acc: 44.956% (17292/38464)
Loss: 1.849 | Acc: 44.831% (20113/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2146, Accuracy: 3093/10000 (30.93%)

Epoch: 103
Loss: 2.014 | Acc: 37.500% (24/64)
Loss: 1.846 | Acc: 44.879% (2901/6464)
Loss: 1.847 | Acc: 44.869% (5772/12864)
Loss: 1.845 | Acc: 44.960% (8661/19264)
Loss: 1.845 | Acc: 45.075% (11568/25664)
Loss: 1.843 | Acc: 45.085% (14456/32064)
Loss: 1.843 | Acc: 45.105% (17349/38464)
Loss: 1.844 | Acc: 45.041% (20207/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0702, Accuracy: 3524/10000 (35.24%)

Epoch: 104
Loss: 1.831 | Acc: 51.562% (33/64)
Loss: 1.823 | Acc: 46.426% (3001/6464)
Loss: 1.830 | Acc: 45.888% (5903/12864)
Loss: 1.830 | Acc: 45.754% (8814/19264)
Loss: 1.834 | Acc: 45.644% (11714/25664)
Loss: 1.837 | Acc: 45.599% (14621/32064)
Loss: 1.842 | Acc: 45.437% (17477/38464)
Loss: 1.842 | Acc: 45.442% (20387/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0602, Accuracy: 3317/10000 (33.17%)

Epoch: 105
Loss: 2.164 | Acc: 26.562% (17/64)
Loss: 1.848 | Acc: 45.019% (2910/6464)
Loss: 1.830 | Acc: 45.763% (5887/12864)
Loss: 1.838 | Acc: 45.406% (8747/19264)
Loss: 1.836 | Acc: 45.402% (11652/25664)
Loss: 1.838 | Acc: 45.284% (14520/32064)
Loss: 1.840 | Acc: 45.209% (17389/38464)
Loss: 1.841 | Acc: 45.177% (20268/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2770, Accuracy: 2815/10000 (28.15%)

Epoch: 106
Loss: 2.186 | Acc: 28.125% (18/64)
Loss: 1.839 | Acc: 45.637% (2950/6464)
Loss: 1.853 | Acc: 45.079% (5799/12864)
Loss: 1.850 | Acc: 45.203% (8708/19264)
Loss: 1.850 | Acc: 45.219% (11605/25664)
Loss: 1.848 | Acc: 45.362% (14545/32064)
Loss: 1.849 | Acc: 45.385% (17457/38464)
Loss: 1.845 | Acc: 45.538% (20430/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0343, Accuracy: 3574/10000 (35.74%)

Epoch: 107
Loss: 2.051 | Acc: 35.938% (23/64)
Loss: 1.821 | Acc: 45.869% (2965/6464)
Loss: 1.831 | Acc: 45.686% (5877/12864)
Loss: 1.828 | Acc: 45.935% (8849/19264)
Loss: 1.834 | Acc: 45.581% (11698/25664)
Loss: 1.832 | Acc: 45.646% (14636/32064)
Loss: 1.836 | Acc: 45.494% (17499/38464)
Loss: 1.838 | Acc: 45.493% (20410/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0202, Accuracy: 3753/10000 (37.53%)

Epoch: 108
Loss: 2.035 | Acc: 34.375% (22/64)
Loss: 1.827 | Acc: 45.931% (2969/6464)
Loss: 1.821 | Acc: 46.160% (5938/12864)
Loss: 1.826 | Acc: 45.935% (8849/19264)
Loss: 1.830 | Acc: 45.819% (11759/25664)
Loss: 1.832 | Acc: 45.624% (14629/32064)
Loss: 1.835 | Acc: 45.604% (17541/38464)
Loss: 1.836 | Acc: 45.564% (20442/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1895, Accuracy: 2706/10000 (27.06%)

Epoch: 109
Loss: 1.815 | Acc: 51.562% (33/64)
Loss: 1.849 | Acc: 45.220% (2923/6464)
Loss: 1.829 | Acc: 45.896% (5904/12864)
Loss: 1.833 | Acc: 45.640% (8792/19264)
Loss: 1.832 | Acc: 45.741% (11739/25664)
Loss: 1.836 | Acc: 45.528% (14598/32064)
Loss: 1.836 | Acc: 45.559% (17524/38464)
Loss: 1.838 | Acc: 45.522% (20423/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9577, Accuracy: 4045/10000 (40.45%)

Epoch: 110
Loss: 1.840 | Acc: 39.062% (25/64)
Loss: 1.848 | Acc: 45.003% (2909/6464)
Loss: 1.838 | Acc: 45.445% (5846/12864)
Loss: 1.833 | Acc: 45.624% (8789/19264)
Loss: 1.833 | Acc: 45.609% (11705/25664)
Loss: 1.834 | Acc: 45.540% (14602/32064)
Loss: 1.834 | Acc: 45.598% (17539/38464)
Loss: 1.832 | Acc: 45.676% (20492/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0330, Accuracy: 3590/10000 (35.90%)

Epoch: 111
Loss: 1.854 | Acc: 39.062% (25/64)
Loss: 1.816 | Acc: 46.071% (2978/6464)
Loss: 1.819 | Acc: 46.238% (5948/12864)
Loss: 1.823 | Acc: 46.112% (8883/19264)
Loss: 1.825 | Acc: 46.096% (11830/25664)
Loss: 1.830 | Acc: 45.936% (14729/32064)
Loss: 1.832 | Acc: 45.822% (17625/38464)
Loss: 1.833 | Acc: 45.839% (20565/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9752, Accuracy: 3880/10000 (38.80%)

Epoch: 112
Loss: 1.818 | Acc: 43.750% (28/64)
Loss: 1.808 | Acc: 46.875% (3030/6464)
Loss: 1.818 | Acc: 46.471% (5978/12864)
Loss: 1.820 | Acc: 46.351% (8929/19264)
Loss: 1.825 | Acc: 46.193% (11855/25664)
Loss: 1.826 | Acc: 46.120% (14788/32064)
Loss: 1.830 | Acc: 45.874% (17645/38464)
Loss: 1.829 | Acc: 45.917% (20600/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9235, Accuracy: 4113/10000 (41.13%)

Epoch: 113
Loss: 1.703 | Acc: 53.125% (34/64)
Loss: 1.802 | Acc: 47.432% (3066/6464)
Loss: 1.812 | Acc: 46.945% (6039/12864)
Loss: 1.815 | Acc: 46.880% (9031/19264)
Loss: 1.818 | Acc: 46.649% (11972/25664)
Loss: 1.821 | Acc: 46.410% (14881/32064)
Loss: 1.827 | Acc: 46.142% (17748/38464)
Loss: 1.827 | Acc: 46.135% (20698/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9261, Accuracy: 4211/10000 (42.11%)

Epoch: 114
Loss: 1.715 | Acc: 48.438% (31/64)
Loss: 1.814 | Acc: 46.658% (3016/6464)
Loss: 1.818 | Acc: 46.471% (5978/12864)
Loss: 1.820 | Acc: 46.444% (8947/19264)
Loss: 1.818 | Acc: 46.513% (11937/25664)
Loss: 1.820 | Acc: 46.554% (14927/32064)
Loss: 1.822 | Acc: 46.459% (17870/38464)
Loss: 1.823 | Acc: 46.300% (20772/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0722, Accuracy: 3402/10000 (34.02%)

Epoch: 115
Loss: 1.883 | Acc: 45.312% (29/64)
Loss: 1.794 | Acc: 47.092% (3044/6464)
Loss: 1.817 | Acc: 46.401% (5969/12864)
Loss: 1.817 | Acc: 46.418% (8942/19264)
Loss: 1.821 | Acc: 46.357% (11897/25664)
Loss: 1.823 | Acc: 46.114% (14786/32064)
Loss: 1.821 | Acc: 46.238% (17785/38464)
Loss: 1.820 | Acc: 46.295% (20770/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9170, Accuracy: 4176/10000 (41.76%)

Epoch: 116
Loss: 1.610 | Acc: 57.812% (37/64)
Loss: 1.803 | Acc: 47.401% (3064/6464)
Loss: 1.809 | Acc: 46.999% (6046/12864)
Loss: 1.814 | Acc: 46.782% (9012/19264)
Loss: 1.815 | Acc: 46.789% (12008/25664)
Loss: 1.814 | Acc: 46.691% (14971/32064)
Loss: 1.814 | Acc: 46.703% (17964/38464)
Loss: 1.816 | Acc: 46.605% (20909/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9870, Accuracy: 3856/10000 (38.56%)

Epoch: 117
Loss: 1.660 | Acc: 46.875% (30/64)
Loss: 1.798 | Acc: 47.200% (3051/6464)
Loss: 1.808 | Acc: 46.859% (6028/12864)
Loss: 1.812 | Acc: 46.735% (9003/19264)
Loss: 1.817 | Acc: 46.583% (11955/25664)
Loss: 1.817 | Acc: 46.569% (14932/32064)
Loss: 1.818 | Acc: 46.631% (17936/38464)
Loss: 1.816 | Acc: 46.668% (20937/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0356, Accuracy: 3745/10000 (37.45%)

Epoch: 118
Loss: 2.015 | Acc: 35.938% (23/64)
Loss: 1.799 | Acc: 47.556% (3074/6464)
Loss: 1.801 | Acc: 47.676% (6133/12864)
Loss: 1.804 | Acc: 47.524% (9155/19264)
Loss: 1.806 | Acc: 47.300% (12139/25664)
Loss: 1.807 | Acc: 47.221% (15141/32064)
Loss: 1.806 | Acc: 47.213% (18160/38464)
Loss: 1.807 | Acc: 47.131% (21145/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9824, Accuracy: 3843/10000 (38.43%)

Epoch: 119
Loss: 1.688 | Acc: 50.000% (32/64)
Loss: 1.815 | Acc: 46.674% (3017/6464)
Loss: 1.808 | Acc: 46.797% (6020/12864)
Loss: 1.795 | Acc: 47.238% (9100/19264)
Loss: 1.800 | Acc: 47.245% (12125/25664)
Loss: 1.803 | Acc: 47.268% (15156/32064)
Loss: 1.805 | Acc: 47.210% (18159/38464)
Loss: 1.807 | Acc: 47.107% (21134/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0210, Accuracy: 3638/10000 (36.38%)

Epoch: 120
Loss: 1.648 | Acc: 51.562% (33/64)
Loss: 1.817 | Acc: 46.380% (2998/6464)
Loss: 1.808 | Acc: 46.805% (6021/12864)
Loss: 1.799 | Acc: 47.379% (9127/19264)
Loss: 1.799 | Acc: 47.300% (12139/25664)
Loss: 1.800 | Acc: 47.299% (15166/32064)
Loss: 1.800 | Acc: 47.322% (18202/38464)
Loss: 1.804 | Acc: 47.169% (21162/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9745, Accuracy: 3963/10000 (39.63%)

Epoch: 121
Loss: 1.780 | Acc: 51.562% (33/64)
Loss: 1.791 | Acc: 47.850% (3093/6464)
Loss: 1.790 | Acc: 47.878% (6159/12864)
Loss: 1.787 | Acc: 47.856% (9219/19264)
Loss: 1.791 | Acc: 47.701% (12242/25664)
Loss: 1.789 | Acc: 47.832% (15337/32064)
Loss: 1.793 | Acc: 47.660% (18332/38464)
Loss: 1.795 | Acc: 47.619% (21364/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9423, Accuracy: 4136/10000 (41.36%)

Epoch: 122
Loss: 1.939 | Acc: 40.625% (26/64)
Loss: 1.789 | Acc: 48.066% (3107/6464)
Loss: 1.794 | Acc: 47.994% (6174/12864)
Loss: 1.790 | Acc: 48.038% (9254/19264)
Loss: 1.786 | Acc: 48.149% (12357/25664)
Loss: 1.788 | Acc: 48.069% (15413/32064)
Loss: 1.788 | Acc: 48.003% (18464/38464)
Loss: 1.791 | Acc: 47.916% (21497/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8703, Accuracy: 4492/10000 (44.92%)

Epoch: 123
Loss: 1.903 | Acc: 40.625% (26/64)
Loss: 1.774 | Acc: 48.360% (3126/6464)
Loss: 1.783 | Acc: 48.088% (6186/12864)
Loss: 1.779 | Acc: 48.396% (9323/19264)
Loss: 1.775 | Acc: 48.550% (12460/25664)
Loss: 1.775 | Acc: 48.438% (15531/32064)
Loss: 1.777 | Acc: 48.352% (18598/38464)
Loss: 1.780 | Acc: 48.255% (21649/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8979, Accuracy: 4268/10000 (42.68%)

Epoch: 124
Loss: 1.695 | Acc: 53.125% (34/64)
Loss: 1.766 | Acc: 48.716% (3149/6464)
Loss: 1.761 | Acc: 48.748% (6271/12864)
Loss: 1.766 | Acc: 48.650% (9372/19264)
Loss: 1.766 | Acc: 48.687% (12495/25664)
Loss: 1.770 | Acc: 48.590% (15580/32064)
Loss: 1.775 | Acc: 48.378% (18608/38464)
Loss: 1.779 | Acc: 48.270% (21656/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9140, Accuracy: 4199/10000 (41.99%)

Epoch: 125
Loss: 1.701 | Acc: 51.562% (33/64)
Loss: 1.772 | Acc: 48.499% (3135/6464)
Loss: 1.762 | Acc: 48.780% (6275/12864)
Loss: 1.765 | Acc: 48.718% (9385/19264)
Loss: 1.760 | Acc: 48.854% (12538/25664)
Loss: 1.768 | Acc: 48.497% (15550/32064)
Loss: 1.769 | Acc: 48.440% (18632/38464)
Loss: 1.770 | Acc: 48.409% (21718/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9208, Accuracy: 4111/10000 (41.11%)

Epoch: 126
Loss: 1.828 | Acc: 42.188% (27/64)
Loss: 1.740 | Acc: 49.536% (3202/6464)
Loss: 1.759 | Acc: 48.842% (6283/12864)
Loss: 1.761 | Acc: 48.853% (9411/19264)
Loss: 1.765 | Acc: 48.683% (12494/25664)
Loss: 1.768 | Acc: 48.643% (15597/32064)
Loss: 1.760 | Acc: 48.944% (18826/38464)
Loss: 1.763 | Acc: 48.794% (21891/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9818, Accuracy: 3902/10000 (39.02%)

Epoch: 127
Loss: 1.667 | Acc: 56.250% (36/64)
Loss: 1.757 | Acc: 48.824% (3156/6464)
Loss: 1.752 | Acc: 49.215% (6331/12864)
Loss: 1.758 | Acc: 48.957% (9431/19264)
Loss: 1.757 | Acc: 49.026% (12582/25664)
Loss: 1.760 | Acc: 48.912% (15683/32064)
Loss: 1.756 | Acc: 49.069% (18874/38464)
Loss: 1.754 | Acc: 49.171% (22060/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0285, Accuracy: 3544/10000 (35.44%)

Epoch: 128
Loss: 2.135 | Acc: 26.562% (17/64)
Loss: 1.729 | Acc: 49.985% (3231/6464)
Loss: 1.737 | Acc: 49.604% (6381/12864)
Loss: 1.737 | Acc: 49.730% (9580/19264)
Loss: 1.741 | Acc: 49.595% (12728/25664)
Loss: 1.742 | Acc: 49.654% (15921/32064)
Loss: 1.742 | Acc: 49.665% (19103/38464)
Loss: 1.745 | Acc: 49.541% (22226/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8461, Accuracy: 4632/10000 (46.32%)

Epoch: 129
Loss: 1.661 | Acc: 56.250% (36/64)
Loss: 1.722 | Acc: 50.696% (3277/6464)
Loss: 1.720 | Acc: 50.746% (6528/12864)
Loss: 1.721 | Acc: 50.493% (9727/19264)
Loss: 1.723 | Acc: 50.378% (12929/25664)
Loss: 1.732 | Acc: 50.069% (16054/32064)
Loss: 1.736 | Acc: 49.948% (19212/38464)
Loss: 1.737 | Acc: 49.904% (22389/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9015, Accuracy: 4343/10000 (43.43%)

Epoch: 130
Loss: 1.883 | Acc: 40.625% (26/64)
Loss: 1.716 | Acc: 50.897% (3290/6464)
Loss: 1.724 | Acc: 50.288% (6469/12864)
Loss: 1.728 | Acc: 50.140% (9659/19264)
Loss: 1.728 | Acc: 50.222% (12889/25664)
Loss: 1.726 | Acc: 50.309% (16131/32064)
Loss: 1.727 | Acc: 50.317% (19354/38464)
Loss: 1.726 | Acc: 50.345% (22587/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8676, Accuracy: 4580/10000 (45.80%)

Epoch: 131
Loss: 1.898 | Acc: 42.188% (27/64)
Loss: 1.695 | Acc: 51.191% (3309/6464)
Loss: 1.702 | Acc: 51.119% (6576/12864)
Loss: 1.703 | Acc: 51.178% (9859/19264)
Loss: 1.703 | Acc: 51.196% (13139/25664)
Loss: 1.709 | Acc: 50.914% (16325/32064)
Loss: 1.713 | Acc: 50.749% (19520/38464)
Loss: 1.717 | Acc: 50.593% (22698/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8969, Accuracy: 4385/10000 (43.85%)

Epoch: 132
Loss: 2.178 | Acc: 31.250% (20/64)
Loss: 1.680 | Acc: 52.259% (3378/6464)
Loss: 1.686 | Acc: 51.765% (6659/12864)
Loss: 1.692 | Acc: 51.329% (9888/19264)
Loss: 1.694 | Acc: 51.290% (13163/25664)
Loss: 1.699 | Acc: 51.207% (16419/32064)
Loss: 1.702 | Acc: 51.037% (19631/38464)
Loss: 1.702 | Acc: 51.063% (22909/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8957, Accuracy: 4409/10000 (44.09%)

Epoch: 133
Loss: 1.663 | Acc: 53.125% (34/64)
Loss: 1.641 | Acc: 53.682% (3470/6464)
Loss: 1.678 | Acc: 51.967% (6685/12864)
Loss: 1.694 | Acc: 51.132% (9850/19264)
Loss: 1.693 | Acc: 51.255% (13154/25664)
Loss: 1.694 | Acc: 51.248% (16432/32064)
Loss: 1.691 | Acc: 51.381% (19763/38464)
Loss: 1.689 | Acc: 51.509% (23109/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8943, Accuracy: 4516/10000 (45.16%)

Epoch: 134
Loss: 1.505 | Acc: 59.375% (38/64)
Loss: 1.660 | Acc: 52.553% (3397/6464)
Loss: 1.672 | Acc: 51.897% (6676/12864)
Loss: 1.674 | Acc: 51.781% (9975/19264)
Loss: 1.673 | Acc: 51.855% (13308/25664)
Loss: 1.676 | Acc: 51.700% (16577/32064)
Loss: 1.672 | Acc: 51.880% (19955/38464)
Loss: 1.671 | Acc: 51.928% (23297/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8855, Accuracy: 4493/10000 (44.93%)

Epoch: 135
Loss: 1.884 | Acc: 46.875% (30/64)
Loss: 1.647 | Acc: 52.367% (3385/6464)
Loss: 1.644 | Acc: 52.666% (6775/12864)
Loss: 1.645 | Acc: 52.642% (10141/19264)
Loss: 1.650 | Acc: 52.568% (13491/25664)
Loss: 1.651 | Acc: 52.585% (16861/32064)
Loss: 1.654 | Acc: 52.433% (20168/38464)
Loss: 1.655 | Acc: 52.416% (23516/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9738, Accuracy: 4064/10000 (40.64%)

Epoch: 136
Loss: 1.971 | Acc: 37.500% (24/64)
Loss: 1.629 | Acc: 53.326% (3447/6464)
Loss: 1.624 | Acc: 53.483% (6880/12864)
Loss: 1.623 | Acc: 53.577% (10321/19264)
Loss: 1.633 | Acc: 53.148% (13640/25664)
Loss: 1.635 | Acc: 52.969% (16984/32064)
Loss: 1.636 | Acc: 52.951% (20367/38464)
Loss: 1.634 | Acc: 53.063% (23806/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9244, Accuracy: 4386/10000 (43.86%)

Epoch: 137
Loss: 1.617 | Acc: 53.125% (34/64)
Loss: 1.579 | Acc: 54.641% (3532/6464)
Loss: 1.591 | Acc: 54.089% (6958/12864)
Loss: 1.604 | Acc: 53.665% (10338/19264)
Loss: 1.600 | Acc: 53.971% (13851/25664)
Loss: 1.600 | Acc: 53.964% (17303/32064)
Loss: 1.603 | Acc: 53.837% (20708/38464)
Loss: 1.605 | Acc: 53.791% (24133/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9243, Accuracy: 4424/10000 (44.24%)

Epoch: 138
Loss: 1.707 | Acc: 50.000% (32/64)
Loss: 1.561 | Acc: 54.858% (3546/6464)
Loss: 1.565 | Acc: 54.944% (7068/12864)
Loss: 1.570 | Acc: 54.693% (10536/19264)
Loss: 1.577 | Acc: 54.500% (13987/25664)
Loss: 1.578 | Acc: 54.513% (17479/32064)
Loss: 1.575 | Acc: 54.591% (20998/38464)
Loss: 1.575 | Acc: 54.692% (24537/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9029, Accuracy: 4503/10000 (45.03%)

Epoch: 139
Loss: 1.500 | Acc: 59.375% (38/64)
Loss: 1.515 | Acc: 55.972% (3618/6464)
Loss: 1.515 | Acc: 56.211% (7231/12864)
Loss: 1.520 | Acc: 56.172% (10821/19264)
Loss: 1.526 | Acc: 55.938% (14356/25664)
Loss: 1.534 | Acc: 55.782% (17886/32064)
Loss: 1.539 | Acc: 55.631% (21398/38464)
Loss: 1.544 | Acc: 55.465% (24884/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9592, Accuracy: 4452/10000 (44.52%)

Epoch: 140
Loss: 1.753 | Acc: 45.312% (29/64)
Loss: 1.484 | Acc: 57.441% (3713/6464)
Loss: 1.500 | Acc: 56.569% (7277/12864)
Loss: 1.500 | Acc: 56.619% (10907/19264)
Loss: 1.502 | Acc: 56.554% (14514/25664)
Loss: 1.504 | Acc: 56.534% (18127/32064)
Loss: 1.508 | Acc: 56.383% (21687/38464)
Loss: 1.509 | Acc: 56.379% (25294/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9505, Accuracy: 4444/10000 (44.44%)

Epoch: 141
Loss: 1.464 | Acc: 53.125% (34/64)
Loss: 1.431 | Acc: 58.756% (3798/6464)
Loss: 1.440 | Acc: 58.411% (7514/12864)
Loss: 1.443 | Acc: 58.394% (11249/19264)
Loss: 1.451 | Acc: 58.003% (14886/25664)
Loss: 1.455 | Acc: 57.940% (18578/32064)
Loss: 1.457 | Acc: 57.953% (22291/38464)
Loss: 1.462 | Acc: 57.784% (25924/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9915, Accuracy: 4382/10000 (43.82%)

Epoch: 142
Loss: 1.208 | Acc: 67.188% (43/64)
Loss: 1.420 | Acc: 58.091% (3755/6464)
Loss: 1.415 | Acc: 58.605% (7539/12864)
Loss: 1.417 | Acc: 58.446% (11259/19264)
Loss: 1.414 | Acc: 58.615% (15043/25664)
Loss: 1.415 | Acc: 58.651% (18806/32064)
Loss: 1.413 | Acc: 58.800% (22617/38464)
Loss: 1.414 | Acc: 58.867% (26410/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0248, Accuracy: 4392/10000 (43.92%)

Epoch: 143
Loss: 1.185 | Acc: 64.062% (41/64)
Loss: 1.333 | Acc: 61.293% (3962/6464)
Loss: 1.348 | Acc: 60.782% (7819/12864)
Loss: 1.347 | Acc: 60.958% (11743/19264)
Loss: 1.352 | Acc: 60.692% (15576/25664)
Loss: 1.352 | Acc: 60.619% (19437/32064)
Loss: 1.352 | Acc: 60.571% (23298/38464)
Loss: 1.352 | Acc: 60.474% (27131/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0847, Accuracy: 4255/10000 (42.55%)

Epoch: 144
Loss: 1.443 | Acc: 57.812% (37/64)
Loss: 1.270 | Acc: 62.794% (4059/6464)
Loss: 1.283 | Acc: 62.197% (8001/12864)
Loss: 1.278 | Acc: 62.329% (12007/19264)
Loss: 1.281 | Acc: 62.258% (15978/25664)
Loss: 1.282 | Acc: 62.213% (19948/32064)
Loss: 1.280 | Acc: 62.336% (23977/38464)
Loss: 1.285 | Acc: 62.239% (27923/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1936, Accuracy: 4206/10000 (42.06%)

Epoch: 145
Loss: 1.082 | Acc: 67.188% (43/64)
Loss: 1.221 | Acc: 63.583% (4110/6464)
Loss: 1.223 | Acc: 63.588% (8180/12864)
Loss: 1.211 | Acc: 64.078% (12344/19264)
Loss: 1.214 | Acc: 64.070% (16443/25664)
Loss: 1.216 | Acc: 63.994% (20519/32064)
Loss: 1.219 | Acc: 63.938% (24593/38464)
Loss: 1.219 | Acc: 63.958% (28694/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2077, Accuracy: 4190/10000 (41.90%)

Epoch: 146
Loss: 1.143 | Acc: 64.062% (41/64)
Loss: 1.140 | Acc: 66.166% (4277/6464)
Loss: 1.141 | Acc: 66.161% (8511/12864)
Loss: 1.152 | Acc: 65.635% (12644/19264)
Loss: 1.147 | Acc: 65.789% (16884/25664)
Loss: 1.147 | Acc: 65.803% (21099/32064)
Loss: 1.152 | Acc: 65.667% (25258/38464)
Loss: 1.152 | Acc: 65.605% (29433/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2391, Accuracy: 4148/10000 (41.48%)

Epoch: 147
Loss: 1.113 | Acc: 67.188% (43/64)
Loss: 1.092 | Acc: 67.311% (4351/6464)
Loss: 1.093 | Acc: 67.444% (8676/12864)
Loss: 1.100 | Acc: 67.104% (12927/19264)
Loss: 1.097 | Acc: 67.262% (17262/25664)
Loss: 1.100 | Acc: 67.072% (21506/32064)
Loss: 1.103 | Acc: 66.982% (25764/38464)
Loss: 1.100 | Acc: 67.130% (30117/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2310, Accuracy: 4059/10000 (40.59%)
torch.Size([100, 10])
Test set: Average loss: 2.2310, Accuracy: 4059/10000 (40.59%)

Epoch: 148
Loss: 1.038 | Acc: 67.188% (43/64)
Loss: 1.074 | Acc: 68.069% (4400/6464)
Loss: 1.075 | Acc: 67.856% (8729/12864)
Loss: 1.070 | Acc: 68.200% (13138/19264)
Loss: 1.061 | Acc: 68.450% (17567/25664)
Loss: 1.060 | Acc: 68.435% (21943/32064)
Loss: 1.061 | Acc: 68.446% (26327/38464)
Loss: 1.061 | Acc: 68.433% (30702/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2898, Accuracy: 4064/10000 (40.64%)
torch.Size([100, 10])
Test set: Average loss: 2.2898, Accuracy: 4064/10000 (40.64%)

Epoch: 149
Loss: 1.079 | Acc: 73.438% (47/64)
Loss: 1.036 | Acc: 69.121% (4468/6464)
Loss: 1.040 | Acc: 69.038% (8881/12864)
Loss: 1.042 | Acc: 69.025% (13297/19264)
Loss: 1.044 | Acc: 68.953% (17696/25664)
Loss: 1.042 | Acc: 68.956% (22110/32064)
Loss: 1.040 | Acc: 69.018% (26547/38464)
Loss: 1.039 | Acc: 69.078% (30991/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2917, Accuracy: 4071/10000 (40.71%)
torch.Size([100, 10])
Test set: Average loss: 2.2917, Accuracy: 4071/10000 (40.71%)

Epoch: 150
Loss: 1.142 | Acc: 64.062% (41/64)
Loss: 2.275 | Acc: 14.774% (955/6464)
Loss: 2.230 | Acc: 17.848% (2296/12864)
Loss: 2.177 | Acc: 22.259% (4288/19264)
Loss: 2.120 | Acc: 26.469% (6793/25664)
Loss: 2.076 | Acc: 29.600% (9491/32064)
Loss: 2.045 | Acc: 31.728% (12204/38464)
Loss: 2.020 | Acc: 33.448% (15006/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5023, Accuracy: 1976/10000 (19.76%)

Epoch: 151
Loss: 1.932 | Acc: 45.312% (29/64)
Loss: 1.858 | Acc: 44.384% (2869/6464)
Loss: 1.851 | Acc: 44.683% (5748/12864)
Loss: 1.855 | Acc: 44.311% (8536/19264)
Loss: 1.856 | Acc: 44.331% (11377/25664)
Loss: 1.857 | Acc: 44.299% (14204/32064)
Loss: 1.859 | Acc: 44.228% (17012/38464)
Loss: 1.859 | Acc: 44.254% (19854/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1511, Accuracy: 3491/10000 (34.91%)

Epoch: 152
Loss: 1.713 | Acc: 46.875% (30/64)
Loss: 1.827 | Acc: 45.405% (2935/6464)
Loss: 1.836 | Acc: 45.320% (5830/12864)
Loss: 1.840 | Acc: 45.338% (8734/19264)
Loss: 1.844 | Acc: 45.090% (11572/25664)
Loss: 1.845 | Acc: 45.044% (14443/32064)
Loss: 1.845 | Acc: 45.058% (17331/38464)
Loss: 1.844 | Acc: 45.194% (20276/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9776, Accuracy: 3915/10000 (39.15%)

Epoch: 153
Loss: 1.829 | Acc: 42.188% (27/64)
Loss: 1.846 | Acc: 44.957% (2906/6464)
Loss: 1.836 | Acc: 45.468% (5849/12864)
Loss: 1.844 | Acc: 45.063% (8681/19264)
Loss: 1.836 | Acc: 45.538% (11687/25664)
Loss: 1.837 | Acc: 45.584% (14616/32064)
Loss: 1.840 | Acc: 45.494% (17499/38464)
Loss: 1.841 | Acc: 45.451% (20391/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9319, Accuracy: 4161/10000 (41.61%)

Epoch: 154
Loss: 2.130 | Acc: 32.812% (21/64)
Loss: 1.826 | Acc: 45.792% (2960/6464)
Loss: 1.829 | Acc: 45.585% (5864/12864)
Loss: 1.832 | Acc: 45.660% (8796/19264)
Loss: 1.835 | Acc: 45.480% (11672/25664)
Loss: 1.832 | Acc: 45.677% (14646/32064)
Loss: 1.833 | Acc: 45.708% (17581/38464)
Loss: 1.833 | Acc: 45.765% (20532/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9796, Accuracy: 3918/10000 (39.18%)

Epoch: 155
Loss: 1.785 | Acc: 43.750% (28/64)
Loss: 1.834 | Acc: 45.668% (2952/6464)
Loss: 1.842 | Acc: 45.569% (5862/12864)
Loss: 1.834 | Acc: 45.837% (8830/19264)
Loss: 1.833 | Acc: 45.842% (11765/25664)
Loss: 1.832 | Acc: 45.799% (14685/32064)
Loss: 1.833 | Acc: 45.731% (17590/38464)
Loss: 1.833 | Acc: 45.716% (20510/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0768, Accuracy: 3362/10000 (33.62%)

Epoch: 156
Loss: 1.656 | Acc: 54.688% (35/64)
Loss: 1.836 | Acc: 45.312% (2929/6464)
Loss: 1.836 | Acc: 45.351% (5834/12864)
Loss: 1.827 | Acc: 45.977% (8857/19264)
Loss: 1.828 | Acc: 45.819% (11759/25664)
Loss: 1.832 | Acc: 45.702% (14654/32064)
Loss: 1.832 | Acc: 45.687% (17573/38464)
Loss: 1.833 | Acc: 45.671% (20490/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9406, Accuracy: 4001/10000 (40.01%)

Epoch: 157
Loss: 1.912 | Acc: 40.625% (26/64)
Loss: 1.835 | Acc: 45.730% (2956/6464)
Loss: 1.828 | Acc: 46.160% (5938/12864)
Loss: 1.833 | Acc: 46.029% (8867/19264)
Loss: 1.833 | Acc: 45.959% (11795/25664)
Loss: 1.834 | Acc: 45.877% (14710/32064)
Loss: 1.834 | Acc: 45.871% (17644/38464)
Loss: 1.834 | Acc: 45.885% (20586/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9535, Accuracy: 4009/10000 (40.09%)

Epoch: 158
Loss: 1.925 | Acc: 46.875% (30/64)
Loss: 1.828 | Acc: 46.024% (2975/6464)
Loss: 1.830 | Acc: 46.043% (5923/12864)
Loss: 1.832 | Acc: 45.852% (8833/19264)
Loss: 1.831 | Acc: 45.998% (11805/25664)
Loss: 1.831 | Acc: 45.961% (14737/32064)
Loss: 1.829 | Acc: 46.025% (17703/38464)
Loss: 1.831 | Acc: 46.026% (20649/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9897, Accuracy: 3962/10000 (39.62%)

Epoch: 159
Loss: 1.714 | Acc: 53.125% (34/64)
Loss: 1.812 | Acc: 46.519% (3007/6464)
Loss: 1.820 | Acc: 46.175% (5940/12864)
Loss: 1.823 | Acc: 46.070% (8875/19264)
Loss: 1.825 | Acc: 45.975% (11799/25664)
Loss: 1.825 | Acc: 46.073% (14773/32064)
Loss: 1.828 | Acc: 45.994% (17691/38464)
Loss: 1.828 | Acc: 45.977% (20627/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1054, Accuracy: 3492/10000 (34.92%)

Epoch: 160
Loss: 1.905 | Acc: 39.062% (25/64)
Loss: 1.814 | Acc: 46.767% (3023/6464)
Loss: 1.819 | Acc: 46.447% (5975/12864)
Loss: 1.816 | Acc: 46.600% (8977/19264)
Loss: 1.822 | Acc: 46.396% (11907/25664)
Loss: 1.822 | Acc: 46.404% (14879/32064)
Loss: 1.824 | Acc: 46.290% (17805/38464)
Loss: 1.826 | Acc: 46.197% (20726/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9824, Accuracy: 3824/10000 (38.24%)

Epoch: 161
Loss: 1.996 | Acc: 43.750% (28/64)
Loss: 1.829 | Acc: 46.364% (2997/6464)
Loss: 1.818 | Acc: 46.665% (6003/12864)
Loss: 1.825 | Acc: 46.371% (8933/19264)
Loss: 1.828 | Acc: 46.185% (11853/25664)
Loss: 1.829 | Acc: 46.180% (14807/32064)
Loss: 1.828 | Acc: 46.176% (17761/38464)
Loss: 1.828 | Acc: 46.184% (20720/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9523, Accuracy: 3926/10000 (39.26%)

Epoch: 162
Loss: 1.664 | Acc: 56.250% (36/64)
Loss: 1.816 | Acc: 46.395% (2999/6464)
Loss: 1.815 | Acc: 46.657% (6002/12864)
Loss: 1.816 | Acc: 46.595% (8976/19264)
Loss: 1.818 | Acc: 46.520% (11939/25664)
Loss: 1.822 | Acc: 46.317% (14851/32064)
Loss: 1.819 | Acc: 46.532% (17898/38464)
Loss: 1.820 | Acc: 46.416% (20824/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1608, Accuracy: 3348/10000 (33.48%)

Epoch: 163
Loss: 1.914 | Acc: 40.625% (26/64)
Loss: 1.801 | Acc: 47.246% (3054/6464)
Loss: 1.806 | Acc: 46.999% (6046/12864)
Loss: 1.813 | Acc: 46.662% (8989/19264)
Loss: 1.817 | Acc: 46.446% (11920/25664)
Loss: 1.819 | Acc: 46.441% (14891/32064)
Loss: 1.819 | Acc: 46.482% (17879/38464)
Loss: 1.821 | Acc: 46.342% (20791/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0523, Accuracy: 3645/10000 (36.45%)

Epoch: 164
Loss: 1.911 | Acc: 42.188% (27/64)
Loss: 1.823 | Acc: 46.256% (2990/6464)
Loss: 1.811 | Acc: 46.852% (6027/12864)
Loss: 1.812 | Acc: 46.844% (9024/19264)
Loss: 1.817 | Acc: 46.610% (11962/25664)
Loss: 1.816 | Acc: 46.526% (14918/32064)
Loss: 1.818 | Acc: 46.516% (17892/38464)
Loss: 1.819 | Acc: 46.474% (20850/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0201, Accuracy: 3686/10000 (36.86%)

Epoch: 165
Loss: 2.007 | Acc: 45.312% (29/64)
Loss: 1.826 | Acc: 46.844% (3028/6464)
Loss: 1.823 | Acc: 46.743% (6013/12864)
Loss: 1.820 | Acc: 46.771% (9010/19264)
Loss: 1.818 | Acc: 46.711% (11988/25664)
Loss: 1.814 | Acc: 46.925% (15046/32064)
Loss: 1.814 | Acc: 46.911% (18044/38464)
Loss: 1.813 | Acc: 46.928% (21054/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9548, Accuracy: 3988/10000 (39.88%)

Epoch: 166
Loss: 1.955 | Acc: 39.062% (25/64)
Loss: 1.789 | Acc: 47.803% (3090/6464)
Loss: 1.799 | Acc: 47.357% (6092/12864)
Loss: 1.799 | Acc: 47.264% (9105/19264)
Loss: 1.806 | Acc: 46.922% (12042/25664)
Loss: 1.809 | Acc: 46.822% (15013/32064)
Loss: 1.811 | Acc: 46.722% (17971/38464)
Loss: 1.812 | Acc: 46.741% (20970/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9102, Accuracy: 4268/10000 (42.68%)

Epoch: 167
Loss: 2.036 | Acc: 42.188% (27/64)
Loss: 1.807 | Acc: 46.689% (3018/6464)
Loss: 1.805 | Acc: 47.007% (6047/12864)
Loss: 1.806 | Acc: 47.109% (9075/19264)
Loss: 1.802 | Acc: 47.374% (12158/25664)
Loss: 1.804 | Acc: 47.343% (15180/32064)
Loss: 1.806 | Acc: 47.265% (18180/38464)
Loss: 1.807 | Acc: 47.178% (21166/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9963, Accuracy: 3948/10000 (39.48%)

Epoch: 168
Loss: 1.785 | Acc: 51.562% (33/64)
Loss: 1.798 | Acc: 47.416% (3065/6464)
Loss: 1.806 | Acc: 46.992% (6045/12864)
Loss: 1.802 | Acc: 47.223% (9097/19264)
Loss: 1.799 | Acc: 47.315% (12143/25664)
Loss: 1.801 | Acc: 47.268% (15156/32064)
Loss: 1.801 | Acc: 47.187% (18150/38464)
Loss: 1.804 | Acc: 47.062% (21114/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9670, Accuracy: 3885/10000 (38.85%)

Epoch: 169
Loss: 1.959 | Acc: 35.938% (23/64)
Loss: 1.800 | Acc: 47.679% (3082/6464)
Loss: 1.803 | Acc: 47.427% (6101/12864)
Loss: 1.802 | Acc: 47.508% (9152/19264)
Loss: 1.803 | Acc: 47.401% (12165/25664)
Loss: 1.804 | Acc: 47.337% (15178/32064)
Loss: 1.803 | Acc: 47.348% (18212/38464)
Loss: 1.803 | Acc: 47.365% (21250/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9849, Accuracy: 3875/10000 (38.75%)

Epoch: 170
Loss: 1.877 | Acc: 48.438% (31/64)
Loss: 1.784 | Acc: 47.633% (3079/6464)
Loss: 1.791 | Acc: 47.497% (6110/12864)
Loss: 1.793 | Acc: 47.451% (9141/19264)
Loss: 1.794 | Acc: 47.323% (12145/25664)
Loss: 1.793 | Acc: 47.455% (15216/32064)
Loss: 1.794 | Acc: 47.437% (18246/38464)
Loss: 1.797 | Acc: 47.336% (21237/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9586, Accuracy: 3935/10000 (39.35%)

Epoch: 171
Loss: 1.869 | Acc: 42.188% (27/64)
Loss: 1.769 | Acc: 48.886% (3160/6464)
Loss: 1.779 | Acc: 48.290% (6212/12864)
Loss: 1.779 | Acc: 48.256% (9296/19264)
Loss: 1.783 | Acc: 48.060% (12334/25664)
Loss: 1.783 | Acc: 48.085% (15418/32064)
Loss: 1.786 | Acc: 48.006% (18465/38464)
Loss: 1.790 | Acc: 47.851% (21468/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2224, Accuracy: 2756/10000 (27.56%)

Epoch: 172
Loss: 1.816 | Acc: 45.312% (29/64)
Loss: 1.791 | Acc: 47.679% (3082/6464)
Loss: 1.779 | Acc: 48.064% (6183/12864)
Loss: 1.776 | Acc: 48.303% (9305/19264)
Loss: 1.777 | Acc: 48.247% (12382/25664)
Loss: 1.781 | Acc: 48.135% (15434/32064)
Loss: 1.783 | Acc: 48.053% (18483/38464)
Loss: 1.783 | Acc: 48.163% (21608/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9238, Accuracy: 4246/10000 (42.46%)

Epoch: 173
Loss: 1.787 | Acc: 51.562% (33/64)
Loss: 1.800 | Acc: 47.757% (3087/6464)
Loss: 1.786 | Acc: 47.785% (6147/12864)
Loss: 1.782 | Acc: 48.017% (9250/19264)
Loss: 1.779 | Acc: 48.052% (12332/25664)
Loss: 1.776 | Acc: 48.341% (15500/32064)
Loss: 1.779 | Acc: 48.204% (18541/38464)
Loss: 1.777 | Acc: 48.299% (21669/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8722, Accuracy: 4442/10000 (44.42%)

Epoch: 174
Loss: 1.743 | Acc: 48.438% (31/64)
Loss: 1.756 | Acc: 49.211% (3181/6464)
Loss: 1.766 | Acc: 48.531% (6243/12864)
Loss: 1.758 | Acc: 49.024% (9444/19264)
Loss: 1.762 | Acc: 48.940% (12560/25664)
Loss: 1.767 | Acc: 48.799% (15647/32064)
Loss: 1.769 | Acc: 48.721% (18740/38464)
Loss: 1.771 | Acc: 48.674% (21837/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9267, Accuracy: 4295/10000 (42.95%)

Epoch: 175
Loss: 1.656 | Acc: 51.562% (33/64)
Loss: 1.763 | Acc: 48.963% (3165/6464)
Loss: 1.762 | Acc: 48.881% (6288/12864)
Loss: 1.758 | Acc: 49.123% (9463/19264)
Loss: 1.759 | Acc: 49.170% (12619/25664)
Loss: 1.754 | Acc: 49.395% (15838/32064)
Loss: 1.757 | Acc: 49.197% (18923/38464)
Loss: 1.760 | Acc: 49.057% (22009/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8914, Accuracy: 4414/10000 (44.14%)

Epoch: 176
Loss: 1.857 | Acc: 45.312% (29/64)
Loss: 1.759 | Acc: 48.917% (3162/6464)
Loss: 1.760 | Acc: 48.989% (6302/12864)
Loss: 1.759 | Acc: 49.019% (9443/19264)
Loss: 1.765 | Acc: 48.835% (12533/25664)
Loss: 1.764 | Acc: 48.946% (15694/32064)
Loss: 1.758 | Acc: 49.186% (18919/38464)
Loss: 1.754 | Acc: 49.318% (22126/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9242, Accuracy: 4209/10000 (42.09%)

Epoch: 177
Loss: 1.763 | Acc: 43.750% (28/64)
Loss: 1.763 | Acc: 49.056% (3171/6464)
Loss: 1.740 | Acc: 49.961% (6427/12864)
Loss: 1.744 | Acc: 49.896% (9612/19264)
Loss: 1.749 | Acc: 49.649% (12742/25664)
Loss: 1.750 | Acc: 49.579% (15897/32064)
Loss: 1.750 | Acc: 49.493% (19037/38464)
Loss: 1.750 | Acc: 49.501% (22208/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9760, Accuracy: 3892/10000 (38.92%)

Epoch: 178
Loss: 1.746 | Acc: 46.875% (30/64)
Loss: 1.710 | Acc: 51.098% (3303/6464)
Loss: 1.737 | Acc: 49.992% (6431/12864)
Loss: 1.733 | Acc: 50.078% (9647/19264)
Loss: 1.736 | Acc: 50.031% (12840/25664)
Loss: 1.735 | Acc: 50.056% (16050/32064)
Loss: 1.734 | Acc: 50.161% (19294/38464)
Loss: 1.737 | Acc: 50.022% (22442/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9496, Accuracy: 4069/10000 (40.69%)

Epoch: 179
Loss: 1.618 | Acc: 54.688% (35/64)
Loss: 1.730 | Acc: 49.722% (3214/6464)
Loss: 1.713 | Acc: 50.560% (6504/12864)
Loss: 1.717 | Acc: 50.363% (9702/19264)
Loss: 1.720 | Acc: 50.370% (12927/25664)
Loss: 1.718 | Acc: 50.552% (16209/32064)
Loss: 1.719 | Acc: 50.546% (19442/38464)
Loss: 1.724 | Acc: 50.381% (22603/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9153, Accuracy: 4219/10000 (42.19%)

Epoch: 180
Loss: 1.809 | Acc: 48.438% (31/64)
Loss: 1.699 | Acc: 51.346% (3319/6464)
Loss: 1.703 | Acc: 51.135% (6578/12864)
Loss: 1.705 | Acc: 51.158% (9855/19264)
Loss: 1.707 | Acc: 51.153% (13128/25664)
Loss: 1.716 | Acc: 50.742% (16270/32064)
Loss: 1.717 | Acc: 50.689% (19497/38464)
Loss: 1.717 | Acc: 50.664% (22730/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9454, Accuracy: 4219/10000 (42.19%)

Epoch: 181
Loss: 1.536 | Acc: 59.375% (38/64)
Loss: 1.686 | Acc: 51.408% (3323/6464)
Loss: 1.689 | Acc: 51.337% (6604/12864)
Loss: 1.685 | Acc: 51.682% (9956/19264)
Loss: 1.691 | Acc: 51.485% (13213/25664)
Loss: 1.696 | Acc: 51.344% (16463/32064)
Loss: 1.702 | Acc: 51.193% (19691/38464)
Loss: 1.704 | Acc: 51.077% (22915/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8715, Accuracy: 4545/10000 (45.45%)

Epoch: 182
Loss: 2.015 | Acc: 34.375% (22/64)
Loss: 1.697 | Acc: 51.037% (3299/6464)
Loss: 1.679 | Acc: 52.060% (6697/12864)
Loss: 1.675 | Acc: 52.253% (10066/19264)
Loss: 1.679 | Acc: 52.163% (13387/25664)
Loss: 1.685 | Acc: 51.921% (16648/32064)
Loss: 1.686 | Acc: 51.867% (19950/38464)
Loss: 1.690 | Acc: 51.681% (23186/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9115, Accuracy: 4378/10000 (43.78%)

Epoch: 183
Loss: 1.638 | Acc: 53.125% (34/64)
Loss: 1.662 | Acc: 52.584% (3399/6464)
Loss: 1.669 | Acc: 52.285% (6726/12864)
Loss: 1.672 | Acc: 52.108% (10038/19264)
Loss: 1.678 | Acc: 51.827% (13301/25664)
Loss: 1.682 | Acc: 51.718% (16583/32064)
Loss: 1.682 | Acc: 51.648% (19866/38464)
Loss: 1.682 | Acc: 51.734% (23210/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9128, Accuracy: 4462/10000 (44.62%)

Epoch: 184
Loss: 1.424 | Acc: 60.938% (39/64)
Loss: 1.639 | Acc: 52.986% (3425/6464)
Loss: 1.645 | Acc: 52.977% (6815/12864)
Loss: 1.651 | Acc: 52.632% (10139/19264)
Loss: 1.650 | Acc: 52.615% (13503/25664)
Loss: 1.652 | Acc: 52.635% (16877/32064)
Loss: 1.656 | Acc: 52.496% (20192/38464)
Loss: 1.662 | Acc: 52.327% (23476/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9443, Accuracy: 4322/10000 (43.22%)

Epoch: 185
Loss: 1.783 | Acc: 50.000% (32/64)
Loss: 1.622 | Acc: 53.713% (3472/6464)
Loss: 1.627 | Acc: 53.506% (6883/12864)
Loss: 1.630 | Acc: 53.509% (10308/19264)
Loss: 1.633 | Acc: 53.437% (13714/25664)
Loss: 1.638 | Acc: 53.247% (17073/32064)
Loss: 1.634 | Acc: 53.416% (20546/38464)
Loss: 1.638 | Acc: 53.239% (23885/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9168, Accuracy: 4351/10000 (43.51%)

Epoch: 186
Loss: 1.575 | Acc: 56.250% (36/64)
Loss: 1.604 | Acc: 54.425% (3518/6464)
Loss: 1.605 | Acc: 54.260% (6980/12864)
Loss: 1.612 | Acc: 53.935% (10390/19264)
Loss: 1.616 | Acc: 53.826% (13814/25664)
Loss: 1.616 | Acc: 53.771% (17241/32064)
Loss: 1.620 | Acc: 53.624% (20626/38464)
Loss: 1.620 | Acc: 53.642% (24066/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9027, Accuracy: 4461/10000 (44.61%)

Epoch: 187
Loss: 1.561 | Acc: 59.375% (38/64)
Loss: 1.600 | Acc: 53.434% (3454/6464)
Loss: 1.592 | Acc: 54.081% (6957/12864)
Loss: 1.588 | Acc: 54.319% (10464/19264)
Loss: 1.597 | Acc: 54.087% (13881/25664)
Loss: 1.596 | Acc: 54.092% (17344/32064)
Loss: 1.596 | Acc: 54.170% (20836/38464)
Loss: 1.595 | Acc: 54.213% (24322/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9457, Accuracy: 4357/10000 (43.57%)

Epoch: 188
Loss: 1.447 | Acc: 62.500% (40/64)
Loss: 1.559 | Acc: 55.028% (3557/6464)
Loss: 1.567 | Acc: 54.820% (7052/12864)
Loss: 1.563 | Acc: 55.077% (10610/19264)
Loss: 1.563 | Acc: 55.101% (14141/25664)
Loss: 1.562 | Acc: 55.046% (17650/32064)
Loss: 1.560 | Acc: 55.210% (21236/38464)
Loss: 1.564 | Acc: 55.055% (24700/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9359, Accuracy: 4481/10000 (44.81%)

Epoch: 189
Loss: 1.465 | Acc: 57.812% (37/64)
Loss: 1.511 | Acc: 56.436% (3648/6464)
Loss: 1.518 | Acc: 56.390% (7254/12864)
Loss: 1.519 | Acc: 56.349% (10855/19264)
Loss: 1.524 | Acc: 56.184% (14419/25664)
Loss: 1.528 | Acc: 56.057% (17974/32064)
Loss: 1.531 | Acc: 55.933% (21514/38464)
Loss: 1.534 | Acc: 55.802% (25035/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9786, Accuracy: 4408/10000 (44.08%)

Epoch: 190
Loss: 1.481 | Acc: 54.688% (35/64)
Loss: 1.467 | Acc: 57.519% (3718/6464)
Loss: 1.477 | Acc: 57.167% (7354/12864)
Loss: 1.479 | Acc: 57.174% (11014/19264)
Loss: 1.478 | Acc: 57.349% (14718/25664)
Loss: 1.483 | Acc: 57.292% (18370/32064)
Loss: 1.485 | Acc: 57.129% (21974/38464)
Loss: 1.487 | Acc: 57.117% (25625/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9744, Accuracy: 4428/10000 (44.28%)

Epoch: 191
Loss: 1.607 | Acc: 50.000% (32/64)
Loss: 1.426 | Acc: 58.725% (3796/6464)
Loss: 1.421 | Acc: 58.846% (7570/12864)
Loss: 1.432 | Acc: 58.518% (11273/19264)
Loss: 1.435 | Acc: 58.401% (14988/25664)
Loss: 1.435 | Acc: 58.424% (18733/32064)
Loss: 1.439 | Acc: 58.322% (22433/38464)
Loss: 1.444 | Acc: 58.154% (26090/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0425, Accuracy: 4275/10000 (42.75%)

Epoch: 192
Loss: 1.519 | Acc: 57.812% (37/64)
Loss: 1.412 | Acc: 58.029% (3751/6464)
Loss: 1.397 | Acc: 58.916% (7579/12864)
Loss: 1.384 | Acc: 59.551% (11472/19264)
Loss: 1.387 | Acc: 59.511% (15273/25664)
Loss: 1.392 | Acc: 59.434% (19057/32064)
Loss: 1.392 | Acc: 59.419% (22855/38464)
Loss: 1.392 | Acc: 59.449% (26671/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0663, Accuracy: 4361/10000 (43.61%)

Epoch: 193
Loss: 1.102 | Acc: 64.062% (41/64)
Loss: 1.306 | Acc: 61.634% (3984/6464)
Loss: 1.322 | Acc: 61.070% (7856/12864)
Loss: 1.322 | Acc: 61.150% (11780/19264)
Loss: 1.328 | Acc: 60.945% (15641/25664)
Loss: 1.328 | Acc: 60.959% (19546/32064)
Loss: 1.330 | Acc: 60.878% (23416/38464)
Loss: 1.330 | Acc: 60.884% (27315/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1051, Accuracy: 4270/10000 (42.70%)

Epoch: 194
Loss: 0.942 | Acc: 78.125% (50/64)
Loss: 1.262 | Acc: 62.887% (4065/6464)
Loss: 1.247 | Acc: 63.285% (8141/12864)
Loss: 1.251 | Acc: 63.206% (12176/19264)
Loss: 1.256 | Acc: 63.084% (16190/25664)
Loss: 1.261 | Acc: 62.890% (20165/32064)
Loss: 1.263 | Acc: 62.848% (24174/38464)
Loss: 1.260 | Acc: 62.957% (28245/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1673, Accuracy: 4280/10000 (42.80%)

Epoch: 195
Loss: 1.127 | Acc: 68.750% (44/64)
Loss: 1.175 | Acc: 65.408% (4228/6464)
Loss: 1.192 | Acc: 64.677% (8320/12864)
Loss: 1.196 | Acc: 64.550% (12435/19264)
Loss: 1.196 | Acc: 64.429% (16535/25664)
Loss: 1.197 | Acc: 64.381% (20643/32064)
Loss: 1.198 | Acc: 64.281% (24725/38464)
Loss: 1.198 | Acc: 64.386% (28886/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1922, Accuracy: 4140/10000 (41.40%)

Epoch: 196
Loss: 1.178 | Acc: 59.375% (38/64)
Loss: 1.119 | Acc: 66.816% (4319/6464)
Loss: 1.121 | Acc: 66.838% (8598/12864)
Loss: 1.137 | Acc: 66.149% (12743/19264)
Loss: 1.135 | Acc: 66.435% (17050/25664)
Loss: 1.133 | Acc: 66.364% (21279/32064)
Loss: 1.136 | Acc: 66.166% (25450/38464)
Loss: 1.134 | Acc: 66.196% (29698/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2514, Accuracy: 4134/10000 (41.34%)

Epoch: 197
Loss: 1.142 | Acc: 67.188% (43/64)
Loss: 1.074 | Acc: 68.626% (4436/6464)
Loss: 1.082 | Acc: 68.074% (8757/12864)
Loss: 1.077 | Acc: 68.189% (13136/19264)
Loss: 1.080 | Acc: 68.041% (17462/25664)
Loss: 1.080 | Acc: 68.023% (21811/32064)
Loss: 1.076 | Acc: 68.074% (26184/38464)
Loss: 1.077 | Acc: 68.041% (30526/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3097, Accuracy: 4100/10000 (41.00%)
torch.Size([100, 10])
Test set: Average loss: 2.3097, Accuracy: 4100/10000 (41.00%)

Epoch: 198
Loss: 0.742 | Acc: 79.688% (51/64)
Loss: 1.025 | Acc: 69.601% (4499/6464)
Loss: 1.030 | Acc: 69.395% (8927/12864)
Loss: 1.034 | Acc: 69.134% (13318/19264)
Loss: 1.032 | Acc: 69.260% (17775/25664)
Loss: 1.038 | Acc: 69.009% (22127/32064)
Loss: 1.039 | Acc: 68.984% (26534/38464)
Loss: 1.039 | Acc: 69.022% (30966/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2883, Accuracy: 4077/10000 (40.77%)
torch.Size([100, 10])
Test set: Average loss: 2.2883, Accuracy: 4077/10000 (40.77%)

Epoch: 199
Loss: 1.267 | Acc: 60.938% (39/64)
Loss: 1.044 | Acc: 68.626% (4436/6464)
Loss: 1.028 | Acc: 69.193% (8901/12864)
Loss: 1.025 | Acc: 69.503% (13389/19264)
Loss: 1.020 | Acc: 69.572% (17855/25664)
Loss: 1.021 | Acc: 69.573% (22308/32064)
Loss: 1.019 | Acc: 69.553% (26753/38464)
Loss: 1.021 | Acc: 69.526% (31192/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3124, Accuracy: 4052/10000 (40.52%)
torch.Size([100, 10])
Test set: Average loss: 2.3124, Accuracy: 4052/10000 (40.52%)
4608
10000
-1.9744281768798828
