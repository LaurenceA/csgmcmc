==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.361 | Acc: 15.625% (10/64)
Loss: 2.815 | Acc: 16.832% (1088/6464)
Loss: 2.405 | Acc: 20.507% (2638/12864)
Loss: 2.233 | Acc: 22.742% (4381/19264)
Loss: 2.131 | Acc: 24.930% (6398/25664)
Loss: 2.052 | Acc: 26.893% (8623/32064)
Loss: 1.988 | Acc: 28.733% (11052/38464)
Loss: 1.932 | Acc: 30.298% (13593/44864)
torch.Size([100, 10])
Test set: Average loss: 2.8809, Accuracy: 2448/10000 (24.48%)

Epoch: 1
Loss: 1.925 | Acc: 39.062% (25/64)
Loss: 1.507 | Acc: 44.353% (2867/6464)
Loss: 1.483 | Acc: 45.157% (5809/12864)
Loss: 1.472 | Acc: 45.640% (8792/19264)
Loss: 1.455 | Acc: 46.536% (11943/25664)
Loss: 1.432 | Acc: 47.599% (15262/32064)
Loss: 1.413 | Acc: 48.284% (18572/38464)
Loss: 1.391 | Acc: 49.088% (22023/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4531, Accuracy: 4973/10000 (49.73%)

Epoch: 2
Loss: 1.186 | Acc: 60.938% (39/64)
Loss: 1.187 | Acc: 57.132% (3693/6464)
Loss: 1.188 | Acc: 57.548% (7403/12864)
Loss: 1.160 | Acc: 58.378% (11246/19264)
Loss: 1.137 | Acc: 59.266% (15210/25664)
Loss: 1.120 | Acc: 60.102% (19271/32064)
Loss: 1.105 | Acc: 60.701% (23348/38464)
Loss: 1.091 | Acc: 61.136% (27428/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3002, Accuracy: 5529/10000 (55.29%)

Epoch: 3
Loss: 0.924 | Acc: 68.750% (44/64)
Loss: 0.949 | Acc: 66.213% (4280/6464)
Loss: 0.946 | Acc: 66.371% (8538/12864)
Loss: 0.931 | Acc: 66.923% (12892/19264)
Loss: 0.914 | Acc: 67.620% (17354/25664)
Loss: 0.900 | Acc: 68.195% (21866/32064)
Loss: 0.887 | Acc: 68.623% (26395/38464)
Loss: 0.877 | Acc: 69.149% (31023/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6705, Accuracy: 5257/10000 (52.57%)

Epoch: 4
Loss: 1.134 | Acc: 57.812% (37/64)
Loss: 0.769 | Acc: 73.035% (4721/6464)
Loss: 0.765 | Acc: 73.562% (9463/12864)
Loss: 0.759 | Acc: 73.765% (14210/19264)
Loss: 0.753 | Acc: 73.788% (18937/25664)
Loss: 0.748 | Acc: 74.071% (23750/32064)
Loss: 0.739 | Acc: 74.485% (28650/38464)
Loss: 0.734 | Acc: 74.719% (33522/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3706, Accuracy: 5874/10000 (58.74%)

Epoch: 5
Loss: 0.943 | Acc: 67.188% (43/64)
Loss: 0.664 | Acc: 76.640% (4954/6464)
Loss: 0.663 | Acc: 76.943% (9898/12864)
Loss: 0.658 | Acc: 77.170% (14866/19264)
Loss: 0.658 | Acc: 77.096% (19786/25664)
Loss: 0.654 | Acc: 77.274% (24777/32064)
Loss: 0.652 | Acc: 77.420% (29779/38464)
Loss: 0.650 | Acc: 77.508% (34773/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1190, Accuracy: 6610/10000 (66.10%)

Epoch: 6
Loss: 0.599 | Acc: 85.938% (55/64)
Loss: 0.603 | Acc: 79.316% (5127/6464)
Loss: 0.601 | Acc: 79.493% (10226/12864)
Loss: 0.599 | Acc: 79.407% (15297/19264)
Loss: 0.594 | Acc: 79.520% (20408/25664)
Loss: 0.592 | Acc: 79.525% (25499/32064)
Loss: 0.590 | Acc: 79.638% (30632/38464)
Loss: 0.589 | Acc: 79.659% (35738/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1880, Accuracy: 4232/10000 (42.32%)

Epoch: 7
Loss: 0.672 | Acc: 68.750% (44/64)
Loss: 0.559 | Acc: 80.585% (5209/6464)
Loss: 0.562 | Acc: 80.558% (10363/12864)
Loss: 0.558 | Acc: 80.996% (15603/19264)
Loss: 0.555 | Acc: 81.114% (20817/25664)
Loss: 0.552 | Acc: 81.191% (26033/32064)
Loss: 0.555 | Acc: 81.042% (31172/38464)
Loss: 0.555 | Acc: 81.040% (36358/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9028, Accuracy: 7223/10000 (72.23%)

Epoch: 8
Loss: 0.722 | Acc: 81.250% (52/64)
Loss: 0.529 | Acc: 82.240% (5316/6464)
Loss: 0.522 | Acc: 82.284% (10585/12864)
Loss: 0.517 | Acc: 82.460% (15885/19264)
Loss: 0.515 | Acc: 82.396% (21146/25664)
Loss: 0.516 | Acc: 82.438% (26433/32064)
Loss: 0.519 | Acc: 82.176% (31608/38464)
Loss: 0.518 | Acc: 82.179% (36869/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6633, Accuracy: 7817/10000 (78.17%)

Epoch: 9
Loss: 0.523 | Acc: 79.688% (51/64)
Loss: 0.488 | Acc: 83.447% (5394/6464)
Loss: 0.487 | Acc: 83.279% (10713/12864)
Loss: 0.498 | Acc: 82.823% (15955/19264)
Loss: 0.494 | Acc: 82.980% (21296/25664)
Loss: 0.493 | Acc: 83.050% (26629/32064)
Loss: 0.498 | Acc: 82.911% (31891/38464)
Loss: 0.496 | Acc: 82.919% (37201/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7898, Accuracy: 7295/10000 (72.95%)

Epoch: 10
Loss: 0.602 | Acc: 81.250% (52/64)
Loss: 0.486 | Acc: 83.230% (5380/6464)
Loss: 0.473 | Acc: 83.691% (10766/12864)
Loss: 0.482 | Acc: 83.332% (16053/19264)
Loss: 0.479 | Acc: 83.467% (21421/25664)
Loss: 0.475 | Acc: 83.642% (26819/32064)
Loss: 0.478 | Acc: 83.696% (32193/38464)
Loss: 0.477 | Acc: 83.686% (37545/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5721, Accuracy: 8092/10000 (80.92%)

Epoch: 11
Loss: 0.637 | Acc: 71.875% (46/64)
Loss: 0.451 | Acc: 84.019% (5431/6464)
Loss: 0.455 | Acc: 84.188% (10830/12864)
Loss: 0.454 | Acc: 84.271% (16234/19264)
Loss: 0.457 | Acc: 84.250% (21622/25664)
Loss: 0.458 | Acc: 84.260% (27017/32064)
Loss: 0.458 | Acc: 84.177% (32378/38464)
Loss: 0.458 | Acc: 84.181% (37767/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2381, Accuracy: 6814/10000 (68.14%)

Epoch: 12
Loss: 0.593 | Acc: 84.375% (54/64)
Loss: 0.422 | Acc: 85.613% (5534/6464)
Loss: 0.420 | Acc: 85.735% (11029/12864)
Loss: 0.424 | Acc: 85.476% (16466/19264)
Loss: 0.433 | Acc: 85.232% (21874/25664)
Loss: 0.435 | Acc: 85.145% (27301/32064)
Loss: 0.437 | Acc: 85.033% (32707/38464)
Loss: 0.438 | Acc: 85.033% (38149/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0028, Accuracy: 6860/10000 (68.60%)

Epoch: 13
Loss: 0.827 | Acc: 78.125% (50/64)
Loss: 0.416 | Acc: 85.736% (5542/6464)
Loss: 0.421 | Acc: 85.681% (11022/12864)
Loss: 0.423 | Acc: 85.585% (16487/19264)
Loss: 0.423 | Acc: 85.528% (21950/25664)
Loss: 0.419 | Acc: 85.719% (27485/32064)
Loss: 0.420 | Acc: 85.626% (32935/38464)
Loss: 0.418 | Acc: 85.730% (38462/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5862, Accuracy: 5892/10000 (58.92%)

Epoch: 14
Loss: 0.669 | Acc: 78.125% (50/64)
Loss: 0.430 | Acc: 84.994% (5494/6464)
Loss: 0.418 | Acc: 85.269% (10969/12864)
Loss: 0.418 | Acc: 85.320% (16436/19264)
Loss: 0.413 | Acc: 85.634% (21977/25664)
Loss: 0.407 | Acc: 85.853% (27528/32064)
Loss: 0.408 | Acc: 85.789% (32998/38464)
Loss: 0.407 | Acc: 85.828% (38506/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9324, Accuracy: 7005/10000 (70.05%)

Epoch: 15
Loss: 0.634 | Acc: 76.562% (49/64)
Loss: 0.388 | Acc: 86.850% (5614/6464)
Loss: 0.384 | Acc: 86.948% (11185/12864)
Loss: 0.390 | Acc: 86.830% (16727/19264)
Loss: 0.384 | Acc: 87.025% (22334/25664)
Loss: 0.387 | Acc: 86.945% (27878/32064)
Loss: 0.388 | Acc: 86.829% (33398/38464)
Loss: 0.390 | Acc: 86.738% (38914/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5856, Accuracy: 8057/10000 (80.57%)

Epoch: 16
Loss: 0.441 | Acc: 87.500% (56/64)
Loss: 0.360 | Acc: 87.748% (5672/6464)
Loss: 0.366 | Acc: 87.391% (11242/12864)
Loss: 0.364 | Acc: 87.453% (16847/19264)
Loss: 0.376 | Acc: 87.048% (22340/25664)
Loss: 0.374 | Acc: 87.166% (27949/32064)
Loss: 0.376 | Acc: 87.068% (33490/38464)
Loss: 0.376 | Acc: 87.050% (39054/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9801, Accuracy: 7181/10000 (71.81%)

Epoch: 17
Loss: 0.443 | Acc: 84.375% (54/64)
Loss: 0.347 | Acc: 87.980% (5687/6464)
Loss: 0.367 | Acc: 87.290% (11229/12864)
Loss: 0.365 | Acc: 87.251% (16808/19264)
Loss: 0.365 | Acc: 87.278% (22399/25664)
Loss: 0.363 | Acc: 87.410% (28027/32064)
Loss: 0.364 | Acc: 87.388% (33613/38464)
Loss: 0.364 | Acc: 87.442% (39230/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7112, Accuracy: 7988/10000 (79.88%)

Epoch: 18
Loss: 0.497 | Acc: 84.375% (54/64)
Loss: 0.329 | Acc: 88.815% (5741/6464)
Loss: 0.337 | Acc: 88.394% (11371/12864)
Loss: 0.343 | Acc: 88.144% (16980/19264)
Loss: 0.344 | Acc: 88.038% (22594/25664)
Loss: 0.347 | Acc: 88.005% (28218/32064)
Loss: 0.348 | Acc: 87.971% (33837/38464)
Loss: 0.352 | Acc: 87.874% (39424/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4762, Accuracy: 8391/10000 (83.91%)

Epoch: 19
Loss: 0.301 | Acc: 87.500% (56/64)
Loss: 0.328 | Acc: 88.784% (5739/6464)
Loss: 0.330 | Acc: 88.728% (11414/12864)
Loss: 0.326 | Acc: 88.933% (17132/19264)
Loss: 0.330 | Acc: 88.712% (22767/25664)
Loss: 0.331 | Acc: 88.626% (28417/32064)
Loss: 0.331 | Acc: 88.631% (34091/38464)
Loss: 0.334 | Acc: 88.599% (39749/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5990, Accuracy: 8064/10000 (80.64%)

Epoch: 20
Loss: 0.280 | Acc: 96.875% (62/64)
Loss: 0.313 | Acc: 89.449% (5782/6464)
Loss: 0.314 | Acc: 89.381% (11498/12864)
Loss: 0.323 | Acc: 89.192% (17182/19264)
Loss: 0.324 | Acc: 89.020% (22846/25664)
Loss: 0.324 | Acc: 88.981% (28531/32064)
Loss: 0.324 | Acc: 89.021% (34241/38464)
Loss: 0.324 | Acc: 89.034% (39944/44864)
torch.Size([100, 10])
Test set: Average loss: 6.2613, Accuracy: 2385/10000 (23.85%)

Epoch: 21
Loss: 0.547 | Acc: 78.125% (50/64)
Loss: 0.331 | Acc: 88.830% (5742/6464)
Loss: 0.325 | Acc: 88.969% (11445/12864)
Loss: 0.315 | Acc: 89.296% (17202/19264)
Loss: 0.318 | Acc: 89.183% (22888/25664)
Loss: 0.315 | Acc: 89.371% (28656/32064)
Loss: 0.316 | Acc: 89.335% (34362/38464)
Loss: 0.314 | Acc: 89.375% (40097/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5860, Accuracy: 6288/10000 (62.88%)

Epoch: 22
Loss: 0.390 | Acc: 85.938% (55/64)
Loss: 0.283 | Acc: 90.238% (5833/6464)
Loss: 0.298 | Acc: 89.700% (11539/12864)
Loss: 0.303 | Acc: 89.691% (17278/19264)
Loss: 0.302 | Acc: 89.659% (23010/25664)
Loss: 0.305 | Acc: 89.562% (28717/32064)
Loss: 0.304 | Acc: 89.650% (34483/38464)
Loss: 0.302 | Acc: 89.673% (40231/44864)
torch.Size([100, 10])
Test set: Average loss: 2.7033, Accuracy: 5248/10000 (52.48%)

Epoch: 23
Loss: 0.443 | Acc: 84.375% (54/64)
Loss: 0.259 | Acc: 90.950% (5879/6464)
Loss: 0.280 | Acc: 90.384% (11627/12864)
Loss: 0.283 | Acc: 90.329% (17401/19264)
Loss: 0.287 | Acc: 90.267% (23166/25664)
Loss: 0.291 | Acc: 90.123% (28897/32064)
Loss: 0.290 | Acc: 90.144% (34673/38464)
Loss: 0.290 | Acc: 90.110% (40427/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0770, Accuracy: 6978/10000 (69.78%)

Epoch: 24
Loss: 0.392 | Acc: 82.812% (53/64)
Loss: 0.264 | Acc: 90.903% (5876/6464)
Loss: 0.273 | Acc: 90.578% (11652/12864)
Loss: 0.271 | Acc: 90.739% (17480/19264)
Loss: 0.274 | Acc: 90.586% (23248/25664)
Loss: 0.274 | Acc: 90.584% (29045/32064)
Loss: 0.275 | Acc: 90.576% (34839/38464)
Loss: 0.277 | Acc: 90.531% (40616/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3646, Accuracy: 6918/10000 (69.18%)

Epoch: 25
Loss: 0.424 | Acc: 87.500% (56/64)
Loss: 0.253 | Acc: 91.337% (5904/6464)
Loss: 0.265 | Acc: 90.998% (11706/12864)
Loss: 0.266 | Acc: 91.040% (17538/19264)
Loss: 0.257 | Acc: 91.248% (23418/25664)
Loss: 0.256 | Acc: 91.286% (29270/32064)
Loss: 0.259 | Acc: 91.168% (35067/38464)
Loss: 0.261 | Acc: 91.024% (40837/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0981, Accuracy: 6377/10000 (63.77%)

Epoch: 26
Loss: 0.366 | Acc: 84.375% (54/64)
Loss: 0.230 | Acc: 92.002% (5947/6464)
Loss: 0.236 | Acc: 91.807% (11810/12864)
Loss: 0.235 | Acc: 91.871% (17698/19264)
Loss: 0.239 | Acc: 91.704% (23535/25664)
Loss: 0.243 | Acc: 91.573% (29362/32064)
Loss: 0.244 | Acc: 91.543% (35211/38464)
Loss: 0.245 | Acc: 91.525% (41062/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0985, Accuracy: 7097/10000 (70.97%)

Epoch: 27
Loss: 0.846 | Acc: 76.562% (49/64)
Loss: 0.248 | Acc: 91.646% (5924/6464)
Loss: 0.235 | Acc: 92.086% (11846/12864)
Loss: 0.243 | Acc: 91.938% (17711/19264)
Loss: 0.243 | Acc: 91.887% (23582/25664)
Loss: 0.241 | Acc: 92.016% (29504/32064)
Loss: 0.239 | Acc: 92.063% (35411/38464)
Loss: 0.238 | Acc: 92.087% (41314/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6760, Accuracy: 8110/10000 (81.10%)

Epoch: 28
Loss: 0.575 | Acc: 81.250% (52/64)
Loss: 0.214 | Acc: 92.667% (5990/6464)
Loss: 0.226 | Acc: 92.118% (11850/12864)
Loss: 0.221 | Acc: 92.255% (17772/19264)
Loss: 0.225 | Acc: 92.195% (23661/25664)
Loss: 0.222 | Acc: 92.375% (29619/32064)
Loss: 0.221 | Acc: 92.406% (35543/38464)
Loss: 0.219 | Acc: 92.439% (41472/44864)
torch.Size([100, 10])
Test set: Average loss: 2.7427, Accuracy: 5426/10000 (54.26%)

Epoch: 29
Loss: 0.441 | Acc: 89.062% (57/64)
Loss: 0.222 | Acc: 92.621% (5987/6464)
Loss: 0.212 | Acc: 92.918% (11953/12864)
Loss: 0.203 | Acc: 93.174% (17949/19264)
Loss: 0.202 | Acc: 93.103% (23894/25664)
Loss: 0.202 | Acc: 93.111% (29855/32064)
Loss: 0.204 | Acc: 93.079% (35802/38464)
Loss: 0.204 | Acc: 93.097% (41767/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4370, Accuracy: 8631/10000 (86.31%)

Epoch: 30
Loss: 0.302 | Acc: 89.062% (57/64)
Loss: 0.173 | Acc: 94.168% (6087/6464)
Loss: 0.180 | Acc: 94.045% (12098/12864)
Loss: 0.186 | Acc: 93.724% (18055/19264)
Loss: 0.189 | Acc: 93.540% (24006/25664)
Loss: 0.189 | Acc: 93.504% (29981/32064)
Loss: 0.192 | Acc: 93.378% (35917/38464)
Loss: 0.192 | Acc: 93.398% (41902/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6327, Accuracy: 8135/10000 (81.35%)

Epoch: 31
Loss: 0.240 | Acc: 92.188% (59/64)
Loss: 0.176 | Acc: 93.858% (6067/6464)
Loss: 0.173 | Acc: 93.983% (12090/12864)
Loss: 0.173 | Acc: 94.025% (18113/19264)
Loss: 0.178 | Acc: 93.968% (24116/25664)
Loss: 0.177 | Acc: 93.950% (30124/32064)
Loss: 0.176 | Acc: 94.020% (36164/38464)
Loss: 0.180 | Acc: 93.888% (42122/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9617, Accuracy: 7880/10000 (78.80%)

Epoch: 32
Loss: 0.309 | Acc: 92.188% (59/64)
Loss: 0.157 | Acc: 94.879% (6133/6464)
Loss: 0.160 | Acc: 94.613% (12171/12864)
Loss: 0.161 | Acc: 94.529% (18210/19264)
Loss: 0.162 | Acc: 94.498% (24252/25664)
Loss: 0.164 | Acc: 94.405% (30270/32064)
Loss: 0.164 | Acc: 94.392% (36307/38464)
Loss: 0.163 | Acc: 94.510% (42401/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3573, Accuracy: 8862/10000 (88.62%)

Epoch: 33
Loss: 0.047 | Acc: 98.438% (63/64)
Loss: 0.141 | Acc: 95.127% (6149/6464)
Loss: 0.140 | Acc: 95.297% (12259/12864)
Loss: 0.143 | Acc: 95.162% (18332/19264)
Loss: 0.143 | Acc: 95.192% (24430/25664)
Loss: 0.143 | Acc: 95.228% (30534/32064)
Loss: 0.143 | Acc: 95.175% (36608/38464)
Loss: 0.144 | Acc: 95.094% (42663/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6526, Accuracy: 8315/10000 (83.15%)

Epoch: 34
Loss: 0.170 | Acc: 95.312% (61/64)
Loss: 0.148 | Acc: 94.802% (6128/6464)
Loss: 0.139 | Acc: 95.320% (12262/12864)
Loss: 0.135 | Acc: 95.411% (18380/19264)
Loss: 0.135 | Acc: 95.375% (24477/25664)
Loss: 0.134 | Acc: 95.412% (30593/32064)
Loss: 0.132 | Acc: 95.463% (36719/38464)
Loss: 0.132 | Acc: 95.464% (42829/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2772, Accuracy: 9139/10000 (91.39%)

Epoch: 35
Loss: 0.042 | Acc: 98.438% (63/64)
Loss: 0.111 | Acc: 96.086% (6211/6464)
Loss: 0.107 | Acc: 96.175% (12372/12864)
Loss: 0.105 | Acc: 96.221% (18536/19264)
Loss: 0.105 | Acc: 96.318% (24719/25664)
Loss: 0.105 | Acc: 96.298% (30877/32064)
Loss: 0.109 | Acc: 96.163% (36988/38464)
Loss: 0.111 | Acc: 96.090% (43110/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2675, Accuracy: 9159/10000 (91.59%)

Epoch: 36
Loss: 0.130 | Acc: 95.312% (61/64)
Loss: 0.085 | Acc: 97.386% (6295/6464)
Loss: 0.088 | Acc: 97.155% (12498/12864)
Loss: 0.091 | Acc: 96.953% (18677/19264)
Loss: 0.094 | Acc: 96.789% (24840/25664)
Loss: 0.097 | Acc: 96.772% (31029/32064)
Loss: 0.098 | Acc: 96.729% (37206/38464)
Loss: 0.098 | Acc: 96.730% (43397/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2838, Accuracy: 9119/10000 (91.19%)

Epoch: 37
Loss: 0.071 | Acc: 96.875% (62/64)
Loss: 0.095 | Acc: 96.689% (6250/6464)
Loss: 0.091 | Acc: 96.891% (12464/12864)
Loss: 0.086 | Acc: 97.088% (18703/19264)
Loss: 0.084 | Acc: 97.132% (24928/25664)
Loss: 0.086 | Acc: 97.065% (31123/32064)
Loss: 0.087 | Acc: 97.021% (37318/38464)
Loss: 0.086 | Acc: 97.035% (43534/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2522, Accuracy: 9227/10000 (92.27%)

Epoch: 38
Loss: 0.045 | Acc: 100.000% (64/64)
Loss: 0.082 | Acc: 97.416% (6297/6464)
Loss: 0.069 | Acc: 97.839% (12586/12864)
Loss: 0.069 | Acc: 97.804% (18841/19264)
Loss: 0.070 | Acc: 97.740% (25084/25664)
Loss: 0.070 | Acc: 97.733% (31337/32064)
Loss: 0.069 | Acc: 97.730% (37591/38464)
Loss: 0.069 | Acc: 97.724% (43843/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2303, Accuracy: 9284/10000 (92.84%)

Epoch: 39
Loss: 0.144 | Acc: 96.875% (62/64)
Loss: 0.058 | Acc: 97.865% (6326/6464)
Loss: 0.060 | Acc: 97.924% (12597/12864)
Loss: 0.056 | Acc: 98.079% (18894/19264)
Loss: 0.056 | Acc: 98.099% (25176/25664)
Loss: 0.056 | Acc: 98.079% (31448/32064)
Loss: 0.056 | Acc: 98.079% (37725/38464)
Loss: 0.057 | Acc: 98.041% (43985/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2308, Accuracy: 9291/10000 (92.91%)

Epoch: 40
Loss: 0.065 | Acc: 98.438% (63/64)
Loss: 0.048 | Acc: 98.484% (6366/6464)
Loss: 0.046 | Acc: 98.484% (12669/12864)
Loss: 0.046 | Acc: 98.469% (18969/19264)
Loss: 0.045 | Acc: 98.527% (25286/25664)
Loss: 0.044 | Acc: 98.553% (31600/32064)
Loss: 0.043 | Acc: 98.570% (37914/38464)
Loss: 0.044 | Acc: 98.544% (44211/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2314, Accuracy: 9358/10000 (93.58%)

Epoch: 41
Loss: 0.051 | Acc: 98.438% (63/64)
Loss: 0.028 | Acc: 99.211% (6413/6464)
Loss: 0.030 | Acc: 99.106% (12749/12864)
Loss: 0.030 | Acc: 99.060% (19083/19264)
Loss: 0.032 | Acc: 98.995% (25406/25664)
Loss: 0.032 | Acc: 98.993% (31741/32064)
Loss: 0.032 | Acc: 99.004% (38081/38464)
Loss: 0.032 | Acc: 99.021% (44425/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2179, Accuracy: 9385/10000 (93.85%)

Epoch: 42
Loss: 0.016 | Acc: 100.000% (64/64)
Loss: 0.025 | Acc: 99.211% (6413/6464)
Loss: 0.026 | Acc: 99.160% (12756/12864)
Loss: 0.027 | Acc: 99.118% (19094/19264)
Loss: 0.026 | Acc: 99.162% (25449/25664)
Loss: 0.027 | Acc: 99.174% (31799/32064)
Loss: 0.026 | Acc: 99.199% (38156/38464)
Loss: 0.026 | Acc: 99.218% (44513/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2046, Accuracy: 9421/10000 (94.21%)

Epoch: 43
Loss: 0.031 | Acc: 98.438% (63/64)
Loss: 0.021 | Acc: 99.350% (6422/6464)
Loss: 0.021 | Acc: 99.370% (12783/12864)
Loss: 0.020 | Acc: 99.429% (19154/19264)
Loss: 0.020 | Acc: 99.427% (25517/25664)
Loss: 0.019 | Acc: 99.451% (31888/32064)
Loss: 0.019 | Acc: 99.436% (38247/38464)
Loss: 0.019 | Acc: 99.467% (44625/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2076, Accuracy: 9430/10000 (94.30%)

Epoch: 44
Loss: 0.025 | Acc: 98.438% (63/64)
Loss: 0.013 | Acc: 99.660% (6442/6464)
Loss: 0.013 | Acc: 99.681% (12823/12864)
Loss: 0.013 | Acc: 99.657% (19198/19264)
Loss: 0.013 | Acc: 99.673% (25580/25664)
Loss: 0.014 | Acc: 99.648% (31951/32064)
Loss: 0.013 | Acc: 99.644% (38327/38464)
Loss: 0.014 | Acc: 99.630% (44698/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2026, Accuracy: 9439/10000 (94.39%)

Epoch: 45
Loss: 0.019 | Acc: 98.438% (63/64)
Loss: 0.012 | Acc: 99.675% (6443/6464)
Loss: 0.013 | Acc: 99.650% (12819/12864)
Loss: 0.014 | Acc: 99.652% (19197/19264)
Loss: 0.014 | Acc: 99.665% (25578/25664)
Loss: 0.015 | Acc: 99.654% (31953/32064)
Loss: 0.015 | Acc: 99.654% (38331/38464)
Loss: 0.016 | Acc: 99.637% (44701/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1914, Accuracy: 9430/10000 (94.30%)

Epoch: 46
Loss: 0.028 | Acc: 98.438% (63/64)
Loss: 0.018 | Acc: 99.675% (6443/6464)
Loss: 0.018 | Acc: 99.658% (12820/12864)
Loss: 0.019 | Acc: 99.616% (19190/19264)
Loss: 0.020 | Acc: 99.595% (25560/25664)
Loss: 0.020 | Acc: 99.591% (31933/32064)
Loss: 0.020 | Acc: 99.576% (38301/38464)
Loss: 0.020 | Acc: 99.576% (44674/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1911, Accuracy: 9420/10000 (94.20%)

Epoch: 47
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 0.023 | Acc: 99.551% (6435/6464)
Loss: 0.023 | Acc: 99.541% (12805/12864)
Loss: 0.022 | Acc: 99.543% (19176/19264)
Loss: 0.022 | Acc: 99.548% (25548/25664)
Loss: 0.023 | Acc: 99.545% (31918/32064)
Loss: 0.023 | Acc: 99.548% (38290/38464)
Loss: 0.023 | Acc: 99.545% (44660/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1943, Accuracy: 9410/10000 (94.10%)
torch.Size([100, 10])
Test set: Average loss: 0.1943, Accuracy: 9410/10000 (94.10%)

Epoch: 48
Loss: 0.032 | Acc: 98.438% (63/64)
Loss: 0.022 | Acc: 99.613% (6439/6464)
Loss: 0.023 | Acc: 99.534% (12804/12864)
Loss: 0.023 | Acc: 99.580% (19183/19264)
Loss: 0.023 | Acc: 99.548% (25548/25664)
Loss: 0.024 | Acc: 99.535% (31915/32064)
Loss: 0.023 | Acc: 99.558% (38294/38464)
Loss: 0.023 | Acc: 99.550% (44662/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1893, Accuracy: 9421/10000 (94.21%)
torch.Size([100, 10])
Test set: Average loss: 0.1893, Accuracy: 9421/10000 (94.21%)

Epoch: 49
Loss: 0.010 | Acc: 100.000% (64/64)
Loss: 0.022 | Acc: 99.644% (6441/6464)
Loss: 0.024 | Acc: 99.611% (12814/12864)
Loss: 0.024 | Acc: 99.611% (19189/19264)
Loss: 0.024 | Acc: 99.583% (25557/25664)
Loss: 0.024 | Acc: 99.570% (31926/32064)
Loss: 0.024 | Acc: 99.568% (38298/38464)
Loss: 0.024 | Acc: 99.572% (44672/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1922, Accuracy: 9429/10000 (94.29%)
torch.Size([100, 10])
Test set: Average loss: 0.1922, Accuracy: 9429/10000 (94.29%)

Epoch: 50
Loss: 0.013 | Acc: 100.000% (64/64)
Loss: 1.932 | Acc: 29.517% (1908/6464)
Loss: 1.707 | Acc: 37.920% (4878/12864)
Loss: 1.449 | Acc: 47.659% (9181/19264)
Loss: 1.265 | Acc: 54.769% (14056/25664)
Loss: 1.138 | Acc: 59.596% (19109/32064)
Loss: 1.048 | Acc: 62.968% (24220/38464)
Loss: 0.978 | Acc: 65.469% (29372/44864)
torch.Size([100, 10])
Test set: Average loss: 4.6483, Accuracy: 3154/10000 (31.54%)

Epoch: 51
Loss: 1.519 | Acc: 56.250% (36/64)
Loss: 0.529 | Acc: 82.024% (5302/6464)
Loss: 0.513 | Acc: 82.299% (10587/12864)
Loss: 0.507 | Acc: 82.766% (15944/19264)
Loss: 0.502 | Acc: 82.972% (21294/25664)
Loss: 0.492 | Acc: 83.290% (26706/32064)
Loss: 0.483 | Acc: 83.572% (32145/38464)
Loss: 0.477 | Acc: 83.775% (37585/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6683, Accuracy: 7887/10000 (78.87%)

Epoch: 52
Loss: 0.617 | Acc: 76.562% (49/64)
Loss: 0.410 | Acc: 86.634% (5600/6464)
Loss: 0.421 | Acc: 85.798% (11037/12864)
Loss: 0.417 | Acc: 85.725% (16514/19264)
Loss: 0.418 | Acc: 85.817% (22024/25664)
Loss: 0.415 | Acc: 85.838% (27523/32064)
Loss: 0.416 | Acc: 85.815% (33008/38464)
Loss: 0.415 | Acc: 85.909% (38542/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5349, Accuracy: 8220/10000 (82.20%)

Epoch: 53
Loss: 0.401 | Acc: 90.625% (58/64)
Loss: 0.380 | Acc: 87.191% (5636/6464)
Loss: 0.383 | Acc: 87.096% (11204/12864)
Loss: 0.387 | Acc: 86.945% (16749/19264)
Loss: 0.386 | Acc: 86.982% (22323/25664)
Loss: 0.388 | Acc: 86.889% (27860/32064)
Loss: 0.390 | Acc: 86.829% (33398/38464)
Loss: 0.392 | Acc: 86.742% (38916/44864)
torch.Size([100, 10])
Test set: Average loss: 3.5145, Accuracy: 3522/10000 (35.22%)

Epoch: 54
Loss: 1.021 | Acc: 70.312% (45/64)
Loss: 0.402 | Acc: 85.891% (5552/6464)
Loss: 0.383 | Acc: 86.785% (11164/12864)
Loss: 0.373 | Acc: 87.173% (16793/19264)
Loss: 0.378 | Acc: 87.001% (22328/25664)
Loss: 0.381 | Acc: 86.886% (27859/32064)
Loss: 0.383 | Acc: 86.816% (33393/38464)
Loss: 0.384 | Acc: 86.900% (38987/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0750, Accuracy: 6875/10000 (68.75%)

Epoch: 55
Loss: 0.254 | Acc: 92.188% (59/64)
Loss: 0.368 | Acc: 87.531% (5658/6464)
Loss: 0.362 | Acc: 87.889% (11306/12864)
Loss: 0.363 | Acc: 87.806% (16915/19264)
Loss: 0.368 | Acc: 87.578% (22476/25664)
Loss: 0.366 | Acc: 87.628% (28097/32064)
Loss: 0.370 | Acc: 87.516% (33662/38464)
Loss: 0.370 | Acc: 87.460% (39238/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3159, Accuracy: 6213/10000 (62.13%)

Epoch: 56
Loss: 0.439 | Acc: 87.500% (56/64)
Loss: 0.359 | Acc: 88.026% (5690/6464)
Loss: 0.359 | Acc: 87.850% (11301/12864)
Loss: 0.360 | Acc: 87.739% (16902/19264)
Loss: 0.358 | Acc: 87.734% (22516/25664)
Loss: 0.361 | Acc: 87.665% (28109/32064)
Loss: 0.362 | Acc: 87.664% (33719/38464)
Loss: 0.366 | Acc: 87.585% (39294/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5054, Accuracy: 8324/10000 (83.24%)

Epoch: 57
Loss: 0.501 | Acc: 84.375% (54/64)
Loss: 0.354 | Acc: 87.717% (5670/6464)
Loss: 0.349 | Acc: 87.865% (11303/12864)
Loss: 0.353 | Acc: 87.775% (16909/19264)
Loss: 0.352 | Acc: 87.855% (22547/25664)
Loss: 0.358 | Acc: 87.796% (28151/32064)
Loss: 0.358 | Acc: 87.812% (33776/38464)
Loss: 0.357 | Acc: 87.892% (39432/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8525, Accuracy: 7639/10000 (76.39%)

Epoch: 58
Loss: 0.497 | Acc: 82.812% (53/64)
Loss: 0.341 | Acc: 88.304% (5708/6464)
Loss: 0.347 | Acc: 88.005% (11321/12864)
Loss: 0.344 | Acc: 88.258% (17002/19264)
Loss: 0.347 | Acc: 88.182% (22631/25664)
Loss: 0.346 | Acc: 88.186% (28276/32064)
Loss: 0.353 | Acc: 87.929% (33821/38464)
Loss: 0.350 | Acc: 87.977% (39470/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6804, Accuracy: 5942/10000 (59.42%)

Epoch: 59
Loss: 0.356 | Acc: 90.625% (58/64)
Loss: 0.354 | Acc: 87.964% (5686/6464)
Loss: 0.350 | Acc: 87.935% (11312/12864)
Loss: 0.349 | Acc: 88.123% (16976/19264)
Loss: 0.347 | Acc: 88.260% (22651/25664)
Loss: 0.349 | Acc: 88.192% (28278/32064)
Loss: 0.350 | Acc: 88.121% (33895/38464)
Loss: 0.349 | Acc: 88.184% (39563/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4793, Accuracy: 8392/10000 (83.92%)

Epoch: 60
Loss: 0.352 | Acc: 85.938% (55/64)
Loss: 0.333 | Acc: 88.738% (5736/6464)
Loss: 0.338 | Acc: 88.534% (11389/12864)
Loss: 0.341 | Acc: 88.367% (17023/19264)
Loss: 0.341 | Acc: 88.334% (22670/25664)
Loss: 0.338 | Acc: 88.454% (28362/32064)
Loss: 0.339 | Acc: 88.407% (34005/38464)
Loss: 0.341 | Acc: 88.340% (39633/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5774, Accuracy: 8197/10000 (81.97%)

Epoch: 61
Loss: 0.293 | Acc: 92.188% (59/64)
Loss: 0.325 | Acc: 88.861% (5744/6464)
Loss: 0.328 | Acc: 88.674% (11407/12864)
Loss: 0.335 | Acc: 88.445% (17038/19264)
Loss: 0.336 | Acc: 88.482% (22708/25664)
Loss: 0.337 | Acc: 88.510% (28380/32064)
Loss: 0.338 | Acc: 88.563% (34065/38464)
Loss: 0.336 | Acc: 88.641% (39768/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9280, Accuracy: 5086/10000 (50.86%)

Epoch: 62
Loss: 0.755 | Acc: 85.938% (55/64)
Loss: 0.324 | Acc: 89.325% (5774/6464)
Loss: 0.317 | Acc: 89.303% (11488/12864)
Loss: 0.319 | Acc: 89.348% (17212/19264)
Loss: 0.324 | Acc: 89.211% (22895/25664)
Loss: 0.327 | Acc: 89.106% (28571/32064)
Loss: 0.328 | Acc: 89.060% (34256/38464)
Loss: 0.330 | Acc: 88.951% (39907/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9681, Accuracy: 4465/10000 (44.65%)

Epoch: 63
Loss: 1.183 | Acc: 78.125% (50/64)
Loss: 0.339 | Acc: 88.645% (5730/6464)
Loss: 0.333 | Acc: 88.689% (11409/12864)
Loss: 0.324 | Acc: 89.057% (17156/19264)
Loss: 0.328 | Acc: 88.821% (22795/25664)
Loss: 0.329 | Acc: 88.816% (28478/32064)
Loss: 0.330 | Acc: 88.704% (34119/38464)
Loss: 0.327 | Acc: 88.842% (39858/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5635, Accuracy: 8270/10000 (82.70%)

Epoch: 64
Loss: 0.400 | Acc: 92.188% (59/64)
Loss: 0.307 | Acc: 89.851% (5808/6464)
Loss: 0.303 | Acc: 90.003% (11578/12864)
Loss: 0.312 | Acc: 89.680% (17276/19264)
Loss: 0.313 | Acc: 89.592% (22993/25664)
Loss: 0.311 | Acc: 89.643% (28743/32064)
Loss: 0.313 | Acc: 89.549% (34444/38464)
Loss: 0.316 | Acc: 89.430% (40122/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6690, Accuracy: 6518/10000 (65.18%)

Epoch: 65
Loss: 0.488 | Acc: 79.688% (51/64)
Loss: 0.318 | Acc: 88.939% (5749/6464)
Loss: 0.304 | Acc: 89.669% (11535/12864)
Loss: 0.307 | Acc: 89.675% (17275/19264)
Loss: 0.303 | Acc: 89.811% (23049/25664)
Loss: 0.306 | Acc: 89.677% (28754/32064)
Loss: 0.305 | Acc: 89.720% (34510/38464)
Loss: 0.307 | Acc: 89.606% (40201/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8808, Accuracy: 7588/10000 (75.88%)

Epoch: 66
Loss: 0.434 | Acc: 87.500% (56/64)
Loss: 0.277 | Acc: 90.702% (5863/6464)
Loss: 0.289 | Acc: 90.127% (11594/12864)
Loss: 0.293 | Acc: 90.028% (17343/19264)
Loss: 0.297 | Acc: 89.904% (23073/25664)
Loss: 0.293 | Acc: 90.054% (28875/32064)
Loss: 0.295 | Acc: 89.970% (34606/38464)
Loss: 0.296 | Acc: 89.918% (40341/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5918, Accuracy: 6321/10000 (63.21%)

Epoch: 67
Loss: 0.430 | Acc: 89.062% (57/64)
Loss: 0.296 | Acc: 90.022% (5819/6464)
Loss: 0.291 | Acc: 90.143% (11596/12864)
Loss: 0.286 | Acc: 90.308% (17397/19264)
Loss: 0.289 | Acc: 90.181% (23144/25664)
Loss: 0.291 | Acc: 90.148% (28905/32064)
Loss: 0.296 | Acc: 89.978% (34609/38464)
Loss: 0.297 | Acc: 89.941% (40351/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6311, Accuracy: 7960/10000 (79.60%)

Epoch: 68
Loss: 0.227 | Acc: 90.625% (58/64)
Loss: 0.289 | Acc: 90.130% (5826/6464)
Loss: 0.282 | Acc: 90.353% (11623/12864)
Loss: 0.288 | Acc: 90.205% (17377/19264)
Loss: 0.286 | Acc: 90.255% (23163/25664)
Loss: 0.285 | Acc: 90.304% (28955/32064)
Loss: 0.285 | Acc: 90.297% (34732/38464)
Loss: 0.286 | Acc: 90.280% (40503/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4476, Accuracy: 8566/10000 (85.66%)

Epoch: 69
Loss: 0.288 | Acc: 90.625% (58/64)
Loss: 0.269 | Acc: 90.764% (5867/6464)
Loss: 0.265 | Acc: 90.936% (11698/12864)
Loss: 0.272 | Acc: 90.713% (17475/19264)
Loss: 0.274 | Acc: 90.551% (23239/25664)
Loss: 0.278 | Acc: 90.488% (29014/32064)
Loss: 0.279 | Acc: 90.427% (34782/38464)
Loss: 0.276 | Acc: 90.551% (40625/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6173, Accuracy: 8065/10000 (80.65%)

Epoch: 70
Loss: 0.166 | Acc: 95.312% (61/64)
Loss: 0.237 | Acc: 92.002% (5947/6464)
Loss: 0.248 | Acc: 91.503% (11771/12864)
Loss: 0.257 | Acc: 91.160% (17561/19264)
Loss: 0.255 | Acc: 91.221% (23411/25664)
Loss: 0.259 | Acc: 91.115% (29215/32064)
Loss: 0.263 | Acc: 90.942% (34980/38464)
Loss: 0.265 | Acc: 90.924% (40792/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4751, Accuracy: 6318/10000 (63.18%)

Epoch: 71
Loss: 0.434 | Acc: 85.938% (55/64)
Loss: 0.245 | Acc: 91.708% (5928/6464)
Loss: 0.261 | Acc: 91.076% (11716/12864)
Loss: 0.263 | Acc: 90.926% (17516/19264)
Loss: 0.268 | Acc: 90.835% (23312/25664)
Loss: 0.266 | Acc: 90.962% (29166/32064)
Loss: 0.267 | Acc: 90.921% (34972/38464)
Loss: 0.264 | Acc: 91.082% (40863/44864)
torch.Size([100, 10])
Test set: Average loss: 3.1167, Accuracy: 4874/10000 (48.74%)

Epoch: 72
Loss: 0.736 | Acc: 73.438% (47/64)
Loss: 0.261 | Acc: 91.058% (5886/6464)
Loss: 0.251 | Acc: 91.472% (11767/12864)
Loss: 0.254 | Acc: 91.357% (17599/19264)
Loss: 0.257 | Acc: 91.213% (23409/25664)
Loss: 0.253 | Acc: 91.380% (29300/32064)
Loss: 0.250 | Acc: 91.436% (35170/38464)
Loss: 0.251 | Acc: 91.401% (41006/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4740, Accuracy: 8513/10000 (85.13%)

Epoch: 73
Loss: 0.366 | Acc: 90.625% (58/64)
Loss: 0.245 | Acc: 91.290% (5901/6464)
Loss: 0.242 | Acc: 91.558% (11778/12864)
Loss: 0.239 | Acc: 91.700% (17665/19264)
Loss: 0.243 | Acc: 91.572% (23501/25664)
Loss: 0.246 | Acc: 91.433% (29317/32064)
Loss: 0.243 | Acc: 91.548% (35213/38464)
Loss: 0.243 | Acc: 91.537% (41067/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7059, Accuracy: 7866/10000 (78.66%)

Epoch: 74
Loss: 0.311 | Acc: 89.062% (57/64)
Loss: 0.214 | Acc: 92.636% (5988/6464)
Loss: 0.217 | Acc: 92.568% (11908/12864)
Loss: 0.222 | Acc: 92.281% (17777/19264)
Loss: 0.223 | Acc: 92.285% (23684/25664)
Loss: 0.226 | Acc: 92.216% (29568/32064)
Loss: 0.230 | Acc: 92.071% (35414/38464)
Loss: 0.229 | Acc: 92.152% (41343/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5091, Accuracy: 8389/10000 (83.89%)

Epoch: 75
Loss: 0.332 | Acc: 87.500% (56/64)
Loss: 0.207 | Acc: 92.930% (6007/6464)
Loss: 0.211 | Acc: 92.809% (11939/12864)
Loss: 0.218 | Acc: 92.520% (17823/19264)
Loss: 0.220 | Acc: 92.445% (23725/25664)
Loss: 0.218 | Acc: 92.559% (29678/32064)
Loss: 0.222 | Acc: 92.473% (35569/38464)
Loss: 0.222 | Acc: 92.453% (41478/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3214, Accuracy: 8919/10000 (89.19%)

Epoch: 76
Loss: 0.134 | Acc: 92.188% (59/64)
Loss: 0.191 | Acc: 93.193% (6024/6464)
Loss: 0.194 | Acc: 93.151% (11983/12864)
Loss: 0.199 | Acc: 93.034% (17922/19264)
Loss: 0.204 | Acc: 92.823% (23822/25664)
Loss: 0.207 | Acc: 92.786% (29751/32064)
Loss: 0.211 | Acc: 92.689% (35652/38464)
Loss: 0.210 | Acc: 92.731% (41603/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3696, Accuracy: 8797/10000 (87.97%)

Epoch: 77
Loss: 0.230 | Acc: 90.625% (58/64)
Loss: 0.191 | Acc: 93.533% (6046/6464)
Loss: 0.189 | Acc: 93.377% (12012/12864)
Loss: 0.192 | Acc: 93.449% (18002/19264)
Loss: 0.193 | Acc: 93.372% (23963/25664)
Loss: 0.192 | Acc: 93.438% (29960/32064)
Loss: 0.196 | Acc: 93.308% (35890/38464)
Loss: 0.196 | Acc: 93.298% (41857/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4166, Accuracy: 8707/10000 (87.07%)

Epoch: 78
Loss: 0.201 | Acc: 93.750% (60/64)
Loss: 0.174 | Acc: 94.075% (6081/6464)
Loss: 0.173 | Acc: 94.092% (12104/12864)
Loss: 0.173 | Acc: 94.051% (18118/19264)
Loss: 0.179 | Acc: 93.921% (24104/25664)
Loss: 0.182 | Acc: 93.856% (30094/32064)
Loss: 0.184 | Acc: 93.807% (36082/38464)
Loss: 0.185 | Acc: 93.788% (42077/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5754, Accuracy: 8329/10000 (83.29%)

Epoch: 79
Loss: 0.107 | Acc: 96.875% (62/64)
Loss: 0.151 | Acc: 94.802% (6128/6464)
Loss: 0.152 | Acc: 94.729% (12186/12864)
Loss: 0.159 | Acc: 94.581% (18220/19264)
Loss: 0.164 | Acc: 94.420% (24232/25664)
Loss: 0.166 | Acc: 94.333% (30247/32064)
Loss: 0.167 | Acc: 94.301% (36272/38464)
Loss: 0.167 | Acc: 94.276% (42296/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4201, Accuracy: 6251/10000 (62.51%)

Epoch: 80
Loss: 0.683 | Acc: 78.125% (50/64)
Loss: 0.182 | Acc: 94.121% (6084/6464)
Loss: 0.169 | Acc: 94.419% (12146/12864)
Loss: 0.162 | Acc: 94.643% (18232/19264)
Loss: 0.160 | Acc: 94.638% (24288/25664)
Loss: 0.162 | Acc: 94.570% (30323/32064)
Loss: 0.161 | Acc: 94.564% (36373/38464)
Loss: 0.161 | Acc: 94.557% (42422/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5140, Accuracy: 8396/10000 (83.96%)

Epoch: 81
Loss: 0.151 | Acc: 93.750% (60/64)
Loss: 0.159 | Acc: 94.369% (6100/6464)
Loss: 0.149 | Acc: 94.683% (12180/12864)
Loss: 0.151 | Acc: 94.726% (18248/19264)
Loss: 0.151 | Acc: 94.728% (24311/25664)
Loss: 0.151 | Acc: 94.813% (30401/32064)
Loss: 0.151 | Acc: 94.806% (36466/38464)
Loss: 0.152 | Acc: 94.775% (42520/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3508, Accuracy: 8894/10000 (88.94%)

Epoch: 82
Loss: 0.121 | Acc: 95.312% (61/64)
Loss: 0.139 | Acc: 94.941% (6137/6464)
Loss: 0.129 | Acc: 95.484% (12283/12864)
Loss: 0.127 | Acc: 95.551% (18407/19264)
Loss: 0.129 | Acc: 95.484% (24505/25664)
Loss: 0.130 | Acc: 95.434% (30600/32064)
Loss: 0.132 | Acc: 95.396% (36693/38464)
Loss: 0.132 | Acc: 95.395% (42798/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4593, Accuracy: 8683/10000 (86.83%)

Epoch: 83
Loss: 0.159 | Acc: 93.750% (60/64)
Loss: 0.113 | Acc: 96.442% (6234/6464)
Loss: 0.114 | Acc: 96.238% (12380/12864)
Loss: 0.110 | Acc: 96.283% (18548/19264)
Loss: 0.112 | Acc: 96.205% (24690/25664)
Loss: 0.115 | Acc: 96.070% (30804/32064)
Loss: 0.116 | Acc: 96.017% (36932/38464)
Loss: 0.117 | Acc: 95.970% (43056/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8897, Accuracy: 8019/10000 (80.19%)

Epoch: 84
Loss: 0.170 | Acc: 92.188% (59/64)
Loss: 0.121 | Acc: 96.071% (6210/6464)
Loss: 0.118 | Acc: 95.989% (12348/12864)
Loss: 0.119 | Acc: 95.998% (18493/19264)
Loss: 0.114 | Acc: 96.146% (24675/25664)
Loss: 0.113 | Acc: 96.214% (30850/32064)
Loss: 0.111 | Acc: 96.287% (37036/38464)
Loss: 0.109 | Acc: 96.342% (43223/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2380, Accuracy: 9233/10000 (92.33%)

Epoch: 85
Loss: 0.010 | Acc: 100.000% (64/64)
Loss: 0.088 | Acc: 96.906% (6264/6464)
Loss: 0.087 | Acc: 97.007% (12479/12864)
Loss: 0.087 | Acc: 96.989% (18684/19264)
Loss: 0.091 | Acc: 96.852% (24856/25664)
Loss: 0.090 | Acc: 96.878% (31063/32064)
Loss: 0.091 | Acc: 96.826% (37243/38464)
Loss: 0.093 | Acc: 96.781% (43420/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2850, Accuracy: 9149/10000 (91.49%)

Epoch: 86
Loss: 0.047 | Acc: 100.000% (64/64)
Loss: 0.074 | Acc: 97.679% (6314/6464)
Loss: 0.073 | Acc: 97.629% (12559/12864)
Loss: 0.074 | Acc: 97.623% (18806/19264)
Loss: 0.075 | Acc: 97.584% (25044/25664)
Loss: 0.074 | Acc: 97.577% (31287/32064)
Loss: 0.075 | Acc: 97.543% (37519/38464)
Loss: 0.075 | Acc: 97.508% (43746/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3546, Accuracy: 9067/10000 (90.67%)

Epoch: 87
Loss: 0.095 | Acc: 96.875% (62/64)
Loss: 0.065 | Acc: 97.788% (6321/6464)
Loss: 0.063 | Acc: 97.769% (12577/12864)
Loss: 0.063 | Acc: 97.835% (18847/19264)
Loss: 0.063 | Acc: 97.861% (25115/25664)
Loss: 0.063 | Acc: 97.842% (31372/32064)
Loss: 0.063 | Acc: 97.845% (37635/38464)
Loss: 0.063 | Acc: 97.833% (43892/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2597, Accuracy: 9239/10000 (92.39%)

Epoch: 88
Loss: 0.059 | Acc: 96.875% (62/64)
Loss: 0.058 | Acc: 98.267% (6352/6464)
Loss: 0.053 | Acc: 98.399% (12658/12864)
Loss: 0.052 | Acc: 98.422% (18960/19264)
Loss: 0.051 | Acc: 98.410% (25256/25664)
Loss: 0.052 | Acc: 98.366% (31540/32064)
Loss: 0.053 | Acc: 98.305% (37812/38464)
Loss: 0.052 | Acc: 98.326% (44113/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2209, Accuracy: 9345/10000 (93.45%)

Epoch: 89
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 0.044 | Acc: 98.546% (6370/6464)
Loss: 0.043 | Acc: 98.616% (12686/12864)
Loss: 0.042 | Acc: 98.671% (19008/19264)
Loss: 0.040 | Acc: 98.741% (25341/25664)
Loss: 0.041 | Acc: 98.709% (31650/32064)
Loss: 0.040 | Acc: 98.713% (37969/38464)
Loss: 0.040 | Acc: 98.741% (44299/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2285, Accuracy: 9338/10000 (93.38%)

Epoch: 90
Loss: 0.008 | Acc: 100.000% (64/64)
Loss: 0.028 | Acc: 99.165% (6410/6464)
Loss: 0.030 | Acc: 99.137% (12753/12864)
Loss: 0.029 | Acc: 99.133% (19097/19264)
Loss: 0.028 | Acc: 99.178% (25453/25664)
Loss: 0.029 | Acc: 99.180% (31801/32064)
Loss: 0.028 | Acc: 99.194% (38154/38464)
Loss: 0.029 | Acc: 99.164% (44489/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2243, Accuracy: 9373/10000 (93.73%)

Epoch: 91
Loss: 0.019 | Acc: 100.000% (64/64)
Loss: 0.027 | Acc: 99.288% (6418/6464)
Loss: 0.026 | Acc: 99.254% (12768/12864)
Loss: 0.026 | Acc: 99.273% (19124/19264)
Loss: 0.025 | Acc: 99.306% (25486/25664)
Loss: 0.024 | Acc: 99.320% (31846/32064)
Loss: 0.025 | Acc: 99.308% (38198/38464)
Loss: 0.024 | Acc: 99.318% (44558/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2059, Accuracy: 9427/10000 (94.27%)

Epoch: 92
Loss: 0.021 | Acc: 100.000% (64/64)
Loss: 0.018 | Acc: 99.489% (6431/6464)
Loss: 0.018 | Acc: 99.495% (12799/12864)
Loss: 0.017 | Acc: 99.538% (19175/19264)
Loss: 0.017 | Acc: 99.525% (25542/25664)
Loss: 0.017 | Acc: 99.532% (31914/32064)
Loss: 0.017 | Acc: 99.537% (38286/38464)
Loss: 0.017 | Acc: 99.539% (44657/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2159, Accuracy: 9434/10000 (94.34%)

Epoch: 93
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 0.013 | Acc: 99.598% (6438/6464)
Loss: 0.014 | Acc: 99.619% (12815/12864)
Loss: 0.013 | Acc: 99.637% (19194/19264)
Loss: 0.013 | Acc: 99.634% (25570/25664)
Loss: 0.014 | Acc: 99.648% (31951/32064)
Loss: 0.013 | Acc: 99.659% (38333/38464)
Loss: 0.013 | Acc: 99.648% (44706/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2138, Accuracy: 9451/10000 (94.51%)

Epoch: 94
Loss: 0.011 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.722% (6446/6464)
Loss: 0.011 | Acc: 99.720% (12828/12864)
Loss: 0.011 | Acc: 99.751% (19216/19264)
Loss: 0.011 | Acc: 99.743% (25598/25664)
Loss: 0.011 | Acc: 99.722% (31975/32064)
Loss: 0.010 | Acc: 99.743% (38365/38464)
Loss: 0.010 | Acc: 99.755% (44754/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1979, Accuracy: 9475/10000 (94.75%)

Epoch: 95
Loss: 0.016 | Acc: 98.438% (63/64)
Loss: 0.010 | Acc: 99.752% (6448/6464)
Loss: 0.010 | Acc: 99.751% (12832/12864)
Loss: 0.010 | Acc: 99.766% (19219/19264)
Loss: 0.010 | Acc: 99.770% (25605/25664)
Loss: 0.011 | Acc: 99.744% (31982/32064)
Loss: 0.012 | Acc: 99.727% (38359/38464)
Loss: 0.013 | Acc: 99.708% (44733/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1969, Accuracy: 9439/10000 (94.39%)

Epoch: 96
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.018 | Acc: 99.582% (6437/6464)
Loss: 0.016 | Acc: 99.650% (12819/12864)
Loss: 0.015 | Acc: 99.720% (19210/19264)
Loss: 0.016 | Acc: 99.680% (25582/25664)
Loss: 0.016 | Acc: 99.669% (31958/32064)
Loss: 0.016 | Acc: 99.678% (38340/38464)
Loss: 0.016 | Acc: 99.672% (44717/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1896, Accuracy: 9440/10000 (94.40%)

Epoch: 97
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.016 | Acc: 99.799% (6451/6464)
Loss: 0.016 | Acc: 99.751% (12832/12864)
Loss: 0.017 | Acc: 99.761% (19218/19264)
Loss: 0.018 | Acc: 99.712% (25590/25664)
Loss: 0.018 | Acc: 99.716% (31973/32064)
Loss: 0.018 | Acc: 99.711% (38353/38464)
Loss: 0.018 | Acc: 99.708% (44733/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1898, Accuracy: 9427/10000 (94.27%)
torch.Size([100, 10])
Test set: Average loss: 0.1898, Accuracy: 9427/10000 (94.27%)

Epoch: 98
Loss: 0.011 | Acc: 100.000% (64/64)
Loss: 0.016 | Acc: 99.706% (6445/6464)
Loss: 0.018 | Acc: 99.658% (12820/12864)
Loss: 0.019 | Acc: 99.637% (19194/19264)
Loss: 0.019 | Acc: 99.638% (25571/25664)
Loss: 0.019 | Acc: 99.616% (31941/32064)
Loss: 0.019 | Acc: 99.641% (38326/38464)
Loss: 0.019 | Acc: 99.641% (44703/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1891, Accuracy: 9437/10000 (94.37%)
torch.Size([100, 10])
Test set: Average loss: 0.1891, Accuracy: 9437/10000 (94.37%)

Epoch: 99
Loss: 0.011 | Acc: 100.000% (64/64)
Loss: 0.017 | Acc: 99.722% (6446/6464)
Loss: 0.019 | Acc: 99.681% (12823/12864)
Loss: 0.019 | Acc: 99.683% (19203/19264)
Loss: 0.019 | Acc: 99.669% (25579/25664)
Loss: 0.019 | Acc: 99.694% (31966/32064)
Loss: 0.019 | Acc: 99.678% (38340/38464)
Loss: 0.019 | Acc: 99.672% (44717/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1886, Accuracy: 9435/10000 (94.35%)
torch.Size([100, 10])
Test set: Average loss: 0.1886, Accuracy: 9435/10000 (94.35%)

Epoch: 100
Loss: 0.020 | Acc: 100.000% (64/64)
Loss: 1.954 | Acc: 29.254% (1891/6464)
Loss: 1.683 | Acc: 39.008% (5018/12864)
Loss: 1.409 | Acc: 49.673% (9569/19264)
Loss: 1.229 | Acc: 56.484% (14496/25664)
Loss: 1.104 | Acc: 61.122% (19598/32064)
Loss: 1.014 | Acc: 64.554% (24830/38464)
Loss: 0.945 | Acc: 67.043% (30078/44864)
torch.Size([100, 10])
Test set: Average loss: 4.8346, Accuracy: 3453/10000 (34.53%)

Epoch: 101
Loss: 0.959 | Acc: 70.312% (45/64)
Loss: 0.465 | Acc: 84.592% (5468/6464)
Loss: 0.476 | Acc: 84.017% (10808/12864)
Loss: 0.467 | Acc: 84.235% (16227/19264)
Loss: 0.458 | Acc: 84.461% (21676/25664)
Loss: 0.454 | Acc: 84.540% (27107/32064)
Loss: 0.451 | Acc: 84.692% (32576/38464)
Loss: 0.451 | Acc: 84.736% (38016/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7542, Accuracy: 6338/10000 (63.38%)

Epoch: 102
Loss: 0.344 | Acc: 90.625% (58/64)
Loss: 0.380 | Acc: 87.237% (5639/6464)
Loss: 0.396 | Acc: 86.699% (11153/12864)
Loss: 0.392 | Acc: 86.778% (16717/19264)
Loss: 0.394 | Acc: 86.771% (22269/25664)
Loss: 0.397 | Acc: 86.692% (27797/32064)
Loss: 0.395 | Acc: 86.665% (33335/38464)
Loss: 0.397 | Acc: 86.686% (38891/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1147, Accuracy: 6656/10000 (66.56%)

Epoch: 103
Loss: 0.387 | Acc: 84.375% (54/64)
Loss: 0.376 | Acc: 87.252% (5640/6464)
Loss: 0.367 | Acc: 87.554% (11263/12864)
Loss: 0.374 | Acc: 87.152% (16789/19264)
Loss: 0.371 | Acc: 87.274% (22398/25664)
Loss: 0.372 | Acc: 87.350% (28008/32064)
Loss: 0.372 | Acc: 87.373% (33607/38464)
Loss: 0.373 | Acc: 87.353% (39190/44864)
torch.Size([100, 10])
Test set: Average loss: 2.8554, Accuracy: 4383/10000 (43.83%)

Epoch: 104
Loss: 0.775 | Acc: 75.000% (48/64)
Loss: 0.376 | Acc: 87.454% (5653/6464)
Loss: 0.357 | Acc: 87.982% (11318/12864)
Loss: 0.355 | Acc: 88.071% (16966/19264)
Loss: 0.357 | Acc: 87.999% (22584/25664)
Loss: 0.354 | Acc: 88.083% (28243/32064)
Loss: 0.357 | Acc: 87.986% (33843/38464)
Loss: 0.358 | Acc: 87.895% (39433/44864)
torch.Size([100, 10])
Test set: Average loss: 5.6565, Accuracy: 2610/10000 (26.10%)

Epoch: 105
Loss: 0.453 | Acc: 82.812% (53/64)
Loss: 0.358 | Acc: 88.134% (5697/6464)
Loss: 0.351 | Acc: 88.161% (11341/12864)
Loss: 0.347 | Acc: 88.299% (17010/19264)
Loss: 0.350 | Acc: 88.131% (22618/25664)
Loss: 0.350 | Acc: 88.136% (28260/32064)
Loss: 0.351 | Acc: 88.067% (33874/38464)
Loss: 0.350 | Acc: 88.068% (39511/44864)
torch.Size([100, 10])
Test set: Average loss: 2.7875, Accuracy: 4261/10000 (42.61%)

Epoch: 106
Loss: 0.559 | Acc: 79.688% (51/64)
Loss: 0.346 | Acc: 88.645% (5730/6464)
Loss: 0.339 | Acc: 88.472% (11381/12864)
Loss: 0.335 | Acc: 88.678% (17083/19264)
Loss: 0.343 | Acc: 88.486% (22709/25664)
Loss: 0.346 | Acc: 88.383% (28339/32064)
Loss: 0.346 | Acc: 88.355% (33985/38464)
Loss: 0.348 | Acc: 88.300% (39615/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8548, Accuracy: 7484/10000 (74.84%)

Epoch: 107
Loss: 0.522 | Acc: 85.938% (55/64)
Loss: 0.317 | Acc: 89.588% (5791/6464)
Loss: 0.328 | Acc: 89.117% (11464/12864)
Loss: 0.330 | Acc: 88.974% (17140/19264)
Loss: 0.334 | Acc: 88.844% (22801/25664)
Loss: 0.338 | Acc: 88.698% (28440/32064)
Loss: 0.340 | Acc: 88.628% (34090/38464)
Loss: 0.337 | Acc: 88.695% (39792/44864)
torch.Size([100, 10])
Test set: Average loss: 3.4642, Accuracy: 3252/10000 (32.52%)

Epoch: 108
Loss: 0.767 | Acc: 70.312% (45/64)
Loss: 0.336 | Acc: 88.397% (5714/6464)
Loss: 0.332 | Acc: 88.557% (11392/12864)
Loss: 0.330 | Acc: 88.595% (17067/19264)
Loss: 0.334 | Acc: 88.486% (22709/25664)
Loss: 0.334 | Acc: 88.529% (28386/32064)
Loss: 0.336 | Acc: 88.504% (34042/38464)
Loss: 0.338 | Acc: 88.472% (39692/44864)
torch.Size([100, 10])
Test set: Average loss: 2.8726, Accuracy: 4528/10000 (45.28%)

Epoch: 109
Loss: 0.638 | Acc: 76.562% (49/64)
Loss: 0.340 | Acc: 88.289% (5707/6464)
Loss: 0.335 | Acc: 88.658% (11405/12864)
Loss: 0.336 | Acc: 88.538% (17056/19264)
Loss: 0.334 | Acc: 88.603% (22739/25664)
Loss: 0.336 | Acc: 88.560% (28396/32064)
Loss: 0.334 | Acc: 88.657% (34101/38464)
Loss: 0.331 | Acc: 88.717% (39802/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4756, Accuracy: 6340/10000 (63.40%)

Epoch: 110
Loss: 0.586 | Acc: 78.125% (50/64)
Loss: 0.328 | Acc: 89.403% (5779/6464)
Loss: 0.323 | Acc: 89.451% (11507/12864)
Loss: 0.323 | Acc: 89.421% (17226/19264)
Loss: 0.328 | Acc: 89.234% (22901/25664)
Loss: 0.329 | Acc: 89.134% (28580/32064)
Loss: 0.329 | Acc: 89.122% (34280/38464)
Loss: 0.329 | Acc: 89.096% (39972/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1204, Accuracy: 7041/10000 (70.41%)

Epoch: 111
Loss: 0.870 | Acc: 76.562% (49/64)
Loss: 0.320 | Acc: 88.861% (5744/6464)
Loss: 0.325 | Acc: 88.884% (11434/12864)
Loss: 0.324 | Acc: 88.928% (17131/19264)
Loss: 0.322 | Acc: 89.105% (22868/25664)
Loss: 0.323 | Acc: 89.087% (28565/32064)
Loss: 0.325 | Acc: 88.961% (34218/38464)
Loss: 0.326 | Acc: 88.924% (39895/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7521, Accuracy: 7701/10000 (77.01%)

Epoch: 112
Loss: 0.512 | Acc: 82.812% (53/64)
Loss: 0.298 | Acc: 89.805% (5805/6464)
Loss: 0.301 | Acc: 89.607% (11527/12864)
Loss: 0.307 | Acc: 89.514% (17244/19264)
Loss: 0.307 | Acc: 89.476% (22963/25664)
Loss: 0.310 | Acc: 89.409% (28668/32064)
Loss: 0.313 | Acc: 89.317% (34355/38464)
Loss: 0.315 | Acc: 89.245% (40039/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8893, Accuracy: 7347/10000 (73.47%)

Epoch: 113
Loss: 0.315 | Acc: 87.500% (56/64)
Loss: 0.294 | Acc: 89.790% (5804/6464)
Loss: 0.292 | Acc: 90.166% (11599/12864)
Loss: 0.295 | Acc: 90.142% (17365/19264)
Loss: 0.299 | Acc: 89.896% (23071/25664)
Loss: 0.302 | Acc: 89.724% (28769/32064)
Loss: 0.303 | Acc: 89.666% (34489/38464)
Loss: 0.305 | Acc: 89.651% (40221/44864)
torch.Size([100, 10])
Test set: Average loss: 7.8830, Accuracy: 2483/10000 (24.83%)

Epoch: 114
Loss: 0.740 | Acc: 76.562% (49/64)
Loss: 0.295 | Acc: 89.774% (5803/6464)
Loss: 0.295 | Acc: 89.910% (11566/12864)
Loss: 0.299 | Acc: 89.675% (17275/19264)
Loss: 0.301 | Acc: 89.717% (23025/25664)
Loss: 0.300 | Acc: 89.833% (28804/32064)
Loss: 0.302 | Acc: 89.731% (34514/38464)
Loss: 0.301 | Acc: 89.753% (40267/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5011, Accuracy: 4711/10000 (47.11%)

Epoch: 115
Loss: 0.737 | Acc: 75.000% (48/64)
Loss: 0.284 | Acc: 90.687% (5862/6464)
Loss: 0.286 | Acc: 90.524% (11645/12864)
Loss: 0.291 | Acc: 90.417% (17418/19264)
Loss: 0.292 | Acc: 90.231% (23157/25664)
Loss: 0.292 | Acc: 90.279% (28947/32064)
Loss: 0.296 | Acc: 90.139% (34671/38464)
Loss: 0.299 | Acc: 90.097% (40421/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1703, Accuracy: 6869/10000 (68.69%)

Epoch: 116
Loss: 0.448 | Acc: 85.938% (55/64)
Loss: 0.274 | Acc: 90.996% (5882/6464)
Loss: 0.286 | Acc: 90.314% (11618/12864)
Loss: 0.290 | Acc: 90.070% (17351/19264)
Loss: 0.286 | Acc: 90.220% (23154/25664)
Loss: 0.288 | Acc: 90.167% (28911/32064)
Loss: 0.289 | Acc: 90.134% (34669/38464)
Loss: 0.293 | Acc: 90.008% (40381/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9962, Accuracy: 7127/10000 (71.27%)

Epoch: 117
Loss: 0.459 | Acc: 82.812% (53/64)
Loss: 0.286 | Acc: 90.037% (5820/6464)
Loss: 0.283 | Acc: 90.182% (11601/12864)
Loss: 0.283 | Acc: 90.267% (17389/19264)
Loss: 0.279 | Acc: 90.391% (23198/25664)
Loss: 0.280 | Acc: 90.397% (28985/32064)
Loss: 0.282 | Acc: 90.313% (34738/38464)
Loss: 0.282 | Acc: 90.331% (40526/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6806, Accuracy: 7858/10000 (78.58%)

Epoch: 118
Loss: 0.410 | Acc: 90.625% (58/64)
Loss: 0.279 | Acc: 90.424% (5845/6464)
Loss: 0.268 | Acc: 90.874% (11690/12864)
Loss: 0.268 | Acc: 90.957% (17522/19264)
Loss: 0.275 | Acc: 90.656% (23266/25664)
Loss: 0.275 | Acc: 90.584% (29045/32064)
Loss: 0.278 | Acc: 90.544% (34827/38464)
Loss: 0.276 | Acc: 90.585% (40640/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8028, Accuracy: 7642/10000 (76.42%)

Epoch: 119
Loss: 0.247 | Acc: 92.188% (59/64)
Loss: 0.263 | Acc: 90.857% (5873/6464)
Loss: 0.261 | Acc: 90.975% (11703/12864)
Loss: 0.269 | Acc: 90.609% (17455/19264)
Loss: 0.266 | Acc: 90.859% (23318/25664)
Loss: 0.263 | Acc: 90.943% (29160/32064)
Loss: 0.262 | Acc: 91.023% (35011/38464)
Loss: 0.263 | Acc: 90.986% (40820/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6076, Accuracy: 8198/10000 (81.98%)

Epoch: 120
Loss: 0.261 | Acc: 89.062% (57/64)
Loss: 0.261 | Acc: 91.306% (5902/6464)
Loss: 0.256 | Acc: 91.231% (11736/12864)
Loss: 0.254 | Acc: 91.347% (17597/19264)
Loss: 0.253 | Acc: 91.381% (23452/25664)
Loss: 0.250 | Acc: 91.504% (29340/32064)
Loss: 0.251 | Acc: 91.465% (35181/38464)
Loss: 0.253 | Acc: 91.374% (40994/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4440, Accuracy: 6467/10000 (64.67%)

Epoch: 121
Loss: 0.426 | Acc: 85.938% (55/64)
Loss: 0.244 | Acc: 91.522% (5916/6464)
Loss: 0.247 | Acc: 91.589% (11782/12864)
Loss: 0.249 | Acc: 91.575% (17641/19264)
Loss: 0.249 | Acc: 91.556% (23497/25664)
Loss: 0.248 | Acc: 91.692% (29400/32064)
Loss: 0.250 | Acc: 91.577% (35224/38464)
Loss: 0.250 | Acc: 91.581% (41087/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4845, Accuracy: 8448/10000 (84.48%)

Epoch: 122
Loss: 0.389 | Acc: 84.375% (54/64)
Loss: 0.237 | Acc: 91.770% (5932/6464)
Loss: 0.232 | Acc: 91.892% (11821/12864)
Loss: 0.234 | Acc: 91.881% (17700/19264)
Loss: 0.235 | Acc: 91.954% (23599/25664)
Loss: 0.240 | Acc: 91.813% (29439/32064)
Loss: 0.241 | Acc: 91.808% (35313/38464)
Loss: 0.243 | Acc: 91.706% (41143/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5110, Accuracy: 8386/10000 (83.86%)

Epoch: 123
Loss: 0.442 | Acc: 85.938% (55/64)
Loss: 0.208 | Acc: 92.899% (6005/6464)
Loss: 0.218 | Acc: 92.561% (11907/12864)
Loss: 0.222 | Acc: 92.390% (17798/19264)
Loss: 0.225 | Acc: 92.464% (23730/25664)
Loss: 0.226 | Acc: 92.396% (29626/32064)
Loss: 0.229 | Acc: 92.232% (35476/38464)
Loss: 0.231 | Acc: 92.188% (41359/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5962, Accuracy: 8248/10000 (82.48%)

Epoch: 124
Loss: 0.297 | Acc: 87.500% (56/64)
Loss: 0.218 | Acc: 92.683% (5991/6464)
Loss: 0.209 | Acc: 92.879% (11948/12864)
Loss: 0.211 | Acc: 92.738% (17865/19264)
Loss: 0.216 | Acc: 92.569% (23757/25664)
Loss: 0.220 | Acc: 92.468% (29649/32064)
Loss: 0.218 | Acc: 92.523% (35588/38464)
Loss: 0.219 | Acc: 92.471% (41486/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5501, Accuracy: 8294/10000 (82.94%)

Epoch: 125
Loss: 0.093 | Acc: 96.875% (62/64)
Loss: 0.199 | Acc: 93.270% (6029/6464)
Loss: 0.202 | Acc: 93.175% (11986/12864)
Loss: 0.209 | Acc: 92.868% (17890/19264)
Loss: 0.205 | Acc: 93.033% (23876/25664)
Loss: 0.206 | Acc: 92.973% (29811/32064)
Loss: 0.208 | Acc: 92.871% (35722/38464)
Loss: 0.209 | Acc: 92.867% (41664/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6966, Accuracy: 7884/10000 (78.84%)

Epoch: 126
Loss: 0.302 | Acc: 87.500% (56/64)
Loss: 0.189 | Acc: 93.735% (6059/6464)
Loss: 0.191 | Acc: 93.509% (12029/12864)
Loss: 0.194 | Acc: 93.418% (17996/19264)
Loss: 0.199 | Acc: 93.189% (23916/25664)
Loss: 0.199 | Acc: 93.167% (29873/32064)
Loss: 0.199 | Acc: 93.214% (35854/38464)
Loss: 0.199 | Acc: 93.199% (41813/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3567, Accuracy: 8861/10000 (88.61%)

Epoch: 127
Loss: 0.271 | Acc: 92.188% (59/64)
Loss: 0.182 | Acc: 94.059% (6080/6464)
Loss: 0.186 | Acc: 93.672% (12050/12864)
Loss: 0.184 | Acc: 93.688% (18048/19264)
Loss: 0.189 | Acc: 93.516% (24000/25664)
Loss: 0.191 | Acc: 93.407% (29950/32064)
Loss: 0.191 | Acc: 93.425% (35935/38464)
Loss: 0.190 | Acc: 93.496% (41946/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4995, Accuracy: 8480/10000 (84.80%)

Epoch: 128
Loss: 0.234 | Acc: 90.625% (58/64)
Loss: 0.163 | Acc: 94.338% (6098/6464)
Loss: 0.166 | Acc: 94.341% (12136/12864)
Loss: 0.169 | Acc: 94.285% (18163/19264)
Loss: 0.170 | Acc: 94.292% (24199/25664)
Loss: 0.173 | Acc: 94.233% (30215/32064)
Loss: 0.174 | Acc: 94.208% (36236/38464)
Loss: 0.177 | Acc: 94.058% (42198/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4050, Accuracy: 8787/10000 (87.87%)

Epoch: 129
Loss: 0.237 | Acc: 93.750% (60/64)
Loss: 0.158 | Acc: 94.508% (6109/6464)
Loss: 0.155 | Acc: 94.473% (12153/12864)
Loss: 0.161 | Acc: 94.321% (18170/19264)
Loss: 0.165 | Acc: 94.292% (24199/25664)
Loss: 0.166 | Acc: 94.290% (30233/32064)
Loss: 0.167 | Acc: 94.262% (36257/38464)
Loss: 0.165 | Acc: 94.341% (42325/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9484, Accuracy: 7610/10000 (76.10%)

Epoch: 130
Loss: 0.281 | Acc: 90.625% (58/64)
Loss: 0.164 | Acc: 94.415% (6103/6464)
Loss: 0.157 | Acc: 94.636% (12174/12864)
Loss: 0.156 | Acc: 94.627% (18229/19264)
Loss: 0.156 | Acc: 94.646% (24290/25664)
Loss: 0.153 | Acc: 94.732% (30375/32064)
Loss: 0.155 | Acc: 94.691% (36422/38464)
Loss: 0.157 | Acc: 94.668% (42472/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6767, Accuracy: 8232/10000 (82.32%)

Epoch: 131
Loss: 0.450 | Acc: 87.500% (56/64)
Loss: 0.128 | Acc: 95.591% (6179/6464)
Loss: 0.135 | Acc: 95.437% (12277/12864)
Loss: 0.134 | Acc: 95.427% (18383/19264)
Loss: 0.135 | Acc: 95.371% (24476/25664)
Loss: 0.134 | Acc: 95.387% (30585/32064)
Loss: 0.136 | Acc: 95.320% (36664/38464)
Loss: 0.138 | Acc: 95.263% (42739/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6470, Accuracy: 8454/10000 (84.54%)

Epoch: 132
Loss: 0.439 | Acc: 89.062% (57/64)
Loss: 0.122 | Acc: 95.900% (6199/6464)
Loss: 0.120 | Acc: 96.004% (12350/12864)
Loss: 0.128 | Acc: 95.780% (18451/19264)
Loss: 0.127 | Acc: 95.757% (24575/25664)
Loss: 0.128 | Acc: 95.768% (30707/32064)
Loss: 0.129 | Acc: 95.731% (36822/38464)
Loss: 0.129 | Acc: 95.707% (42938/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3086, Accuracy: 9017/10000 (90.17%)

Epoch: 133
Loss: 0.083 | Acc: 95.312% (61/64)
Loss: 0.099 | Acc: 96.767% (6255/6464)
Loss: 0.106 | Acc: 96.549% (12420/12864)
Loss: 0.109 | Acc: 96.413% (18573/19264)
Loss: 0.110 | Acc: 96.263% (24705/25664)
Loss: 0.112 | Acc: 96.208% (30848/32064)
Loss: 0.113 | Acc: 96.191% (36999/38464)
Loss: 0.113 | Acc: 96.157% (43140/44864)
torch.Size([100, 10])
Test set: Average loss: 2.6373, Accuracy: 5147/10000 (51.47%)

Epoch: 134
Loss: 0.368 | Acc: 87.500% (56/64)
Loss: 0.110 | Acc: 96.210% (6219/6464)
Loss: 0.100 | Acc: 96.564% (12422/12864)
Loss: 0.100 | Acc: 96.595% (18608/19264)
Loss: 0.099 | Acc: 96.633% (24800/25664)
Loss: 0.099 | Acc: 96.641% (30987/32064)
Loss: 0.101 | Acc: 96.594% (37154/38464)
Loss: 0.101 | Acc: 96.590% (43334/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2923, Accuracy: 9134/10000 (91.34%)

Epoch: 135
Loss: 0.060 | Acc: 98.438% (63/64)
Loss: 0.089 | Acc: 97.061% (6274/6464)
Loss: 0.086 | Acc: 97.085% (12489/12864)
Loss: 0.086 | Acc: 97.109% (18707/19264)
Loss: 0.090 | Acc: 96.922% (24874/25664)
Loss: 0.088 | Acc: 96.984% (31097/32064)
Loss: 0.088 | Acc: 96.971% (37299/38464)
Loss: 0.088 | Acc: 97.024% (43529/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2375, Accuracy: 9248/10000 (92.48%)

Epoch: 136
Loss: 0.061 | Acc: 98.438% (63/64)
Loss: 0.077 | Acc: 97.540% (6305/6464)
Loss: 0.074 | Acc: 97.559% (12550/12864)
Loss: 0.072 | Acc: 97.648% (18811/19264)
Loss: 0.071 | Acc: 97.654% (25062/25664)
Loss: 0.072 | Acc: 97.586% (31290/32064)
Loss: 0.072 | Acc: 97.587% (37536/38464)
Loss: 0.073 | Acc: 97.557% (43768/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2188, Accuracy: 9337/10000 (93.37%)

Epoch: 137
Loss: 0.074 | Acc: 98.438% (63/64)
Loss: 0.058 | Acc: 98.082% (6340/6464)
Loss: 0.055 | Acc: 98.165% (12628/12864)
Loss: 0.055 | Acc: 98.136% (18905/19264)
Loss: 0.057 | Acc: 98.099% (25176/25664)
Loss: 0.057 | Acc: 98.119% (31461/32064)
Loss: 0.056 | Acc: 98.126% (37743/38464)
Loss: 0.057 | Acc: 98.090% (44007/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2517, Accuracy: 9254/10000 (92.54%)

Epoch: 138
Loss: 0.022 | Acc: 100.000% (64/64)
Loss: 0.049 | Acc: 98.577% (6372/6464)
Loss: 0.051 | Acc: 98.368% (12654/12864)
Loss: 0.051 | Acc: 98.349% (18946/19264)
Loss: 0.049 | Acc: 98.391% (25251/25664)
Loss: 0.050 | Acc: 98.338% (31531/32064)
Loss: 0.049 | Acc: 98.362% (37834/38464)
Loss: 0.048 | Acc: 98.382% (44138/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2849, Accuracy: 9180/10000 (91.80%)

Epoch: 139
Loss: 0.119 | Acc: 95.312% (61/64)
Loss: 0.038 | Acc: 98.670% (6378/6464)
Loss: 0.039 | Acc: 98.710% (12698/12864)
Loss: 0.037 | Acc: 98.780% (19029/19264)
Loss: 0.037 | Acc: 98.776% (25350/25664)
Loss: 0.037 | Acc: 98.762% (31667/32064)
Loss: 0.037 | Acc: 98.765% (37989/38464)
Loss: 0.036 | Acc: 98.803% (44327/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2708, Accuracy: 9258/10000 (92.58%)

Epoch: 140
Loss: 0.043 | Acc: 98.438% (63/64)
Loss: 0.027 | Acc: 99.257% (6416/6464)
Loss: 0.025 | Acc: 99.262% (12769/12864)
Loss: 0.025 | Acc: 99.221% (19114/19264)
Loss: 0.027 | Acc: 99.158% (25448/25664)
Loss: 0.028 | Acc: 99.111% (31779/32064)
Loss: 0.028 | Acc: 99.106% (38120/38464)
Loss: 0.028 | Acc: 99.073% (44448/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2205, Accuracy: 9367/10000 (93.67%)

Epoch: 141
Loss: 0.013 | Acc: 100.000% (64/64)
Loss: 0.017 | Acc: 99.567% (6436/6464)
Loss: 0.020 | Acc: 99.433% (12791/12864)
Loss: 0.019 | Acc: 99.450% (19158/19264)
Loss: 0.021 | Acc: 99.408% (25512/25664)
Loss: 0.020 | Acc: 99.414% (31876/32064)
Loss: 0.021 | Acc: 99.379% (38225/38464)
Loss: 0.022 | Acc: 99.363% (44578/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2045, Accuracy: 9436/10000 (94.36%)

Epoch: 142
Loss: 0.051 | Acc: 98.438% (63/64)
Loss: 0.018 | Acc: 99.459% (6429/6464)
Loss: 0.018 | Acc: 99.448% (12793/12864)
Loss: 0.018 | Acc: 99.445% (19157/19264)
Loss: 0.018 | Acc: 99.435% (25519/25664)
Loss: 0.018 | Acc: 99.460% (31891/32064)
Loss: 0.017 | Acc: 99.462% (38257/38464)
Loss: 0.017 | Acc: 99.492% (44636/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1894, Accuracy: 9478/10000 (94.78%)

Epoch: 143
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.014 | Acc: 99.660% (6442/6464)
Loss: 0.013 | Acc: 99.705% (12826/12864)
Loss: 0.012 | Acc: 99.699% (19206/19264)
Loss: 0.012 | Acc: 99.712% (25590/25664)
Loss: 0.012 | Acc: 99.710% (31971/32064)
Loss: 0.012 | Acc: 99.706% (38351/38464)
Loss: 0.012 | Acc: 99.699% (44729/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1894, Accuracy: 9471/10000 (94.71%)

Epoch: 144
Loss: 0.012 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.830% (6453/6464)
Loss: 0.010 | Acc: 99.790% (12837/12864)
Loss: 0.010 | Acc: 99.787% (19223/19264)
Loss: 0.010 | Acc: 99.778% (25607/25664)
Loss: 0.010 | Acc: 99.772% (31991/32064)
Loss: 0.010 | Acc: 99.756% (38370/38464)
Loss: 0.010 | Acc: 99.766% (44759/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1851, Accuracy: 9492/10000 (94.92%)

Epoch: 145
Loss: 0.009 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.861% (6455/6464)
Loss: 0.009 | Acc: 99.798% (12838/12864)
Loss: 0.010 | Acc: 99.798% (19225/19264)
Loss: 0.010 | Acc: 99.774% (25606/25664)
Loss: 0.010 | Acc: 99.779% (31993/32064)
Loss: 0.011 | Acc: 99.779% (38379/38464)
Loss: 0.011 | Acc: 99.755% (44754/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1815, Accuracy: 9462/10000 (94.62%)

Epoch: 146
Loss: 0.008 | Acc: 100.000% (64/64)
Loss: 0.014 | Acc: 99.706% (6445/6464)
Loss: 0.014 | Acc: 99.751% (12832/12864)
Loss: 0.014 | Acc: 99.751% (19216/19264)
Loss: 0.014 | Acc: 99.723% (25593/25664)
Loss: 0.014 | Acc: 99.726% (31976/32064)
Loss: 0.015 | Acc: 99.722% (38357/38464)
Loss: 0.015 | Acc: 99.724% (44740/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1786, Accuracy: 9468/10000 (94.68%)

Epoch: 147
Loss: 0.010 | Acc: 100.000% (64/64)
Loss: 0.017 | Acc: 99.722% (6446/6464)
Loss: 0.017 | Acc: 99.697% (12825/12864)
Loss: 0.017 | Acc: 99.699% (19206/19264)
Loss: 0.017 | Acc: 99.712% (25590/25664)
Loss: 0.017 | Acc: 99.719% (31974/32064)
Loss: 0.017 | Acc: 99.717% (38355/38464)
Loss: 0.017 | Acc: 99.710% (44734/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1733, Accuracy: 9466/10000 (94.66%)
torch.Size([100, 10])
Test set: Average loss: 0.1733, Accuracy: 9466/10000 (94.66%)

Epoch: 148
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.017 | Acc: 99.706% (6445/6464)
Loss: 0.016 | Acc: 99.743% (12831/12864)
Loss: 0.016 | Acc: 99.756% (19217/19264)
Loss: 0.016 | Acc: 99.743% (25598/25664)
Loss: 0.017 | Acc: 99.719% (31974/32064)
Loss: 0.017 | Acc: 99.722% (38357/38464)
Loss: 0.017 | Acc: 99.721% (44739/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1750, Accuracy: 9458/10000 (94.58%)
torch.Size([100, 10])
Test set: Average loss: 0.1750, Accuracy: 9458/10000 (94.58%)

Epoch: 149
Loss: 0.008 | Acc: 100.000% (64/64)
Loss: 0.017 | Acc: 99.675% (6443/6464)
Loss: 0.017 | Acc: 99.666% (12821/12864)
Loss: 0.018 | Acc: 99.673% (19201/19264)
Loss: 0.018 | Acc: 99.688% (25584/25664)
Loss: 0.017 | Acc: 99.701% (31968/32064)
Loss: 0.017 | Acc: 99.709% (38352/38464)
Loss: 0.018 | Acc: 99.688% (44724/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1757, Accuracy: 9459/10000 (94.59%)
torch.Size([100, 10])
Test set: Average loss: 0.1757, Accuracy: 9459/10000 (94.59%)

Epoch: 150
Loss: 0.010 | Acc: 100.000% (64/64)
Loss: 1.968 | Acc: 28.403% (1836/6464)
Loss: 1.667 | Acc: 39.342% (5061/12864)
Loss: 1.384 | Acc: 50.130% (9657/19264)
Loss: 1.193 | Acc: 57.349% (14718/25664)
Loss: 1.068 | Acc: 62.032% (19890/32064)
Loss: 0.975 | Acc: 65.526% (25204/38464)
Loss: 0.907 | Acc: 68.081% (30544/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5341, Accuracy: 4516/10000 (45.16%)

Epoch: 151
Loss: 0.715 | Acc: 75.000% (48/64)
Loss: 0.441 | Acc: 84.886% (5487/6464)
Loss: 0.436 | Acc: 85.082% (10945/12864)
Loss: 0.438 | Acc: 84.946% (16364/19264)
Loss: 0.431 | Acc: 85.260% (21881/25664)
Loss: 0.423 | Acc: 85.588% (27443/32064)
Loss: 0.417 | Acc: 85.823% (33011/38464)
Loss: 0.415 | Acc: 85.842% (38512/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1550, Accuracy: 4578/10000 (45.78%)

Epoch: 152
Loss: 0.979 | Acc: 67.188% (43/64)
Loss: 0.367 | Acc: 87.423% (5651/6464)
Loss: 0.365 | Acc: 87.663% (11277/12864)
Loss: 0.373 | Acc: 87.458% (16848/19264)
Loss: 0.374 | Acc: 87.360% (22420/25664)
Loss: 0.376 | Acc: 87.347% (28007/32064)
Loss: 0.376 | Acc: 87.292% (33576/38464)
Loss: 0.374 | Acc: 87.286% (39160/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3415, Accuracy: 6749/10000 (67.49%)

Epoch: 153
Loss: 1.265 | Acc: 68.750% (44/64)
Loss: 0.348 | Acc: 88.351% (5711/6464)
Loss: 0.349 | Acc: 88.130% (11337/12864)
Loss: 0.349 | Acc: 88.081% (16968/19264)
Loss: 0.346 | Acc: 88.268% (22653/25664)
Loss: 0.347 | Acc: 88.202% (28281/32064)
Loss: 0.350 | Acc: 88.153% (33907/38464)
Loss: 0.349 | Acc: 88.211% (39575/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1037, Accuracy: 7043/10000 (70.43%)

Epoch: 154
Loss: 0.419 | Acc: 85.938% (55/64)
Loss: 0.343 | Acc: 88.382% (5713/6464)
Loss: 0.348 | Acc: 88.005% (11321/12864)
Loss: 0.350 | Acc: 88.149% (16981/19264)
Loss: 0.349 | Acc: 88.225% (22642/25664)
Loss: 0.348 | Acc: 88.227% (28289/32064)
Loss: 0.348 | Acc: 88.176% (33916/38464)
Loss: 0.347 | Acc: 88.224% (39581/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1514, Accuracy: 6600/10000 (66.00%)

Epoch: 155
Loss: 0.698 | Acc: 76.562% (49/64)
Loss: 0.341 | Acc: 88.908% (5747/6464)
Loss: 0.339 | Acc: 88.744% (11416/12864)
Loss: 0.336 | Acc: 88.735% (17094/19264)
Loss: 0.337 | Acc: 88.700% (22764/25664)
Loss: 0.338 | Acc: 88.648% (28424/32064)
Loss: 0.339 | Acc: 88.540% (34056/38464)
Loss: 0.340 | Acc: 88.414% (39666/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4238, Accuracy: 6860/10000 (68.60%)

Epoch: 156
Loss: 0.402 | Acc: 84.375% (54/64)
Loss: 0.328 | Acc: 89.124% (5761/6464)
Loss: 0.326 | Acc: 88.985% (11447/12864)
Loss: 0.326 | Acc: 89.021% (17149/19264)
Loss: 0.326 | Acc: 89.024% (22847/25664)
Loss: 0.331 | Acc: 88.838% (28485/32064)
Loss: 0.332 | Acc: 88.740% (34133/38464)
Loss: 0.330 | Acc: 88.828% (39852/44864)
torch.Size([100, 10])
Test set: Average loss: 4.2355, Accuracy: 4469/10000 (44.69%)

Epoch: 157
Loss: 0.599 | Acc: 82.812% (53/64)
Loss: 0.334 | Acc: 88.908% (5747/6464)
Loss: 0.319 | Acc: 89.521% (11516/12864)
Loss: 0.324 | Acc: 89.229% (17189/19264)
Loss: 0.325 | Acc: 89.183% (22888/25664)
Loss: 0.326 | Acc: 89.081% (28563/32064)
Loss: 0.328 | Acc: 89.000% (34233/38464)
Loss: 0.329 | Acc: 88.846% (39860/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1657, Accuracy: 6940/10000 (69.40%)

Epoch: 158
Loss: 0.555 | Acc: 81.250% (52/64)
Loss: 0.320 | Acc: 89.341% (5775/6464)
Loss: 0.320 | Acc: 89.241% (11480/12864)
Loss: 0.319 | Acc: 89.062% (17157/19264)
Loss: 0.317 | Acc: 89.059% (22856/25664)
Loss: 0.322 | Acc: 88.947% (28520/32064)
Loss: 0.325 | Acc: 88.894% (34192/38464)
Loss: 0.325 | Acc: 88.913% (39890/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6370, Accuracy: 6212/10000 (62.12%)

Epoch: 159
Loss: 0.642 | Acc: 78.125% (50/64)
Loss: 0.321 | Acc: 89.016% (5754/6464)
Loss: 0.324 | Acc: 89.078% (11459/12864)
Loss: 0.319 | Acc: 89.213% (17186/19264)
Loss: 0.321 | Acc: 89.195% (22891/25664)
Loss: 0.319 | Acc: 89.265% (28622/32064)
Loss: 0.320 | Acc: 89.213% (34315/38464)
Loss: 0.323 | Acc: 89.123% (39984/44864)
torch.Size([100, 10])
Test set: Average loss: 7.1629, Accuracy: 2382/10000 (23.82%)

Epoch: 160
Loss: 1.080 | Acc: 67.188% (43/64)
Loss: 0.309 | Acc: 89.681% (5797/6464)
Loss: 0.316 | Acc: 89.436% (11505/12864)
Loss: 0.313 | Acc: 89.462% (17234/19264)
Loss: 0.314 | Acc: 89.339% (22928/25664)
Loss: 0.309 | Acc: 89.493% (28695/32064)
Loss: 0.311 | Acc: 89.424% (34396/38464)
Loss: 0.312 | Acc: 89.419% (40117/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8303, Accuracy: 7568/10000 (75.68%)

Epoch: 161
Loss: 0.445 | Acc: 87.500% (56/64)
Loss: 0.301 | Acc: 89.604% (5792/6464)
Loss: 0.303 | Acc: 89.467% (11509/12864)
Loss: 0.304 | Acc: 89.535% (17248/19264)
Loss: 0.306 | Acc: 89.518% (22974/25664)
Loss: 0.310 | Acc: 89.462% (28685/32064)
Loss: 0.310 | Acc: 89.460% (34410/38464)
Loss: 0.311 | Acc: 89.388% (40103/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2328, Accuracy: 6615/10000 (66.15%)

Epoch: 162
Loss: 0.540 | Acc: 82.812% (53/64)
Loss: 0.295 | Acc: 89.944% (5814/6464)
Loss: 0.295 | Acc: 90.019% (11580/12864)
Loss: 0.302 | Acc: 89.789% (17297/19264)
Loss: 0.300 | Acc: 89.842% (23057/25664)
Loss: 0.303 | Acc: 89.817% (28799/32064)
Loss: 0.306 | Acc: 89.650% (34483/38464)
Loss: 0.309 | Acc: 89.553% (40177/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3866, Accuracy: 8707/10000 (87.07%)

Epoch: 163
Loss: 0.320 | Acc: 90.625% (58/64)
Loss: 0.297 | Acc: 90.238% (5833/6464)
Loss: 0.296 | Acc: 90.143% (11596/12864)
Loss: 0.300 | Acc: 89.919% (17322/19264)
Loss: 0.304 | Acc: 89.791% (23044/25664)
Loss: 0.305 | Acc: 89.780% (28787/32064)
Loss: 0.303 | Acc: 89.780% (34533/38464)
Loss: 0.304 | Acc: 89.727% (40255/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6766, Accuracy: 7889/10000 (78.89%)

Epoch: 164
Loss: 0.206 | Acc: 95.312% (61/64)
Loss: 0.276 | Acc: 90.625% (5858/6464)
Loss: 0.277 | Acc: 90.586% (11653/12864)
Loss: 0.288 | Acc: 90.298% (17395/19264)
Loss: 0.292 | Acc: 90.095% (23122/25664)
Loss: 0.296 | Acc: 89.992% (28855/32064)
Loss: 0.295 | Acc: 89.959% (34602/38464)
Loss: 0.298 | Acc: 89.811% (40293/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3989, Accuracy: 6690/10000 (66.90%)

Epoch: 165
Loss: 0.229 | Acc: 92.188% (59/64)
Loss: 0.286 | Acc: 90.207% (5831/6464)
Loss: 0.301 | Acc: 89.863% (11560/12864)
Loss: 0.289 | Acc: 90.246% (17385/19264)
Loss: 0.282 | Acc: 90.489% (23223/25664)
Loss: 0.285 | Acc: 90.394% (28984/32064)
Loss: 0.284 | Acc: 90.396% (34770/38464)
Loss: 0.284 | Acc: 90.436% (40573/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8954, Accuracy: 7320/10000 (73.20%)

Epoch: 166
Loss: 0.748 | Acc: 76.562% (49/64)
Loss: 0.287 | Acc: 90.145% (5827/6464)
Loss: 0.276 | Acc: 90.345% (11622/12864)
Loss: 0.279 | Acc: 90.303% (17396/19264)
Loss: 0.279 | Acc: 90.352% (23188/25664)
Loss: 0.282 | Acc: 90.226% (28930/32064)
Loss: 0.284 | Acc: 90.175% (34685/38464)
Loss: 0.282 | Acc: 90.273% (40500/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4467, Accuracy: 6727/10000 (67.27%)

Epoch: 167
Loss: 0.282 | Acc: 89.062% (57/64)
Loss: 0.283 | Acc: 90.408% (5844/6464)
Loss: 0.270 | Acc: 90.897% (11693/12864)
Loss: 0.267 | Acc: 90.900% (17511/19264)
Loss: 0.269 | Acc: 90.765% (23294/25664)
Loss: 0.274 | Acc: 90.637% (29062/32064)
Loss: 0.277 | Acc: 90.521% (34818/38464)
Loss: 0.276 | Acc: 90.563% (40630/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2917, Accuracy: 7112/10000 (71.12%)

Epoch: 168
Loss: 0.511 | Acc: 84.375% (54/64)
Loss: 0.268 | Acc: 90.702% (5863/6464)
Loss: 0.265 | Acc: 90.874% (11690/12864)
Loss: 0.268 | Acc: 90.807% (17493/19264)
Loss: 0.267 | Acc: 90.843% (23314/25664)
Loss: 0.265 | Acc: 90.921% (29153/32064)
Loss: 0.269 | Acc: 90.804% (34927/38464)
Loss: 0.267 | Acc: 90.861% (40764/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5695, Accuracy: 8285/10000 (82.85%)

Epoch: 169
Loss: 0.619 | Acc: 85.938% (55/64)
Loss: 0.261 | Acc: 91.058% (5886/6464)
Loss: 0.255 | Acc: 91.426% (11761/12864)
Loss: 0.259 | Acc: 91.248% (17578/19264)
Loss: 0.260 | Acc: 91.186% (23402/25664)
Loss: 0.259 | Acc: 91.239% (29255/32064)
Loss: 0.260 | Acc: 91.158% (35063/38464)
Loss: 0.260 | Acc: 91.162% (40899/44864)
torch.Size([100, 10])
Test set: Average loss: 8.8097, Accuracy: 1866/10000 (18.66%)

Epoch: 170
Loss: 0.670 | Acc: 82.812% (53/64)
Loss: 0.271 | Acc: 90.996% (5882/6464)
Loss: 0.257 | Acc: 91.441% (11763/12864)
Loss: 0.255 | Acc: 91.440% (17615/19264)
Loss: 0.252 | Acc: 91.498% (23482/25664)
Loss: 0.257 | Acc: 91.236% (29254/32064)
Loss: 0.256 | Acc: 91.291% (35114/38464)
Loss: 0.258 | Acc: 91.254% (40940/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5751, Accuracy: 8248/10000 (82.48%)

Epoch: 171
Loss: 0.577 | Acc: 79.688% (51/64)
Loss: 0.230 | Acc: 92.188% (5959/6464)
Loss: 0.226 | Acc: 92.257% (11868/12864)
Loss: 0.235 | Acc: 92.011% (17725/19264)
Loss: 0.236 | Acc: 91.950% (23598/25664)
Loss: 0.239 | Acc: 91.888% (29463/32064)
Loss: 0.239 | Acc: 91.889% (35344/38464)
Loss: 0.241 | Acc: 91.800% (41185/44864)
torch.Size([100, 10])
Test set: Average loss: 8.1188, Accuracy: 2727/10000 (27.27%)

Epoch: 172
Loss: 0.490 | Acc: 87.500% (56/64)
Loss: 0.252 | Acc: 91.522% (5916/6464)
Loss: 0.237 | Acc: 91.947% (11828/12864)
Loss: 0.234 | Acc: 92.213% (17764/19264)
Loss: 0.237 | Acc: 92.098% (23636/25664)
Loss: 0.233 | Acc: 92.184% (29558/32064)
Loss: 0.235 | Acc: 92.146% (35443/38464)
Loss: 0.234 | Acc: 92.150% (41342/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4419, Accuracy: 6450/10000 (64.50%)

Epoch: 173
Loss: 0.339 | Acc: 92.188% (59/64)
Loss: 0.235 | Acc: 91.662% (5925/6464)
Loss: 0.225 | Acc: 92.289% (11872/12864)
Loss: 0.222 | Acc: 92.426% (17805/19264)
Loss: 0.221 | Acc: 92.413% (23717/25664)
Loss: 0.222 | Acc: 92.393% (29625/32064)
Loss: 0.224 | Acc: 92.320% (35510/38464)
Loss: 0.225 | Acc: 92.259% (41391/44864)
torch.Size([100, 10])
Test set: Average loss: 2.7512, Accuracy: 4321/10000 (43.21%)

Epoch: 174
Loss: 0.462 | Acc: 81.250% (52/64)
Loss: 0.223 | Acc: 92.466% (5977/6464)
Loss: 0.223 | Acc: 92.382% (11884/12864)
Loss: 0.219 | Acc: 92.499% (17819/19264)
Loss: 0.221 | Acc: 92.402% (23714/25664)
Loss: 0.220 | Acc: 92.403% (29628/32064)
Loss: 0.218 | Acc: 92.497% (35578/38464)
Loss: 0.218 | Acc: 92.477% (41489/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4478, Accuracy: 6615/10000 (66.15%)

Epoch: 175
Loss: 0.156 | Acc: 93.750% (60/64)
Loss: 0.203 | Acc: 93.023% (6013/6464)
Loss: 0.199 | Acc: 93.089% (11975/12864)
Loss: 0.199 | Acc: 93.158% (17946/19264)
Loss: 0.205 | Acc: 93.064% (23884/25664)
Loss: 0.203 | Acc: 93.045% (29834/32064)
Loss: 0.205 | Acc: 92.967% (35759/38464)
Loss: 0.205 | Acc: 92.994% (41721/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6341, Accuracy: 7995/10000 (79.95%)

Epoch: 176
Loss: 0.173 | Acc: 96.875% (62/64)
Loss: 0.187 | Acc: 93.502% (6044/6464)
Loss: 0.192 | Acc: 93.385% (12013/12864)
Loss: 0.193 | Acc: 93.459% (18004/19264)
Loss: 0.194 | Acc: 93.485% (23992/25664)
Loss: 0.193 | Acc: 93.500% (29980/32064)
Loss: 0.189 | Acc: 93.633% (36015/38464)
Loss: 0.190 | Acc: 93.574% (41981/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3976, Accuracy: 8744/10000 (87.44%)

Epoch: 177
Loss: 0.229 | Acc: 93.750% (60/64)
Loss: 0.192 | Acc: 93.564% (6048/6464)
Loss: 0.187 | Acc: 93.711% (12055/12864)
Loss: 0.181 | Acc: 93.916% (18092/19264)
Loss: 0.183 | Acc: 93.844% (24084/25664)
Loss: 0.186 | Acc: 93.709% (30047/32064)
Loss: 0.189 | Acc: 93.646% (36020/38464)
Loss: 0.188 | Acc: 93.654% (42017/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7757, Accuracy: 7809/10000 (78.09%)

Epoch: 178
Loss: 0.224 | Acc: 95.312% (61/64)
Loss: 0.159 | Acc: 94.632% (6117/6464)
Loss: 0.152 | Acc: 94.908% (12209/12864)
Loss: 0.163 | Acc: 94.539% (18212/19264)
Loss: 0.171 | Acc: 94.233% (24184/25664)
Loss: 0.171 | Acc: 94.212% (30208/32064)
Loss: 0.171 | Acc: 94.174% (36223/38464)
Loss: 0.171 | Acc: 94.176% (42251/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5236, Accuracy: 8380/10000 (83.80%)

Epoch: 179
Loss: 0.140 | Acc: 96.875% (62/64)
Loss: 0.156 | Acc: 94.817% (6129/6464)
Loss: 0.153 | Acc: 94.768% (12191/12864)
Loss: 0.157 | Acc: 94.648% (18233/19264)
Loss: 0.158 | Acc: 94.670% (24296/25664)
Loss: 0.158 | Acc: 94.576% (30325/32064)
Loss: 0.158 | Acc: 94.603% (36388/38464)
Loss: 0.161 | Acc: 94.546% (42417/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2947, Accuracy: 9050/10000 (90.50%)

Epoch: 180
Loss: 0.189 | Acc: 95.312% (61/64)
Loss: 0.151 | Acc: 94.941% (6137/6464)
Loss: 0.145 | Acc: 95.087% (12232/12864)
Loss: 0.140 | Acc: 95.136% (18327/19264)
Loss: 0.142 | Acc: 95.114% (24410/25664)
Loss: 0.144 | Acc: 95.060% (30480/32064)
Loss: 0.146 | Acc: 94.969% (36529/38464)
Loss: 0.147 | Acc: 94.940% (42594/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8804, Accuracy: 7767/10000 (77.67%)

Epoch: 181
Loss: 0.291 | Acc: 93.750% (60/64)
Loss: 0.146 | Acc: 95.142% (6150/6464)
Loss: 0.138 | Acc: 95.258% (12254/12864)
Loss: 0.134 | Acc: 95.505% (18398/19264)
Loss: 0.133 | Acc: 95.523% (24515/25664)
Loss: 0.131 | Acc: 95.615% (30658/32064)
Loss: 0.132 | Acc: 95.523% (36742/38464)
Loss: 0.132 | Acc: 95.515% (42852/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3784, Accuracy: 8859/10000 (88.59%)

Epoch: 182
Loss: 0.108 | Acc: 95.312% (61/64)
Loss: 0.115 | Acc: 96.225% (6220/6464)
Loss: 0.116 | Acc: 96.043% (12355/12864)
Loss: 0.121 | Acc: 95.904% (18475/19264)
Loss: 0.120 | Acc: 95.893% (24610/25664)
Loss: 0.122 | Acc: 95.830% (30727/32064)
Loss: 0.122 | Acc: 95.848% (36867/38464)
Loss: 0.122 | Acc: 95.841% (42998/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2344, Accuracy: 9233/10000 (92.33%)

Epoch: 183
Loss: 0.073 | Acc: 96.875% (62/64)
Loss: 0.111 | Acc: 96.581% (6243/6464)
Loss: 0.113 | Acc: 96.362% (12396/12864)
Loss: 0.110 | Acc: 96.444% (18579/19264)
Loss: 0.107 | Acc: 96.485% (24762/25664)
Loss: 0.108 | Acc: 96.432% (30920/32064)
Loss: 0.109 | Acc: 96.397% (37078/38464)
Loss: 0.109 | Acc: 96.382% (43241/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2486, Accuracy: 9223/10000 (92.23%)

Epoch: 184
Loss: 0.152 | Acc: 93.750% (60/64)
Loss: 0.080 | Acc: 97.215% (6284/6464)
Loss: 0.090 | Acc: 96.805% (12453/12864)
Loss: 0.094 | Acc: 96.724% (18633/19264)
Loss: 0.095 | Acc: 96.746% (24829/25664)
Loss: 0.096 | Acc: 96.703% (31007/32064)
Loss: 0.097 | Acc: 96.706% (37197/38464)
Loss: 0.095 | Acc: 96.743% (43403/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2438, Accuracy: 9227/10000 (92.27%)

Epoch: 185
Loss: 0.132 | Acc: 95.312% (61/64)
Loss: 0.087 | Acc: 97.030% (6272/6464)
Loss: 0.082 | Acc: 97.334% (12521/12864)
Loss: 0.082 | Acc: 97.228% (18730/19264)
Loss: 0.084 | Acc: 97.167% (24937/25664)
Loss: 0.086 | Acc: 97.103% (31135/32064)
Loss: 0.084 | Acc: 97.182% (37380/38464)
Loss: 0.084 | Acc: 97.178% (43598/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2509, Accuracy: 9236/10000 (92.36%)

Epoch: 186
Loss: 0.082 | Acc: 98.438% (63/64)
Loss: 0.069 | Acc: 97.571% (6307/6464)
Loss: 0.070 | Acc: 97.613% (12557/12864)
Loss: 0.067 | Acc: 97.757% (18832/19264)
Loss: 0.064 | Acc: 97.908% (25127/25664)
Loss: 0.066 | Acc: 97.792% (31356/32064)
Loss: 0.066 | Acc: 97.767% (37605/38464)
Loss: 0.068 | Acc: 97.702% (43833/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2456, Accuracy: 9286/10000 (92.86%)

Epoch: 187
Loss: 0.041 | Acc: 98.438% (63/64)
Loss: 0.057 | Acc: 98.190% (6347/6464)
Loss: 0.053 | Acc: 98.259% (12640/12864)
Loss: 0.053 | Acc: 98.271% (18931/19264)
Loss: 0.053 | Acc: 98.254% (25216/25664)
Loss: 0.054 | Acc: 98.200% (31487/32064)
Loss: 0.054 | Acc: 98.183% (37765/38464)
Loss: 0.055 | Acc: 98.154% (44036/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2504, Accuracy: 9291/10000 (92.91%)

Epoch: 188
Loss: 0.024 | Acc: 98.438% (63/64)
Loss: 0.049 | Acc: 98.577% (6372/6464)
Loss: 0.047 | Acc: 98.585% (12682/12864)
Loss: 0.045 | Acc: 98.609% (18996/19264)
Loss: 0.045 | Acc: 98.601% (25305/25664)
Loss: 0.045 | Acc: 98.600% (31615/32064)
Loss: 0.045 | Acc: 98.575% (37916/38464)
Loss: 0.045 | Acc: 98.573% (44224/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2182, Accuracy: 9369/10000 (93.69%)

Epoch: 189
Loss: 0.022 | Acc: 100.000% (64/64)
Loss: 0.037 | Acc: 98.933% (6395/6464)
Loss: 0.036 | Acc: 98.935% (12727/12864)
Loss: 0.036 | Acc: 98.957% (19063/19264)
Loss: 0.034 | Acc: 98.995% (25406/25664)
Loss: 0.034 | Acc: 99.002% (31744/32064)
Loss: 0.034 | Acc: 98.947% (38059/38464)
Loss: 0.034 | Acc: 98.923% (44381/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2048, Accuracy: 9410/10000 (94.10%)

Epoch: 190
Loss: 0.032 | Acc: 98.438% (63/64)
Loss: 0.026 | Acc: 99.211% (6413/6464)
Loss: 0.028 | Acc: 99.160% (12756/12864)
Loss: 0.028 | Acc: 99.180% (19106/19264)
Loss: 0.028 | Acc: 99.174% (25452/25664)
Loss: 0.028 | Acc: 99.158% (31794/32064)
Loss: 0.028 | Acc: 99.171% (38145/38464)
Loss: 0.027 | Acc: 99.178% (44495/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2142, Accuracy: 9414/10000 (94.14%)

Epoch: 191
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 0.022 | Acc: 99.443% (6428/6464)
Loss: 0.021 | Acc: 99.471% (12796/12864)
Loss: 0.020 | Acc: 99.471% (19162/19264)
Loss: 0.020 | Acc: 99.454% (25524/25664)
Loss: 0.021 | Acc: 99.445% (31886/32064)
Loss: 0.021 | Acc: 99.420% (38241/38464)
Loss: 0.021 | Acc: 99.400% (44595/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1969, Accuracy: 9449/10000 (94.49%)

Epoch: 192
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.015 | Acc: 99.644% (6441/6464)
Loss: 0.015 | Acc: 99.588% (12811/12864)
Loss: 0.014 | Acc: 99.621% (19191/19264)
Loss: 0.014 | Acc: 99.606% (25563/25664)
Loss: 0.014 | Acc: 99.598% (31935/32064)
Loss: 0.014 | Acc: 99.605% (38312/38464)
Loss: 0.015 | Acc: 99.581% (44676/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1894, Accuracy: 9467/10000 (94.67%)

Epoch: 193
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.012 | Acc: 99.691% (6444/6464)
Loss: 0.013 | Acc: 99.674% (12822/12864)
Loss: 0.013 | Acc: 99.631% (19193/19264)
Loss: 0.013 | Acc: 99.653% (25575/25664)
Loss: 0.013 | Acc: 99.657% (31954/32064)
Loss: 0.012 | Acc: 99.675% (38339/38464)
Loss: 0.012 | Acc: 99.668% (44715/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1905, Accuracy: 9465/10000 (94.65%)

Epoch: 194
Loss: 0.017 | Acc: 98.438% (63/64)
Loss: 0.008 | Acc: 99.830% (6453/6464)
Loss: 0.008 | Acc: 99.837% (12843/12864)
Loss: 0.008 | Acc: 99.824% (19230/19264)
Loss: 0.008 | Acc: 99.821% (25618/25664)
Loss: 0.008 | Acc: 99.825% (32008/32064)
Loss: 0.008 | Acc: 99.834% (38400/38464)
Loss: 0.008 | Acc: 99.822% (44784/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1886, Accuracy: 9485/10000 (94.85%)

Epoch: 195
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.907% (6458/6464)
Loss: 0.007 | Acc: 99.883% (12849/12864)
Loss: 0.008 | Acc: 99.865% (19238/19264)
Loss: 0.008 | Acc: 99.840% (25623/25664)
Loss: 0.009 | Acc: 99.816% (32005/32064)
Loss: 0.009 | Acc: 99.813% (38392/38464)
Loss: 0.010 | Acc: 99.808% (44778/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1793, Accuracy: 9484/10000 (94.84%)

Epoch: 196
Loss: 0.024 | Acc: 98.438% (63/64)
Loss: 0.012 | Acc: 99.814% (6452/6464)
Loss: 0.013 | Acc: 99.782% (12836/12864)
Loss: 0.013 | Acc: 99.756% (19217/19264)
Loss: 0.013 | Acc: 99.770% (25605/25664)
Loss: 0.013 | Acc: 99.785% (31995/32064)
Loss: 0.013 | Acc: 99.789% (38383/38464)
Loss: 0.014 | Acc: 99.782% (44766/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1782, Accuracy: 9466/10000 (94.66%)

Epoch: 197
Loss: 0.009 | Acc: 100.000% (64/64)
Loss: 0.016 | Acc: 99.706% (6445/6464)
Loss: 0.015 | Acc: 99.743% (12831/12864)
Loss: 0.015 | Acc: 99.740% (19214/19264)
Loss: 0.016 | Acc: 99.723% (25593/25664)
Loss: 0.016 | Acc: 99.716% (31973/32064)
Loss: 0.016 | Acc: 99.724% (38358/38464)
Loss: 0.016 | Acc: 99.728% (44742/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1783, Accuracy: 9477/10000 (94.77%)
torch.Size([100, 10])
Test set: Average loss: 0.1783, Accuracy: 9477/10000 (94.77%)

Epoch: 198
Loss: 0.013 | Acc: 100.000% (64/64)
Loss: 0.015 | Acc: 99.783% (6450/6464)
Loss: 0.016 | Acc: 99.720% (12828/12864)
Loss: 0.016 | Acc: 99.735% (19213/19264)
Loss: 0.016 | Acc: 99.747% (25599/25664)
Loss: 0.016 | Acc: 99.744% (31982/32064)
Loss: 0.017 | Acc: 99.730% (38360/38464)
Loss: 0.017 | Acc: 99.721% (44739/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1781, Accuracy: 9471/10000 (94.71%)
torch.Size([100, 10])
Test set: Average loss: 0.1781, Accuracy: 9471/10000 (94.71%)

Epoch: 199
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 0.015 | Acc: 99.691% (6444/6464)
Loss: 0.015 | Acc: 99.705% (12826/12864)
Loss: 0.016 | Acc: 99.730% (19212/19264)
Loss: 0.016 | Acc: 99.723% (25593/25664)
Loss: 0.017 | Acc: 99.707% (31970/32064)
Loss: 0.016 | Acc: 99.706% (38351/38464)
Loss: 0.016 | Acc: 99.701% (44730/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1795, Accuracy: 9478/10000 (94.78%)
torch.Size([100, 10])
Test set: Average loss: 0.1795, Accuracy: 9478/10000 (94.78%)
9578
10000
-0.13743451237678528
