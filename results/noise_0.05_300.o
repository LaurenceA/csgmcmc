==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.355 | Acc: 15.625% (10/64)
Loss: 2.914 | Acc: 16.197% (1047/6464)
Loss: 2.492 | Acc: 19.372% (2492/12864)
Loss: 2.321 | Acc: 21.553% (4152/19264)
Loss: 2.218 | Acc: 23.523% (6037/25664)
Loss: 2.145 | Acc: 25.156% (8066/32064)
Loss: 2.087 | Acc: 26.659% (10254/38464)
Loss: 2.037 | Acc: 28.076% (12596/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5539, Accuracy: 2774/10000 (27.74%)

Epoch: 1
Loss: 2.112 | Acc: 29.688% (19/64)
Loss: 1.671 | Acc: 39.650% (2563/6464)
Loss: 1.655 | Acc: 40.260% (5179/12864)
Loss: 1.638 | Acc: 40.547% (7811/19264)
Loss: 1.625 | Acc: 41.233% (10582/25664)
Loss: 1.609 | Acc: 41.972% (13458/32064)
Loss: 1.594 | Acc: 42.674% (16414/38464)
Loss: 1.581 | Acc: 43.389% (19466/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5905, Accuracy: 4471/10000 (44.71%)

Epoch: 2
Loss: 1.443 | Acc: 53.125% (34/64)
Loss: 1.437 | Acc: 49.629% (3208/6464)
Loss: 1.439 | Acc: 49.518% (6370/12864)
Loss: 1.423 | Acc: 50.358% (9701/19264)
Loss: 1.405 | Acc: 51.153% (13128/25664)
Loss: 1.391 | Acc: 51.931% (16651/32064)
Loss: 1.383 | Acc: 52.387% (20150/38464)
Loss: 1.375 | Acc: 52.706% (23646/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4197, Accuracy: 5205/10000 (52.05%)

Epoch: 3
Loss: 1.073 | Acc: 64.062% (41/64)
Loss: 1.284 | Acc: 56.807% (3672/6464)
Loss: 1.279 | Acc: 56.911% (7321/12864)
Loss: 1.259 | Acc: 57.558% (11088/19264)
Loss: 1.243 | Acc: 58.132% (14919/25664)
Loss: 1.232 | Acc: 58.555% (18775/32064)
Loss: 1.223 | Acc: 58.936% (22669/38464)
Loss: 1.215 | Acc: 59.317% (26612/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4863, Accuracy: 3405/10000 (34.05%)

Epoch: 4
Loss: 1.506 | Acc: 43.750% (28/64)
Loss: 1.138 | Acc: 62.871% (4064/6464)
Loss: 1.130 | Acc: 63.176% (8127/12864)
Loss: 1.122 | Acc: 63.434% (12220/19264)
Loss: 1.114 | Acc: 63.720% (16353/25664)
Loss: 1.105 | Acc: 64.066% (20542/32064)
Loss: 1.095 | Acc: 64.439% (24786/38464)
Loss: 1.089 | Acc: 64.707% (29030/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6602, Accuracy: 4732/10000 (47.32%)

Epoch: 5
Loss: 1.542 | Acc: 45.312% (29/64)
Loss: 0.992 | Acc: 68.209% (4409/6464)
Loss: 0.999 | Acc: 68.439% (8804/12864)
Loss: 0.994 | Acc: 68.843% (13262/19264)
Loss: 0.992 | Acc: 68.921% (17688/25664)
Loss: 0.983 | Acc: 69.162% (22176/32064)
Loss: 0.979 | Acc: 69.371% (26683/38464)
Loss: 0.974 | Acc: 69.512% (31186/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6105, Accuracy: 4989/10000 (49.89%)

Epoch: 6
Loss: 1.042 | Acc: 65.625% (42/64)
Loss: 0.914 | Acc: 71.519% (4623/6464)
Loss: 0.910 | Acc: 71.937% (9254/12864)
Loss: 0.906 | Acc: 72.067% (13883/19264)
Loss: 0.902 | Acc: 72.311% (18558/25664)
Loss: 0.895 | Acc: 72.521% (23253/32064)
Loss: 0.895 | Acc: 72.611% (27929/38464)
Loss: 0.892 | Acc: 72.731% (32630/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5747, Accuracy: 5307/10000 (53.07%)

Epoch: 7
Loss: 1.087 | Acc: 71.875% (46/64)
Loss: 0.842 | Acc: 74.814% (4836/6464)
Loss: 0.849 | Acc: 74.433% (9575/12864)
Loss: 0.851 | Acc: 74.663% (14383/19264)
Loss: 0.850 | Acc: 74.758% (19186/25664)
Loss: 0.844 | Acc: 74.866% (24005/32064)
Loss: 0.844 | Acc: 74.774% (28761/38464)
Loss: 0.839 | Acc: 74.895% (33601/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2874, Accuracy: 6278/10000 (62.78%)

Epoch: 8
Loss: 1.091 | Acc: 68.750% (44/64)
Loss: 0.818 | Acc: 75.696% (4893/6464)
Loss: 0.805 | Acc: 75.808% (9752/12864)
Loss: 0.798 | Acc: 76.189% (14677/19264)
Loss: 0.799 | Acc: 76.200% (19556/25664)
Loss: 0.798 | Acc: 76.173% (24424/32064)
Loss: 0.803 | Acc: 75.949% (29213/38464)
Loss: 0.798 | Acc: 76.132% (34156/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9388, Accuracy: 7166/10000 (71.66%)

Epoch: 9
Loss: 0.879 | Acc: 76.562% (49/64)
Loss: 0.772 | Acc: 77.413% (5004/6464)
Loss: 0.774 | Acc: 77.635% (9987/12864)
Loss: 0.780 | Acc: 77.268% (14885/19264)
Loss: 0.776 | Acc: 77.272% (19831/25664)
Loss: 0.778 | Acc: 77.270% (24776/32064)
Loss: 0.776 | Acc: 77.246% (29712/38464)
Loss: 0.770 | Acc: 77.381% (34716/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2374, Accuracy: 6268/10000 (62.68%)

Epoch: 10
Loss: 0.820 | Acc: 73.438% (47/64)
Loss: 0.760 | Acc: 77.908% (5036/6464)
Loss: 0.739 | Acc: 78.444% (10091/12864)
Loss: 0.747 | Acc: 78.016% (15029/19264)
Loss: 0.744 | Acc: 78.031% (20026/25664)
Loss: 0.746 | Acc: 78.078% (25035/32064)
Loss: 0.747 | Acc: 78.099% (30040/38464)
Loss: 0.748 | Acc: 78.094% (35036/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7964, Accuracy: 7691/10000 (76.91%)

Epoch: 11
Loss: 0.967 | Acc: 73.438% (47/64)
Loss: 0.720 | Acc: 78.899% (5100/6464)
Loss: 0.730 | Acc: 78.848% (10143/12864)
Loss: 0.724 | Acc: 79.127% (15243/19264)
Loss: 0.727 | Acc: 79.029% (20282/25664)
Loss: 0.726 | Acc: 78.955% (25316/32064)
Loss: 0.727 | Acc: 78.957% (30370/38464)
Loss: 0.730 | Acc: 78.950% (35420/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1710, Accuracy: 6551/10000 (65.51%)

Epoch: 12
Loss: 0.744 | Acc: 82.812% (53/64)
Loss: 0.699 | Acc: 80.322% (5192/6464)
Loss: 0.705 | Acc: 80.037% (10296/12864)
Loss: 0.703 | Acc: 79.843% (15381/19264)
Loss: 0.704 | Acc: 79.839% (20490/25664)
Loss: 0.707 | Acc: 79.856% (25605/32064)
Loss: 0.707 | Acc: 79.903% (30734/38464)
Loss: 0.710 | Acc: 79.801% (35802/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6346, Accuracy: 4930/10000 (49.30%)

Epoch: 13
Loss: 0.939 | Acc: 67.188% (43/64)
Loss: 0.696 | Acc: 80.136% (5180/6464)
Loss: 0.693 | Acc: 80.255% (10324/12864)
Loss: 0.693 | Acc: 80.248% (15459/19264)
Loss: 0.696 | Acc: 80.214% (20586/25664)
Loss: 0.690 | Acc: 80.427% (25788/32064)
Loss: 0.692 | Acc: 80.324% (30896/38464)
Loss: 0.692 | Acc: 80.332% (36040/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6092, Accuracy: 5254/10000 (52.54%)

Epoch: 14
Loss: 0.761 | Acc: 71.875% (46/64)
Loss: 0.712 | Acc: 79.502% (5139/6464)
Loss: 0.700 | Acc: 79.975% (10288/12864)
Loss: 0.686 | Acc: 80.290% (15467/19264)
Loss: 0.682 | Acc: 80.463% (20650/25664)
Loss: 0.678 | Acc: 80.673% (25867/32064)
Loss: 0.675 | Acc: 80.769% (31067/38464)
Loss: 0.677 | Acc: 80.766% (36235/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2246, Accuracy: 6226/10000 (62.26%)

Epoch: 15
Loss: 0.899 | Acc: 70.312% (45/64)
Loss: 0.665 | Acc: 81.451% (5265/6464)
Loss: 0.658 | Acc: 81.514% (10486/12864)
Loss: 0.668 | Acc: 81.437% (15688/19264)
Loss: 0.662 | Acc: 81.620% (20947/25664)
Loss: 0.662 | Acc: 81.612% (26168/32064)
Loss: 0.662 | Acc: 81.604% (31388/38464)
Loss: 0.660 | Acc: 81.582% (36601/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0309, Accuracy: 6971/10000 (69.71%)

Epoch: 16
Loss: 0.839 | Acc: 79.688% (51/64)
Loss: 0.622 | Acc: 82.565% (5337/6464)
Loss: 0.622 | Acc: 82.572% (10622/12864)
Loss: 0.633 | Acc: 82.309% (15856/19264)
Loss: 0.639 | Acc: 82.088% (21067/25664)
Loss: 0.637 | Acc: 82.217% (26362/32064)
Loss: 0.640 | Acc: 82.072% (31568/38464)
Loss: 0.642 | Acc: 81.983% (36781/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1661, Accuracy: 6605/10000 (66.05%)

Epoch: 17
Loss: 0.639 | Acc: 82.812% (53/64)
Loss: 0.593 | Acc: 83.571% (5402/6464)
Loss: 0.632 | Acc: 82.377% (10597/12864)
Loss: 0.636 | Acc: 82.273% (15849/19264)
Loss: 0.632 | Acc: 82.431% (21155/25664)
Loss: 0.631 | Acc: 82.582% (26479/32064)
Loss: 0.634 | Acc: 82.402% (31695/38464)
Loss: 0.633 | Acc: 82.438% (36985/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8627, Accuracy: 7540/10000 (75.40%)

Epoch: 18
Loss: 0.704 | Acc: 79.688% (51/64)
Loss: 0.601 | Acc: 83.957% (5427/6464)
Loss: 0.605 | Acc: 83.598% (10754/12864)
Loss: 0.609 | Acc: 83.384% (16063/19264)
Loss: 0.615 | Acc: 83.175% (21346/25664)
Loss: 0.619 | Acc: 83.009% (26616/32064)
Loss: 0.620 | Acc: 82.963% (31911/38464)
Loss: 0.620 | Acc: 82.899% (37192/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9044, Accuracy: 7434/10000 (74.34%)

Epoch: 19
Loss: 0.605 | Acc: 84.375% (54/64)
Loss: 0.604 | Acc: 83.416% (5392/6464)
Loss: 0.596 | Acc: 83.574% (10751/12864)
Loss: 0.587 | Acc: 83.913% (16165/19264)
Loss: 0.588 | Acc: 83.884% (21528/25664)
Loss: 0.597 | Acc: 83.620% (26812/32064)
Loss: 0.602 | Acc: 83.501% (32118/38464)
Loss: 0.603 | Acc: 83.434% (37432/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3614, Accuracy: 6265/10000 (62.65%)

Epoch: 20
Loss: 0.551 | Acc: 85.938% (55/64)
Loss: 0.580 | Acc: 84.205% (5443/6464)
Loss: 0.588 | Acc: 84.010% (10807/12864)
Loss: 0.587 | Acc: 84.157% (16212/19264)
Loss: 0.587 | Acc: 84.149% (21596/25664)
Loss: 0.583 | Acc: 84.247% (27013/32064)
Loss: 0.585 | Acc: 84.237% (32401/38464)
Loss: 0.587 | Acc: 84.252% (37799/44864)
torch.Size([100, 10])
Test set: Average loss: 2.8634, Accuracy: 3704/10000 (37.04%)

Epoch: 21
Loss: 0.836 | Acc: 71.875% (46/64)
Loss: 0.596 | Acc: 83.663% (5408/6464)
Loss: 0.587 | Acc: 83.808% (10781/12864)
Loss: 0.582 | Acc: 83.960% (16174/19264)
Loss: 0.582 | Acc: 83.993% (21556/25664)
Loss: 0.580 | Acc: 84.147% (26981/32064)
Loss: 0.579 | Acc: 84.276% (32416/38464)
Loss: 0.577 | Acc: 84.355% (37845/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0677, Accuracy: 7023/10000 (70.23%)

Epoch: 22
Loss: 0.692 | Acc: 81.250% (52/64)
Loss: 0.550 | Acc: 85.149% (5504/6464)
Loss: 0.566 | Acc: 84.779% (10906/12864)
Loss: 0.558 | Acc: 84.951% (16365/19264)
Loss: 0.565 | Acc: 84.730% (21745/25664)
Loss: 0.562 | Acc: 84.812% (27194/32064)
Loss: 0.564 | Acc: 84.781% (32610/38464)
Loss: 0.561 | Acc: 84.912% (38095/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1484, Accuracy: 6755/10000 (67.55%)

Epoch: 23
Loss: 0.565 | Acc: 82.812% (53/64)
Loss: 0.517 | Acc: 86.510% (5592/6464)
Loss: 0.538 | Acc: 85.642% (11017/12864)
Loss: 0.543 | Acc: 85.605% (16491/19264)
Loss: 0.546 | Acc: 85.419% (21922/25664)
Loss: 0.550 | Acc: 85.292% (27348/32064)
Loss: 0.548 | Acc: 85.410% (32852/38464)
Loss: 0.548 | Acc: 85.380% (38305/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3078, Accuracy: 6227/10000 (62.27%)

Epoch: 24
Loss: 0.778 | Acc: 79.688% (51/64)
Loss: 0.524 | Acc: 85.783% (5545/6464)
Loss: 0.535 | Acc: 85.665% (11020/12864)
Loss: 0.540 | Acc: 85.548% (16480/19264)
Loss: 0.545 | Acc: 85.540% (21953/25664)
Loss: 0.542 | Acc: 85.563% (27435/32064)
Loss: 0.541 | Acc: 85.649% (32944/38464)
Loss: 0.542 | Acc: 85.670% (38435/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0273, Accuracy: 7070/10000 (70.70%)

Epoch: 25
Loss: 0.760 | Acc: 75.000% (48/64)
Loss: 0.518 | Acc: 86.556% (5595/6464)
Loss: 0.525 | Acc: 86.388% (11113/12864)
Loss: 0.525 | Acc: 86.342% (16633/19264)
Loss: 0.523 | Acc: 86.374% (22167/25664)
Loss: 0.522 | Acc: 86.421% (27710/32064)
Loss: 0.524 | Acc: 86.327% (33205/38464)
Loss: 0.526 | Acc: 86.292% (38714/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7984, Accuracy: 5333/10000 (53.33%)

Epoch: 26
Loss: 0.475 | Acc: 87.500% (56/64)
Loss: 0.515 | Acc: 86.309% (5579/6464)
Loss: 0.514 | Acc: 86.466% (11123/12864)
Loss: 0.505 | Acc: 86.732% (16708/19264)
Loss: 0.513 | Acc: 86.588% (22222/25664)
Loss: 0.514 | Acc: 86.583% (27762/32064)
Loss: 0.512 | Acc: 86.694% (33346/38464)
Loss: 0.511 | Acc: 86.698% (38896/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6629, Accuracy: 8227/10000 (82.27%)

Epoch: 27
Loss: 0.672 | Acc: 79.688% (51/64)
Loss: 0.500 | Acc: 87.515% (5657/6464)
Loss: 0.491 | Acc: 87.562% (11264/12864)
Loss: 0.496 | Acc: 87.318% (16821/19264)
Loss: 0.495 | Acc: 87.200% (22379/25664)
Loss: 0.494 | Acc: 87.263% (27980/32064)
Loss: 0.498 | Acc: 87.196% (33539/38464)
Loss: 0.499 | Acc: 87.208% (39125/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4314, Accuracy: 6070/10000 (60.70%)

Epoch: 28
Loss: 0.740 | Acc: 71.875% (46/64)
Loss: 0.485 | Acc: 87.438% (5652/6464)
Loss: 0.491 | Acc: 87.407% (11244/12864)
Loss: 0.484 | Acc: 87.474% (16851/19264)
Loss: 0.488 | Acc: 87.371% (22423/25664)
Loss: 0.487 | Acc: 87.512% (28060/32064)
Loss: 0.490 | Acc: 87.469% (33644/38464)
Loss: 0.487 | Acc: 87.551% (39279/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9140, Accuracy: 7489/10000 (74.89%)

Epoch: 29
Loss: 0.353 | Acc: 92.188% (59/64)
Loss: 0.465 | Acc: 88.289% (5707/6464)
Loss: 0.464 | Acc: 88.549% (11391/12864)
Loss: 0.457 | Acc: 88.689% (17085/19264)
Loss: 0.461 | Acc: 88.572% (22731/25664)
Loss: 0.461 | Acc: 88.545% (28391/32064)
Loss: 0.464 | Acc: 88.454% (34023/38464)
Loss: 0.466 | Acc: 88.338% (39632/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6952, Accuracy: 8100/10000 (81.00%)

Epoch: 30
Loss: 0.551 | Acc: 85.938% (55/64)
Loss: 0.446 | Acc: 88.769% (5738/6464)
Loss: 0.444 | Acc: 88.954% (11443/12864)
Loss: 0.446 | Acc: 88.870% (17120/19264)
Loss: 0.448 | Acc: 88.801% (22790/25664)
Loss: 0.455 | Acc: 88.651% (28425/32064)
Loss: 0.457 | Acc: 88.608% (34082/38464)
Loss: 0.456 | Acc: 88.666% (39779/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6081, Accuracy: 8424/10000 (84.24%)

Epoch: 31
Loss: 0.412 | Acc: 90.625% (58/64)
Loss: 0.427 | Acc: 89.511% (5786/6464)
Loss: 0.431 | Acc: 89.412% (11502/12864)
Loss: 0.432 | Acc: 89.322% (17207/19264)
Loss: 0.433 | Acc: 89.242% (22903/25664)
Loss: 0.435 | Acc: 89.187% (28597/32064)
Loss: 0.433 | Acc: 89.239% (34325/38464)
Loss: 0.436 | Acc: 89.123% (39984/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6253, Accuracy: 8364/10000 (83.64%)

Epoch: 32
Loss: 0.625 | Acc: 84.375% (54/64)
Loss: 0.399 | Acc: 90.408% (5844/6464)
Loss: 0.412 | Acc: 89.902% (11565/12864)
Loss: 0.411 | Acc: 89.955% (17329/19264)
Loss: 0.412 | Acc: 89.904% (23073/25664)
Loss: 0.413 | Acc: 89.842% (28807/32064)
Loss: 0.416 | Acc: 89.796% (34539/38464)
Loss: 0.415 | Acc: 89.874% (40321/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6002, Accuracy: 8456/10000 (84.56%)

Epoch: 33
Loss: 0.335 | Acc: 95.312% (61/64)
Loss: 0.377 | Acc: 90.470% (5848/6464)
Loss: 0.398 | Acc: 90.096% (11590/12864)
Loss: 0.405 | Acc: 89.945% (17327/19264)
Loss: 0.403 | Acc: 90.122% (23129/25664)
Loss: 0.396 | Acc: 90.322% (28961/32064)
Loss: 0.400 | Acc: 90.217% (34701/38464)
Loss: 0.399 | Acc: 90.251% (40490/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7631, Accuracy: 7953/10000 (79.53%)

Epoch: 34
Loss: 0.526 | Acc: 85.938% (55/64)
Loss: 0.390 | Acc: 90.347% (5840/6464)
Loss: 0.383 | Acc: 90.563% (11650/12864)
Loss: 0.375 | Acc: 90.822% (17496/19264)
Loss: 0.378 | Acc: 90.683% (23273/25664)
Loss: 0.381 | Acc: 90.644% (29064/32064)
Loss: 0.382 | Acc: 90.617% (34855/38464)
Loss: 0.385 | Acc: 90.516% (40609/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5471, Accuracy: 8668/10000 (86.68%)

Epoch: 35
Loss: 0.223 | Acc: 95.312% (61/64)
Loss: 0.338 | Acc: 91.692% (5927/6464)
Loss: 0.352 | Acc: 91.558% (11778/12864)
Loss: 0.352 | Acc: 91.637% (17653/19264)
Loss: 0.353 | Acc: 91.611% (23511/25664)
Loss: 0.352 | Acc: 91.660% (29390/32064)
Loss: 0.356 | Acc: 91.551% (35214/38464)
Loss: 0.360 | Acc: 91.476% (41040/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5799, Accuracy: 8566/10000 (85.66%)

Epoch: 36
Loss: 0.362 | Acc: 92.188% (59/64)
Loss: 0.340 | Acc: 92.033% (5949/6464)
Loss: 0.337 | Acc: 92.164% (11856/12864)
Loss: 0.337 | Acc: 92.130% (17748/19264)
Loss: 0.339 | Acc: 91.958% (23600/25664)
Loss: 0.341 | Acc: 91.897% (29466/32064)
Loss: 0.341 | Acc: 91.938% (35363/38464)
Loss: 0.341 | Acc: 91.938% (41247/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6342, Accuracy: 8363/10000 (83.63%)

Epoch: 37
Loss: 0.256 | Acc: 93.750% (60/64)
Loss: 0.311 | Acc: 93.193% (6024/6464)
Loss: 0.305 | Acc: 93.276% (11999/12864)
Loss: 0.307 | Acc: 92.956% (17907/19264)
Loss: 0.304 | Acc: 92.951% (23855/25664)
Loss: 0.313 | Acc: 92.746% (29738/32064)
Loss: 0.317 | Acc: 92.700% (35656/38464)
Loss: 0.321 | Acc: 92.566% (41529/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6213, Accuracy: 8492/10000 (84.92%)

Epoch: 38
Loss: 0.505 | Acc: 87.500% (56/64)
Loss: 0.292 | Acc: 93.054% (6015/6464)
Loss: 0.294 | Acc: 93.229% (11993/12864)
Loss: 0.296 | Acc: 93.132% (17941/19264)
Loss: 0.297 | Acc: 93.076% (23887/25664)
Loss: 0.299 | Acc: 93.020% (29826/32064)
Loss: 0.301 | Acc: 92.962% (35757/38464)
Loss: 0.301 | Acc: 92.990% (41719/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6222, Accuracy: 8521/10000 (85.21%)

Epoch: 39
Loss: 0.095 | Acc: 96.875% (62/64)
Loss: 0.258 | Acc: 94.152% (6086/6464)
Loss: 0.261 | Acc: 94.131% (12109/12864)
Loss: 0.264 | Acc: 93.947% (18098/19264)
Loss: 0.268 | Acc: 93.863% (24089/25664)
Loss: 0.270 | Acc: 93.815% (30081/32064)
Loss: 0.270 | Acc: 93.789% (36075/38464)
Loss: 0.273 | Acc: 93.679% (42028/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6217, Accuracy: 8520/10000 (85.20%)

Epoch: 40
Loss: 0.146 | Acc: 96.875% (62/64)
Loss: 0.253 | Acc: 93.951% (6073/6464)
Loss: 0.247 | Acc: 94.131% (12109/12864)
Loss: 0.251 | Acc: 94.139% (18135/19264)
Loss: 0.255 | Acc: 94.101% (24150/25664)
Loss: 0.251 | Acc: 94.149% (30188/32064)
Loss: 0.252 | Acc: 94.080% (36187/38464)
Loss: 0.254 | Acc: 94.024% (42183/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6447, Accuracy: 8525/10000 (85.25%)

Epoch: 41
Loss: 0.296 | Acc: 93.750% (60/64)
Loss: 0.232 | Acc: 94.678% (6120/6464)
Loss: 0.230 | Acc: 94.675% (12179/12864)
Loss: 0.226 | Acc: 94.767% (18256/19264)
Loss: 0.228 | Acc: 94.748% (24316/25664)
Loss: 0.225 | Acc: 94.773% (30388/32064)
Loss: 0.226 | Acc: 94.772% (36453/38464)
Loss: 0.225 | Acc: 94.757% (42512/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6164, Accuracy: 8597/10000 (85.97%)

Epoch: 42
Loss: 0.166 | Acc: 95.312% (61/64)
Loss: 0.193 | Acc: 95.653% (6183/6464)
Loss: 0.197 | Acc: 95.375% (12269/12864)
Loss: 0.202 | Acc: 95.255% (18350/19264)
Loss: 0.202 | Acc: 95.203% (24433/25664)
Loss: 0.200 | Acc: 95.284% (30552/32064)
Loss: 0.203 | Acc: 95.258% (36640/38464)
Loss: 0.202 | Acc: 95.288% (42750/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5925, Accuracy: 8739/10000 (87.39%)

Epoch: 43
Loss: 0.144 | Acc: 96.875% (62/64)
Loss: 0.166 | Acc: 96.040% (6208/6464)
Loss: 0.177 | Acc: 95.857% (12331/12864)
Loss: 0.177 | Acc: 95.795% (18454/19264)
Loss: 0.177 | Acc: 95.839% (24596/25664)
Loss: 0.177 | Acc: 95.852% (30734/32064)
Loss: 0.179 | Acc: 95.788% (36844/38464)
Loss: 0.177 | Acc: 95.830% (42993/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6054, Accuracy: 8741/10000 (87.41%)

Epoch: 44
Loss: 0.133 | Acc: 96.875% (62/64)
Loss: 0.156 | Acc: 96.148% (6215/6464)
Loss: 0.165 | Acc: 95.911% (12338/12864)
Loss: 0.159 | Acc: 96.122% (18517/19264)
Loss: 0.160 | Acc: 96.154% (24677/25664)
Loss: 0.163 | Acc: 96.058% (30800/32064)
Loss: 0.162 | Acc: 96.082% (36957/38464)
Loss: 0.161 | Acc: 96.122% (43124/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5914, Accuracy: 8782/10000 (87.82%)

Epoch: 45
Loss: 0.113 | Acc: 98.438% (63/64)
Loss: 0.129 | Acc: 96.906% (6264/6464)
Loss: 0.136 | Acc: 96.681% (12437/12864)
Loss: 0.135 | Acc: 96.688% (18626/19264)
Loss: 0.137 | Acc: 96.579% (24786/25664)
Loss: 0.136 | Acc: 96.638% (30986/32064)
Loss: 0.136 | Acc: 96.641% (37172/38464)
Loss: 0.136 | Acc: 96.683% (43376/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6056, Accuracy: 8766/10000 (87.66%)

Epoch: 46
Loss: 0.122 | Acc: 95.312% (61/64)
Loss: 0.129 | Acc: 96.767% (6255/6464)
Loss: 0.129 | Acc: 96.867% (12461/12864)
Loss: 0.126 | Acc: 96.911% (18669/19264)
Loss: 0.126 | Acc: 96.875% (24862/25664)
Loss: 0.126 | Acc: 96.909% (31073/32064)
Loss: 0.125 | Acc: 96.935% (37285/38464)
Loss: 0.124 | Acc: 96.951% (43496/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6091, Accuracy: 8772/10000 (87.72%)

Epoch: 47
Loss: 0.025 | Acc: 100.000% (64/64)
Loss: 0.120 | Acc: 96.999% (6270/6464)
Loss: 0.117 | Acc: 97.085% (12489/12864)
Loss: 0.117 | Acc: 97.114% (18708/19264)
Loss: 0.115 | Acc: 97.175% (24939/25664)
Loss: 0.117 | Acc: 97.109% (31137/32064)
Loss: 0.117 | Acc: 97.135% (37362/38464)
Loss: 0.116 | Acc: 97.167% (43593/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6088, Accuracy: 8774/10000 (87.74%)
torch.Size([100, 10])
Test set: Average loss: 0.6088, Accuracy: 8774/10000 (87.74%)

Epoch: 48
Loss: 0.033 | Acc: 100.000% (64/64)
Loss: 0.111 | Acc: 97.184% (6282/6464)
Loss: 0.110 | Acc: 97.256% (12511/12864)
Loss: 0.112 | Acc: 97.212% (18727/19264)
Loss: 0.111 | Acc: 97.249% (24958/25664)
Loss: 0.112 | Acc: 97.234% (31177/32064)
Loss: 0.112 | Acc: 97.203% (37388/38464)
Loss: 0.111 | Acc: 97.232% (43622/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6093, Accuracy: 8790/10000 (87.90%)
torch.Size([100, 10])
Test set: Average loss: 0.6093, Accuracy: 8790/10000 (87.90%)

Epoch: 49
Loss: 0.142 | Acc: 95.312% (61/64)
Loss: 0.111 | Acc: 97.231% (6285/6464)
Loss: 0.114 | Acc: 97.116% (12493/12864)
Loss: 0.112 | Acc: 97.212% (18727/19264)
Loss: 0.110 | Acc: 97.269% (24963/25664)
Loss: 0.109 | Acc: 97.330% (31208/32064)
Loss: 0.111 | Acc: 97.299% (37425/38464)
Loss: 0.111 | Acc: 97.261% (43635/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6069, Accuracy: 8796/10000 (87.96%)
torch.Size([100, 10])
Test set: Average loss: 0.6069, Accuracy: 8796/10000 (87.96%)

Epoch: 50
Loss: 0.045 | Acc: 98.438% (63/64)
Loss: 1.640 | Acc: 42.683% (2759/6464)
Loss: 1.306 | Acc: 56.087% (7215/12864)
Loss: 1.145 | Acc: 62.531% (12046/19264)
Loss: 1.062 | Acc: 65.964% (16929/25664)
Loss: 1.002 | Acc: 68.407% (21934/32064)
Loss: 0.961 | Acc: 69.993% (26922/38464)
Loss: 0.928 | Acc: 71.271% (31975/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2235, Accuracy: 6295/10000 (62.95%)

Epoch: 51
Loss: 0.677 | Acc: 79.688% (51/64)
Loss: 0.681 | Acc: 80.507% (5204/6464)
Loss: 0.681 | Acc: 80.706% (10382/12864)
Loss: 0.689 | Acc: 80.492% (15506/19264)
Loss: 0.692 | Acc: 80.451% (20647/25664)
Loss: 0.685 | Acc: 80.754% (25893/32064)
Loss: 0.679 | Acc: 80.948% (31136/38464)
Loss: 0.678 | Acc: 80.985% (36333/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9974, Accuracy: 7181/10000 (71.81%)

Epoch: 52
Loss: 0.847 | Acc: 76.562% (49/64)
Loss: 0.648 | Acc: 81.915% (5295/6464)
Loss: 0.641 | Acc: 82.012% (10550/12864)
Loss: 0.637 | Acc: 82.122% (15820/19264)
Loss: 0.641 | Acc: 81.959% (21034/25664)
Loss: 0.640 | Acc: 82.092% (26322/32064)
Loss: 0.639 | Acc: 82.181% (31610/38464)
Loss: 0.640 | Acc: 82.231% (36892/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1892, Accuracy: 6592/10000 (65.92%)

Epoch: 53
Loss: 0.823 | Acc: 78.125% (50/64)
Loss: 0.605 | Acc: 83.524% (5399/6464)
Loss: 0.609 | Acc: 83.489% (10740/12864)
Loss: 0.619 | Acc: 83.176% (16023/19264)
Loss: 0.624 | Acc: 82.906% (21277/25664)
Loss: 0.627 | Acc: 82.725% (26525/32064)
Loss: 0.628 | Acc: 82.677% (31801/38464)
Loss: 0.627 | Acc: 82.739% (37120/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3353, Accuracy: 4595/10000 (45.95%)

Epoch: 54
Loss: 0.930 | Acc: 70.312% (45/64)
Loss: 0.615 | Acc: 82.828% (5354/6464)
Loss: 0.611 | Acc: 82.937% (10669/12864)
Loss: 0.604 | Acc: 83.243% (16036/19264)
Loss: 0.613 | Acc: 83.085% (21323/25664)
Loss: 0.617 | Acc: 82.925% (26589/32064)
Loss: 0.621 | Acc: 82.776% (31839/38464)
Loss: 0.623 | Acc: 82.757% (37128/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9974, Accuracy: 7136/10000 (71.36%)

Epoch: 55
Loss: 0.619 | Acc: 85.938% (55/64)
Loss: 0.613 | Acc: 83.060% (5369/6464)
Loss: 0.614 | Acc: 83.209% (10704/12864)
Loss: 0.611 | Acc: 83.306% (16048/19264)
Loss: 0.617 | Acc: 83.190% (21350/25664)
Loss: 0.613 | Acc: 83.271% (26700/32064)
Loss: 0.615 | Acc: 83.150% (31983/38464)
Loss: 0.617 | Acc: 83.080% (37273/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0849, Accuracy: 6762/10000 (67.62%)

Epoch: 56
Loss: 0.442 | Acc: 89.062% (57/64)
Loss: 0.601 | Acc: 84.050% (5433/6464)
Loss: 0.610 | Acc: 83.652% (10761/12864)
Loss: 0.604 | Acc: 83.861% (16155/19264)
Loss: 0.599 | Acc: 83.814% (21510/25664)
Loss: 0.604 | Acc: 83.689% (26834/32064)
Loss: 0.606 | Acc: 83.572% (32145/38464)
Loss: 0.609 | Acc: 83.443% (37436/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9196, Accuracy: 7210/10000 (72.10%)

Epoch: 57
Loss: 0.836 | Acc: 71.875% (46/64)
Loss: 0.609 | Acc: 82.642% (5342/6464)
Loss: 0.604 | Acc: 83.061% (10685/12864)
Loss: 0.602 | Acc: 83.181% (16024/19264)
Loss: 0.604 | Acc: 83.151% (21340/25664)
Loss: 0.601 | Acc: 83.187% (26673/32064)
Loss: 0.605 | Acc: 83.153% (31984/38464)
Loss: 0.605 | Acc: 83.122% (37292/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3112, Accuracy: 6166/10000 (61.66%)

Epoch: 58
Loss: 0.812 | Acc: 71.875% (46/64)
Loss: 0.619 | Acc: 82.812% (5353/6464)
Loss: 0.613 | Acc: 83.349% (10722/12864)
Loss: 0.602 | Acc: 83.752% (16134/19264)
Loss: 0.599 | Acc: 83.806% (21508/25664)
Loss: 0.597 | Acc: 83.904% (26903/32064)
Loss: 0.598 | Acc: 83.876% (32262/38464)
Loss: 0.600 | Acc: 83.896% (37639/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3042, Accuracy: 4937/10000 (49.37%)

Epoch: 59
Loss: 0.448 | Acc: 84.375% (54/64)
Loss: 0.596 | Acc: 83.973% (5428/6464)
Loss: 0.585 | Acc: 84.359% (10852/12864)
Loss: 0.592 | Acc: 84.006% (16183/19264)
Loss: 0.593 | Acc: 83.900% (21532/25664)
Loss: 0.594 | Acc: 83.826% (26878/32064)
Loss: 0.596 | Acc: 83.772% (32222/38464)
Loss: 0.598 | Acc: 83.740% (37569/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8743, Accuracy: 7457/10000 (74.57%)

Epoch: 60
Loss: 0.577 | Acc: 85.938% (55/64)
Loss: 0.577 | Acc: 84.638% (5471/6464)
Loss: 0.578 | Acc: 84.468% (10866/12864)
Loss: 0.590 | Acc: 84.235% (16227/19264)
Loss: 0.592 | Acc: 84.083% (21579/25664)
Loss: 0.589 | Acc: 84.147% (26981/32064)
Loss: 0.590 | Acc: 84.133% (32361/38464)
Loss: 0.589 | Acc: 84.192% (37772/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8608, Accuracy: 7595/10000 (75.95%)

Epoch: 61
Loss: 0.775 | Acc: 79.688% (51/64)
Loss: 0.566 | Acc: 84.499% (5462/6464)
Loss: 0.565 | Acc: 84.686% (10894/12864)
Loss: 0.578 | Acc: 84.240% (16228/19264)
Loss: 0.583 | Acc: 84.211% (21612/25664)
Loss: 0.586 | Acc: 84.091% (26963/32064)
Loss: 0.587 | Acc: 84.097% (32347/38464)
Loss: 0.585 | Acc: 84.170% (37762/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7617, Accuracy: 5296/10000 (52.96%)

Epoch: 62
Loss: 0.683 | Acc: 78.125% (50/64)
Loss: 0.552 | Acc: 85.582% (5532/6464)
Loss: 0.560 | Acc: 85.199% (10960/12864)
Loss: 0.568 | Acc: 84.941% (16363/19264)
Loss: 0.570 | Acc: 84.792% (21761/25664)
Loss: 0.574 | Acc: 84.684% (27153/32064)
Loss: 0.573 | Acc: 84.674% (32569/38464)
Loss: 0.575 | Acc: 84.571% (37942/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7154, Accuracy: 8051/10000 (80.51%)

Epoch: 63
Loss: 0.227 | Acc: 95.312% (61/64)
Loss: 0.545 | Acc: 85.504% (5527/6464)
Loss: 0.557 | Acc: 85.152% (10954/12864)
Loss: 0.562 | Acc: 84.988% (16372/19264)
Loss: 0.559 | Acc: 84.952% (21802/25664)
Loss: 0.560 | Acc: 84.958% (27241/32064)
Loss: 0.566 | Acc: 84.827% (32628/38464)
Loss: 0.567 | Acc: 84.832% (38059/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0297, Accuracy: 7041/10000 (70.41%)

Epoch: 64
Loss: 0.855 | Acc: 76.562% (49/64)
Loss: 0.572 | Acc: 84.406% (5456/6464)
Loss: 0.556 | Acc: 84.904% (10922/12864)
Loss: 0.553 | Acc: 84.889% (16353/19264)
Loss: 0.557 | Acc: 84.772% (21756/25664)
Loss: 0.557 | Acc: 84.896% (27221/32064)
Loss: 0.559 | Acc: 84.978% (32686/38464)
Loss: 0.564 | Acc: 84.778% (38035/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0995, Accuracy: 6925/10000 (69.25%)

Epoch: 65
Loss: 0.416 | Acc: 87.500% (56/64)
Loss: 0.551 | Acc: 85.303% (5514/6464)
Loss: 0.548 | Acc: 85.448% (10992/12864)
Loss: 0.551 | Acc: 85.418% (16455/19264)
Loss: 0.556 | Acc: 85.322% (21897/25664)
Loss: 0.560 | Acc: 85.183% (27313/32064)
Loss: 0.557 | Acc: 85.150% (32752/38464)
Loss: 0.560 | Acc: 85.177% (38214/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8292, Accuracy: 7715/10000 (77.15%)

Epoch: 66
Loss: 0.579 | Acc: 82.812% (53/64)
Loss: 0.520 | Acc: 86.494% (5591/6464)
Loss: 0.541 | Acc: 85.665% (11020/12864)
Loss: 0.545 | Acc: 85.507% (16472/19264)
Loss: 0.552 | Acc: 85.326% (21898/25664)
Loss: 0.548 | Acc: 85.376% (27375/32064)
Loss: 0.549 | Acc: 85.347% (32828/38464)
Loss: 0.548 | Acc: 85.358% (38295/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3276, Accuracy: 6075/10000 (60.75%)

Epoch: 67
Loss: 0.753 | Acc: 81.250% (52/64)
Loss: 0.554 | Acc: 85.164% (5505/6464)
Loss: 0.540 | Acc: 85.790% (11036/12864)
Loss: 0.537 | Acc: 85.995% (16566/19264)
Loss: 0.538 | Acc: 85.973% (22064/25664)
Loss: 0.540 | Acc: 85.844% (27525/32064)
Loss: 0.543 | Acc: 85.719% (32971/38464)
Loss: 0.547 | Acc: 85.579% (38394/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4462, Accuracy: 6151/10000 (61.51%)

Epoch: 68
Loss: 0.552 | Acc: 81.250% (52/64)
Loss: 0.551 | Acc: 85.102% (5501/6464)
Loss: 0.544 | Acc: 85.595% (11011/12864)
Loss: 0.545 | Acc: 85.559% (16482/19264)
Loss: 0.542 | Acc: 85.661% (21984/25664)
Loss: 0.543 | Acc: 85.685% (27474/32064)
Loss: 0.544 | Acc: 85.672% (32953/38464)
Loss: 0.540 | Acc: 85.732% (38463/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7077, Accuracy: 8069/10000 (80.69%)

Epoch: 69
Loss: 0.765 | Acc: 78.125% (50/64)
Loss: 0.509 | Acc: 86.510% (5592/6464)
Loss: 0.518 | Acc: 86.318% (11104/12864)
Loss: 0.527 | Acc: 86.109% (16588/19264)
Loss: 0.528 | Acc: 86.074% (22090/25664)
Loss: 0.531 | Acc: 86.000% (27575/32064)
Loss: 0.528 | Acc: 86.122% (33126/38464)
Loss: 0.529 | Acc: 86.109% (38632/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1953, Accuracy: 6820/10000 (68.20%)

Epoch: 70
Loss: 0.702 | Acc: 84.375% (54/64)
Loss: 0.518 | Acc: 86.433% (5587/6464)
Loss: 0.508 | Acc: 86.692% (11152/12864)
Loss: 0.509 | Acc: 86.472% (16658/19264)
Loss: 0.510 | Acc: 86.619% (22230/25664)
Loss: 0.515 | Acc: 86.496% (27734/32064)
Loss: 0.517 | Acc: 86.377% (33224/38464)
Loss: 0.523 | Acc: 86.274% (38706/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0294, Accuracy: 6990/10000 (69.90%)

Epoch: 71
Loss: 0.740 | Acc: 81.250% (52/64)
Loss: 0.510 | Acc: 86.897% (5617/6464)
Loss: 0.507 | Acc: 86.676% (11150/12864)
Loss: 0.506 | Acc: 86.737% (16709/19264)
Loss: 0.505 | Acc: 86.927% (22309/25664)
Loss: 0.514 | Acc: 86.717% (27805/32064)
Loss: 0.514 | Acc: 86.694% (33346/38464)
Loss: 0.511 | Acc: 86.740% (38915/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0900, Accuracy: 6930/10000 (69.30%)

Epoch: 72
Loss: 0.606 | Acc: 79.688% (51/64)
Loss: 0.496 | Acc: 87.113% (5631/6464)
Loss: 0.503 | Acc: 87.096% (11204/12864)
Loss: 0.504 | Acc: 86.986% (16757/19264)
Loss: 0.499 | Acc: 86.954% (22316/25664)
Loss: 0.499 | Acc: 87.132% (27938/32064)
Loss: 0.497 | Acc: 87.172% (33530/38464)
Loss: 0.501 | Acc: 87.083% (39069/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8230, Accuracy: 7818/10000 (78.18%)

Epoch: 73
Loss: 0.318 | Acc: 90.625% (58/64)
Loss: 0.471 | Acc: 87.871% (5680/6464)
Loss: 0.488 | Acc: 87.414% (11245/12864)
Loss: 0.492 | Acc: 87.199% (16798/19264)
Loss: 0.492 | Acc: 87.282% (22400/25664)
Loss: 0.492 | Acc: 87.325% (28000/32064)
Loss: 0.489 | Acc: 87.425% (33627/38464)
Loss: 0.493 | Acc: 87.326% (39178/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7884, Accuracy: 7861/10000 (78.61%)

Epoch: 74
Loss: 0.559 | Acc: 85.938% (55/64)
Loss: 0.448 | Acc: 88.598% (5727/6464)
Loss: 0.464 | Acc: 88.176% (11343/12864)
Loss: 0.472 | Acc: 87.946% (16942/19264)
Loss: 0.474 | Acc: 87.882% (22554/25664)
Loss: 0.479 | Acc: 87.762% (28140/32064)
Loss: 0.484 | Acc: 87.640% (33710/38464)
Loss: 0.483 | Acc: 87.689% (39341/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8758, Accuracy: 5829/10000 (58.29%)

Epoch: 75
Loss: 0.693 | Acc: 81.250% (52/64)
Loss: 0.454 | Acc: 88.567% (5725/6464)
Loss: 0.460 | Acc: 88.487% (11383/12864)
Loss: 0.460 | Acc: 88.533% (17055/19264)
Loss: 0.461 | Acc: 88.486% (22709/25664)
Loss: 0.464 | Acc: 88.330% (28322/32064)
Loss: 0.471 | Acc: 88.129% (33898/38464)
Loss: 0.470 | Acc: 88.117% (39533/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6253, Accuracy: 8376/10000 (83.76%)

Epoch: 76
Loss: 0.707 | Acc: 84.375% (54/64)
Loss: 0.452 | Acc: 88.738% (5736/6464)
Loss: 0.453 | Acc: 88.658% (11405/12864)
Loss: 0.460 | Acc: 88.486% (17046/19264)
Loss: 0.463 | Acc: 88.295% (22660/25664)
Loss: 0.462 | Acc: 88.292% (28310/32064)
Loss: 0.463 | Acc: 88.251% (33945/38464)
Loss: 0.459 | Acc: 88.349% (39637/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6720, Accuracy: 8243/10000 (82.43%)

Epoch: 77
Loss: 0.653 | Acc: 87.500% (56/64)
Loss: 0.434 | Acc: 89.619% (5793/6464)
Loss: 0.445 | Acc: 89.226% (11478/12864)
Loss: 0.445 | Acc: 89.047% (17154/19264)
Loss: 0.449 | Acc: 88.918% (22820/25664)
Loss: 0.449 | Acc: 88.863% (28493/32064)
Loss: 0.446 | Acc: 88.901% (34195/38464)
Loss: 0.444 | Acc: 88.953% (39908/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6330, Accuracy: 8376/10000 (83.76%)

Epoch: 78
Loss: 0.504 | Acc: 87.500% (56/64)
Loss: 0.414 | Acc: 90.254% (5834/6464)
Loss: 0.409 | Acc: 90.174% (11600/12864)
Loss: 0.422 | Acc: 89.826% (17304/19264)
Loss: 0.429 | Acc: 89.631% (23003/25664)
Loss: 0.433 | Acc: 89.368% (28655/32064)
Loss: 0.434 | Acc: 89.265% (34335/38464)
Loss: 0.432 | Acc: 89.250% (40041/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6412, Accuracy: 8367/10000 (83.67%)

Epoch: 79
Loss: 0.457 | Acc: 89.062% (57/64)
Loss: 0.401 | Acc: 90.207% (5831/6464)
Loss: 0.396 | Acc: 90.127% (11594/12864)
Loss: 0.401 | Acc: 90.012% (17340/19264)
Loss: 0.407 | Acc: 89.990% (23095/25664)
Loss: 0.410 | Acc: 89.905% (28827/32064)
Loss: 0.411 | Acc: 89.848% (34559/38464)
Loss: 0.412 | Acc: 89.852% (40311/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9615, Accuracy: 7464/10000 (74.64%)

Epoch: 80
Loss: 0.823 | Acc: 73.438% (47/64)
Loss: 0.436 | Acc: 89.264% (5770/6464)
Loss: 0.411 | Acc: 89.894% (11564/12864)
Loss: 0.410 | Acc: 90.049% (17347/19264)
Loss: 0.406 | Acc: 90.196% (23148/25664)
Loss: 0.409 | Acc: 90.029% (28867/32064)
Loss: 0.406 | Acc: 90.113% (34661/38464)
Loss: 0.405 | Acc: 90.157% (40448/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6353, Accuracy: 8358/10000 (83.58%)

Epoch: 81
Loss: 0.281 | Acc: 92.188% (59/64)
Loss: 0.375 | Acc: 90.888% (5875/6464)
Loss: 0.394 | Acc: 90.501% (11642/12864)
Loss: 0.397 | Acc: 90.589% (17451/19264)
Loss: 0.395 | Acc: 90.664% (23268/25664)
Loss: 0.391 | Acc: 90.669% (29072/32064)
Loss: 0.395 | Acc: 90.591% (34845/38464)
Loss: 0.396 | Acc: 90.422% (40567/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6593, Accuracy: 8297/10000 (82.97%)

Epoch: 82
Loss: 0.410 | Acc: 85.938% (55/64)
Loss: 0.384 | Acc: 90.826% (5871/6464)
Loss: 0.369 | Acc: 91.123% (11722/12864)
Loss: 0.359 | Acc: 91.419% (17611/19264)
Loss: 0.365 | Acc: 91.315% (23435/25664)
Loss: 0.368 | Acc: 91.199% (29242/32064)
Loss: 0.369 | Acc: 91.210% (35083/38464)
Loss: 0.371 | Acc: 91.155% (40896/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6722, Accuracy: 8309/10000 (83.09%)

Epoch: 83
Loss: 0.482 | Acc: 89.062% (57/64)
Loss: 0.335 | Acc: 91.940% (5943/6464)
Loss: 0.348 | Acc: 91.628% (11787/12864)
Loss: 0.342 | Acc: 91.746% (17674/19264)
Loss: 0.348 | Acc: 91.630% (23516/25664)
Loss: 0.349 | Acc: 91.629% (29380/32064)
Loss: 0.356 | Acc: 91.454% (35177/38464)
Loss: 0.358 | Acc: 91.416% (41013/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8437, Accuracy: 7813/10000 (78.13%)

Epoch: 84
Loss: 0.234 | Acc: 93.750% (60/64)
Loss: 0.340 | Acc: 92.110% (5954/6464)
Loss: 0.339 | Acc: 92.110% (11849/12864)
Loss: 0.348 | Acc: 91.907% (17705/19264)
Loss: 0.346 | Acc: 91.938% (23595/25664)
Loss: 0.343 | Acc: 91.982% (29493/32064)
Loss: 0.343 | Acc: 91.980% (35379/38464)
Loss: 0.342 | Acc: 91.987% (41269/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5944, Accuracy: 8551/10000 (85.51%)

Epoch: 85
Loss: 0.572 | Acc: 89.062% (57/64)
Loss: 0.317 | Acc: 92.806% (5999/6464)
Loss: 0.307 | Acc: 92.934% (11955/12864)
Loss: 0.312 | Acc: 92.707% (17859/19264)
Loss: 0.313 | Acc: 92.643% (23776/25664)
Loss: 0.313 | Acc: 92.658% (29710/32064)
Loss: 0.316 | Acc: 92.606% (35620/38464)
Loss: 0.319 | Acc: 92.486% (41493/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6034, Accuracy: 8548/10000 (85.48%)

Epoch: 86
Loss: 0.174 | Acc: 95.312% (61/64)
Loss: 0.298 | Acc: 93.069% (6016/6464)
Loss: 0.288 | Acc: 93.276% (11999/12864)
Loss: 0.296 | Acc: 93.106% (17936/19264)
Loss: 0.298 | Acc: 93.103% (23894/25664)
Loss: 0.296 | Acc: 93.151% (29868/32064)
Loss: 0.297 | Acc: 93.087% (35805/38464)
Loss: 0.299 | Acc: 93.030% (41737/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5780, Accuracy: 8626/10000 (86.26%)

Epoch: 87
Loss: 0.319 | Acc: 92.188% (59/64)
Loss: 0.308 | Acc: 92.574% (5984/6464)
Loss: 0.285 | Acc: 93.299% (12002/12864)
Loss: 0.283 | Acc: 93.366% (17986/19264)
Loss: 0.280 | Acc: 93.485% (23992/25664)
Loss: 0.281 | Acc: 93.426% (29956/32064)
Loss: 0.282 | Acc: 93.425% (35935/38464)
Loss: 0.279 | Acc: 93.534% (41963/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5524, Accuracy: 8785/10000 (87.85%)

Epoch: 88
Loss: 0.343 | Acc: 90.625% (58/64)
Loss: 0.242 | Acc: 94.400% (6102/6464)
Loss: 0.244 | Acc: 94.279% (12128/12864)
Loss: 0.244 | Acc: 94.394% (18184/19264)
Loss: 0.248 | Acc: 94.241% (24186/25664)
Loss: 0.248 | Acc: 94.243% (30218/32064)
Loss: 0.249 | Acc: 94.249% (36252/38464)
Loss: 0.253 | Acc: 94.142% (42236/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5980, Accuracy: 8627/10000 (86.27%)

Epoch: 89
Loss: 0.343 | Acc: 90.625% (58/64)
Loss: 0.227 | Acc: 94.694% (6121/6464)
Loss: 0.232 | Acc: 94.597% (12169/12864)
Loss: 0.232 | Acc: 94.664% (18236/19264)
Loss: 0.233 | Acc: 94.596% (24277/25664)
Loss: 0.233 | Acc: 94.580% (30326/32064)
Loss: 0.232 | Acc: 94.637% (36401/38464)
Loss: 0.234 | Acc: 94.604% (42443/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5497, Accuracy: 8789/10000 (87.89%)

Epoch: 90
Loss: 0.084 | Acc: 96.875% (62/64)
Loss: 0.201 | Acc: 95.467% (6171/6464)
Loss: 0.199 | Acc: 95.499% (12285/12864)
Loss: 0.204 | Acc: 95.385% (18375/19264)
Loss: 0.203 | Acc: 95.344% (24469/25664)
Loss: 0.208 | Acc: 95.244% (30539/32064)
Loss: 0.208 | Acc: 95.201% (36618/38464)
Loss: 0.209 | Acc: 95.210% (42715/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5590, Accuracy: 8785/10000 (87.85%)

Epoch: 91
Loss: 0.317 | Acc: 92.188% (59/64)
Loss: 0.189 | Acc: 95.808% (6193/6464)
Loss: 0.189 | Acc: 95.670% (12307/12864)
Loss: 0.184 | Acc: 95.733% (18442/19264)
Loss: 0.182 | Acc: 95.776% (24580/25664)
Loss: 0.186 | Acc: 95.696% (30684/32064)
Loss: 0.189 | Acc: 95.611% (36776/38464)
Loss: 0.189 | Acc: 95.620% (42899/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5719, Accuracy: 8824/10000 (88.24%)

Epoch: 92
Loss: 0.308 | Acc: 92.188% (59/64)
Loss: 0.151 | Acc: 96.194% (6218/6464)
Loss: 0.149 | Acc: 96.440% (12406/12864)
Loss: 0.156 | Acc: 96.247% (18541/19264)
Loss: 0.160 | Acc: 96.189% (24686/25664)
Loss: 0.162 | Acc: 96.136% (30825/32064)
Loss: 0.162 | Acc: 96.113% (36969/38464)
Loss: 0.163 | Acc: 96.073% (43102/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5929, Accuracy: 8795/10000 (87.95%)

Epoch: 93
Loss: 0.187 | Acc: 93.750% (60/64)
Loss: 0.136 | Acc: 96.736% (6253/6464)
Loss: 0.139 | Acc: 96.712% (12441/12864)
Loss: 0.138 | Acc: 96.673% (18623/19264)
Loss: 0.139 | Acc: 96.618% (24796/25664)
Loss: 0.140 | Acc: 96.591% (30971/32064)
Loss: 0.138 | Acc: 96.631% (37168/38464)
Loss: 0.140 | Acc: 96.596% (43337/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5704, Accuracy: 8855/10000 (88.55%)

Epoch: 94
Loss: 0.053 | Acc: 96.875% (62/64)
Loss: 0.130 | Acc: 96.782% (6256/6464)
Loss: 0.128 | Acc: 96.821% (12455/12864)
Loss: 0.127 | Acc: 96.844% (18656/19264)
Loss: 0.127 | Acc: 96.848% (24855/25664)
Loss: 0.125 | Acc: 96.940% (31083/32064)
Loss: 0.124 | Acc: 96.963% (37296/38464)
Loss: 0.123 | Acc: 97.013% (43524/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5864, Accuracy: 8870/10000 (88.70%)

Epoch: 95
Loss: 0.093 | Acc: 96.875% (62/64)
Loss: 0.099 | Acc: 97.200% (6283/6464)
Loss: 0.102 | Acc: 97.341% (12522/12864)
Loss: 0.102 | Acc: 97.456% (18774/19264)
Loss: 0.104 | Acc: 97.382% (24992/25664)
Loss: 0.106 | Acc: 97.305% (31200/32064)
Loss: 0.108 | Acc: 97.265% (37412/38464)
Loss: 0.106 | Acc: 97.290% (43648/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6031, Accuracy: 8846/10000 (88.46%)

Epoch: 96
Loss: 0.113 | Acc: 96.875% (62/64)
Loss: 0.101 | Acc: 97.587% (6308/6464)
Loss: 0.095 | Acc: 97.707% (12569/12864)
Loss: 0.100 | Acc: 97.534% (18789/19264)
Loss: 0.098 | Acc: 97.569% (25040/25664)
Loss: 0.097 | Acc: 97.617% (31300/32064)
Loss: 0.096 | Acc: 97.626% (37551/38464)
Loss: 0.097 | Acc: 97.606% (43790/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5987, Accuracy: 8835/10000 (88.35%)

Epoch: 97
Loss: 0.050 | Acc: 98.438% (63/64)
Loss: 0.093 | Acc: 97.618% (6310/6464)
Loss: 0.090 | Acc: 97.652% (12562/12864)
Loss: 0.088 | Acc: 97.716% (18824/19264)
Loss: 0.086 | Acc: 97.763% (25090/25664)
Loss: 0.087 | Acc: 97.751% (31343/32064)
Loss: 0.088 | Acc: 97.738% (37594/38464)
Loss: 0.088 | Acc: 97.729% (43845/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5964, Accuracy: 8854/10000 (88.54%)
torch.Size([100, 10])
Test set: Average loss: 0.5964, Accuracy: 8854/10000 (88.54%)

Epoch: 98
Loss: 0.029 | Acc: 100.000% (64/64)
Loss: 0.088 | Acc: 97.710% (6316/6464)
Loss: 0.086 | Acc: 97.823% (12584/12864)
Loss: 0.086 | Acc: 97.825% (18845/19264)
Loss: 0.086 | Acc: 97.818% (25104/25664)
Loss: 0.086 | Acc: 97.814% (31363/32064)
Loss: 0.086 | Acc: 97.780% (37610/38464)
Loss: 0.085 | Acc: 97.800% (43877/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5980, Accuracy: 8845/10000 (88.45%)
torch.Size([100, 10])
Test set: Average loss: 0.5980, Accuracy: 8845/10000 (88.45%)

Epoch: 99
Loss: 0.018 | Acc: 100.000% (64/64)
Loss: 0.088 | Acc: 97.695% (6315/6464)
Loss: 0.081 | Acc: 97.948% (12600/12864)
Loss: 0.082 | Acc: 97.887% (18857/19264)
Loss: 0.082 | Acc: 97.892% (25123/25664)
Loss: 0.082 | Acc: 97.879% (31384/32064)
Loss: 0.082 | Acc: 97.902% (37657/38464)
Loss: 0.082 | Acc: 97.871% (43909/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5976, Accuracy: 8847/10000 (88.47%)
torch.Size([100, 10])
Test set: Average loss: 0.5976, Accuracy: 8847/10000 (88.47%)

Epoch: 100
Loss: 0.127 | Acc: 96.875% (62/64)
Loss: 1.444 | Acc: 51.671% (3340/6464)
Loss: 1.164 | Acc: 62.500% (8040/12864)
Loss: 1.035 | Acc: 67.431% (12990/19264)
Loss: 0.966 | Acc: 70.075% (17984/25664)
Loss: 0.915 | Acc: 72.109% (23121/32064)
Loss: 0.878 | Acc: 73.536% (28285/38464)
Loss: 0.850 | Acc: 74.536% (33440/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8550, Accuracy: 5186/10000 (51.86%)

Epoch: 101
Loss: 0.796 | Acc: 75.000% (48/64)
Loss: 0.625 | Acc: 82.611% (5340/6464)
Loss: 0.642 | Acc: 82.167% (10570/12864)
Loss: 0.643 | Acc: 82.034% (15803/19264)
Loss: 0.638 | Acc: 82.177% (21090/25664)
Loss: 0.636 | Acc: 82.304% (26390/32064)
Loss: 0.635 | Acc: 82.352% (31676/38464)
Loss: 0.639 | Acc: 82.293% (36920/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2432, Accuracy: 6465/10000 (64.65%)

Epoch: 102
Loss: 0.568 | Acc: 84.375% (54/64)
Loss: 0.580 | Acc: 84.530% (5464/6464)
Loss: 0.596 | Acc: 83.870% (10789/12864)
Loss: 0.598 | Acc: 83.830% (16149/19264)
Loss: 0.603 | Acc: 83.514% (21433/25664)
Loss: 0.606 | Acc: 83.567% (26795/32064)
Loss: 0.608 | Acc: 83.561% (32141/38464)
Loss: 0.610 | Acc: 83.490% (37457/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9508, Accuracy: 3642/10000 (36.42%)

Epoch: 103
Loss: 0.737 | Acc: 76.562% (49/64)
Loss: 0.612 | Acc: 82.441% (5329/6464)
Loss: 0.598 | Acc: 83.543% (10747/12864)
Loss: 0.598 | Acc: 83.659% (16116/19264)
Loss: 0.599 | Acc: 83.787% (21503/25664)
Loss: 0.599 | Acc: 83.745% (26852/32064)
Loss: 0.599 | Acc: 83.720% (32202/38464)
Loss: 0.598 | Acc: 83.760% (37578/44864)
torch.Size([100, 10])
Test set: Average loss: 3.5550, Accuracy: 3504/10000 (35.04%)

Epoch: 104
Loss: 1.107 | Acc: 70.312% (45/64)
Loss: 0.613 | Acc: 83.292% (5384/6464)
Loss: 0.610 | Acc: 83.598% (10754/12864)
Loss: 0.601 | Acc: 84.058% (16193/19264)
Loss: 0.601 | Acc: 83.896% (21531/25664)
Loss: 0.597 | Acc: 83.941% (26915/32064)
Loss: 0.595 | Acc: 83.954% (32292/38464)
Loss: 0.597 | Acc: 83.853% (37620/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8753, Accuracy: 7579/10000 (75.79%)

Epoch: 105
Loss: 0.740 | Acc: 75.000% (48/64)
Loss: 0.577 | Acc: 84.421% (5457/6464)
Loss: 0.580 | Acc: 84.235% (10836/12864)
Loss: 0.581 | Acc: 84.365% (16252/19264)
Loss: 0.582 | Acc: 84.137% (21593/25664)
Loss: 0.588 | Acc: 84.060% (26953/32064)
Loss: 0.590 | Acc: 84.006% (32312/38464)
Loss: 0.590 | Acc: 84.030% (37699/44864)
torch.Size([100, 10])
Test set: Average loss: 3.8126, Accuracy: 4038/10000 (40.38%)

Epoch: 106
Loss: 0.877 | Acc: 73.438% (47/64)
Loss: 0.592 | Acc: 83.895% (5423/6464)
Loss: 0.578 | Acc: 84.266% (10840/12864)
Loss: 0.574 | Acc: 84.463% (16271/19264)
Loss: 0.578 | Acc: 84.371% (21653/25664)
Loss: 0.585 | Acc: 84.144% (26980/32064)
Loss: 0.586 | Acc: 84.105% (32350/38464)
Loss: 0.588 | Acc: 84.074% (37719/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8570, Accuracy: 7621/10000 (76.21%)

Epoch: 107
Loss: 0.514 | Acc: 85.938% (55/64)
Loss: 0.566 | Acc: 85.071% (5499/6464)
Loss: 0.574 | Acc: 84.461% (10865/12864)
Loss: 0.580 | Acc: 84.313% (16242/19264)
Loss: 0.584 | Acc: 84.293% (21633/25664)
Loss: 0.584 | Acc: 84.144% (26980/32064)
Loss: 0.583 | Acc: 84.146% (32366/38464)
Loss: 0.579 | Acc: 84.317% (37828/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8392, Accuracy: 4598/10000 (45.98%)

Epoch: 108
Loss: 1.053 | Acc: 68.750% (44/64)
Loss: 0.589 | Acc: 83.926% (5425/6464)
Loss: 0.577 | Acc: 84.437% (10862/12864)
Loss: 0.576 | Acc: 84.598% (16297/19264)
Loss: 0.577 | Acc: 84.589% (21709/25664)
Loss: 0.572 | Acc: 84.662% (27146/32064)
Loss: 0.577 | Acc: 84.632% (32553/38464)
Loss: 0.580 | Acc: 84.482% (37902/44864)
torch.Size([100, 10])
Test set: Average loss: 2.7341, Accuracy: 3614/10000 (36.14%)

Epoch: 109
Loss: 0.709 | Acc: 79.688% (51/64)
Loss: 0.582 | Acc: 83.540% (5400/6464)
Loss: 0.584 | Acc: 83.846% (10786/12864)
Loss: 0.579 | Acc: 84.126% (16206/19264)
Loss: 0.571 | Acc: 84.371% (21653/25664)
Loss: 0.574 | Acc: 84.363% (27050/32064)
Loss: 0.577 | Acc: 84.289% (32421/38464)
Loss: 0.578 | Acc: 84.304% (37822/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2323, Accuracy: 6616/10000 (66.16%)

Epoch: 110
Loss: 1.072 | Acc: 67.188% (43/64)
Loss: 0.591 | Acc: 83.942% (5426/6464)
Loss: 0.576 | Acc: 84.220% (10834/12864)
Loss: 0.575 | Acc: 84.297% (16239/19264)
Loss: 0.572 | Acc: 84.387% (21657/25664)
Loss: 0.575 | Acc: 84.462% (27082/32064)
Loss: 0.574 | Acc: 84.505% (32504/38464)
Loss: 0.573 | Acc: 84.556% (37935/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4463, Accuracy: 6022/10000 (60.22%)

Epoch: 111
Loss: 0.860 | Acc: 75.000% (48/64)
Loss: 0.571 | Acc: 85.195% (5507/6464)
Loss: 0.575 | Acc: 84.779% (10906/12864)
Loss: 0.570 | Acc: 84.832% (16342/19264)
Loss: 0.566 | Acc: 84.780% (21758/25664)
Loss: 0.565 | Acc: 84.843% (27204/32064)
Loss: 0.569 | Acc: 84.757% (32601/38464)
Loss: 0.570 | Acc: 84.729% (38013/44864)
torch.Size([100, 10])
Test set: Average loss: 7.3620, Accuracy: 2825/10000 (28.25%)

Epoch: 112
Loss: 1.131 | Acc: 65.625% (42/64)
Loss: 0.567 | Acc: 84.731% (5477/6464)
Loss: 0.554 | Acc: 85.106% (10948/12864)
Loss: 0.562 | Acc: 85.024% (16379/19264)
Loss: 0.557 | Acc: 85.209% (21868/25664)
Loss: 0.558 | Acc: 85.186% (27314/32064)
Loss: 0.562 | Acc: 85.074% (32723/38464)
Loss: 0.562 | Acc: 85.131% (38193/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9739, Accuracy: 7174/10000 (71.74%)

Epoch: 113
Loss: 0.528 | Acc: 84.375% (54/64)
Loss: 0.552 | Acc: 85.288% (5513/6464)
Loss: 0.550 | Acc: 85.432% (10990/12864)
Loss: 0.548 | Acc: 85.408% (16453/19264)
Loss: 0.546 | Acc: 85.454% (21931/25664)
Loss: 0.545 | Acc: 85.482% (27409/32064)
Loss: 0.550 | Acc: 85.277% (32801/38464)
Loss: 0.552 | Acc: 85.289% (38264/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1271, Accuracy: 6731/10000 (67.31%)

Epoch: 114
Loss: 0.781 | Acc: 78.125% (50/64)
Loss: 0.552 | Acc: 85.427% (5522/6464)
Loss: 0.547 | Acc: 85.393% (10985/12864)
Loss: 0.552 | Acc: 85.159% (16405/19264)
Loss: 0.546 | Acc: 85.470% (21935/25664)
Loss: 0.547 | Acc: 85.498% (27414/32064)
Loss: 0.549 | Acc: 85.459% (32871/38464)
Loss: 0.551 | Acc: 85.423% (38324/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5796, Accuracy: 5561/10000 (55.61%)

Epoch: 115
Loss: 0.612 | Acc: 85.938% (55/64)
Loss: 0.519 | Acc: 86.603% (5598/6464)
Loss: 0.518 | Acc: 86.738% (11158/12864)
Loss: 0.531 | Acc: 86.207% (16607/19264)
Loss: 0.533 | Acc: 86.023% (22077/25664)
Loss: 0.537 | Acc: 85.788% (27507/32064)
Loss: 0.540 | Acc: 85.732% (32976/38464)
Loss: 0.542 | Acc: 85.728% (38461/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9295, Accuracy: 7441/10000 (74.41%)

Epoch: 116
Loss: 0.477 | Acc: 84.375% (54/64)
Loss: 0.510 | Acc: 86.773% (5609/6464)
Loss: 0.525 | Acc: 86.233% (11093/12864)
Loss: 0.534 | Acc: 85.808% (16530/19264)
Loss: 0.534 | Acc: 85.879% (22040/25664)
Loss: 0.537 | Acc: 85.928% (27552/32064)
Loss: 0.535 | Acc: 85.951% (33060/38464)
Loss: 0.538 | Acc: 85.826% (38505/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2621, Accuracy: 6732/10000 (67.32%)

Epoch: 117
Loss: 0.566 | Acc: 82.812% (53/64)
Loss: 0.534 | Acc: 85.938% (5555/6464)
Loss: 0.522 | Acc: 86.194% (11088/12864)
Loss: 0.513 | Acc: 86.405% (16645/19264)
Loss: 0.516 | Acc: 86.421% (22179/25664)
Loss: 0.526 | Acc: 86.171% (27630/32064)
Loss: 0.528 | Acc: 86.054% (33100/38464)
Loss: 0.528 | Acc: 86.042% (38602/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7855, Accuracy: 7843/10000 (78.43%)

Epoch: 118
Loss: 0.625 | Acc: 85.938% (55/64)
Loss: 0.507 | Acc: 86.711% (5605/6464)
Loss: 0.514 | Acc: 86.528% (11131/12864)
Loss: 0.512 | Acc: 86.571% (16677/19264)
Loss: 0.516 | Acc: 86.436% (22183/25664)
Loss: 0.519 | Acc: 86.330% (27681/32064)
Loss: 0.521 | Acc: 86.283% (33188/38464)
Loss: 0.523 | Acc: 86.274% (38706/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0721, Accuracy: 6968/10000 (69.68%)

Epoch: 119
Loss: 0.422 | Acc: 90.625% (58/64)
Loss: 0.507 | Acc: 86.757% (5608/6464)
Loss: 0.502 | Acc: 86.870% (11175/12864)
Loss: 0.505 | Acc: 86.680% (16698/19264)
Loss: 0.506 | Acc: 86.767% (22268/25664)
Loss: 0.510 | Acc: 86.758% (27818/32064)
Loss: 0.509 | Acc: 86.816% (33393/38464)
Loss: 0.511 | Acc: 86.704% (38899/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0141, Accuracy: 7078/10000 (70.78%)

Epoch: 120
Loss: 0.542 | Acc: 85.938% (55/64)
Loss: 0.511 | Acc: 86.665% (5602/6464)
Loss: 0.511 | Acc: 86.536% (11132/12864)
Loss: 0.512 | Acc: 86.628% (16688/19264)
Loss: 0.509 | Acc: 86.830% (22284/25664)
Loss: 0.506 | Acc: 86.970% (27886/32064)
Loss: 0.508 | Acc: 86.902% (33426/38464)
Loss: 0.506 | Acc: 86.965% (39016/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9226, Accuracy: 7519/10000 (75.19%)

Epoch: 121
Loss: 0.409 | Acc: 85.938% (55/64)
Loss: 0.468 | Acc: 87.856% (5679/6464)
Loss: 0.477 | Acc: 87.749% (11288/12864)
Loss: 0.490 | Acc: 87.230% (16804/19264)
Loss: 0.496 | Acc: 87.114% (22357/25664)
Loss: 0.492 | Acc: 87.269% (27982/32064)
Loss: 0.495 | Acc: 87.232% (33553/38464)
Loss: 0.495 | Acc: 87.288% (39161/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8772, Accuracy: 7562/10000 (75.62%)

Epoch: 122
Loss: 0.623 | Acc: 81.250% (52/64)
Loss: 0.475 | Acc: 87.546% (5659/6464)
Loss: 0.462 | Acc: 88.075% (11330/12864)
Loss: 0.468 | Acc: 87.895% (16932/19264)
Loss: 0.473 | Acc: 87.858% (22548/25664)
Loss: 0.480 | Acc: 87.709% (28123/32064)
Loss: 0.478 | Acc: 87.755% (33754/38464)
Loss: 0.482 | Acc: 87.607% (39304/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7870, Accuracy: 7823/10000 (78.23%)

Epoch: 123
Loss: 0.448 | Acc: 84.375% (54/64)
Loss: 0.476 | Acc: 87.964% (5686/6464)
Loss: 0.476 | Acc: 87.928% (11311/12864)
Loss: 0.476 | Acc: 87.920% (16937/19264)
Loss: 0.473 | Acc: 88.034% (22593/25664)
Loss: 0.476 | Acc: 87.946% (28199/32064)
Loss: 0.476 | Acc: 87.968% (33836/38464)
Loss: 0.477 | Acc: 87.948% (39457/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7301, Accuracy: 8041/10000 (80.41%)

Epoch: 124
Loss: 0.545 | Acc: 87.500% (56/64)
Loss: 0.456 | Acc: 88.567% (5725/6464)
Loss: 0.452 | Acc: 88.573% (11394/12864)
Loss: 0.454 | Acc: 88.564% (17061/19264)
Loss: 0.458 | Acc: 88.396% (22686/25664)
Loss: 0.464 | Acc: 88.277% (28305/32064)
Loss: 0.464 | Acc: 88.275% (33954/38464)
Loss: 0.468 | Acc: 88.191% (39566/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6938, Accuracy: 8179/10000 (81.79%)

Epoch: 125
Loss: 0.433 | Acc: 85.938% (55/64)
Loss: 0.419 | Acc: 89.341% (5775/6464)
Loss: 0.430 | Acc: 89.140% (11467/12864)
Loss: 0.441 | Acc: 88.948% (17135/19264)
Loss: 0.441 | Acc: 88.973% (22834/25664)
Loss: 0.446 | Acc: 88.847% (28488/32064)
Loss: 0.448 | Acc: 88.782% (34149/38464)
Loss: 0.453 | Acc: 88.710% (39799/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9511, Accuracy: 7210/10000 (72.10%)

Epoch: 126
Loss: 0.458 | Acc: 84.375% (54/64)
Loss: 0.414 | Acc: 89.573% (5790/6464)
Loss: 0.423 | Acc: 89.467% (11509/12864)
Loss: 0.438 | Acc: 89.068% (17158/19264)
Loss: 0.444 | Acc: 88.934% (22824/25664)
Loss: 0.441 | Acc: 88.994% (28535/32064)
Loss: 0.440 | Acc: 89.044% (34250/38464)
Loss: 0.442 | Acc: 88.976% (39918/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7761, Accuracy: 7971/10000 (79.71%)

Epoch: 127
Loss: 0.534 | Acc: 85.938% (55/64)
Loss: 0.416 | Acc: 89.759% (5802/6464)
Loss: 0.434 | Acc: 89.187% (11473/12864)
Loss: 0.439 | Acc: 88.969% (17139/19264)
Loss: 0.438 | Acc: 88.992% (22839/25664)
Loss: 0.438 | Acc: 89.041% (28550/32064)
Loss: 0.436 | Acc: 89.140% (34287/38464)
Loss: 0.434 | Acc: 89.219% (40027/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7393, Accuracy: 8041/10000 (80.41%)

Epoch: 128
Loss: 0.514 | Acc: 85.938% (55/64)
Loss: 0.398 | Acc: 90.269% (5835/6464)
Loss: 0.406 | Acc: 89.995% (11577/12864)
Loss: 0.410 | Acc: 89.784% (17296/19264)
Loss: 0.417 | Acc: 89.589% (22992/25664)
Loss: 0.419 | Acc: 89.583% (28724/32064)
Loss: 0.423 | Acc: 89.536% (34439/38464)
Loss: 0.422 | Acc: 89.551% (40176/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6366, Accuracy: 8387/10000 (83.87%)

Epoch: 129
Loss: 0.428 | Acc: 87.500% (56/64)
Loss: 0.394 | Acc: 90.594% (5856/6464)
Loss: 0.400 | Acc: 90.221% (11606/12864)
Loss: 0.392 | Acc: 90.350% (17405/19264)
Loss: 0.398 | Acc: 90.212% (23152/25664)
Loss: 0.402 | Acc: 90.110% (28893/32064)
Loss: 0.407 | Acc: 90.032% (34630/38464)
Loss: 0.408 | Acc: 90.037% (40394/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6782, Accuracy: 8262/10000 (82.62%)

Epoch: 130
Loss: 0.358 | Acc: 92.188% (59/64)
Loss: 0.395 | Acc: 90.532% (5852/6464)
Loss: 0.399 | Acc: 90.477% (11639/12864)
Loss: 0.391 | Acc: 90.578% (17449/19264)
Loss: 0.394 | Acc: 90.446% (23212/25664)
Loss: 0.392 | Acc: 90.572% (29041/32064)
Loss: 0.391 | Acc: 90.589% (34844/38464)
Loss: 0.394 | Acc: 90.547% (40623/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8085, Accuracy: 7819/10000 (78.19%)

Epoch: 131
Loss: 0.796 | Acc: 78.125% (50/64)
Loss: 0.362 | Acc: 91.166% (5893/6464)
Loss: 0.379 | Acc: 90.648% (11661/12864)
Loss: 0.373 | Acc: 90.807% (17493/19264)
Loss: 0.372 | Acc: 90.945% (23340/25664)
Loss: 0.376 | Acc: 90.862% (29134/32064)
Loss: 0.377 | Acc: 90.841% (34941/38464)
Loss: 0.382 | Acc: 90.712% (40697/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5920, Accuracy: 8526/10000 (85.26%)

Epoch: 132
Loss: 0.374 | Acc: 92.188% (59/64)
Loss: 0.323 | Acc: 92.450% (5976/6464)
Loss: 0.351 | Acc: 91.589% (11782/12864)
Loss: 0.354 | Acc: 91.378% (17603/19264)
Loss: 0.363 | Acc: 91.233% (23414/25664)
Loss: 0.366 | Acc: 91.165% (29231/32064)
Loss: 0.364 | Acc: 91.226% (35089/38464)
Loss: 0.366 | Acc: 91.180% (40907/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5998, Accuracy: 8518/10000 (85.18%)

Epoch: 133
Loss: 0.339 | Acc: 92.188% (59/64)
Loss: 0.306 | Acc: 92.837% (6001/6464)
Loss: 0.329 | Acc: 92.304% (11874/12864)
Loss: 0.334 | Acc: 92.162% (17754/19264)
Loss: 0.338 | Acc: 92.028% (23618/25664)
Loss: 0.340 | Acc: 91.929% (29476/32064)
Loss: 0.342 | Acc: 91.891% (35345/38464)
Loss: 0.346 | Acc: 91.813% (41191/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5765, Accuracy: 8631/10000 (86.31%)

Epoch: 134
Loss: 0.177 | Acc: 96.875% (62/64)
Loss: 0.310 | Acc: 92.976% (6010/6464)
Loss: 0.312 | Acc: 92.786% (11936/12864)
Loss: 0.315 | Acc: 92.774% (17872/19264)
Loss: 0.322 | Acc: 92.589% (23762/25664)
Loss: 0.324 | Acc: 92.518% (29665/32064)
Loss: 0.326 | Acc: 92.486% (35574/38464)
Loss: 0.321 | Acc: 92.589% (41539/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5564, Accuracy: 8684/10000 (86.84%)

Epoch: 135
Loss: 0.235 | Acc: 95.312% (61/64)
Loss: 0.286 | Acc: 93.270% (6029/6464)
Loss: 0.291 | Acc: 93.027% (11967/12864)
Loss: 0.295 | Acc: 93.065% (17928/19264)
Loss: 0.304 | Acc: 92.940% (23852/25664)
Loss: 0.307 | Acc: 92.836% (29767/32064)
Loss: 0.310 | Acc: 92.806% (35697/38464)
Loss: 0.309 | Acc: 92.807% (41637/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6128, Accuracy: 8546/10000 (85.46%)

Epoch: 136
Loss: 0.233 | Acc: 95.312% (61/64)
Loss: 0.292 | Acc: 93.007% (6012/6464)
Loss: 0.289 | Acc: 93.221% (11992/12864)
Loss: 0.279 | Acc: 93.568% (18025/19264)
Loss: 0.282 | Acc: 93.446% (23982/25664)
Loss: 0.288 | Acc: 93.326% (29924/32064)
Loss: 0.289 | Acc: 93.326% (35897/38464)
Loss: 0.289 | Acc: 93.340% (41876/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5660, Accuracy: 8730/10000 (87.30%)

Epoch: 137
Loss: 0.335 | Acc: 92.188% (59/64)
Loss: 0.265 | Acc: 93.967% (6074/6464)
Loss: 0.263 | Acc: 93.975% (12089/12864)
Loss: 0.264 | Acc: 93.901% (18089/19264)
Loss: 0.262 | Acc: 93.914% (24102/25664)
Loss: 0.266 | Acc: 93.806% (30078/32064)
Loss: 0.267 | Acc: 93.823% (36088/38464)
Loss: 0.267 | Acc: 93.824% (42093/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5996, Accuracy: 8597/10000 (85.97%)

Epoch: 138
Loss: 0.246 | Acc: 95.312% (61/64)
Loss: 0.254 | Acc: 94.090% (6082/6464)
Loss: 0.248 | Acc: 94.271% (12127/12864)
Loss: 0.244 | Acc: 94.430% (18191/19264)
Loss: 0.245 | Acc: 94.420% (24232/25664)
Loss: 0.245 | Acc: 94.386% (30264/32064)
Loss: 0.243 | Acc: 94.442% (36326/38464)
Loss: 0.246 | Acc: 94.394% (42349/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5690, Accuracy: 8755/10000 (87.55%)

Epoch: 139
Loss: 0.464 | Acc: 89.062% (57/64)
Loss: 0.227 | Acc: 94.833% (6130/6464)
Loss: 0.221 | Acc: 94.869% (12204/12864)
Loss: 0.219 | Acc: 94.954% (18292/19264)
Loss: 0.223 | Acc: 94.868% (24347/25664)
Loss: 0.224 | Acc: 94.798% (30396/32064)
Loss: 0.225 | Acc: 94.764% (36450/38464)
Loss: 0.224 | Acc: 94.802% (42532/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5942, Accuracy: 8700/10000 (87.00%)

Epoch: 140
Loss: 0.284 | Acc: 93.750% (60/64)
Loss: 0.201 | Acc: 95.328% (6162/6464)
Loss: 0.197 | Acc: 95.577% (12295/12864)
Loss: 0.198 | Acc: 95.510% (18399/19264)
Loss: 0.199 | Acc: 95.515% (24513/25664)
Loss: 0.197 | Acc: 95.503% (30622/32064)
Loss: 0.197 | Acc: 95.526% (36743/38464)
Loss: 0.199 | Acc: 95.462% (42828/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5910, Accuracy: 8752/10000 (87.52%)

Epoch: 141
Loss: 0.182 | Acc: 96.875% (62/64)
Loss: 0.163 | Acc: 96.241% (6221/6464)
Loss: 0.174 | Acc: 95.896% (12336/12864)
Loss: 0.174 | Acc: 95.925% (18479/19264)
Loss: 0.177 | Acc: 95.850% (24599/25664)
Loss: 0.174 | Acc: 95.918% (30755/32064)
Loss: 0.172 | Acc: 95.918% (36894/38464)
Loss: 0.174 | Acc: 95.856% (43005/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5830, Accuracy: 8853/10000 (88.53%)

Epoch: 142
Loss: 0.063 | Acc: 98.438% (63/64)
Loss: 0.146 | Acc: 96.364% (6229/6464)
Loss: 0.147 | Acc: 96.385% (12399/12864)
Loss: 0.150 | Acc: 96.309% (18553/19264)
Loss: 0.150 | Acc: 96.329% (24722/25664)
Loss: 0.148 | Acc: 96.401% (30910/32064)
Loss: 0.150 | Acc: 96.358% (37063/38464)
Loss: 0.152 | Acc: 96.302% (43205/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6125, Accuracy: 8772/10000 (87.72%)

Epoch: 143
Loss: 0.102 | Acc: 96.875% (62/64)
Loss: 0.143 | Acc: 96.566% (6242/6464)
Loss: 0.137 | Acc: 96.650% (12433/12864)
Loss: 0.138 | Acc: 96.652% (18619/19264)
Loss: 0.140 | Acc: 96.579% (24786/25664)
Loss: 0.137 | Acc: 96.647% (30989/32064)
Loss: 0.135 | Acc: 96.716% (37201/38464)
Loss: 0.135 | Acc: 96.679% (43374/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6001, Accuracy: 8844/10000 (88.44%)

Epoch: 144
Loss: 0.065 | Acc: 98.438% (63/64)
Loss: 0.110 | Acc: 97.184% (6282/6464)
Loss: 0.107 | Acc: 97.256% (12511/12864)
Loss: 0.114 | Acc: 97.124% (18710/19264)
Loss: 0.115 | Acc: 97.062% (24910/25664)
Loss: 0.115 | Acc: 97.040% (31115/32064)
Loss: 0.116 | Acc: 97.021% (37318/38464)
Loss: 0.116 | Acc: 97.044% (43538/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6017, Accuracy: 8868/10000 (88.68%)

Epoch: 145
Loss: 0.046 | Acc: 98.438% (63/64)
Loss: 0.103 | Acc: 97.525% (6304/6464)
Loss: 0.099 | Acc: 97.551% (12549/12864)
Loss: 0.097 | Acc: 97.571% (18796/19264)
Loss: 0.098 | Acc: 97.522% (25028/25664)
Loss: 0.099 | Acc: 97.555% (31280/32064)
Loss: 0.100 | Acc: 97.489% (37498/38464)
Loss: 0.100 | Acc: 97.495% (43740/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6095, Accuracy: 8830/10000 (88.30%)

Epoch: 146
Loss: 0.188 | Acc: 92.188% (59/64)
Loss: 0.085 | Acc: 97.803% (6322/6464)
Loss: 0.085 | Acc: 97.847% (12587/12864)
Loss: 0.090 | Acc: 97.726% (18826/19264)
Loss: 0.088 | Acc: 97.806% (25101/25664)
Loss: 0.091 | Acc: 97.739% (31339/32064)
Loss: 0.091 | Acc: 97.697% (37578/38464)
Loss: 0.090 | Acc: 97.715% (43839/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6142, Accuracy: 8869/10000 (88.69%)

Epoch: 147
Loss: 0.132 | Acc: 96.875% (62/64)
Loss: 0.086 | Acc: 97.865% (6326/6464)
Loss: 0.089 | Acc: 97.683% (12566/12864)
Loss: 0.087 | Acc: 97.716% (18824/19264)
Loss: 0.085 | Acc: 97.806% (25101/25664)
Loss: 0.084 | Acc: 97.811% (31362/32064)
Loss: 0.084 | Acc: 97.795% (37616/38464)
Loss: 0.085 | Acc: 97.793% (43874/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6119, Accuracy: 8850/10000 (88.50%)
torch.Size([100, 10])
Test set: Average loss: 0.6119, Accuracy: 8850/10000 (88.50%)

Epoch: 148
Loss: 0.015 | Acc: 100.000% (64/64)
Loss: 0.073 | Acc: 98.051% (6338/6464)
Loss: 0.076 | Acc: 97.948% (12600/12864)
Loss: 0.077 | Acc: 97.944% (18868/19264)
Loss: 0.078 | Acc: 97.923% (25131/25664)
Loss: 0.079 | Acc: 97.889% (31387/32064)
Loss: 0.079 | Acc: 97.918% (37663/38464)
Loss: 0.079 | Acc: 97.932% (43936/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6145, Accuracy: 8862/10000 (88.62%)
torch.Size([100, 10])
Test set: Average loss: 0.6145, Accuracy: 8862/10000 (88.62%)

Epoch: 149
Loss: 0.228 | Acc: 93.750% (60/64)
Loss: 0.083 | Acc: 97.881% (6327/6464)
Loss: 0.079 | Acc: 97.987% (12605/12864)
Loss: 0.080 | Acc: 97.955% (18870/19264)
Loss: 0.079 | Acc: 97.982% (25146/25664)
Loss: 0.079 | Acc: 97.960% (31410/32064)
Loss: 0.079 | Acc: 97.907% (37659/38464)
Loss: 0.079 | Acc: 97.927% (43934/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6138, Accuracy: 8854/10000 (88.54%)
torch.Size([100, 10])
Test set: Average loss: 0.6138, Accuracy: 8854/10000 (88.54%)

Epoch: 150
Loss: 0.044 | Acc: 98.438% (63/64)
Loss: 1.776 | Acc: 37.454% (2421/6464)
Loss: 1.376 | Acc: 53.568% (6891/12864)
Loss: 1.209 | Acc: 60.444% (11644/19264)
Loss: 1.095 | Acc: 64.818% (16635/25664)
Loss: 1.018 | Acc: 67.821% (21746/32064)
Loss: 0.965 | Acc: 69.767% (26835/38464)
Loss: 0.927 | Acc: 71.233% (31958/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3130, Accuracy: 5993/10000 (59.93%)

Epoch: 151
Loss: 0.528 | Acc: 85.938% (55/64)
Loss: 0.635 | Acc: 81.683% (5280/6464)
Loss: 0.642 | Acc: 81.569% (10493/12864)
Loss: 0.651 | Acc: 81.489% (15698/19264)
Loss: 0.647 | Acc: 81.640% (20952/25664)
Loss: 0.644 | Acc: 81.846% (26243/32064)
Loss: 0.643 | Acc: 81.905% (31504/38464)
Loss: 0.640 | Acc: 82.048% (36810/44864)
torch.Size([100, 10])
Test set: Average loss: 2.6431, Accuracy: 3588/10000 (35.88%)

Epoch: 152
Loss: 1.061 | Acc: 67.188% (43/64)
Loss: 0.608 | Acc: 83.230% (5380/6464)
Loss: 0.591 | Acc: 83.629% (10758/12864)
Loss: 0.600 | Acc: 83.524% (16090/19264)
Loss: 0.605 | Acc: 83.280% (21373/25664)
Loss: 0.608 | Acc: 83.290% (26706/32064)
Loss: 0.610 | Acc: 83.345% (32058/38464)
Loss: 0.609 | Acc: 83.365% (37401/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5691, Accuracy: 5665/10000 (56.65%)

Epoch: 153
Loss: 0.811 | Acc: 73.438% (47/64)
Loss: 0.595 | Acc: 83.400% (5391/6464)
Loss: 0.589 | Acc: 83.605% (10755/12864)
Loss: 0.590 | Acc: 83.783% (16140/19264)
Loss: 0.588 | Acc: 83.981% (21553/25664)
Loss: 0.589 | Acc: 84.057% (26952/32064)
Loss: 0.592 | Acc: 83.964% (32296/38464)
Loss: 0.591 | Acc: 84.085% (37724/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7495, Accuracy: 7878/10000 (78.78%)

Epoch: 154
Loss: 0.677 | Acc: 81.250% (52/64)
Loss: 0.585 | Acc: 84.019% (5431/6464)
Loss: 0.597 | Acc: 83.776% (10777/12864)
Loss: 0.596 | Acc: 83.871% (16157/19264)
Loss: 0.591 | Acc: 84.017% (21562/25664)
Loss: 0.589 | Acc: 84.029% (26943/32064)
Loss: 0.593 | Acc: 83.920% (32279/38464)
Loss: 0.591 | Acc: 84.058% (37712/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4446, Accuracy: 5742/10000 (57.42%)

Epoch: 155
Loss: 0.897 | Acc: 73.438% (47/64)
Loss: 0.609 | Acc: 83.447% (5394/6464)
Loss: 0.599 | Acc: 83.761% (10775/12864)
Loss: 0.587 | Acc: 84.110% (16203/19264)
Loss: 0.584 | Acc: 84.188% (21606/25664)
Loss: 0.577 | Acc: 84.310% (27033/32064)
Loss: 0.581 | Acc: 84.313% (32430/38464)
Loss: 0.586 | Acc: 84.130% (37744/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0766, Accuracy: 6916/10000 (69.16%)

Epoch: 156
Loss: 0.503 | Acc: 82.812% (53/64)
Loss: 0.565 | Acc: 84.483% (5461/6464)
Loss: 0.565 | Acc: 84.429% (10861/12864)
Loss: 0.568 | Acc: 84.417% (16262/19264)
Loss: 0.570 | Acc: 84.554% (21700/25664)
Loss: 0.570 | Acc: 84.444% (27076/32064)
Loss: 0.575 | Acc: 84.401% (32464/38464)
Loss: 0.574 | Acc: 84.442% (37884/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3461, Accuracy: 4402/10000 (44.02%)

Epoch: 157
Loss: 0.787 | Acc: 81.250% (52/64)
Loss: 0.570 | Acc: 84.746% (5478/6464)
Loss: 0.558 | Acc: 85.012% (10936/12864)
Loss: 0.569 | Acc: 84.749% (16326/19264)
Loss: 0.572 | Acc: 84.780% (21758/25664)
Loss: 0.574 | Acc: 84.659% (27145/32064)
Loss: 0.573 | Acc: 84.669% (32567/38464)
Loss: 0.574 | Acc: 84.674% (37988/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8469, Accuracy: 7491/10000 (74.91%)

Epoch: 158
Loss: 0.581 | Acc: 79.688% (51/64)
Loss: 0.554 | Acc: 85.056% (5498/6464)
Loss: 0.554 | Acc: 85.059% (10942/12864)
Loss: 0.562 | Acc: 84.879% (16351/19264)
Loss: 0.562 | Acc: 84.959% (21804/25664)
Loss: 0.569 | Acc: 84.790% (27187/32064)
Loss: 0.569 | Acc: 84.799% (32617/38464)
Loss: 0.571 | Acc: 84.758% (38026/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8520, Accuracy: 7564/10000 (75.64%)

Epoch: 159
Loss: 0.478 | Acc: 90.625% (58/64)
Loss: 0.560 | Acc: 84.793% (5481/6464)
Loss: 0.558 | Acc: 84.725% (10899/12864)
Loss: 0.558 | Acc: 84.837% (16343/19264)
Loss: 0.562 | Acc: 84.761% (21753/25664)
Loss: 0.562 | Acc: 84.793% (27188/32064)
Loss: 0.565 | Acc: 84.708% (32582/38464)
Loss: 0.568 | Acc: 84.671% (37987/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7190, Accuracy: 5504/10000 (55.04%)

Epoch: 160
Loss: 0.683 | Acc: 79.688% (51/64)
Loss: 0.555 | Acc: 85.350% (5517/6464)
Loss: 0.564 | Acc: 85.238% (10965/12864)
Loss: 0.555 | Acc: 85.444% (16460/19264)
Loss: 0.559 | Acc: 85.111% (21843/25664)
Loss: 0.553 | Acc: 85.323% (27358/32064)
Loss: 0.557 | Acc: 85.186% (32766/38464)
Loss: 0.557 | Acc: 85.106% (38182/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1331, Accuracy: 6711/10000 (67.11%)

Epoch: 161
Loss: 0.923 | Acc: 73.438% (47/64)
Loss: 0.536 | Acc: 85.582% (5532/6464)
Loss: 0.539 | Acc: 85.549% (11005/12864)
Loss: 0.549 | Acc: 85.361% (16444/19264)
Loss: 0.555 | Acc: 85.205% (21867/25664)
Loss: 0.561 | Acc: 85.242% (27332/32064)
Loss: 0.562 | Acc: 85.241% (32787/38464)
Loss: 0.563 | Acc: 85.162% (38207/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9636, Accuracy: 7371/10000 (73.71%)

Epoch: 162
Loss: 0.648 | Acc: 84.375% (54/64)
Loss: 0.523 | Acc: 86.603% (5598/6464)
Loss: 0.525 | Acc: 86.381% (11112/12864)
Loss: 0.533 | Acc: 86.114% (16589/19264)
Loss: 0.540 | Acc: 85.926% (22052/25664)
Loss: 0.544 | Acc: 85.725% (27487/32064)
Loss: 0.547 | Acc: 85.636% (32939/38464)
Loss: 0.550 | Acc: 85.518% (38367/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5991, Accuracy: 8430/10000 (84.30%)

Epoch: 163
Loss: 0.535 | Acc: 84.375% (54/64)
Loss: 0.529 | Acc: 86.154% (5569/6464)
Loss: 0.539 | Acc: 85.805% (11038/12864)
Loss: 0.542 | Acc: 85.751% (16519/19264)
Loss: 0.549 | Acc: 85.610% (21971/25664)
Loss: 0.549 | Acc: 85.613% (27451/32064)
Loss: 0.547 | Acc: 85.589% (32921/38464)
Loss: 0.549 | Acc: 85.559% (38385/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0791, Accuracy: 6875/10000 (68.75%)

Epoch: 164
Loss: 0.729 | Acc: 82.812% (53/64)
Loss: 0.538 | Acc: 85.922% (5554/6464)
Loss: 0.523 | Acc: 86.109% (11077/12864)
Loss: 0.529 | Acc: 86.093% (16585/19264)
Loss: 0.542 | Acc: 85.750% (22007/25664)
Loss: 0.540 | Acc: 85.753% (27496/32064)
Loss: 0.541 | Acc: 85.701% (32964/38464)
Loss: 0.543 | Acc: 85.596% (38402/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7385, Accuracy: 7902/10000 (79.02%)

Epoch: 165
Loss: 0.365 | Acc: 92.188% (59/64)
Loss: 0.536 | Acc: 86.216% (5573/6464)
Loss: 0.540 | Acc: 86.062% (11071/12864)
Loss: 0.541 | Acc: 86.098% (16586/19264)
Loss: 0.537 | Acc: 86.175% (22116/25664)
Loss: 0.534 | Acc: 86.171% (27630/32064)
Loss: 0.531 | Acc: 86.262% (33180/38464)
Loss: 0.533 | Acc: 86.247% (38694/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5190, Accuracy: 5743/10000 (57.43%)

Epoch: 166
Loss: 1.005 | Acc: 67.188% (43/64)
Loss: 0.513 | Acc: 86.634% (5600/6464)
Loss: 0.516 | Acc: 86.334% (11106/12864)
Loss: 0.518 | Acc: 86.290% (16623/19264)
Loss: 0.521 | Acc: 86.269% (22140/25664)
Loss: 0.524 | Acc: 86.075% (27599/32064)
Loss: 0.527 | Acc: 86.015% (33085/38464)
Loss: 0.529 | Acc: 85.964% (38567/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7882, Accuracy: 5393/10000 (53.93%)

Epoch: 167
Loss: 0.718 | Acc: 76.562% (49/64)
Loss: 0.514 | Acc: 86.262% (5576/6464)
Loss: 0.506 | Acc: 86.793% (11165/12864)
Loss: 0.516 | Acc: 86.628% (16688/19264)
Loss: 0.511 | Acc: 86.795% (22275/25664)
Loss: 0.518 | Acc: 86.580% (27761/32064)
Loss: 0.520 | Acc: 86.515% (33277/38464)
Loss: 0.521 | Acc: 86.528% (38820/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1392, Accuracy: 6944/10000 (69.44%)

Epoch: 168
Loss: 0.467 | Acc: 87.500% (56/64)
Loss: 0.489 | Acc: 87.206% (5637/6464)
Loss: 0.501 | Acc: 87.010% (11193/12864)
Loss: 0.506 | Acc: 86.815% (16724/19264)
Loss: 0.512 | Acc: 86.600% (22225/25664)
Loss: 0.514 | Acc: 86.611% (27771/32064)
Loss: 0.518 | Acc: 86.538% (33286/38464)
Loss: 0.517 | Acc: 86.584% (38845/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7504, Accuracy: 7954/10000 (79.54%)

Epoch: 169
Loss: 0.503 | Acc: 84.375% (54/64)
Loss: 0.496 | Acc: 86.897% (5617/6464)
Loss: 0.494 | Acc: 87.142% (11210/12864)
Loss: 0.502 | Acc: 86.981% (16756/19264)
Loss: 0.498 | Acc: 87.153% (22367/25664)
Loss: 0.503 | Acc: 87.063% (27916/32064)
Loss: 0.507 | Acc: 86.938% (33440/38464)
Loss: 0.506 | Acc: 86.887% (38981/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0127, Accuracy: 7137/10000 (71.37%)

Epoch: 170
Loss: 0.947 | Acc: 75.000% (48/64)
Loss: 0.506 | Acc: 87.051% (5627/6464)
Loss: 0.495 | Acc: 87.492% (11255/12864)
Loss: 0.500 | Acc: 87.246% (16807/19264)
Loss: 0.504 | Acc: 87.075% (22347/25664)
Loss: 0.504 | Acc: 87.038% (27908/32064)
Loss: 0.500 | Acc: 87.188% (33536/38464)
Loss: 0.503 | Acc: 87.148% (39098/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2352, Accuracy: 6669/10000 (66.69%)

Epoch: 171
Loss: 0.815 | Acc: 75.000% (48/64)
Loss: 0.479 | Acc: 88.041% (5691/6464)
Loss: 0.469 | Acc: 88.238% (11351/12864)
Loss: 0.483 | Acc: 87.827% (16919/19264)
Loss: 0.484 | Acc: 87.687% (22504/25664)
Loss: 0.483 | Acc: 87.634% (28099/32064)
Loss: 0.486 | Acc: 87.552% (33676/38464)
Loss: 0.488 | Acc: 87.536% (39272/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0918, Accuracy: 6984/10000 (69.84%)

Epoch: 172
Loss: 1.155 | Acc: 73.438% (47/64)
Loss: 0.492 | Acc: 87.222% (5638/6464)
Loss: 0.487 | Acc: 87.438% (11248/12864)
Loss: 0.483 | Acc: 87.588% (16873/19264)
Loss: 0.483 | Acc: 87.656% (22496/25664)
Loss: 0.480 | Acc: 87.743% (28134/32064)
Loss: 0.479 | Acc: 87.705% (33735/38464)
Loss: 0.482 | Acc: 87.652% (39324/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0623, Accuracy: 7014/10000 (70.14%)

Epoch: 173
Loss: 0.432 | Acc: 92.188% (59/64)
Loss: 0.459 | Acc: 88.366% (5712/6464)
Loss: 0.463 | Acc: 88.324% (11362/12864)
Loss: 0.470 | Acc: 88.227% (16996/19264)
Loss: 0.466 | Acc: 88.310% (22664/25664)
Loss: 0.465 | Acc: 88.358% (28331/32064)
Loss: 0.469 | Acc: 88.277% (33955/38464)
Loss: 0.470 | Acc: 88.260% (39597/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2491, Accuracy: 6635/10000 (66.35%)

Epoch: 174
Loss: 0.480 | Acc: 92.188% (59/64)
Loss: 0.459 | Acc: 88.490% (5720/6464)
Loss: 0.462 | Acc: 88.254% (11353/12864)
Loss: 0.456 | Acc: 88.403% (17030/19264)
Loss: 0.463 | Acc: 88.322% (22667/25664)
Loss: 0.460 | Acc: 88.408% (28347/32064)
Loss: 0.461 | Acc: 88.363% (33988/38464)
Loss: 0.463 | Acc: 88.302% (39616/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6742, Accuracy: 8145/10000 (81.45%)

Epoch: 175
Loss: 0.451 | Acc: 90.625% (58/64)
Loss: 0.439 | Acc: 89.062% (5757/6464)
Loss: 0.433 | Acc: 89.218% (11477/12864)
Loss: 0.439 | Acc: 89.229% (17189/19264)
Loss: 0.446 | Acc: 89.055% (22855/25664)
Loss: 0.444 | Acc: 89.013% (28541/32064)
Loss: 0.449 | Acc: 88.870% (34183/38464)
Loss: 0.450 | Acc: 88.771% (39826/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9152, Accuracy: 7523/10000 (75.23%)

Epoch: 176
Loss: 0.722 | Acc: 82.812% (53/64)
Loss: 0.426 | Acc: 89.774% (5803/6464)
Loss: 0.439 | Acc: 89.265% (11483/12864)
Loss: 0.438 | Acc: 89.011% (17147/19264)
Loss: 0.444 | Acc: 88.922% (22821/25664)
Loss: 0.443 | Acc: 88.960% (28524/32064)
Loss: 0.438 | Acc: 89.076% (34262/38464)
Loss: 0.439 | Acc: 89.013% (39935/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7322, Accuracy: 8050/10000 (80.50%)

Epoch: 177
Loss: 0.405 | Acc: 84.375% (54/64)
Loss: 0.429 | Acc: 89.310% (5773/6464)
Loss: 0.430 | Acc: 89.405% (11501/12864)
Loss: 0.419 | Acc: 89.748% (17289/19264)
Loss: 0.426 | Acc: 89.495% (22968/25664)
Loss: 0.428 | Acc: 89.371% (28656/32064)
Loss: 0.433 | Acc: 89.244% (34327/38464)
Loss: 0.431 | Acc: 89.312% (40069/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0786, Accuracy: 7027/10000 (70.27%)

Epoch: 178
Loss: 0.424 | Acc: 87.500% (56/64)
Loss: 0.379 | Acc: 90.780% (5868/6464)
Loss: 0.387 | Acc: 90.749% (11674/12864)
Loss: 0.398 | Acc: 90.381% (17411/19264)
Loss: 0.404 | Acc: 90.154% (23137/25664)
Loss: 0.411 | Acc: 89.992% (28855/32064)
Loss: 0.410 | Acc: 90.001% (34618/38464)
Loss: 0.411 | Acc: 90.003% (40379/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8617, Accuracy: 7503/10000 (75.03%)

Epoch: 179
Loss: 0.595 | Acc: 82.812% (53/64)
Loss: 0.406 | Acc: 90.393% (5843/6464)
Loss: 0.400 | Acc: 90.446% (11635/12864)
Loss: 0.393 | Acc: 90.537% (17441/19264)
Loss: 0.396 | Acc: 90.430% (23208/25664)
Loss: 0.395 | Acc: 90.422% (28993/32064)
Loss: 0.400 | Acc: 90.274% (34723/38464)
Loss: 0.400 | Acc: 90.273% (40500/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6334, Accuracy: 8334/10000 (83.34%)

Epoch: 180
Loss: 0.253 | Acc: 90.625% (58/64)
Loss: 0.375 | Acc: 91.120% (5890/6464)
Loss: 0.382 | Acc: 90.874% (11690/12864)
Loss: 0.381 | Acc: 90.859% (17503/19264)
Loss: 0.377 | Acc: 90.906% (23330/25664)
Loss: 0.382 | Acc: 90.747% (29097/32064)
Loss: 0.383 | Acc: 90.734% (34900/38464)
Loss: 0.383 | Acc: 90.739% (40709/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5681, Accuracy: 8622/10000 (86.22%)

Epoch: 181
Loss: 0.378 | Acc: 92.188% (59/64)
Loss: 0.366 | Acc: 91.058% (5886/6464)
Loss: 0.357 | Acc: 91.449% (11764/12864)
Loss: 0.364 | Acc: 91.269% (17582/19264)
Loss: 0.364 | Acc: 91.256% (23420/25664)
Loss: 0.361 | Acc: 91.311% (29278/32064)
Loss: 0.367 | Acc: 91.187% (35074/38464)
Loss: 0.369 | Acc: 91.109% (40875/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6480, Accuracy: 8329/10000 (83.29%)

Epoch: 182
Loss: 0.398 | Acc: 89.062% (57/64)
Loss: 0.369 | Acc: 90.718% (5864/6464)
Loss: 0.350 | Acc: 91.597% (11783/12864)
Loss: 0.353 | Acc: 91.476% (17622/19264)
Loss: 0.352 | Acc: 91.560% (23498/25664)
Loss: 0.356 | Acc: 91.501% (29339/32064)
Loss: 0.355 | Acc: 91.553% (35215/38464)
Loss: 0.354 | Acc: 91.601% (41096/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5498, Accuracy: 8707/10000 (87.07%)

Epoch: 183
Loss: 0.365 | Acc: 92.188% (59/64)
Loss: 0.330 | Acc: 92.249% (5963/6464)
Loss: 0.333 | Acc: 92.118% (11850/12864)
Loss: 0.339 | Acc: 91.964% (17716/19264)
Loss: 0.340 | Acc: 91.954% (23599/25664)
Loss: 0.342 | Acc: 91.944% (29481/32064)
Loss: 0.342 | Acc: 91.974% (35377/38464)
Loss: 0.342 | Acc: 91.994% (41272/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5621, Accuracy: 8658/10000 (86.58%)

Epoch: 184
Loss: 0.344 | Acc: 89.062% (57/64)
Loss: 0.319 | Acc: 92.389% (5972/6464)
Loss: 0.315 | Acc: 92.483% (11897/12864)
Loss: 0.322 | Acc: 92.359% (17792/19264)
Loss: 0.321 | Acc: 92.519% (23744/25664)
Loss: 0.317 | Acc: 92.596% (29690/32064)
Loss: 0.322 | Acc: 92.476% (35570/38464)
Loss: 0.322 | Acc: 92.484% (41492/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5673, Accuracy: 8637/10000 (86.37%)

Epoch: 185
Loss: 0.253 | Acc: 93.750% (60/64)
Loss: 0.281 | Acc: 93.286% (6030/6464)
Loss: 0.292 | Acc: 93.019% (11966/12864)
Loss: 0.288 | Acc: 93.174% (17949/19264)
Loss: 0.301 | Acc: 92.924% (23848/25664)
Loss: 0.302 | Acc: 92.864% (29776/32064)
Loss: 0.303 | Acc: 92.840% (35710/38464)
Loss: 0.304 | Acc: 92.850% (41656/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5741, Accuracy: 8668/10000 (86.68%)

Epoch: 186
Loss: 0.166 | Acc: 96.875% (62/64)
Loss: 0.278 | Acc: 93.239% (6027/6464)
Loss: 0.276 | Acc: 93.369% (12011/12864)
Loss: 0.274 | Acc: 93.480% (18008/19264)
Loss: 0.283 | Acc: 93.368% (23962/25664)
Loss: 0.288 | Acc: 93.207% (29886/32064)
Loss: 0.289 | Acc: 93.266% (35874/38464)
Loss: 0.285 | Acc: 93.338% (41875/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6031, Accuracy: 8641/10000 (86.41%)

Epoch: 187
Loss: 0.250 | Acc: 96.875% (62/64)
Loss: 0.254 | Acc: 93.920% (6071/6464)
Loss: 0.255 | Acc: 93.937% (12084/12864)
Loss: 0.264 | Acc: 93.817% (18073/19264)
Loss: 0.265 | Acc: 93.793% (24071/25664)
Loss: 0.267 | Acc: 93.750% (30060/32064)
Loss: 0.264 | Acc: 93.802% (36080/38464)
Loss: 0.264 | Acc: 93.839% (42100/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6448, Accuracy: 8485/10000 (84.85%)

Epoch: 188
Loss: 0.330 | Acc: 93.750% (60/64)
Loss: 0.243 | Acc: 94.616% (6116/6464)
Loss: 0.238 | Acc: 94.628% (12173/12864)
Loss: 0.240 | Acc: 94.601% (18224/19264)
Loss: 0.242 | Acc: 94.533% (24261/25664)
Loss: 0.241 | Acc: 94.527% (30309/32064)
Loss: 0.241 | Acc: 94.514% (36354/38464)
Loss: 0.240 | Acc: 94.548% (42418/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5702, Accuracy: 8745/10000 (87.45%)

Epoch: 189
Loss: 0.186 | Acc: 95.312% (61/64)
Loss: 0.200 | Acc: 95.529% (6175/6464)
Loss: 0.207 | Acc: 95.281% (12257/12864)
Loss: 0.214 | Acc: 95.120% (18324/19264)
Loss: 0.218 | Acc: 95.016% (24385/25664)
Loss: 0.219 | Acc: 94.976% (30453/32064)
Loss: 0.220 | Acc: 94.941% (36518/38464)
Loss: 0.219 | Acc: 94.963% (42604/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5755, Accuracy: 8794/10000 (87.94%)

Epoch: 190
Loss: 0.362 | Acc: 90.625% (58/64)
Loss: 0.181 | Acc: 95.869% (6197/6464)
Loss: 0.183 | Acc: 95.740% (12316/12864)
Loss: 0.189 | Acc: 95.640% (18424/19264)
Loss: 0.191 | Acc: 95.566% (24526/25664)
Loss: 0.190 | Acc: 95.603% (30654/32064)
Loss: 0.191 | Acc: 95.565% (36758/38464)
Loss: 0.191 | Acc: 95.551% (42868/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5889, Accuracy: 8797/10000 (87.97%)

Epoch: 191
Loss: 0.262 | Acc: 93.750% (60/64)
Loss: 0.172 | Acc: 95.823% (6194/6464)
Loss: 0.169 | Acc: 96.020% (12352/12864)
Loss: 0.168 | Acc: 96.003% (18494/19264)
Loss: 0.168 | Acc: 95.987% (24634/25664)
Loss: 0.169 | Acc: 96.011% (30785/32064)
Loss: 0.171 | Acc: 95.949% (36906/38464)
Loss: 0.172 | Acc: 95.939% (43042/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6019, Accuracy: 8743/10000 (87.43%)

Epoch: 192
Loss: 0.076 | Acc: 100.000% (64/64)
Loss: 0.152 | Acc: 96.349% (6228/6464)
Loss: 0.143 | Acc: 96.580% (12424/12864)
Loss: 0.145 | Acc: 96.486% (18587/19264)
Loss: 0.146 | Acc: 96.446% (24752/25664)
Loss: 0.148 | Acc: 96.379% (30903/32064)
Loss: 0.150 | Acc: 96.332% (37053/38464)
Loss: 0.152 | Acc: 96.278% (43194/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6126, Accuracy: 8805/10000 (88.05%)

Epoch: 193
Loss: 0.087 | Acc: 98.438% (63/64)
Loss: 0.136 | Acc: 96.519% (6239/6464)
Loss: 0.135 | Acc: 96.681% (12437/12864)
Loss: 0.136 | Acc: 96.615% (18612/19264)
Loss: 0.134 | Acc: 96.633% (24800/25664)
Loss: 0.132 | Acc: 96.725% (31014/32064)
Loss: 0.132 | Acc: 96.719% (37202/38464)
Loss: 0.131 | Acc: 96.741% (43402/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5906, Accuracy: 8859/10000 (88.59%)

Epoch: 194
Loss: 0.128 | Acc: 96.875% (62/64)
Loss: 0.110 | Acc: 97.200% (6283/6464)
Loss: 0.113 | Acc: 97.155% (12498/12864)
Loss: 0.113 | Acc: 97.166% (18718/19264)
Loss: 0.115 | Acc: 97.156% (24934/25664)
Loss: 0.113 | Acc: 97.156% (31152/32064)
Loss: 0.113 | Acc: 97.140% (37364/38464)
Loss: 0.112 | Acc: 97.187% (43602/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5941, Accuracy: 8874/10000 (88.74%)

Epoch: 195
Loss: 0.203 | Acc: 96.875% (62/64)
Loss: 0.097 | Acc: 97.509% (6303/6464)
Loss: 0.101 | Acc: 97.373% (12526/12864)
Loss: 0.104 | Acc: 97.332% (18750/19264)
Loss: 0.102 | Acc: 97.385% (24993/25664)
Loss: 0.099 | Acc: 97.464% (31251/32064)
Loss: 0.100 | Acc: 97.442% (37480/38464)
Loss: 0.100 | Acc: 97.430% (43711/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5990, Accuracy: 8879/10000 (88.79%)

Epoch: 196
Loss: 0.163 | Acc: 96.875% (62/64)
Loss: 0.088 | Acc: 97.633% (6311/6464)
Loss: 0.088 | Acc: 97.746% (12574/12864)
Loss: 0.089 | Acc: 97.664% (18814/19264)
Loss: 0.090 | Acc: 97.643% (25059/25664)
Loss: 0.088 | Acc: 97.705% (31328/32064)
Loss: 0.090 | Acc: 97.668% (37567/38464)
Loss: 0.088 | Acc: 97.726% (43844/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6085, Accuracy: 8853/10000 (88.53%)

Epoch: 197
Loss: 0.027 | Acc: 100.000% (64/64)
Loss: 0.079 | Acc: 97.927% (6330/6464)
Loss: 0.083 | Acc: 97.816% (12583/12864)
Loss: 0.083 | Acc: 97.861% (18852/19264)
Loss: 0.081 | Acc: 97.869% (25117/25664)
Loss: 0.083 | Acc: 97.851% (31375/32064)
Loss: 0.083 | Acc: 97.847% (37636/38464)
Loss: 0.083 | Acc: 97.842% (43896/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6066, Accuracy: 8873/10000 (88.73%)
torch.Size([100, 10])
Test set: Average loss: 0.6066, Accuracy: 8873/10000 (88.73%)

Epoch: 198
Loss: 0.019 | Acc: 100.000% (64/64)
Loss: 0.086 | Acc: 97.788% (6321/6464)
Loss: 0.084 | Acc: 97.738% (12573/12864)
Loss: 0.078 | Acc: 97.939% (18867/19264)
Loss: 0.078 | Acc: 97.931% (25133/25664)
Loss: 0.078 | Acc: 97.932% (31401/32064)
Loss: 0.080 | Acc: 97.902% (37657/38464)
Loss: 0.079 | Acc: 97.916% (43929/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6090, Accuracy: 8879/10000 (88.79%)
torch.Size([100, 10])
Test set: Average loss: 0.6090, Accuracy: 8879/10000 (88.79%)

Epoch: 199
Loss: 0.035 | Acc: 100.000% (64/64)
Loss: 0.083 | Acc: 97.881% (6327/6464)
Loss: 0.082 | Acc: 97.870% (12590/12864)
Loss: 0.083 | Acc: 97.856% (18851/19264)
Loss: 0.079 | Acc: 97.970% (25143/25664)
Loss: 0.080 | Acc: 97.923% (31398/32064)
Loss: 0.079 | Acc: 97.959% (37679/38464)
Loss: 0.079 | Acc: 97.969% (43953/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6109, Accuracy: 8883/10000 (88.83%)
torch.Size([100, 10])
Test set: Average loss: 0.6109, Accuracy: 8883/10000 (88.83%)
9040
10000
-0.4926081597805023
