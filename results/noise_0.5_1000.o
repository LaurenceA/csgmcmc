==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.418 | Acc: 12.500% (8/64)
Loss: 2.885 | Acc: 12.051% (779/6464)
Loss: 2.579 | Acc: 13.433% (1728/12864)
Loss: 2.474 | Acc: 13.569% (2614/19264)
Loss: 2.417 | Acc: 14.086% (3615/25664)
Loss: 2.382 | Acc: 14.661% (4701/32064)
Loss: 2.358 | Acc: 15.131% (5820/38464)
Loss: 2.338 | Acc: 15.625% (7010/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2738, Accuracy: 1733/10000 (17.33%)

Epoch: 1
Loss: 2.315 | Acc: 7.812% (5/64)
Loss: 2.214 | Acc: 18.905% (1222/6464)
Loss: 2.204 | Acc: 19.761% (2542/12864)
Loss: 2.202 | Acc: 19.980% (3849/19264)
Loss: 2.202 | Acc: 20.051% (5146/25664)
Loss: 2.201 | Acc: 20.203% (6478/32064)
Loss: 2.197 | Acc: 20.510% (7889/38464)
Loss: 2.196 | Acc: 20.754% (9311/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2846, Accuracy: 1721/10000 (17.21%)

Epoch: 2
Loss: 2.154 | Acc: 15.625% (10/64)
Loss: 2.166 | Acc: 22.819% (1475/6464)
Loss: 2.167 | Acc: 22.715% (2922/12864)
Loss: 2.163 | Acc: 23.162% (4462/19264)
Loss: 2.161 | Acc: 23.321% (5985/25664)
Loss: 2.161 | Acc: 23.453% (7520/32064)
Loss: 2.159 | Acc: 23.635% (9091/38464)
Loss: 2.156 | Acc: 23.854% (10702/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1285, Accuracy: 2601/10000 (26.01%)

Epoch: 3
Loss: 2.423 | Acc: 10.938% (7/64)
Loss: 2.139 | Acc: 25.449% (1645/6464)
Loss: 2.142 | Acc: 25.311% (3256/12864)
Loss: 2.136 | Acc: 25.561% (4924/19264)
Loss: 2.135 | Acc: 25.733% (6604/25664)
Loss: 2.134 | Acc: 25.749% (8256/32064)
Loss: 2.131 | Acc: 25.822% (9932/38464)
Loss: 2.128 | Acc: 25.987% (11659/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1495, Accuracy: 2401/10000 (24.01%)

Epoch: 4
Loss: 2.051 | Acc: 29.688% (19/64)
Loss: 2.105 | Acc: 28.094% (1816/6464)
Loss: 2.097 | Acc: 28.335% (3645/12864)
Loss: 2.102 | Acc: 28.177% (5428/19264)
Loss: 2.102 | Acc: 28.028% (7193/25664)
Loss: 2.103 | Acc: 27.997% (8977/32064)
Loss: 2.102 | Acc: 28.208% (10850/38464)
Loss: 2.100 | Acc: 28.314% (12703/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1355, Accuracy: 2591/10000 (25.91%)

Epoch: 5
Loss: 2.071 | Acc: 28.125% (18/64)
Loss: 2.074 | Acc: 29.873% (1931/6464)
Loss: 2.085 | Acc: 29.283% (3767/12864)
Loss: 2.082 | Acc: 29.444% (5672/19264)
Loss: 2.079 | Acc: 29.765% (7639/25664)
Loss: 2.077 | Acc: 29.968% (9609/32064)
Loss: 2.077 | Acc: 30.122% (11586/38464)
Loss: 2.074 | Acc: 30.461% (13666/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1016, Accuracy: 2940/10000 (29.40%)

Epoch: 6
Loss: 1.950 | Acc: 37.500% (24/64)
Loss: 2.041 | Acc: 32.751% (2117/6464)
Loss: 2.049 | Acc: 32.191% (4141/12864)
Loss: 2.054 | Acc: 32.023% (6169/19264)
Loss: 2.051 | Acc: 32.185% (8260/25664)
Loss: 2.047 | Acc: 32.270% (10347/32064)
Loss: 2.047 | Acc: 32.313% (12429/38464)
Loss: 2.047 | Acc: 32.344% (14511/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0728, Accuracy: 3146/10000 (31.46%)

Epoch: 7
Loss: 2.070 | Acc: 29.688% (19/64)
Loss: 2.023 | Acc: 33.880% (2190/6464)
Loss: 2.021 | Acc: 33.730% (4339/12864)
Loss: 2.023 | Acc: 33.913% (6533/19264)
Loss: 2.021 | Acc: 34.079% (8746/25664)
Loss: 2.019 | Acc: 34.194% (10964/32064)
Loss: 2.020 | Acc: 34.211% (13159/38464)
Loss: 2.018 | Acc: 34.281% (15380/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0757, Accuracy: 3173/10000 (31.73%)

Epoch: 8
Loss: 2.103 | Acc: 28.125% (18/64)
Loss: 1.998 | Acc: 34.947% (2259/6464)
Loss: 1.996 | Acc: 35.106% (4516/12864)
Loss: 1.993 | Acc: 35.486% (6836/19264)
Loss: 1.999 | Acc: 35.365% (9076/25664)
Loss: 1.996 | Acc: 35.632% (11425/32064)
Loss: 1.997 | Acc: 35.542% (13671/38464)
Loss: 1.996 | Acc: 35.628% (15984/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1613, Accuracy: 2950/10000 (29.50%)

Epoch: 9
Loss: 2.051 | Acc: 29.688% (19/64)
Loss: 1.971 | Acc: 37.531% (2426/6464)
Loss: 1.978 | Acc: 37.088% (4771/12864)
Loss: 1.979 | Acc: 37.080% (7143/19264)
Loss: 1.979 | Acc: 37.067% (9513/25664)
Loss: 1.979 | Acc: 37.126% (11904/32064)
Loss: 1.981 | Acc: 37.042% (14248/38464)
Loss: 1.981 | Acc: 36.990% (16595/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0478, Accuracy: 3286/10000 (32.86%)

Epoch: 10
Loss: 1.909 | Acc: 43.750% (28/64)
Loss: 1.971 | Acc: 37.252% (2408/6464)
Loss: 1.970 | Acc: 37.679% (4847/12864)
Loss: 1.968 | Acc: 37.427% (7210/19264)
Loss: 1.969 | Acc: 37.449% (9611/25664)
Loss: 1.965 | Acc: 37.703% (12089/32064)
Loss: 1.965 | Acc: 37.695% (14499/38464)
Loss: 1.965 | Acc: 37.652% (16892/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1136, Accuracy: 3071/10000 (30.71%)

Epoch: 11
Loss: 1.887 | Acc: 40.625% (26/64)
Loss: 1.947 | Acc: 39.001% (2521/6464)
Loss: 1.954 | Acc: 38.837% (4996/12864)
Loss: 1.954 | Acc: 38.663% (7448/19264)
Loss: 1.955 | Acc: 38.536% (9890/25664)
Loss: 1.955 | Acc: 38.507% (12347/32064)
Loss: 1.955 | Acc: 38.566% (14834/38464)
Loss: 1.952 | Acc: 38.724% (17373/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0734, Accuracy: 3216/10000 (32.16%)

Epoch: 12
Loss: 1.890 | Acc: 35.938% (23/64)
Loss: 1.953 | Acc: 38.537% (2491/6464)
Loss: 1.946 | Acc: 38.938% (5009/12864)
Loss: 1.940 | Acc: 39.390% (7588/19264)
Loss: 1.940 | Acc: 39.374% (10105/25664)
Loss: 1.940 | Acc: 39.487% (12661/32064)
Loss: 1.937 | Acc: 39.627% (15242/38464)
Loss: 1.938 | Acc: 39.502% (17722/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0004, Accuracy: 3632/10000 (36.32%)

Epoch: 13
Loss: 2.072 | Acc: 32.812% (21/64)
Loss: 1.925 | Acc: 40.207% (2599/6464)
Loss: 1.925 | Acc: 40.275% (5181/12864)
Loss: 1.926 | Acc: 40.350% (7773/19264)
Loss: 1.926 | Acc: 40.368% (10360/25664)
Loss: 1.927 | Acc: 40.282% (12916/32064)
Loss: 1.928 | Acc: 40.266% (15488/38464)
Loss: 1.927 | Acc: 40.322% (18090/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9952, Accuracy: 3769/10000 (37.69%)

Epoch: 14
Loss: 1.886 | Acc: 42.188% (27/64)
Loss: 1.917 | Acc: 41.012% (2651/6464)
Loss: 1.916 | Acc: 40.959% (5269/12864)
Loss: 1.915 | Acc: 41.056% (7909/19264)
Loss: 1.915 | Acc: 41.069% (10540/25664)
Loss: 1.915 | Acc: 41.068% (13168/32064)
Loss: 1.916 | Acc: 41.085% (15803/38464)
Loss: 1.914 | Acc: 41.173% (18472/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0931, Accuracy: 3014/10000 (30.14%)

Epoch: 15
Loss: 2.007 | Acc: 32.812% (21/64)
Loss: 1.917 | Acc: 40.764% (2635/6464)
Loss: 1.910 | Acc: 41.433% (5330/12864)
Loss: 1.910 | Acc: 41.523% (7999/19264)
Loss: 1.910 | Acc: 41.494% (10649/25664)
Loss: 1.907 | Acc: 41.614% (13343/32064)
Loss: 1.906 | Acc: 41.618% (16008/38464)
Loss: 1.908 | Acc: 41.548% (18640/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0627, Accuracy: 3328/10000 (33.28%)

Epoch: 16
Loss: 2.191 | Acc: 31.250% (20/64)
Loss: 1.886 | Acc: 42.559% (2751/6464)
Loss: 1.895 | Acc: 41.892% (5389/12864)
Loss: 1.900 | Acc: 41.700% (8033/19264)
Loss: 1.904 | Acc: 41.619% (10681/25664)
Loss: 1.903 | Acc: 41.701% (13371/32064)
Loss: 1.902 | Acc: 41.829% (16089/38464)
Loss: 1.897 | Acc: 42.000% (18843/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0280, Accuracy: 3577/10000 (35.77%)

Epoch: 17
Loss: 1.860 | Acc: 42.188% (27/64)
Loss: 1.891 | Acc: 42.775% (2765/6464)
Loss: 1.899 | Acc: 42.413% (5456/12864)
Loss: 1.898 | Acc: 42.525% (8192/19264)
Loss: 1.893 | Acc: 42.717% (10963/25664)
Loss: 1.896 | Acc: 42.506% (13629/32064)
Loss: 1.894 | Acc: 42.536% (16361/38464)
Loss: 1.893 | Acc: 42.531% (19081/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9795, Accuracy: 3875/10000 (38.75%)

Epoch: 18
Loss: 1.955 | Acc: 40.625% (26/64)
Loss: 1.869 | Acc: 43.781% (2830/6464)
Loss: 1.883 | Acc: 43.136% (5549/12864)
Loss: 1.882 | Acc: 43.039% (8291/19264)
Loss: 1.882 | Acc: 42.920% (11015/25664)
Loss: 1.882 | Acc: 43.036% (13799/32064)
Loss: 1.882 | Acc: 42.954% (16522/38464)
Loss: 1.881 | Acc: 43.017% (19299/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9878, Accuracy: 3823/10000 (38.23%)

Epoch: 19
Loss: 2.206 | Acc: 26.562% (17/64)
Loss: 1.868 | Acc: 43.209% (2793/6464)
Loss: 1.870 | Acc: 43.501% (5596/12864)
Loss: 1.865 | Acc: 43.802% (8438/19264)
Loss: 1.867 | Acc: 43.773% (11234/25664)
Loss: 1.871 | Acc: 43.644% (13994/32064)
Loss: 1.874 | Acc: 43.571% (16759/38464)
Loss: 1.873 | Acc: 43.525% (19527/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0370, Accuracy: 3425/10000 (34.25%)

Epoch: 20
Loss: 1.822 | Acc: 48.438% (31/64)
Loss: 1.866 | Acc: 44.075% (2849/6464)
Loss: 1.860 | Acc: 44.076% (5670/12864)
Loss: 1.861 | Acc: 43.859% (8449/19264)
Loss: 1.865 | Acc: 43.680% (11210/25664)
Loss: 1.864 | Acc: 43.828% (14053/32064)
Loss: 1.867 | Acc: 43.789% (16843/38464)
Loss: 1.867 | Acc: 43.752% (19629/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0635, Accuracy: 3304/10000 (33.04%)

Epoch: 21
Loss: 1.930 | Acc: 42.188% (27/64)
Loss: 1.859 | Acc: 44.152% (2854/6464)
Loss: 1.860 | Acc: 44.131% (5677/12864)
Loss: 1.857 | Acc: 44.254% (8525/19264)
Loss: 1.859 | Acc: 44.183% (11339/25664)
Loss: 1.859 | Acc: 44.233% (14183/32064)
Loss: 1.861 | Acc: 44.075% (16953/38464)
Loss: 1.858 | Acc: 44.207% (19833/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9411, Accuracy: 4015/10000 (40.15%)

Epoch: 22
Loss: 1.721 | Acc: 53.125% (34/64)
Loss: 1.841 | Acc: 44.817% (2897/6464)
Loss: 1.855 | Acc: 44.294% (5698/12864)
Loss: 1.854 | Acc: 44.347% (8543/19264)
Loss: 1.858 | Acc: 44.151% (11331/25664)
Loss: 1.856 | Acc: 44.302% (14205/32064)
Loss: 1.855 | Acc: 44.439% (17093/38464)
Loss: 1.853 | Acc: 44.490% (19960/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9295, Accuracy: 4091/10000 (40.91%)

Epoch: 23
Loss: 1.845 | Acc: 42.188% (27/64)
Loss: 1.834 | Acc: 45.436% (2937/6464)
Loss: 1.845 | Acc: 44.932% (5780/12864)
Loss: 1.849 | Acc: 44.850% (8640/19264)
Loss: 1.850 | Acc: 44.677% (11466/25664)
Loss: 1.850 | Acc: 44.701% (14333/32064)
Loss: 1.852 | Acc: 44.566% (17142/38464)
Loss: 1.849 | Acc: 44.751% (20077/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0615, Accuracy: 3397/10000 (33.97%)

Epoch: 24
Loss: 1.702 | Acc: 54.688% (35/64)
Loss: 1.848 | Acc: 44.678% (2888/6464)
Loss: 1.838 | Acc: 45.072% (5798/12864)
Loss: 1.839 | Acc: 45.209% (8709/19264)
Loss: 1.845 | Acc: 44.927% (11530/25664)
Loss: 1.839 | Acc: 45.144% (14475/32064)
Loss: 1.838 | Acc: 45.203% (17387/38464)
Loss: 1.840 | Acc: 45.152% (20257/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9495, Accuracy: 3934/10000 (39.34%)

Epoch: 25
Loss: 1.825 | Acc: 46.875% (30/64)
Loss: 1.815 | Acc: 46.179% (2985/6464)
Loss: 1.827 | Acc: 45.655% (5873/12864)
Loss: 1.830 | Acc: 45.515% (8768/19264)
Loss: 1.830 | Acc: 45.597% (11702/25664)
Loss: 1.831 | Acc: 45.534% (14600/32064)
Loss: 1.833 | Acc: 45.497% (17500/38464)
Loss: 1.834 | Acc: 45.500% (20413/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9250, Accuracy: 4050/10000 (40.50%)

Epoch: 26
Loss: 1.985 | Acc: 39.062% (25/64)
Loss: 1.839 | Acc: 45.978% (2972/6464)
Loss: 1.842 | Acc: 45.491% (5852/12864)
Loss: 1.832 | Acc: 45.868% (8836/19264)
Loss: 1.830 | Acc: 45.932% (11788/25664)
Loss: 1.831 | Acc: 45.768% (14675/32064)
Loss: 1.828 | Acc: 45.903% (17656/38464)
Loss: 1.826 | Acc: 45.999% (20637/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8891, Accuracy: 4324/10000 (43.24%)

Epoch: 27
Loss: 1.914 | Acc: 34.375% (22/64)
Loss: 1.845 | Acc: 44.848% (2899/6464)
Loss: 1.825 | Acc: 45.725% (5882/12864)
Loss: 1.817 | Acc: 45.909% (8844/19264)
Loss: 1.822 | Acc: 45.796% (11753/25664)
Loss: 1.820 | Acc: 46.017% (14755/32064)
Loss: 1.815 | Acc: 46.264% (17795/38464)
Loss: 1.815 | Acc: 46.295% (20770/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8868, Accuracy: 4378/10000 (43.78%)

Epoch: 28
Loss: 1.863 | Acc: 45.312% (29/64)
Loss: 1.803 | Acc: 47.293% (3057/6464)
Loss: 1.811 | Acc: 46.828% (6024/12864)
Loss: 1.806 | Acc: 47.083% (9070/19264)
Loss: 1.810 | Acc: 46.817% (12015/25664)
Loss: 1.809 | Acc: 46.791% (15003/32064)
Loss: 1.809 | Acc: 46.745% (17980/38464)
Loss: 1.806 | Acc: 46.871% (21028/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8826, Accuracy: 4337/10000 (43.37%)

Epoch: 29
Loss: 1.850 | Acc: 42.188% (27/64)
Loss: 1.792 | Acc: 47.447% (3067/6464)
Loss: 1.788 | Acc: 47.621% (6126/12864)
Loss: 1.788 | Acc: 47.721% (9193/19264)
Loss: 1.792 | Acc: 47.619% (12221/25664)
Loss: 1.791 | Acc: 47.742% (15308/32064)
Loss: 1.796 | Acc: 47.538% (18285/38464)
Loss: 1.795 | Acc: 47.533% (21325/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9087, Accuracy: 4156/10000 (41.56%)

Epoch: 30
Loss: 2.060 | Acc: 37.500% (24/64)
Loss: 1.765 | Acc: 48.438% (3131/6464)
Loss: 1.770 | Acc: 48.266% (6209/12864)
Loss: 1.777 | Acc: 48.147% (9275/19264)
Loss: 1.781 | Acc: 48.001% (12319/25664)
Loss: 1.783 | Acc: 47.907% (15361/32064)
Loss: 1.788 | Acc: 47.678% (18339/38464)
Loss: 1.789 | Acc: 47.642% (21374/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9225, Accuracy: 4146/10000 (41.46%)

Epoch: 31
Loss: 1.749 | Acc: 50.000% (32/64)
Loss: 1.766 | Acc: 48.530% (3137/6464)
Loss: 1.775 | Acc: 48.399% (6226/12864)
Loss: 1.779 | Acc: 48.292% (9303/19264)
Loss: 1.781 | Acc: 48.235% (12379/25664)
Loss: 1.780 | Acc: 48.169% (15445/32064)
Loss: 1.780 | Acc: 48.136% (18515/38464)
Loss: 1.782 | Acc: 48.012% (21540/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8856, Accuracy: 4352/10000 (43.52%)

Epoch: 32
Loss: 1.626 | Acc: 53.125% (34/64)
Loss: 1.761 | Acc: 48.871% (3159/6464)
Loss: 1.767 | Acc: 48.266% (6209/12864)
Loss: 1.773 | Acc: 48.209% (9287/19264)
Loss: 1.770 | Acc: 48.469% (12439/25664)
Loss: 1.770 | Acc: 48.550% (15567/32064)
Loss: 1.770 | Acc: 48.469% (18643/38464)
Loss: 1.771 | Acc: 48.478% (21749/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8846, Accuracy: 4423/10000 (44.23%)

Epoch: 33
Loss: 1.771 | Acc: 46.875% (30/64)
Loss: 1.733 | Acc: 49.876% (3224/6464)
Loss: 1.740 | Acc: 49.440% (6360/12864)
Loss: 1.741 | Acc: 49.304% (9498/19264)
Loss: 1.750 | Acc: 49.010% (12578/25664)
Loss: 1.750 | Acc: 49.080% (15737/32064)
Loss: 1.755 | Acc: 48.947% (18827/38464)
Loss: 1.758 | Acc: 48.857% (21919/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9285, Accuracy: 4118/10000 (41.18%)

Epoch: 34
Loss: 1.748 | Acc: 53.125% (34/64)
Loss: 1.735 | Acc: 50.031% (3234/6464)
Loss: 1.734 | Acc: 49.751% (6400/12864)
Loss: 1.736 | Acc: 49.746% (9583/19264)
Loss: 1.743 | Acc: 49.451% (12691/25664)
Loss: 1.746 | Acc: 49.345% (15822/32064)
Loss: 1.747 | Acc: 49.275% (18953/38464)
Loss: 1.749 | Acc: 49.224% (22084/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9396, Accuracy: 4095/10000 (40.95%)

Epoch: 35
Loss: 1.505 | Acc: 59.375% (38/64)
Loss: 1.685 | Acc: 51.532% (3331/6464)
Loss: 1.707 | Acc: 50.630% (6513/12864)
Loss: 1.719 | Acc: 50.125% (9656/19264)
Loss: 1.722 | Acc: 50.016% (12836/25664)
Loss: 1.725 | Acc: 49.938% (16012/32064)
Loss: 1.727 | Acc: 49.945% (19211/38464)
Loss: 1.732 | Acc: 49.746% (22318/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8736, Accuracy: 4441/10000 (44.41%)

Epoch: 36
Loss: 1.815 | Acc: 48.438% (31/64)
Loss: 1.726 | Acc: 49.551% (3203/6464)
Loss: 1.714 | Acc: 50.249% (6464/12864)
Loss: 1.713 | Acc: 50.467% (9722/19264)
Loss: 1.713 | Acc: 50.440% (12945/25664)
Loss: 1.714 | Acc: 50.349% (16144/32064)
Loss: 1.717 | Acc: 50.268% (19335/38464)
Loss: 1.717 | Acc: 50.294% (22564/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8761, Accuracy: 4500/10000 (45.00%)

Epoch: 37
Loss: 1.659 | Acc: 53.125% (34/64)
Loss: 1.696 | Acc: 51.253% (3313/6464)
Loss: 1.695 | Acc: 51.384% (6610/12864)
Loss: 1.695 | Acc: 51.287% (9880/19264)
Loss: 1.698 | Acc: 51.212% (13143/25664)
Loss: 1.705 | Acc: 50.923% (16328/32064)
Loss: 1.708 | Acc: 50.697% (19500/38464)
Loss: 1.705 | Acc: 50.762% (22774/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8877, Accuracy: 4466/10000 (44.66%)

Epoch: 38
Loss: 1.778 | Acc: 46.875% (30/64)
Loss: 1.680 | Acc: 51.609% (3336/6464)
Loss: 1.681 | Acc: 51.671% (6647/12864)
Loss: 1.686 | Acc: 51.562% (9933/19264)
Loss: 1.692 | Acc: 51.243% (13151/25664)
Loss: 1.691 | Acc: 51.241% (16430/32064)
Loss: 1.684 | Acc: 51.440% (19786/38464)
Loss: 1.687 | Acc: 51.364% (23044/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8919, Accuracy: 4424/10000 (44.24%)

Epoch: 39
Loss: 1.843 | Acc: 40.625% (26/64)
Loss: 1.653 | Acc: 52.058% (3365/6464)
Loss: 1.649 | Acc: 52.480% (6751/12864)
Loss: 1.663 | Acc: 52.102% (10037/19264)
Loss: 1.656 | Acc: 52.369% (13440/25664)
Loss: 1.657 | Acc: 52.420% (16808/32064)
Loss: 1.658 | Acc: 52.439% (20170/38464)
Loss: 1.665 | Acc: 52.164% (23403/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8887, Accuracy: 4527/10000 (45.27%)

Epoch: 40
Loss: 1.628 | Acc: 54.688% (35/64)
Loss: 1.628 | Acc: 52.893% (3419/6464)
Loss: 1.631 | Acc: 53.172% (6840/12864)
Loss: 1.636 | Acc: 53.109% (10231/19264)
Loss: 1.636 | Acc: 53.043% (13613/25664)
Loss: 1.635 | Acc: 53.016% (16999/32064)
Loss: 1.640 | Acc: 52.852% (20329/38464)
Loss: 1.640 | Acc: 52.860% (23715/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8818, Accuracy: 4535/10000 (45.35%)

Epoch: 41
Loss: 1.683 | Acc: 51.562% (33/64)
Loss: 1.600 | Acc: 53.620% (3466/6464)
Loss: 1.605 | Acc: 53.428% (6873/12864)
Loss: 1.606 | Acc: 53.447% (10296/19264)
Loss: 1.610 | Acc: 53.312% (13682/25664)
Loss: 1.613 | Acc: 53.253% (17075/32064)
Loss: 1.616 | Acc: 53.200% (20463/38464)
Loss: 1.615 | Acc: 53.277% (23902/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9451, Accuracy: 4364/10000 (43.64%)

Epoch: 42
Loss: 1.469 | Acc: 59.375% (38/64)
Loss: 1.596 | Acc: 53.651% (3468/6464)
Loss: 1.591 | Acc: 53.692% (6907/12864)
Loss: 1.587 | Acc: 53.883% (10380/19264)
Loss: 1.588 | Acc: 53.885% (13829/25664)
Loss: 1.587 | Acc: 54.001% (17315/32064)
Loss: 1.585 | Acc: 54.201% (20848/38464)
Loss: 1.583 | Acc: 54.277% (24351/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9347, Accuracy: 4478/10000 (44.78%)

Epoch: 43
Loss: 1.543 | Acc: 56.250% (36/64)
Loss: 1.510 | Acc: 56.668% (3663/6464)
Loss: 1.525 | Acc: 55.908% (7192/12864)
Loss: 1.529 | Acc: 55.767% (10743/19264)
Loss: 1.533 | Acc: 55.607% (14271/25664)
Loss: 1.535 | Acc: 55.576% (17820/32064)
Loss: 1.538 | Acc: 55.501% (21348/38464)
Loss: 1.539 | Acc: 55.481% (24891/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9585, Accuracy: 4413/10000 (44.13%)

Epoch: 44
Loss: 1.336 | Acc: 62.500% (40/64)
Loss: 1.476 | Acc: 57.132% (3693/6464)
Loss: 1.492 | Acc: 56.592% (7280/12864)
Loss: 1.488 | Acc: 56.816% (10945/19264)
Loss: 1.494 | Acc: 56.523% (14506/25664)
Loss: 1.498 | Acc: 56.266% (18041/32064)
Loss: 1.502 | Acc: 56.130% (21590/38464)
Loss: 1.504 | Acc: 56.150% (25191/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9918, Accuracy: 4397/10000 (43.97%)

Epoch: 45
Loss: 1.430 | Acc: 54.688% (35/64)
Loss: 1.451 | Acc: 57.225% (3699/6464)
Loss: 1.441 | Acc: 57.735% (7427/12864)
Loss: 1.452 | Acc: 57.615% (11099/19264)
Loss: 1.458 | Acc: 57.329% (14713/25664)
Loss: 1.454 | Acc: 57.479% (18430/32064)
Loss: 1.449 | Acc: 57.701% (22194/38464)
Loss: 1.443 | Acc: 57.902% (25977/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0137, Accuracy: 4313/10000 (43.13%)

Epoch: 46
Loss: 1.332 | Acc: 67.188% (43/64)
Loss: 1.402 | Acc: 59.715% (3860/6464)
Loss: 1.388 | Acc: 59.725% (7683/12864)
Loss: 1.390 | Acc: 59.629% (11487/19264)
Loss: 1.391 | Acc: 59.535% (15279/25664)
Loss: 1.388 | Acc: 59.578% (19103/32064)
Loss: 1.389 | Acc: 59.513% (22891/38464)
Loss: 1.388 | Acc: 59.527% (26706/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0446, Accuracy: 4282/10000 (42.82%)

Epoch: 47
Loss: 1.134 | Acc: 70.312% (45/64)
Loss: 1.345 | Acc: 60.149% (3888/6464)
Loss: 1.352 | Acc: 60.261% (7752/12864)
Loss: 1.340 | Acc: 60.854% (11723/19264)
Loss: 1.335 | Acc: 60.961% (15645/25664)
Loss: 1.343 | Acc: 60.579% (19424/32064)
Loss: 1.343 | Acc: 60.516% (23277/38464)
Loss: 1.341 | Acc: 60.545% (27163/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0597, Accuracy: 4296/10000 (42.96%)
torch.Size([100, 10])
Test set: Average loss: 2.0597, Accuracy: 4296/10000 (42.96%)

Epoch: 48
Loss: 1.331 | Acc: 60.938% (39/64)
Loss: 1.281 | Acc: 62.237% (4023/6464)
Loss: 1.299 | Acc: 61.684% (7935/12864)
Loss: 1.307 | Acc: 61.348% (11818/19264)
Loss: 1.309 | Acc: 61.280% (15727/25664)
Loss: 1.304 | Acc: 61.555% (19737/32064)
Loss: 1.301 | Acc: 61.671% (23721/38464)
Loss: 1.300 | Acc: 61.686% (27675/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0676, Accuracy: 4265/10000 (42.65%)
torch.Size([100, 10])
Test set: Average loss: 2.0676, Accuracy: 4265/10000 (42.65%)

Epoch: 49
Loss: 1.285 | Acc: 60.938% (39/64)
Loss: 1.309 | Acc: 61.108% (3950/6464)
Loss: 1.303 | Acc: 61.466% (7907/12864)
Loss: 1.296 | Acc: 61.846% (11914/19264)
Loss: 1.286 | Acc: 62.278% (15983/25664)
Loss: 1.285 | Acc: 62.210% (19947/32064)
Loss: 1.286 | Acc: 62.198% (23924/38464)
Loss: 1.284 | Acc: 62.239% (27923/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0826, Accuracy: 4242/10000 (42.42%)
torch.Size([100, 10])
Test set: Average loss: 2.0826, Accuracy: 4242/10000 (42.42%)

Epoch: 50
Loss: 1.221 | Acc: 68.750% (44/64)
Loss: 2.145 | Acc: 24.923% (1611/6464)
Loss: 2.053 | Acc: 31.678% (4075/12864)
Loss: 2.011 | Acc: 34.442% (6635/19264)
Loss: 1.992 | Acc: 35.899% (9213/25664)
Loss: 1.976 | Acc: 37.038% (11876/32064)
Loss: 1.964 | Acc: 37.786% (14534/38464)
Loss: 1.955 | Acc: 38.454% (17252/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0679, Accuracy: 3369/10000 (33.69%)

Epoch: 51
Loss: 1.950 | Acc: 39.062% (25/64)
Loss: 1.893 | Acc: 42.358% (2738/6464)
Loss: 1.897 | Acc: 42.257% (5436/12864)
Loss: 1.894 | Acc: 42.291% (8147/19264)
Loss: 1.889 | Acc: 42.546% (10919/25664)
Loss: 1.886 | Acc: 42.777% (13716/32064)
Loss: 1.884 | Acc: 42.973% (16529/38464)
Loss: 1.883 | Acc: 43.041% (19310/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0068, Accuracy: 3675/10000 (36.75%)

Epoch: 52
Loss: 1.621 | Acc: 50.000% (32/64)
Loss: 1.861 | Acc: 43.982% (2843/6464)
Loss: 1.865 | Acc: 44.045% (5666/12864)
Loss: 1.864 | Acc: 44.051% (8486/19264)
Loss: 1.871 | Acc: 43.672% (11208/25664)
Loss: 1.870 | Acc: 43.688% (14008/32064)
Loss: 1.869 | Acc: 43.799% (16847/38464)
Loss: 1.870 | Acc: 43.819% (19659/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0889, Accuracy: 3448/10000 (34.48%)

Epoch: 53
Loss: 1.767 | Acc: 42.188% (27/64)
Loss: 1.853 | Acc: 44.647% (2886/6464)
Loss: 1.856 | Acc: 44.543% (5730/12864)
Loss: 1.864 | Acc: 44.129% (8501/19264)
Loss: 1.868 | Acc: 43.918% (11271/25664)
Loss: 1.871 | Acc: 43.797% (14043/32064)
Loss: 1.871 | Acc: 43.820% (16855/38464)
Loss: 1.872 | Acc: 43.797% (19649/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2969, Accuracy: 2795/10000 (27.95%)

Epoch: 54
Loss: 1.764 | Acc: 45.312% (29/64)
Loss: 1.866 | Acc: 43.704% (2825/6464)
Loss: 1.869 | Acc: 43.797% (5634/12864)
Loss: 1.868 | Acc: 44.015% (8479/19264)
Loss: 1.863 | Acc: 44.171% (11336/25664)
Loss: 1.866 | Acc: 43.987% (14104/32064)
Loss: 1.866 | Acc: 44.023% (16933/38464)
Loss: 1.866 | Acc: 43.968% (19726/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0331, Accuracy: 3728/10000 (37.28%)

Epoch: 55
Loss: 1.753 | Acc: 48.438% (31/64)
Loss: 1.855 | Acc: 44.090% (2850/6464)
Loss: 1.856 | Acc: 44.473% (5721/12864)
Loss: 1.854 | Acc: 44.669% (8605/19264)
Loss: 1.859 | Acc: 44.346% (11381/25664)
Loss: 1.859 | Acc: 44.439% (14249/32064)
Loss: 1.858 | Acc: 44.486% (17111/38464)
Loss: 1.861 | Acc: 44.345% (19895/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0245, Accuracy: 3793/10000 (37.93%)

Epoch: 56
Loss: 2.146 | Acc: 34.375% (22/64)
Loss: 1.865 | Acc: 44.508% (2877/6464)
Loss: 1.857 | Acc: 44.698% (5750/12864)
Loss: 1.859 | Acc: 44.658% (8603/19264)
Loss: 1.868 | Acc: 44.042% (11303/25664)
Loss: 1.865 | Acc: 44.130% (14150/32064)
Loss: 1.862 | Acc: 44.293% (17037/38464)
Loss: 1.863 | Acc: 44.301% (19875/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9901, Accuracy: 3912/10000 (39.12%)

Epoch: 57
Loss: 2.031 | Acc: 39.062% (25/64)
Loss: 1.843 | Acc: 44.926% (2904/6464)
Loss: 1.850 | Acc: 44.683% (5748/12864)
Loss: 1.858 | Acc: 44.492% (8571/19264)
Loss: 1.858 | Acc: 44.553% (11434/25664)
Loss: 1.857 | Acc: 44.611% (14304/32064)
Loss: 1.860 | Acc: 44.535% (17130/38464)
Loss: 1.857 | Acc: 44.601% (20010/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9947, Accuracy: 3763/10000 (37.63%)

Epoch: 58
Loss: 1.656 | Acc: 50.000% (32/64)
Loss: 1.845 | Acc: 45.142% (2918/6464)
Loss: 1.851 | Acc: 44.893% (5775/12864)
Loss: 1.854 | Acc: 44.741% (8619/19264)
Loss: 1.854 | Acc: 44.767% (11489/25664)
Loss: 1.854 | Acc: 44.764% (14353/32064)
Loss: 1.855 | Acc: 44.715% (17199/38464)
Loss: 1.854 | Acc: 44.793% (20096/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9636, Accuracy: 3900/10000 (39.00%)

Epoch: 59
Loss: 1.804 | Acc: 50.000% (32/64)
Loss: 1.854 | Acc: 45.096% (2915/6464)
Loss: 1.845 | Acc: 45.219% (5817/12864)
Loss: 1.849 | Acc: 45.027% (8674/19264)
Loss: 1.846 | Acc: 45.118% (11579/25664)
Loss: 1.849 | Acc: 44.901% (14397/32064)
Loss: 1.851 | Acc: 44.803% (17233/38464)
Loss: 1.853 | Acc: 44.677% (20044/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9869, Accuracy: 3786/10000 (37.86%)

Epoch: 60
Loss: 2.010 | Acc: 37.500% (24/64)
Loss: 1.851 | Acc: 44.601% (2883/6464)
Loss: 1.860 | Acc: 44.380% (5709/12864)
Loss: 1.861 | Acc: 44.285% (8531/19264)
Loss: 1.857 | Acc: 44.580% (11441/25664)
Loss: 1.855 | Acc: 44.645% (14315/32064)
Loss: 1.855 | Acc: 44.670% (17182/38464)
Loss: 1.856 | Acc: 44.650% (20032/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1423, Accuracy: 3331/10000 (33.31%)

Epoch: 61
Loss: 1.831 | Acc: 43.750% (28/64)
Loss: 1.835 | Acc: 45.297% (2928/6464)
Loss: 1.835 | Acc: 45.561% (5861/12864)
Loss: 1.842 | Acc: 45.100% (8688/19264)
Loss: 1.850 | Acc: 44.802% (11498/25664)
Loss: 1.849 | Acc: 44.829% (14374/32064)
Loss: 1.848 | Acc: 44.899% (17270/38464)
Loss: 1.848 | Acc: 44.934% (20159/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9762, Accuracy: 3893/10000 (38.93%)

Epoch: 62
Loss: 1.763 | Acc: 50.000% (32/64)
Loss: 1.832 | Acc: 45.668% (2952/6464)
Loss: 1.837 | Acc: 45.491% (5852/12864)
Loss: 1.839 | Acc: 45.499% (8765/19264)
Loss: 1.837 | Acc: 45.507% (11679/25664)
Loss: 1.844 | Acc: 45.238% (14505/32064)
Loss: 1.845 | Acc: 45.250% (17405/38464)
Loss: 1.846 | Acc: 45.248% (20300/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1124, Accuracy: 3436/10000 (34.36%)

Epoch: 63
Loss: 1.695 | Acc: 51.562% (33/64)
Loss: 1.829 | Acc: 45.622% (2949/6464)
Loss: 1.831 | Acc: 45.732% (5883/12864)
Loss: 1.826 | Acc: 46.018% (8865/19264)
Loss: 1.833 | Acc: 45.776% (11748/25664)
Loss: 1.839 | Acc: 45.493% (14587/32064)
Loss: 1.844 | Acc: 45.250% (17405/38464)
Loss: 1.845 | Acc: 45.217% (20286/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9634, Accuracy: 3990/10000 (39.90%)

Epoch: 64
Loss: 1.903 | Acc: 39.062% (25/64)
Loss: 1.836 | Acc: 45.436% (2937/6464)
Loss: 1.839 | Acc: 45.297% (5827/12864)
Loss: 1.833 | Acc: 45.650% (8794/19264)
Loss: 1.837 | Acc: 45.535% (11686/25664)
Loss: 1.838 | Acc: 45.506% (14591/32064)
Loss: 1.837 | Acc: 45.523% (17510/38464)
Loss: 1.840 | Acc: 45.426% (20380/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9626, Accuracy: 3866/10000 (38.66%)

Epoch: 65
Loss: 1.617 | Acc: 56.250% (36/64)
Loss: 1.830 | Acc: 45.560% (2945/6464)
Loss: 1.824 | Acc: 45.958% (5912/12864)
Loss: 1.836 | Acc: 45.489% (8763/19264)
Loss: 1.838 | Acc: 45.348% (11638/25664)
Loss: 1.841 | Acc: 45.241% (14506/32064)
Loss: 1.843 | Acc: 45.214% (17391/38464)
Loss: 1.839 | Acc: 45.375% (20357/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0327, Accuracy: 3477/10000 (34.77%)

Epoch: 66
Loss: 1.978 | Acc: 39.062% (25/64)
Loss: 1.834 | Acc: 45.545% (2944/6464)
Loss: 1.839 | Acc: 45.320% (5830/12864)
Loss: 1.843 | Acc: 45.198% (8707/19264)
Loss: 1.840 | Acc: 45.418% (11656/25664)
Loss: 1.838 | Acc: 45.462% (14577/32064)
Loss: 1.837 | Acc: 45.479% (17493/38464)
Loss: 1.832 | Acc: 45.680% (20494/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0932, Accuracy: 3327/10000 (33.27%)

Epoch: 67
Loss: 1.650 | Acc: 56.250% (36/64)
Loss: 1.834 | Acc: 45.900% (2967/6464)
Loss: 1.835 | Acc: 45.903% (5905/12864)
Loss: 1.831 | Acc: 46.050% (8871/19264)
Loss: 1.831 | Acc: 46.100% (11831/25664)
Loss: 1.828 | Acc: 46.195% (14812/32064)
Loss: 1.828 | Acc: 46.108% (17735/38464)
Loss: 1.827 | Acc: 46.122% (20692/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0772, Accuracy: 3633/10000 (36.33%)

Epoch: 68
Loss: 1.892 | Acc: 40.625% (26/64)
Loss: 1.835 | Acc: 45.545% (2944/6464)
Loss: 1.818 | Acc: 46.222% (5946/12864)
Loss: 1.825 | Acc: 46.060% (8873/19264)
Loss: 1.816 | Acc: 46.489% (11931/25664)
Loss: 1.816 | Acc: 46.526% (14918/32064)
Loss: 1.822 | Acc: 46.306% (17811/38464)
Loss: 1.821 | Acc: 46.353% (20796/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9102, Accuracy: 4259/10000 (42.59%)

Epoch: 69
Loss: 1.852 | Acc: 45.312% (29/64)
Loss: 1.789 | Acc: 48.144% (3112/6464)
Loss: 1.793 | Acc: 47.738% (6141/12864)
Loss: 1.809 | Acc: 47.015% (9057/19264)
Loss: 1.815 | Acc: 46.793% (12009/25664)
Loss: 1.816 | Acc: 46.816% (15011/32064)
Loss: 1.817 | Acc: 46.766% (17988/38464)
Loss: 1.818 | Acc: 46.674% (20940/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1092, Accuracy: 3193/10000 (31.93%)

Epoch: 70
Loss: 1.952 | Acc: 35.938% (23/64)
Loss: 1.792 | Acc: 47.788% (3089/6464)
Loss: 1.799 | Acc: 47.396% (6097/12864)
Loss: 1.809 | Acc: 46.896% (9034/19264)
Loss: 1.810 | Acc: 46.976% (12056/25664)
Loss: 1.814 | Acc: 46.819% (15012/32064)
Loss: 1.815 | Acc: 46.753% (17983/38464)
Loss: 1.815 | Acc: 46.683% (20944/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9578, Accuracy: 3957/10000 (39.57%)

Epoch: 71
Loss: 1.769 | Acc: 45.312% (29/64)
Loss: 1.777 | Acc: 47.896% (3096/6464)
Loss: 1.791 | Acc: 47.349% (6091/12864)
Loss: 1.796 | Acc: 47.316% (9115/19264)
Loss: 1.801 | Acc: 47.280% (12134/25664)
Loss: 1.803 | Acc: 47.165% (15123/32064)
Loss: 1.804 | Acc: 47.161% (18140/38464)
Loss: 1.805 | Acc: 47.033% (21101/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9926, Accuracy: 3745/10000 (37.45%)

Epoch: 72
Loss: 1.828 | Acc: 43.750% (28/64)
Loss: 1.791 | Acc: 47.803% (3090/6464)
Loss: 1.805 | Acc: 47.124% (6062/12864)
Loss: 1.811 | Acc: 46.880% (9031/19264)
Loss: 1.807 | Acc: 46.957% (12051/25664)
Loss: 1.807 | Acc: 46.969% (15060/32064)
Loss: 1.802 | Acc: 47.226% (18165/38464)
Loss: 1.804 | Acc: 47.223% (21186/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9886, Accuracy: 3867/10000 (38.67%)

Epoch: 73
Loss: 1.693 | Acc: 50.000% (32/64)
Loss: 1.804 | Acc: 46.983% (3037/6464)
Loss: 1.795 | Acc: 47.629% (6127/12864)
Loss: 1.799 | Acc: 47.467% (9144/19264)
Loss: 1.801 | Acc: 47.397% (12164/25664)
Loss: 1.800 | Acc: 47.424% (15206/32064)
Loss: 1.799 | Acc: 47.509% (18274/38464)
Loss: 1.797 | Acc: 47.533% (21325/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9350, Accuracy: 4102/10000 (41.02%)

Epoch: 74
Loss: 1.833 | Acc: 43.750% (28/64)
Loss: 1.788 | Acc: 48.051% (3106/6464)
Loss: 1.788 | Acc: 47.971% (6171/12864)
Loss: 1.790 | Acc: 47.825% (9213/19264)
Loss: 1.792 | Acc: 47.748% (12254/25664)
Loss: 1.788 | Acc: 47.885% (15354/32064)
Loss: 1.792 | Acc: 47.665% (18334/38464)
Loss: 1.793 | Acc: 47.655% (21380/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8832, Accuracy: 4380/10000 (43.80%)

Epoch: 75
Loss: 1.589 | Acc: 53.125% (34/64)
Loss: 1.756 | Acc: 49.257% (3184/6464)
Loss: 1.765 | Acc: 48.725% (6268/12864)
Loss: 1.776 | Acc: 48.173% (9280/19264)
Loss: 1.779 | Acc: 48.021% (12324/25664)
Loss: 1.780 | Acc: 47.982% (15385/32064)
Loss: 1.782 | Acc: 48.027% (18473/38464)
Loss: 1.783 | Acc: 48.021% (21544/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9041, Accuracy: 4286/10000 (42.86%)

Epoch: 76
Loss: 1.674 | Acc: 53.125% (34/64)
Loss: 1.765 | Acc: 48.886% (3160/6464)
Loss: 1.758 | Acc: 49.199% (6329/12864)
Loss: 1.769 | Acc: 48.900% (9420/19264)
Loss: 1.774 | Acc: 48.547% (12459/25664)
Loss: 1.776 | Acc: 48.394% (15517/32064)
Loss: 1.778 | Acc: 48.300% (18578/38464)
Loss: 1.775 | Acc: 48.424% (21725/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9121, Accuracy: 4207/10000 (42.07%)

Epoch: 77
Loss: 1.822 | Acc: 45.312% (29/64)
Loss: 1.773 | Acc: 48.283% (3121/6464)
Loss: 1.767 | Acc: 48.772% (6274/12864)
Loss: 1.769 | Acc: 48.609% (9364/19264)
Loss: 1.777 | Acc: 48.289% (12393/25664)
Loss: 1.773 | Acc: 48.456% (15537/32064)
Loss: 1.771 | Acc: 48.578% (18685/38464)
Loss: 1.771 | Acc: 48.607% (21807/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9105, Accuracy: 4241/10000 (42.41%)

Epoch: 78
Loss: 1.843 | Acc: 40.625% (26/64)
Loss: 1.763 | Acc: 48.623% (3143/6464)
Loss: 1.771 | Acc: 48.422% (6229/12864)
Loss: 1.763 | Acc: 48.744% (9390/19264)
Loss: 1.765 | Acc: 48.660% (12488/25664)
Loss: 1.761 | Acc: 48.752% (15632/32064)
Loss: 1.762 | Acc: 48.757% (18754/38464)
Loss: 1.764 | Acc: 48.738% (21866/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9716, Accuracy: 3897/10000 (38.97%)

Epoch: 79
Loss: 1.634 | Acc: 54.688% (35/64)
Loss: 1.751 | Acc: 49.505% (3200/6464)
Loss: 1.757 | Acc: 49.036% (6308/12864)
Loss: 1.750 | Acc: 49.460% (9528/19264)
Loss: 1.750 | Acc: 49.423% (12684/25664)
Loss: 1.752 | Acc: 49.401% (15840/32064)
Loss: 1.752 | Acc: 49.319% (18970/38464)
Loss: 1.751 | Acc: 49.391% (22159/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8823, Accuracy: 4363/10000 (43.63%)

Epoch: 80
Loss: 1.795 | Acc: 42.188% (27/64)
Loss: 1.760 | Acc: 48.793% (3154/6464)
Loss: 1.745 | Acc: 49.565% (6376/12864)
Loss: 1.740 | Acc: 49.735% (9581/19264)
Loss: 1.738 | Acc: 49.844% (12792/25664)
Loss: 1.741 | Acc: 49.651% (15920/32064)
Loss: 1.743 | Acc: 49.602% (19079/38464)
Loss: 1.745 | Acc: 49.548% (22229/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8761, Accuracy: 4487/10000 (44.87%)

Epoch: 81
Loss: 1.849 | Acc: 43.750% (28/64)
Loss: 1.727 | Acc: 49.412% (3194/6464)
Loss: 1.733 | Acc: 49.518% (6370/12864)
Loss: 1.733 | Acc: 49.792% (9592/19264)
Loss: 1.738 | Acc: 49.696% (12754/25664)
Loss: 1.736 | Acc: 49.763% (15956/32064)
Loss: 1.734 | Acc: 49.922% (19202/38464)
Loss: 1.735 | Acc: 49.857% (22368/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8953, Accuracy: 4363/10000 (43.63%)

Epoch: 82
Loss: 1.697 | Acc: 56.250% (36/64)
Loss: 1.731 | Acc: 49.505% (3200/6464)
Loss: 1.728 | Acc: 49.821% (6409/12864)
Loss: 1.724 | Acc: 50.218% (9674/19264)
Loss: 1.721 | Acc: 50.261% (12899/25664)
Loss: 1.722 | Acc: 50.321% (16135/32064)
Loss: 1.725 | Acc: 50.263% (19333/38464)
Loss: 1.724 | Acc: 50.363% (22595/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8859, Accuracy: 4442/10000 (44.42%)

Epoch: 83
Loss: 1.789 | Acc: 45.312% (29/64)
Loss: 1.686 | Acc: 51.779% (3347/6464)
Loss: 1.684 | Acc: 51.562% (6633/12864)
Loss: 1.691 | Acc: 51.417% (9905/19264)
Loss: 1.701 | Acc: 50.920% (13068/25664)
Loss: 1.702 | Acc: 50.986% (16348/32064)
Loss: 1.704 | Acc: 50.967% (19604/38464)
Loss: 1.705 | Acc: 50.983% (22873/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8834, Accuracy: 4470/10000 (44.70%)

Epoch: 84
Loss: 1.946 | Acc: 40.625% (26/64)
Loss: 1.700 | Acc: 51.191% (3309/6464)
Loss: 1.689 | Acc: 51.562% (6633/12864)
Loss: 1.696 | Acc: 51.246% (9872/19264)
Loss: 1.702 | Acc: 50.869% (13055/25664)
Loss: 1.700 | Acc: 50.998% (16352/32064)
Loss: 1.699 | Acc: 51.024% (19626/38464)
Loss: 1.697 | Acc: 51.208% (22974/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8783, Accuracy: 4475/10000 (44.75%)

Epoch: 85
Loss: 1.640 | Acc: 57.812% (37/64)
Loss: 1.685 | Acc: 51.346% (3319/6464)
Loss: 1.679 | Acc: 51.765% (6659/12864)
Loss: 1.670 | Acc: 52.014% (10020/19264)
Loss: 1.669 | Acc: 52.030% (13353/25664)
Loss: 1.671 | Acc: 52.040% (16686/32064)
Loss: 1.676 | Acc: 51.861% (19948/38464)
Loss: 1.681 | Acc: 51.656% (23175/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9325, Accuracy: 4188/10000 (41.88%)

Epoch: 86
Loss: 1.669 | Acc: 51.562% (33/64)
Loss: 1.645 | Acc: 53.001% (3426/6464)
Loss: 1.648 | Acc: 52.744% (6785/12864)
Loss: 1.645 | Acc: 52.829% (10177/19264)
Loss: 1.652 | Acc: 52.576% (13493/25664)
Loss: 1.658 | Acc: 52.464% (16822/32064)
Loss: 1.664 | Acc: 52.298% (20116/38464)
Loss: 1.662 | Acc: 52.349% (23486/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9005, Accuracy: 4485/10000 (44.85%)

Epoch: 87
Loss: 1.377 | Acc: 65.625% (42/64)
Loss: 1.623 | Acc: 53.481% (3457/6464)
Loss: 1.627 | Acc: 53.374% (6866/12864)
Loss: 1.640 | Acc: 52.855% (10182/19264)
Loss: 1.641 | Acc: 52.774% (13544/25664)
Loss: 1.638 | Acc: 52.944% (16976/32064)
Loss: 1.638 | Acc: 53.039% (20401/38464)
Loss: 1.637 | Acc: 53.116% (23830/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8997, Accuracy: 4551/10000 (45.51%)

Epoch: 88
Loss: 1.682 | Acc: 53.125% (34/64)
Loss: 1.618 | Acc: 53.636% (3467/6464)
Loss: 1.617 | Acc: 53.786% (6919/12864)
Loss: 1.620 | Acc: 53.468% (10300/19264)
Loss: 1.620 | Acc: 53.491% (13728/25664)
Loss: 1.622 | Acc: 53.350% (17106/32064)
Loss: 1.614 | Acc: 53.650% (20636/38464)
Loss: 1.614 | Acc: 53.727% (24104/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9216, Accuracy: 4429/10000 (44.29%)

Epoch: 89
Loss: 1.485 | Acc: 56.250% (36/64)
Loss: 1.590 | Acc: 53.976% (3489/6464)
Loss: 1.566 | Acc: 55.053% (7082/12864)
Loss: 1.574 | Acc: 54.833% (10563/19264)
Loss: 1.578 | Acc: 54.645% (14024/25664)
Loss: 1.576 | Acc: 54.725% (17547/32064)
Loss: 1.580 | Acc: 54.552% (20983/38464)
Loss: 1.584 | Acc: 54.382% (24398/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9133, Accuracy: 4564/10000 (45.64%)

Epoch: 90
Loss: 1.639 | Acc: 53.125% (34/64)
Loss: 1.528 | Acc: 56.265% (3637/6464)
Loss: 1.545 | Acc: 55.372% (7123/12864)
Loss: 1.554 | Acc: 55.139% (10622/19264)
Loss: 1.553 | Acc: 55.132% (14149/25664)
Loss: 1.556 | Acc: 55.006% (17637/32064)
Loss: 1.558 | Acc: 54.999% (21155/38464)
Loss: 1.557 | Acc: 55.098% (24719/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9437, Accuracy: 4487/10000 (44.87%)

Epoch: 91
Loss: 1.505 | Acc: 60.938% (39/64)
Loss: 1.512 | Acc: 56.606% (3659/6464)
Loss: 1.518 | Acc: 56.367% (7251/12864)
Loss: 1.517 | Acc: 56.260% (10838/19264)
Loss: 1.515 | Acc: 56.367% (14466/25664)
Loss: 1.517 | Acc: 56.241% (18033/32064)
Loss: 1.517 | Acc: 56.299% (21655/38464)
Loss: 1.516 | Acc: 56.393% (25300/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9540, Accuracy: 4484/10000 (44.84%)

Epoch: 92
Loss: 1.445 | Acc: 59.375% (38/64)
Loss: 1.457 | Acc: 57.735% (3732/6464)
Loss: 1.446 | Acc: 58.287% (7498/12864)
Loss: 1.453 | Acc: 57.973% (11168/19264)
Loss: 1.458 | Acc: 57.875% (14853/25664)
Loss: 1.468 | Acc: 57.532% (18447/32064)
Loss: 1.466 | Acc: 57.584% (22149/38464)
Loss: 1.467 | Acc: 57.527% (25809/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0078, Accuracy: 4407/10000 (44.07%)

Epoch: 93
Loss: 1.414 | Acc: 60.938% (39/64)
Loss: 1.411 | Acc: 58.586% (3787/6464)
Loss: 1.397 | Acc: 59.484% (7652/12864)
Loss: 1.400 | Acc: 59.375% (11438/19264)
Loss: 1.404 | Acc: 59.172% (15186/25664)
Loss: 1.403 | Acc: 59.141% (18963/32064)
Loss: 1.411 | Acc: 58.850% (22636/38464)
Loss: 1.412 | Acc: 58.831% (26394/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0175, Accuracy: 4386/10000 (43.86%)

Epoch: 94
Loss: 1.308 | Acc: 57.812% (37/64)
Loss: 1.329 | Acc: 61.402% (3969/6464)
Loss: 1.342 | Acc: 60.821% (7824/12864)
Loss: 1.349 | Acc: 60.527% (11660/19264)
Loss: 1.352 | Acc: 60.544% (15538/25664)
Loss: 1.350 | Acc: 60.548% (19414/32064)
Loss: 1.351 | Acc: 60.548% (23289/38464)
Loss: 1.351 | Acc: 60.514% (27149/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0965, Accuracy: 4282/10000 (42.82%)

Epoch: 95
Loss: 1.120 | Acc: 64.062% (41/64)
Loss: 1.272 | Acc: 62.376% (4032/6464)
Loss: 1.282 | Acc: 62.111% (7990/12864)
Loss: 1.288 | Acc: 61.986% (11941/19264)
Loss: 1.292 | Acc: 61.873% (15879/25664)
Loss: 1.295 | Acc: 61.783% (19810/32064)
Loss: 1.297 | Acc: 61.798% (23770/38464)
Loss: 1.293 | Acc: 61.992% (27812/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1666, Accuracy: 4216/10000 (42.16%)

Epoch: 96
Loss: 1.159 | Acc: 67.188% (43/64)
Loss: 1.243 | Acc: 63.243% (4088/6464)
Loss: 1.232 | Acc: 63.596% (8181/12864)
Loss: 1.231 | Acc: 63.663% (12264/19264)
Loss: 1.231 | Acc: 63.533% (16305/25664)
Loss: 1.229 | Acc: 63.638% (20405/32064)
Loss: 1.227 | Acc: 63.743% (24518/38464)
Loss: 1.226 | Acc: 63.726% (28590/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1866, Accuracy: 4212/10000 (42.12%)

Epoch: 97
Loss: 1.173 | Acc: 64.062% (41/64)
Loss: 1.148 | Acc: 65.780% (4252/6464)
Loss: 1.152 | Acc: 65.703% (8452/12864)
Loss: 1.157 | Acc: 65.454% (12609/19264)
Loss: 1.156 | Acc: 65.500% (16810/25664)
Loss: 1.156 | Acc: 65.603% (21035/32064)
Loss: 1.155 | Acc: 65.672% (25260/38464)
Loss: 1.159 | Acc: 65.585% (29424/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2188, Accuracy: 4122/10000 (41.22%)
torch.Size([100, 10])
Test set: Average loss: 2.2188, Accuracy: 4122/10000 (41.22%)

Epoch: 98
Loss: 0.930 | Acc: 75.000% (48/64)
Loss: 1.124 | Acc: 66.043% (4269/6464)
Loss: 1.135 | Acc: 66.021% (8493/12864)
Loss: 1.129 | Acc: 66.347% (12781/19264)
Loss: 1.129 | Acc: 66.365% (17032/25664)
Loss: 1.129 | Acc: 66.305% (21260/32064)
Loss: 1.125 | Acc: 66.457% (25562/38464)
Loss: 1.124 | Acc: 66.494% (29832/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2348, Accuracy: 4113/10000 (41.13%)
torch.Size([100, 10])
Test set: Average loss: 2.2348, Accuracy: 4113/10000 (41.13%)

Epoch: 99
Loss: 1.175 | Acc: 65.625% (42/64)
Loss: 1.081 | Acc: 67.775% (4381/6464)
Loss: 1.094 | Acc: 67.312% (8659/12864)
Loss: 1.090 | Acc: 67.426% (12989/19264)
Loss: 1.094 | Acc: 67.332% (17280/25664)
Loss: 1.097 | Acc: 67.222% (21554/32064)
Loss: 1.095 | Acc: 67.299% (25886/38464)
Loss: 1.098 | Acc: 67.306% (30196/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2387, Accuracy: 4090/10000 (40.90%)
torch.Size([100, 10])
Test set: Average loss: 2.2387, Accuracy: 4090/10000 (40.90%)

Epoch: 100
Loss: 1.169 | Acc: 59.375% (38/64)
Loss: 2.176 | Acc: 23.670% (1530/6464)
Loss: 2.084 | Acc: 29.882% (3844/12864)
Loss: 2.027 | Acc: 33.633% (6479/19264)
Loss: 1.991 | Acc: 35.805% (9189/25664)
Loss: 1.972 | Acc: 37.095% (11894/32064)
Loss: 1.954 | Acc: 38.137% (14669/38464)
Loss: 1.942 | Acc: 38.938% (17469/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0248, Accuracy: 3728/10000 (37.28%)

Epoch: 101
Loss: 1.966 | Acc: 39.062% (25/64)
Loss: 1.843 | Acc: 45.220% (2923/6464)
Loss: 1.847 | Acc: 45.009% (5790/12864)
Loss: 1.844 | Acc: 45.146% (8697/19264)
Loss: 1.849 | Acc: 44.892% (11521/25664)
Loss: 1.848 | Acc: 44.789% (14361/32064)
Loss: 1.848 | Acc: 44.824% (17241/38464)
Loss: 1.851 | Acc: 44.715% (20061/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0530, Accuracy: 3416/10000 (34.16%)

Epoch: 102
Loss: 1.852 | Acc: 42.188% (27/64)
Loss: 1.844 | Acc: 45.127% (2917/6464)
Loss: 1.845 | Acc: 44.916% (5778/12864)
Loss: 1.847 | Acc: 44.830% (8636/19264)
Loss: 1.843 | Acc: 45.106% (11576/25664)
Loss: 1.842 | Acc: 45.157% (14479/32064)
Loss: 1.846 | Acc: 44.980% (17301/38464)
Loss: 1.849 | Acc: 44.867% (20129/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1639, Accuracy: 3319/10000 (33.19%)

Epoch: 103
Loss: 1.972 | Acc: 37.500% (24/64)
Loss: 1.855 | Acc: 44.647% (2886/6464)
Loss: 1.851 | Acc: 44.729% (5754/12864)
Loss: 1.848 | Acc: 44.871% (8644/19264)
Loss: 1.847 | Acc: 45.012% (11552/25664)
Loss: 1.844 | Acc: 45.231% (14503/32064)
Loss: 1.844 | Acc: 45.323% (17433/38464)
Loss: 1.845 | Acc: 45.261% (20306/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0589, Accuracy: 3492/10000 (34.92%)

Epoch: 104
Loss: 1.844 | Acc: 45.312% (29/64)
Loss: 1.821 | Acc: 46.349% (2996/6464)
Loss: 1.830 | Acc: 45.779% (5889/12864)
Loss: 1.830 | Acc: 45.728% (8809/19264)
Loss: 1.835 | Acc: 45.644% (11714/25664)
Loss: 1.838 | Acc: 45.584% (14616/32064)
Loss: 1.844 | Acc: 45.364% (17449/38464)
Loss: 1.843 | Acc: 45.357% (20349/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1947, Accuracy: 3041/10000 (30.41%)

Epoch: 105
Loss: 2.108 | Acc: 31.250% (20/64)
Loss: 1.857 | Acc: 44.802% (2896/6464)
Loss: 1.834 | Acc: 45.561% (5861/12864)
Loss: 1.841 | Acc: 45.131% (8694/19264)
Loss: 1.837 | Acc: 45.289% (11623/25664)
Loss: 1.838 | Acc: 45.219% (14499/32064)
Loss: 1.840 | Acc: 45.229% (17397/38464)
Loss: 1.841 | Acc: 45.201% (20279/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2230, Accuracy: 2876/10000 (28.76%)

Epoch: 106
Loss: 2.117 | Acc: 32.812% (21/64)
Loss: 1.843 | Acc: 45.452% (2938/6464)
Loss: 1.854 | Acc: 44.963% (5784/12864)
Loss: 1.851 | Acc: 45.001% (8669/19264)
Loss: 1.850 | Acc: 45.051% (11562/25664)
Loss: 1.848 | Acc: 45.163% (14481/32064)
Loss: 1.849 | Acc: 45.115% (17353/38464)
Loss: 1.845 | Acc: 45.199% (20278/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0472, Accuracy: 3590/10000 (35.90%)

Epoch: 107
Loss: 1.977 | Acc: 37.500% (24/64)
Loss: 1.824 | Acc: 45.823% (2962/6464)
Loss: 1.832 | Acc: 45.600% (5866/12864)
Loss: 1.829 | Acc: 45.826% (8828/19264)
Loss: 1.836 | Acc: 45.496% (11676/25664)
Loss: 1.835 | Acc: 45.574% (14613/32064)
Loss: 1.838 | Acc: 45.458% (17485/38464)
Loss: 1.839 | Acc: 45.402% (20369/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1019, Accuracy: 3409/10000 (34.09%)

Epoch: 108
Loss: 1.971 | Acc: 39.062% (25/64)
Loss: 1.829 | Acc: 46.179% (2985/6464)
Loss: 1.824 | Acc: 46.222% (5946/12864)
Loss: 1.825 | Acc: 46.070% (8875/19264)
Loss: 1.830 | Acc: 45.944% (11791/25664)
Loss: 1.832 | Acc: 45.734% (14664/32064)
Loss: 1.836 | Acc: 45.611% (17544/38464)
Loss: 1.837 | Acc: 45.587% (20452/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1133, Accuracy: 3318/10000 (33.18%)

Epoch: 109
Loss: 1.685 | Acc: 57.812% (37/64)
Loss: 1.840 | Acc: 45.699% (2954/6464)
Loss: 1.825 | Acc: 46.541% (5987/12864)
Loss: 1.830 | Acc: 46.159% (8892/19264)
Loss: 1.831 | Acc: 46.006% (11807/25664)
Loss: 1.835 | Acc: 45.771% (14676/32064)
Loss: 1.836 | Acc: 45.715% (17584/38464)
Loss: 1.837 | Acc: 45.598% (20457/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9356, Accuracy: 4138/10000 (41.38%)

Epoch: 110
Loss: 1.803 | Acc: 43.750% (28/64)
Loss: 1.841 | Acc: 45.637% (2950/6464)
Loss: 1.833 | Acc: 45.857% (5899/12864)
Loss: 1.831 | Acc: 45.915% (8845/19264)
Loss: 1.830 | Acc: 45.952% (11793/25664)
Loss: 1.832 | Acc: 45.805% (14687/32064)
Loss: 1.832 | Acc: 45.817% (17623/38464)
Loss: 1.830 | Acc: 45.934% (20608/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9250, Accuracy: 4118/10000 (41.18%)

Epoch: 111
Loss: 1.815 | Acc: 42.188% (27/64)
Loss: 1.811 | Acc: 46.798% (3025/6464)
Loss: 1.816 | Acc: 46.502% (5982/12864)
Loss: 1.822 | Acc: 46.216% (8903/19264)
Loss: 1.824 | Acc: 46.139% (11841/25664)
Loss: 1.829 | Acc: 45.971% (14740/32064)
Loss: 1.831 | Acc: 45.866% (17642/38464)
Loss: 1.833 | Acc: 45.830% (20561/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9920, Accuracy: 3789/10000 (37.89%)

Epoch: 112
Loss: 1.796 | Acc: 42.188% (27/64)
Loss: 1.811 | Acc: 46.658% (3016/6464)
Loss: 1.819 | Acc: 46.377% (5966/12864)
Loss: 1.822 | Acc: 46.397% (8938/19264)
Loss: 1.827 | Acc: 46.185% (11853/25664)
Loss: 1.828 | Acc: 46.095% (14780/32064)
Loss: 1.832 | Acc: 45.910% (17659/38464)
Loss: 1.829 | Acc: 45.979% (20628/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9375, Accuracy: 4017/10000 (40.17%)

Epoch: 113
Loss: 1.643 | Acc: 57.812% (37/64)
Loss: 1.800 | Acc: 47.463% (3068/6464)
Loss: 1.811 | Acc: 46.642% (6000/12864)
Loss: 1.815 | Acc: 46.564% (8970/19264)
Loss: 1.818 | Acc: 46.287% (11879/25664)
Loss: 1.821 | Acc: 46.195% (14812/32064)
Loss: 1.826 | Acc: 45.991% (17690/38464)
Loss: 1.826 | Acc: 46.084% (20675/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0209, Accuracy: 3639/10000 (36.39%)

Epoch: 114
Loss: 1.768 | Acc: 46.875% (30/64)
Loss: 1.817 | Acc: 46.380% (2998/6464)
Loss: 1.821 | Acc: 45.950% (5911/12864)
Loss: 1.820 | Acc: 46.159% (8892/19264)
Loss: 1.818 | Acc: 46.287% (11879/25664)
Loss: 1.821 | Acc: 46.254% (14831/32064)
Loss: 1.823 | Acc: 46.139% (17747/38464)
Loss: 1.825 | Acc: 46.055% (20662/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9998, Accuracy: 3748/10000 (37.48%)

Epoch: 115
Loss: 1.796 | Acc: 48.438% (31/64)
Loss: 1.793 | Acc: 47.293% (3057/6464)
Loss: 1.815 | Acc: 46.704% (6008/12864)
Loss: 1.815 | Acc: 46.740% (9004/19264)
Loss: 1.818 | Acc: 46.649% (11972/25664)
Loss: 1.821 | Acc: 46.501% (14910/32064)
Loss: 1.819 | Acc: 46.573% (17914/38464)
Loss: 1.819 | Acc: 46.581% (20898/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9705, Accuracy: 3868/10000 (38.68%)

Epoch: 116
Loss: 1.623 | Acc: 53.125% (34/64)
Loss: 1.807 | Acc: 46.937% (3034/6464)
Loss: 1.808 | Acc: 47.030% (6050/12864)
Loss: 1.815 | Acc: 46.745% (9005/19264)
Loss: 1.816 | Acc: 46.774% (12004/25664)
Loss: 1.813 | Acc: 46.822% (15013/32064)
Loss: 1.813 | Acc: 46.852% (18021/38464)
Loss: 1.816 | Acc: 46.708% (20955/44864)
torch.Size([100, 10])
Test set: Average loss: 3.0633, Accuracy: 1635/10000 (16.35%)

Epoch: 117
Loss: 1.675 | Acc: 46.875% (30/64)
Loss: 1.803 | Acc: 46.442% (3002/6464)
Loss: 1.808 | Acc: 46.688% (6006/12864)
Loss: 1.812 | Acc: 46.704% (8997/19264)
Loss: 1.816 | Acc: 46.501% (11934/25664)
Loss: 1.818 | Acc: 46.457% (14896/32064)
Loss: 1.818 | Acc: 46.417% (17854/38464)
Loss: 1.816 | Acc: 46.503% (20863/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9821, Accuracy: 3940/10000 (39.40%)

Epoch: 118
Loss: 2.002 | Acc: 40.625% (26/64)
Loss: 1.795 | Acc: 47.525% (3072/6464)
Loss: 1.798 | Acc: 47.427% (6101/12864)
Loss: 1.804 | Acc: 47.223% (9097/19264)
Loss: 1.805 | Acc: 47.132% (12096/25664)
Loss: 1.806 | Acc: 47.047% (15085/32064)
Loss: 1.806 | Acc: 47.047% (18096/38464)
Loss: 1.807 | Acc: 47.002% (21087/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0463, Accuracy: 3571/10000 (35.71%)

Epoch: 119
Loss: 1.638 | Acc: 53.125% (34/64)
Loss: 1.816 | Acc: 46.581% (3011/6464)
Loss: 1.805 | Acc: 47.062% (6054/12864)
Loss: 1.794 | Acc: 47.462% (9143/19264)
Loss: 1.798 | Acc: 47.370% (12157/25664)
Loss: 1.801 | Acc: 47.318% (15172/32064)
Loss: 1.802 | Acc: 47.278% (18185/38464)
Loss: 1.805 | Acc: 47.149% (21153/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9634, Accuracy: 3988/10000 (39.88%)

Epoch: 120
Loss: 1.646 | Acc: 53.125% (34/64)
Loss: 1.812 | Acc: 46.890% (3031/6464)
Loss: 1.808 | Acc: 47.054% (6053/12864)
Loss: 1.800 | Acc: 47.316% (9115/19264)
Loss: 1.798 | Acc: 47.385% (12161/25664)
Loss: 1.799 | Acc: 47.471% (15221/32064)
Loss: 1.799 | Acc: 47.426% (18242/38464)
Loss: 1.802 | Acc: 47.274% (21209/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9719, Accuracy: 4080/10000 (40.80%)

Epoch: 121
Loss: 1.774 | Acc: 46.875% (30/64)
Loss: 1.792 | Acc: 47.927% (3098/6464)
Loss: 1.790 | Acc: 47.707% (6137/12864)
Loss: 1.787 | Acc: 47.882% (9224/19264)
Loss: 1.793 | Acc: 47.643% (12227/25664)
Loss: 1.790 | Acc: 47.680% (15288/32064)
Loss: 1.794 | Acc: 47.476% (18261/38464)
Loss: 1.795 | Acc: 47.486% (21304/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9518, Accuracy: 4134/10000 (41.34%)

Epoch: 122
Loss: 1.933 | Acc: 45.312% (29/64)
Loss: 1.788 | Acc: 47.788% (3089/6464)
Loss: 1.791 | Acc: 47.862% (6157/12864)
Loss: 1.788 | Acc: 48.017% (9250/19264)
Loss: 1.784 | Acc: 48.141% (12355/25664)
Loss: 1.787 | Acc: 48.035% (15402/32064)
Loss: 1.787 | Acc: 47.996% (18461/38464)
Loss: 1.789 | Acc: 47.876% (21479/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9046, Accuracy: 4345/10000 (43.45%)

Epoch: 123
Loss: 1.877 | Acc: 50.000% (32/64)
Loss: 1.770 | Acc: 48.283% (3121/6464)
Loss: 1.782 | Acc: 48.189% (6199/12864)
Loss: 1.781 | Acc: 48.178% (9281/19264)
Loss: 1.775 | Acc: 48.434% (12430/25664)
Loss: 1.775 | Acc: 48.363% (15507/32064)
Loss: 1.777 | Acc: 48.284% (18572/38464)
Loss: 1.781 | Acc: 48.203% (21626/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9562, Accuracy: 4019/10000 (40.19%)

Epoch: 124
Loss: 1.748 | Acc: 53.125% (34/64)
Loss: 1.766 | Acc: 48.685% (3147/6464)
Loss: 1.763 | Acc: 48.896% (6290/12864)
Loss: 1.768 | Acc: 48.827% (9406/19264)
Loss: 1.766 | Acc: 48.866% (12541/25664)
Loss: 1.770 | Acc: 48.653% (15600/32064)
Loss: 1.775 | Acc: 48.440% (18632/38464)
Loss: 1.778 | Acc: 48.317% (21677/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9447, Accuracy: 4067/10000 (40.67%)

Epoch: 125
Loss: 1.771 | Acc: 45.312% (29/64)
Loss: 1.777 | Acc: 48.252% (3119/6464)
Loss: 1.762 | Acc: 49.137% (6321/12864)
Loss: 1.766 | Acc: 48.925% (9425/19264)
Loss: 1.761 | Acc: 49.038% (12585/25664)
Loss: 1.769 | Acc: 48.771% (15638/32064)
Loss: 1.770 | Acc: 48.684% (18726/38464)
Loss: 1.770 | Acc: 48.687% (21843/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9244, Accuracy: 4146/10000 (41.46%)

Epoch: 126
Loss: 1.753 | Acc: 46.875% (30/64)
Loss: 1.740 | Acc: 49.629% (3208/6464)
Loss: 1.758 | Acc: 48.888% (6289/12864)
Loss: 1.762 | Acc: 48.868% (9414/19264)
Loss: 1.767 | Acc: 48.632% (12481/25664)
Loss: 1.771 | Acc: 48.469% (15541/32064)
Loss: 1.761 | Acc: 48.968% (18835/38464)
Loss: 1.763 | Acc: 48.879% (21929/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9245, Accuracy: 4264/10000 (42.64%)

Epoch: 127
Loss: 1.740 | Acc: 54.688% (35/64)
Loss: 1.756 | Acc: 48.809% (3155/6464)
Loss: 1.753 | Acc: 49.153% (6323/12864)
Loss: 1.758 | Acc: 48.936% (9427/19264)
Loss: 1.756 | Acc: 48.983% (12571/25664)
Loss: 1.758 | Acc: 48.940% (15692/32064)
Loss: 1.754 | Acc: 49.100% (18886/38464)
Loss: 1.752 | Acc: 49.220% (22082/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9627, Accuracy: 3924/10000 (39.24%)

Epoch: 128
Loss: 2.154 | Acc: 31.250% (20/64)
Loss: 1.719 | Acc: 50.650% (3274/6464)
Loss: 1.731 | Acc: 50.187% (6456/12864)
Loss: 1.732 | Acc: 50.182% (9667/19264)
Loss: 1.740 | Acc: 50.023% (12838/25664)
Loss: 1.741 | Acc: 49.991% (16029/32064)
Loss: 1.742 | Acc: 49.836% (19169/38464)
Loss: 1.744 | Acc: 49.744% (22317/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8969, Accuracy: 4377/10000 (43.77%)

Epoch: 129
Loss: 1.705 | Acc: 53.125% (34/64)
Loss: 1.724 | Acc: 50.743% (3280/6464)
Loss: 1.721 | Acc: 50.824% (6538/12864)
Loss: 1.723 | Acc: 50.592% (9746/19264)
Loss: 1.724 | Acc: 50.526% (12967/25664)
Loss: 1.733 | Acc: 50.128% (16073/32064)
Loss: 1.737 | Acc: 50.036% (19246/38464)
Loss: 1.738 | Acc: 49.924% (22398/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8999, Accuracy: 4328/10000 (43.28%)

Epoch: 130
Loss: 1.824 | Acc: 46.875% (30/64)
Loss: 1.714 | Acc: 51.114% (3304/6464)
Loss: 1.724 | Acc: 50.466% (6492/12864)
Loss: 1.728 | Acc: 50.265% (9683/19264)
Loss: 1.728 | Acc: 50.257% (12898/25664)
Loss: 1.728 | Acc: 50.243% (16110/32064)
Loss: 1.728 | Acc: 50.247% (19327/38464)
Loss: 1.726 | Acc: 50.361% (22594/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8806, Accuracy: 4498/10000 (44.98%)

Epoch: 131
Loss: 1.867 | Acc: 43.750% (28/64)
Loss: 1.691 | Acc: 51.640% (3338/6464)
Loss: 1.703 | Acc: 51.049% (6567/12864)
Loss: 1.704 | Acc: 51.189% (9861/19264)
Loss: 1.705 | Acc: 51.138% (13124/25664)
Loss: 1.709 | Acc: 51.035% (16364/32064)
Loss: 1.712 | Acc: 50.832% (19552/38464)
Loss: 1.716 | Acc: 50.709% (22750/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8902, Accuracy: 4435/10000 (44.35%)

Epoch: 132
Loss: 2.143 | Acc: 31.250% (20/64)
Loss: 1.689 | Acc: 51.810% (3349/6464)
Loss: 1.692 | Acc: 51.500% (6625/12864)
Loss: 1.697 | Acc: 51.220% (9867/19264)
Loss: 1.696 | Acc: 51.356% (13180/25664)
Loss: 1.698 | Acc: 51.191% (16414/32064)
Loss: 1.702 | Acc: 51.139% (19670/38464)
Loss: 1.702 | Acc: 51.135% (22941/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8848, Accuracy: 4464/10000 (44.64%)

Epoch: 133
Loss: 1.639 | Acc: 53.125% (34/64)
Loss: 1.641 | Acc: 53.202% (3439/6464)
Loss: 1.677 | Acc: 51.609% (6639/12864)
Loss: 1.694 | Acc: 51.106% (9845/19264)
Loss: 1.693 | Acc: 51.134% (13123/25664)
Loss: 1.693 | Acc: 51.226% (16425/32064)
Loss: 1.689 | Acc: 51.342% (19748/38464)
Loss: 1.687 | Acc: 51.493% (23102/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8819, Accuracy: 4560/10000 (45.60%)

Epoch: 134
Loss: 1.595 | Acc: 56.250% (36/64)
Loss: 1.656 | Acc: 52.754% (3410/6464)
Loss: 1.668 | Acc: 52.379% (6738/12864)
Loss: 1.673 | Acc: 52.128% (10042/19264)
Loss: 1.671 | Acc: 52.112% (13374/25664)
Loss: 1.672 | Acc: 52.136% (16717/32064)
Loss: 1.669 | Acc: 52.197% (20077/38464)
Loss: 1.670 | Acc: 52.151% (23397/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8885, Accuracy: 4562/10000 (45.62%)

Epoch: 135
Loss: 1.879 | Acc: 42.188% (27/64)
Loss: 1.651 | Acc: 52.336% (3383/6464)
Loss: 1.640 | Acc: 52.837% (6797/12864)
Loss: 1.642 | Acc: 52.923% (10195/19264)
Loss: 1.649 | Acc: 52.665% (13516/25664)
Loss: 1.649 | Acc: 52.688% (16894/32064)
Loss: 1.654 | Acc: 52.475% (20184/38464)
Loss: 1.657 | Acc: 52.385% (23502/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9497, Accuracy: 4237/10000 (42.37%)

Epoch: 136
Loss: 1.953 | Acc: 37.500% (24/64)
Loss: 1.632 | Acc: 53.017% (3427/6464)
Loss: 1.622 | Acc: 53.545% (6888/12864)
Loss: 1.622 | Acc: 53.473% (10301/19264)
Loss: 1.633 | Acc: 53.035% (13611/25664)
Loss: 1.635 | Acc: 52.922% (16969/32064)
Loss: 1.637 | Acc: 52.831% (20321/38464)
Loss: 1.635 | Acc: 53.043% (23797/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9070, Accuracy: 4458/10000 (44.58%)

Epoch: 137
Loss: 1.534 | Acc: 56.250% (36/64)
Loss: 1.579 | Acc: 54.904% (3549/6464)
Loss: 1.587 | Acc: 54.361% (6993/12864)
Loss: 1.600 | Acc: 53.997% (10402/19264)
Loss: 1.598 | Acc: 54.189% (13907/25664)
Loss: 1.598 | Acc: 54.195% (17377/32064)
Loss: 1.602 | Acc: 54.030% (20782/38464)
Loss: 1.605 | Acc: 53.988% (24221/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8985, Accuracy: 4473/10000 (44.73%)

Epoch: 138
Loss: 1.862 | Acc: 42.188% (27/64)
Loss: 1.565 | Acc: 55.306% (3575/6464)
Loss: 1.569 | Acc: 54.804% (7050/12864)
Loss: 1.572 | Acc: 54.688% (10535/19264)
Loss: 1.581 | Acc: 54.426% (13968/25664)
Loss: 1.580 | Acc: 54.513% (17479/32064)
Loss: 1.578 | Acc: 54.612% (21006/38464)
Loss: 1.577 | Acc: 54.679% (24531/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9072, Accuracy: 4428/10000 (44.28%)

Epoch: 139
Loss: 1.473 | Acc: 56.250% (36/64)
Loss: 1.517 | Acc: 56.451% (3649/6464)
Loss: 1.519 | Acc: 56.250% (7236/12864)
Loss: 1.524 | Acc: 56.172% (10821/19264)
Loss: 1.529 | Acc: 55.884% (14342/25664)
Loss: 1.538 | Acc: 55.714% (17864/32064)
Loss: 1.541 | Acc: 55.631% (21398/38464)
Loss: 1.545 | Acc: 55.477% (24889/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9287, Accuracy: 4465/10000 (44.65%)

Epoch: 140
Loss: 1.682 | Acc: 51.562% (33/64)
Loss: 1.492 | Acc: 56.807% (3672/6464)
Loss: 1.502 | Acc: 56.367% (7251/12864)
Loss: 1.503 | Acc: 56.624% (10908/19264)
Loss: 1.505 | Acc: 56.398% (14474/25664)
Loss: 1.504 | Acc: 56.521% (18123/32064)
Loss: 1.509 | Acc: 56.385% (21688/38464)
Loss: 1.509 | Acc: 56.451% (25326/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9819, Accuracy: 4431/10000 (44.31%)

Epoch: 141
Loss: 1.504 | Acc: 57.812% (37/64)
Loss: 1.437 | Acc: 58.571% (3786/6464)
Loss: 1.444 | Acc: 58.240% (7492/12864)
Loss: 1.446 | Acc: 58.202% (11212/19264)
Loss: 1.456 | Acc: 57.738% (14818/25664)
Loss: 1.458 | Acc: 57.759% (18520/32064)
Loss: 1.461 | Acc: 57.662% (22179/38464)
Loss: 1.463 | Acc: 57.632% (25856/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0060, Accuracy: 4391/10000 (43.91%)

Epoch: 142
Loss: 1.096 | Acc: 71.875% (46/64)
Loss: 1.408 | Acc: 58.648% (3791/6464)
Loss: 1.408 | Acc: 58.808% (7565/12864)
Loss: 1.417 | Acc: 58.570% (11283/19264)
Loss: 1.416 | Acc: 58.650% (15052/25664)
Loss: 1.418 | Acc: 58.673% (18813/32064)
Loss: 1.416 | Acc: 58.793% (22614/38464)
Loss: 1.417 | Acc: 58.789% (26375/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0282, Accuracy: 4321/10000 (43.21%)

Epoch: 143
Loss: 1.132 | Acc: 68.750% (44/64)
Loss: 1.352 | Acc: 60.334% (3900/6464)
Loss: 1.354 | Acc: 60.238% (7749/12864)
Loss: 1.349 | Acc: 60.450% (11645/19264)
Loss: 1.350 | Acc: 60.384% (15497/25664)
Loss: 1.350 | Acc: 60.554% (19416/32064)
Loss: 1.352 | Acc: 60.506% (23273/38464)
Loss: 1.352 | Acc: 60.427% (27110/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1046, Accuracy: 4199/10000 (41.99%)

Epoch: 144
Loss: 1.438 | Acc: 53.125% (34/64)
Loss: 1.282 | Acc: 62.206% (4021/6464)
Loss: 1.290 | Acc: 61.769% (7946/12864)
Loss: 1.286 | Acc: 61.981% (11940/19264)
Loss: 1.288 | Acc: 61.997% (15911/25664)
Loss: 1.287 | Acc: 62.032% (19890/32064)
Loss: 1.289 | Acc: 62.048% (23866/38464)
Loss: 1.292 | Acc: 61.990% (27811/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1878, Accuracy: 4198/10000 (41.98%)

Epoch: 145
Loss: 1.119 | Acc: 68.750% (44/64)
Loss: 1.217 | Acc: 63.769% (4122/6464)
Loss: 1.213 | Acc: 64.024% (8236/12864)
Loss: 1.210 | Acc: 64.011% (12331/19264)
Loss: 1.210 | Acc: 64.179% (16471/25664)
Loss: 1.212 | Acc: 64.197% (20584/32064)
Loss: 1.214 | Acc: 64.114% (24661/38464)
Loss: 1.215 | Acc: 64.185% (28796/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2612, Accuracy: 4109/10000 (41.09%)

Epoch: 146
Loss: 1.159 | Acc: 59.375% (38/64)
Loss: 1.124 | Acc: 66.352% (4289/6464)
Loss: 1.130 | Acc: 66.410% (8543/12864)
Loss: 1.140 | Acc: 66.071% (12728/19264)
Loss: 1.138 | Acc: 66.268% (17007/25664)
Loss: 1.141 | Acc: 66.271% (21249/32064)
Loss: 1.143 | Acc: 66.075% (25415/38464)
Loss: 1.145 | Acc: 65.962% (29593/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2754, Accuracy: 4098/10000 (40.98%)

Epoch: 147
Loss: 0.964 | Acc: 75.000% (48/64)
Loss: 1.080 | Acc: 67.481% (4362/6464)
Loss: 1.080 | Acc: 67.693% (8708/12864)
Loss: 1.088 | Acc: 67.312% (12967/19264)
Loss: 1.086 | Acc: 67.554% (17337/25664)
Loss: 1.087 | Acc: 67.543% (21657/32064)
Loss: 1.092 | Acc: 67.317% (25893/38464)
Loss: 1.089 | Acc: 67.410% (30243/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2985, Accuracy: 4025/10000 (40.25%)
torch.Size([100, 10])
Test set: Average loss: 2.2985, Accuracy: 4025/10000 (40.25%)

Epoch: 148
Loss: 0.895 | Acc: 71.875% (46/64)
Loss: 1.046 | Acc: 68.456% (4425/6464)
Loss: 1.056 | Acc: 68.338% (8791/12864)
Loss: 1.053 | Acc: 68.345% (13166/19264)
Loss: 1.046 | Acc: 68.692% (17629/25664)
Loss: 1.043 | Acc: 68.800% (22060/32064)
Loss: 1.045 | Acc: 68.719% (26432/38464)
Loss: 1.045 | Acc: 68.768% (30852/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3317, Accuracy: 3990/10000 (39.90%)
torch.Size([100, 10])
Test set: Average loss: 2.3317, Accuracy: 3990/10000 (39.90%)

Epoch: 149
Loss: 0.923 | Acc: 70.312% (45/64)
Loss: 1.025 | Acc: 69.415% (4487/6464)
Loss: 1.032 | Acc: 69.201% (8902/12864)
Loss: 1.036 | Acc: 69.145% (13320/19264)
Loss: 1.034 | Acc: 69.167% (17751/25664)
Loss: 1.034 | Acc: 69.271% (22211/32064)
Loss: 1.033 | Acc: 69.244% (26634/38464)
Loss: 1.032 | Acc: 69.236% (31062/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3408, Accuracy: 4002/10000 (40.02%)
torch.Size([100, 10])
Test set: Average loss: 2.3408, Accuracy: 4002/10000 (40.02%)

Epoch: 150
Loss: 1.192 | Acc: 60.938% (39/64)
Loss: 2.271 | Acc: 14.898% (963/6464)
Loss: 2.186 | Acc: 21.712% (2793/12864)
Loss: 2.124 | Acc: 26.692% (5142/19264)
Loss: 2.071 | Acc: 30.401% (7802/25664)
Loss: 2.034 | Acc: 32.887% (10545/32064)
Loss: 2.010 | Acc: 34.547% (13288/38464)
Loss: 1.989 | Acc: 35.935% (16122/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2467, Accuracy: 2462/10000 (24.62%)

Epoch: 151
Loss: 1.977 | Acc: 35.938% (23/64)
Loss: 1.854 | Acc: 44.400% (2870/6464)
Loss: 1.847 | Acc: 44.784% (5761/12864)
Loss: 1.852 | Acc: 44.560% (8584/19264)
Loss: 1.853 | Acc: 44.490% (11418/25664)
Loss: 1.855 | Acc: 44.558% (14287/32064)
Loss: 1.855 | Acc: 44.540% (17132/38464)
Loss: 1.856 | Acc: 44.575% (19998/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1474, Accuracy: 3429/10000 (34.29%)

Epoch: 152
Loss: 1.681 | Acc: 48.438% (31/64)
Loss: 1.822 | Acc: 46.086% (2979/6464)
Loss: 1.835 | Acc: 45.553% (5860/12864)
Loss: 1.841 | Acc: 45.271% (8721/19264)
Loss: 1.845 | Acc: 45.055% (11563/25664)
Loss: 1.847 | Acc: 44.998% (14428/32064)
Loss: 1.845 | Acc: 45.092% (17344/38464)
Loss: 1.845 | Acc: 45.148% (20255/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0851, Accuracy: 3349/10000 (33.49%)

Epoch: 153
Loss: 1.748 | Acc: 45.312% (29/64)
Loss: 1.845 | Acc: 44.601% (2883/6464)
Loss: 1.833 | Acc: 45.429% (5844/12864)
Loss: 1.842 | Acc: 45.276% (8722/19264)
Loss: 1.835 | Acc: 45.648% (11715/25664)
Loss: 1.837 | Acc: 45.518% (14595/32064)
Loss: 1.840 | Acc: 45.406% (17465/38464)
Loss: 1.840 | Acc: 45.440% (20386/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9505, Accuracy: 3998/10000 (39.98%)

Epoch: 154
Loss: 2.106 | Acc: 32.812% (21/64)
Loss: 1.825 | Acc: 45.823% (2962/6464)
Loss: 1.827 | Acc: 45.888% (5903/12864)
Loss: 1.830 | Acc: 45.769% (8817/19264)
Loss: 1.832 | Acc: 45.722% (11734/25664)
Loss: 1.830 | Acc: 45.740% (14666/32064)
Loss: 1.831 | Acc: 45.708% (17581/38464)
Loss: 1.832 | Acc: 45.709% (20507/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9994, Accuracy: 3769/10000 (37.69%)

Epoch: 155
Loss: 1.855 | Acc: 42.188% (27/64)
Loss: 1.841 | Acc: 45.637% (2950/6464)
Loss: 1.845 | Acc: 45.538% (5858/12864)
Loss: 1.834 | Acc: 46.003% (8862/19264)
Loss: 1.832 | Acc: 45.975% (11799/25664)
Loss: 1.831 | Acc: 46.017% (14755/32064)
Loss: 1.832 | Acc: 45.926% (17665/38464)
Loss: 1.832 | Acc: 45.783% (20540/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1653, Accuracy: 2933/10000 (29.33%)

Epoch: 156
Loss: 1.689 | Acc: 53.125% (34/64)
Loss: 1.835 | Acc: 45.730% (2956/6464)
Loss: 1.836 | Acc: 45.491% (5852/12864)
Loss: 1.828 | Acc: 45.832% (8829/19264)
Loss: 1.829 | Acc: 45.835% (11763/25664)
Loss: 1.833 | Acc: 45.615% (14626/32064)
Loss: 1.834 | Acc: 45.554% (17522/38464)
Loss: 1.834 | Acc: 45.555% (20438/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9523, Accuracy: 3928/10000 (39.28%)

Epoch: 157
Loss: 2.008 | Acc: 37.500% (24/64)
Loss: 1.836 | Acc: 45.575% (2946/6464)
Loss: 1.829 | Acc: 46.059% (5925/12864)
Loss: 1.832 | Acc: 45.920% (8846/19264)
Loss: 1.832 | Acc: 45.792% (11752/25664)
Loss: 1.833 | Acc: 45.783% (14680/32064)
Loss: 1.834 | Acc: 45.791% (17613/38464)
Loss: 1.834 | Acc: 45.776% (20537/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9113, Accuracy: 4331/10000 (43.31%)

Epoch: 158
Loss: 1.934 | Acc: 42.188% (27/64)
Loss: 1.824 | Acc: 46.055% (2977/6464)
Loss: 1.826 | Acc: 46.090% (5929/12864)
Loss: 1.830 | Acc: 45.889% (8840/19264)
Loss: 1.830 | Acc: 45.971% (11798/25664)
Loss: 1.829 | Acc: 45.983% (14744/32064)
Loss: 1.829 | Acc: 46.012% (17698/38464)
Loss: 1.829 | Acc: 46.064% (20666/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9720, Accuracy: 4057/10000 (40.57%)

Epoch: 159
Loss: 1.744 | Acc: 48.438% (31/64)
Loss: 1.814 | Acc: 46.519% (3007/6464)
Loss: 1.819 | Acc: 46.354% (5963/12864)
Loss: 1.820 | Acc: 46.237% (8907/19264)
Loss: 1.822 | Acc: 46.291% (11880/25664)
Loss: 1.823 | Acc: 46.329% (14855/32064)
Loss: 1.826 | Acc: 46.228% (17781/38464)
Loss: 1.827 | Acc: 46.197% (20726/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2000, Accuracy: 3197/10000 (31.97%)

Epoch: 160
Loss: 1.870 | Acc: 43.750% (28/64)
Loss: 1.817 | Acc: 46.225% (2988/6464)
Loss: 1.816 | Acc: 46.665% (6003/12864)
Loss: 1.815 | Acc: 46.480% (8954/19264)
Loss: 1.823 | Acc: 46.111% (11834/25664)
Loss: 1.821 | Acc: 46.229% (14823/32064)
Loss: 1.823 | Acc: 46.165% (17757/38464)
Loss: 1.825 | Acc: 46.093% (20679/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9634, Accuracy: 3870/10000 (38.70%)

Epoch: 161
Loss: 2.066 | Acc: 40.625% (26/64)
Loss: 1.825 | Acc: 46.473% (3004/6464)
Loss: 1.819 | Acc: 46.611% (5996/12864)
Loss: 1.827 | Acc: 46.242% (8908/19264)
Loss: 1.829 | Acc: 46.041% (11816/25664)
Loss: 1.829 | Acc: 46.083% (14776/32064)
Loss: 1.828 | Acc: 46.059% (17716/38464)
Loss: 1.827 | Acc: 46.088% (20677/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9542, Accuracy: 3933/10000 (39.33%)

Epoch: 162
Loss: 1.696 | Acc: 53.125% (34/64)
Loss: 1.821 | Acc: 46.086% (2979/6464)
Loss: 1.814 | Acc: 46.657% (6002/12864)
Loss: 1.816 | Acc: 46.512% (8960/19264)
Loss: 1.819 | Acc: 46.415% (11912/25664)
Loss: 1.825 | Acc: 46.186% (14809/32064)
Loss: 1.820 | Acc: 46.462% (17871/38464)
Loss: 1.821 | Acc: 46.436% (20833/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0974, Accuracy: 3365/10000 (33.65%)

Epoch: 163
Loss: 1.899 | Acc: 39.062% (25/64)
Loss: 1.803 | Acc: 47.014% (3039/6464)
Loss: 1.806 | Acc: 47.038% (6051/12864)
Loss: 1.811 | Acc: 46.844% (9024/19264)
Loss: 1.816 | Acc: 46.505% (11935/25664)
Loss: 1.819 | Acc: 46.451% (14894/32064)
Loss: 1.820 | Acc: 46.464% (17872/38464)
Loss: 1.822 | Acc: 46.431% (20831/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1056, Accuracy: 3399/10000 (33.99%)

Epoch: 164
Loss: 2.021 | Acc: 37.500% (24/64)
Loss: 1.817 | Acc: 46.658% (3016/6464)
Loss: 1.808 | Acc: 46.984% (6044/12864)
Loss: 1.810 | Acc: 46.906% (9036/19264)
Loss: 1.817 | Acc: 46.454% (11922/25664)
Loss: 1.816 | Acc: 46.529% (14919/32064)
Loss: 1.819 | Acc: 46.399% (17847/38464)
Loss: 1.821 | Acc: 46.327% (20784/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0283, Accuracy: 3705/10000 (37.05%)

Epoch: 165
Loss: 2.010 | Acc: 40.625% (26/64)
Loss: 1.827 | Acc: 46.395% (2999/6464)
Loss: 1.821 | Acc: 46.401% (5969/12864)
Loss: 1.819 | Acc: 46.465% (8951/19264)
Loss: 1.816 | Acc: 46.598% (11959/25664)
Loss: 1.812 | Acc: 46.816% (15011/32064)
Loss: 1.813 | Acc: 46.787% (17996/38464)
Loss: 1.813 | Acc: 46.810% (21001/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9863, Accuracy: 3771/10000 (37.71%)

Epoch: 166
Loss: 1.995 | Acc: 35.938% (23/64)
Loss: 1.798 | Acc: 47.416% (3065/6464)
Loss: 1.800 | Acc: 47.209% (6073/12864)
Loss: 1.801 | Acc: 47.026% (9059/19264)
Loss: 1.808 | Acc: 46.668% (11977/25664)
Loss: 1.809 | Acc: 46.638% (14954/32064)
Loss: 1.811 | Acc: 46.638% (17939/38464)
Loss: 1.812 | Acc: 46.672% (20939/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9375, Accuracy: 4174/10000 (41.74%)

Epoch: 167
Loss: 2.020 | Acc: 40.625% (26/64)
Loss: 1.806 | Acc: 46.782% (3024/6464)
Loss: 1.803 | Acc: 47.054% (6053/12864)
Loss: 1.806 | Acc: 47.140% (9081/19264)
Loss: 1.800 | Acc: 47.456% (12179/25664)
Loss: 1.804 | Acc: 47.302% (15167/32064)
Loss: 1.806 | Acc: 47.195% (18153/38464)
Loss: 1.807 | Acc: 47.082% (21123/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9344, Accuracy: 4182/10000 (41.82%)

Epoch: 168
Loss: 1.765 | Acc: 51.562% (33/64)
Loss: 1.804 | Acc: 47.571% (3075/6464)
Loss: 1.808 | Acc: 47.225% (6075/12864)
Loss: 1.804 | Acc: 47.353% (9122/19264)
Loss: 1.799 | Acc: 47.444% (12176/25664)
Loss: 1.801 | Acc: 47.374% (15190/32064)
Loss: 1.801 | Acc: 47.338% (18208/38464)
Loss: 1.803 | Acc: 47.236% (21192/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0025, Accuracy: 3718/10000 (37.18%)

Epoch: 169
Loss: 1.852 | Acc: 45.312% (29/64)
Loss: 1.804 | Acc: 47.509% (3071/6464)
Loss: 1.803 | Acc: 47.295% (6084/12864)
Loss: 1.801 | Acc: 47.451% (9141/19264)
Loss: 1.803 | Acc: 47.424% (12171/25664)
Loss: 1.803 | Acc: 47.362% (15186/32064)
Loss: 1.803 | Acc: 47.333% (18206/38464)
Loss: 1.803 | Acc: 47.319% (21229/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0198, Accuracy: 3644/10000 (36.44%)

Epoch: 170
Loss: 1.906 | Acc: 48.438% (31/64)
Loss: 1.790 | Acc: 47.679% (3082/6464)
Loss: 1.793 | Acc: 47.341% (6090/12864)
Loss: 1.795 | Acc: 47.161% (9085/19264)
Loss: 1.796 | Acc: 47.288% (12136/25664)
Loss: 1.796 | Acc: 47.427% (15207/32064)
Loss: 1.795 | Acc: 47.546% (18288/38464)
Loss: 1.797 | Acc: 47.463% (21294/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9532, Accuracy: 4066/10000 (40.66%)

Epoch: 171
Loss: 1.792 | Acc: 46.875% (30/64)
Loss: 1.772 | Acc: 48.654% (3145/6464)
Loss: 1.780 | Acc: 48.274% (6210/12864)
Loss: 1.781 | Acc: 48.199% (9285/19264)
Loss: 1.785 | Acc: 47.943% (12304/25664)
Loss: 1.784 | Acc: 48.060% (15410/32064)
Loss: 1.787 | Acc: 47.996% (18461/38464)
Loss: 1.790 | Acc: 47.842% (21464/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9743, Accuracy: 3842/10000 (38.42%)

Epoch: 172
Loss: 1.840 | Acc: 40.625% (26/64)
Loss: 1.783 | Acc: 48.082% (3108/6464)
Loss: 1.774 | Acc: 48.570% (6248/12864)
Loss: 1.772 | Acc: 48.619% (9366/19264)
Loss: 1.774 | Acc: 48.461% (12437/25664)
Loss: 1.779 | Acc: 48.194% (15453/32064)
Loss: 1.782 | Acc: 48.110% (18505/38464)
Loss: 1.783 | Acc: 48.114% (21586/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9193, Accuracy: 4213/10000 (42.13%)

Epoch: 173
Loss: 1.837 | Acc: 46.875% (30/64)
Loss: 1.800 | Acc: 47.231% (3053/6464)
Loss: 1.783 | Acc: 47.940% (6167/12864)
Loss: 1.780 | Acc: 48.131% (9272/19264)
Loss: 1.780 | Acc: 48.200% (12370/25664)
Loss: 1.776 | Acc: 48.425% (15527/32064)
Loss: 1.778 | Acc: 48.367% (18604/38464)
Loss: 1.776 | Acc: 48.498% (21758/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9057, Accuracy: 4213/10000 (42.13%)

Epoch: 174
Loss: 1.875 | Acc: 43.750% (28/64)
Loss: 1.758 | Acc: 48.871% (3159/6464)
Loss: 1.768 | Acc: 48.352% (6220/12864)
Loss: 1.759 | Acc: 48.837% (9408/19264)
Loss: 1.763 | Acc: 48.702% (12499/25664)
Loss: 1.768 | Acc: 48.556% (15569/32064)
Loss: 1.769 | Acc: 48.565% (18680/38464)
Loss: 1.771 | Acc: 48.518% (21767/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0101, Accuracy: 3769/10000 (37.69%)

Epoch: 175
Loss: 1.680 | Acc: 48.438% (31/64)
Loss: 1.757 | Acc: 48.855% (3158/6464)
Loss: 1.759 | Acc: 48.616% (6254/12864)
Loss: 1.756 | Acc: 48.785% (9398/19264)
Loss: 1.757 | Acc: 48.792% (12522/25664)
Loss: 1.754 | Acc: 49.080% (15737/32064)
Loss: 1.757 | Acc: 48.926% (18819/38464)
Loss: 1.760 | Acc: 48.819% (21902/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9103, Accuracy: 4241/10000 (42.41%)

Epoch: 176
Loss: 1.860 | Acc: 43.750% (28/64)
Loss: 1.762 | Acc: 48.700% (3148/6464)
Loss: 1.765 | Acc: 48.601% (6252/12864)
Loss: 1.763 | Acc: 48.806% (9402/19264)
Loss: 1.765 | Acc: 48.812% (12527/25664)
Loss: 1.765 | Acc: 48.877% (15672/32064)
Loss: 1.758 | Acc: 49.145% (18903/38464)
Loss: 1.755 | Acc: 49.351% (22141/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9975, Accuracy: 3803/10000 (38.03%)

Epoch: 177
Loss: 1.778 | Acc: 48.438% (31/64)
Loss: 1.762 | Acc: 49.010% (3168/6464)
Loss: 1.740 | Acc: 49.681% (6391/12864)
Loss: 1.744 | Acc: 49.574% (9550/19264)
Loss: 1.748 | Acc: 49.482% (12699/25664)
Loss: 1.750 | Acc: 49.542% (15885/32064)
Loss: 1.749 | Acc: 49.496% (19038/38464)
Loss: 1.747 | Acc: 49.621% (22262/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8973, Accuracy: 4296/10000 (42.96%)

Epoch: 178
Loss: 1.766 | Acc: 48.438% (31/64)
Loss: 1.707 | Acc: 51.098% (3303/6464)
Loss: 1.737 | Acc: 49.720% (6396/12864)
Loss: 1.732 | Acc: 49.896% (9612/19264)
Loss: 1.737 | Acc: 49.688% (12752/25664)
Loss: 1.736 | Acc: 49.860% (15987/32064)
Loss: 1.734 | Acc: 49.951% (19213/38464)
Loss: 1.738 | Acc: 49.746% (22318/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9819, Accuracy: 3902/10000 (39.02%)

Epoch: 179
Loss: 1.595 | Acc: 56.250% (36/64)
Loss: 1.728 | Acc: 49.629% (3208/6464)
Loss: 1.714 | Acc: 50.490% (6495/12864)
Loss: 1.720 | Acc: 50.353% (9700/19264)
Loss: 1.722 | Acc: 50.425% (12941/25664)
Loss: 1.721 | Acc: 50.593% (16222/32064)
Loss: 1.720 | Acc: 50.601% (19463/38464)
Loss: 1.725 | Acc: 50.450% (22634/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9133, Accuracy: 4256/10000 (42.56%)

Epoch: 180
Loss: 1.812 | Acc: 50.000% (32/64)
Loss: 1.703 | Acc: 51.191% (3309/6464)
Loss: 1.707 | Acc: 51.182% (6584/12864)
Loss: 1.703 | Acc: 51.313% (9885/19264)
Loss: 1.704 | Acc: 51.212% (13143/25664)
Loss: 1.713 | Acc: 50.851% (16305/32064)
Loss: 1.714 | Acc: 50.835% (19553/38464)
Loss: 1.715 | Acc: 50.785% (22784/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8849, Accuracy: 4521/10000 (45.21%)

Epoch: 181
Loss: 1.601 | Acc: 56.250% (36/64)
Loss: 1.684 | Acc: 51.779% (3347/6464)
Loss: 1.686 | Acc: 51.702% (6651/12864)
Loss: 1.684 | Acc: 51.884% (9995/19264)
Loss: 1.692 | Acc: 51.555% (13231/25664)
Loss: 1.696 | Acc: 51.294% (16447/32064)
Loss: 1.703 | Acc: 51.056% (19638/38464)
Loss: 1.705 | Acc: 50.970% (22867/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9284, Accuracy: 4158/10000 (41.58%)

Epoch: 182
Loss: 1.987 | Acc: 31.250% (20/64)
Loss: 1.702 | Acc: 50.665% (3275/6464)
Loss: 1.681 | Acc: 51.695% (6650/12864)
Loss: 1.677 | Acc: 51.723% (9964/19264)
Loss: 1.680 | Acc: 51.734% (13277/25664)
Loss: 1.687 | Acc: 51.500% (16513/32064)
Loss: 1.688 | Acc: 51.492% (19806/38464)
Loss: 1.690 | Acc: 51.406% (23063/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8667, Accuracy: 4563/10000 (45.63%)

Epoch: 183
Loss: 1.576 | Acc: 56.250% (36/64)
Loss: 1.664 | Acc: 52.228% (3376/6464)
Loss: 1.672 | Acc: 52.021% (6692/12864)
Loss: 1.672 | Acc: 52.134% (10043/19264)
Loss: 1.679 | Acc: 51.831% (13302/25664)
Loss: 1.683 | Acc: 51.656% (16563/32064)
Loss: 1.682 | Acc: 51.716% (19892/38464)
Loss: 1.682 | Acc: 51.801% (23240/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9450, Accuracy: 4390/10000 (43.90%)

Epoch: 184
Loss: 1.440 | Acc: 59.375% (38/64)
Loss: 1.639 | Acc: 52.939% (3422/6464)
Loss: 1.647 | Acc: 52.558% (6761/12864)
Loss: 1.650 | Acc: 52.440% (10102/19264)
Loss: 1.652 | Acc: 52.455% (13462/25664)
Loss: 1.653 | Acc: 52.492% (16831/32064)
Loss: 1.655 | Acc: 52.504% (20195/38464)
Loss: 1.660 | Acc: 52.398% (23508/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9148, Accuracy: 4439/10000 (44.39%)

Epoch: 185
Loss: 1.726 | Acc: 50.000% (32/64)
Loss: 1.616 | Acc: 54.100% (3497/6464)
Loss: 1.628 | Acc: 53.483% (6880/12864)
Loss: 1.633 | Acc: 53.312% (10270/19264)
Loss: 1.638 | Acc: 53.141% (13638/25664)
Loss: 1.641 | Acc: 53.025% (17002/32064)
Loss: 1.637 | Acc: 53.216% (20469/38464)
Loss: 1.641 | Acc: 53.109% (23827/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9126, Accuracy: 4413/10000 (44.13%)

Epoch: 186
Loss: 1.567 | Acc: 54.688% (35/64)
Loss: 1.607 | Acc: 53.728% (3473/6464)
Loss: 1.607 | Acc: 53.809% (6922/12864)
Loss: 1.613 | Acc: 53.494% (10305/19264)
Loss: 1.617 | Acc: 53.460% (13720/25664)
Loss: 1.616 | Acc: 53.537% (17166/32064)
Loss: 1.621 | Acc: 53.354% (20522/38464)
Loss: 1.621 | Acc: 53.359% (23939/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9248, Accuracy: 4427/10000 (44.27%)

Epoch: 187
Loss: 1.462 | Acc: 60.938% (39/64)
Loss: 1.606 | Acc: 53.527% (3460/6464)
Loss: 1.598 | Acc: 54.104% (6960/12864)
Loss: 1.592 | Acc: 54.418% (10483/19264)
Loss: 1.598 | Acc: 54.130% (13892/25664)
Loss: 1.596 | Acc: 54.101% (17347/32064)
Loss: 1.596 | Acc: 54.144% (20826/38464)
Loss: 1.595 | Acc: 54.266% (24346/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9574, Accuracy: 4303/10000 (43.03%)

Epoch: 188
Loss: 1.388 | Acc: 62.500% (40/64)
Loss: 1.557 | Acc: 55.074% (3560/6464)
Loss: 1.567 | Acc: 54.695% (7036/12864)
Loss: 1.566 | Acc: 54.797% (10556/19264)
Loss: 1.564 | Acc: 54.902% (14090/25664)
Loss: 1.565 | Acc: 54.859% (17590/32064)
Loss: 1.562 | Acc: 55.054% (21176/38464)
Loss: 1.568 | Acc: 54.806% (24588/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9211, Accuracy: 4447/10000 (44.47%)

Epoch: 189
Loss: 1.465 | Acc: 57.812% (37/64)
Loss: 1.512 | Acc: 56.467% (3650/6464)
Loss: 1.521 | Acc: 56.289% (7241/12864)
Loss: 1.520 | Acc: 56.364% (10858/19264)
Loss: 1.524 | Acc: 56.153% (14411/25664)
Loss: 1.529 | Acc: 56.022% (17963/32064)
Loss: 1.531 | Acc: 56.045% (21557/38464)
Loss: 1.534 | Acc: 55.876% (25068/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9829, Accuracy: 4436/10000 (44.36%)

Epoch: 190
Loss: 1.524 | Acc: 56.250% (36/64)
Loss: 1.473 | Acc: 57.256% (3701/6464)
Loss: 1.483 | Acc: 56.887% (7318/12864)
Loss: 1.484 | Acc: 56.863% (10954/19264)
Loss: 1.486 | Acc: 56.901% (14603/25664)
Loss: 1.486 | Acc: 56.977% (18269/32064)
Loss: 1.490 | Acc: 56.827% (21858/38464)
Loss: 1.490 | Acc: 56.894% (25525/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9964, Accuracy: 4364/10000 (43.64%)

Epoch: 191
Loss: 1.624 | Acc: 54.688% (35/64)
Loss: 1.430 | Acc: 58.447% (3778/6464)
Loss: 1.426 | Acc: 58.776% (7561/12864)
Loss: 1.434 | Acc: 58.337% (11238/19264)
Loss: 1.439 | Acc: 58.268% (14954/25664)
Loss: 1.439 | Acc: 58.296% (18692/32064)
Loss: 1.443 | Acc: 58.156% (22369/38464)
Loss: 1.446 | Acc: 58.087% (26060/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0089, Accuracy: 4352/10000 (43.52%)

Epoch: 192
Loss: 1.397 | Acc: 57.812% (37/64)
Loss: 1.419 | Acc: 58.277% (3767/6464)
Loss: 1.401 | Acc: 59.002% (7590/12864)
Loss: 1.386 | Acc: 59.671% (11495/19264)
Loss: 1.391 | Acc: 59.504% (15271/25664)
Loss: 1.397 | Acc: 59.306% (19016/32064)
Loss: 1.399 | Acc: 59.281% (22802/38464)
Loss: 1.398 | Acc: 59.295% (26602/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1021, Accuracy: 4345/10000 (43.45%)

Epoch: 193
Loss: 1.247 | Acc: 62.500% (40/64)
Loss: 1.329 | Acc: 60.999% (3943/6464)
Loss: 1.326 | Acc: 61.280% (7883/12864)
Loss: 1.321 | Acc: 61.374% (11823/19264)
Loss: 1.331 | Acc: 61.015% (15659/25664)
Loss: 1.328 | Acc: 61.118% (19597/32064)
Loss: 1.332 | Acc: 60.951% (23444/38464)
Loss: 1.333 | Acc: 60.944% (27342/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1424, Accuracy: 4198/10000 (41.98%)

Epoch: 194
Loss: 1.037 | Acc: 71.875% (46/64)
Loss: 1.273 | Acc: 62.283% (4026/6464)
Loss: 1.255 | Acc: 62.943% (8097/12864)
Loss: 1.252 | Acc: 63.061% (12148/19264)
Loss: 1.258 | Acc: 62.878% (16137/25664)
Loss: 1.265 | Acc: 62.712% (20108/32064)
Loss: 1.267 | Acc: 62.638% (24093/38464)
Loss: 1.266 | Acc: 62.672% (28117/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1866, Accuracy: 4223/10000 (42.23%)

Epoch: 195
Loss: 1.019 | Acc: 73.438% (47/64)
Loss: 1.196 | Acc: 64.387% (4162/6464)
Loss: 1.198 | Acc: 64.280% (8269/12864)
Loss: 1.198 | Acc: 64.410% (12408/19264)
Loss: 1.194 | Acc: 64.585% (16575/25664)
Loss: 1.195 | Acc: 64.518% (20687/32064)
Loss: 1.194 | Acc: 64.413% (24776/38464)
Loss: 1.194 | Acc: 64.482% (28929/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2333, Accuracy: 4159/10000 (41.59%)

Epoch: 196
Loss: 1.164 | Acc: 65.625% (42/64)
Loss: 1.121 | Acc: 66.569% (4303/6464)
Loss: 1.113 | Acc: 66.667% (8576/12864)
Loss: 1.128 | Acc: 66.040% (12722/19264)
Loss: 1.123 | Acc: 66.284% (17011/25664)
Loss: 1.121 | Acc: 66.352% (21275/32064)
Loss: 1.122 | Acc: 66.356% (25523/38464)
Loss: 1.123 | Acc: 66.365% (29774/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2889, Accuracy: 4137/10000 (41.37%)

Epoch: 197
Loss: 0.985 | Acc: 65.625% (42/64)
Loss: 1.059 | Acc: 68.363% (4419/6464)
Loss: 1.066 | Acc: 68.330% (8790/12864)
Loss: 1.059 | Acc: 68.501% (13196/19264)
Loss: 1.060 | Acc: 68.508% (17582/25664)
Loss: 1.060 | Acc: 68.391% (21929/32064)
Loss: 1.060 | Acc: 68.412% (26314/38464)
Loss: 1.061 | Acc: 68.277% (30632/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3444, Accuracy: 4037/10000 (40.37%)
torch.Size([100, 10])
Test set: Average loss: 2.3444, Accuracy: 4037/10000 (40.37%)

Epoch: 198
Loss: 0.928 | Acc: 75.000% (48/64)
Loss: 1.013 | Acc: 69.771% (4510/6464)
Loss: 1.011 | Acc: 69.932% (8996/12864)
Loss: 1.016 | Acc: 69.679% (13423/19264)
Loss: 1.016 | Acc: 69.670% (17880/25664)
Loss: 1.019 | Acc: 69.539% (22297/32064)
Loss: 1.019 | Acc: 69.543% (26749/38464)
Loss: 1.019 | Acc: 69.668% (31256/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3634, Accuracy: 4015/10000 (40.15%)
torch.Size([100, 10])
Test set: Average loss: 2.3634, Accuracy: 4015/10000 (40.15%)

Epoch: 199
Loss: 1.051 | Acc: 68.750% (44/64)
Loss: 1.019 | Acc: 69.477% (4491/6464)
Loss: 1.009 | Acc: 70.009% (9006/12864)
Loss: 1.007 | Acc: 69.954% (13476/19264)
Loss: 1.003 | Acc: 70.040% (17975/25664)
Loss: 1.003 | Acc: 70.054% (22462/32064)
Loss: 1.001 | Acc: 70.151% (26983/38464)
Loss: 1.003 | Acc: 70.085% (31443/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3610, Accuracy: 4007/10000 (40.07%)
torch.Size([100, 10])
Test set: Average loss: 2.3610, Accuracy: 4007/10000 (40.07%)
4536
10000
-1.9904685020446777
