==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.418 | Acc: 12.500% (8/64)
Loss: 2.914 | Acc: 12.222% (790/6464)
Loss: 2.593 | Acc: 13.223% (1701/12864)
Loss: 2.484 | Acc: 13.710% (2641/19264)
Loss: 2.422 | Acc: 14.553% (3735/25664)
Loss: 2.385 | Acc: 15.067% (4831/32064)
Loss: 2.359 | Acc: 15.596% (5999/38464)
Loss: 2.338 | Acc: 16.073% (7211/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3292, Accuracy: 1541/10000 (15.41%)

Epoch: 1
Loss: 2.344 | Acc: 6.250% (4/64)
Loss: 2.202 | Acc: 20.158% (1303/6464)
Loss: 2.193 | Acc: 20.872% (2685/12864)
Loss: 2.190 | Acc: 21.211% (4086/19264)
Loss: 2.189 | Acc: 21.470% (5510/25664)
Loss: 2.188 | Acc: 21.629% (6935/32064)
Loss: 2.183 | Acc: 21.836% (8399/38464)
Loss: 2.182 | Acc: 21.944% (9845/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2639, Accuracy: 1915/10000 (19.15%)

Epoch: 2
Loss: 2.085 | Acc: 26.562% (17/64)
Loss: 2.151 | Acc: 23.994% (1551/6464)
Loss: 2.154 | Acc: 23.772% (3058/12864)
Loss: 2.152 | Acc: 23.941% (4612/19264)
Loss: 2.149 | Acc: 24.225% (6217/25664)
Loss: 2.149 | Acc: 24.202% (7760/32064)
Loss: 2.148 | Acc: 24.420% (9393/38464)
Loss: 2.146 | Acc: 24.672% (11069/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1354, Accuracy: 2580/10000 (25.80%)

Epoch: 3
Loss: 2.403 | Acc: 17.188% (11/64)
Loss: 2.130 | Acc: 26.408% (1707/6464)
Loss: 2.133 | Acc: 26.119% (3360/12864)
Loss: 2.126 | Acc: 26.422% (5090/19264)
Loss: 2.126 | Acc: 26.309% (6752/25664)
Loss: 2.126 | Acc: 26.497% (8496/32064)
Loss: 2.125 | Acc: 26.526% (10203/38464)
Loss: 2.123 | Acc: 26.663% (11962/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2482, Accuracy: 2251/10000 (22.51%)

Epoch: 4
Loss: 2.065 | Acc: 29.688% (19/64)
Loss: 2.099 | Acc: 28.295% (1829/6464)
Loss: 2.090 | Acc: 28.716% (3694/12864)
Loss: 2.097 | Acc: 28.535% (5497/19264)
Loss: 2.097 | Acc: 28.417% (7293/25664)
Loss: 2.099 | Acc: 28.356% (9092/32064)
Loss: 2.097 | Acc: 28.510% (10966/38464)
Loss: 2.095 | Acc: 28.589% (12826/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1970, Accuracy: 2590/10000 (25.90%)

Epoch: 5
Loss: 2.082 | Acc: 23.438% (15/64)
Loss: 2.068 | Acc: 29.626% (1915/6464)
Loss: 2.082 | Acc: 29.345% (3775/12864)
Loss: 2.079 | Acc: 29.573% (5697/19264)
Loss: 2.078 | Acc: 29.746% (7634/25664)
Loss: 2.076 | Acc: 29.868% (9577/32064)
Loss: 2.076 | Acc: 29.921% (11509/38464)
Loss: 2.073 | Acc: 30.149% (13526/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1732, Accuracy: 2524/10000 (25.24%)

Epoch: 6
Loss: 1.985 | Acc: 39.062% (25/64)
Loss: 2.041 | Acc: 32.983% (2132/6464)
Loss: 2.048 | Acc: 32.408% (4169/12864)
Loss: 2.054 | Acc: 32.169% (6197/19264)
Loss: 2.052 | Acc: 32.279% (8284/25664)
Loss: 2.047 | Acc: 32.391% (10386/32064)
Loss: 2.047 | Acc: 32.404% (12464/38464)
Loss: 2.046 | Acc: 32.514% (14587/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1133, Accuracy: 2939/10000 (29.39%)

Epoch: 7
Loss: 2.010 | Acc: 40.625% (26/64)
Loss: 2.026 | Acc: 33.772% (2183/6464)
Loss: 2.021 | Acc: 33.932% (4365/12864)
Loss: 2.023 | Acc: 33.991% (6548/19264)
Loss: 2.021 | Acc: 34.207% (8779/25664)
Loss: 2.021 | Acc: 34.428% (11039/32064)
Loss: 2.020 | Acc: 34.453% (13252/38464)
Loss: 2.019 | Acc: 34.493% (15475/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0697, Accuracy: 3202/10000 (32.02%)

Epoch: 8
Loss: 2.114 | Acc: 28.125% (18/64)
Loss: 1.999 | Acc: 34.901% (2256/6464)
Loss: 1.994 | Acc: 35.417% (4556/12864)
Loss: 1.991 | Acc: 35.709% (6879/19264)
Loss: 1.997 | Acc: 35.493% (9109/25664)
Loss: 1.993 | Acc: 35.672% (11438/32064)
Loss: 1.995 | Acc: 35.566% (13680/38464)
Loss: 1.994 | Acc: 35.574% (15960/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1129, Accuracy: 3263/10000 (32.63%)

Epoch: 9
Loss: 2.111 | Acc: 31.250% (20/64)
Loss: 1.968 | Acc: 37.469% (2422/6464)
Loss: 1.980 | Acc: 36.754% (4728/12864)
Loss: 1.982 | Acc: 36.669% (7064/19264)
Loss: 1.982 | Acc: 36.654% (9407/25664)
Loss: 1.982 | Acc: 36.630% (11745/32064)
Loss: 1.984 | Acc: 36.580% (14070/38464)
Loss: 1.983 | Acc: 36.669% (16451/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1028, Accuracy: 3080/10000 (30.80%)

Epoch: 10
Loss: 1.934 | Acc: 48.438% (31/64)
Loss: 1.978 | Acc: 37.515% (2425/6464)
Loss: 1.977 | Acc: 37.376% (4808/12864)
Loss: 1.972 | Acc: 37.375% (7200/19264)
Loss: 1.973 | Acc: 37.293% (9571/25664)
Loss: 1.969 | Acc: 37.537% (12036/32064)
Loss: 1.970 | Acc: 37.505% (14426/38464)
Loss: 1.969 | Acc: 37.471% (16811/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0882, Accuracy: 3105/10000 (31.05%)

Epoch: 11
Loss: 1.952 | Acc: 40.625% (26/64)
Loss: 1.950 | Acc: 38.351% (2479/6464)
Loss: 1.959 | Acc: 38.021% (4891/12864)
Loss: 1.959 | Acc: 38.107% (7341/19264)
Loss: 1.961 | Acc: 38.010% (9755/25664)
Loss: 1.962 | Acc: 37.896% (12151/32064)
Loss: 1.961 | Acc: 38.023% (14625/38464)
Loss: 1.959 | Acc: 38.126% (17105/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1225, Accuracy: 3080/10000 (30.80%)

Epoch: 12
Loss: 1.844 | Acc: 43.750% (28/64)
Loss: 1.960 | Acc: 38.413% (2483/6464)
Loss: 1.951 | Acc: 38.635% (4970/12864)
Loss: 1.946 | Acc: 38.928% (7499/19264)
Loss: 1.947 | Acc: 38.887% (9980/25664)
Loss: 1.947 | Acc: 38.935% (12484/32064)
Loss: 1.944 | Acc: 39.026% (15011/38464)
Loss: 1.946 | Acc: 38.942% (17471/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9899, Accuracy: 3628/10000 (36.28%)

Epoch: 13
Loss: 2.150 | Acc: 29.688% (19/64)
Loss: 1.934 | Acc: 39.697% (2566/6464)
Loss: 1.933 | Acc: 39.778% (5117/12864)
Loss: 1.932 | Acc: 39.857% (7678/19264)
Loss: 1.932 | Acc: 39.807% (10216/25664)
Loss: 1.933 | Acc: 39.755% (12747/32064)
Loss: 1.934 | Acc: 39.733% (15283/38464)
Loss: 1.933 | Acc: 39.789% (17851/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9966, Accuracy: 3743/10000 (37.43%)

Epoch: 14
Loss: 1.953 | Acc: 42.188% (27/64)
Loss: 1.921 | Acc: 40.532% (2620/6464)
Loss: 1.920 | Acc: 40.493% (5209/12864)
Loss: 1.920 | Acc: 40.511% (7804/19264)
Loss: 1.920 | Acc: 40.555% (10408/25664)
Loss: 1.920 | Acc: 40.488% (12982/32064)
Loss: 1.920 | Acc: 40.487% (15573/38464)
Loss: 1.918 | Acc: 40.672% (18247/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1410, Accuracy: 2781/10000 (27.81%)

Epoch: 15
Loss: 1.949 | Acc: 39.062% (25/64)
Loss: 1.926 | Acc: 40.501% (2618/6464)
Loss: 1.919 | Acc: 41.161% (5295/12864)
Loss: 1.919 | Acc: 41.118% (7921/19264)
Loss: 1.916 | Acc: 41.194% (10572/25664)
Loss: 1.912 | Acc: 41.302% (13243/32064)
Loss: 1.910 | Acc: 41.405% (15926/38464)
Loss: 1.912 | Acc: 41.213% (18490/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1006, Accuracy: 3169/10000 (31.69%)

Epoch: 16
Loss: 2.227 | Acc: 23.438% (15/64)
Loss: 1.891 | Acc: 41.770% (2700/6464)
Loss: 1.899 | Acc: 41.659% (5359/12864)
Loss: 1.904 | Acc: 41.507% (7996/19264)
Loss: 1.907 | Acc: 41.451% (10638/25664)
Loss: 1.905 | Acc: 41.642% (13352/32064)
Loss: 1.903 | Acc: 41.748% (16058/38464)
Loss: 1.899 | Acc: 41.971% (18830/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9791, Accuracy: 3739/10000 (37.39%)

Epoch: 17
Loss: 1.861 | Acc: 42.188% (27/64)
Loss: 1.893 | Acc: 42.373% (2739/6464)
Loss: 1.901 | Acc: 42.001% (5403/12864)
Loss: 1.901 | Acc: 42.182% (8126/19264)
Loss: 1.897 | Acc: 42.347% (10868/25664)
Loss: 1.900 | Acc: 42.206% (13533/32064)
Loss: 1.898 | Acc: 42.206% (16234/38464)
Loss: 1.895 | Acc: 42.288% (18972/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0796, Accuracy: 3551/10000 (35.51%)

Epoch: 18
Loss: 1.977 | Acc: 35.938% (23/64)
Loss: 1.866 | Acc: 43.518% (2813/6464)
Loss: 1.882 | Acc: 42.934% (5523/12864)
Loss: 1.883 | Acc: 42.893% (8263/19264)
Loss: 1.883 | Acc: 42.799% (10984/25664)
Loss: 1.882 | Acc: 42.842% (13737/32064)
Loss: 1.883 | Acc: 42.783% (16456/38464)
Loss: 1.882 | Acc: 42.901% (19247/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9756, Accuracy: 3897/10000 (38.97%)

Epoch: 19
Loss: 2.196 | Acc: 31.250% (20/64)
Loss: 1.867 | Acc: 43.889% (2837/6464)
Loss: 1.867 | Acc: 43.680% (5619/12864)
Loss: 1.863 | Acc: 43.989% (8474/19264)
Loss: 1.867 | Acc: 43.984% (11288/25664)
Loss: 1.872 | Acc: 43.728% (14021/32064)
Loss: 1.875 | Acc: 43.584% (16764/38464)
Loss: 1.875 | Acc: 43.487% (19510/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0376, Accuracy: 3472/10000 (34.72%)

Epoch: 20
Loss: 1.896 | Acc: 42.188% (27/64)
Loss: 1.871 | Acc: 43.719% (2826/6464)
Loss: 1.861 | Acc: 44.108% (5674/12864)
Loss: 1.863 | Acc: 43.952% (8467/19264)
Loss: 1.865 | Acc: 43.844% (11252/25664)
Loss: 1.866 | Acc: 43.753% (14029/32064)
Loss: 1.868 | Acc: 43.786% (16842/38464)
Loss: 1.869 | Acc: 43.763% (19634/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9513, Accuracy: 4022/10000 (40.22%)

Epoch: 21
Loss: 1.890 | Acc: 42.188% (27/64)
Loss: 1.861 | Acc: 43.410% (2806/6464)
Loss: 1.862 | Acc: 43.548% (5602/12864)
Loss: 1.858 | Acc: 44.072% (8490/19264)
Loss: 1.860 | Acc: 44.027% (11299/25664)
Loss: 1.861 | Acc: 44.081% (14134/32064)
Loss: 1.862 | Acc: 44.028% (16935/38464)
Loss: 1.859 | Acc: 44.136% (19801/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9300, Accuracy: 4106/10000 (41.06%)

Epoch: 22
Loss: 1.712 | Acc: 53.125% (34/64)
Loss: 1.841 | Acc: 44.756% (2893/6464)
Loss: 1.854 | Acc: 44.193% (5685/12864)
Loss: 1.852 | Acc: 44.498% (8572/19264)
Loss: 1.856 | Acc: 44.241% (11354/25664)
Loss: 1.854 | Acc: 44.377% (14229/32064)
Loss: 1.854 | Acc: 44.439% (17093/38464)
Loss: 1.852 | Acc: 44.483% (19957/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0011, Accuracy: 3713/10000 (37.13%)

Epoch: 23
Loss: 1.751 | Acc: 46.875% (30/64)
Loss: 1.841 | Acc: 44.910% (2903/6464)
Loss: 1.848 | Acc: 44.636% (5742/12864)
Loss: 1.850 | Acc: 44.716% (8614/19264)
Loss: 1.852 | Acc: 44.557% (11435/25664)
Loss: 1.852 | Acc: 44.586% (14296/32064)
Loss: 1.853 | Acc: 44.564% (17141/38464)
Loss: 1.849 | Acc: 44.744% (20074/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0569, Accuracy: 3346/10000 (33.46%)

Epoch: 24
Loss: 1.796 | Acc: 46.875% (30/64)
Loss: 1.855 | Acc: 44.462% (2874/6464)
Loss: 1.844 | Acc: 44.970% (5785/12864)
Loss: 1.843 | Acc: 45.037% (8676/19264)
Loss: 1.847 | Acc: 44.954% (11537/25664)
Loss: 1.839 | Acc: 45.228% (14502/32064)
Loss: 1.840 | Acc: 45.164% (17372/38464)
Loss: 1.842 | Acc: 45.052% (20212/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0168, Accuracy: 3548/10000 (35.48%)

Epoch: 25
Loss: 1.869 | Acc: 48.438% (31/64)
Loss: 1.816 | Acc: 46.086% (2979/6464)
Loss: 1.826 | Acc: 45.678% (5876/12864)
Loss: 1.829 | Acc: 45.671% (8798/19264)
Loss: 1.829 | Acc: 45.772% (11747/25664)
Loss: 1.831 | Acc: 45.659% (14640/32064)
Loss: 1.832 | Acc: 45.645% (17557/38464)
Loss: 1.833 | Acc: 45.633% (20473/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9677, Accuracy: 3796/10000 (37.96%)

Epoch: 26
Loss: 2.033 | Acc: 35.938% (23/64)
Loss: 1.844 | Acc: 45.189% (2921/6464)
Loss: 1.843 | Acc: 45.118% (5804/12864)
Loss: 1.833 | Acc: 45.588% (8782/19264)
Loss: 1.832 | Acc: 45.597% (11702/25664)
Loss: 1.833 | Acc: 45.556% (14607/32064)
Loss: 1.830 | Acc: 45.682% (17571/38464)
Loss: 1.827 | Acc: 45.823% (20558/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8761, Accuracy: 4372/10000 (43.72%)

Epoch: 27
Loss: 1.937 | Acc: 32.812% (21/64)
Loss: 1.847 | Acc: 44.663% (2887/6464)
Loss: 1.822 | Acc: 46.012% (5919/12864)
Loss: 1.817 | Acc: 46.096% (8880/19264)
Loss: 1.822 | Acc: 45.870% (11772/25664)
Loss: 1.821 | Acc: 46.011% (14753/32064)
Loss: 1.816 | Acc: 46.204% (17772/38464)
Loss: 1.815 | Acc: 46.231% (20741/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9286, Accuracy: 4127/10000 (41.27%)

Epoch: 28
Loss: 1.808 | Acc: 40.625% (26/64)
Loss: 1.813 | Acc: 46.473% (3004/6464)
Loss: 1.814 | Acc: 46.525% (5985/12864)
Loss: 1.809 | Acc: 46.735% (9003/19264)
Loss: 1.812 | Acc: 46.645% (11971/25664)
Loss: 1.810 | Acc: 46.766% (14995/32064)
Loss: 1.811 | Acc: 46.735% (17976/38464)
Loss: 1.808 | Acc: 46.835% (21012/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8952, Accuracy: 4311/10000 (43.11%)

Epoch: 29
Loss: 1.796 | Acc: 48.438% (31/64)
Loss: 1.793 | Acc: 47.463% (3068/6464)
Loss: 1.787 | Acc: 47.738% (6141/12864)
Loss: 1.788 | Acc: 47.799% (9208/19264)
Loss: 1.792 | Acc: 47.576% (12210/25664)
Loss: 1.792 | Acc: 47.521% (15237/32064)
Loss: 1.797 | Acc: 47.366% (18219/38464)
Loss: 1.796 | Acc: 47.388% (21260/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8802, Accuracy: 4349/10000 (43.49%)

Epoch: 30
Loss: 2.039 | Acc: 35.938% (23/64)
Loss: 1.763 | Acc: 48.422% (3130/6464)
Loss: 1.769 | Acc: 48.368% (6222/12864)
Loss: 1.776 | Acc: 48.064% (9259/19264)
Loss: 1.780 | Acc: 47.943% (12304/25664)
Loss: 1.784 | Acc: 47.798% (15326/32064)
Loss: 1.789 | Acc: 47.595% (18307/38464)
Loss: 1.790 | Acc: 47.570% (21342/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9202, Accuracy: 4093/10000 (40.93%)

Epoch: 31
Loss: 1.713 | Acc: 50.000% (32/64)
Loss: 1.770 | Acc: 48.809% (3155/6464)
Loss: 1.775 | Acc: 48.243% (6206/12864)
Loss: 1.780 | Acc: 48.183% (9282/19264)
Loss: 1.781 | Acc: 48.110% (12347/25664)
Loss: 1.779 | Acc: 48.157% (15441/32064)
Loss: 1.779 | Acc: 48.058% (18485/38464)
Loss: 1.782 | Acc: 47.963% (21518/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8966, Accuracy: 4340/10000 (43.40%)

Epoch: 32
Loss: 1.677 | Acc: 45.312% (29/64)
Loss: 1.769 | Acc: 48.453% (3132/6464)
Loss: 1.771 | Acc: 48.158% (6195/12864)
Loss: 1.775 | Acc: 48.162% (9278/19264)
Loss: 1.773 | Acc: 48.305% (12397/25664)
Loss: 1.770 | Acc: 48.466% (15540/32064)
Loss: 1.771 | Acc: 48.380% (18609/38464)
Loss: 1.772 | Acc: 48.426% (21726/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8695, Accuracy: 4535/10000 (45.35%)

Epoch: 33
Loss: 1.764 | Acc: 50.000% (32/64)
Loss: 1.737 | Acc: 49.768% (3217/6464)
Loss: 1.745 | Acc: 49.394% (6354/12864)
Loss: 1.744 | Acc: 49.486% (9533/19264)
Loss: 1.752 | Acc: 49.201% (12627/25664)
Loss: 1.752 | Acc: 49.205% (15777/32064)
Loss: 1.756 | Acc: 49.080% (18878/38464)
Loss: 1.760 | Acc: 48.948% (21960/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9210, Accuracy: 4230/10000 (42.30%)

Epoch: 34
Loss: 1.754 | Acc: 53.125% (34/64)
Loss: 1.733 | Acc: 50.046% (3235/6464)
Loss: 1.734 | Acc: 49.969% (6428/12864)
Loss: 1.738 | Acc: 49.740% (9582/19264)
Loss: 1.744 | Acc: 49.501% (12704/25664)
Loss: 1.746 | Acc: 49.407% (15842/32064)
Loss: 1.747 | Acc: 49.379% (18993/38464)
Loss: 1.749 | Acc: 49.334% (22133/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8643, Accuracy: 4546/10000 (45.46%)

Epoch: 35
Loss: 1.466 | Acc: 62.500% (40/64)
Loss: 1.686 | Acc: 51.238% (3312/6464)
Loss: 1.706 | Acc: 50.552% (6503/12864)
Loss: 1.720 | Acc: 50.052% (9642/19264)
Loss: 1.723 | Acc: 49.977% (12826/25664)
Loss: 1.727 | Acc: 49.894% (15998/32064)
Loss: 1.728 | Acc: 49.857% (19177/38464)
Loss: 1.734 | Acc: 49.668% (22283/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8616, Accuracy: 4523/10000 (45.23%)

Epoch: 36
Loss: 1.760 | Acc: 50.000% (32/64)
Loss: 1.728 | Acc: 49.582% (3205/6464)
Loss: 1.717 | Acc: 50.295% (6470/12864)
Loss: 1.718 | Acc: 50.415% (9712/19264)
Loss: 1.717 | Acc: 50.487% (12957/25664)
Loss: 1.717 | Acc: 50.471% (16183/32064)
Loss: 1.718 | Acc: 50.395% (19384/38464)
Loss: 1.718 | Acc: 50.399% (22611/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8848, Accuracy: 4454/10000 (44.54%)

Epoch: 37
Loss: 1.641 | Acc: 51.562% (33/64)
Loss: 1.696 | Acc: 51.253% (3313/6464)
Loss: 1.696 | Acc: 51.407% (6613/12864)
Loss: 1.696 | Acc: 51.204% (9864/19264)
Loss: 1.700 | Acc: 51.064% (13105/25664)
Loss: 1.706 | Acc: 50.805% (16290/32064)
Loss: 1.708 | Acc: 50.684% (19495/38464)
Loss: 1.707 | Acc: 50.715% (22753/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8906, Accuracy: 4471/10000 (44.71%)

Epoch: 38
Loss: 1.729 | Acc: 53.125% (34/64)
Loss: 1.676 | Acc: 52.011% (3362/6464)
Loss: 1.680 | Acc: 51.765% (6659/12864)
Loss: 1.686 | Acc: 51.620% (9944/19264)
Loss: 1.691 | Acc: 51.360% (13181/25664)
Loss: 1.690 | Acc: 51.350% (16465/32064)
Loss: 1.686 | Acc: 51.490% (19805/38464)
Loss: 1.688 | Acc: 51.389% (23055/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9103, Accuracy: 4318/10000 (43.18%)

Epoch: 39
Loss: 1.811 | Acc: 40.625% (26/64)
Loss: 1.652 | Acc: 52.599% (3400/6464)
Loss: 1.652 | Acc: 52.550% (6760/12864)
Loss: 1.666 | Acc: 52.045% (10026/19264)
Loss: 1.660 | Acc: 52.307% (13424/25664)
Loss: 1.661 | Acc: 52.264% (16758/32064)
Loss: 1.661 | Acc: 52.249% (20097/38464)
Loss: 1.668 | Acc: 52.004% (23331/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9161, Accuracy: 4370/10000 (43.70%)

Epoch: 40
Loss: 1.666 | Acc: 48.438% (31/64)
Loss: 1.639 | Acc: 53.017% (3427/6464)
Loss: 1.635 | Acc: 53.109% (6832/12864)
Loss: 1.636 | Acc: 53.026% (10215/19264)
Loss: 1.637 | Acc: 52.961% (13592/25664)
Loss: 1.637 | Acc: 52.885% (16957/32064)
Loss: 1.642 | Acc: 52.610% (20236/38464)
Loss: 1.643 | Acc: 52.541% (23572/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8755, Accuracy: 4635/10000 (46.35%)

Epoch: 41
Loss: 1.767 | Acc: 43.750% (28/64)
Loss: 1.605 | Acc: 53.929% (3486/6464)
Loss: 1.612 | Acc: 53.584% (6893/12864)
Loss: 1.607 | Acc: 53.587% (10323/19264)
Loss: 1.612 | Acc: 53.398% (13704/25664)
Loss: 1.613 | Acc: 53.421% (17129/32064)
Loss: 1.616 | Acc: 53.323% (20510/38464)
Loss: 1.615 | Acc: 53.381% (23949/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9119, Accuracy: 4582/10000 (45.82%)

Epoch: 42
Loss: 1.452 | Acc: 62.500% (40/64)
Loss: 1.606 | Acc: 53.589% (3464/6464)
Loss: 1.603 | Acc: 53.591% (6894/12864)
Loss: 1.596 | Acc: 53.701% (10345/19264)
Loss: 1.595 | Acc: 53.729% (13789/25664)
Loss: 1.592 | Acc: 53.911% (17286/32064)
Loss: 1.589 | Acc: 54.058% (20793/38464)
Loss: 1.586 | Acc: 54.179% (24307/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9186, Accuracy: 4571/10000 (45.71%)

Epoch: 43
Loss: 1.494 | Acc: 54.688% (35/64)
Loss: 1.512 | Acc: 56.637% (3661/6464)
Loss: 1.528 | Acc: 55.815% (7180/12864)
Loss: 1.535 | Acc: 55.502% (10692/19264)
Loss: 1.540 | Acc: 55.463% (14234/25664)
Loss: 1.540 | Acc: 55.470% (17786/32064)
Loss: 1.542 | Acc: 55.470% (21336/38464)
Loss: 1.542 | Acc: 55.412% (24860/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9613, Accuracy: 4435/10000 (44.35%)

Epoch: 44
Loss: 1.330 | Acc: 62.500% (40/64)
Loss: 1.480 | Acc: 57.008% (3685/6464)
Loss: 1.495 | Acc: 56.367% (7251/12864)
Loss: 1.493 | Acc: 56.515% (10887/19264)
Loss: 1.497 | Acc: 56.344% (14460/25664)
Loss: 1.501 | Acc: 56.138% (18000/32064)
Loss: 1.502 | Acc: 56.190% (21613/38464)
Loss: 1.502 | Acc: 56.234% (25229/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9865, Accuracy: 4479/10000 (44.79%)

Epoch: 45
Loss: 1.488 | Acc: 56.250% (36/64)
Loss: 1.510 | Acc: 55.987% (3619/6464)
Loss: 1.546 | Acc: 55.379% (7124/12864)
Loss: 1.589 | Acc: 54.272% (10455/19264)
Loss: 1.622 | Acc: 53.234% (13662/25664)
Loss: 1.640 | Acc: 52.819% (16936/32064)
Loss: 1.653 | Acc: 52.537% (20208/38464)
Loss: 1.665 | Acc: 52.269% (23450/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8784, Accuracy: 4484/10000 (44.84%)

Epoch: 46
Loss: 1.762 | Acc: 50.000% (32/64)
Loss: 1.788 | Acc: 48.546% (3138/6464)
Loss: 1.784 | Acc: 48.577% (6249/12864)
Loss: 1.788 | Acc: 48.323% (9309/19264)
Loss: 1.795 | Acc: 48.052% (12332/25664)
Loss: 1.797 | Acc: 48.079% (15416/32064)
Loss: 1.802 | Acc: 47.944% (18441/38464)
Loss: 1.803 | Acc: 47.874% (21478/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8823, Accuracy: 4441/10000 (44.41%)

Epoch: 47
Loss: 1.602 | Acc: 59.375% (38/64)
Loss: 1.828 | Acc: 47.246% (3054/6464)
Loss: 1.830 | Acc: 46.937% (6038/12864)
Loss: 1.826 | Acc: 47.015% (9057/19264)
Loss: 1.821 | Acc: 47.163% (12104/25664)
Loss: 1.828 | Acc: 46.813% (15010/32064)
Loss: 1.830 | Acc: 46.740% (17978/38464)
Loss: 1.832 | Acc: 46.634% (20922/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8926, Accuracy: 4387/10000 (43.87%)
torch.Size([100, 10])
Test set: Average loss: 1.8926, Accuracy: 4387/10000 (43.87%)

Epoch: 48
Loss: 1.776 | Acc: 48.438% (31/64)
Loss: 1.827 | Acc: 46.364% (2997/6464)
Loss: 1.834 | Acc: 46.315% (5958/12864)
Loss: 1.836 | Acc: 46.221% (8904/19264)
Loss: 1.844 | Acc: 45.839% (11764/25664)
Loss: 1.839 | Acc: 46.189% (14810/32064)
Loss: 1.837 | Acc: 46.267% (17796/38464)
Loss: 1.838 | Acc: 46.200% (20727/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8914, Accuracy: 4407/10000 (44.07%)
torch.Size([100, 10])
Test set: Average loss: 1.8914, Accuracy: 4407/10000 (44.07%)

Epoch: 49
Loss: 1.862 | Acc: 43.750% (28/64)
Loss: 1.860 | Acc: 45.142% (2918/6464)
Loss: 1.855 | Acc: 45.445% (5846/12864)
Loss: 1.854 | Acc: 45.556% (8776/19264)
Loss: 1.847 | Acc: 45.827% (11761/25664)
Loss: 1.845 | Acc: 45.977% (14742/32064)
Loss: 1.843 | Acc: 46.066% (17719/38464)
Loss: 1.840 | Acc: 46.224% (20738/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8919, Accuracy: 4407/10000 (44.07%)
torch.Size([100, 10])
Test set: Average loss: 1.8919, Accuracy: 4407/10000 (44.07%)

Epoch: 50
Loss: 1.842 | Acc: 51.562% (33/64)
Loss: 2.115 | Acc: 28.543% (1845/6464)
Loss: 2.057 | Acc: 32.696% (4206/12864)
Loss: 2.024 | Acc: 34.936% (6730/19264)
Loss: 2.008 | Acc: 35.914% (9217/25664)
Loss: 1.995 | Acc: 36.689% (11764/32064)
Loss: 1.984 | Acc: 37.336% (14361/38464)
Loss: 1.976 | Acc: 37.883% (16996/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2328, Accuracy: 2845/10000 (28.45%)

Epoch: 51
Loss: 1.948 | Acc: 39.062% (25/64)
Loss: 1.913 | Acc: 41.708% (2696/6464)
Loss: 1.917 | Acc: 41.519% (5341/12864)
Loss: 1.911 | Acc: 41.938% (8079/19264)
Loss: 1.907 | Acc: 42.016% (10783/25664)
Loss: 1.904 | Acc: 42.191% (13528/32064)
Loss: 1.901 | Acc: 42.299% (16270/38464)
Loss: 1.899 | Acc: 42.399% (19022/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0480, Accuracy: 3560/10000 (35.60%)

Epoch: 52
Loss: 1.676 | Acc: 48.438% (31/64)
Loss: 1.879 | Acc: 42.976% (2778/6464)
Loss: 1.881 | Acc: 42.903% (5519/12864)
Loss: 1.880 | Acc: 43.195% (8321/19264)
Loss: 1.884 | Acc: 42.967% (11027/25664)
Loss: 1.883 | Acc: 43.108% (13822/32064)
Loss: 1.880 | Acc: 43.235% (16630/38464)
Loss: 1.882 | Acc: 43.139% (19354/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9931, Accuracy: 3842/10000 (38.42%)

Epoch: 53
Loss: 1.734 | Acc: 46.875% (30/64)
Loss: 1.865 | Acc: 43.580% (2817/6464)
Loss: 1.868 | Acc: 43.773% (5631/12864)
Loss: 1.874 | Acc: 43.553% (8390/19264)
Loss: 1.878 | Acc: 43.364% (11129/25664)
Loss: 1.881 | Acc: 43.248% (13867/32064)
Loss: 1.881 | Acc: 43.282% (16648/38464)
Loss: 1.882 | Acc: 43.302% (19427/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1009, Accuracy: 3453/10000 (34.53%)

Epoch: 54
Loss: 1.826 | Acc: 46.875% (30/64)
Loss: 1.867 | Acc: 43.673% (2823/6464)
Loss: 1.873 | Acc: 43.377% (5580/12864)
Loss: 1.874 | Acc: 43.454% (8371/19264)
Loss: 1.870 | Acc: 43.758% (11230/25664)
Loss: 1.873 | Acc: 43.625% (13988/32064)
Loss: 1.874 | Acc: 43.667% (16796/38464)
Loss: 1.874 | Acc: 43.623% (19571/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9994, Accuracy: 3773/10000 (37.73%)

Epoch: 55
Loss: 1.753 | Acc: 51.562% (33/64)
Loss: 1.864 | Acc: 43.889% (2837/6464)
Loss: 1.868 | Acc: 43.657% (5616/12864)
Loss: 1.864 | Acc: 43.978% (8472/19264)
Loss: 1.868 | Acc: 43.777% (11235/25664)
Loss: 1.868 | Acc: 43.769% (14034/32064)
Loss: 1.867 | Acc: 43.807% (16850/38464)
Loss: 1.869 | Acc: 43.734% (19621/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0033, Accuracy: 3884/10000 (38.84%)

Epoch: 56
Loss: 2.187 | Acc: 31.250% (20/64)
Loss: 1.870 | Acc: 44.121% (2852/6464)
Loss: 1.865 | Acc: 44.317% (5701/12864)
Loss: 1.865 | Acc: 44.176% (8510/19264)
Loss: 1.875 | Acc: 43.625% (11196/25664)
Loss: 1.872 | Acc: 43.691% (14009/32064)
Loss: 1.869 | Acc: 43.872% (16875/38464)
Loss: 1.869 | Acc: 43.846% (19671/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0864, Accuracy: 3587/10000 (35.87%)

Epoch: 57
Loss: 2.008 | Acc: 40.625% (26/64)
Loss: 1.848 | Acc: 44.694% (2889/6464)
Loss: 1.854 | Acc: 44.613% (5739/12864)
Loss: 1.865 | Acc: 44.233% (8521/19264)
Loss: 1.864 | Acc: 44.253% (11357/25664)
Loss: 1.864 | Acc: 44.193% (14170/32064)
Loss: 1.867 | Acc: 44.044% (16941/38464)
Loss: 1.865 | Acc: 44.107% (19788/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0395, Accuracy: 3506/10000 (35.06%)

Epoch: 58
Loss: 1.744 | Acc: 42.188% (27/64)
Loss: 1.854 | Acc: 44.261% (2861/6464)
Loss: 1.861 | Acc: 44.131% (5677/12864)
Loss: 1.861 | Acc: 44.067% (8489/19264)
Loss: 1.860 | Acc: 44.198% (11343/25664)
Loss: 1.862 | Acc: 44.218% (14178/32064)
Loss: 1.863 | Acc: 44.221% (17009/38464)
Loss: 1.861 | Acc: 44.347% (19896/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0159, Accuracy: 3710/10000 (37.10%)

Epoch: 59
Loss: 1.825 | Acc: 46.875% (30/64)
Loss: 1.864 | Acc: 44.678% (2888/6464)
Loss: 1.852 | Acc: 45.072% (5798/12864)
Loss: 1.857 | Acc: 44.736% (8618/19264)
Loss: 1.854 | Acc: 44.818% (11502/25664)
Loss: 1.856 | Acc: 44.667% (14322/32064)
Loss: 1.858 | Acc: 44.566% (17142/38464)
Loss: 1.860 | Acc: 44.461% (19947/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1214, Accuracy: 3127/10000 (31.27%)

Epoch: 60
Loss: 2.038 | Acc: 39.062% (25/64)
Loss: 1.864 | Acc: 43.967% (2842/6464)
Loss: 1.868 | Acc: 43.859% (5642/12864)
Loss: 1.867 | Acc: 43.932% (8463/19264)
Loss: 1.862 | Acc: 44.366% (11386/25664)
Loss: 1.861 | Acc: 44.424% (14244/32064)
Loss: 1.861 | Acc: 44.351% (17059/38464)
Loss: 1.861 | Acc: 44.356% (19900/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9540, Accuracy: 4018/10000 (40.18%)

Epoch: 61
Loss: 1.818 | Acc: 45.312% (29/64)
Loss: 1.843 | Acc: 44.632% (2885/6464)
Loss: 1.844 | Acc: 44.714% (5752/12864)
Loss: 1.849 | Acc: 44.622% (8596/19264)
Loss: 1.856 | Acc: 44.334% (11378/25664)
Loss: 1.854 | Acc: 44.458% (14255/32064)
Loss: 1.853 | Acc: 44.618% (17162/38464)
Loss: 1.853 | Acc: 44.642% (20028/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0956, Accuracy: 3358/10000 (33.58%)

Epoch: 62
Loss: 1.839 | Acc: 46.875% (30/64)
Loss: 1.844 | Acc: 45.297% (2928/6464)
Loss: 1.848 | Acc: 44.900% (5776/12864)
Loss: 1.845 | Acc: 45.188% (8705/19264)
Loss: 1.844 | Acc: 45.153% (11588/25664)
Loss: 1.850 | Acc: 44.913% (14401/32064)
Loss: 1.850 | Acc: 44.985% (17303/38464)
Loss: 1.851 | Acc: 44.980% (20180/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9727, Accuracy: 3863/10000 (38.63%)

Epoch: 63
Loss: 1.687 | Acc: 54.688% (35/64)
Loss: 1.835 | Acc: 45.390% (2934/6464)
Loss: 1.837 | Acc: 45.569% (5862/12864)
Loss: 1.833 | Acc: 45.640% (8792/19264)
Loss: 1.837 | Acc: 45.418% (11656/25664)
Loss: 1.843 | Acc: 45.119% (14467/32064)
Loss: 1.849 | Acc: 44.800% (17232/38464)
Loss: 1.850 | Acc: 44.842% (20118/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9804, Accuracy: 3804/10000 (38.04%)

Epoch: 64
Loss: 1.954 | Acc: 43.750% (28/64)
Loss: 1.835 | Acc: 45.405% (2935/6464)
Loss: 1.840 | Acc: 45.235% (5819/12864)
Loss: 1.837 | Acc: 45.349% (8736/19264)
Loss: 1.841 | Acc: 45.254% (11614/25664)
Loss: 1.842 | Acc: 45.200% (14493/32064)
Loss: 1.842 | Acc: 45.193% (17383/38464)
Loss: 1.845 | Acc: 45.054% (20213/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9579, Accuracy: 3864/10000 (38.64%)

Epoch: 65
Loss: 1.638 | Acc: 51.562% (33/64)
Loss: 1.834 | Acc: 45.746% (2957/6464)
Loss: 1.831 | Acc: 45.717% (5881/12864)
Loss: 1.843 | Acc: 45.318% (8730/19264)
Loss: 1.846 | Acc: 45.231% (11608/25664)
Loss: 1.847 | Acc: 45.182% (14487/32064)
Loss: 1.848 | Acc: 45.190% (17382/38464)
Loss: 1.845 | Acc: 45.344% (20343/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9947, Accuracy: 3743/10000 (37.43%)

Epoch: 66
Loss: 1.919 | Acc: 40.625% (26/64)
Loss: 1.836 | Acc: 45.993% (2973/6464)
Loss: 1.843 | Acc: 45.305% (5828/12864)
Loss: 1.846 | Acc: 45.120% (8692/19264)
Loss: 1.843 | Acc: 45.118% (11579/25664)
Loss: 1.842 | Acc: 45.222% (14500/32064)
Loss: 1.840 | Acc: 45.307% (17427/38464)
Loss: 1.836 | Acc: 45.518% (20421/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1043, Accuracy: 3289/10000 (32.89%)

Epoch: 67
Loss: 1.654 | Acc: 56.250% (36/64)
Loss: 1.843 | Acc: 45.374% (2933/6464)
Loss: 1.840 | Acc: 45.468% (5849/12864)
Loss: 1.836 | Acc: 45.754% (8814/19264)
Loss: 1.836 | Acc: 45.671% (11721/25664)
Loss: 1.834 | Acc: 45.687% (14649/32064)
Loss: 1.834 | Acc: 45.669% (17566/38464)
Loss: 1.833 | Acc: 45.732% (20517/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0968, Accuracy: 3652/10000 (36.52%)

Epoch: 68
Loss: 1.879 | Acc: 43.750% (28/64)
Loss: 1.839 | Acc: 45.575% (2946/6464)
Loss: 1.825 | Acc: 45.802% (5892/12864)
Loss: 1.832 | Acc: 45.453% (8756/19264)
Loss: 1.822 | Acc: 46.014% (11809/25664)
Loss: 1.822 | Acc: 46.064% (14770/32064)
Loss: 1.827 | Acc: 45.903% (17656/38464)
Loss: 1.827 | Acc: 45.925% (20604/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8986, Accuracy: 4385/10000 (43.85%)

Epoch: 69
Loss: 1.863 | Acc: 42.188% (27/64)
Loss: 1.796 | Acc: 47.277% (3056/6464)
Loss: 1.804 | Acc: 47.186% (6070/12864)
Loss: 1.818 | Acc: 46.615% (8980/19264)
Loss: 1.823 | Acc: 46.404% (11909/25664)
Loss: 1.823 | Acc: 46.370% (14868/32064)
Loss: 1.823 | Acc: 46.360% (17832/38464)
Loss: 1.824 | Acc: 46.360% (20799/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0213, Accuracy: 3651/10000 (36.51%)

Epoch: 70
Loss: 1.856 | Acc: 46.875% (30/64)
Loss: 1.799 | Acc: 47.602% (3077/6464)
Loss: 1.806 | Acc: 46.992% (6045/12864)
Loss: 1.817 | Acc: 46.589% (8975/19264)
Loss: 1.816 | Acc: 46.645% (11971/25664)
Loss: 1.821 | Acc: 46.420% (14884/32064)
Loss: 1.821 | Acc: 46.472% (17875/38464)
Loss: 1.821 | Acc: 46.496% (20860/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9856, Accuracy: 3799/10000 (37.99%)

Epoch: 71
Loss: 1.755 | Acc: 42.188% (27/64)
Loss: 1.793 | Acc: 47.339% (3060/6464)
Loss: 1.801 | Acc: 47.054% (6053/12864)
Loss: 1.806 | Acc: 46.953% (9045/19264)
Loss: 1.810 | Acc: 46.809% (12013/25664)
Loss: 1.813 | Acc: 46.669% (14964/32064)
Loss: 1.813 | Acc: 46.612% (17929/38464)
Loss: 1.813 | Acc: 46.605% (20909/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9730, Accuracy: 3855/10000 (38.55%)

Epoch: 72
Loss: 1.847 | Acc: 48.438% (31/64)
Loss: 1.797 | Acc: 47.556% (3074/6464)
Loss: 1.810 | Acc: 46.945% (6039/12864)
Loss: 1.817 | Acc: 46.543% (8966/19264)
Loss: 1.813 | Acc: 46.758% (12000/25664)
Loss: 1.813 | Acc: 46.710% (14977/32064)
Loss: 1.808 | Acc: 46.943% (18056/38464)
Loss: 1.809 | Acc: 46.966% (21071/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9557, Accuracy: 4085/10000 (40.85%)

Epoch: 73
Loss: 1.672 | Acc: 53.125% (34/64)
Loss: 1.810 | Acc: 46.782% (3024/6464)
Loss: 1.799 | Acc: 47.318% (6087/12864)
Loss: 1.805 | Acc: 47.015% (9057/19264)
Loss: 1.806 | Acc: 47.000% (12062/25664)
Loss: 1.806 | Acc: 47.078% (15095/32064)
Loss: 1.804 | Acc: 47.166% (18142/38464)
Loss: 1.802 | Acc: 47.272% (21208/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9312, Accuracy: 4076/10000 (40.76%)

Epoch: 74
Loss: 1.846 | Acc: 43.750% (28/64)
Loss: 1.796 | Acc: 47.757% (3087/6464)
Loss: 1.795 | Acc: 47.621% (6126/12864)
Loss: 1.795 | Acc: 47.534% (9157/19264)
Loss: 1.798 | Acc: 47.385% (12161/25664)
Loss: 1.793 | Acc: 47.558% (15249/32064)
Loss: 1.798 | Acc: 47.322% (18202/38464)
Loss: 1.797 | Acc: 47.428% (21278/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9746, Accuracy: 3753/10000 (37.53%)

Epoch: 75
Loss: 1.556 | Acc: 56.250% (36/64)
Loss: 1.770 | Acc: 48.468% (3133/6464)
Loss: 1.773 | Acc: 48.406% (6227/12864)
Loss: 1.784 | Acc: 48.027% (9252/19264)
Loss: 1.787 | Acc: 47.861% (12283/25664)
Loss: 1.788 | Acc: 47.792% (15324/32064)
Loss: 1.790 | Acc: 47.699% (18347/38464)
Loss: 1.791 | Acc: 47.709% (21404/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8918, Accuracy: 4375/10000 (43.75%)

Epoch: 76
Loss: 1.739 | Acc: 51.562% (33/64)
Loss: 1.776 | Acc: 48.639% (3144/6464)
Loss: 1.770 | Acc: 48.663% (6260/12864)
Loss: 1.782 | Acc: 48.183% (9282/19264)
Loss: 1.785 | Acc: 47.974% (12312/25664)
Loss: 1.785 | Acc: 47.995% (15389/32064)
Loss: 1.786 | Acc: 47.866% (18411/38464)
Loss: 1.783 | Acc: 48.047% (21556/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9001, Accuracy: 4274/10000 (42.74%)

Epoch: 77
Loss: 1.814 | Acc: 50.000% (32/64)
Loss: 1.788 | Acc: 47.865% (3094/6464)
Loss: 1.775 | Acc: 48.453% (6233/12864)
Loss: 1.778 | Acc: 48.225% (9290/19264)
Loss: 1.783 | Acc: 48.056% (12333/25664)
Loss: 1.781 | Acc: 48.176% (15447/32064)
Loss: 1.778 | Acc: 48.326% (18588/38464)
Loss: 1.778 | Acc: 48.335% (21685/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9242, Accuracy: 4165/10000 (41.65%)

Epoch: 78
Loss: 1.825 | Acc: 48.438% (31/64)
Loss: 1.771 | Acc: 48.252% (3119/6464)
Loss: 1.776 | Acc: 48.259% (6208/12864)
Loss: 1.772 | Acc: 48.438% (9331/19264)
Loss: 1.771 | Acc: 48.519% (12452/25664)
Loss: 1.769 | Acc: 48.631% (15593/32064)
Loss: 1.768 | Acc: 48.664% (18718/38464)
Loss: 1.770 | Acc: 48.585% (21797/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9531, Accuracy: 4012/10000 (40.12%)

Epoch: 79
Loss: 1.656 | Acc: 53.125% (34/64)
Loss: 1.753 | Acc: 49.257% (3184/6464)
Loss: 1.761 | Acc: 49.005% (6304/12864)
Loss: 1.758 | Acc: 49.092% (9457/19264)
Loss: 1.759 | Acc: 49.061% (12591/25664)
Loss: 1.761 | Acc: 48.983% (15706/32064)
Loss: 1.761 | Acc: 48.944% (18826/38464)
Loss: 1.760 | Acc: 48.972% (21971/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8930, Accuracy: 4258/10000 (42.58%)

Epoch: 80
Loss: 1.856 | Acc: 45.312% (29/64)
Loss: 1.771 | Acc: 48.283% (3121/6464)
Loss: 1.755 | Acc: 49.153% (6323/12864)
Loss: 1.750 | Acc: 49.393% (9515/19264)
Loss: 1.749 | Acc: 49.419% (12683/25664)
Loss: 1.754 | Acc: 49.286% (15803/32064)
Loss: 1.753 | Acc: 49.366% (18988/38464)
Loss: 1.756 | Acc: 49.296% (22116/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8928, Accuracy: 4376/10000 (43.76%)

Epoch: 81
Loss: 1.800 | Acc: 43.750% (28/64)
Loss: 1.736 | Acc: 49.691% (3212/6464)
Loss: 1.743 | Acc: 49.456% (6362/12864)
Loss: 1.744 | Acc: 49.439% (9524/19264)
Loss: 1.747 | Acc: 49.416% (12682/25664)
Loss: 1.745 | Acc: 49.542% (15885/32064)
Loss: 1.742 | Acc: 49.724% (19126/38464)
Loss: 1.743 | Acc: 49.639% (22270/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8934, Accuracy: 4376/10000 (43.76%)

Epoch: 82
Loss: 1.671 | Acc: 51.562% (33/64)
Loss: 1.740 | Acc: 49.242% (3183/6464)
Loss: 1.736 | Acc: 49.736% (6398/12864)
Loss: 1.731 | Acc: 50.052% (9642/19264)
Loss: 1.731 | Acc: 50.078% (12852/25664)
Loss: 1.733 | Acc: 49.972% (16023/32064)
Loss: 1.736 | Acc: 49.880% (19186/38464)
Loss: 1.736 | Acc: 49.924% (22398/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8509, Accuracy: 4627/10000 (46.27%)

Epoch: 83
Loss: 1.808 | Acc: 46.875% (30/64)
Loss: 1.692 | Acc: 51.470% (3327/6464)
Loss: 1.693 | Acc: 51.360% (6607/12864)
Loss: 1.704 | Acc: 51.043% (9833/19264)
Loss: 1.714 | Acc: 50.670% (13004/25664)
Loss: 1.714 | Acc: 50.689% (16253/32064)
Loss: 1.716 | Acc: 50.601% (19463/38464)
Loss: 1.717 | Acc: 50.660% (22728/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8586, Accuracy: 4538/10000 (45.38%)

Epoch: 84
Loss: 1.904 | Acc: 45.312% (29/64)
Loss: 1.706 | Acc: 50.882% (3289/6464)
Loss: 1.698 | Acc: 51.345% (6605/12864)
Loss: 1.709 | Acc: 50.898% (9805/19264)
Loss: 1.716 | Acc: 50.651% (12999/25664)
Loss: 1.713 | Acc: 50.752% (16273/32064)
Loss: 1.713 | Acc: 50.759% (19524/38464)
Loss: 1.711 | Acc: 50.883% (22828/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8737, Accuracy: 4445/10000 (44.45%)

Epoch: 85
Loss: 1.651 | Acc: 53.125% (34/64)
Loss: 1.708 | Acc: 50.526% (3266/6464)
Loss: 1.696 | Acc: 51.197% (6586/12864)
Loss: 1.689 | Acc: 51.474% (9916/19264)
Loss: 1.686 | Acc: 51.660% (13258/25664)
Loss: 1.687 | Acc: 51.669% (16567/32064)
Loss: 1.693 | Acc: 51.474% (19799/38464)
Loss: 1.698 | Acc: 51.257% (22996/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8908, Accuracy: 4423/10000 (44.23%)

Epoch: 86
Loss: 1.641 | Acc: 50.000% (32/64)
Loss: 1.666 | Acc: 51.996% (3361/6464)
Loss: 1.665 | Acc: 52.379% (6738/12864)
Loss: 1.660 | Acc: 52.575% (10128/19264)
Loss: 1.667 | Acc: 52.287% (13419/25664)
Loss: 1.676 | Acc: 51.912% (16645/32064)
Loss: 1.681 | Acc: 51.646% (19865/38464)
Loss: 1.679 | Acc: 51.792% (23236/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8634, Accuracy: 4592/10000 (45.92%)

Epoch: 87
Loss: 1.366 | Acc: 65.625% (42/64)
Loss: 1.643 | Acc: 52.893% (3419/6464)
Loss: 1.649 | Acc: 52.775% (6789/12864)
Loss: 1.658 | Acc: 52.248% (10065/19264)
Loss: 1.659 | Acc: 52.361% (13438/25664)
Loss: 1.657 | Acc: 52.498% (16833/32064)
Loss: 1.657 | Acc: 52.608% (20235/38464)
Loss: 1.655 | Acc: 52.664% (23627/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8665, Accuracy: 4664/10000 (46.64%)

Epoch: 88
Loss: 1.755 | Acc: 48.438% (31/64)
Loss: 1.637 | Acc: 53.001% (3426/6464)
Loss: 1.635 | Acc: 53.141% (6836/12864)
Loss: 1.639 | Acc: 53.026% (10215/19264)
Loss: 1.636 | Acc: 53.137% (13637/25664)
Loss: 1.638 | Acc: 53.056% (17012/32064)
Loss: 1.633 | Acc: 53.276% (20492/38464)
Loss: 1.633 | Acc: 53.330% (23926/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9015, Accuracy: 4487/10000 (44.87%)

Epoch: 89
Loss: 1.530 | Acc: 57.812% (37/64)
Loss: 1.613 | Acc: 53.868% (3482/6464)
Loss: 1.591 | Acc: 54.952% (7069/12864)
Loss: 1.600 | Acc: 54.537% (10506/19264)
Loss: 1.605 | Acc: 54.271% (13928/25664)
Loss: 1.605 | Acc: 54.195% (17377/32064)
Loss: 1.610 | Acc: 53.999% (20770/38464)
Loss: 1.612 | Acc: 53.950% (24204/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8850, Accuracy: 4621/10000 (46.21%)

Epoch: 90
Loss: 1.581 | Acc: 56.250% (36/64)
Loss: 1.540 | Acc: 56.157% (3630/6464)
Loss: 1.565 | Acc: 55.045% (7081/12864)
Loss: 1.579 | Acc: 54.667% (10531/19264)
Loss: 1.579 | Acc: 54.664% (14029/25664)
Loss: 1.582 | Acc: 54.535% (17486/32064)
Loss: 1.585 | Acc: 54.480% (20955/38464)
Loss: 1.585 | Acc: 54.474% (24439/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9121, Accuracy: 4511/10000 (45.11%)

Epoch: 91
Loss: 1.617 | Acc: 53.125% (34/64)
Loss: 1.546 | Acc: 55.631% (3596/6464)
Loss: 1.553 | Acc: 55.434% (7131/12864)
Loss: 1.552 | Acc: 55.227% (10639/19264)
Loss: 1.550 | Acc: 55.447% (14230/25664)
Loss: 1.552 | Acc: 55.392% (17761/32064)
Loss: 1.552 | Acc: 55.496% (21346/38464)
Loss: 1.552 | Acc: 55.570% (24931/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9291, Accuracy: 4468/10000 (44.68%)

Epoch: 92
Loss: 1.472 | Acc: 59.375% (38/64)
Loss: 1.513 | Acc: 56.652% (3662/6464)
Loss: 1.494 | Acc: 57.268% (7367/12864)
Loss: 1.502 | Acc: 57.039% (10988/19264)
Loss: 1.507 | Acc: 56.912% (14606/25664)
Loss: 1.515 | Acc: 56.565% (18137/32064)
Loss: 1.512 | Acc: 56.653% (21791/38464)
Loss: 1.513 | Acc: 56.571% (25380/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9655, Accuracy: 4451/10000 (44.51%)

Epoch: 93
Loss: 1.299 | Acc: 68.750% (44/64)
Loss: 1.470 | Acc: 57.410% (3711/6464)
Loss: 1.456 | Acc: 58.193% (7486/12864)
Loss: 1.458 | Acc: 58.010% (11175/19264)
Loss: 1.463 | Acc: 57.781% (14829/25664)
Loss: 1.462 | Acc: 57.869% (18555/32064)
Loss: 1.467 | Acc: 57.649% (22174/38464)
Loss: 1.470 | Acc: 57.599% (25841/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9659, Accuracy: 4466/10000 (44.66%)

Epoch: 94
Loss: 1.356 | Acc: 56.250% (36/64)
Loss: 1.393 | Acc: 59.746% (3862/6464)
Loss: 1.405 | Acc: 59.204% (7616/12864)
Loss: 1.412 | Acc: 59.074% (11380/19264)
Loss: 1.412 | Acc: 59.009% (15144/25664)
Loss: 1.416 | Acc: 58.879% (18879/32064)
Loss: 1.416 | Acc: 58.949% (22674/38464)
Loss: 1.416 | Acc: 58.936% (26441/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0168, Accuracy: 4363/10000 (43.63%)

Epoch: 95
Loss: 1.123 | Acc: 65.625% (42/64)
Loss: 1.394 | Acc: 59.978% (3877/6464)
Loss: 1.446 | Acc: 58.388% (7511/12864)
Loss: 1.486 | Acc: 57.096% (10999/19264)
Loss: 1.517 | Acc: 56.293% (14447/25664)
Loss: 1.543 | Acc: 55.598% (17827/32064)
Loss: 1.564 | Acc: 55.018% (21162/38464)
Loss: 1.577 | Acc: 54.745% (24561/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8766, Accuracy: 4506/10000 (45.06%)

Epoch: 96
Loss: 1.489 | Acc: 59.375% (38/64)
Loss: 1.711 | Acc: 50.665% (3275/6464)
Loss: 1.700 | Acc: 51.205% (6587/12864)
Loss: 1.712 | Acc: 50.758% (9778/19264)
Loss: 1.721 | Acc: 50.549% (12973/25664)
Loss: 1.722 | Acc: 50.655% (16242/32064)
Loss: 1.725 | Acc: 50.447% (19404/38464)
Loss: 1.731 | Acc: 50.172% (22509/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8757, Accuracy: 4507/10000 (45.07%)

Epoch: 97
Loss: 1.942 | Acc: 43.750% (28/64)
Loss: 1.756 | Acc: 49.489% (3199/6464)
Loss: 1.755 | Acc: 49.456% (6362/12864)
Loss: 1.763 | Acc: 49.086% (9456/19264)
Loss: 1.764 | Acc: 48.979% (12570/25664)
Loss: 1.767 | Acc: 48.912% (15683/32064)
Loss: 1.767 | Acc: 48.963% (18833/38464)
Loss: 1.768 | Acc: 48.921% (21948/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8770, Accuracy: 4452/10000 (44.52%)
torch.Size([100, 10])
Test set: Average loss: 1.8770, Accuracy: 4452/10000 (44.52%)

Epoch: 98
Loss: 1.514 | Acc: 59.375% (38/64)
Loss: 1.783 | Acc: 48.051% (3106/6464)
Loss: 1.788 | Acc: 48.119% (6190/12864)
Loss: 1.789 | Acc: 48.136% (9273/19264)
Loss: 1.787 | Acc: 48.208% (12372/25664)
Loss: 1.786 | Acc: 48.366% (15508/32064)
Loss: 1.785 | Acc: 48.396% (18615/38464)
Loss: 1.785 | Acc: 48.393% (21711/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8816, Accuracy: 4462/10000 (44.62%)
torch.Size([100, 10])
Test set: Average loss: 1.8816, Accuracy: 4462/10000 (44.62%)

Epoch: 99
Loss: 1.664 | Acc: 54.688% (35/64)
Loss: 1.770 | Acc: 48.933% (3163/6464)
Loss: 1.780 | Acc: 48.430% (6230/12864)
Loss: 1.781 | Acc: 48.427% (9329/19264)
Loss: 1.783 | Acc: 48.375% (12415/25664)
Loss: 1.782 | Acc: 48.335% (15498/32064)
Loss: 1.782 | Acc: 48.334% (18591/38464)
Loss: 1.782 | Acc: 48.288% (21664/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8802, Accuracy: 4457/10000 (44.57%)
torch.Size([100, 10])
Test set: Average loss: 1.8802, Accuracy: 4457/10000 (44.57%)

Epoch: 100
Loss: 1.906 | Acc: 42.188% (27/64)
Loss: 2.248 | Acc: 17.621% (1139/6464)
Loss: 2.169 | Acc: 23.523% (3026/12864)
Loss: 2.113 | Acc: 27.772% (5350/19264)
Loss: 2.071 | Acc: 30.580% (7848/25664)
Loss: 2.045 | Acc: 32.367% (10378/32064)
Loss: 2.022 | Acc: 33.881% (13032/38464)
Loss: 2.006 | Acc: 34.966% (15687/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1767, Accuracy: 3013/10000 (30.13%)

Epoch: 101
Loss: 2.095 | Acc: 31.250% (20/64)
Loss: 1.880 | Acc: 43.332% (2801/6464)
Loss: 1.884 | Acc: 43.097% (5544/12864)
Loss: 1.877 | Acc: 43.392% (8359/19264)
Loss: 1.881 | Acc: 43.286% (11109/25664)
Loss: 1.879 | Acc: 43.354% (13901/32064)
Loss: 1.877 | Acc: 43.482% (16725/38464)
Loss: 1.879 | Acc: 43.380% (19462/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0103, Accuracy: 3498/10000 (34.98%)

Epoch: 102
Loss: 1.901 | Acc: 37.500% (24/64)
Loss: 1.868 | Acc: 44.183% (2856/6464)
Loss: 1.868 | Acc: 44.084% (5671/12864)
Loss: 1.869 | Acc: 43.916% (8460/19264)
Loss: 1.865 | Acc: 44.027% (11299/25664)
Loss: 1.864 | Acc: 44.121% (14147/32064)
Loss: 1.867 | Acc: 43.976% (16915/38464)
Loss: 1.869 | Acc: 43.964% (19724/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1148, Accuracy: 3365/10000 (33.65%)

Epoch: 103
Loss: 2.014 | Acc: 37.500% (24/64)
Loss: 1.868 | Acc: 44.338% (2866/6464)
Loss: 1.866 | Acc: 44.193% (5685/12864)
Loss: 1.864 | Acc: 44.352% (8544/19264)
Loss: 1.864 | Acc: 44.354% (11383/25664)
Loss: 1.862 | Acc: 44.421% (14243/32064)
Loss: 1.861 | Acc: 44.468% (17104/38464)
Loss: 1.861 | Acc: 44.443% (19939/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0753, Accuracy: 3521/10000 (35.21%)

Epoch: 104
Loss: 1.801 | Acc: 46.875% (30/64)
Loss: 1.844 | Acc: 45.312% (2929/6464)
Loss: 1.850 | Acc: 44.986% (5787/12864)
Loss: 1.847 | Acc: 45.136% (8695/19264)
Loss: 1.851 | Acc: 44.790% (11495/25664)
Loss: 1.854 | Acc: 44.639% (14313/32064)
Loss: 1.859 | Acc: 44.369% (17066/38464)
Loss: 1.858 | Acc: 44.434% (19935/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0968, Accuracy: 3306/10000 (33.06%)

Epoch: 105
Loss: 2.129 | Acc: 26.562% (17/64)
Loss: 1.861 | Acc: 44.756% (2893/6464)
Loss: 1.846 | Acc: 45.134% (5806/12864)
Loss: 1.853 | Acc: 44.778% (8626/19264)
Loss: 1.849 | Acc: 44.872% (11516/25664)
Loss: 1.850 | Acc: 44.798% (14364/32064)
Loss: 1.852 | Acc: 44.702% (17194/38464)
Loss: 1.852 | Acc: 44.769% (20085/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3299, Accuracy: 2538/10000 (25.38%)

Epoch: 106
Loss: 2.139 | Acc: 31.250% (20/64)
Loss: 1.856 | Acc: 44.988% (2908/6464)
Loss: 1.866 | Acc: 44.341% (5704/12864)
Loss: 1.863 | Acc: 44.435% (8560/19264)
Loss: 1.859 | Acc: 44.650% (11459/25664)
Loss: 1.859 | Acc: 44.748% (14348/32064)
Loss: 1.859 | Acc: 44.691% (17190/38464)
Loss: 1.857 | Acc: 44.818% (20107/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0396, Accuracy: 3559/10000 (35.59%)

Epoch: 107
Loss: 2.040 | Acc: 37.500% (24/64)
Loss: 1.837 | Acc: 45.096% (2915/6464)
Loss: 1.844 | Acc: 44.776% (5760/12864)
Loss: 1.842 | Acc: 45.043% (8677/19264)
Loss: 1.846 | Acc: 44.884% (11519/25664)
Loss: 1.845 | Acc: 45.066% (14450/32064)
Loss: 1.848 | Acc: 44.933% (17283/38464)
Loss: 1.850 | Acc: 44.902% (20145/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2307, Accuracy: 2967/10000 (29.67%)

Epoch: 108
Loss: 2.016 | Acc: 37.500% (24/64)
Loss: 1.840 | Acc: 45.405% (2935/6464)
Loss: 1.834 | Acc: 45.771% (5888/12864)
Loss: 1.837 | Acc: 45.645% (8793/19264)
Loss: 1.840 | Acc: 45.511% (11680/25664)
Loss: 1.841 | Acc: 45.359% (14544/32064)
Loss: 1.845 | Acc: 45.149% (17366/38464)
Loss: 1.846 | Acc: 45.143% (20253/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1400, Accuracy: 3271/10000 (32.71%)

Epoch: 109
Loss: 1.783 | Acc: 43.750% (28/64)
Loss: 1.852 | Acc: 45.668% (2952/6464)
Loss: 1.837 | Acc: 46.082% (5928/12864)
Loss: 1.843 | Acc: 45.665% (8797/19264)
Loss: 1.841 | Acc: 45.613% (11706/25664)
Loss: 1.845 | Acc: 45.366% (14546/32064)
Loss: 1.846 | Acc: 45.245% (17403/38464)
Loss: 1.847 | Acc: 45.232% (20293/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0247, Accuracy: 3621/10000 (36.21%)

Epoch: 110
Loss: 1.868 | Acc: 42.188% (27/64)
Loss: 1.856 | Acc: 44.787% (2895/6464)
Loss: 1.848 | Acc: 45.266% (5823/12864)
Loss: 1.846 | Acc: 45.427% (8751/19264)
Loss: 1.844 | Acc: 45.484% (11673/25664)
Loss: 1.844 | Acc: 45.428% (14566/32064)
Loss: 1.844 | Acc: 45.427% (17473/38464)
Loss: 1.842 | Acc: 45.560% (20440/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9109, Accuracy: 4208/10000 (42.08%)

Epoch: 111
Loss: 1.816 | Acc: 43.750% (28/64)
Loss: 1.819 | Acc: 46.349% (2996/6464)
Loss: 1.825 | Acc: 46.028% (5921/12864)
Loss: 1.831 | Acc: 45.738% (8811/19264)
Loss: 1.833 | Acc: 45.757% (11743/25664)
Loss: 1.839 | Acc: 45.512% (14593/32064)
Loss: 1.840 | Acc: 45.476% (17492/38464)
Loss: 1.842 | Acc: 45.433% (20383/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9995, Accuracy: 3822/10000 (38.22%)

Epoch: 112
Loss: 1.782 | Acc: 50.000% (32/64)
Loss: 1.828 | Acc: 46.132% (2982/6464)
Loss: 1.832 | Acc: 46.082% (5928/12864)
Loss: 1.832 | Acc: 46.034% (8868/19264)
Loss: 1.836 | Acc: 45.913% (11783/25664)
Loss: 1.836 | Acc: 45.858% (14704/32064)
Loss: 1.840 | Acc: 45.637% (17554/38464)
Loss: 1.838 | Acc: 45.591% (20454/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9417, Accuracy: 4030/10000 (40.30%)

Epoch: 113
Loss: 1.613 | Acc: 60.938% (39/64)
Loss: 1.807 | Acc: 46.906% (3032/6464)
Loss: 1.821 | Acc: 46.206% (5944/12864)
Loss: 1.827 | Acc: 46.003% (8862/19264)
Loss: 1.829 | Acc: 45.839% (11764/25664)
Loss: 1.832 | Acc: 45.690% (14650/32064)
Loss: 1.837 | Acc: 45.526% (17511/38464)
Loss: 1.836 | Acc: 45.611% (20463/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9664, Accuracy: 3951/10000 (39.51%)

Epoch: 114
Loss: 1.770 | Acc: 48.438% (31/64)
Loss: 1.828 | Acc: 45.931% (2969/6464)
Loss: 1.828 | Acc: 45.888% (5903/12864)
Loss: 1.828 | Acc: 45.930% (8848/19264)
Loss: 1.824 | Acc: 46.193% (11855/25664)
Loss: 1.828 | Acc: 46.117% (14787/32064)
Loss: 1.830 | Acc: 45.975% (17684/38464)
Loss: 1.833 | Acc: 45.861% (20575/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0241, Accuracy: 3576/10000 (35.76%)

Epoch: 115
Loss: 1.704 | Acc: 53.125% (34/64)
Loss: 1.795 | Acc: 47.339% (3060/6464)
Loss: 1.821 | Acc: 46.300% (5956/12864)
Loss: 1.822 | Acc: 46.242% (8908/19264)
Loss: 1.827 | Acc: 46.135% (11840/25664)
Loss: 1.830 | Acc: 46.024% (14757/32064)
Loss: 1.826 | Acc: 46.178% (17762/38464)
Loss: 1.827 | Acc: 46.139% (20700/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8817, Accuracy: 4371/10000 (43.71%)

Epoch: 116
Loss: 1.614 | Acc: 57.812% (37/64)
Loss: 1.815 | Acc: 46.349% (2996/6464)
Loss: 1.816 | Acc: 46.362% (5964/12864)
Loss: 1.823 | Acc: 46.081% (8877/19264)
Loss: 1.823 | Acc: 46.162% (11847/25664)
Loss: 1.822 | Acc: 46.239% (14826/32064)
Loss: 1.822 | Acc: 46.222% (17779/38464)
Loss: 1.824 | Acc: 46.137% (20699/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0676, Accuracy: 3301/10000 (33.01%)

Epoch: 117
Loss: 1.641 | Acc: 46.875% (30/64)
Loss: 1.808 | Acc: 46.798% (3025/6464)
Loss: 1.818 | Acc: 46.533% (5986/12864)
Loss: 1.820 | Acc: 46.579% (8973/19264)
Loss: 1.824 | Acc: 46.415% (11912/25664)
Loss: 1.825 | Acc: 46.435% (14889/32064)
Loss: 1.825 | Acc: 46.428% (17858/38464)
Loss: 1.823 | Acc: 46.523% (20872/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0007, Accuracy: 3903/10000 (39.03%)

Epoch: 118
Loss: 2.001 | Acc: 39.062% (25/64)
Loss: 1.810 | Acc: 46.798% (3025/6464)
Loss: 1.810 | Acc: 46.844% (6026/12864)
Loss: 1.812 | Acc: 46.917% (9038/19264)
Loss: 1.814 | Acc: 46.867% (12028/25664)
Loss: 1.815 | Acc: 46.828% (15015/32064)
Loss: 1.814 | Acc: 46.917% (18046/38464)
Loss: 1.814 | Acc: 46.873% (21029/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9788, Accuracy: 3944/10000 (39.44%)

Epoch: 119
Loss: 1.697 | Acc: 53.125% (34/64)
Loss: 1.827 | Acc: 46.395% (2999/6464)
Loss: 1.819 | Acc: 46.704% (6008/12864)
Loss: 1.806 | Acc: 47.026% (9059/19264)
Loss: 1.810 | Acc: 47.031% (12070/25664)
Loss: 1.811 | Acc: 47.087% (15098/32064)
Loss: 1.814 | Acc: 46.932% (18052/38464)
Loss: 1.816 | Acc: 46.790% (20992/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9406, Accuracy: 4113/10000 (41.13%)

Epoch: 120
Loss: 1.642 | Acc: 51.562% (33/64)
Loss: 1.827 | Acc: 46.272% (2991/6464)
Loss: 1.821 | Acc: 46.346% (5962/12864)
Loss: 1.811 | Acc: 46.813% (9018/19264)
Loss: 1.808 | Acc: 46.953% (12050/25664)
Loss: 1.809 | Acc: 47.037% (15082/32064)
Loss: 1.808 | Acc: 47.096% (18115/38464)
Loss: 1.810 | Acc: 47.029% (21099/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9559, Accuracy: 4091/10000 (40.91%)

Epoch: 121
Loss: 1.825 | Acc: 45.312% (29/64)
Loss: 1.806 | Acc: 47.169% (3049/6464)
Loss: 1.802 | Acc: 47.411% (6099/12864)
Loss: 1.798 | Acc: 47.550% (9160/19264)
Loss: 1.803 | Acc: 47.233% (12122/25664)
Loss: 1.802 | Acc: 47.271% (15157/32064)
Loss: 1.803 | Acc: 47.236% (18169/38464)
Loss: 1.805 | Acc: 47.198% (21175/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9624, Accuracy: 4084/10000 (40.84%)

Epoch: 122
Loss: 1.963 | Acc: 34.375% (22/64)
Loss: 1.793 | Acc: 47.416% (3065/6464)
Loss: 1.801 | Acc: 47.163% (6067/12864)
Loss: 1.798 | Acc: 47.404% (9132/19264)
Loss: 1.795 | Acc: 47.541% (12201/25664)
Loss: 1.797 | Acc: 47.458% (15217/32064)
Loss: 1.798 | Acc: 47.473% (18260/38464)
Loss: 1.800 | Acc: 47.381% (21257/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9704, Accuracy: 3994/10000 (39.94%)

Epoch: 123
Loss: 1.950 | Acc: 39.062% (25/64)
Loss: 1.785 | Acc: 47.757% (3087/6464)
Loss: 1.794 | Acc: 47.544% (6116/12864)
Loss: 1.790 | Acc: 47.892% (9226/19264)
Loss: 1.786 | Acc: 48.071% (12337/25664)
Loss: 1.786 | Acc: 48.013% (15395/32064)
Loss: 1.788 | Acc: 47.915% (18430/38464)
Loss: 1.791 | Acc: 47.800% (21445/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8999, Accuracy: 4274/10000 (42.74%)

Epoch: 124
Loss: 1.788 | Acc: 46.875% (30/64)
Loss: 1.781 | Acc: 48.113% (3110/6464)
Loss: 1.775 | Acc: 48.492% (6238/12864)
Loss: 1.778 | Acc: 48.349% (9314/19264)
Loss: 1.777 | Acc: 48.317% (12400/25664)
Loss: 1.781 | Acc: 48.138% (15435/32064)
Loss: 1.785 | Acc: 48.014% (18468/38464)
Loss: 1.788 | Acc: 47.876% (21479/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9345, Accuracy: 4081/10000 (40.81%)

Epoch: 125
Loss: 1.814 | Acc: 48.438% (31/64)
Loss: 1.789 | Acc: 47.989% (3102/6464)
Loss: 1.776 | Acc: 48.430% (6230/12864)
Loss: 1.778 | Acc: 48.292% (9303/19264)
Loss: 1.772 | Acc: 48.539% (12457/25664)
Loss: 1.779 | Acc: 48.338% (15499/32064)
Loss: 1.779 | Acc: 48.297% (18577/38464)
Loss: 1.780 | Acc: 48.232% (21639/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9843, Accuracy: 3714/10000 (37.14%)

Epoch: 126
Loss: 1.797 | Acc: 40.625% (26/64)
Loss: 1.743 | Acc: 49.397% (3193/6464)
Loss: 1.765 | Acc: 48.678% (6262/12864)
Loss: 1.769 | Acc: 48.552% (9353/19264)
Loss: 1.774 | Acc: 48.348% (12408/25664)
Loss: 1.778 | Acc: 48.200% (15455/32064)
Loss: 1.770 | Acc: 48.586% (18688/38464)
Loss: 1.771 | Acc: 48.582% (21796/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9861, Accuracy: 3950/10000 (39.50%)

Epoch: 127
Loss: 1.719 | Acc: 54.688% (35/64)
Loss: 1.774 | Acc: 48.577% (3140/6464)
Loss: 1.766 | Acc: 48.865% (6286/12864)
Loss: 1.771 | Acc: 48.676% (9377/19264)
Loss: 1.769 | Acc: 48.796% (12523/25664)
Loss: 1.770 | Acc: 48.731% (15625/32064)
Loss: 1.767 | Acc: 48.817% (18777/38464)
Loss: 1.765 | Acc: 48.892% (21935/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0473, Accuracy: 3443/10000 (34.43%)

Epoch: 128
Loss: 2.145 | Acc: 34.375% (22/64)
Loss: 1.740 | Acc: 49.644% (3209/6464)
Loss: 1.748 | Acc: 49.518% (6370/12864)
Loss: 1.748 | Acc: 49.486% (9533/19264)
Loss: 1.753 | Acc: 49.400% (12678/25664)
Loss: 1.755 | Acc: 49.301% (15808/32064)
Loss: 1.756 | Acc: 49.173% (18914/38464)
Loss: 1.757 | Acc: 49.108% (22032/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8691, Accuracy: 4487/10000 (44.87%)

Epoch: 129
Loss: 1.729 | Acc: 48.438% (31/64)
Loss: 1.734 | Acc: 50.449% (3261/6464)
Loss: 1.732 | Acc: 50.389% (6482/12864)
Loss: 1.734 | Acc: 50.166% (9664/19264)
Loss: 1.737 | Acc: 50.062% (12848/25664)
Loss: 1.745 | Acc: 49.719% (15942/32064)
Loss: 1.748 | Acc: 49.652% (19098/38464)
Loss: 1.749 | Acc: 49.597% (22251/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9060, Accuracy: 4292/10000 (42.92%)

Epoch: 130
Loss: 1.875 | Acc: 45.312% (29/64)
Loss: 1.734 | Acc: 50.062% (3236/6464)
Loss: 1.742 | Acc: 49.596% (6380/12864)
Loss: 1.748 | Acc: 49.362% (9509/19264)
Loss: 1.747 | Acc: 49.505% (12705/25664)
Loss: 1.744 | Acc: 49.682% (15930/32064)
Loss: 1.744 | Acc: 49.680% (19109/38464)
Loss: 1.742 | Acc: 49.775% (22331/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9175, Accuracy: 4329/10000 (43.29%)

Epoch: 131
Loss: 1.839 | Acc: 43.750% (28/64)
Loss: 1.709 | Acc: 51.207% (3310/6464)
Loss: 1.720 | Acc: 50.684% (6520/12864)
Loss: 1.719 | Acc: 50.638% (9755/19264)
Loss: 1.720 | Acc: 50.690% (13009/25664)
Loss: 1.723 | Acc: 50.621% (16231/32064)
Loss: 1.727 | Acc: 50.450% (19405/38464)
Loss: 1.732 | Acc: 50.283% (22559/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8738, Accuracy: 4484/10000 (44.84%)

Epoch: 132
Loss: 2.139 | Acc: 32.812% (21/64)
Loss: 1.704 | Acc: 51.361% (3320/6464)
Loss: 1.709 | Acc: 51.197% (6586/12864)
Loss: 1.715 | Acc: 50.877% (9801/19264)
Loss: 1.714 | Acc: 50.916% (13067/25664)
Loss: 1.716 | Acc: 50.851% (16305/32064)
Loss: 1.719 | Acc: 50.762% (19525/38464)
Loss: 1.719 | Acc: 50.749% (22768/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8738, Accuracy: 4483/10000 (44.83%)

Epoch: 133
Loss: 1.665 | Acc: 53.125% (34/64)
Loss: 1.667 | Acc: 52.738% (3409/6464)
Loss: 1.701 | Acc: 51.298% (6599/12864)
Loss: 1.715 | Acc: 50.732% (9773/19264)
Loss: 1.715 | Acc: 50.830% (13045/25664)
Loss: 1.716 | Acc: 50.789% (16285/32064)
Loss: 1.713 | Acc: 50.827% (19550/38464)
Loss: 1.711 | Acc: 50.996% (22879/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8798, Accuracy: 4525/10000 (45.25%)

Epoch: 134
Loss: 1.562 | Acc: 57.812% (37/64)
Loss: 1.684 | Acc: 51.825% (3350/6464)
Loss: 1.693 | Acc: 51.485% (6623/12864)
Loss: 1.694 | Acc: 51.453% (9912/19264)
Loss: 1.695 | Acc: 51.500% (13217/25664)
Loss: 1.697 | Acc: 51.438% (16493/32064)
Loss: 1.693 | Acc: 51.651% (19867/38464)
Loss: 1.692 | Acc: 51.710% (23199/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8557, Accuracy: 4613/10000 (46.13%)

Epoch: 135
Loss: 1.909 | Acc: 43.750% (28/64)
Loss: 1.680 | Acc: 52.058% (3365/6464)
Loss: 1.671 | Acc: 52.254% (6722/12864)
Loss: 1.671 | Acc: 52.191% (10054/19264)
Loss: 1.675 | Acc: 52.026% (13352/25664)
Loss: 1.676 | Acc: 52.121% (16712/32064)
Loss: 1.679 | Acc: 52.046% (20019/38464)
Loss: 1.680 | Acc: 51.968% (23315/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9052, Accuracy: 4369/10000 (43.69%)

Epoch: 136
Loss: 2.078 | Acc: 32.812% (21/64)
Loss: 1.660 | Acc: 52.785% (3412/6464)
Loss: 1.651 | Acc: 53.109% (6832/12864)
Loss: 1.652 | Acc: 52.969% (10204/19264)
Loss: 1.661 | Acc: 52.548% (13486/25664)
Loss: 1.665 | Acc: 52.299% (16769/32064)
Loss: 1.667 | Acc: 52.207% (20081/38464)
Loss: 1.664 | Acc: 52.376% (23498/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9145, Accuracy: 4334/10000 (43.34%)

Epoch: 137
Loss: 1.657 | Acc: 51.562% (33/64)
Loss: 1.620 | Acc: 53.929% (3486/6464)
Loss: 1.627 | Acc: 53.545% (6888/12864)
Loss: 1.638 | Acc: 53.011% (10212/19264)
Loss: 1.634 | Acc: 53.215% (13657/25664)
Loss: 1.635 | Acc: 53.212% (17062/32064)
Loss: 1.639 | Acc: 53.063% (20410/38464)
Loss: 1.641 | Acc: 53.045% (23798/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8706, Accuracy: 4640/10000 (46.40%)

Epoch: 138
Loss: 1.733 | Acc: 46.875% (30/64)
Loss: 1.598 | Acc: 54.533% (3525/6464)
Loss: 1.612 | Acc: 54.050% (6953/12864)
Loss: 1.615 | Acc: 53.893% (10382/19264)
Loss: 1.622 | Acc: 53.776% (13801/25664)
Loss: 1.621 | Acc: 53.820% (17257/32064)
Loss: 1.619 | Acc: 53.879% (20724/38464)
Loss: 1.615 | Acc: 54.017% (24234/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8786, Accuracy: 4606/10000 (46.06%)

Epoch: 139
Loss: 1.570 | Acc: 53.125% (34/64)
Loss: 1.571 | Acc: 54.858% (3546/6464)
Loss: 1.569 | Acc: 55.076% (7085/12864)
Loss: 1.571 | Acc: 55.082% (10611/19264)
Loss: 1.579 | Acc: 54.882% (14085/25664)
Loss: 1.585 | Acc: 54.753% (17556/32064)
Loss: 1.587 | Acc: 54.656% (21023/38464)
Loss: 1.591 | Acc: 54.494% (24448/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9072, Accuracy: 4532/10000 (45.32%)

Epoch: 140
Loss: 1.667 | Acc: 48.438% (31/64)
Loss: 1.541 | Acc: 56.219% (3634/6464)
Loss: 1.558 | Acc: 55.675% (7162/12864)
Loss: 1.558 | Acc: 55.793% (10748/19264)
Loss: 1.560 | Acc: 55.662% (14285/25664)
Loss: 1.560 | Acc: 55.695% (17858/32064)
Loss: 1.564 | Acc: 55.447% (21327/38464)
Loss: 1.564 | Acc: 55.474% (24888/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9224, Accuracy: 4531/10000 (45.31%)

Epoch: 141
Loss: 1.554 | Acc: 53.125% (34/64)
Loss: 1.497 | Acc: 57.147% (3694/6464)
Loss: 1.511 | Acc: 56.600% (7281/12864)
Loss: 1.511 | Acc: 56.696% (10922/19264)
Loss: 1.522 | Acc: 56.289% (14446/25664)
Loss: 1.523 | Acc: 56.303% (18053/32064)
Loss: 1.524 | Acc: 56.414% (21699/38464)
Loss: 1.527 | Acc: 56.297% (25257/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9384, Accuracy: 4526/10000 (45.26%)

Epoch: 142
Loss: 1.276 | Acc: 65.625% (42/64)
Loss: 1.495 | Acc: 56.761% (3669/6464)
Loss: 1.490 | Acc: 56.926% (7323/12864)
Loss: 1.497 | Acc: 56.811% (10944/19264)
Loss: 1.493 | Acc: 56.959% (14618/25664)
Loss: 1.492 | Acc: 57.027% (18285/32064)
Loss: 1.490 | Acc: 57.066% (21950/38464)
Loss: 1.490 | Acc: 57.144% (25637/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9698, Accuracy: 4502/10000 (45.02%)

Epoch: 143
Loss: 1.304 | Acc: 60.938% (39/64)
Loss: 1.431 | Acc: 58.973% (3812/6464)
Loss: 1.443 | Acc: 58.473% (7522/12864)
Loss: 1.437 | Acc: 58.607% (11290/19264)
Loss: 1.438 | Acc: 58.502% (15014/25664)
Loss: 1.439 | Acc: 58.527% (18766/32064)
Loss: 1.443 | Acc: 58.423% (22472/38464)
Loss: 1.445 | Acc: 58.359% (26182/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9874, Accuracy: 4444/10000 (44.44%)

Epoch: 144
Loss: 1.600 | Acc: 53.125% (34/64)
Loss: 1.388 | Acc: 59.468% (3844/6464)
Loss: 1.391 | Acc: 59.546% (7660/12864)
Loss: 1.387 | Acc: 59.795% (11519/19264)
Loss: 1.389 | Acc: 59.846% (15359/25664)
Loss: 1.387 | Acc: 59.955% (19224/32064)
Loss: 1.387 | Acc: 59.905% (23042/38464)
Loss: 1.391 | Acc: 59.845% (26849/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0425, Accuracy: 4383/10000 (43.83%)

Epoch: 145
Loss: 1.344 | Acc: 59.375% (38/64)
Loss: 1.380 | Acc: 59.653% (3856/6464)
Loss: 1.418 | Acc: 58.963% (7585/12864)
Loss: 1.446 | Acc: 58.332% (11237/19264)
Loss: 1.469 | Acc: 57.797% (14833/25664)
Loss: 1.494 | Acc: 57.114% (18313/32064)
Loss: 1.516 | Acc: 56.505% (21734/38464)
Loss: 1.536 | Acc: 56.034% (25139/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8968, Accuracy: 4465/10000 (44.65%)

Epoch: 146
Loss: 1.669 | Acc: 48.438% (31/64)
Loss: 1.639 | Acc: 53.156% (3436/6464)
Loss: 1.649 | Acc: 52.791% (6791/12864)
Loss: 1.667 | Acc: 52.170% (10050/19264)
Loss: 1.670 | Acc: 52.178% (13391/25664)
Loss: 1.677 | Acc: 51.974% (16665/32064)
Loss: 1.687 | Acc: 51.609% (19851/38464)
Loss: 1.694 | Acc: 51.313% (23021/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8851, Accuracy: 4477/10000 (44.77%)

Epoch: 147
Loss: 1.647 | Acc: 53.125% (34/64)
Loss: 1.709 | Acc: 50.975% (3295/6464)
Loss: 1.717 | Acc: 50.544% (6502/12864)
Loss: 1.728 | Acc: 50.244% (9679/19264)
Loss: 1.727 | Acc: 50.323% (12915/25664)
Loss: 1.732 | Acc: 50.100% (16064/32064)
Loss: 1.737 | Acc: 49.935% (19207/38464)
Loss: 1.735 | Acc: 50.020% (22441/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8849, Accuracy: 4470/10000 (44.70%)
torch.Size([100, 10])
Test set: Average loss: 1.8849, Accuracy: 4470/10000 (44.70%)

Epoch: 148
Loss: 1.697 | Acc: 51.562% (33/64)
Loss: 1.738 | Acc: 50.015% (3233/6464)
Loss: 1.747 | Acc: 49.782% (6404/12864)
Loss: 1.748 | Acc: 49.798% (9593/19264)
Loss: 1.744 | Acc: 49.758% (12770/25664)
Loss: 1.744 | Acc: 49.744% (15950/32064)
Loss: 1.746 | Acc: 49.685% (19111/38464)
Loss: 1.746 | Acc: 49.719% (22306/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8781, Accuracy: 4483/10000 (44.83%)
torch.Size([100, 10])
Test set: Average loss: 1.8781, Accuracy: 4483/10000 (44.83%)

Epoch: 149
Loss: 1.618 | Acc: 54.688% (35/64)
Loss: 1.739 | Acc: 50.278% (3250/6464)
Loss: 1.747 | Acc: 49.759% (6401/12864)
Loss: 1.748 | Acc: 49.413% (9519/19264)
Loss: 1.749 | Acc: 49.380% (12673/25664)
Loss: 1.747 | Acc: 49.429% (15849/32064)
Loss: 1.749 | Acc: 49.324% (18972/38464)
Loss: 1.746 | Acc: 49.438% (22180/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8793, Accuracy: 4477/10000 (44.77%)
torch.Size([100, 10])
Test set: Average loss: 1.8793, Accuracy: 4477/10000 (44.77%)

Epoch: 150
Loss: 1.849 | Acc: 39.062% (25/64)
Loss: 2.163 | Acc: 24.861% (1607/6464)
Loss: 2.082 | Acc: 30.325% (3901/12864)
Loss: 2.042 | Acc: 33.238% (6403/19264)
Loss: 2.010 | Acc: 35.369% (9077/25664)
Loss: 1.985 | Acc: 36.892% (11829/32064)
Loss: 1.971 | Acc: 37.718% (14508/38464)
Loss: 1.957 | Acc: 38.664% (17346/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1488, Accuracy: 3160/10000 (31.60%)

Epoch: 151
Loss: 2.023 | Acc: 39.062% (25/64)
Loss: 1.872 | Acc: 43.858% (2835/6464)
Loss: 1.864 | Acc: 44.045% (5666/12864)
Loss: 1.868 | Acc: 43.901% (8457/19264)
Loss: 1.869 | Acc: 43.859% (11256/25664)
Loss: 1.870 | Acc: 43.918% (14082/32064)
Loss: 1.871 | Acc: 43.914% (16891/38464)
Loss: 1.870 | Acc: 43.902% (19696/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1280, Accuracy: 3424/10000 (34.24%)

Epoch: 152
Loss: 1.701 | Acc: 50.000% (32/64)
Loss: 1.842 | Acc: 44.817% (2897/6464)
Loss: 1.853 | Acc: 44.488% (5723/12864)
Loss: 1.857 | Acc: 44.357% (8545/19264)
Loss: 1.859 | Acc: 44.338% (11379/25664)
Loss: 1.861 | Acc: 44.290% (14201/32064)
Loss: 1.859 | Acc: 44.434% (17091/38464)
Loss: 1.858 | Acc: 44.501% (19965/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0770, Accuracy: 3303/10000 (33.03%)

Epoch: 153
Loss: 1.814 | Acc: 43.750% (28/64)
Loss: 1.857 | Acc: 44.709% (2890/6464)
Loss: 1.849 | Acc: 45.126% (5805/12864)
Loss: 1.856 | Acc: 44.747% (8620/19264)
Loss: 1.847 | Acc: 45.184% (11596/25664)
Loss: 1.849 | Acc: 45.022% (14436/32064)
Loss: 1.852 | Acc: 44.813% (17237/38464)
Loss: 1.852 | Acc: 44.862% (20127/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9975, Accuracy: 3709/10000 (37.09%)

Epoch: 154
Loss: 2.127 | Acc: 34.375% (22/64)
Loss: 1.835 | Acc: 45.343% (2931/6464)
Loss: 1.840 | Acc: 45.305% (5828/12864)
Loss: 1.843 | Acc: 45.318% (8730/19264)
Loss: 1.844 | Acc: 45.344% (11637/25664)
Loss: 1.842 | Acc: 45.425% (14565/32064)
Loss: 1.842 | Acc: 45.390% (17459/38464)
Loss: 1.843 | Acc: 45.408% (20372/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9500, Accuracy: 3959/10000 (39.59%)

Epoch: 155
Loss: 1.886 | Acc: 43.750% (28/64)
Loss: 1.846 | Acc: 45.452% (2938/6464)
Loss: 1.851 | Acc: 45.118% (5804/12864)
Loss: 1.844 | Acc: 45.344% (8735/19264)
Loss: 1.841 | Acc: 45.496% (11676/25664)
Loss: 1.840 | Acc: 45.556% (14607/32064)
Loss: 1.842 | Acc: 45.422% (17471/38464)
Loss: 1.843 | Acc: 45.379% (20359/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9905, Accuracy: 3876/10000 (38.76%)

Epoch: 156
Loss: 1.662 | Acc: 53.125% (34/64)
Loss: 1.843 | Acc: 45.560% (2945/6464)
Loss: 1.844 | Acc: 45.476% (5850/12864)
Loss: 1.835 | Acc: 45.842% (8831/19264)
Loss: 1.836 | Acc: 45.854% (11768/25664)
Loss: 1.841 | Acc: 45.537% (14601/32064)
Loss: 1.842 | Acc: 45.455% (17484/38464)
Loss: 1.841 | Acc: 45.522% (20423/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9613, Accuracy: 3926/10000 (39.26%)

Epoch: 157
Loss: 1.916 | Acc: 40.625% (26/64)
Loss: 1.845 | Acc: 45.560% (2945/6464)
Loss: 1.839 | Acc: 45.732% (5883/12864)
Loss: 1.843 | Acc: 45.489% (8763/19264)
Loss: 1.842 | Acc: 45.480% (11672/25664)
Loss: 1.843 | Acc: 45.350% (14541/32064)
Loss: 1.844 | Acc: 45.312% (17429/38464)
Loss: 1.843 | Acc: 45.451% (20391/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9826, Accuracy: 3826/10000 (38.26%)

Epoch: 158
Loss: 1.935 | Acc: 45.312% (29/64)
Loss: 1.839 | Acc: 46.009% (2974/6464)
Loss: 1.838 | Acc: 45.787% (5890/12864)
Loss: 1.841 | Acc: 45.582% (8781/19264)
Loss: 1.841 | Acc: 45.558% (11692/25664)
Loss: 1.842 | Acc: 45.512% (14593/32064)
Loss: 1.840 | Acc: 45.619% (17547/38464)
Loss: 1.840 | Acc: 45.687% (20497/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0176, Accuracy: 3750/10000 (37.50%)

Epoch: 159
Loss: 1.699 | Acc: 56.250% (36/64)
Loss: 1.831 | Acc: 45.978% (2972/6464)
Loss: 1.831 | Acc: 46.035% (5922/12864)
Loss: 1.832 | Acc: 45.977% (8857/19264)
Loss: 1.834 | Acc: 45.877% (11774/25664)
Loss: 1.834 | Acc: 45.808% (14688/32064)
Loss: 1.836 | Acc: 45.741% (17594/38464)
Loss: 1.837 | Acc: 45.734% (20518/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1315, Accuracy: 3314/10000 (33.14%)

Epoch: 160
Loss: 1.909 | Acc: 40.625% (26/64)
Loss: 1.828 | Acc: 46.163% (2984/6464)
Loss: 1.828 | Acc: 46.206% (5944/12864)
Loss: 1.828 | Acc: 46.096% (8880/19264)
Loss: 1.834 | Acc: 45.901% (11780/25664)
Loss: 1.831 | Acc: 46.055% (14767/32064)
Loss: 1.832 | Acc: 46.001% (17694/38464)
Loss: 1.834 | Acc: 45.914% (20599/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9510, Accuracy: 3928/10000 (39.28%)

Epoch: 161
Loss: 2.038 | Acc: 42.188% (27/64)
Loss: 1.838 | Acc: 45.931% (2969/6464)
Loss: 1.825 | Acc: 46.214% (5945/12864)
Loss: 1.833 | Acc: 45.998% (8861/19264)
Loss: 1.836 | Acc: 45.811% (11757/25664)
Loss: 1.837 | Acc: 45.830% (14695/32064)
Loss: 1.836 | Acc: 45.861% (17640/38464)
Loss: 1.834 | Acc: 45.961% (20620/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9346, Accuracy: 4008/10000 (40.08%)

Epoch: 162
Loss: 1.682 | Acc: 51.562% (33/64)
Loss: 1.828 | Acc: 45.823% (2962/6464)
Loss: 1.821 | Acc: 46.339% (5961/12864)
Loss: 1.824 | Acc: 46.200% (8900/19264)
Loss: 1.826 | Acc: 46.127% (11838/25664)
Loss: 1.832 | Acc: 45.918% (14723/32064)
Loss: 1.828 | Acc: 46.077% (17723/38464)
Loss: 1.829 | Acc: 45.977% (20627/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2355, Accuracy: 3136/10000 (31.36%)

Epoch: 163
Loss: 1.895 | Acc: 42.188% (27/64)
Loss: 1.810 | Acc: 46.349% (2996/6464)
Loss: 1.816 | Acc: 46.385% (5967/12864)
Loss: 1.820 | Acc: 46.211% (8902/19264)
Loss: 1.825 | Acc: 46.065% (11822/25664)
Loss: 1.826 | Acc: 46.039% (14762/32064)
Loss: 1.828 | Acc: 46.056% (17715/38464)
Loss: 1.830 | Acc: 46.032% (20652/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9420, Accuracy: 4152/10000 (41.52%)

Epoch: 164
Loss: 2.017 | Acc: 37.500% (24/64)
Loss: 1.825 | Acc: 46.101% (2980/6464)
Loss: 1.815 | Acc: 46.626% (5998/12864)
Loss: 1.818 | Acc: 46.522% (8962/19264)
Loss: 1.825 | Acc: 46.135% (11840/25664)
Loss: 1.825 | Acc: 46.145% (14796/32064)
Loss: 1.826 | Acc: 46.072% (17721/38464)
Loss: 1.828 | Acc: 46.008% (20641/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0525, Accuracy: 3544/10000 (35.44%)

Epoch: 165
Loss: 2.018 | Acc: 43.750% (28/64)
Loss: 1.842 | Acc: 45.715% (2955/6464)
Loss: 1.834 | Acc: 45.655% (5873/12864)
Loss: 1.830 | Acc: 45.884% (8839/19264)
Loss: 1.828 | Acc: 45.987% (11802/25664)
Loss: 1.823 | Acc: 46.261% (14833/32064)
Loss: 1.822 | Acc: 46.264% (17795/38464)
Loss: 1.822 | Acc: 46.311% (20777/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9772, Accuracy: 3876/10000 (38.76%)

Epoch: 166
Loss: 1.920 | Acc: 35.938% (23/64)
Loss: 1.800 | Acc: 47.478% (3069/6464)
Loss: 1.804 | Acc: 47.365% (6093/12864)
Loss: 1.805 | Acc: 47.119% (9077/19264)
Loss: 1.813 | Acc: 46.750% (11998/25664)
Loss: 1.815 | Acc: 46.703% (14975/32064)
Loss: 1.817 | Acc: 46.638% (17939/38464)
Loss: 1.818 | Acc: 46.661% (20934/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9725, Accuracy: 3968/10000 (39.68%)

Epoch: 167
Loss: 2.071 | Acc: 39.062% (25/64)
Loss: 1.808 | Acc: 46.736% (3021/6464)
Loss: 1.810 | Acc: 46.828% (6024/12864)
Loss: 1.814 | Acc: 46.735% (9003/19264)
Loss: 1.808 | Acc: 47.004% (12063/25664)
Loss: 1.810 | Acc: 46.940% (15051/32064)
Loss: 1.812 | Acc: 46.802% (18002/38464)
Loss: 1.813 | Acc: 46.777% (20986/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0313, Accuracy: 3647/10000 (36.47%)

Epoch: 168
Loss: 1.760 | Acc: 48.438% (31/64)
Loss: 1.815 | Acc: 46.875% (3030/6464)
Loss: 1.818 | Acc: 46.743% (6013/12864)
Loss: 1.814 | Acc: 46.844% (9024/19264)
Loss: 1.808 | Acc: 47.144% (12099/25664)
Loss: 1.810 | Acc: 46.990% (15067/32064)
Loss: 1.809 | Acc: 46.922% (18048/38464)
Loss: 1.812 | Acc: 46.764% (20980/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9676, Accuracy: 3886/10000 (38.86%)

Epoch: 169
Loss: 1.950 | Acc: 40.625% (26/64)
Loss: 1.813 | Acc: 47.014% (3039/6464)
Loss: 1.811 | Acc: 46.961% (6041/12864)
Loss: 1.809 | Acc: 47.114% (9076/19264)
Loss: 1.810 | Acc: 47.093% (12086/25664)
Loss: 1.811 | Acc: 47.012% (15074/32064)
Loss: 1.811 | Acc: 47.031% (18090/38464)
Loss: 1.810 | Acc: 47.089% (21126/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9282, Accuracy: 4131/10000 (41.31%)

Epoch: 170
Loss: 1.826 | Acc: 48.438% (31/64)
Loss: 1.792 | Acc: 47.618% (3078/6464)
Loss: 1.799 | Acc: 47.326% (6088/12864)
Loss: 1.803 | Acc: 47.316% (9115/19264)
Loss: 1.803 | Acc: 47.327% (12146/25664)
Loss: 1.804 | Acc: 47.280% (15160/32064)
Loss: 1.803 | Acc: 47.314% (18199/38464)
Loss: 1.805 | Acc: 47.180% (21167/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2962, Accuracy: 2535/10000 (25.35%)

Epoch: 171
Loss: 1.949 | Acc: 37.500% (24/64)
Loss: 1.789 | Acc: 47.865% (3094/6464)
Loss: 1.790 | Acc: 47.886% (6160/12864)
Loss: 1.790 | Acc: 47.872% (9222/19264)
Loss: 1.794 | Acc: 47.670% (12234/25664)
Loss: 1.792 | Acc: 47.783% (15321/32064)
Loss: 1.795 | Acc: 47.689% (18343/38464)
Loss: 1.799 | Acc: 47.519% (21319/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9653, Accuracy: 3915/10000 (39.15%)

Epoch: 172
Loss: 1.855 | Acc: 42.188% (27/64)
Loss: 1.790 | Acc: 47.710% (3084/6464)
Loss: 1.786 | Acc: 47.854% (6156/12864)
Loss: 1.782 | Acc: 48.048% (9256/19264)
Loss: 1.784 | Acc: 47.919% (12298/25664)
Loss: 1.788 | Acc: 47.829% (15336/32064)
Loss: 1.791 | Acc: 47.728% (18358/38464)
Loss: 1.792 | Acc: 47.706% (21403/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9846, Accuracy: 3892/10000 (38.92%)

Epoch: 173
Loss: 1.787 | Acc: 50.000% (32/64)
Loss: 1.811 | Acc: 46.983% (3037/6464)
Loss: 1.796 | Acc: 47.582% (6121/12864)
Loss: 1.793 | Acc: 47.892% (9226/19264)
Loss: 1.792 | Acc: 47.884% (12289/25664)
Loss: 1.788 | Acc: 48.048% (15406/32064)
Loss: 1.790 | Acc: 47.959% (18447/38464)
Loss: 1.787 | Acc: 48.063% (21563/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8775, Accuracy: 4382/10000 (43.82%)

Epoch: 174
Loss: 1.807 | Acc: 46.875% (30/64)
Loss: 1.770 | Acc: 48.422% (3130/6464)
Loss: 1.780 | Acc: 47.924% (6165/12864)
Loss: 1.770 | Acc: 48.552% (9353/19264)
Loss: 1.774 | Acc: 48.418% (12426/25664)
Loss: 1.778 | Acc: 48.300% (15487/32064)
Loss: 1.780 | Acc: 48.243% (18556/38464)
Loss: 1.782 | Acc: 48.161% (21607/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8685, Accuracy: 4492/10000 (44.92%)

Epoch: 175
Loss: 1.724 | Acc: 48.438% (31/64)
Loss: 1.770 | Acc: 48.778% (3153/6464)
Loss: 1.770 | Acc: 48.764% (6273/12864)
Loss: 1.767 | Acc: 48.832% (9407/19264)
Loss: 1.767 | Acc: 48.932% (12558/25664)
Loss: 1.763 | Acc: 49.105% (15745/32064)
Loss: 1.765 | Acc: 48.983% (18841/38464)
Loss: 1.770 | Acc: 48.801% (21894/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8957, Accuracy: 4276/10000 (42.76%)

Epoch: 176
Loss: 1.916 | Acc: 42.188% (27/64)
Loss: 1.776 | Acc: 48.298% (3122/6464)
Loss: 1.776 | Acc: 48.414% (6228/12864)
Loss: 1.775 | Acc: 48.500% (9343/19264)
Loss: 1.777 | Acc: 48.445% (12433/25664)
Loss: 1.777 | Acc: 48.515% (15556/32064)
Loss: 1.770 | Acc: 48.781% (18763/38464)
Loss: 1.766 | Acc: 48.874% (21927/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9053, Accuracy: 4294/10000 (42.94%)

Epoch: 177
Loss: 1.723 | Acc: 53.125% (34/64)
Loss: 1.773 | Acc: 48.840% (3157/6464)
Loss: 1.756 | Acc: 49.401% (6355/12864)
Loss: 1.758 | Acc: 49.372% (9511/19264)
Loss: 1.760 | Acc: 49.182% (12622/25664)
Loss: 1.763 | Acc: 49.127% (15752/32064)
Loss: 1.761 | Acc: 49.168% (18912/38464)
Loss: 1.760 | Acc: 49.244% (22093/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8989, Accuracy: 4267/10000 (42.67%)

Epoch: 178
Loss: 1.727 | Acc: 45.312% (29/64)
Loss: 1.721 | Acc: 50.449% (3261/6464)
Loss: 1.752 | Acc: 49.114% (6318/12864)
Loss: 1.746 | Acc: 49.471% (9530/19264)
Loss: 1.751 | Acc: 49.318% (12657/25664)
Loss: 1.749 | Acc: 49.498% (15871/32064)
Loss: 1.747 | Acc: 49.574% (19068/38464)
Loss: 1.750 | Acc: 49.532% (22222/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0984, Accuracy: 3379/10000 (33.79%)

Epoch: 179
Loss: 1.778 | Acc: 48.438% (31/64)
Loss: 1.751 | Acc: 49.381% (3192/6464)
Loss: 1.735 | Acc: 50.039% (6437/12864)
Loss: 1.737 | Acc: 49.787% (9591/19264)
Loss: 1.739 | Acc: 49.821% (12786/25664)
Loss: 1.737 | Acc: 49.963% (16020/32064)
Loss: 1.736 | Acc: 50.039% (19247/38464)
Loss: 1.741 | Acc: 49.877% (22377/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8682, Accuracy: 4467/10000 (44.67%)

Epoch: 180
Loss: 1.786 | Acc: 45.312% (29/64)
Loss: 1.713 | Acc: 50.866% (3288/6464)
Loss: 1.720 | Acc: 50.567% (6505/12864)
Loss: 1.721 | Acc: 50.555% (9739/19264)
Loss: 1.724 | Acc: 50.405% (12936/25664)
Loss: 1.732 | Acc: 50.094% (16062/32064)
Loss: 1.733 | Acc: 50.044% (19249/38464)
Loss: 1.734 | Acc: 50.089% (22472/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8886, Accuracy: 4390/10000 (43.90%)

Epoch: 181
Loss: 1.636 | Acc: 51.562% (33/64)
Loss: 1.709 | Acc: 50.913% (3291/6464)
Loss: 1.710 | Acc: 50.956% (6555/12864)
Loss: 1.705 | Acc: 51.256% (9874/19264)
Loss: 1.709 | Acc: 51.134% (13123/25664)
Loss: 1.715 | Acc: 50.886% (16316/32064)
Loss: 1.719 | Acc: 50.751% (19521/38464)
Loss: 1.722 | Acc: 50.629% (22714/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8865, Accuracy: 4407/10000 (44.07%)

Epoch: 182
Loss: 2.024 | Acc: 29.688% (19/64)
Loss: 1.714 | Acc: 50.727% (3279/6464)
Loss: 1.699 | Acc: 51.314% (6601/12864)
Loss: 1.698 | Acc: 51.412% (9904/19264)
Loss: 1.700 | Acc: 51.434% (13200/25664)
Loss: 1.705 | Acc: 51.244% (16431/32064)
Loss: 1.705 | Acc: 51.253% (19714/38464)
Loss: 1.709 | Acc: 51.094% (22923/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8835, Accuracy: 4468/10000 (44.68%)

Epoch: 183
Loss: 1.690 | Acc: 56.250% (36/64)
Loss: 1.692 | Acc: 51.918% (3356/6464)
Loss: 1.697 | Acc: 51.469% (6621/12864)
Loss: 1.698 | Acc: 51.568% (9934/19264)
Loss: 1.702 | Acc: 51.348% (13178/25664)
Loss: 1.705 | Acc: 51.248% (16432/32064)
Loss: 1.703 | Acc: 51.266% (19719/38464)
Loss: 1.704 | Acc: 51.297% (23014/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8914, Accuracy: 4518/10000 (45.18%)

Epoch: 184
Loss: 1.488 | Acc: 56.250% (36/64)
Loss: 1.665 | Acc: 52.599% (3400/6464)
Loss: 1.672 | Acc: 52.169% (6711/12864)
Loss: 1.678 | Acc: 51.895% (9997/19264)
Loss: 1.677 | Acc: 51.999% (13345/25664)
Loss: 1.679 | Acc: 51.993% (16671/32064)
Loss: 1.680 | Acc: 51.958% (19985/38464)
Loss: 1.687 | Acc: 51.763% (23223/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9592, Accuracy: 4158/10000 (41.58%)

Epoch: 185
Loss: 1.734 | Acc: 51.562% (33/64)
Loss: 1.651 | Acc: 52.491% (3393/6464)
Loss: 1.659 | Acc: 52.340% (6733/12864)
Loss: 1.661 | Acc: 52.393% (10093/19264)
Loss: 1.666 | Acc: 52.315% (13426/25664)
Loss: 1.667 | Acc: 52.295% (16768/32064)
Loss: 1.663 | Acc: 52.524% (20203/38464)
Loss: 1.668 | Acc: 52.354% (23488/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8941, Accuracy: 4393/10000 (43.93%)

Epoch: 186
Loss: 1.529 | Acc: 57.812% (37/64)
Loss: 1.637 | Acc: 53.202% (3439/6464)
Loss: 1.642 | Acc: 52.923% (6808/12864)
Loss: 1.650 | Acc: 52.720% (10156/19264)
Loss: 1.650 | Acc: 52.891% (13574/25664)
Loss: 1.649 | Acc: 52.882% (16956/32064)
Loss: 1.652 | Acc: 52.823% (20318/38464)
Loss: 1.652 | Acc: 52.837% (23705/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8627, Accuracy: 4631/10000 (46.31%)

Epoch: 187
Loss: 1.570 | Acc: 56.250% (36/64)
Loss: 1.645 | Acc: 52.908% (3420/6464)
Loss: 1.630 | Acc: 53.475% (6879/12864)
Loss: 1.629 | Acc: 53.499% (10306/19264)
Loss: 1.636 | Acc: 53.156% (13642/25664)
Loss: 1.636 | Acc: 53.150% (17042/32064)
Loss: 1.636 | Acc: 53.159% (20447/38464)
Loss: 1.633 | Acc: 53.245% (23888/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9307, Accuracy: 4275/10000 (42.75%)

Epoch: 188
Loss: 1.491 | Acc: 60.938% (39/64)
Loss: 1.600 | Acc: 54.053% (3494/6464)
Loss: 1.609 | Acc: 53.856% (6928/12864)
Loss: 1.607 | Acc: 54.007% (10404/19264)
Loss: 1.607 | Acc: 54.095% (13883/25664)
Loss: 1.608 | Acc: 54.092% (17344/32064)
Loss: 1.606 | Acc: 54.253% (20868/38464)
Loss: 1.610 | Acc: 54.032% (24241/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9026, Accuracy: 4532/10000 (45.32%)

Epoch: 189
Loss: 1.627 | Acc: 51.562% (33/64)
Loss: 1.568 | Acc: 55.399% (3581/6464)
Loss: 1.573 | Acc: 55.239% (7106/12864)
Loss: 1.571 | Acc: 55.347% (10662/19264)
Loss: 1.575 | Acc: 55.139% (14151/25664)
Loss: 1.579 | Acc: 54.968% (17625/32064)
Loss: 1.581 | Acc: 54.937% (21131/38464)
Loss: 1.585 | Acc: 54.772% (24573/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9472, Accuracy: 4402/10000 (44.02%)

Epoch: 190
Loss: 1.679 | Acc: 50.000% (32/64)
Loss: 1.536 | Acc: 55.770% (3605/6464)
Loss: 1.548 | Acc: 55.387% (7125/12864)
Loss: 1.549 | Acc: 55.612% (10713/19264)
Loss: 1.545 | Acc: 55.868% (14338/25664)
Loss: 1.544 | Acc: 55.994% (17954/32064)
Loss: 1.549 | Acc: 55.831% (21475/38464)
Loss: 1.549 | Acc: 55.873% (25067/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9395, Accuracy: 4461/10000 (44.61%)

Epoch: 191
Loss: 1.764 | Acc: 46.875% (30/64)
Loss: 1.508 | Acc: 56.807% (3672/6464)
Loss: 1.501 | Acc: 57.121% (7348/12864)
Loss: 1.509 | Acc: 56.821% (10946/19264)
Loss: 1.516 | Acc: 56.519% (14505/25664)
Loss: 1.514 | Acc: 56.537% (18128/32064)
Loss: 1.516 | Acc: 56.479% (21724/38464)
Loss: 1.517 | Acc: 56.480% (25339/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9652, Accuracy: 4367/10000 (43.67%)

Epoch: 192
Loss: 1.576 | Acc: 51.562% (33/64)
Loss: 1.485 | Acc: 57.194% (3697/6464)
Loss: 1.477 | Acc: 57.470% (7393/12864)
Loss: 1.469 | Acc: 57.802% (11135/19264)
Loss: 1.472 | Acc: 57.746% (14820/25664)
Loss: 1.478 | Acc: 57.494% (18435/32064)
Loss: 1.478 | Acc: 57.558% (22139/38464)
Loss: 1.476 | Acc: 57.641% (25860/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9927, Accuracy: 4441/10000 (44.41%)

Epoch: 193
Loss: 1.295 | Acc: 60.938% (39/64)
Loss: 1.420 | Acc: 59.158% (3824/6464)
Loss: 1.424 | Acc: 59.173% (7612/12864)
Loss: 1.421 | Acc: 59.302% (11424/19264)
Loss: 1.428 | Acc: 59.036% (15151/25664)
Loss: 1.423 | Acc: 59.135% (18961/32064)
Loss: 1.426 | Acc: 59.073% (22722/38464)
Loss: 1.427 | Acc: 59.067% (26500/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0211, Accuracy: 4382/10000 (43.82%)

Epoch: 194
Loss: 1.059 | Acc: 71.875% (46/64)
Loss: 1.367 | Acc: 60.582% (3916/6464)
Loss: 1.364 | Acc: 60.868% (7830/12864)
Loss: 1.363 | Acc: 60.886% (11729/19264)
Loss: 1.367 | Acc: 60.723% (15584/25664)
Loss: 1.373 | Acc: 60.457% (19385/32064)
Loss: 1.377 | Acc: 60.285% (23188/38464)
Loss: 1.374 | Acc: 60.409% (27102/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0629, Accuracy: 4348/10000 (43.48%)

Epoch: 195
Loss: 1.367 | Acc: 56.250% (36/64)
Loss: 1.361 | Acc: 60.566% (3915/6464)
Loss: 1.402 | Acc: 59.445% (7647/12864)
Loss: 1.433 | Acc: 58.555% (11280/19264)
Loss: 1.456 | Acc: 57.910% (14862/25664)
Loss: 1.477 | Acc: 57.404% (18406/32064)
Loss: 1.500 | Acc: 56.721% (21817/38464)
Loss: 1.519 | Acc: 56.223% (25224/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9153, Accuracy: 4440/10000 (44.40%)

Epoch: 196
Loss: 1.767 | Acc: 48.438% (31/64)
Loss: 1.631 | Acc: 52.785% (3412/6464)
Loss: 1.634 | Acc: 52.985% (6816/12864)
Loss: 1.656 | Acc: 52.263% (10068/19264)
Loss: 1.655 | Acc: 52.428% (13455/25664)
Loss: 1.659 | Acc: 52.355% (16787/32064)
Loss: 1.668 | Acc: 52.049% (20020/38464)
Loss: 1.673 | Acc: 51.904% (23286/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9028, Accuracy: 4471/10000 (44.71%)

Epoch: 197
Loss: 1.623 | Acc: 50.000% (32/64)
Loss: 1.696 | Acc: 51.191% (3309/6464)
Loss: 1.705 | Acc: 50.746% (6528/12864)
Loss: 1.701 | Acc: 50.914% (9808/19264)
Loss: 1.708 | Acc: 50.495% (12959/25664)
Loss: 1.711 | Acc: 50.549% (16208/32064)
Loss: 1.711 | Acc: 50.699% (19501/38464)
Loss: 1.715 | Acc: 50.586% (22695/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8945, Accuracy: 4457/10000 (44.57%)
torch.Size([100, 10])
Test set: Average loss: 1.8945, Accuracy: 4457/10000 (44.57%)

Epoch: 198
Loss: 1.503 | Acc: 62.500% (40/64)
Loss: 1.698 | Acc: 51.624% (3337/6464)
Loss: 1.708 | Acc: 50.995% (6560/12864)
Loss: 1.713 | Acc: 50.851% (9796/19264)
Loss: 1.715 | Acc: 50.842% (13048/25664)
Loss: 1.723 | Acc: 50.518% (16198/32064)
Loss: 1.722 | Acc: 50.465% (19411/38464)
Loss: 1.724 | Acc: 50.303% (22568/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8979, Accuracy: 4468/10000 (44.68%)
torch.Size([100, 10])
Test set: Average loss: 1.8979, Accuracy: 4468/10000 (44.68%)

Epoch: 199
Loss: 1.805 | Acc: 45.312% (29/64)
Loss: 1.734 | Acc: 50.387% (3257/6464)
Loss: 1.734 | Acc: 50.202% (6458/12864)
Loss: 1.730 | Acc: 50.067% (9645/19264)
Loss: 1.728 | Acc: 50.253% (12897/25664)
Loss: 1.729 | Acc: 50.256% (16114/32064)
Loss: 1.727 | Acc: 50.393% (19383/38464)
Loss: 1.726 | Acc: 50.426% (22623/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8977, Accuracy: 4462/10000 (44.62%)
torch.Size([100, 10])
Test set: Average loss: 1.8977, Accuracy: 4462/10000 (44.62%)
4759
10000
-1.8342894315719604
