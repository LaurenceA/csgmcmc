==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.358 | Acc: 15.625% (10/64)
Loss: 3.139 | Acc: 11.788% (762/6464)
Loss: 2.653 | Acc: 15.267% (1964/12864)
Loss: 2.463 | Acc: 17.520% (3375/19264)
Loss: 2.351 | Acc: 19.397% (4978/25664)
Loss: 2.275 | Acc: 20.964% (6722/32064)
Loss: 2.221 | Acc: 22.273% (8567/38464)
Loss: 2.172 | Acc: 23.533% (10558/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0410, Accuracy: 2988/10000 (29.88%)

Epoch: 1
Loss: 2.161 | Acc: 23.438% (15/64)
Loss: 1.819 | Acc: 33.911% (2192/6464)
Loss: 1.810 | Acc: 34.484% (4436/12864)
Loss: 1.797 | Acc: 35.034% (6749/19264)
Loss: 1.789 | Acc: 35.587% (9133/25664)
Loss: 1.779 | Acc: 36.190% (11604/32064)
Loss: 1.770 | Acc: 36.647% (14096/38464)
Loss: 1.759 | Acc: 37.224% (16700/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7056, Accuracy: 4015/10000 (40.15%)

Epoch: 2
Loss: 1.382 | Acc: 51.562% (33/64)
Loss: 1.649 | Acc: 41.909% (2709/6464)
Loss: 1.649 | Acc: 42.016% (5405/12864)
Loss: 1.637 | Acc: 42.624% (8211/19264)
Loss: 1.626 | Acc: 43.142% (11072/25664)
Loss: 1.617 | Acc: 43.688% (14008/32064)
Loss: 1.611 | Acc: 44.057% (16946/38464)
Loss: 1.605 | Acc: 44.392% (19916/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8527, Accuracy: 3885/10000 (38.85%)

Epoch: 3
Loss: 1.670 | Acc: 40.625% (26/64)
Loss: 1.524 | Acc: 47.942% (3099/6464)
Loss: 1.534 | Acc: 47.839% (6154/12864)
Loss: 1.515 | Acc: 48.790% (9399/19264)
Loss: 1.502 | Acc: 49.388% (12675/25664)
Loss: 1.491 | Acc: 49.916% (16005/32064)
Loss: 1.478 | Acc: 50.468% (19412/38464)
Loss: 1.468 | Acc: 50.996% (22879/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0079, Accuracy: 3737/10000 (37.37%)

Epoch: 4
Loss: 1.710 | Acc: 45.312% (29/64)
Loss: 1.385 | Acc: 55.538% (3590/6464)
Loss: 1.366 | Acc: 55.993% (7203/12864)
Loss: 1.354 | Acc: 56.401% (10865/19264)
Loss: 1.347 | Acc: 56.764% (14568/25664)
Loss: 1.340 | Acc: 56.908% (18247/32064)
Loss: 1.329 | Acc: 57.378% (22070/38464)
Loss: 1.324 | Acc: 57.650% (25864/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4191, Accuracy: 5479/10000 (54.79%)

Epoch: 5
Loss: 1.591 | Acc: 48.438% (31/64)
Loss: 1.222 | Acc: 61.866% (3999/6464)
Loss: 1.238 | Acc: 61.451% (7905/12864)
Loss: 1.232 | Acc: 61.592% (11865/19264)
Loss: 1.229 | Acc: 61.721% (15840/25664)
Loss: 1.218 | Acc: 62.126% (19920/32064)
Loss: 1.215 | Acc: 62.383% (23995/38464)
Loss: 1.208 | Acc: 62.685% (28123/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6334, Accuracy: 4862/10000 (48.62%)

Epoch: 6
Loss: 1.217 | Acc: 71.875% (46/64)
Loss: 1.143 | Acc: 65.687% (4246/6464)
Loss: 1.150 | Acc: 65.462% (8421/12864)
Loss: 1.138 | Acc: 65.755% (12667/19264)
Loss: 1.132 | Acc: 66.194% (16988/25664)
Loss: 1.121 | Acc: 66.529% (21332/32064)
Loss: 1.121 | Acc: 66.595% (25615/38464)
Loss: 1.119 | Acc: 66.639% (29897/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5166, Accuracy: 5292/10000 (52.92%)

Epoch: 7
Loss: 1.308 | Acc: 60.938% (39/64)
Loss: 1.068 | Acc: 68.239% (4411/6464)
Loss: 1.078 | Acc: 68.307% (8787/12864)
Loss: 1.080 | Acc: 68.459% (13188/19264)
Loss: 1.075 | Acc: 68.524% (17586/25664)
Loss: 1.068 | Acc: 68.809% (22063/32064)
Loss: 1.067 | Acc: 68.833% (26476/38464)
Loss: 1.060 | Acc: 69.004% (30958/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2337, Accuracy: 6286/10000 (62.86%)

Epoch: 8
Loss: 1.118 | Acc: 70.312% (45/64)
Loss: 1.031 | Acc: 70.096% (4531/6464)
Loss: 1.030 | Acc: 70.017% (9007/12864)
Loss: 1.029 | Acc: 70.354% (13553/19264)
Loss: 1.026 | Acc: 70.503% (18094/25664)
Loss: 1.021 | Acc: 70.543% (22619/32064)
Loss: 1.022 | Acc: 70.450% (27098/38464)
Loss: 1.019 | Acc: 70.569% (31660/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2679, Accuracy: 6245/10000 (62.45%)

Epoch: 9
Loss: 1.311 | Acc: 59.375% (38/64)
Loss: 0.985 | Acc: 71.844% (4644/6464)
Loss: 1.000 | Acc: 71.276% (9169/12864)
Loss: 0.999 | Acc: 71.195% (13715/19264)
Loss: 0.994 | Acc: 71.372% (18317/25664)
Loss: 0.997 | Acc: 71.351% (22878/32064)
Loss: 0.996 | Acc: 71.420% (27471/38464)
Loss: 0.991 | Acc: 71.596% (32121/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3654, Accuracy: 5711/10000 (57.11%)

Epoch: 10
Loss: 0.926 | Acc: 68.750% (44/64)
Loss: 0.988 | Acc: 71.844% (4644/6464)
Loss: 0.970 | Acc: 72.707% (9353/12864)
Loss: 0.971 | Acc: 72.659% (13997/19264)
Loss: 0.965 | Acc: 72.869% (18701/25664)
Loss: 0.967 | Acc: 72.823% (23350/32064)
Loss: 0.966 | Acc: 72.938% (28055/38464)
Loss: 0.966 | Acc: 72.898% (32705/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0746, Accuracy: 6943/10000 (69.43%)

Epoch: 11
Loss: 1.111 | Acc: 64.062% (41/64)
Loss: 0.952 | Acc: 73.499% (4751/6464)
Loss: 0.956 | Acc: 73.445% (9448/12864)
Loss: 0.942 | Acc: 73.816% (14220/19264)
Loss: 0.946 | Acc: 73.613% (18892/25664)
Loss: 0.945 | Acc: 73.618% (23605/32064)
Loss: 0.946 | Acc: 73.617% (28316/38464)
Loss: 0.949 | Acc: 73.553% (32999/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1980, Accuracy: 6518/10000 (65.18%)

Epoch: 12
Loss: 0.942 | Acc: 75.000% (48/64)
Loss: 0.922 | Acc: 74.660% (4826/6464)
Loss: 0.924 | Acc: 74.588% (9595/12864)
Loss: 0.923 | Acc: 74.465% (14345/19264)
Loss: 0.924 | Acc: 74.435% (19103/25664)
Loss: 0.922 | Acc: 74.510% (23891/32064)
Loss: 0.924 | Acc: 74.493% (28653/38464)
Loss: 0.928 | Acc: 74.363% (33362/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4530, Accuracy: 5632/10000 (56.32%)

Epoch: 13
Loss: 1.186 | Acc: 64.062% (41/64)
Loss: 0.917 | Acc: 75.541% (4883/6464)
Loss: 0.914 | Acc: 75.241% (9679/12864)
Loss: 0.915 | Acc: 74.917% (14432/19264)
Loss: 0.917 | Acc: 74.813% (19200/25664)
Loss: 0.908 | Acc: 75.178% (24105/32064)
Loss: 0.907 | Acc: 75.140% (28902/38464)
Loss: 0.909 | Acc: 75.098% (33692/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1934, Accuracy: 6551/10000 (65.51%)

Epoch: 14
Loss: 1.068 | Acc: 71.875% (46/64)
Loss: 0.938 | Acc: 73.685% (4763/6464)
Loss: 0.918 | Acc: 74.448% (9577/12864)
Loss: 0.904 | Acc: 75.067% (14461/19264)
Loss: 0.901 | Acc: 75.144% (19285/25664)
Loss: 0.898 | Acc: 75.352% (24161/32064)
Loss: 0.893 | Acc: 75.523% (29049/38464)
Loss: 0.893 | Acc: 75.602% (33918/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3712, Accuracy: 5909/10000 (59.09%)

Epoch: 15
Loss: 1.150 | Acc: 67.188% (43/64)
Loss: 0.863 | Acc: 76.284% (4931/6464)
Loss: 0.877 | Acc: 76.236% (9807/12864)
Loss: 0.888 | Acc: 75.981% (14637/19264)
Loss: 0.880 | Acc: 76.255% (19570/25664)
Loss: 0.879 | Acc: 76.238% (24445/32064)
Loss: 0.880 | Acc: 76.191% (29306/38464)
Loss: 0.878 | Acc: 76.273% (34219/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9861, Accuracy: 7275/10000 (72.75%)

Epoch: 16
Loss: 0.829 | Acc: 78.125% (50/64)
Loss: 0.857 | Acc: 76.996% (4977/6464)
Loss: 0.856 | Acc: 76.726% (9870/12864)
Loss: 0.853 | Acc: 76.941% (14822/19264)
Loss: 0.859 | Acc: 76.804% (19711/25664)
Loss: 0.858 | Acc: 76.965% (24678/32064)
Loss: 0.860 | Acc: 76.942% (29595/38464)
Loss: 0.858 | Acc: 76.877% (34490/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3111, Accuracy: 6280/10000 (62.80%)

Epoch: 17
Loss: 0.932 | Acc: 68.750% (44/64)
Loss: 0.838 | Acc: 77.645% (5019/6464)
Loss: 0.852 | Acc: 77.231% (9935/12864)
Loss: 0.856 | Acc: 77.071% (14847/19264)
Loss: 0.851 | Acc: 77.330% (19846/25664)
Loss: 0.849 | Acc: 77.411% (24821/32064)
Loss: 0.850 | Acc: 77.420% (29779/38464)
Loss: 0.847 | Acc: 77.488% (34764/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0818, Accuracy: 6968/10000 (69.68%)

Epoch: 18
Loss: 0.783 | Acc: 79.688% (51/64)
Loss: 0.810 | Acc: 78.651% (5084/6464)
Loss: 0.818 | Acc: 78.343% (10078/12864)
Loss: 0.826 | Acc: 78.156% (15056/19264)
Loss: 0.830 | Acc: 78.106% (20045/25664)
Loss: 0.830 | Acc: 78.031% (25020/32064)
Loss: 0.832 | Acc: 77.925% (29973/38464)
Loss: 0.833 | Acc: 77.884% (34942/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9532, Accuracy: 7398/10000 (73.98%)

Epoch: 19
Loss: 1.037 | Acc: 75.000% (48/64)
Loss: 0.817 | Acc: 78.357% (5065/6464)
Loss: 0.816 | Acc: 78.350% (10079/12864)
Loss: 0.810 | Acc: 78.608% (15143/19264)
Loss: 0.813 | Acc: 78.581% (20167/25664)
Loss: 0.816 | Acc: 78.496% (25169/32064)
Loss: 0.816 | Acc: 78.450% (30175/38464)
Loss: 0.817 | Acc: 78.424% (35184/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2786, Accuracy: 6139/10000 (61.39%)

Epoch: 20
Loss: 0.780 | Acc: 81.250% (52/64)
Loss: 0.807 | Acc: 79.053% (5110/6464)
Loss: 0.803 | Acc: 79.229% (10192/12864)
Loss: 0.804 | Acc: 78.919% (15203/19264)
Loss: 0.804 | Acc: 79.025% (20281/25664)
Loss: 0.801 | Acc: 79.073% (25354/32064)
Loss: 0.804 | Acc: 79.058% (30409/38464)
Loss: 0.805 | Acc: 79.061% (35470/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4140, Accuracy: 5915/10000 (59.15%)

Epoch: 21
Loss: 0.841 | Acc: 78.125% (50/64)
Loss: 0.789 | Acc: 78.960% (5104/6464)
Loss: 0.790 | Acc: 79.221% (10191/12864)
Loss: 0.784 | Acc: 79.469% (15309/19264)
Loss: 0.791 | Acc: 79.395% (20376/25664)
Loss: 0.790 | Acc: 79.466% (25480/32064)
Loss: 0.790 | Acc: 79.485% (30573/38464)
Loss: 0.790 | Acc: 79.496% (35665/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1034, Accuracy: 6915/10000 (69.15%)

Epoch: 22
Loss: 0.651 | Acc: 85.938% (55/64)
Loss: 0.780 | Acc: 80.043% (5174/6464)
Loss: 0.787 | Acc: 79.688% (10251/12864)
Loss: 0.780 | Acc: 79.859% (15384/19264)
Loss: 0.791 | Acc: 79.504% (20404/25664)
Loss: 0.780 | Acc: 79.706% (25557/32064)
Loss: 0.779 | Acc: 79.664% (30642/38464)
Loss: 0.778 | Acc: 79.712% (35762/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1502, Accuracy: 6734/10000 (67.34%)

Epoch: 23
Loss: 0.825 | Acc: 81.250% (52/64)
Loss: 0.728 | Acc: 81.235% (5251/6464)
Loss: 0.758 | Acc: 80.496% (10355/12864)
Loss: 0.763 | Acc: 80.430% (15494/19264)
Loss: 0.759 | Acc: 80.482% (20655/25664)
Loss: 0.763 | Acc: 80.293% (25745/32064)
Loss: 0.764 | Acc: 80.275% (30877/38464)
Loss: 0.764 | Acc: 80.347% (36047/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1799, Accuracy: 6516/10000 (65.16%)

Epoch: 24
Loss: 0.792 | Acc: 82.812% (53/64)
Loss: 0.750 | Acc: 80.461% (5201/6464)
Loss: 0.759 | Acc: 80.208% (10318/12864)
Loss: 0.755 | Acc: 80.471% (15502/19264)
Loss: 0.759 | Acc: 80.447% (20646/25664)
Loss: 0.754 | Acc: 80.561% (25831/32064)
Loss: 0.754 | Acc: 80.535% (30977/38464)
Loss: 0.757 | Acc: 80.497% (36114/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0781, Accuracy: 6958/10000 (69.58%)

Epoch: 25
Loss: 0.803 | Acc: 73.438% (47/64)
Loss: 0.732 | Acc: 81.822% (5289/6464)
Loss: 0.746 | Acc: 81.304% (10459/12864)
Loss: 0.739 | Acc: 81.463% (15693/19264)
Loss: 0.737 | Acc: 81.558% (20931/25664)
Loss: 0.738 | Acc: 81.574% (26156/32064)
Loss: 0.741 | Acc: 81.453% (31330/38464)
Loss: 0.741 | Acc: 81.408% (36523/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0312, Accuracy: 7113/10000 (71.13%)

Epoch: 26
Loss: 0.544 | Acc: 89.062% (57/64)
Loss: 0.741 | Acc: 81.281% (5254/6464)
Loss: 0.737 | Acc: 81.600% (10497/12864)
Loss: 0.726 | Acc: 81.888% (15775/19264)
Loss: 0.739 | Acc: 81.476% (20910/25664)
Loss: 0.739 | Acc: 81.440% (26113/32064)
Loss: 0.734 | Acc: 81.528% (31359/38464)
Loss: 0.730 | Acc: 81.562% (36592/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9490, Accuracy: 7462/10000 (74.62%)

Epoch: 27
Loss: 0.689 | Acc: 76.562% (49/64)
Loss: 0.744 | Acc: 81.451% (5265/6464)
Loss: 0.711 | Acc: 82.385% (10598/12864)
Loss: 0.711 | Acc: 82.273% (15849/19264)
Loss: 0.710 | Acc: 82.325% (21128/25664)
Loss: 0.704 | Acc: 82.544% (26467/32064)
Loss: 0.706 | Acc: 82.529% (31744/38464)
Loss: 0.709 | Acc: 82.438% (36985/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1582, Accuracy: 6880/10000 (68.80%)

Epoch: 28
Loss: 1.014 | Acc: 75.000% (48/64)
Loss: 0.687 | Acc: 82.828% (5354/6464)
Loss: 0.703 | Acc: 82.502% (10613/12864)
Loss: 0.692 | Acc: 82.740% (15939/19264)
Loss: 0.695 | Acc: 82.711% (21227/25664)
Loss: 0.694 | Acc: 82.769% (26539/32064)
Loss: 0.699 | Acc: 82.683% (31803/38464)
Loss: 0.699 | Acc: 82.723% (37113/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0957, Accuracy: 6841/10000 (68.41%)

Epoch: 29
Loss: 0.664 | Acc: 85.938% (55/64)
Loss: 0.658 | Acc: 83.431% (5393/6464)
Loss: 0.670 | Acc: 83.326% (10719/12864)
Loss: 0.668 | Acc: 83.508% (16087/19264)
Loss: 0.677 | Acc: 83.311% (21381/25664)
Loss: 0.679 | Acc: 83.187% (26673/32064)
Loss: 0.680 | Acc: 83.174% (31992/38464)
Loss: 0.679 | Acc: 83.178% (37317/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8888, Accuracy: 7654/10000 (76.54%)

Epoch: 30
Loss: 0.988 | Acc: 76.562% (49/64)
Loss: 0.645 | Acc: 84.623% (5470/6464)
Loss: 0.662 | Acc: 83.839% (10785/12864)
Loss: 0.660 | Acc: 83.996% (16181/19264)
Loss: 0.657 | Acc: 84.024% (21564/25664)
Loss: 0.665 | Acc: 83.839% (26882/32064)
Loss: 0.667 | Acc: 83.793% (32230/38464)
Loss: 0.669 | Acc: 83.769% (37582/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8536, Accuracy: 7837/10000 (78.37%)

Epoch: 31
Loss: 0.504 | Acc: 84.375% (54/64)
Loss: 0.619 | Acc: 85.272% (5512/6464)
Loss: 0.641 | Acc: 84.639% (10888/12864)
Loss: 0.649 | Acc: 84.484% (16275/19264)
Loss: 0.649 | Acc: 84.410% (21663/25664)
Loss: 0.652 | Acc: 84.291% (27027/32064)
Loss: 0.651 | Acc: 84.274% (32415/38464)
Loss: 0.654 | Acc: 84.177% (37765/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8074, Accuracy: 8000/10000 (80.00%)

Epoch: 32
Loss: 0.839 | Acc: 81.250% (52/64)
Loss: 0.643 | Acc: 84.561% (5466/6464)
Loss: 0.640 | Acc: 84.670% (10892/12864)
Loss: 0.638 | Acc: 84.707% (16318/19264)
Loss: 0.631 | Acc: 84.878% (21783/25664)
Loss: 0.632 | Acc: 84.852% (27207/32064)
Loss: 0.636 | Acc: 84.775% (32608/38464)
Loss: 0.634 | Acc: 84.854% (38069/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8287, Accuracy: 7904/10000 (79.04%)

Epoch: 33
Loss: 0.492 | Acc: 89.062% (57/64)
Loss: 0.582 | Acc: 86.231% (5574/6464)
Loss: 0.604 | Acc: 85.595% (11011/12864)
Loss: 0.607 | Acc: 85.533% (16477/19264)
Loss: 0.611 | Acc: 85.450% (21930/25664)
Loss: 0.606 | Acc: 85.585% (27442/32064)
Loss: 0.612 | Acc: 85.392% (32845/38464)
Loss: 0.614 | Acc: 85.356% (38294/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8586, Accuracy: 7820/10000 (78.20%)

Epoch: 34
Loss: 0.823 | Acc: 78.125% (50/64)
Loss: 0.581 | Acc: 86.046% (5562/6464)
Loss: 0.580 | Acc: 86.326% (11105/12864)
Loss: 0.584 | Acc: 86.223% (16610/19264)
Loss: 0.587 | Acc: 86.109% (22099/25664)
Loss: 0.592 | Acc: 85.991% (27572/32064)
Loss: 0.593 | Acc: 85.940% (33056/38464)
Loss: 0.596 | Acc: 85.909% (38542/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8293, Accuracy: 7980/10000 (79.80%)

Epoch: 35
Loss: 0.532 | Acc: 89.062% (57/64)
Loss: 0.553 | Acc: 86.680% (5603/6464)
Loss: 0.569 | Acc: 86.396% (11114/12864)
Loss: 0.572 | Acc: 86.415% (16647/19264)
Loss: 0.570 | Acc: 86.436% (22183/25664)
Loss: 0.569 | Acc: 86.499% (27735/32064)
Loss: 0.573 | Acc: 86.418% (33240/38464)
Loss: 0.575 | Acc: 86.312% (38723/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8173, Accuracy: 8017/10000 (80.17%)

Epoch: 36
Loss: 0.498 | Acc: 87.500% (56/64)
Loss: 0.536 | Acc: 87.299% (5643/6464)
Loss: 0.548 | Acc: 86.964% (11187/12864)
Loss: 0.547 | Acc: 87.090% (16777/19264)
Loss: 0.550 | Acc: 86.974% (22321/25664)
Loss: 0.551 | Acc: 86.904% (27865/32064)
Loss: 0.553 | Acc: 86.933% (33438/38464)
Loss: 0.554 | Acc: 86.925% (38998/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7972, Accuracy: 8063/10000 (80.63%)

Epoch: 37
Loss: 0.526 | Acc: 81.250% (52/64)
Loss: 0.515 | Acc: 88.088% (5694/6464)
Loss: 0.515 | Acc: 88.067% (11329/12864)
Loss: 0.516 | Acc: 88.045% (16961/19264)
Loss: 0.512 | Acc: 88.194% (22634/25664)
Loss: 0.521 | Acc: 87.927% (28193/32064)
Loss: 0.524 | Acc: 87.770% (33760/38464)
Loss: 0.531 | Acc: 87.582% (39293/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8405, Accuracy: 7993/10000 (79.93%)

Epoch: 38
Loss: 0.698 | Acc: 81.250% (52/64)
Loss: 0.494 | Acc: 88.366% (5712/6464)
Loss: 0.495 | Acc: 88.487% (11383/12864)
Loss: 0.495 | Acc: 88.476% (17044/19264)
Loss: 0.498 | Acc: 88.322% (22667/25664)
Loss: 0.501 | Acc: 88.273% (28304/32064)
Loss: 0.502 | Acc: 88.223% (33934/38464)
Loss: 0.502 | Acc: 88.244% (39590/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7961, Accuracy: 8148/10000 (81.48%)

Epoch: 39
Loss: 0.354 | Acc: 90.625% (58/64)
Loss: 0.448 | Acc: 89.836% (5807/6464)
Loss: 0.451 | Acc: 89.653% (11533/12864)
Loss: 0.457 | Acc: 89.426% (17227/19264)
Loss: 0.459 | Acc: 89.343% (22929/25664)
Loss: 0.466 | Acc: 89.209% (28604/32064)
Loss: 0.466 | Acc: 89.156% (34293/38464)
Loss: 0.470 | Acc: 89.036% (39945/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8874, Accuracy: 7963/10000 (79.63%)

Epoch: 40
Loss: 0.344 | Acc: 95.312% (61/64)
Loss: 0.436 | Acc: 89.341% (5775/6464)
Loss: 0.430 | Acc: 89.591% (11525/12864)
Loss: 0.438 | Acc: 89.483% (17238/19264)
Loss: 0.446 | Acc: 89.296% (22917/25664)
Loss: 0.445 | Acc: 89.359% (28652/32064)
Loss: 0.443 | Acc: 89.403% (34388/38464)
Loss: 0.444 | Acc: 89.419% (40117/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8482, Accuracy: 8100/10000 (81.00%)

Epoch: 41
Loss: 0.679 | Acc: 81.250% (52/64)
Loss: 0.397 | Acc: 90.579% (5855/6464)
Loss: 0.418 | Acc: 89.980% (11575/12864)
Loss: 0.412 | Acc: 90.127% (17362/19264)
Loss: 0.416 | Acc: 90.056% (23112/25664)
Loss: 0.412 | Acc: 90.138% (28902/32064)
Loss: 0.414 | Acc: 90.079% (34648/38464)
Loss: 0.414 | Acc: 90.083% (40415/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8733, Accuracy: 8051/10000 (80.51%)

Epoch: 42
Loss: 0.413 | Acc: 89.062% (57/64)
Loss: 0.371 | Acc: 90.934% (5878/6464)
Loss: 0.373 | Acc: 90.913% (11695/12864)
Loss: 0.373 | Acc: 90.947% (17520/19264)
Loss: 0.378 | Acc: 90.816% (23307/25664)
Loss: 0.377 | Acc: 90.853% (29131/32064)
Loss: 0.377 | Acc: 90.836% (34939/38464)
Loss: 0.377 | Acc: 90.794% (40734/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8937, Accuracy: 8107/10000 (81.07%)

Epoch: 43
Loss: 0.252 | Acc: 93.750% (60/64)
Loss: 0.336 | Acc: 91.445% (5911/6464)
Loss: 0.342 | Acc: 91.301% (11745/12864)
Loss: 0.340 | Acc: 91.487% (17624/19264)
Loss: 0.337 | Acc: 91.603% (23509/25664)
Loss: 0.335 | Acc: 91.657% (29389/32064)
Loss: 0.338 | Acc: 91.626% (35243/38464)
Loss: 0.338 | Acc: 91.657% (41121/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9001, Accuracy: 8138/10000 (81.38%)

Epoch: 44
Loss: 0.232 | Acc: 95.312% (61/64)
Loss: 0.292 | Acc: 92.590% (5985/6464)
Loss: 0.308 | Acc: 92.211% (11862/12864)
Loss: 0.301 | Acc: 92.421% (17804/19264)
Loss: 0.305 | Acc: 92.371% (23706/25664)
Loss: 0.307 | Acc: 92.269% (29585/32064)
Loss: 0.304 | Acc: 92.323% (35511/38464)
Loss: 0.301 | Acc: 92.404% (41456/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9079, Accuracy: 8187/10000 (81.87%)

Epoch: 45
Loss: 0.312 | Acc: 92.188% (59/64)
Loss: 0.269 | Acc: 92.976% (6010/6464)
Loss: 0.273 | Acc: 92.934% (11955/12864)
Loss: 0.271 | Acc: 92.987% (17913/19264)
Loss: 0.274 | Acc: 92.897% (23841/25664)
Loss: 0.273 | Acc: 92.995% (29818/32064)
Loss: 0.271 | Acc: 93.066% (35797/38464)
Loss: 0.269 | Acc: 93.146% (41789/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9200, Accuracy: 8171/10000 (81.71%)

Epoch: 46
Loss: 0.194 | Acc: 95.312% (61/64)
Loss: 0.260 | Acc: 93.209% (6025/6464)
Loss: 0.255 | Acc: 93.470% (12024/12864)
Loss: 0.249 | Acc: 93.568% (18025/19264)
Loss: 0.246 | Acc: 93.614% (24025/25664)
Loss: 0.246 | Acc: 93.685% (30039/32064)
Loss: 0.244 | Acc: 93.675% (36031/38464)
Loss: 0.242 | Acc: 93.732% (42052/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9253, Accuracy: 8173/10000 (81.73%)

Epoch: 47
Loss: 0.112 | Acc: 98.438% (63/64)
Loss: 0.216 | Acc: 94.152% (6086/6464)
Loss: 0.219 | Acc: 94.076% (12102/12864)
Loss: 0.224 | Acc: 93.994% (18107/19264)
Loss: 0.222 | Acc: 94.050% (24137/25664)
Loss: 0.225 | Acc: 93.956% (30126/32064)
Loss: 0.222 | Acc: 94.088% (36190/38464)
Loss: 0.221 | Acc: 94.109% (42221/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9371, Accuracy: 8149/10000 (81.49%)
torch.Size([100, 10])
Test set: Average loss: 0.9371, Accuracy: 8149/10000 (81.49%)

Epoch: 48
Loss: 0.343 | Acc: 89.062% (57/64)
Loss: 0.216 | Acc: 94.415% (6103/6464)
Loss: 0.210 | Acc: 94.543% (12162/12864)
Loss: 0.212 | Acc: 94.352% (18176/19264)
Loss: 0.210 | Acc: 94.467% (24244/25664)
Loss: 0.209 | Acc: 94.445% (30283/32064)
Loss: 0.211 | Acc: 94.395% (36308/38464)
Loss: 0.210 | Acc: 94.441% (42370/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9468, Accuracy: 8158/10000 (81.58%)
torch.Size([100, 10])
Test set: Average loss: 0.9468, Accuracy: 8158/10000 (81.58%)

Epoch: 49
Loss: 0.203 | Acc: 92.188% (59/64)
Loss: 0.208 | Acc: 94.493% (6108/6464)
Loss: 0.214 | Acc: 94.333% (12135/12864)
Loss: 0.211 | Acc: 94.440% (18193/19264)
Loss: 0.211 | Acc: 94.412% (24230/25664)
Loss: 0.209 | Acc: 94.439% (30281/32064)
Loss: 0.210 | Acc: 94.429% (36321/38464)
Loss: 0.210 | Acc: 94.399% (42351/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9425, Accuracy: 8159/10000 (81.59%)
torch.Size([100, 10])
Test set: Average loss: 0.9425, Accuracy: 8159/10000 (81.59%)

Epoch: 50
Loss: 0.129 | Acc: 96.875% (62/64)
Loss: 1.553 | Acc: 49.196% (3180/6464)
Loss: 1.304 | Acc: 59.274% (7625/12864)
Loss: 1.191 | Acc: 63.777% (12286/19264)
Loss: 1.139 | Acc: 66.019% (16943/25664)
Loss: 1.100 | Acc: 67.708% (21710/32064)
Loss: 1.072 | Acc: 68.706% (26427/38464)
Loss: 1.051 | Acc: 69.575% (31214/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1658, Accuracy: 6657/10000 (66.57%)

Epoch: 51
Loss: 0.764 | Acc: 81.250% (52/64)
Loss: 0.868 | Acc: 76.918% (4972/6464)
Loss: 0.873 | Acc: 76.648% (9860/12864)
Loss: 0.877 | Acc: 76.495% (14736/19264)
Loss: 0.878 | Acc: 76.290% (19579/25664)
Loss: 0.876 | Acc: 76.350% (24481/32064)
Loss: 0.870 | Acc: 76.505% (29427/38464)
Loss: 0.868 | Acc: 76.609% (34370/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9218, Accuracy: 7567/10000 (75.67%)

Epoch: 52
Loss: 0.795 | Acc: 79.688% (51/64)
Loss: 0.849 | Acc: 77.785% (5028/6464)
Loss: 0.838 | Acc: 77.806% (10009/12864)
Loss: 0.834 | Acc: 77.725% (14973/19264)
Loss: 0.836 | Acc: 77.650% (19928/25664)
Loss: 0.833 | Acc: 77.788% (24942/32064)
Loss: 0.835 | Acc: 77.758% (29909/38464)
Loss: 0.839 | Acc: 77.664% (34843/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2165, Accuracy: 6415/10000 (64.15%)

Epoch: 53
Loss: 1.205 | Acc: 70.312% (45/64)
Loss: 0.795 | Acc: 79.084% (5112/6464)
Loss: 0.814 | Acc: 78.483% (10096/12864)
Loss: 0.824 | Acc: 78.177% (15060/19264)
Loss: 0.826 | Acc: 78.109% (20046/25664)
Loss: 0.830 | Acc: 78.134% (25053/32064)
Loss: 0.826 | Acc: 78.268% (30105/38464)
Loss: 0.828 | Acc: 78.252% (35107/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2562, Accuracy: 6409/10000 (64.09%)

Epoch: 54
Loss: 0.777 | Acc: 75.000% (48/64)
Loss: 0.785 | Acc: 78.868% (5098/6464)
Loss: 0.815 | Acc: 78.514% (10100/12864)
Loss: 0.811 | Acc: 78.623% (15146/19264)
Loss: 0.818 | Acc: 78.468% (20138/25664)
Loss: 0.820 | Acc: 78.387% (25134/32064)
Loss: 0.823 | Acc: 78.216% (30085/38464)
Loss: 0.825 | Acc: 78.225% (35095/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6959, Accuracy: 5366/10000 (53.66%)

Epoch: 55
Loss: 1.022 | Acc: 71.875% (46/64)
Loss: 0.804 | Acc: 78.790% (5093/6464)
Loss: 0.804 | Acc: 78.910% (10151/12864)
Loss: 0.809 | Acc: 78.888% (15197/19264)
Loss: 0.812 | Acc: 78.760% (20213/25664)
Loss: 0.810 | Acc: 78.780% (25260/32064)
Loss: 0.813 | Acc: 78.655% (30254/38464)
Loss: 0.815 | Acc: 78.649% (35285/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0154, Accuracy: 7180/10000 (71.80%)

Epoch: 56
Loss: 0.980 | Acc: 78.125% (50/64)
Loss: 0.816 | Acc: 78.728% (5089/6464)
Loss: 0.813 | Acc: 78.926% (10153/12864)
Loss: 0.804 | Acc: 79.049% (15228/19264)
Loss: 0.805 | Acc: 78.877% (20243/25664)
Loss: 0.807 | Acc: 78.902% (25299/32064)
Loss: 0.810 | Acc: 78.801% (30310/38464)
Loss: 0.812 | Acc: 78.722% (35318/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0704, Accuracy: 7067/10000 (70.67%)

Epoch: 57
Loss: 0.919 | Acc: 78.125% (50/64)
Loss: 0.805 | Acc: 78.620% (5082/6464)
Loss: 0.804 | Acc: 78.957% (10157/12864)
Loss: 0.800 | Acc: 79.168% (15251/19264)
Loss: 0.808 | Acc: 78.939% (20259/25664)
Loss: 0.808 | Acc: 78.955% (25316/32064)
Loss: 0.812 | Acc: 78.871% (30337/38464)
Loss: 0.808 | Acc: 78.963% (35426/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6523, Accuracy: 5599/10000 (55.99%)

Epoch: 58
Loss: 1.154 | Acc: 67.188% (43/64)
Loss: 0.805 | Acc: 79.038% (5109/6464)
Loss: 0.812 | Acc: 78.794% (10136/12864)
Loss: 0.801 | Acc: 79.241% (15265/19264)
Loss: 0.805 | Acc: 79.126% (20307/25664)
Loss: 0.804 | Acc: 79.104% (25364/32064)
Loss: 0.805 | Acc: 79.038% (30401/38464)
Loss: 0.804 | Acc: 79.066% (35472/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9946, Accuracy: 7352/10000 (73.52%)

Epoch: 59
Loss: 0.555 | Acc: 87.500% (56/64)
Loss: 0.808 | Acc: 79.146% (5116/6464)
Loss: 0.796 | Acc: 79.415% (10216/12864)
Loss: 0.798 | Acc: 79.101% (15238/19264)
Loss: 0.795 | Acc: 79.313% (20355/25664)
Loss: 0.796 | Acc: 79.298% (25426/32064)
Loss: 0.795 | Acc: 79.334% (30515/38464)
Loss: 0.800 | Acc: 79.177% (35522/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1813, Accuracy: 6576/10000 (65.76%)

Epoch: 60
Loss: 0.829 | Acc: 78.125% (50/64)
Loss: 0.803 | Acc: 78.976% (5105/6464)
Loss: 0.784 | Acc: 79.509% (10228/12864)
Loss: 0.800 | Acc: 79.096% (15237/19264)
Loss: 0.800 | Acc: 79.161% (20316/25664)
Loss: 0.795 | Acc: 79.260% (25414/32064)
Loss: 0.794 | Acc: 79.350% (30521/38464)
Loss: 0.794 | Acc: 79.407% (35625/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9667, Accuracy: 7486/10000 (74.86%)

Epoch: 61
Loss: 0.910 | Acc: 81.250% (52/64)
Loss: 0.771 | Acc: 80.229% (5186/6464)
Loss: 0.771 | Acc: 80.216% (10319/12864)
Loss: 0.777 | Acc: 80.051% (15421/19264)
Loss: 0.785 | Acc: 79.917% (20510/25664)
Loss: 0.789 | Acc: 79.769% (25577/32064)
Loss: 0.789 | Acc: 79.810% (30698/38464)
Loss: 0.789 | Acc: 79.766% (35786/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6997, Accuracy: 5413/10000 (54.13%)

Epoch: 62
Loss: 0.985 | Acc: 81.250% (52/64)
Loss: 0.789 | Acc: 79.718% (5153/6464)
Loss: 0.775 | Acc: 80.138% (10309/12864)
Loss: 0.783 | Acc: 79.947% (15401/19264)
Loss: 0.782 | Acc: 79.945% (20517/25664)
Loss: 0.782 | Acc: 79.906% (25621/32064)
Loss: 0.782 | Acc: 79.942% (30749/38464)
Loss: 0.785 | Acc: 79.823% (35812/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9346, Accuracy: 7508/10000 (75.08%)

Epoch: 63
Loss: 0.520 | Acc: 87.500% (56/64)
Loss: 0.766 | Acc: 80.600% (5210/6464)
Loss: 0.773 | Acc: 80.527% (10359/12864)
Loss: 0.770 | Acc: 80.440% (15496/19264)
Loss: 0.773 | Acc: 80.206% (20584/25664)
Loss: 0.774 | Acc: 80.105% (25685/32064)
Loss: 0.778 | Acc: 80.002% (30772/38464)
Loss: 0.777 | Acc: 80.107% (35939/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2998, Accuracy: 6475/10000 (64.75%)

Epoch: 64
Loss: 0.925 | Acc: 75.000% (48/64)
Loss: 0.777 | Acc: 80.183% (5183/6464)
Loss: 0.771 | Acc: 80.574% (10365/12864)
Loss: 0.764 | Acc: 80.586% (15524/19264)
Loss: 0.770 | Acc: 80.385% (20630/25664)
Loss: 0.766 | Acc: 80.595% (25842/32064)
Loss: 0.768 | Acc: 80.491% (30960/38464)
Loss: 0.772 | Acc: 80.323% (36036/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1848, Accuracy: 6599/10000 (65.99%)

Epoch: 65
Loss: 0.560 | Acc: 85.938% (55/64)
Loss: 0.742 | Acc: 80.894% (5229/6464)
Loss: 0.752 | Acc: 80.791% (10393/12864)
Loss: 0.758 | Acc: 80.700% (15546/19264)
Loss: 0.757 | Acc: 80.615% (20689/25664)
Loss: 0.762 | Acc: 80.570% (25834/32064)
Loss: 0.761 | Acc: 80.610% (31006/38464)
Loss: 0.764 | Acc: 80.512% (36121/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0132, Accuracy: 7224/10000 (72.24%)

Epoch: 66
Loss: 0.821 | Acc: 81.250% (52/64)
Loss: 0.726 | Acc: 81.822% (5289/6464)
Loss: 0.749 | Acc: 80.838% (10399/12864)
Loss: 0.750 | Acc: 80.824% (15570/19264)
Loss: 0.756 | Acc: 80.708% (20713/25664)
Loss: 0.753 | Acc: 80.788% (25904/32064)
Loss: 0.754 | Acc: 80.792% (31076/38464)
Loss: 0.754 | Acc: 80.755% (36230/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1256, Accuracy: 6743/10000 (67.43%)

Epoch: 67
Loss: 0.870 | Acc: 75.000% (48/64)
Loss: 0.741 | Acc: 81.235% (5251/6464)
Loss: 0.736 | Acc: 81.328% (10462/12864)
Loss: 0.732 | Acc: 81.619% (15723/19264)
Loss: 0.738 | Acc: 81.445% (20902/25664)
Loss: 0.742 | Acc: 81.306% (26070/32064)
Loss: 0.746 | Acc: 81.133% (31207/38464)
Loss: 0.751 | Acc: 80.942% (36314/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4212, Accuracy: 5971/10000 (59.71%)

Epoch: 68
Loss: 0.673 | Acc: 78.125% (50/64)
Loss: 0.740 | Acc: 81.142% (5245/6464)
Loss: 0.735 | Acc: 81.250% (10452/12864)
Loss: 0.741 | Acc: 81.183% (15639/19264)
Loss: 0.742 | Acc: 81.184% (20835/25664)
Loss: 0.744 | Acc: 81.216% (26041/32064)
Loss: 0.744 | Acc: 81.193% (31230/38464)
Loss: 0.741 | Acc: 81.188% (36424/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0171, Accuracy: 7199/10000 (71.99%)

Epoch: 69
Loss: 0.914 | Acc: 76.562% (49/64)
Loss: 0.694 | Acc: 82.348% (5323/6464)
Loss: 0.702 | Acc: 82.331% (10591/12864)
Loss: 0.723 | Acc: 81.951% (15787/19264)
Loss: 0.730 | Acc: 81.725% (20974/25664)
Loss: 0.735 | Acc: 81.553% (26149/32064)
Loss: 0.733 | Acc: 81.562% (31372/38464)
Loss: 0.735 | Acc: 81.526% (36576/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3784, Accuracy: 5936/10000 (59.36%)

Epoch: 70
Loss: 0.820 | Acc: 78.125% (50/64)
Loss: 0.710 | Acc: 82.070% (5305/6464)
Loss: 0.703 | Acc: 82.416% (10602/12864)
Loss: 0.707 | Acc: 82.335% (15861/19264)
Loss: 0.712 | Acc: 82.259% (21111/25664)
Loss: 0.716 | Acc: 82.201% (26357/32064)
Loss: 0.721 | Acc: 82.046% (31558/38464)
Loss: 0.726 | Acc: 81.856% (36724/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1599, Accuracy: 6621/10000 (66.21%)

Epoch: 71
Loss: 0.749 | Acc: 79.688% (51/64)
Loss: 0.702 | Acc: 82.596% (5339/6464)
Loss: 0.707 | Acc: 82.385% (10598/12864)
Loss: 0.704 | Acc: 82.558% (15904/19264)
Loss: 0.713 | Acc: 82.380% (21142/25664)
Loss: 0.716 | Acc: 82.401% (26421/32064)
Loss: 0.718 | Acc: 82.274% (31646/38464)
Loss: 0.715 | Acc: 82.275% (36912/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5008, Accuracy: 5731/10000 (57.31%)

Epoch: 72
Loss: 0.810 | Acc: 81.250% (52/64)
Loss: 0.708 | Acc: 82.085% (5306/6464)
Loss: 0.711 | Acc: 82.121% (10564/12864)
Loss: 0.717 | Acc: 81.925% (15782/19264)
Loss: 0.709 | Acc: 82.259% (21111/25664)
Loss: 0.710 | Acc: 82.301% (26389/32064)
Loss: 0.706 | Acc: 82.420% (31702/38464)
Loss: 0.709 | Acc: 82.411% (36973/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3034, Accuracy: 6367/10000 (63.67%)

Epoch: 73
Loss: 0.746 | Acc: 82.812% (53/64)
Loss: 0.663 | Acc: 83.323% (5386/6464)
Loss: 0.683 | Acc: 83.069% (10686/12864)
Loss: 0.695 | Acc: 82.807% (15952/19264)
Loss: 0.700 | Acc: 82.684% (21220/25664)
Loss: 0.701 | Acc: 82.663% (26505/32064)
Loss: 0.696 | Acc: 82.781% (31841/38464)
Loss: 0.698 | Acc: 82.728% (37115/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0192, Accuracy: 7219/10000 (72.19%)

Epoch: 74
Loss: 0.874 | Acc: 76.562% (49/64)
Loss: 0.659 | Acc: 84.097% (5436/6464)
Loss: 0.669 | Acc: 83.963% (10801/12864)
Loss: 0.680 | Acc: 83.638% (16112/19264)
Loss: 0.680 | Acc: 83.557% (21444/25664)
Loss: 0.681 | Acc: 83.418% (26747/32064)
Loss: 0.689 | Acc: 83.161% (31987/38464)
Loss: 0.688 | Acc: 83.158% (37308/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9672, Accuracy: 7382/10000 (73.82%)

Epoch: 75
Loss: 0.581 | Acc: 85.938% (55/64)
Loss: 0.655 | Acc: 84.004% (5430/6464)
Loss: 0.662 | Acc: 83.901% (10793/12864)
Loss: 0.665 | Acc: 83.882% (16159/19264)
Loss: 0.665 | Acc: 83.853% (21520/25664)
Loss: 0.670 | Acc: 83.667% (26827/32064)
Loss: 0.673 | Acc: 83.626% (32166/38464)
Loss: 0.676 | Acc: 83.526% (37473/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9077, Accuracy: 7601/10000 (76.01%)

Epoch: 76
Loss: 0.589 | Acc: 85.938% (55/64)
Loss: 0.653 | Acc: 84.205% (5443/6464)
Loss: 0.647 | Acc: 84.352% (10851/12864)
Loss: 0.660 | Acc: 84.032% (16188/19264)
Loss: 0.662 | Acc: 83.911% (21535/25664)
Loss: 0.672 | Acc: 83.633% (26816/32064)
Loss: 0.672 | Acc: 83.618% (32163/38464)
Loss: 0.668 | Acc: 83.731% (37565/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8572, Accuracy: 7837/10000 (78.37%)

Epoch: 77
Loss: 0.781 | Acc: 82.812% (53/64)
Loss: 0.651 | Acc: 84.035% (5432/6464)
Loss: 0.657 | Acc: 84.126% (10822/12864)
Loss: 0.660 | Acc: 84.001% (16182/19264)
Loss: 0.660 | Acc: 84.036% (21567/25664)
Loss: 0.658 | Acc: 84.101% (26966/32064)
Loss: 0.654 | Acc: 84.157% (32370/38464)
Loss: 0.651 | Acc: 84.212% (37781/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9489, Accuracy: 7449/10000 (74.49%)

Epoch: 78
Loss: 0.566 | Acc: 85.938% (55/64)
Loss: 0.626 | Acc: 85.149% (5504/6464)
Loss: 0.631 | Acc: 84.950% (10928/12864)
Loss: 0.639 | Acc: 84.671% (16311/19264)
Loss: 0.644 | Acc: 84.539% (21696/25664)
Loss: 0.645 | Acc: 84.500% (27094/32064)
Loss: 0.641 | Acc: 84.575% (32531/38464)
Loss: 0.642 | Acc: 84.533% (37925/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9782, Accuracy: 7417/10000 (74.17%)

Epoch: 79
Loss: 0.614 | Acc: 89.062% (57/64)
Loss: 0.601 | Acc: 85.876% (5551/6464)
Loss: 0.605 | Acc: 85.697% (11024/12864)
Loss: 0.608 | Acc: 85.543% (16479/19264)
Loss: 0.615 | Acc: 85.493% (21941/25664)
Loss: 0.616 | Acc: 85.557% (27433/32064)
Loss: 0.616 | Acc: 85.550% (32906/38464)
Loss: 0.617 | Acc: 85.461% (38341/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0404, Accuracy: 7203/10000 (72.03%)

Epoch: 80
Loss: 0.992 | Acc: 78.125% (50/64)
Loss: 0.640 | Acc: 84.576% (5467/6464)
Loss: 0.615 | Acc: 85.246% (10966/12864)
Loss: 0.605 | Acc: 85.465% (16464/19264)
Loss: 0.600 | Acc: 85.575% (21962/25664)
Loss: 0.605 | Acc: 85.504% (27416/32064)
Loss: 0.608 | Acc: 85.431% (32860/38464)
Loss: 0.611 | Acc: 85.400% (38314/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8386, Accuracy: 7876/10000 (78.76%)

Epoch: 81
Loss: 0.384 | Acc: 90.625% (58/64)
Loss: 0.591 | Acc: 85.876% (5551/6464)
Loss: 0.605 | Acc: 85.533% (11003/12864)
Loss: 0.600 | Acc: 85.683% (16506/19264)
Loss: 0.597 | Acc: 85.809% (22022/25664)
Loss: 0.592 | Acc: 85.950% (27559/32064)
Loss: 0.593 | Acc: 85.911% (33045/38464)
Loss: 0.596 | Acc: 85.786% (38487/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7836, Accuracy: 8085/10000 (80.85%)

Epoch: 82
Loss: 0.371 | Acc: 90.625% (58/64)
Loss: 0.581 | Acc: 86.479% (5590/6464)
Loss: 0.571 | Acc: 86.606% (11141/12864)
Loss: 0.564 | Acc: 86.752% (16712/19264)
Loss: 0.569 | Acc: 86.651% (22238/25664)
Loss: 0.573 | Acc: 86.527% (27744/32064)
Loss: 0.578 | Acc: 86.450% (33252/38464)
Loss: 0.578 | Acc: 86.412% (38768/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8455, Accuracy: 7943/10000 (79.43%)

Epoch: 83
Loss: 0.562 | Acc: 87.500% (56/64)
Loss: 0.533 | Acc: 87.686% (5668/6464)
Loss: 0.538 | Acc: 87.430% (11247/12864)
Loss: 0.533 | Acc: 87.484% (16853/19264)
Loss: 0.545 | Acc: 87.169% (22371/25664)
Loss: 0.546 | Acc: 87.213% (27964/32064)
Loss: 0.554 | Acc: 87.105% (33504/38464)
Loss: 0.554 | Acc: 87.130% (39090/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9460, Accuracy: 7639/10000 (76.39%)

Epoch: 84
Loss: 0.445 | Acc: 89.062% (57/64)
Loss: 0.527 | Acc: 87.778% (5674/6464)
Loss: 0.531 | Acc: 87.593% (11268/12864)
Loss: 0.542 | Acc: 87.277% (16813/19264)
Loss: 0.544 | Acc: 87.223% (22385/25664)
Loss: 0.539 | Acc: 87.294% (27990/32064)
Loss: 0.543 | Acc: 87.217% (33547/38464)
Loss: 0.541 | Acc: 87.275% (39155/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7951, Accuracy: 8140/10000 (81.40%)

Epoch: 85
Loss: 0.592 | Acc: 87.500% (56/64)
Loss: 0.513 | Acc: 88.165% (5699/6464)
Loss: 0.508 | Acc: 88.262% (11354/12864)
Loss: 0.513 | Acc: 87.978% (16948/19264)
Loss: 0.513 | Acc: 88.053% (22598/25664)
Loss: 0.511 | Acc: 88.146% (28263/32064)
Loss: 0.513 | Acc: 88.184% (33919/38464)
Loss: 0.514 | Acc: 88.109% (39529/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8436, Accuracy: 7998/10000 (79.98%)

Epoch: 86
Loss: 0.497 | Acc: 89.062% (57/64)
Loss: 0.487 | Acc: 88.707% (5734/6464)
Loss: 0.470 | Acc: 88.985% (11447/12864)
Loss: 0.476 | Acc: 88.891% (17124/19264)
Loss: 0.489 | Acc: 88.509% (22715/25664)
Loss: 0.489 | Acc: 88.588% (28405/32064)
Loss: 0.493 | Acc: 88.501% (34041/38464)
Loss: 0.494 | Acc: 88.458% (39686/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8594, Accuracy: 8028/10000 (80.28%)

Epoch: 87
Loss: 0.402 | Acc: 90.625% (58/64)
Loss: 0.478 | Acc: 89.032% (5755/6464)
Loss: 0.461 | Acc: 89.265% (11483/12864)
Loss: 0.468 | Acc: 89.016% (17148/19264)
Loss: 0.468 | Acc: 89.000% (22841/25664)
Loss: 0.469 | Acc: 88.991% (28534/32064)
Loss: 0.469 | Acc: 88.990% (34229/38464)
Loss: 0.467 | Acc: 89.071% (39961/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7839, Accuracy: 8243/10000 (82.43%)

Epoch: 88
Loss: 0.362 | Acc: 92.188% (59/64)
Loss: 0.430 | Acc: 89.697% (5798/6464)
Loss: 0.426 | Acc: 89.956% (11572/12864)
Loss: 0.432 | Acc: 89.784% (17296/19264)
Loss: 0.438 | Acc: 89.663% (23011/25664)
Loss: 0.438 | Acc: 89.711% (28765/32064)
Loss: 0.436 | Acc: 89.770% (34529/38464)
Loss: 0.438 | Acc: 89.702% (40244/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8252, Accuracy: 8176/10000 (81.76%)

Epoch: 89
Loss: 0.453 | Acc: 90.625% (58/64)
Loss: 0.398 | Acc: 90.470% (5848/6464)
Loss: 0.402 | Acc: 90.438% (11634/12864)
Loss: 0.405 | Acc: 90.355% (17406/19264)
Loss: 0.403 | Acc: 90.305% (23176/25664)
Loss: 0.411 | Acc: 90.148% (28905/32064)
Loss: 0.410 | Acc: 90.191% (34691/38464)
Loss: 0.410 | Acc: 90.208% (40471/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8883, Accuracy: 8019/10000 (80.19%)

Epoch: 90
Loss: 0.274 | Acc: 93.750% (60/64)
Loss: 0.368 | Acc: 91.027% (5884/6464)
Loss: 0.368 | Acc: 91.185% (11730/12864)
Loss: 0.371 | Acc: 91.009% (17532/19264)
Loss: 0.371 | Acc: 91.007% (23356/25664)
Loss: 0.376 | Acc: 90.865% (29135/32064)
Loss: 0.377 | Acc: 90.862% (34949/38464)
Loss: 0.376 | Acc: 90.915% (40788/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8434, Accuracy: 8218/10000 (82.18%)

Epoch: 91
Loss: 0.373 | Acc: 92.188% (59/64)
Loss: 0.352 | Acc: 91.507% (5915/6464)
Loss: 0.345 | Acc: 91.604% (11784/12864)
Loss: 0.348 | Acc: 91.487% (17624/19264)
Loss: 0.343 | Acc: 91.552% (23496/25664)
Loss: 0.344 | Acc: 91.573% (29362/32064)
Loss: 0.344 | Acc: 91.605% (35235/38464)
Loss: 0.344 | Acc: 91.619% (41104/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8797, Accuracy: 8167/10000 (81.67%)

Epoch: 92
Loss: 0.412 | Acc: 92.188% (59/64)
Loss: 0.307 | Acc: 92.141% (5956/6464)
Loss: 0.298 | Acc: 92.615% (11914/12864)
Loss: 0.303 | Acc: 92.499% (17819/19264)
Loss: 0.308 | Acc: 92.320% (23693/25664)
Loss: 0.315 | Acc: 92.113% (29535/32064)
Loss: 0.316 | Acc: 92.073% (35415/38464)
Loss: 0.314 | Acc: 92.101% (41320/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8950, Accuracy: 8209/10000 (82.09%)

Epoch: 93
Loss: 0.320 | Acc: 92.188% (59/64)
Loss: 0.260 | Acc: 93.255% (6028/6464)
Loss: 0.259 | Acc: 93.268% (11998/12864)
Loss: 0.260 | Acc: 93.169% (17948/19264)
Loss: 0.266 | Acc: 93.088% (23890/25664)
Loss: 0.268 | Acc: 93.048% (29835/32064)
Loss: 0.267 | Acc: 93.118% (35817/38464)
Loss: 0.270 | Acc: 93.017% (41731/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9122, Accuracy: 8216/10000 (82.16%)

Epoch: 94
Loss: 0.218 | Acc: 93.750% (60/64)
Loss: 0.233 | Acc: 94.183% (6088/6464)
Loss: 0.237 | Acc: 94.030% (12096/12864)
Loss: 0.241 | Acc: 93.817% (18073/19264)
Loss: 0.241 | Acc: 93.851% (24086/25664)
Loss: 0.241 | Acc: 93.850% (30092/32064)
Loss: 0.238 | Acc: 93.903% (36119/38464)
Loss: 0.236 | Acc: 93.964% (42156/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9310, Accuracy: 8233/10000 (82.33%)

Epoch: 95
Loss: 0.156 | Acc: 96.875% (62/64)
Loss: 0.199 | Acc: 94.663% (6119/6464)
Loss: 0.203 | Acc: 94.496% (12156/12864)
Loss: 0.206 | Acc: 94.430% (18191/19264)
Loss: 0.204 | Acc: 94.514% (24256/25664)
Loss: 0.206 | Acc: 94.486% (30296/32064)
Loss: 0.208 | Acc: 94.460% (36333/38464)
Loss: 0.207 | Acc: 94.512% (42402/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9583, Accuracy: 8172/10000 (81.72%)

Epoch: 96
Loss: 0.172 | Acc: 95.312% (61/64)
Loss: 0.196 | Acc: 94.678% (6120/6464)
Loss: 0.189 | Acc: 94.900% (12208/12864)
Loss: 0.195 | Acc: 94.778% (18258/19264)
Loss: 0.194 | Acc: 94.740% (24314/25664)
Loss: 0.191 | Acc: 94.879% (30422/32064)
Loss: 0.190 | Acc: 94.891% (36499/38464)
Loss: 0.190 | Acc: 94.898% (42575/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9680, Accuracy: 8196/10000 (81.96%)

Epoch: 97
Loss: 0.186 | Acc: 93.750% (60/64)
Loss: 0.172 | Acc: 95.374% (6165/6464)
Loss: 0.179 | Acc: 95.149% (12240/12864)
Loss: 0.176 | Acc: 95.261% (18351/19264)
Loss: 0.175 | Acc: 95.297% (24457/25664)
Loss: 0.172 | Acc: 95.369% (30579/32064)
Loss: 0.171 | Acc: 95.401% (36695/38464)
Loss: 0.170 | Acc: 95.426% (42812/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9676, Accuracy: 8200/10000 (82.00%)
torch.Size([100, 10])
Test set: Average loss: 0.9676, Accuracy: 8200/10000 (82.00%)

Epoch: 98
Loss: 0.071 | Acc: 98.438% (63/64)
Loss: 0.162 | Acc: 95.560% (6177/6464)
Loss: 0.165 | Acc: 95.491% (12284/12864)
Loss: 0.165 | Acc: 95.505% (18398/19264)
Loss: 0.164 | Acc: 95.546% (24521/25664)
Loss: 0.162 | Acc: 95.515% (30626/32064)
Loss: 0.162 | Acc: 95.552% (36753/38464)
Loss: 0.162 | Acc: 95.584% (42883/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9690, Accuracy: 8190/10000 (81.90%)
torch.Size([100, 10])
Test set: Average loss: 0.9690, Accuracy: 8190/10000 (81.90%)

Epoch: 99
Loss: 0.073 | Acc: 98.438% (63/64)
Loss: 0.148 | Acc: 96.055% (6209/6464)
Loss: 0.149 | Acc: 95.981% (12347/12864)
Loss: 0.151 | Acc: 95.878% (18470/19264)
Loss: 0.156 | Acc: 95.706% (24562/25664)
Loss: 0.158 | Acc: 95.656% (30671/32064)
Loss: 0.157 | Acc: 95.676% (36801/38464)
Loss: 0.157 | Acc: 95.671% (42922/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9656, Accuracy: 8194/10000 (81.94%)
torch.Size([100, 10])
Test set: Average loss: 0.9656, Accuracy: 8194/10000 (81.94%)

Epoch: 100
Loss: 0.130 | Acc: 95.312% (61/64)
Loss: 1.687 | Acc: 41.646% (2692/6464)
Loss: 1.381 | Acc: 55.271% (7110/12864)
Loss: 1.243 | Acc: 61.083% (11767/19264)
Loss: 1.166 | Acc: 64.413% (16531/25664)
Loss: 1.114 | Acc: 66.586% (21350/32064)
Loss: 1.075 | Acc: 68.199% (26232/38464)
Loss: 1.048 | Acc: 69.292% (31087/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3135, Accuracy: 6129/10000 (61.29%)

Epoch: 101
Loss: 0.927 | Acc: 76.562% (49/64)
Loss: 0.834 | Acc: 77.707% (5023/6464)
Loss: 0.839 | Acc: 77.635% (9987/12864)
Loss: 0.837 | Acc: 77.793% (14986/19264)
Loss: 0.834 | Acc: 77.798% (19966/25664)
Loss: 0.833 | Acc: 77.832% (24956/32064)
Loss: 0.831 | Acc: 77.956% (29985/38464)
Loss: 0.835 | Acc: 77.898% (34948/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1110, Accuracy: 6926/10000 (69.26%)

Epoch: 102
Loss: 0.698 | Acc: 82.812% (53/64)
Loss: 0.804 | Acc: 78.527% (5076/6464)
Loss: 0.811 | Acc: 78.374% (10082/12864)
Loss: 0.808 | Acc: 78.686% (15158/19264)
Loss: 0.805 | Acc: 78.776% (20217/25664)
Loss: 0.805 | Acc: 78.845% (25281/32064)
Loss: 0.807 | Acc: 78.866% (30335/38464)
Loss: 0.805 | Acc: 78.956% (35423/44864)
torch.Size([100, 10])
Test set: Average loss: 2.7818, Accuracy: 3353/10000 (33.53%)

Epoch: 103
Loss: 0.969 | Acc: 67.188% (43/64)
Loss: 0.807 | Acc: 78.280% (5060/6464)
Loss: 0.810 | Acc: 78.731% (10128/12864)
Loss: 0.801 | Acc: 78.961% (15211/19264)
Loss: 0.796 | Acc: 79.239% (20336/25664)
Loss: 0.799 | Acc: 79.248% (25410/32064)
Loss: 0.801 | Acc: 79.248% (30482/38464)
Loss: 0.801 | Acc: 79.184% (35525/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0151, Accuracy: 4919/10000 (49.19%)

Epoch: 104
Loss: 0.910 | Acc: 73.438% (47/64)
Loss: 0.781 | Acc: 79.471% (5137/6464)
Loss: 0.797 | Acc: 79.128% (10179/12864)
Loss: 0.792 | Acc: 79.615% (15337/19264)
Loss: 0.794 | Acc: 79.504% (20404/25664)
Loss: 0.795 | Acc: 79.532% (25501/32064)
Loss: 0.795 | Acc: 79.500% (30579/38464)
Loss: 0.795 | Acc: 79.494% (35664/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1765, Accuracy: 6537/10000 (65.37%)

Epoch: 105
Loss: 0.922 | Acc: 78.125% (50/64)
Loss: 0.777 | Acc: 79.796% (5158/6464)
Loss: 0.774 | Acc: 79.913% (10280/12864)
Loss: 0.779 | Acc: 79.859% (15384/19264)
Loss: 0.777 | Acc: 79.867% (20497/25664)
Loss: 0.782 | Acc: 79.787% (25583/32064)
Loss: 0.783 | Acc: 79.797% (30693/38464)
Loss: 0.786 | Acc: 79.647% (35733/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9001, Accuracy: 4703/10000 (47.03%)

Epoch: 106
Loss: 1.042 | Acc: 70.312% (45/64)
Loss: 0.785 | Acc: 79.796% (5158/6464)
Loss: 0.784 | Acc: 79.734% (10257/12864)
Loss: 0.775 | Acc: 80.051% (15421/19264)
Loss: 0.779 | Acc: 80.030% (20539/25664)
Loss: 0.780 | Acc: 79.903% (25620/32064)
Loss: 0.782 | Acc: 79.838% (30709/38464)
Loss: 0.785 | Acc: 79.790% (35797/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1737, Accuracy: 6795/10000 (67.95%)

Epoch: 107
Loss: 0.630 | Acc: 85.938% (55/64)
Loss: 0.770 | Acc: 80.291% (5190/6464)
Loss: 0.772 | Acc: 80.022% (10294/12864)
Loss: 0.777 | Acc: 79.942% (15400/19264)
Loss: 0.784 | Acc: 79.836% (20489/25664)
Loss: 0.784 | Acc: 79.756% (25573/32064)
Loss: 0.784 | Acc: 79.734% (30669/38464)
Loss: 0.783 | Acc: 79.835% (35817/44864)
torch.Size([100, 10])
Test set: Average loss: 2.6439, Accuracy: 3871/10000 (38.71%)

Epoch: 108
Loss: 1.285 | Acc: 62.500% (40/64)
Loss: 0.781 | Acc: 80.028% (5173/6464)
Loss: 0.779 | Acc: 80.030% (10295/12864)
Loss: 0.783 | Acc: 80.020% (15415/19264)
Loss: 0.783 | Acc: 80.054% (20545/25664)
Loss: 0.778 | Acc: 80.205% (25717/32064)
Loss: 0.783 | Acc: 80.109% (30813/38464)
Loss: 0.784 | Acc: 80.035% (35907/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1125, Accuracy: 4385/10000 (43.85%)

Epoch: 109
Loss: 1.294 | Acc: 67.188% (43/64)
Loss: 0.798 | Acc: 79.517% (5140/6464)
Loss: 0.790 | Acc: 79.859% (10273/12864)
Loss: 0.787 | Acc: 79.895% (15391/19264)
Loss: 0.781 | Acc: 79.976% (20525/25664)
Loss: 0.779 | Acc: 80.006% (25653/32064)
Loss: 0.783 | Acc: 79.890% (30729/38464)
Loss: 0.784 | Acc: 79.915% (35853/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6300, Accuracy: 5404/10000 (54.04%)

Epoch: 110
Loss: 1.053 | Acc: 71.875% (46/64)
Loss: 0.785 | Acc: 79.811% (5159/6464)
Loss: 0.763 | Acc: 80.512% (10357/12864)
Loss: 0.762 | Acc: 80.637% (15534/19264)
Loss: 0.763 | Acc: 80.455% (20648/25664)
Loss: 0.766 | Acc: 80.374% (25771/32064)
Loss: 0.770 | Acc: 80.262% (30872/38464)
Loss: 0.769 | Acc: 80.265% (36010/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0389, Accuracy: 7206/10000 (72.06%)

Epoch: 111
Loss: 0.766 | Acc: 79.688% (51/64)
Loss: 0.772 | Acc: 80.291% (5190/6464)
Loss: 0.768 | Acc: 80.379% (10340/12864)
Loss: 0.761 | Acc: 80.430% (15494/19264)
Loss: 0.755 | Acc: 80.630% (20693/25664)
Loss: 0.763 | Acc: 80.539% (25824/32064)
Loss: 0.767 | Acc: 80.452% (30945/38464)
Loss: 0.769 | Acc: 80.390% (36066/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1826, Accuracy: 6637/10000 (66.37%)

Epoch: 112
Loss: 1.173 | Acc: 68.750% (44/64)
Loss: 0.753 | Acc: 80.832% (5225/6464)
Loss: 0.756 | Acc: 80.543% (10361/12864)
Loss: 0.762 | Acc: 80.466% (15501/19264)
Loss: 0.759 | Acc: 80.521% (20665/25664)
Loss: 0.762 | Acc: 80.511% (25815/32064)
Loss: 0.766 | Acc: 80.410% (30929/38464)
Loss: 0.769 | Acc: 80.343% (36045/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3360, Accuracy: 5992/10000 (59.92%)

Epoch: 113
Loss: 0.813 | Acc: 75.000% (48/64)
Loss: 0.752 | Acc: 81.080% (5241/6464)
Loss: 0.753 | Acc: 81.126% (10436/12864)
Loss: 0.748 | Acc: 81.219% (15646/19264)
Loss: 0.746 | Acc: 81.149% (20826/25664)
Loss: 0.743 | Acc: 81.172% (26027/32064)
Loss: 0.750 | Acc: 81.024% (31165/38464)
Loss: 0.756 | Acc: 80.829% (36263/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2499, Accuracy: 4166/10000 (41.66%)

Epoch: 114
Loss: 0.985 | Acc: 73.438% (47/64)
Loss: 0.753 | Acc: 80.941% (5232/6464)
Loss: 0.744 | Acc: 81.133% (10437/12864)
Loss: 0.750 | Acc: 80.648% (15536/19264)
Loss: 0.745 | Acc: 80.895% (20761/25664)
Loss: 0.750 | Acc: 80.792% (25905/32064)
Loss: 0.756 | Acc: 80.634% (31015/38464)
Loss: 0.757 | Acc: 80.664% (36189/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3299, Accuracy: 6260/10000 (62.60%)

Epoch: 115
Loss: 0.940 | Acc: 76.562% (49/64)
Loss: 0.716 | Acc: 82.024% (5302/6464)
Loss: 0.726 | Acc: 81.771% (10519/12864)
Loss: 0.742 | Acc: 81.359% (15673/19264)
Loss: 0.741 | Acc: 81.363% (20881/25664)
Loss: 0.742 | Acc: 81.266% (26057/32064)
Loss: 0.744 | Acc: 81.193% (31230/38464)
Loss: 0.745 | Acc: 81.101% (36385/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0144, Accuracy: 7267/10000 (72.67%)

Epoch: 116
Loss: 0.675 | Acc: 82.812% (53/64)
Loss: 0.732 | Acc: 82.054% (5304/6464)
Loss: 0.734 | Acc: 81.693% (10509/12864)
Loss: 0.735 | Acc: 81.665% (15732/19264)
Loss: 0.735 | Acc: 81.628% (20949/25664)
Loss: 0.743 | Acc: 81.397% (26099/32064)
Loss: 0.739 | Acc: 81.492% (31345/38464)
Loss: 0.739 | Acc: 81.390% (36515/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0763, Accuracy: 6986/10000 (69.86%)

Epoch: 117
Loss: 0.641 | Acc: 79.688% (51/64)
Loss: 0.739 | Acc: 81.467% (5266/6464)
Loss: 0.730 | Acc: 81.957% (10543/12864)
Loss: 0.726 | Acc: 82.029% (15802/19264)
Loss: 0.727 | Acc: 82.045% (21056/25664)
Loss: 0.738 | Acc: 81.677% (26189/32064)
Loss: 0.736 | Acc: 81.656% (31408/38464)
Loss: 0.734 | Acc: 81.691% (36650/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9483, Accuracy: 7438/10000 (74.38%)

Epoch: 118
Loss: 0.862 | Acc: 79.688% (51/64)
Loss: 0.705 | Acc: 82.580% (5338/6464)
Loss: 0.708 | Acc: 82.509% (10614/12864)
Loss: 0.703 | Acc: 82.470% (15887/19264)
Loss: 0.712 | Acc: 82.181% (21091/25664)
Loss: 0.720 | Acc: 81.902% (26261/32064)
Loss: 0.719 | Acc: 81.900% (31502/38464)
Loss: 0.723 | Acc: 81.859% (36725/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9746, Accuracy: 7452/10000 (74.52%)

Epoch: 119
Loss: 0.557 | Acc: 89.062% (57/64)
Loss: 0.716 | Acc: 82.441% (5329/6464)
Loss: 0.708 | Acc: 82.688% (10637/12864)
Loss: 0.707 | Acc: 82.480% (15889/19264)
Loss: 0.714 | Acc: 82.251% (21109/25664)
Loss: 0.717 | Acc: 82.248% (26372/32064)
Loss: 0.717 | Acc: 82.235% (31631/38464)
Loss: 0.719 | Acc: 82.155% (36858/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2536, Accuracy: 6504/10000 (65.04%)

Epoch: 120
Loss: 0.563 | Acc: 85.938% (55/64)
Loss: 0.706 | Acc: 82.565% (5337/6464)
Loss: 0.708 | Acc: 82.470% (10609/12864)
Loss: 0.705 | Acc: 82.511% (15895/19264)
Loss: 0.710 | Acc: 82.485% (21169/25664)
Loss: 0.706 | Acc: 82.632% (26495/32064)
Loss: 0.711 | Acc: 82.501% (31733/38464)
Loss: 0.710 | Acc: 82.498% (37012/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0528, Accuracy: 7123/10000 (71.23%)

Epoch: 121
Loss: 0.721 | Acc: 81.250% (52/64)
Loss: 0.660 | Acc: 83.926% (5425/6464)
Loss: 0.678 | Acc: 83.294% (10715/12864)
Loss: 0.688 | Acc: 83.072% (16003/19264)
Loss: 0.693 | Acc: 82.890% (21273/25664)
Loss: 0.693 | Acc: 82.931% (26591/32064)
Loss: 0.697 | Acc: 82.885% (31881/38464)
Loss: 0.699 | Acc: 82.884% (37185/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0771, Accuracy: 7001/10000 (70.01%)

Epoch: 122
Loss: 0.726 | Acc: 82.812% (53/64)
Loss: 0.679 | Acc: 83.540% (5400/6464)
Loss: 0.667 | Acc: 83.815% (10782/12864)
Loss: 0.673 | Acc: 83.591% (16103/19264)
Loss: 0.678 | Acc: 83.506% (21431/25664)
Loss: 0.681 | Acc: 83.436% (26753/32064)
Loss: 0.682 | Acc: 83.371% (32068/38464)
Loss: 0.686 | Acc: 83.209% (37331/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8769, Accuracy: 7736/10000 (77.36%)

Epoch: 123
Loss: 0.573 | Acc: 85.938% (55/64)
Loss: 0.678 | Acc: 83.431% (5393/6464)
Loss: 0.676 | Acc: 83.598% (10754/12864)
Loss: 0.681 | Acc: 83.373% (16061/19264)
Loss: 0.677 | Acc: 83.494% (21428/25664)
Loss: 0.681 | Acc: 83.349% (26725/32064)
Loss: 0.681 | Acc: 83.322% (32049/38464)
Loss: 0.685 | Acc: 83.289% (37367/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0648, Accuracy: 7110/10000 (71.10%)

Epoch: 124
Loss: 0.567 | Acc: 87.500% (56/64)
Loss: 0.655 | Acc: 84.189% (5442/6464)
Loss: 0.657 | Acc: 83.963% (10801/12864)
Loss: 0.662 | Acc: 83.903% (16163/19264)
Loss: 0.662 | Acc: 83.900% (21532/25664)
Loss: 0.667 | Acc: 83.764% (26858/32064)
Loss: 0.669 | Acc: 83.774% (32223/38464)
Loss: 0.673 | Acc: 83.655% (37531/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2085, Accuracy: 6538/10000 (65.38%)

Epoch: 125
Loss: 0.761 | Acc: 81.250% (52/64)
Loss: 0.639 | Acc: 84.375% (5454/6464)
Loss: 0.632 | Acc: 84.600% (10883/12864)
Loss: 0.649 | Acc: 84.219% (16224/19264)
Loss: 0.649 | Acc: 84.285% (21631/25664)
Loss: 0.653 | Acc: 84.188% (26994/32064)
Loss: 0.653 | Acc: 84.183% (32380/38464)
Loss: 0.659 | Acc: 84.092% (37727/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9747, Accuracy: 7481/10000 (74.81%)

Epoch: 126
Loss: 0.513 | Acc: 85.938% (55/64)
Loss: 0.613 | Acc: 85.365% (5518/6464)
Loss: 0.621 | Acc: 85.230% (10964/12864)
Loss: 0.640 | Acc: 84.868% (16349/19264)
Loss: 0.644 | Acc: 84.613% (21715/25664)
Loss: 0.647 | Acc: 84.522% (27101/32064)
Loss: 0.647 | Acc: 84.508% (32505/38464)
Loss: 0.648 | Acc: 84.518% (37918/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8308, Accuracy: 7938/10000 (79.38%)

Epoch: 127
Loss: 0.680 | Acc: 82.812% (53/64)
Loss: 0.625 | Acc: 84.947% (5491/6464)
Loss: 0.631 | Acc: 84.904% (10922/12864)
Loss: 0.640 | Acc: 84.557% (16289/19264)
Loss: 0.641 | Acc: 84.648% (21724/25664)
Loss: 0.643 | Acc: 84.559% (27113/32064)
Loss: 0.638 | Acc: 84.770% (32606/38464)
Loss: 0.635 | Acc: 84.859% (38071/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9195, Accuracy: 7604/10000 (76.04%)

Epoch: 128
Loss: 0.733 | Acc: 82.812% (53/64)
Loss: 0.595 | Acc: 85.705% (5540/6464)
Loss: 0.605 | Acc: 85.362% (10981/12864)
Loss: 0.614 | Acc: 85.107% (16395/19264)
Loss: 0.619 | Acc: 85.045% (21826/25664)
Loss: 0.623 | Acc: 84.993% (27252/32064)
Loss: 0.625 | Acc: 84.950% (32675/38464)
Loss: 0.625 | Acc: 84.988% (38129/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8736, Accuracy: 7806/10000 (78.06%)

Epoch: 129
Loss: 0.612 | Acc: 87.500% (56/64)
Loss: 0.598 | Acc: 85.442% (5523/6464)
Loss: 0.608 | Acc: 85.308% (10974/12864)
Loss: 0.600 | Acc: 85.642% (16498/19264)
Loss: 0.604 | Acc: 85.509% (21945/25664)
Loss: 0.612 | Acc: 85.329% (27360/32064)
Loss: 0.615 | Acc: 85.269% (32798/38464)
Loss: 0.616 | Acc: 85.318% (38277/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9758, Accuracy: 7510/10000 (75.10%)

Epoch: 130
Loss: 0.776 | Acc: 82.812% (53/64)
Loss: 0.601 | Acc: 85.860% (5550/6464)
Loss: 0.616 | Acc: 85.627% (11015/12864)
Loss: 0.599 | Acc: 86.021% (16571/19264)
Loss: 0.599 | Acc: 85.910% (22048/25664)
Loss: 0.595 | Acc: 86.000% (27575/32064)
Loss: 0.596 | Acc: 86.021% (33087/38464)
Loss: 0.594 | Acc: 86.020% (38592/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9511, Accuracy: 7498/10000 (74.98%)

Epoch: 131
Loss: 0.745 | Acc: 79.688% (51/64)
Loss: 0.566 | Acc: 86.897% (5617/6464)
Loss: 0.567 | Acc: 86.660% (11148/12864)
Loss: 0.560 | Acc: 86.913% (16743/19264)
Loss: 0.567 | Acc: 86.666% (22242/25664)
Loss: 0.574 | Acc: 86.527% (27744/32064)
Loss: 0.575 | Acc: 86.561% (33295/38464)
Loss: 0.579 | Acc: 86.468% (38793/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9789, Accuracy: 7496/10000 (74.96%)

Epoch: 132
Loss: 0.698 | Acc: 81.250% (52/64)
Loss: 0.547 | Acc: 87.051% (5627/6464)
Loss: 0.556 | Acc: 86.762% (11161/12864)
Loss: 0.557 | Acc: 86.742% (16710/19264)
Loss: 0.566 | Acc: 86.452% (22187/25664)
Loss: 0.570 | Acc: 86.421% (27710/32064)
Loss: 0.571 | Acc: 86.463% (33257/38464)
Loss: 0.570 | Acc: 86.530% (38821/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8760, Accuracy: 7817/10000 (78.17%)

Epoch: 133
Loss: 0.539 | Acc: 87.500% (56/64)
Loss: 0.493 | Acc: 88.475% (5719/6464)
Loss: 0.518 | Acc: 87.912% (11309/12864)
Loss: 0.530 | Acc: 87.557% (16867/19264)
Loss: 0.533 | Acc: 87.473% (22449/25664)
Loss: 0.543 | Acc: 87.229% (27969/32064)
Loss: 0.546 | Acc: 87.149% (33521/38464)
Loss: 0.547 | Acc: 87.177% (39111/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8839, Accuracy: 7895/10000 (78.95%)

Epoch: 134
Loss: 0.381 | Acc: 90.625% (58/64)
Loss: 0.527 | Acc: 87.655% (5666/6464)
Loss: 0.522 | Acc: 87.733% (11286/12864)
Loss: 0.519 | Acc: 87.905% (16934/19264)
Loss: 0.519 | Acc: 87.882% (22554/25664)
Loss: 0.527 | Acc: 87.725% (28128/32064)
Loss: 0.526 | Acc: 87.734% (33746/38464)
Loss: 0.520 | Acc: 87.874% (39424/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8556, Accuracy: 7920/10000 (79.20%)

Epoch: 135
Loss: 0.513 | Acc: 85.938% (55/64)
Loss: 0.463 | Acc: 88.923% (5748/6464)
Loss: 0.470 | Acc: 89.031% (11453/12864)
Loss: 0.473 | Acc: 88.881% (17122/19264)
Loss: 0.489 | Acc: 88.575% (22732/25664)
Loss: 0.493 | Acc: 88.489% (28373/32064)
Loss: 0.502 | Acc: 88.306% (33966/38464)
Loss: 0.501 | Acc: 88.374% (39648/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8128, Accuracy: 8117/10000 (81.17%)

Epoch: 136
Loss: 0.413 | Acc: 90.625% (58/64)
Loss: 0.479 | Acc: 88.506% (5721/6464)
Loss: 0.474 | Acc: 88.790% (11422/12864)
Loss: 0.467 | Acc: 89.135% (17171/19264)
Loss: 0.470 | Acc: 89.031% (22849/25664)
Loss: 0.476 | Acc: 88.878% (28498/32064)
Loss: 0.481 | Acc: 88.777% (34147/38464)
Loss: 0.480 | Acc: 88.820% (39848/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0508, Accuracy: 7543/10000 (75.43%)

Epoch: 137
Loss: 0.581 | Acc: 89.062% (57/64)
Loss: 0.441 | Acc: 89.465% (5783/6464)
Loss: 0.437 | Acc: 89.614% (11528/12864)
Loss: 0.444 | Acc: 89.535% (17248/19264)
Loss: 0.443 | Acc: 89.546% (22981/25664)
Loss: 0.449 | Acc: 89.421% (28672/32064)
Loss: 0.452 | Acc: 89.372% (34376/38464)
Loss: 0.453 | Acc: 89.354% (40088/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9860, Accuracy: 7581/10000 (75.81%)

Epoch: 138
Loss: 0.533 | Acc: 87.500% (56/64)
Loss: 0.434 | Acc: 89.341% (5775/6464)
Loss: 0.432 | Acc: 89.459% (11508/12864)
Loss: 0.420 | Acc: 89.966% (17331/19264)
Loss: 0.416 | Acc: 90.044% (23109/25664)
Loss: 0.419 | Acc: 89.995% (28856/32064)
Loss: 0.415 | Acc: 90.108% (34659/38464)
Loss: 0.420 | Acc: 90.025% (40389/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8522, Accuracy: 8085/10000 (80.85%)

Epoch: 139
Loss: 0.469 | Acc: 89.062% (57/64)
Loss: 0.384 | Acc: 90.749% (5866/6464)
Loss: 0.382 | Acc: 90.827% (11684/12864)
Loss: 0.383 | Acc: 90.853% (17502/19264)
Loss: 0.389 | Acc: 90.699% (23277/25664)
Loss: 0.393 | Acc: 90.609% (29053/32064)
Loss: 0.392 | Acc: 90.628% (34859/38464)
Loss: 0.393 | Acc: 90.607% (40650/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8710, Accuracy: 8090/10000 (80.90%)

Epoch: 140
Loss: 0.357 | Acc: 89.062% (57/64)
Loss: 0.350 | Acc: 91.615% (5922/6464)
Loss: 0.357 | Acc: 91.371% (11754/12864)
Loss: 0.353 | Acc: 91.518% (17630/19264)
Loss: 0.356 | Acc: 91.432% (23465/25664)
Loss: 0.353 | Acc: 91.483% (29333/32064)
Loss: 0.354 | Acc: 91.465% (35181/38464)
Loss: 0.356 | Acc: 91.392% (41002/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8861, Accuracy: 8144/10000 (81.44%)

Epoch: 141
Loss: 0.325 | Acc: 90.625% (58/64)
Loss: 0.312 | Acc: 92.218% (5961/6464)
Loss: 0.325 | Acc: 91.923% (11825/12864)
Loss: 0.323 | Acc: 92.021% (17727/19264)
Loss: 0.326 | Acc: 91.938% (23595/25664)
Loss: 0.322 | Acc: 92.072% (29522/32064)
Loss: 0.321 | Acc: 92.058% (35409/38464)
Loss: 0.326 | Acc: 91.971% (41262/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8988, Accuracy: 8153/10000 (81.53%)

Epoch: 142
Loss: 0.170 | Acc: 95.312% (61/64)
Loss: 0.299 | Acc: 92.404% (5973/6464)
Loss: 0.289 | Acc: 92.708% (11926/12864)
Loss: 0.288 | Acc: 92.686% (17855/19264)
Loss: 0.288 | Acc: 92.733% (23799/25664)
Loss: 0.288 | Acc: 92.771% (29746/32064)
Loss: 0.289 | Acc: 92.759% (35679/38464)
Loss: 0.289 | Acc: 92.758% (41615/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9142, Accuracy: 8189/10000 (81.89%)

Epoch: 143
Loss: 0.302 | Acc: 92.188% (59/64)
Loss: 0.265 | Acc: 93.023% (6013/6464)
Loss: 0.263 | Acc: 93.066% (11972/12864)
Loss: 0.252 | Acc: 93.501% (18012/19264)
Loss: 0.253 | Acc: 93.485% (23992/25664)
Loss: 0.253 | Acc: 93.482% (29974/32064)
Loss: 0.252 | Acc: 93.529% (35975/38464)
Loss: 0.256 | Acc: 93.420% (41912/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9364, Accuracy: 8190/10000 (81.90%)

Epoch: 144
Loss: 0.382 | Acc: 90.625% (58/64)
Loss: 0.227 | Acc: 94.090% (6082/6464)
Loss: 0.221 | Acc: 94.248% (12124/12864)
Loss: 0.222 | Acc: 94.238% (18154/19264)
Loss: 0.222 | Acc: 94.214% (24179/25664)
Loss: 0.221 | Acc: 94.212% (30208/32064)
Loss: 0.222 | Acc: 94.195% (36231/38464)
Loss: 0.223 | Acc: 94.147% (42238/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9464, Accuracy: 8205/10000 (82.05%)

Epoch: 145
Loss: 0.175 | Acc: 96.875% (62/64)
Loss: 0.191 | Acc: 94.585% (6114/6464)
Loss: 0.194 | Acc: 94.660% (12177/12864)
Loss: 0.193 | Acc: 94.669% (18237/19264)
Loss: 0.193 | Acc: 94.638% (24288/25664)
Loss: 0.192 | Acc: 94.695% (30363/32064)
Loss: 0.193 | Acc: 94.712% (36430/38464)
Loss: 0.192 | Acc: 94.762% (42514/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9688, Accuracy: 8156/10000 (81.56%)

Epoch: 146
Loss: 0.340 | Acc: 92.188% (59/64)
Loss: 0.169 | Acc: 95.684% (6185/6464)
Loss: 0.172 | Acc: 95.445% (12278/12864)
Loss: 0.174 | Acc: 95.287% (18356/19264)
Loss: 0.170 | Acc: 95.394% (24482/25664)
Loss: 0.170 | Acc: 95.403% (30590/32064)
Loss: 0.172 | Acc: 95.351% (36676/38464)
Loss: 0.173 | Acc: 95.341% (42774/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9643, Accuracy: 8203/10000 (82.03%)

Epoch: 147
Loss: 0.189 | Acc: 96.875% (62/64)
Loss: 0.152 | Acc: 95.838% (6195/6464)
Loss: 0.156 | Acc: 95.732% (12315/12864)
Loss: 0.160 | Acc: 95.645% (18425/19264)
Loss: 0.155 | Acc: 95.827% (24593/25664)
Loss: 0.156 | Acc: 95.758% (30704/32064)
Loss: 0.158 | Acc: 95.731% (36822/38464)
Loss: 0.158 | Acc: 95.749% (42957/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9690, Accuracy: 8211/10000 (82.11%)
torch.Size([100, 10])
Test set: Average loss: 0.9690, Accuracy: 8211/10000 (82.11%)

Epoch: 148
Loss: 0.061 | Acc: 98.438% (63/64)
Loss: 0.148 | Acc: 96.071% (6210/6464)
Loss: 0.147 | Acc: 96.051% (12356/12864)
Loss: 0.149 | Acc: 95.873% (18469/19264)
Loss: 0.147 | Acc: 95.955% (24626/25664)
Loss: 0.148 | Acc: 95.933% (30760/32064)
Loss: 0.151 | Acc: 95.856% (36870/38464)
Loss: 0.150 | Acc: 95.876% (43014/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9728, Accuracy: 8189/10000 (81.89%)
torch.Size([100, 10])
Test set: Average loss: 0.9728, Accuracy: 8189/10000 (81.89%)

Epoch: 149
Loss: 0.267 | Acc: 93.750% (60/64)
Loss: 0.141 | Acc: 96.163% (6216/6464)
Loss: 0.141 | Acc: 96.175% (12372/12864)
Loss: 0.139 | Acc: 96.252% (18542/19264)
Loss: 0.137 | Acc: 96.263% (24705/25664)
Loss: 0.139 | Acc: 96.195% (30844/32064)
Loss: 0.142 | Acc: 96.103% (36965/38464)
Loss: 0.144 | Acc: 96.046% (43090/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9771, Accuracy: 8214/10000 (82.14%)
torch.Size([100, 10])
Test set: Average loss: 0.9771, Accuracy: 8214/10000 (82.14%)

Epoch: 150
Loss: 0.048 | Acc: 100.000% (64/64)
Loss: 1.383 | Acc: 56.080% (3625/6464)
Loss: 1.196 | Acc: 63.829% (8211/12864)
Loss: 1.116 | Acc: 67.058% (12918/19264)
Loss: 1.065 | Acc: 69.093% (17732/25664)
Loss: 1.027 | Acc: 70.543% (22619/32064)
Loss: 0.999 | Acc: 71.623% (27549/38464)
Loss: 0.982 | Acc: 72.361% (32464/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9884, Accuracy: 4366/10000 (43.66%)

Epoch: 151
Loss: 0.846 | Acc: 76.562% (49/64)
Loss: 0.813 | Acc: 78.481% (5073/6464)
Loss: 0.817 | Acc: 78.358% (10080/12864)
Loss: 0.824 | Acc: 78.296% (15083/19264)
Loss: 0.820 | Acc: 78.386% (20117/25664)
Loss: 0.817 | Acc: 78.471% (25161/32064)
Loss: 0.819 | Acc: 78.453% (30176/38464)
Loss: 0.819 | Acc: 78.413% (35179/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2033, Accuracy: 3757/10000 (37.57%)

Epoch: 152
Loss: 1.052 | Acc: 68.750% (44/64)
Loss: 0.788 | Acc: 79.455% (5136/6464)
Loss: 0.781 | Acc: 79.734% (10257/12864)
Loss: 0.788 | Acc: 79.511% (15317/19264)
Loss: 0.794 | Acc: 79.259% (20341/25664)
Loss: 0.797 | Acc: 79.291% (25424/32064)
Loss: 0.801 | Acc: 79.305% (30504/38464)
Loss: 0.797 | Acc: 79.375% (35611/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4814, Accuracy: 5772/10000 (57.72%)

Epoch: 153
Loss: 1.055 | Acc: 65.625% (42/64)
Loss: 0.788 | Acc: 79.223% (5121/6464)
Loss: 0.772 | Acc: 79.781% (10263/12864)
Loss: 0.779 | Acc: 79.745% (15362/19264)
Loss: 0.778 | Acc: 79.804% (20481/25664)
Loss: 0.783 | Acc: 79.731% (25565/32064)
Loss: 0.787 | Acc: 79.602% (30618/38464)
Loss: 0.787 | Acc: 79.627% (35724/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2464, Accuracy: 4298/10000 (42.98%)

Epoch: 154
Loss: 0.878 | Acc: 76.562% (49/64)
Loss: 0.772 | Acc: 79.842% (5161/6464)
Loss: 0.788 | Acc: 79.664% (10248/12864)
Loss: 0.781 | Acc: 79.895% (15391/19264)
Loss: 0.780 | Acc: 80.046% (20543/25664)
Loss: 0.782 | Acc: 79.953% (25636/32064)
Loss: 0.781 | Acc: 79.953% (30753/38464)
Loss: 0.779 | Acc: 80.046% (35912/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2974, Accuracy: 6179/10000 (61.79%)

Epoch: 155
Loss: 1.044 | Acc: 70.312% (45/64)
Loss: 0.781 | Acc: 79.827% (5160/6464)
Loss: 0.781 | Acc: 79.859% (10273/12864)
Loss: 0.778 | Acc: 79.895% (15391/19264)
Loss: 0.775 | Acc: 79.999% (20531/25664)
Loss: 0.775 | Acc: 80.031% (25661/32064)
Loss: 0.779 | Acc: 79.898% (30732/38464)
Loss: 0.781 | Acc: 79.886% (35840/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9382, Accuracy: 7516/10000 (75.16%)

Epoch: 156
Loss: 0.558 | Acc: 82.812% (53/64)
Loss: 0.762 | Acc: 80.476% (5202/6464)
Loss: 0.762 | Acc: 80.589% (10367/12864)
Loss: 0.759 | Acc: 80.534% (15514/19264)
Loss: 0.759 | Acc: 80.502% (20660/25664)
Loss: 0.766 | Acc: 80.317% (25753/32064)
Loss: 0.771 | Acc: 80.202% (30849/38464)
Loss: 0.771 | Acc: 80.149% (35958/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1653, Accuracy: 6657/10000 (66.57%)

Epoch: 157
Loss: 0.692 | Acc: 82.812% (53/64)
Loss: 0.777 | Acc: 80.306% (5191/6464)
Loss: 0.765 | Acc: 80.185% (10315/12864)
Loss: 0.775 | Acc: 80.087% (15428/19264)
Loss: 0.778 | Acc: 80.042% (20542/25664)
Loss: 0.776 | Acc: 80.049% (25667/32064)
Loss: 0.771 | Acc: 80.194% (30846/38464)
Loss: 0.774 | Acc: 80.138% (35953/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0119, Accuracy: 7201/10000 (72.01%)

Epoch: 158
Loss: 0.696 | Acc: 78.125% (50/64)
Loss: 0.765 | Acc: 80.662% (5214/6464)
Loss: 0.758 | Acc: 80.636% (10373/12864)
Loss: 0.761 | Acc: 80.528% (15513/19264)
Loss: 0.762 | Acc: 80.502% (20660/25664)
Loss: 0.766 | Acc: 80.417% (25785/32064)
Loss: 0.766 | Acc: 80.491% (30960/38464)
Loss: 0.771 | Acc: 80.309% (36030/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1122, Accuracy: 6949/10000 (69.49%)

Epoch: 159
Loss: 0.826 | Acc: 82.812% (53/64)
Loss: 0.745 | Acc: 80.832% (5225/6464)
Loss: 0.749 | Acc: 80.745% (10387/12864)
Loss: 0.750 | Acc: 80.824% (15570/19264)
Loss: 0.752 | Acc: 80.736% (20720/25664)
Loss: 0.754 | Acc: 80.654% (25861/32064)
Loss: 0.759 | Acc: 80.584% (30996/38464)
Loss: 0.765 | Acc: 80.405% (36073/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3501, Accuracy: 6239/10000 (62.39%)

Epoch: 160
Loss: 0.935 | Acc: 71.875% (46/64)
Loss: 0.770 | Acc: 80.925% (5231/6464)
Loss: 0.771 | Acc: 80.854% (10401/12864)
Loss: 0.759 | Acc: 80.944% (15593/19264)
Loss: 0.759 | Acc: 80.759% (20726/25664)
Loss: 0.756 | Acc: 80.866% (25929/32064)
Loss: 0.763 | Acc: 80.665% (31027/38464)
Loss: 0.763 | Acc: 80.577% (36150/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0748, Accuracy: 7088/10000 (70.88%)

Epoch: 161
Loss: 1.222 | Acc: 70.312% (45/64)
Loss: 0.720 | Acc: 82.024% (5302/6464)
Loss: 0.741 | Acc: 81.351% (10465/12864)
Loss: 0.754 | Acc: 81.032% (15610/19264)
Loss: 0.758 | Acc: 80.876% (20756/25664)
Loss: 0.761 | Acc: 80.770% (25898/32064)
Loss: 0.762 | Acc: 80.808% (31082/38464)
Loss: 0.762 | Acc: 80.753% (36229/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2452, Accuracy: 6394/10000 (63.94%)

Epoch: 162
Loss: 0.821 | Acc: 82.812% (53/64)
Loss: 0.743 | Acc: 80.941% (5232/6464)
Loss: 0.744 | Acc: 80.993% (10419/12864)
Loss: 0.744 | Acc: 81.048% (15613/19264)
Loss: 0.747 | Acc: 81.036% (20797/25664)
Loss: 0.751 | Acc: 80.854% (25925/32064)
Loss: 0.753 | Acc: 80.857% (31101/38464)
Loss: 0.755 | Acc: 80.791% (36246/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9161, Accuracy: 7604/10000 (76.04%)

Epoch: 163
Loss: 0.458 | Acc: 87.500% (56/64)
Loss: 0.716 | Acc: 81.946% (5297/6464)
Loss: 0.735 | Acc: 81.390% (10470/12864)
Loss: 0.737 | Acc: 81.504% (15701/19264)
Loss: 0.745 | Acc: 81.324% (20871/25664)
Loss: 0.749 | Acc: 81.228% (26045/32064)
Loss: 0.751 | Acc: 81.039% (31171/38464)
Loss: 0.752 | Acc: 81.029% (36353/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0847, Accuracy: 6852/10000 (68.52%)

Epoch: 164
Loss: 0.986 | Acc: 73.438% (47/64)
Loss: 0.733 | Acc: 81.699% (5281/6464)
Loss: 0.711 | Acc: 82.144% (10567/12864)
Loss: 0.725 | Acc: 81.691% (15737/19264)
Loss: 0.740 | Acc: 81.094% (20812/25664)
Loss: 0.739 | Acc: 81.188% (26032/32064)
Loss: 0.742 | Acc: 81.156% (31216/38464)
Loss: 0.745 | Acc: 81.116% (36392/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1408, Accuracy: 6725/10000 (67.25%)

Epoch: 165
Loss: 0.746 | Acc: 82.812% (53/64)
Loss: 0.751 | Acc: 81.327% (5257/6464)
Loss: 0.741 | Acc: 81.646% (10503/12864)
Loss: 0.738 | Acc: 81.613% (15722/19264)
Loss: 0.738 | Acc: 81.624% (20948/25664)
Loss: 0.738 | Acc: 81.606% (26166/32064)
Loss: 0.733 | Acc: 81.695% (31423/38464)
Loss: 0.735 | Acc: 81.731% (36668/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1914, Accuracy: 6603/10000 (66.03%)

Epoch: 166
Loss: 1.156 | Acc: 67.188% (43/64)
Loss: 0.721 | Acc: 81.946% (5297/6464)
Loss: 0.719 | Acc: 81.755% (10517/12864)
Loss: 0.713 | Acc: 81.883% (15774/19264)
Loss: 0.722 | Acc: 81.799% (20993/25664)
Loss: 0.726 | Acc: 81.743% (26210/32064)
Loss: 0.731 | Acc: 81.559% (31371/38464)
Loss: 0.731 | Acc: 81.602% (36610/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4272, Accuracy: 6321/10000 (63.21%)

Epoch: 167
Loss: 0.628 | Acc: 85.938% (55/64)
Loss: 0.709 | Acc: 81.730% (5283/6464)
Loss: 0.716 | Acc: 81.965% (10544/12864)
Loss: 0.722 | Acc: 81.972% (15791/19264)
Loss: 0.718 | Acc: 82.177% (21090/25664)
Loss: 0.721 | Acc: 82.011% (26296/32064)
Loss: 0.724 | Acc: 81.887% (31497/38464)
Loss: 0.726 | Acc: 81.867% (36729/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3320, Accuracy: 6462/10000 (64.62%)

Epoch: 168
Loss: 0.517 | Acc: 84.375% (54/64)
Loss: 0.685 | Acc: 83.122% (5373/6464)
Loss: 0.709 | Acc: 82.377% (10597/12864)
Loss: 0.715 | Acc: 82.164% (15828/19264)
Loss: 0.714 | Acc: 82.092% (21068/25664)
Loss: 0.719 | Acc: 82.052% (26309/32064)
Loss: 0.720 | Acc: 82.085% (31573/38464)
Loss: 0.718 | Acc: 82.193% (36875/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0773, Accuracy: 6945/10000 (69.45%)

Epoch: 169
Loss: 0.757 | Acc: 81.250% (52/64)
Loss: 0.702 | Acc: 82.256% (5317/6464)
Loss: 0.707 | Acc: 82.346% (10593/12864)
Loss: 0.712 | Acc: 82.345% (15863/19264)
Loss: 0.712 | Acc: 82.396% (21146/25664)
Loss: 0.718 | Acc: 82.204% (26358/32064)
Loss: 0.718 | Acc: 82.186% (31612/38464)
Loss: 0.716 | Acc: 82.175% (36867/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0978, Accuracy: 6952/10000 (69.52%)

Epoch: 170
Loss: 1.106 | Acc: 70.312% (45/64)
Loss: 0.701 | Acc: 82.673% (5344/6464)
Loss: 0.695 | Acc: 82.882% (10662/12864)
Loss: 0.707 | Acc: 82.563% (15905/19264)
Loss: 0.706 | Acc: 82.618% (21203/25664)
Loss: 0.708 | Acc: 82.476% (26445/32064)
Loss: 0.705 | Acc: 82.514% (31738/38464)
Loss: 0.709 | Acc: 82.429% (36981/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1811, Accuracy: 6836/10000 (68.36%)

Epoch: 171
Loss: 0.836 | Acc: 79.688% (51/64)
Loss: 0.676 | Acc: 83.199% (5378/6464)
Loss: 0.684 | Acc: 83.263% (10711/12864)
Loss: 0.688 | Acc: 83.098% (16008/19264)
Loss: 0.693 | Acc: 82.980% (21296/25664)
Loss: 0.690 | Acc: 83.050% (26629/32064)
Loss: 0.692 | Acc: 83.036% (31939/38464)
Loss: 0.690 | Acc: 83.145% (37302/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9211, Accuracy: 7582/10000 (75.82%)

Epoch: 172
Loss: 0.986 | Acc: 73.438% (47/64)
Loss: 0.685 | Acc: 83.230% (5380/6464)
Loss: 0.675 | Acc: 83.473% (10738/12864)
Loss: 0.671 | Acc: 83.622% (16109/19264)
Loss: 0.672 | Acc: 83.498% (21429/25664)
Loss: 0.673 | Acc: 83.552% (26790/32064)
Loss: 0.676 | Acc: 83.421% (32087/38464)
Loss: 0.681 | Acc: 83.352% (37395/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9724, Accuracy: 5002/10000 (50.02%)

Epoch: 173
Loss: 0.970 | Acc: 76.562% (49/64)
Loss: 0.685 | Acc: 83.292% (5384/6464)
Loss: 0.673 | Acc: 83.287% (10714/12864)
Loss: 0.674 | Acc: 83.435% (16073/19264)
Loss: 0.675 | Acc: 83.374% (21397/25664)
Loss: 0.678 | Acc: 83.424% (26749/32064)
Loss: 0.679 | Acc: 83.351% (32060/38464)
Loss: 0.678 | Acc: 83.388% (37411/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2148, Accuracy: 6602/10000 (66.02%)

Epoch: 174
Loss: 0.902 | Acc: 76.562% (49/64)
Loss: 0.650 | Acc: 83.973% (5428/6464)
Loss: 0.650 | Acc: 84.313% (10846/12864)
Loss: 0.653 | Acc: 84.126% (16206/19264)
Loss: 0.664 | Acc: 83.845% (21518/25664)
Loss: 0.662 | Acc: 83.932% (26912/32064)
Loss: 0.663 | Acc: 83.941% (32287/38464)
Loss: 0.666 | Acc: 83.871% (37628/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8701, Accuracy: 7774/10000 (77.74%)

Epoch: 175
Loss: 0.569 | Acc: 87.500% (56/64)
Loss: 0.639 | Acc: 84.777% (5480/6464)
Loss: 0.637 | Acc: 84.639% (10888/12864)
Loss: 0.639 | Acc: 84.619% (16301/19264)
Loss: 0.648 | Acc: 84.340% (21645/25664)
Loss: 0.642 | Acc: 84.440% (27075/32064)
Loss: 0.646 | Acc: 84.341% (32441/38464)
Loss: 0.651 | Acc: 84.275% (37809/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9354, Accuracy: 7603/10000 (76.03%)

Epoch: 176
Loss: 0.805 | Acc: 81.250% (52/64)
Loss: 0.642 | Acc: 84.561% (5466/6464)
Loss: 0.641 | Acc: 84.593% (10882/12864)
Loss: 0.645 | Acc: 84.422% (16263/19264)
Loss: 0.649 | Acc: 84.348% (21647/25664)
Loss: 0.648 | Acc: 84.378% (27055/32064)
Loss: 0.644 | Acc: 84.448% (32482/38464)
Loss: 0.642 | Acc: 84.486% (37904/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1221, Accuracy: 6929/10000 (69.29%)

Epoch: 177
Loss: 0.518 | Acc: 82.812% (53/64)
Loss: 0.647 | Acc: 84.561% (5466/6464)
Loss: 0.623 | Acc: 85.308% (10974/12864)
Loss: 0.624 | Acc: 85.341% (16440/19264)
Loss: 0.628 | Acc: 85.150% (21853/25664)
Loss: 0.630 | Acc: 85.017% (27260/32064)
Loss: 0.636 | Acc: 84.786% (32612/38464)
Loss: 0.634 | Acc: 84.836% (38061/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8675, Accuracy: 7742/10000 (77.42%)

Epoch: 178
Loss: 0.505 | Acc: 85.938% (55/64)
Loss: 0.586 | Acc: 86.433% (5587/6464)
Loss: 0.602 | Acc: 85.922% (11053/12864)
Loss: 0.606 | Acc: 85.761% (16521/19264)
Loss: 0.608 | Acc: 85.622% (21974/25664)
Loss: 0.612 | Acc: 85.548% (27430/32064)
Loss: 0.613 | Acc: 85.488% (32882/38464)
Loss: 0.614 | Acc: 85.485% (38352/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1527, Accuracy: 6851/10000 (68.51%)

Epoch: 179
Loss: 0.583 | Acc: 85.938% (55/64)
Loss: 0.606 | Acc: 85.860% (5550/6464)
Loss: 0.605 | Acc: 85.673% (11021/12864)
Loss: 0.600 | Acc: 85.797% (16528/19264)
Loss: 0.600 | Acc: 85.801% (22020/25664)
Loss: 0.605 | Acc: 85.713% (27483/32064)
Loss: 0.602 | Acc: 85.784% (32996/38464)
Loss: 0.602 | Acc: 85.775% (38482/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8134, Accuracy: 8003/10000 (80.03%)

Epoch: 180
Loss: 0.518 | Acc: 85.938% (55/64)
Loss: 0.589 | Acc: 86.309% (5579/6464)
Loss: 0.594 | Acc: 86.046% (11069/12864)
Loss: 0.587 | Acc: 86.233% (16612/19264)
Loss: 0.584 | Acc: 86.284% (22144/25664)
Loss: 0.588 | Acc: 86.181% (27633/32064)
Loss: 0.589 | Acc: 86.153% (33138/38464)
Loss: 0.588 | Acc: 86.129% (38641/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9136, Accuracy: 7658/10000 (76.58%)

Epoch: 181
Loss: 0.664 | Acc: 79.688% (51/64)
Loss: 0.574 | Acc: 85.907% (5553/6464)
Loss: 0.556 | Acc: 86.544% (11133/12864)
Loss: 0.564 | Acc: 86.555% (16674/19264)
Loss: 0.571 | Acc: 86.436% (22183/25664)
Loss: 0.567 | Acc: 86.639% (27780/32064)
Loss: 0.573 | Acc: 86.473% (33261/38464)
Loss: 0.575 | Acc: 86.450% (38785/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9375, Accuracy: 7640/10000 (76.40%)

Epoch: 182
Loss: 0.687 | Acc: 81.250% (52/64)
Loss: 0.547 | Acc: 87.160% (5634/6464)
Loss: 0.527 | Acc: 87.718% (11284/12864)
Loss: 0.538 | Acc: 87.521% (16860/19264)
Loss: 0.541 | Acc: 87.387% (22427/25664)
Loss: 0.549 | Acc: 87.244% (27974/32064)
Loss: 0.551 | Acc: 87.193% (33538/38464)
Loss: 0.551 | Acc: 87.230% (39135/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8351, Accuracy: 7962/10000 (79.62%)

Epoch: 183
Loss: 0.484 | Acc: 90.625% (58/64)
Loss: 0.503 | Acc: 88.397% (5714/6464)
Loss: 0.522 | Acc: 87.928% (11311/12864)
Loss: 0.532 | Acc: 87.645% (16884/19264)
Loss: 0.532 | Acc: 87.594% (22480/25664)
Loss: 0.533 | Acc: 87.581% (28082/32064)
Loss: 0.535 | Acc: 87.477% (33647/38464)
Loss: 0.536 | Acc: 87.493% (39253/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7959, Accuracy: 8139/10000 (81.39%)

Epoch: 184
Loss: 0.599 | Acc: 84.375% (54/64)
Loss: 0.496 | Acc: 88.490% (5720/6464)
Loss: 0.512 | Acc: 87.803% (11295/12864)
Loss: 0.521 | Acc: 87.723% (16899/19264)
Loss: 0.517 | Acc: 87.827% (22540/25664)
Loss: 0.517 | Acc: 87.877% (28177/32064)
Loss: 0.516 | Acc: 87.900% (33810/38464)
Loss: 0.517 | Acc: 87.921% (39445/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8019, Accuracy: 8111/10000 (81.11%)

Epoch: 185
Loss: 0.456 | Acc: 89.062% (57/64)
Loss: 0.483 | Acc: 88.490% (5720/6464)
Loss: 0.472 | Acc: 88.954% (11443/12864)
Loss: 0.481 | Acc: 88.761% (17099/19264)
Loss: 0.491 | Acc: 88.494% (22711/25664)
Loss: 0.493 | Acc: 88.379% (28338/32064)
Loss: 0.493 | Acc: 88.423% (34011/38464)
Loss: 0.495 | Acc: 88.443% (39679/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8911, Accuracy: 7956/10000 (79.56%)

Epoch: 186
Loss: 0.367 | Acc: 90.625% (58/64)
Loss: 0.448 | Acc: 89.558% (5789/6464)
Loss: 0.461 | Acc: 89.202% (11475/12864)
Loss: 0.459 | Acc: 89.286% (17200/19264)
Loss: 0.465 | Acc: 89.179% (22887/25664)
Loss: 0.468 | Acc: 89.128% (28578/32064)
Loss: 0.469 | Acc: 89.117% (34278/38464)
Loss: 0.468 | Acc: 89.069% (39960/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8071, Accuracy: 8162/10000 (81.62%)

Epoch: 187
Loss: 0.223 | Acc: 96.875% (62/64)
Loss: 0.422 | Acc: 90.084% (5823/6464)
Loss: 0.425 | Acc: 90.081% (11588/12864)
Loss: 0.434 | Acc: 89.831% (17305/19264)
Loss: 0.439 | Acc: 89.670% (23013/25664)
Loss: 0.438 | Acc: 89.727% (28770/32064)
Loss: 0.443 | Acc: 89.634% (34477/38464)
Loss: 0.443 | Acc: 89.642% (40217/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9031, Accuracy: 7985/10000 (79.85%)

Epoch: 188
Loss: 0.672 | Acc: 82.812% (53/64)
Loss: 0.423 | Acc: 89.635% (5794/6464)
Loss: 0.419 | Acc: 89.817% (11554/12864)
Loss: 0.423 | Acc: 89.836% (17306/19264)
Loss: 0.424 | Acc: 89.791% (23044/25664)
Loss: 0.425 | Acc: 89.792% (28791/32064)
Loss: 0.421 | Acc: 89.962% (34603/38464)
Loss: 0.421 | Acc: 89.950% (40355/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8301, Accuracy: 8182/10000 (81.82%)

Epoch: 189
Loss: 0.212 | Acc: 93.750% (60/64)
Loss: 0.364 | Acc: 90.934% (5878/6464)
Loss: 0.373 | Acc: 90.928% (11697/12864)
Loss: 0.378 | Acc: 90.978% (17526/19264)
Loss: 0.381 | Acc: 90.960% (23344/25664)
Loss: 0.382 | Acc: 90.906% (29148/32064)
Loss: 0.385 | Acc: 90.864% (34950/38464)
Loss: 0.387 | Acc: 90.799% (40736/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8509, Accuracy: 8229/10000 (82.29%)

Epoch: 190
Loss: 0.422 | Acc: 87.500% (56/64)
Loss: 0.345 | Acc: 91.615% (5922/6464)
Loss: 0.346 | Acc: 91.698% (11796/12864)
Loss: 0.347 | Acc: 91.523% (17631/19264)
Loss: 0.349 | Acc: 91.467% (23474/25664)
Loss: 0.347 | Acc: 91.551% (29355/32064)
Loss: 0.349 | Acc: 91.538% (35209/38464)
Loss: 0.350 | Acc: 91.534% (41066/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8965, Accuracy: 8091/10000 (80.91%)

Epoch: 191
Loss: 0.446 | Acc: 87.500% (56/64)
Loss: 0.302 | Acc: 92.466% (5977/6464)
Loss: 0.304 | Acc: 92.491% (11898/12864)
Loss: 0.311 | Acc: 92.348% (17790/19264)
Loss: 0.313 | Acc: 92.332% (23696/25664)
Loss: 0.313 | Acc: 92.378% (29620/32064)
Loss: 0.319 | Acc: 92.211% (35468/38464)
Loss: 0.319 | Acc: 92.188% (41359/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8820, Accuracy: 8172/10000 (81.72%)

Epoch: 192
Loss: 0.148 | Acc: 96.875% (62/64)
Loss: 0.279 | Acc: 92.946% (6008/6464)
Loss: 0.278 | Acc: 92.926% (11954/12864)
Loss: 0.276 | Acc: 93.039% (17923/19264)
Loss: 0.279 | Acc: 92.978% (23862/25664)
Loss: 0.281 | Acc: 92.911% (29791/32064)
Loss: 0.280 | Acc: 92.918% (35740/38464)
Loss: 0.282 | Acc: 92.870% (41665/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9208, Accuracy: 8214/10000 (82.14%)

Epoch: 193
Loss: 0.197 | Acc: 93.750% (60/64)
Loss: 0.258 | Acc: 93.472% (6042/6464)
Loss: 0.247 | Acc: 93.657% (12048/12864)
Loss: 0.246 | Acc: 93.667% (18044/19264)
Loss: 0.250 | Acc: 93.536% (24005/25664)
Loss: 0.248 | Acc: 93.572% (30003/32064)
Loss: 0.246 | Acc: 93.615% (36008/38464)
Loss: 0.245 | Acc: 93.665% (42022/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9225, Accuracy: 8215/10000 (82.15%)

Epoch: 194
Loss: 0.192 | Acc: 93.750% (60/64)
Loss: 0.220 | Acc: 93.982% (6075/6464)
Loss: 0.219 | Acc: 94.069% (12101/12864)
Loss: 0.215 | Acc: 94.202% (18147/19264)
Loss: 0.217 | Acc: 94.159% (24165/25664)
Loss: 0.218 | Acc: 94.121% (30179/32064)
Loss: 0.218 | Acc: 94.150% (36214/38464)
Loss: 0.217 | Acc: 94.191% (42258/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9459, Accuracy: 8214/10000 (82.14%)

Epoch: 195
Loss: 0.246 | Acc: 92.188% (59/64)
Loss: 0.184 | Acc: 94.817% (6129/6464)
Loss: 0.185 | Acc: 94.947% (12214/12864)
Loss: 0.190 | Acc: 94.825% (18267/19264)
Loss: 0.189 | Acc: 94.857% (24344/25664)
Loss: 0.189 | Acc: 94.920% (30435/32064)
Loss: 0.188 | Acc: 94.943% (36519/38464)
Loss: 0.188 | Acc: 94.927% (42588/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9608, Accuracy: 8221/10000 (82.21%)

Epoch: 196
Loss: 0.253 | Acc: 90.625% (58/64)
Loss: 0.165 | Acc: 95.359% (6164/6464)
Loss: 0.165 | Acc: 95.437% (12277/12864)
Loss: 0.168 | Acc: 95.333% (18365/19264)
Loss: 0.165 | Acc: 95.457% (24498/25664)
Loss: 0.162 | Acc: 95.550% (30637/32064)
Loss: 0.163 | Acc: 95.487% (36728/38464)
Loss: 0.163 | Acc: 95.500% (42845/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9798, Accuracy: 8192/10000 (81.92%)

Epoch: 197
Loss: 0.095 | Acc: 98.438% (63/64)
Loss: 0.152 | Acc: 95.854% (6196/6464)
Loss: 0.153 | Acc: 95.725% (12314/12864)
Loss: 0.154 | Acc: 95.665% (18429/19264)
Loss: 0.154 | Acc: 95.671% (24553/25664)
Loss: 0.154 | Acc: 95.696% (30684/32064)
Loss: 0.153 | Acc: 95.760% (36833/38464)
Loss: 0.153 | Acc: 95.761% (42962/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9848, Accuracy: 8214/10000 (82.14%)
torch.Size([100, 10])
Test set: Average loss: 0.9848, Accuracy: 8214/10000 (82.14%)

Epoch: 198
Loss: 0.239 | Acc: 92.188% (59/64)
Loss: 0.152 | Acc: 95.761% (6190/6464)
Loss: 0.148 | Acc: 95.911% (12338/12864)
Loss: 0.146 | Acc: 95.961% (18486/19264)
Loss: 0.147 | Acc: 95.897% (24611/25664)
Loss: 0.144 | Acc: 96.008% (30784/32064)
Loss: 0.145 | Acc: 95.973% (36915/38464)
Loss: 0.144 | Acc: 95.988% (43064/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9838, Accuracy: 8190/10000 (81.90%)
torch.Size([100, 10])
Test set: Average loss: 0.9838, Accuracy: 8190/10000 (81.90%)

Epoch: 199
Loss: 0.031 | Acc: 100.000% (64/64)
Loss: 0.147 | Acc: 95.838% (6195/6464)
Loss: 0.138 | Acc: 96.121% (12365/12864)
Loss: 0.140 | Acc: 96.133% (18519/19264)
Loss: 0.138 | Acc: 96.232% (24697/25664)
Loss: 0.140 | Acc: 96.198% (30845/32064)
Loss: 0.139 | Acc: 96.261% (37026/38464)
Loss: 0.141 | Acc: 96.215% (43166/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9877, Accuracy: 8202/10000 (82.02%)
torch.Size([100, 10])
Test set: Average loss: 0.9877, Accuracy: 8202/10000 (82.02%)
8456
10000
-0.7991575598716736
