==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.361 | Acc: 15.625% (10/64)
Loss: 2.811 | Acc: 17.157% (1109/6464)
Loss: 2.418 | Acc: 19.784% (2545/12864)
Loss: 2.252 | Acc: 21.699% (4180/19264)
Loss: 2.153 | Acc: 23.730% (6090/25664)
Loss: 2.076 | Acc: 25.555% (8194/32064)
Loss: 2.013 | Acc: 27.394% (10537/38464)
Loss: 1.958 | Acc: 29.052% (13034/44864)
torch.Size([100, 10])
Test set: Average loss: 2.6588, Accuracy: 2404/10000 (24.04%)

Epoch: 1
Loss: 1.953 | Acc: 34.375% (22/64)
Loss: 1.530 | Acc: 43.193% (2792/6464)
Loss: 1.509 | Acc: 44.014% (5662/12864)
Loss: 1.495 | Acc: 44.404% (8554/19264)
Loss: 1.477 | Acc: 45.250% (11613/25664)
Loss: 1.452 | Acc: 46.242% (14827/32064)
Loss: 1.433 | Acc: 47.023% (18087/38464)
Loss: 1.409 | Acc: 48.025% (21546/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8160, Accuracy: 4254/10000 (42.54%)

Epoch: 2
Loss: 1.282 | Acc: 51.562% (33/64)
Loss: 1.197 | Acc: 56.498% (3652/6464)
Loss: 1.198 | Acc: 56.981% (7330/12864)
Loss: 1.172 | Acc: 57.854% (11145/19264)
Loss: 1.149 | Acc: 58.829% (15098/25664)
Loss: 1.131 | Acc: 59.584% (19105/32064)
Loss: 1.116 | Acc: 60.145% (23134/38464)
Loss: 1.103 | Acc: 60.672% (27220/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0741, Accuracy: 6170/10000 (61.70%)

Epoch: 3
Loss: 0.932 | Acc: 67.188% (43/64)
Loss: 0.972 | Acc: 65.625% (4242/6464)
Loss: 0.974 | Acc: 65.594% (8438/12864)
Loss: 0.955 | Acc: 66.274% (12767/19264)
Loss: 0.941 | Acc: 66.852% (17157/25664)
Loss: 0.928 | Acc: 67.278% (21572/32064)
Loss: 0.915 | Acc: 67.700% (26040/38464)
Loss: 0.904 | Acc: 68.150% (30575/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3117, Accuracy: 5861/10000 (58.61%)

Epoch: 4
Loss: 1.237 | Acc: 57.812% (37/64)
Loss: 0.795 | Acc: 72.355% (4677/6464)
Loss: 0.784 | Acc: 72.341% (9306/12864)
Loss: 0.780 | Acc: 72.643% (13994/19264)
Loss: 0.771 | Acc: 72.900% (18709/25664)
Loss: 0.764 | Acc: 73.238% (23483/32064)
Loss: 0.754 | Acc: 73.606% (28312/38464)
Loss: 0.747 | Acc: 73.879% (33145/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3410, Accuracy: 5907/10000 (59.07%)

Epoch: 5
Loss: 0.972 | Acc: 71.875% (46/64)
Loss: 0.672 | Acc: 76.856% (4968/6464)
Loss: 0.675 | Acc: 76.664% (9862/12864)
Loss: 0.667 | Acc: 77.154% (14863/19264)
Loss: 0.666 | Acc: 77.018% (19766/25664)
Loss: 0.660 | Acc: 77.246% (24768/32064)
Loss: 0.658 | Acc: 77.322% (29741/38464)
Loss: 0.655 | Acc: 77.430% (34738/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1109, Accuracy: 6696/10000 (66.96%)

Epoch: 6
Loss: 0.641 | Acc: 81.250% (52/64)
Loss: 0.608 | Acc: 79.270% (5124/6464)
Loss: 0.604 | Acc: 79.439% (10219/12864)
Loss: 0.601 | Acc: 79.376% (15291/19264)
Loss: 0.597 | Acc: 79.411% (20380/25664)
Loss: 0.595 | Acc: 79.475% (25483/32064)
Loss: 0.596 | Acc: 79.469% (30567/38464)
Loss: 0.594 | Acc: 79.592% (35708/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3912, Accuracy: 5894/10000 (58.94%)

Epoch: 7
Loss: 0.635 | Acc: 73.438% (47/64)
Loss: 0.548 | Acc: 80.894% (5229/6464)
Loss: 0.561 | Acc: 80.698% (10381/12864)
Loss: 0.553 | Acc: 81.188% (15640/19264)
Loss: 0.554 | Acc: 81.336% (20874/25664)
Loss: 0.552 | Acc: 81.319% (26074/32064)
Loss: 0.553 | Acc: 81.260% (31256/38464)
Loss: 0.553 | Acc: 81.205% (36432/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7037, Accuracy: 7724/10000 (77.24%)

Epoch: 8
Loss: 0.623 | Acc: 78.125% (50/64)
Loss: 0.532 | Acc: 81.498% (5268/6464)
Loss: 0.519 | Acc: 81.911% (10537/12864)
Loss: 0.517 | Acc: 81.998% (15796/19264)
Loss: 0.515 | Acc: 82.205% (21097/25664)
Loss: 0.514 | Acc: 82.248% (26372/32064)
Loss: 0.517 | Acc: 82.124% (31588/38464)
Loss: 0.516 | Acc: 82.186% (36872/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3491, Accuracy: 6339/10000 (63.39%)

Epoch: 9
Loss: 0.543 | Acc: 79.688% (51/64)
Loss: 0.500 | Acc: 82.983% (5364/6464)
Loss: 0.490 | Acc: 83.240% (10708/12864)
Loss: 0.500 | Acc: 82.953% (15980/19264)
Loss: 0.499 | Acc: 82.968% (21293/25664)
Loss: 0.497 | Acc: 82.997% (26612/32064)
Loss: 0.499 | Acc: 82.950% (31906/38464)
Loss: 0.496 | Acc: 83.033% (37252/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8917, Accuracy: 7032/10000 (70.32%)

Epoch: 10
Loss: 0.665 | Acc: 78.125% (50/64)
Loss: 0.479 | Acc: 83.617% (5405/6464)
Loss: 0.468 | Acc: 83.776% (10777/12864)
Loss: 0.474 | Acc: 83.737% (16131/19264)
Loss: 0.475 | Acc: 83.678% (21475/25664)
Loss: 0.472 | Acc: 83.826% (26878/32064)
Loss: 0.473 | Acc: 83.897% (32270/38464)
Loss: 0.473 | Acc: 83.927% (37653/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6760, Accuracy: 7774/10000 (77.74%)

Epoch: 11
Loss: 0.661 | Acc: 75.000% (48/64)
Loss: 0.452 | Acc: 84.282% (5448/6464)
Loss: 0.456 | Acc: 84.087% (10817/12864)
Loss: 0.450 | Acc: 84.463% (16271/19264)
Loss: 0.456 | Acc: 84.356% (21649/25664)
Loss: 0.458 | Acc: 84.272% (27021/32064)
Loss: 0.456 | Acc: 84.302% (32426/38464)
Loss: 0.455 | Acc: 84.355% (37845/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8095, Accuracy: 7587/10000 (75.87%)

Epoch: 12
Loss: 0.500 | Acc: 87.500% (56/64)
Loss: 0.417 | Acc: 85.705% (5540/6464)
Loss: 0.419 | Acc: 85.533% (11003/12864)
Loss: 0.421 | Acc: 85.517% (16474/19264)
Loss: 0.428 | Acc: 85.318% (21896/25664)
Loss: 0.431 | Acc: 85.223% (27326/32064)
Loss: 0.433 | Acc: 85.176% (32762/38464)
Loss: 0.433 | Acc: 85.153% (38203/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0566, Accuracy: 4705/10000 (47.05%)

Epoch: 13
Loss: 1.504 | Acc: 60.938% (39/64)
Loss: 0.448 | Acc: 85.040% (5497/6464)
Loss: 0.428 | Acc: 85.704% (11025/12864)
Loss: 0.428 | Acc: 85.501% (16471/19264)
Loss: 0.426 | Acc: 85.447% (21929/25664)
Loss: 0.422 | Acc: 85.629% (27456/32064)
Loss: 0.421 | Acc: 85.587% (32920/38464)
Loss: 0.421 | Acc: 85.561% (38386/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9765, Accuracy: 5368/10000 (53.68%)

Epoch: 14
Loss: 0.613 | Acc: 73.438% (47/64)
Loss: 0.422 | Acc: 85.690% (5539/6464)
Loss: 0.412 | Acc: 85.790% (11036/12864)
Loss: 0.412 | Acc: 85.678% (16505/19264)
Loss: 0.412 | Acc: 85.825% (22026/25664)
Loss: 0.404 | Acc: 86.115% (27612/32064)
Loss: 0.406 | Acc: 86.075% (33108/38464)
Loss: 0.404 | Acc: 86.111% (38633/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2622, Accuracy: 6303/10000 (63.03%)

Epoch: 15
Loss: 0.881 | Acc: 67.188% (43/64)
Loss: 0.406 | Acc: 86.510% (5592/6464)
Loss: 0.391 | Acc: 86.684% (11151/12864)
Loss: 0.396 | Acc: 86.441% (16652/19264)
Loss: 0.390 | Acc: 86.752% (22264/25664)
Loss: 0.390 | Acc: 86.783% (27826/32064)
Loss: 0.390 | Acc: 86.793% (33384/38464)
Loss: 0.391 | Acc: 86.740% (38915/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6671, Accuracy: 7832/10000 (78.32%)

Epoch: 16
Loss: 0.404 | Acc: 85.938% (55/64)
Loss: 0.366 | Acc: 87.562% (5660/6464)
Loss: 0.362 | Acc: 87.819% (11297/12864)
Loss: 0.364 | Acc: 87.718% (16898/19264)
Loss: 0.370 | Acc: 87.391% (22428/25664)
Loss: 0.369 | Acc: 87.413% (28028/32064)
Loss: 0.371 | Acc: 87.422% (33626/38464)
Loss: 0.372 | Acc: 87.368% (39197/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6688, Accuracy: 7820/10000 (78.20%)

Epoch: 17
Loss: 0.372 | Acc: 85.938% (55/64)
Loss: 0.342 | Acc: 88.227% (5703/6464)
Loss: 0.364 | Acc: 87.586% (11267/12864)
Loss: 0.363 | Acc: 87.510% (16858/19264)
Loss: 0.361 | Acc: 87.539% (22466/25664)
Loss: 0.359 | Acc: 87.575% (28080/32064)
Loss: 0.361 | Acc: 87.484% (33650/38464)
Loss: 0.361 | Acc: 87.531% (39270/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5794, Accuracy: 8176/10000 (81.76%)

Epoch: 18
Loss: 0.540 | Acc: 85.938% (55/64)
Loss: 0.329 | Acc: 88.954% (5750/6464)
Loss: 0.336 | Acc: 88.464% (11380/12864)
Loss: 0.338 | Acc: 88.362% (17022/19264)
Loss: 0.340 | Acc: 88.396% (22686/25664)
Loss: 0.342 | Acc: 88.392% (28342/32064)
Loss: 0.347 | Acc: 88.270% (33952/38464)
Loss: 0.348 | Acc: 88.144% (39545/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5822, Accuracy: 8066/10000 (80.66%)

Epoch: 19
Loss: 0.278 | Acc: 92.188% (59/64)
Loss: 0.321 | Acc: 89.016% (5754/6464)
Loss: 0.329 | Acc: 88.798% (11423/12864)
Loss: 0.325 | Acc: 88.896% (17125/19264)
Loss: 0.328 | Acc: 88.716% (22768/25664)
Loss: 0.331 | Acc: 88.620% (28415/32064)
Loss: 0.332 | Acc: 88.623% (34088/38464)
Loss: 0.334 | Acc: 88.543% (39724/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5183, Accuracy: 8278/10000 (82.78%)

Epoch: 20
Loss: 0.304 | Acc: 89.062% (57/64)
Loss: 0.301 | Acc: 89.588% (5791/6464)
Loss: 0.305 | Acc: 89.397% (11500/12864)
Loss: 0.316 | Acc: 89.120% (17168/19264)
Loss: 0.318 | Acc: 89.012% (22844/25664)
Loss: 0.321 | Acc: 88.941% (28518/32064)
Loss: 0.320 | Acc: 89.029% (34244/38464)
Loss: 0.319 | Acc: 89.038% (39946/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0859, Accuracy: 7088/10000 (70.88%)

Epoch: 21
Loss: 0.489 | Acc: 84.375% (54/64)
Loss: 0.325 | Acc: 89.155% (5763/6464)
Loss: 0.321 | Acc: 89.101% (11462/12864)
Loss: 0.314 | Acc: 89.421% (17226/19264)
Loss: 0.316 | Acc: 89.363% (22934/25664)
Loss: 0.314 | Acc: 89.446% (28680/32064)
Loss: 0.314 | Acc: 89.356% (34370/38464)
Loss: 0.314 | Acc: 89.343% (40083/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7541, Accuracy: 7651/10000 (76.51%)

Epoch: 22
Loss: 0.447 | Acc: 84.375% (54/64)
Loss: 0.275 | Acc: 90.532% (5852/6464)
Loss: 0.289 | Acc: 90.229% (11607/12864)
Loss: 0.297 | Acc: 89.893% (17317/19264)
Loss: 0.297 | Acc: 89.896% (23071/25664)
Loss: 0.297 | Acc: 89.792% (28791/32064)
Loss: 0.298 | Acc: 89.764% (34527/38464)
Loss: 0.299 | Acc: 89.709% (40247/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0070, Accuracy: 7323/10000 (73.23%)

Epoch: 23
Loss: 0.457 | Acc: 82.812% (53/64)
Loss: 0.263 | Acc: 91.027% (5884/6464)
Loss: 0.281 | Acc: 90.470% (11638/12864)
Loss: 0.280 | Acc: 90.532% (17440/19264)
Loss: 0.286 | Acc: 90.411% (23203/25664)
Loss: 0.287 | Acc: 90.310% (28957/32064)
Loss: 0.286 | Acc: 90.308% (34736/38464)
Loss: 0.287 | Acc: 90.280% (40503/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2561, Accuracy: 6634/10000 (66.34%)

Epoch: 24
Loss: 0.428 | Acc: 81.250% (52/64)
Loss: 0.276 | Acc: 90.254% (5834/6464)
Loss: 0.280 | Acc: 90.283% (11614/12864)
Loss: 0.279 | Acc: 90.397% (17414/19264)
Loss: 0.276 | Acc: 90.477% (23220/25664)
Loss: 0.278 | Acc: 90.482% (29012/32064)
Loss: 0.279 | Acc: 90.469% (34798/38464)
Loss: 0.280 | Acc: 90.429% (40570/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7509, Accuracy: 7729/10000 (77.29%)

Epoch: 25
Loss: 0.356 | Acc: 90.625% (58/64)
Loss: 0.242 | Acc: 91.600% (5921/6464)
Loss: 0.255 | Acc: 91.123% (11722/12864)
Loss: 0.257 | Acc: 91.149% (17559/19264)
Loss: 0.254 | Acc: 91.112% (23383/25664)
Loss: 0.255 | Acc: 91.155% (29228/32064)
Loss: 0.257 | Acc: 91.122% (35049/38464)
Loss: 0.260 | Acc: 90.997% (40825/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2030, Accuracy: 5730/10000 (57.30%)

Epoch: 26
Loss: 0.688 | Acc: 78.125% (50/64)
Loss: 0.252 | Acc: 91.290% (5901/6464)
Loss: 0.250 | Acc: 91.278% (11742/12864)
Loss: 0.245 | Acc: 91.539% (17634/19264)
Loss: 0.247 | Acc: 91.467% (23474/25664)
Loss: 0.249 | Acc: 91.377% (29299/32064)
Loss: 0.248 | Acc: 91.402% (35157/38464)
Loss: 0.248 | Acc: 91.410% (41010/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7907, Accuracy: 7791/10000 (77.91%)

Epoch: 27
Loss: 0.285 | Acc: 90.625% (58/64)
Loss: 0.233 | Acc: 92.265% (5964/6464)
Loss: 0.232 | Acc: 92.226% (11864/12864)
Loss: 0.236 | Acc: 92.063% (17735/19264)
Loss: 0.238 | Acc: 91.895% (23584/25664)
Loss: 0.235 | Acc: 92.041% (29512/32064)
Loss: 0.234 | Acc: 92.081% (35418/38464)
Loss: 0.234 | Acc: 92.067% (41305/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3978, Accuracy: 6831/10000 (68.31%)

Epoch: 28
Loss: 0.797 | Acc: 75.000% (48/64)
Loss: 0.230 | Acc: 92.064% (5951/6464)
Loss: 0.228 | Acc: 92.195% (11860/12864)
Loss: 0.223 | Acc: 92.390% (17798/19264)
Loss: 0.226 | Acc: 92.234% (23671/25664)
Loss: 0.224 | Acc: 92.318% (29601/32064)
Loss: 0.224 | Acc: 92.380% (35533/38464)
Loss: 0.221 | Acc: 92.464% (41483/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5039, Accuracy: 6602/10000 (66.02%)

Epoch: 29
Loss: 0.349 | Acc: 92.188% (59/64)
Loss: 0.210 | Acc: 92.760% (5996/6464)
Loss: 0.209 | Acc: 92.988% (11962/12864)
Loss: 0.199 | Acc: 93.340% (17981/19264)
Loss: 0.198 | Acc: 93.388% (23967/25664)
Loss: 0.202 | Acc: 93.235% (29895/32064)
Loss: 0.205 | Acc: 93.149% (35829/38464)
Loss: 0.205 | Acc: 93.146% (41789/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7182, Accuracy: 7958/10000 (79.58%)

Epoch: 30
Loss: 0.373 | Acc: 87.500% (56/64)
Loss: 0.190 | Acc: 93.379% (6036/6464)
Loss: 0.186 | Acc: 93.486% (12026/12864)
Loss: 0.190 | Acc: 93.335% (17980/19264)
Loss: 0.191 | Acc: 93.380% (23965/25664)
Loss: 0.192 | Acc: 93.398% (29947/32064)
Loss: 0.193 | Acc: 93.402% (35926/38464)
Loss: 0.192 | Acc: 93.420% (41912/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6850, Accuracy: 8229/10000 (82.29%)

Epoch: 31
Loss: 0.217 | Acc: 95.312% (61/64)
Loss: 0.166 | Acc: 94.725% (6123/6464)
Loss: 0.174 | Acc: 94.193% (12117/12864)
Loss: 0.176 | Acc: 94.061% (18120/19264)
Loss: 0.176 | Acc: 94.050% (24137/25664)
Loss: 0.177 | Acc: 94.006% (30142/32064)
Loss: 0.176 | Acc: 93.992% (36153/38464)
Loss: 0.179 | Acc: 93.933% (42142/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4052, Accuracy: 8772/10000 (87.72%)

Epoch: 32
Loss: 0.156 | Acc: 96.875% (62/64)
Loss: 0.150 | Acc: 95.050% (6144/6464)
Loss: 0.153 | Acc: 94.916% (12210/12864)
Loss: 0.154 | Acc: 94.856% (18273/19264)
Loss: 0.158 | Acc: 94.670% (24296/25664)
Loss: 0.161 | Acc: 94.452% (30285/32064)
Loss: 0.161 | Acc: 94.460% (36333/38464)
Loss: 0.161 | Acc: 94.443% (42371/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5981, Accuracy: 8333/10000 (83.33%)

Epoch: 33
Loss: 0.108 | Acc: 96.875% (62/64)
Loss: 0.139 | Acc: 95.127% (6149/6464)
Loss: 0.138 | Acc: 95.235% (12251/12864)
Loss: 0.140 | Acc: 95.183% (18336/19264)
Loss: 0.141 | Acc: 95.242% (24443/25664)
Loss: 0.144 | Acc: 95.150% (30509/32064)
Loss: 0.145 | Acc: 95.123% (36588/38464)
Loss: 0.144 | Acc: 95.170% (42697/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5208, Accuracy: 8529/10000 (85.29%)

Epoch: 34
Loss: 0.207 | Acc: 92.188% (59/64)
Loss: 0.149 | Acc: 94.740% (6124/6464)
Loss: 0.141 | Acc: 95.118% (12236/12864)
Loss: 0.134 | Acc: 95.401% (18378/19264)
Loss: 0.135 | Acc: 95.379% (24478/25664)
Loss: 0.133 | Acc: 95.447% (30604/32064)
Loss: 0.132 | Acc: 95.487% (36728/38464)
Loss: 0.132 | Acc: 95.493% (42842/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3144, Accuracy: 9024/10000 (90.24%)

Epoch: 35
Loss: 0.084 | Acc: 96.875% (62/64)
Loss: 0.118 | Acc: 95.838% (6195/6464)
Loss: 0.116 | Acc: 95.965% (12345/12864)
Loss: 0.110 | Acc: 96.221% (18536/19264)
Loss: 0.110 | Acc: 96.178% (24683/25664)
Loss: 0.109 | Acc: 96.236% (30857/32064)
Loss: 0.112 | Acc: 96.116% (36970/38464)
Loss: 0.113 | Acc: 96.097% (43113/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2783, Accuracy: 9143/10000 (91.43%)

Epoch: 36
Loss: 0.086 | Acc: 96.875% (62/64)
Loss: 0.091 | Acc: 96.968% (6268/6464)
Loss: 0.096 | Acc: 96.867% (12461/12864)
Loss: 0.095 | Acc: 96.885% (18664/19264)
Loss: 0.095 | Acc: 96.856% (24857/25664)
Loss: 0.096 | Acc: 96.834% (31049/32064)
Loss: 0.095 | Acc: 96.836% (37247/38464)
Loss: 0.098 | Acc: 96.759% (43410/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2600, Accuracy: 9190/10000 (91.90%)

Epoch: 37
Loss: 0.107 | Acc: 93.750% (60/64)
Loss: 0.078 | Acc: 97.386% (6295/6464)
Loss: 0.078 | Acc: 97.481% (12540/12864)
Loss: 0.079 | Acc: 97.353% (18754/19264)
Loss: 0.082 | Acc: 97.288% (24968/25664)
Loss: 0.083 | Acc: 97.215% (31171/32064)
Loss: 0.083 | Acc: 97.208% (37390/38464)
Loss: 0.083 | Acc: 97.218% (43616/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3189, Accuracy: 9086/10000 (90.86%)

Epoch: 38
Loss: 0.063 | Acc: 98.438% (63/64)
Loss: 0.084 | Acc: 97.200% (6283/6464)
Loss: 0.073 | Acc: 97.458% (12537/12864)
Loss: 0.071 | Acc: 97.555% (18793/19264)
Loss: 0.071 | Acc: 97.592% (25046/25664)
Loss: 0.072 | Acc: 97.586% (31290/32064)
Loss: 0.071 | Acc: 97.603% (37542/38464)
Loss: 0.071 | Acc: 97.611% (43792/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3348, Accuracy: 9007/10000 (90.07%)

Epoch: 39
Loss: 0.127 | Acc: 95.312% (61/64)
Loss: 0.057 | Acc: 98.175% (6346/6464)
Loss: 0.055 | Acc: 98.305% (12646/12864)
Loss: 0.055 | Acc: 98.292% (18935/19264)
Loss: 0.056 | Acc: 98.274% (25221/25664)
Loss: 0.055 | Acc: 98.278% (31512/32064)
Loss: 0.055 | Acc: 98.269% (37798/38464)
Loss: 0.055 | Acc: 98.244% (44076/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2277, Accuracy: 9319/10000 (93.19%)

Epoch: 40
Loss: 0.020 | Acc: 100.000% (64/64)
Loss: 0.044 | Acc: 98.530% (6369/6464)
Loss: 0.045 | Acc: 98.500% (12671/12864)
Loss: 0.044 | Acc: 98.531% (18981/19264)
Loss: 0.043 | Acc: 98.597% (25304/25664)
Loss: 0.044 | Acc: 98.587% (31611/32064)
Loss: 0.043 | Acc: 98.601% (37926/38464)
Loss: 0.043 | Acc: 98.580% (44227/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2431, Accuracy: 9313/10000 (93.13%)

Epoch: 41
Loss: 0.082 | Acc: 96.875% (62/64)
Loss: 0.034 | Acc: 99.041% (6402/6464)
Loss: 0.033 | Acc: 99.005% (12736/12864)
Loss: 0.034 | Acc: 98.962% (19064/19264)
Loss: 0.035 | Acc: 98.925% (25388/25664)
Loss: 0.035 | Acc: 98.896% (31710/32064)
Loss: 0.035 | Acc: 98.908% (38044/38464)
Loss: 0.035 | Acc: 98.923% (44381/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2181, Accuracy: 9368/10000 (93.68%)

Epoch: 42
Loss: 0.016 | Acc: 100.000% (64/64)
Loss: 0.025 | Acc: 99.335% (6421/6464)
Loss: 0.023 | Acc: 99.347% (12780/12864)
Loss: 0.024 | Acc: 99.320% (19133/19264)
Loss: 0.023 | Acc: 99.349% (25497/25664)
Loss: 0.024 | Acc: 99.326% (31848/32064)
Loss: 0.024 | Acc: 99.329% (38206/38464)
Loss: 0.023 | Acc: 99.325% (44561/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2195, Accuracy: 9397/10000 (93.97%)

Epoch: 43
Loss: 0.012 | Acc: 100.000% (64/64)
Loss: 0.018 | Acc: 99.459% (6429/6464)
Loss: 0.020 | Acc: 99.409% (12788/12864)
Loss: 0.018 | Acc: 99.471% (19162/19264)
Loss: 0.018 | Acc: 99.470% (25528/25664)
Loss: 0.018 | Acc: 99.467% (31893/32064)
Loss: 0.018 | Acc: 99.451% (38253/38464)
Loss: 0.018 | Acc: 99.465% (44624/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2217, Accuracy: 9385/10000 (93.85%)

Epoch: 44
Loss: 0.023 | Acc: 98.438% (63/64)
Loss: 0.015 | Acc: 99.536% (6434/6464)
Loss: 0.015 | Acc: 99.588% (12811/12864)
Loss: 0.015 | Acc: 99.637% (19194/19264)
Loss: 0.015 | Acc: 99.622% (25567/25664)
Loss: 0.015 | Acc: 99.632% (31946/32064)
Loss: 0.015 | Acc: 99.620% (38318/38464)
Loss: 0.015 | Acc: 99.630% (44698/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2130, Accuracy: 9442/10000 (94.42%)

Epoch: 45
Loss: 0.041 | Acc: 98.438% (63/64)
Loss: 0.011 | Acc: 99.737% (6447/6464)
Loss: 0.011 | Acc: 99.767% (12834/12864)
Loss: 0.011 | Acc: 99.725% (19211/19264)
Loss: 0.011 | Acc: 99.747% (25599/25664)
Loss: 0.012 | Acc: 99.722% (31975/32064)
Loss: 0.012 | Acc: 99.719% (38356/38464)
Loss: 0.012 | Acc: 99.726% (44741/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2136, Accuracy: 9428/10000 (94.28%)

Epoch: 46
Loss: 0.021 | Acc: 98.438% (63/64)
Loss: 0.013 | Acc: 99.737% (6447/6464)
Loss: 0.012 | Acc: 99.736% (12830/12864)
Loss: 0.012 | Acc: 99.730% (19212/19264)
Loss: 0.012 | Acc: 99.731% (25595/25664)
Loss: 0.011 | Acc: 99.750% (31984/32064)
Loss: 0.011 | Acc: 99.758% (38371/38464)
Loss: 0.011 | Acc: 99.762% (44757/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2107, Accuracy: 9419/10000 (94.19%)

Epoch: 47
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.752% (6448/6464)
Loss: 0.010 | Acc: 99.829% (12842/12864)
Loss: 0.010 | Acc: 99.813% (19228/19264)
Loss: 0.010 | Acc: 99.805% (25614/25664)
Loss: 0.010 | Acc: 99.804% (32001/32064)
Loss: 0.010 | Acc: 99.810% (38391/38464)
Loss: 0.010 | Acc: 99.811% (44779/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2157, Accuracy: 9411/10000 (94.11%)
torch.Size([100, 10])
Test set: Average loss: 0.2157, Accuracy: 9411/10000 (94.11%)

Epoch: 48
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.768% (6449/6464)
Loss: 0.010 | Acc: 99.775% (12835/12864)
Loss: 0.010 | Acc: 99.803% (19226/19264)
Loss: 0.010 | Acc: 99.797% (25612/25664)
Loss: 0.010 | Acc: 99.794% (31998/32064)
Loss: 0.010 | Acc: 99.800% (38387/38464)
Loss: 0.010 | Acc: 99.784% (44767/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2070, Accuracy: 9432/10000 (94.32%)
torch.Size([100, 10])
Test set: Average loss: 0.2070, Accuracy: 9432/10000 (94.32%)

Epoch: 49
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.768% (6449/6464)
Loss: 0.011 | Acc: 99.720% (12828/12864)
Loss: 0.011 | Acc: 99.730% (19212/19264)
Loss: 0.011 | Acc: 99.743% (25598/25664)
Loss: 0.011 | Acc: 99.744% (31982/32064)
Loss: 0.010 | Acc: 99.763% (38373/38464)
Loss: 0.011 | Acc: 99.759% (44756/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2094, Accuracy: 9419/10000 (94.19%)
torch.Size([100, 10])
Test set: Average loss: 0.2094, Accuracy: 9419/10000 (94.19%)

Epoch: 50
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 1.876 | Acc: 30.863% (1995/6464)
Loss: 1.760 | Acc: 34.577% (4448/12864)
Loss: 1.614 | Acc: 40.184% (7741/19264)
Loss: 1.433 | Acc: 47.487% (12187/25664)
Loss: 1.287 | Acc: 53.159% (17045/32064)
Loss: 1.178 | Acc: 57.386% (22073/38464)
Loss: 1.091 | Acc: 60.728% (27245/44864)
torch.Size([100, 10])
Test set: Average loss: 4.1593, Accuracy: 3417/10000 (34.17%)

Epoch: 51
Loss: 1.219 | Acc: 64.062% (41/64)
Loss: 0.539 | Acc: 81.714% (5282/6464)
Loss: 0.518 | Acc: 82.548% (10619/12864)
Loss: 0.508 | Acc: 82.838% (15958/19264)
Loss: 0.499 | Acc: 83.058% (21316/25664)
Loss: 0.492 | Acc: 83.321% (26716/32064)
Loss: 0.484 | Acc: 83.499% (32117/38464)
Loss: 0.478 | Acc: 83.729% (37564/44864)
torch.Size([100, 10])
Test set: Average loss: 2.7653, Accuracy: 4659/10000 (46.59%)

Epoch: 52
Loss: 0.717 | Acc: 75.000% (48/64)
Loss: 0.426 | Acc: 85.458% (5524/6464)
Loss: 0.420 | Acc: 85.704% (11025/12864)
Loss: 0.413 | Acc: 85.891% (16546/19264)
Loss: 0.415 | Acc: 85.910% (22048/25664)
Loss: 0.415 | Acc: 85.888% (27539/32064)
Loss: 0.413 | Acc: 85.956% (33062/38464)
Loss: 0.411 | Acc: 86.078% (38618/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4969, Accuracy: 8393/10000 (83.93%)

Epoch: 53
Loss: 0.402 | Acc: 84.375% (54/64)
Loss: 0.366 | Acc: 87.686% (5668/6464)
Loss: 0.372 | Acc: 87.531% (11260/12864)
Loss: 0.378 | Acc: 87.209% (16800/19264)
Loss: 0.380 | Acc: 87.040% (22338/25664)
Loss: 0.382 | Acc: 87.007% (27898/32064)
Loss: 0.384 | Acc: 87.009% (33467/38464)
Loss: 0.385 | Acc: 86.958% (39013/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0207, Accuracy: 7072/10000 (70.72%)

Epoch: 54
Loss: 0.574 | Acc: 78.125% (50/64)
Loss: 0.376 | Acc: 87.067% (5628/6464)
Loss: 0.361 | Acc: 87.632% (11273/12864)
Loss: 0.363 | Acc: 87.630% (16881/19264)
Loss: 0.371 | Acc: 87.235% (22388/25664)
Loss: 0.376 | Acc: 87.116% (27933/32064)
Loss: 0.379 | Acc: 87.006% (33466/38464)
Loss: 0.379 | Acc: 87.023% (39042/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8361, Accuracy: 7480/10000 (74.80%)

Epoch: 55
Loss: 0.477 | Acc: 84.375% (54/64)
Loss: 0.373 | Acc: 87.160% (5634/6464)
Loss: 0.366 | Acc: 87.570% (11265/12864)
Loss: 0.365 | Acc: 87.578% (16871/19264)
Loss: 0.366 | Acc: 87.527% (22463/25664)
Loss: 0.366 | Acc: 87.516% (28061/32064)
Loss: 0.368 | Acc: 87.523% (33665/38464)
Loss: 0.369 | Acc: 87.571% (39288/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5027, Accuracy: 8369/10000 (83.69%)

Epoch: 56
Loss: 0.282 | Acc: 92.188% (59/64)
Loss: 0.351 | Acc: 88.397% (5714/6464)
Loss: 0.358 | Acc: 87.912% (11309/12864)
Loss: 0.359 | Acc: 87.889% (16931/19264)
Loss: 0.355 | Acc: 87.944% (22570/25664)
Loss: 0.357 | Acc: 87.962% (28204/32064)
Loss: 0.357 | Acc: 87.952% (33830/38464)
Loss: 0.361 | Acc: 87.792% (39387/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5774, Accuracy: 8160/10000 (81.60%)

Epoch: 57
Loss: 0.397 | Acc: 89.062% (57/64)
Loss: 0.346 | Acc: 88.506% (5721/6464)
Loss: 0.347 | Acc: 88.472% (11381/12864)
Loss: 0.348 | Acc: 88.445% (17038/19264)
Loss: 0.350 | Acc: 88.334% (22670/25664)
Loss: 0.354 | Acc: 88.108% (28251/32064)
Loss: 0.354 | Acc: 88.098% (33886/38464)
Loss: 0.354 | Acc: 88.071% (39512/44864)
torch.Size([100, 10])
Test set: Average loss: 3.7487, Accuracy: 3885/10000 (38.85%)

Epoch: 58
Loss: 0.542 | Acc: 82.812% (53/64)
Loss: 0.360 | Acc: 88.026% (5690/6464)
Loss: 0.354 | Acc: 88.207% (11347/12864)
Loss: 0.350 | Acc: 88.216% (16994/19264)
Loss: 0.351 | Acc: 88.213% (22639/25664)
Loss: 0.348 | Acc: 88.283% (28307/32064)
Loss: 0.352 | Acc: 88.082% (33880/38464)
Loss: 0.350 | Acc: 88.178% (39560/44864)
torch.Size([100, 10])
Test set: Average loss: 3.0006, Accuracy: 4897/10000 (48.97%)

Epoch: 59
Loss: 0.518 | Acc: 84.375% (54/64)
Loss: 0.339 | Acc: 88.583% (5726/6464)
Loss: 0.341 | Acc: 88.394% (11371/12864)
Loss: 0.344 | Acc: 88.185% (16988/19264)
Loss: 0.343 | Acc: 88.236% (22645/25664)
Loss: 0.346 | Acc: 88.152% (28265/32064)
Loss: 0.347 | Acc: 88.075% (33877/38464)
Loss: 0.345 | Acc: 88.149% (39547/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1131, Accuracy: 7150/10000 (71.50%)

Epoch: 60
Loss: 0.293 | Acc: 90.625% (58/64)
Loss: 0.340 | Acc: 88.660% (5731/6464)
Loss: 0.339 | Acc: 88.573% (11394/12864)
Loss: 0.339 | Acc: 88.559% (17060/19264)
Loss: 0.338 | Acc: 88.525% (22719/25664)
Loss: 0.338 | Acc: 88.510% (28380/32064)
Loss: 0.337 | Acc: 88.485% (34035/38464)
Loss: 0.337 | Acc: 88.503% (39706/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4987, Accuracy: 6583/10000 (65.83%)

Epoch: 61
Loss: 0.278 | Acc: 89.062% (57/64)
Loss: 0.322 | Acc: 88.861% (5744/6464)
Loss: 0.325 | Acc: 88.806% (11424/12864)
Loss: 0.328 | Acc: 88.663% (17080/19264)
Loss: 0.332 | Acc: 88.494% (22711/25664)
Loss: 0.334 | Acc: 88.457% (28363/32064)
Loss: 0.333 | Acc: 88.535% (34054/38464)
Loss: 0.331 | Acc: 88.577% (39739/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5238, Accuracy: 6375/10000 (63.75%)

Epoch: 62
Loss: 0.593 | Acc: 87.500% (56/64)
Loss: 0.331 | Acc: 88.645% (5730/6464)
Loss: 0.321 | Acc: 88.899% (11436/12864)
Loss: 0.319 | Acc: 89.099% (17164/19264)
Loss: 0.321 | Acc: 89.098% (22866/25664)
Loss: 0.325 | Acc: 89.016% (28542/32064)
Loss: 0.325 | Acc: 89.086% (34266/38464)
Loss: 0.328 | Acc: 89.029% (39942/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4260, Accuracy: 6912/10000 (69.12%)

Epoch: 63
Loss: 0.434 | Acc: 85.938% (55/64)
Loss: 0.308 | Acc: 89.480% (5784/6464)
Loss: 0.312 | Acc: 89.280% (11485/12864)
Loss: 0.314 | Acc: 89.229% (17189/19264)
Loss: 0.317 | Acc: 89.059% (22856/25664)
Loss: 0.316 | Acc: 89.181% (28595/32064)
Loss: 0.320 | Acc: 88.904% (34196/38464)
Loss: 0.319 | Acc: 88.971% (39916/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5011, Accuracy: 8324/10000 (83.24%)

Epoch: 64
Loss: 0.310 | Acc: 85.938% (55/64)
Loss: 0.298 | Acc: 89.821% (5806/6464)
Loss: 0.295 | Acc: 90.135% (11595/12864)
Loss: 0.304 | Acc: 89.768% (17293/19264)
Loss: 0.306 | Acc: 89.627% (23002/25664)
Loss: 0.306 | Acc: 89.555% (28715/32064)
Loss: 0.308 | Acc: 89.502% (34426/38464)
Loss: 0.311 | Acc: 89.334% (40079/44864)
torch.Size([100, 10])
Test set: Average loss: 3.6593, Accuracy: 3792/10000 (37.92%)

Epoch: 65
Loss: 0.637 | Acc: 70.312% (45/64)
Loss: 0.343 | Acc: 88.506% (5721/6464)
Loss: 0.317 | Acc: 89.350% (11494/12864)
Loss: 0.309 | Acc: 89.457% (17233/19264)
Loss: 0.306 | Acc: 89.600% (22995/25664)
Loss: 0.303 | Acc: 89.696% (28760/32064)
Loss: 0.307 | Acc: 89.575% (34454/38464)
Loss: 0.308 | Acc: 89.533% (40168/44864)
torch.Size([100, 10])
Test set: Average loss: 3.4144, Accuracy: 4191/10000 (41.91%)

Epoch: 66
Loss: 0.604 | Acc: 84.375% (54/64)
Loss: 0.292 | Acc: 90.068% (5822/6464)
Loss: 0.291 | Acc: 90.229% (11607/12864)
Loss: 0.295 | Acc: 90.070% (17351/19264)
Loss: 0.299 | Acc: 89.908% (23074/25664)
Loss: 0.295 | Acc: 90.001% (28858/32064)
Loss: 0.297 | Acc: 89.894% (34577/38464)
Loss: 0.298 | Acc: 89.838% (40305/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4783, Accuracy: 5444/10000 (54.44%)

Epoch: 67
Loss: 0.393 | Acc: 87.500% (56/64)
Loss: 0.288 | Acc: 90.254% (5834/6464)
Loss: 0.293 | Acc: 90.120% (11593/12864)
Loss: 0.289 | Acc: 90.096% (17356/19264)
Loss: 0.287 | Acc: 90.231% (23157/25664)
Loss: 0.289 | Acc: 90.101% (28890/32064)
Loss: 0.294 | Acc: 89.957% (34601/38464)
Loss: 0.293 | Acc: 90.028% (40390/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7324, Accuracy: 7722/10000 (77.22%)

Epoch: 68
Loss: 0.325 | Acc: 87.500% (56/64)
Loss: 0.283 | Acc: 90.176% (5829/6464)
Loss: 0.280 | Acc: 90.260% (11611/12864)
Loss: 0.288 | Acc: 90.028% (17343/19264)
Loss: 0.285 | Acc: 90.126% (23130/25664)
Loss: 0.284 | Acc: 90.151% (28906/32064)
Loss: 0.283 | Acc: 90.199% (34694/38464)
Loss: 0.285 | Acc: 90.159% (40449/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4547, Accuracy: 8485/10000 (84.85%)

Epoch: 69
Loss: 0.218 | Acc: 95.312% (61/64)
Loss: 0.269 | Acc: 90.470% (5848/6464)
Loss: 0.268 | Acc: 90.742% (11673/12864)
Loss: 0.273 | Acc: 90.718% (17476/19264)
Loss: 0.274 | Acc: 90.726% (23284/25664)
Loss: 0.274 | Acc: 90.740% (29095/32064)
Loss: 0.273 | Acc: 90.729% (34898/38464)
Loss: 0.271 | Acc: 90.857% (40762/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9390, Accuracy: 7451/10000 (74.51%)

Epoch: 70
Loss: 0.235 | Acc: 93.750% (60/64)
Loss: 0.249 | Acc: 91.337% (5904/6464)
Loss: 0.258 | Acc: 90.983% (11704/12864)
Loss: 0.263 | Acc: 90.822% (17496/19264)
Loss: 0.259 | Acc: 90.952% (23342/25664)
Loss: 0.260 | Acc: 90.937% (29158/32064)
Loss: 0.266 | Acc: 90.760% (34910/38464)
Loss: 0.267 | Acc: 90.752% (40715/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5613, Accuracy: 8137/10000 (81.37%)

Epoch: 71
Loss: 0.403 | Acc: 85.938% (55/64)
Loss: 0.239 | Acc: 92.002% (5947/6464)
Loss: 0.256 | Acc: 91.325% (11748/12864)
Loss: 0.253 | Acc: 91.357% (17599/19264)
Loss: 0.252 | Acc: 91.447% (23469/25664)
Loss: 0.254 | Acc: 91.458% (29325/32064)
Loss: 0.257 | Acc: 91.298% (35117/38464)
Loss: 0.257 | Acc: 91.280% (40952/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7658, Accuracy: 7776/10000 (77.76%)

Epoch: 72
Loss: 0.453 | Acc: 84.375% (54/64)
Loss: 0.251 | Acc: 91.197% (5895/6464)
Loss: 0.246 | Acc: 91.472% (11767/12864)
Loss: 0.249 | Acc: 91.414% (17610/19264)
Loss: 0.248 | Acc: 91.510% (23485/25664)
Loss: 0.244 | Acc: 91.688% (29399/32064)
Loss: 0.243 | Acc: 91.709% (35275/38464)
Loss: 0.244 | Acc: 91.682% (41132/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4113, Accuracy: 8691/10000 (86.91%)

Epoch: 73
Loss: 0.182 | Acc: 93.750% (60/64)
Loss: 0.225 | Acc: 92.234% (5962/6464)
Loss: 0.236 | Acc: 92.001% (11835/12864)
Loss: 0.231 | Acc: 92.172% (17756/19264)
Loss: 0.234 | Acc: 91.985% (23607/25664)
Loss: 0.235 | Acc: 91.910% (29470/32064)
Loss: 0.236 | Acc: 91.920% (35356/38464)
Loss: 0.238 | Acc: 91.849% (41207/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4394, Accuracy: 8630/10000 (86.30%)

Epoch: 74
Loss: 0.241 | Acc: 90.625% (58/64)
Loss: 0.211 | Acc: 92.868% (6003/6464)
Loss: 0.211 | Acc: 92.786% (11936/12864)
Loss: 0.215 | Acc: 92.691% (17856/19264)
Loss: 0.219 | Acc: 92.577% (23759/25664)
Loss: 0.220 | Acc: 92.565% (29680/32064)
Loss: 0.225 | Acc: 92.385% (35535/38464)
Loss: 0.225 | Acc: 92.355% (41434/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0390, Accuracy: 7310/10000 (73.10%)

Epoch: 75
Loss: 0.381 | Acc: 89.062% (57/64)
Loss: 0.223 | Acc: 92.358% (5970/6464)
Loss: 0.216 | Acc: 92.600% (11912/12864)
Loss: 0.216 | Acc: 92.603% (17839/19264)
Loss: 0.221 | Acc: 92.491% (23737/25664)
Loss: 0.218 | Acc: 92.599% (29691/32064)
Loss: 0.221 | Acc: 92.460% (35564/38464)
Loss: 0.222 | Acc: 92.415% (41461/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3848, Accuracy: 8721/10000 (87.21%)

Epoch: 76
Loss: 0.203 | Acc: 90.625% (58/64)
Loss: 0.182 | Acc: 93.642% (6053/6464)
Loss: 0.190 | Acc: 93.532% (12032/12864)
Loss: 0.193 | Acc: 93.464% (18005/19264)
Loss: 0.195 | Acc: 93.360% (23960/25664)
Loss: 0.200 | Acc: 93.154% (29869/32064)
Loss: 0.206 | Acc: 92.954% (35754/38464)
Loss: 0.205 | Acc: 93.010% (41728/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4762, Accuracy: 8548/10000 (85.48%)

Epoch: 77
Loss: 0.149 | Acc: 96.875% (62/64)
Loss: 0.191 | Acc: 93.224% (6026/6464)
Loss: 0.189 | Acc: 93.276% (11999/12864)
Loss: 0.188 | Acc: 93.314% (17976/19264)
Loss: 0.192 | Acc: 93.232% (23927/25664)
Loss: 0.191 | Acc: 93.357% (29934/32064)
Loss: 0.194 | Acc: 93.266% (35874/38464)
Loss: 0.194 | Acc: 93.266% (41843/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3398, Accuracy: 8913/10000 (89.13%)

Epoch: 78
Loss: 0.181 | Acc: 95.312% (61/64)
Loss: 0.156 | Acc: 94.771% (6126/6464)
Loss: 0.168 | Acc: 94.224% (12121/12864)
Loss: 0.173 | Acc: 94.113% (18130/19264)
Loss: 0.177 | Acc: 93.949% (24111/25664)
Loss: 0.183 | Acc: 93.719% (30050/32064)
Loss: 0.183 | Acc: 93.732% (36053/38464)
Loss: 0.183 | Acc: 93.725% (42049/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3197, Accuracy: 8941/10000 (89.41%)

Epoch: 79
Loss: 0.074 | Acc: 98.438% (63/64)
Loss: 0.155 | Acc: 94.817% (6129/6464)
Loss: 0.161 | Acc: 94.706% (12183/12864)
Loss: 0.160 | Acc: 94.679% (18239/19264)
Loss: 0.162 | Acc: 94.537% (24262/25664)
Loss: 0.164 | Acc: 94.492% (30298/32064)
Loss: 0.162 | Acc: 94.520% (36356/38464)
Loss: 0.164 | Acc: 94.428% (42364/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4131, Accuracy: 6395/10000 (63.95%)

Epoch: 80
Loss: 0.496 | Acc: 85.938% (55/64)
Loss: 0.172 | Acc: 93.920% (6071/6464)
Loss: 0.166 | Acc: 94.317% (12133/12864)
Loss: 0.164 | Acc: 94.378% (18181/19264)
Loss: 0.161 | Acc: 94.537% (24262/25664)
Loss: 0.163 | Acc: 94.408% (30271/32064)
Loss: 0.161 | Acc: 94.478% (36340/38464)
Loss: 0.161 | Acc: 94.521% (42406/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5578, Accuracy: 8344/10000 (83.44%)

Epoch: 81
Loss: 0.121 | Acc: 95.312% (61/64)
Loss: 0.144 | Acc: 95.297% (6160/6464)
Loss: 0.145 | Acc: 95.134% (12238/12864)
Loss: 0.145 | Acc: 95.048% (18310/19264)
Loss: 0.147 | Acc: 94.989% (24378/25664)
Loss: 0.147 | Acc: 95.022% (30468/32064)
Loss: 0.150 | Acc: 94.941% (36518/38464)
Loss: 0.152 | Acc: 94.862% (42559/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2816, Accuracy: 5832/10000 (58.32%)

Epoch: 82
Loss: 0.167 | Acc: 93.750% (60/64)
Loss: 0.143 | Acc: 95.158% (6151/6464)
Loss: 0.141 | Acc: 95.258% (12254/12864)
Loss: 0.139 | Acc: 95.323% (18363/19264)
Loss: 0.136 | Acc: 95.476% (24503/25664)
Loss: 0.134 | Acc: 95.462% (30609/32064)
Loss: 0.134 | Acc: 95.466% (36720/38464)
Loss: 0.133 | Acc: 95.477% (42835/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5199, Accuracy: 8526/10000 (85.26%)

Epoch: 83
Loss: 0.174 | Acc: 92.188% (59/64)
Loss: 0.126 | Acc: 95.715% (6187/6464)
Loss: 0.121 | Acc: 95.973% (12346/12864)
Loss: 0.119 | Acc: 95.987% (18491/19264)
Loss: 0.117 | Acc: 95.963% (24628/25664)
Loss: 0.120 | Acc: 95.874% (30741/32064)
Loss: 0.118 | Acc: 95.947% (36905/38464)
Loss: 0.119 | Acc: 95.892% (43021/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2954, Accuracy: 9065/10000 (90.65%)

Epoch: 84
Loss: 0.106 | Acc: 96.875% (62/64)
Loss: 0.098 | Acc: 96.720% (6252/6464)
Loss: 0.100 | Acc: 96.758% (12447/12864)
Loss: 0.108 | Acc: 96.501% (18590/19264)
Loss: 0.104 | Acc: 96.614% (24795/25664)
Loss: 0.105 | Acc: 96.588% (30970/32064)
Loss: 0.103 | Acc: 96.586% (37151/38464)
Loss: 0.103 | Acc: 96.574% (43327/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3360, Accuracy: 9004/10000 (90.04%)

Epoch: 85
Loss: 0.019 | Acc: 100.000% (64/64)
Loss: 0.088 | Acc: 97.061% (6274/6464)
Loss: 0.088 | Acc: 96.999% (12478/12864)
Loss: 0.092 | Acc: 96.870% (18661/19264)
Loss: 0.094 | Acc: 96.832% (24851/25664)
Loss: 0.092 | Acc: 96.831% (31048/32064)
Loss: 0.094 | Acc: 96.766% (37220/38464)
Loss: 0.094 | Acc: 96.777% (43418/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2811, Accuracy: 9153/10000 (91.53%)

Epoch: 86
Loss: 0.052 | Acc: 98.438% (63/64)
Loss: 0.080 | Acc: 97.463% (6300/6464)
Loss: 0.075 | Acc: 97.590% (12554/12864)
Loss: 0.074 | Acc: 97.612% (18804/19264)
Loss: 0.077 | Acc: 97.467% (25014/25664)
Loss: 0.075 | Acc: 97.530% (31272/32064)
Loss: 0.075 | Acc: 97.525% (37512/38464)
Loss: 0.075 | Acc: 97.548% (43764/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2314, Accuracy: 9301/10000 (93.01%)

Epoch: 87
Loss: 0.072 | Acc: 98.438% (63/64)
Loss: 0.061 | Acc: 97.958% (6332/6464)
Loss: 0.063 | Acc: 97.870% (12590/12864)
Loss: 0.065 | Acc: 97.809% (18842/19264)
Loss: 0.063 | Acc: 97.849% (25112/25664)
Loss: 0.064 | Acc: 97.842% (31372/32064)
Loss: 0.064 | Acc: 97.866% (37643/38464)
Loss: 0.063 | Acc: 97.905% (43924/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2430, Accuracy: 9316/10000 (93.16%)

Epoch: 88
Loss: 0.061 | Acc: 98.438% (63/64)
Loss: 0.053 | Acc: 98.298% (6354/6464)
Loss: 0.050 | Acc: 98.344% (12651/12864)
Loss: 0.051 | Acc: 98.297% (18936/19264)
Loss: 0.050 | Acc: 98.336% (25237/25664)
Loss: 0.049 | Acc: 98.381% (31545/32064)
Loss: 0.049 | Acc: 98.380% (37841/38464)
Loss: 0.050 | Acc: 98.371% (44133/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2307, Accuracy: 9296/10000 (92.96%)

Epoch: 89
Loss: 0.056 | Acc: 96.875% (62/64)
Loss: 0.052 | Acc: 98.360% (6358/6464)
Loss: 0.048 | Acc: 98.500% (12671/12864)
Loss: 0.045 | Acc: 98.572% (18989/19264)
Loss: 0.044 | Acc: 98.597% (25304/25664)
Loss: 0.043 | Acc: 98.622% (31622/32064)
Loss: 0.042 | Acc: 98.656% (37947/38464)
Loss: 0.041 | Acc: 98.663% (44264/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2296, Accuracy: 9360/10000 (93.60%)

Epoch: 90
Loss: 0.019 | Acc: 100.000% (64/64)
Loss: 0.022 | Acc: 99.397% (6425/6464)
Loss: 0.024 | Acc: 99.285% (12772/12864)
Loss: 0.024 | Acc: 99.278% (19125/19264)
Loss: 0.026 | Acc: 99.232% (25467/25664)
Loss: 0.026 | Acc: 99.198% (31807/32064)
Loss: 0.027 | Acc: 99.189% (38152/38464)
Loss: 0.027 | Acc: 99.175% (44494/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2048, Accuracy: 9408/10000 (94.08%)

Epoch: 91
Loss: 0.020 | Acc: 100.000% (64/64)
Loss: 0.025 | Acc: 99.211% (6413/6464)
Loss: 0.025 | Acc: 99.207% (12762/12864)
Loss: 0.024 | Acc: 99.211% (19112/19264)
Loss: 0.024 | Acc: 99.228% (25466/25664)
Loss: 0.023 | Acc: 99.261% (31827/32064)
Loss: 0.023 | Acc: 99.241% (38172/38464)
Loss: 0.023 | Acc: 99.247% (44526/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2019, Accuracy: 9438/10000 (94.38%)

Epoch: 92
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.015 | Acc: 99.644% (6441/6464)
Loss: 0.015 | Acc: 99.642% (12818/12864)
Loss: 0.015 | Acc: 99.626% (19192/19264)
Loss: 0.015 | Acc: 99.622% (25567/25664)
Loss: 0.015 | Acc: 99.623% (31943/32064)
Loss: 0.015 | Acc: 99.602% (38311/38464)
Loss: 0.015 | Acc: 99.601% (44685/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2075, Accuracy: 9449/10000 (94.49%)

Epoch: 93
Loss: 0.021 | Acc: 98.438% (63/64)
Loss: 0.013 | Acc: 99.660% (6442/6464)
Loss: 0.013 | Acc: 99.697% (12825/12864)
Loss: 0.013 | Acc: 99.678% (19202/19264)
Loss: 0.014 | Acc: 99.642% (25572/25664)
Loss: 0.014 | Acc: 99.632% (31946/32064)
Loss: 0.014 | Acc: 99.628% (38321/38464)
Loss: 0.013 | Acc: 99.655% (44709/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2072, Accuracy: 9462/10000 (94.62%)

Epoch: 94
Loss: 0.011 | Acc: 100.000% (64/64)
Loss: 0.015 | Acc: 99.675% (6443/6464)
Loss: 0.013 | Acc: 99.697% (12825/12864)
Loss: 0.012 | Acc: 99.704% (19207/19264)
Loss: 0.012 | Acc: 99.719% (25592/25664)
Loss: 0.011 | Acc: 99.716% (31973/32064)
Loss: 0.011 | Acc: 99.732% (38361/38464)
Loss: 0.011 | Acc: 99.744% (44749/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1951, Accuracy: 9479/10000 (94.79%)

Epoch: 95
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.845% (6454/6464)
Loss: 0.007 | Acc: 99.852% (12845/12864)
Loss: 0.007 | Acc: 99.855% (19236/19264)
Loss: 0.008 | Acc: 99.817% (25617/25664)
Loss: 0.008 | Acc: 99.804% (32001/32064)
Loss: 0.008 | Acc: 99.808% (38390/38464)
Loss: 0.008 | Acc: 99.806% (44777/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1957, Accuracy: 9472/10000 (94.72%)

Epoch: 96
Loss: 0.008 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.752% (6448/6464)
Loss: 0.010 | Acc: 99.806% (12839/12864)
Loss: 0.009 | Acc: 99.818% (19229/19264)
Loss: 0.009 | Acc: 99.817% (25617/25664)
Loss: 0.009 | Acc: 99.819% (32006/32064)
Loss: 0.008 | Acc: 99.828% (38398/38464)
Loss: 0.009 | Acc: 99.824% (44785/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1930, Accuracy: 9489/10000 (94.89%)

Epoch: 97
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.799% (6451/6464)
Loss: 0.008 | Acc: 99.829% (12842/12864)
Loss: 0.008 | Acc: 99.839% (19233/19264)
Loss: 0.009 | Acc: 99.829% (25620/25664)
Loss: 0.008 | Acc: 99.841% (32013/32064)
Loss: 0.008 | Acc: 99.849% (38406/38464)
Loss: 0.008 | Acc: 99.835% (44790/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1939, Accuracy: 9484/10000 (94.84%)
torch.Size([100, 10])
Test set: Average loss: 0.1939, Accuracy: 9484/10000 (94.84%)

Epoch: 98
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.830% (6453/6464)
Loss: 0.008 | Acc: 99.813% (12840/12864)
Loss: 0.008 | Acc: 99.824% (19230/19264)
Loss: 0.007 | Acc: 99.848% (25625/25664)
Loss: 0.008 | Acc: 99.857% (32018/32064)
Loss: 0.008 | Acc: 99.854% (38408/38464)
Loss: 0.008 | Acc: 99.855% (44799/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1932, Accuracy: 9497/10000 (94.97%)
torch.Size([100, 10])
Test set: Average loss: 0.1932, Accuracy: 9497/10000 (94.97%)

Epoch: 99
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.799% (6451/6464)
Loss: 0.008 | Acc: 99.813% (12840/12864)
Loss: 0.008 | Acc: 99.813% (19228/19264)
Loss: 0.008 | Acc: 99.825% (25619/25664)
Loss: 0.008 | Acc: 99.847% (32015/32064)
Loss: 0.008 | Acc: 99.841% (38403/38464)
Loss: 0.008 | Acc: 99.842% (44793/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1916, Accuracy: 9492/10000 (94.92%)
torch.Size([100, 10])
Test set: Average loss: 0.1916, Accuracy: 9492/10000 (94.92%)

Epoch: 100
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 2.005 | Acc: 27.645% (1787/6464)
Loss: 1.926 | Acc: 29.299% (3769/12864)
Loss: 1.846 | Acc: 31.811% (6128/19264)
Loss: 1.775 | Acc: 34.379% (8823/25664)
Loss: 1.713 | Acc: 36.730% (11777/32064)
Loss: 1.649 | Acc: 39.060% (15024/38464)
Loss: 1.585 | Acc: 41.579% (18654/44864)
torch.Size([100, 10])
Test set: Average loss: 3.0613, Accuracy: 3144/10000 (31.44%)

Epoch: 101
Loss: 1.236 | Acc: 46.875% (30/64)
Loss: 0.957 | Acc: 66.182% (4278/6464)
Loss: 0.926 | Acc: 67.825% (8725/12864)
Loss: 0.886 | Acc: 69.098% (13311/19264)
Loss: 0.851 | Acc: 70.309% (18044/25664)
Loss: 0.821 | Acc: 71.385% (22889/32064)
Loss: 0.797 | Acc: 72.268% (27797/38464)
Loss: 0.777 | Acc: 72.967% (32736/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2544, Accuracy: 6198/10000 (61.98%)

Epoch: 102
Loss: 0.600 | Acc: 75.000% (48/64)
Loss: 0.597 | Acc: 79.455% (5136/6464)
Loss: 0.587 | Acc: 79.936% (10283/12864)
Loss: 0.577 | Acc: 80.274% (15464/19264)
Loss: 0.572 | Acc: 80.533% (20668/25664)
Loss: 0.567 | Acc: 80.707% (25878/32064)
Loss: 0.556 | Acc: 81.026% (31166/38464)
Loss: 0.552 | Acc: 81.159% (36411/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4832, Accuracy: 4706/10000 (47.06%)

Epoch: 103
Loss: 0.672 | Acc: 78.125% (50/64)
Loss: 0.509 | Acc: 82.534% (5335/6464)
Loss: 0.490 | Acc: 83.326% (10719/12864)
Loss: 0.490 | Acc: 83.238% (16035/19264)
Loss: 0.485 | Acc: 83.479% (21424/25664)
Loss: 0.479 | Acc: 83.708% (26840/32064)
Loss: 0.476 | Acc: 83.845% (32250/38464)
Loss: 0.474 | Acc: 83.887% (37635/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5804, Accuracy: 5199/10000 (51.99%)

Epoch: 104
Loss: 0.902 | Acc: 76.562% (49/64)
Loss: 0.454 | Acc: 84.189% (5442/6464)
Loss: 0.447 | Acc: 84.507% (10871/12864)
Loss: 0.440 | Acc: 85.003% (16375/19264)
Loss: 0.437 | Acc: 85.143% (21851/25664)
Loss: 0.436 | Acc: 85.217% (27324/32064)
Loss: 0.436 | Acc: 85.186% (32766/38464)
Loss: 0.436 | Acc: 85.206% (38227/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5419, Accuracy: 8141/10000 (81.41%)

Epoch: 105
Loss: 0.570 | Acc: 79.688% (51/64)
Loss: 0.407 | Acc: 86.046% (5562/6464)
Loss: 0.407 | Acc: 86.070% (11072/12864)
Loss: 0.409 | Acc: 86.021% (16571/19264)
Loss: 0.411 | Acc: 85.871% (22038/25664)
Loss: 0.408 | Acc: 85.981% (27569/32064)
Loss: 0.409 | Acc: 85.896% (33039/38464)
Loss: 0.409 | Acc: 85.926% (38550/44864)
torch.Size([100, 10])
Test set: Average loss: 3.3833, Accuracy: 3732/10000 (37.32%)

Epoch: 106
Loss: 0.763 | Acc: 75.000% (48/64)
Loss: 0.408 | Acc: 86.015% (5560/6464)
Loss: 0.390 | Acc: 86.870% (11175/12864)
Loss: 0.386 | Acc: 86.856% (16732/19264)
Loss: 0.388 | Acc: 86.853% (22290/25664)
Loss: 0.389 | Acc: 86.755% (27817/32064)
Loss: 0.391 | Acc: 86.723% (33357/38464)
Loss: 0.391 | Acc: 86.718% (38905/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4660, Accuracy: 5864/10000 (58.64%)

Epoch: 107
Loss: 0.929 | Acc: 71.875% (46/64)
Loss: 0.367 | Acc: 87.732% (5671/6464)
Loss: 0.379 | Acc: 86.995% (11191/12864)
Loss: 0.380 | Acc: 87.080% (16775/19264)
Loss: 0.383 | Acc: 86.931% (22310/25664)
Loss: 0.383 | Acc: 86.945% (27878/32064)
Loss: 0.383 | Acc: 86.920% (33433/38464)
Loss: 0.379 | Acc: 87.050% (39054/44864)
torch.Size([100, 10])
Test set: Average loss: 2.8764, Accuracy: 3783/10000 (37.83%)

Epoch: 108
Loss: 0.566 | Acc: 81.250% (52/64)
Loss: 0.361 | Acc: 88.212% (5702/6464)
Loss: 0.368 | Acc: 87.795% (11294/12864)
Loss: 0.365 | Acc: 87.780% (16910/19264)
Loss: 0.367 | Acc: 87.629% (22489/25664)
Loss: 0.364 | Acc: 87.659% (28107/32064)
Loss: 0.367 | Acc: 87.513% (33661/38464)
Loss: 0.370 | Acc: 87.389% (39206/44864)
torch.Size([100, 10])
Test set: Average loss: 3.4104, Accuracy: 4783/10000 (47.83%)

Epoch: 109
Loss: 0.869 | Acc: 75.000% (48/64)
Loss: 0.373 | Acc: 87.608% (5663/6464)
Loss: 0.367 | Acc: 87.539% (11261/12864)
Loss: 0.369 | Acc: 87.484% (16853/19264)
Loss: 0.364 | Acc: 87.613% (22485/25664)
Loss: 0.365 | Acc: 87.615% (28093/32064)
Loss: 0.363 | Acc: 87.640% (33710/38464)
Loss: 0.360 | Acc: 87.687% (39340/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3870, Accuracy: 5182/10000 (51.82%)

Epoch: 110
Loss: 0.928 | Acc: 70.312% (45/64)
Loss: 0.369 | Acc: 87.392% (5649/6464)
Loss: 0.355 | Acc: 88.114% (11335/12864)
Loss: 0.354 | Acc: 88.237% (16998/19264)
Loss: 0.354 | Acc: 88.155% (22624/25664)
Loss: 0.356 | Acc: 88.133% (28259/32064)
Loss: 0.357 | Acc: 88.067% (33874/38464)
Loss: 0.355 | Acc: 88.117% (39533/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6815, Accuracy: 7933/10000 (79.33%)

Epoch: 111
Loss: 0.410 | Acc: 85.938% (55/64)
Loss: 0.327 | Acc: 88.954% (5750/6464)
Loss: 0.335 | Acc: 88.759% (11418/12864)
Loss: 0.336 | Acc: 88.735% (17094/19264)
Loss: 0.334 | Acc: 88.899% (22815/25664)
Loss: 0.338 | Acc: 88.785% (28468/32064)
Loss: 0.340 | Acc: 88.631% (34091/38464)
Loss: 0.341 | Acc: 88.541% (39723/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8276, Accuracy: 7401/10000 (74.01%)

Epoch: 112
Loss: 0.621 | Acc: 78.125% (50/64)
Loss: 0.316 | Acc: 89.217% (5767/6464)
Loss: 0.323 | Acc: 88.860% (11431/12864)
Loss: 0.326 | Acc: 88.844% (17115/19264)
Loss: 0.329 | Acc: 88.743% (22775/25664)
Loss: 0.332 | Acc: 88.701% (28441/32064)
Loss: 0.334 | Acc: 88.706% (34120/38464)
Loss: 0.334 | Acc: 88.708% (39798/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0517, Accuracy: 7152/10000 (71.52%)

Epoch: 113
Loss: 0.411 | Acc: 89.062% (57/64)
Loss: 0.322 | Acc: 89.233% (5768/6464)
Loss: 0.325 | Acc: 89.125% (11465/12864)
Loss: 0.323 | Acc: 89.068% (17158/19264)
Loss: 0.323 | Acc: 89.047% (22853/25664)
Loss: 0.324 | Acc: 88.935% (28516/32064)
Loss: 0.325 | Acc: 88.904% (34196/38464)
Loss: 0.325 | Acc: 88.953% (39908/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4828, Accuracy: 6341/10000 (63.41%)

Epoch: 114
Loss: 0.703 | Acc: 75.000% (48/64)
Loss: 0.320 | Acc: 88.830% (5742/6464)
Loss: 0.319 | Acc: 88.915% (11438/12864)
Loss: 0.322 | Acc: 88.876% (17121/19264)
Loss: 0.320 | Acc: 88.950% (22828/25664)
Loss: 0.318 | Acc: 89.069% (28559/32064)
Loss: 0.321 | Acc: 88.912% (34199/38464)
Loss: 0.321 | Acc: 88.935% (39900/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9906, Accuracy: 7129/10000 (71.29%)

Epoch: 115
Loss: 0.419 | Acc: 85.938% (55/64)
Loss: 0.286 | Acc: 90.269% (5835/6464)
Loss: 0.291 | Acc: 90.174% (11600/12864)
Loss: 0.300 | Acc: 89.831% (17305/19264)
Loss: 0.303 | Acc: 89.721% (23026/25664)
Loss: 0.306 | Acc: 89.646% (28744/32064)
Loss: 0.311 | Acc: 89.419% (34394/38464)
Loss: 0.313 | Acc: 89.348% (40085/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5685, Accuracy: 8201/10000 (82.01%)

Epoch: 116
Loss: 0.324 | Acc: 90.625% (58/64)
Loss: 0.295 | Acc: 89.991% (5817/6464)
Loss: 0.296 | Acc: 90.011% (11579/12864)
Loss: 0.300 | Acc: 89.857% (17310/19264)
Loss: 0.298 | Acc: 89.826% (23053/25664)
Loss: 0.302 | Acc: 89.752% (28778/32064)
Loss: 0.301 | Acc: 89.796% (34539/38464)
Loss: 0.305 | Acc: 89.644% (40218/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6639, Accuracy: 7898/10000 (78.98%)

Epoch: 117
Loss: 0.429 | Acc: 82.812% (53/64)
Loss: 0.285 | Acc: 90.254% (5834/6464)
Loss: 0.289 | Acc: 90.182% (11601/12864)
Loss: 0.287 | Acc: 90.173% (17371/19264)
Loss: 0.287 | Acc: 90.115% (23127/25664)
Loss: 0.288 | Acc: 90.104% (28891/32064)
Loss: 0.291 | Acc: 90.040% (34633/38464)
Loss: 0.291 | Acc: 90.074% (40411/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5203, Accuracy: 8296/10000 (82.96%)

Epoch: 118
Loss: 0.365 | Acc: 90.625% (58/64)
Loss: 0.278 | Acc: 90.749% (5866/6464)
Loss: 0.275 | Acc: 90.819% (11683/12864)
Loss: 0.277 | Acc: 90.667% (17466/19264)
Loss: 0.281 | Acc: 90.457% (23215/25664)
Loss: 0.282 | Acc: 90.432% (28996/32064)
Loss: 0.283 | Acc: 90.401% (34772/38464)
Loss: 0.283 | Acc: 90.451% (40580/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7335, Accuracy: 7792/10000 (77.92%)

Epoch: 119
Loss: 0.287 | Acc: 93.750% (60/64)
Loss: 0.280 | Acc: 90.347% (5840/6464)
Loss: 0.280 | Acc: 90.174% (11600/12864)
Loss: 0.280 | Acc: 90.215% (17379/19264)
Loss: 0.280 | Acc: 90.395% (23199/25664)
Loss: 0.278 | Acc: 90.429% (28995/32064)
Loss: 0.278 | Acc: 90.472% (34799/38464)
Loss: 0.280 | Acc: 90.418% (40565/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5594, Accuracy: 8297/10000 (82.97%)

Epoch: 120
Loss: 0.190 | Acc: 90.625% (58/64)
Loss: 0.264 | Acc: 91.244% (5898/6464)
Loss: 0.260 | Acc: 91.379% (11755/12864)
Loss: 0.260 | Acc: 91.289% (17586/19264)
Loss: 0.262 | Acc: 91.151% (23393/25664)
Loss: 0.261 | Acc: 91.208% (29245/32064)
Loss: 0.263 | Acc: 91.205% (35081/38464)
Loss: 0.264 | Acc: 91.180% (40907/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2765, Accuracy: 7062/10000 (70.62%)

Epoch: 121
Loss: 0.234 | Acc: 89.062% (57/64)
Loss: 0.237 | Acc: 91.646% (5924/6464)
Loss: 0.251 | Acc: 91.387% (11756/12864)
Loss: 0.260 | Acc: 91.129% (17555/19264)
Loss: 0.260 | Acc: 91.151% (23393/25664)
Loss: 0.257 | Acc: 91.283% (29269/32064)
Loss: 0.258 | Acc: 91.218% (35086/38464)
Loss: 0.258 | Acc: 91.227% (40928/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5194, Accuracy: 8339/10000 (83.39%)

Epoch: 122
Loss: 0.443 | Acc: 87.500% (56/64)
Loss: 0.232 | Acc: 92.234% (5962/6464)
Loss: 0.233 | Acc: 92.079% (11845/12864)
Loss: 0.240 | Acc: 91.746% (17674/19264)
Loss: 0.245 | Acc: 91.529% (23490/25664)
Loss: 0.246 | Acc: 91.536% (29350/32064)
Loss: 0.247 | Acc: 91.512% (35199/38464)
Loss: 0.250 | Acc: 91.465% (41035/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7862, Accuracy: 7806/10000 (78.06%)

Epoch: 123
Loss: 0.224 | Acc: 92.188% (59/64)
Loss: 0.225 | Acc: 92.420% (5974/6464)
Loss: 0.229 | Acc: 92.149% (11854/12864)
Loss: 0.237 | Acc: 91.912% (17706/19264)
Loss: 0.235 | Acc: 92.016% (23615/25664)
Loss: 0.239 | Acc: 91.832% (29445/32064)
Loss: 0.240 | Acc: 91.798% (35309/38464)
Loss: 0.240 | Acc: 91.793% (41182/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3901, Accuracy: 8738/10000 (87.38%)

Epoch: 124
Loss: 0.154 | Acc: 95.312% (61/64)
Loss: 0.225 | Acc: 92.652% (5989/6464)
Loss: 0.229 | Acc: 92.351% (11880/12864)
Loss: 0.228 | Acc: 92.348% (17790/19264)
Loss: 0.229 | Acc: 92.223% (23668/25664)
Loss: 0.230 | Acc: 92.219% (29569/32064)
Loss: 0.227 | Acc: 92.302% (35503/38464)
Loss: 0.228 | Acc: 92.286% (41403/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6586, Accuracy: 8080/10000 (80.80%)

Epoch: 125
Loss: 0.150 | Acc: 93.750% (60/64)
Loss: 0.210 | Acc: 92.822% (6000/6464)
Loss: 0.214 | Acc: 92.809% (11939/12864)
Loss: 0.221 | Acc: 92.416% (17803/19264)
Loss: 0.219 | Acc: 92.538% (23749/25664)
Loss: 0.215 | Acc: 92.671% (29714/32064)
Loss: 0.217 | Acc: 92.598% (35617/38464)
Loss: 0.218 | Acc: 92.558% (41525/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7405, Accuracy: 7723/10000 (77.23%)

Epoch: 126
Loss: 0.378 | Acc: 84.375% (54/64)
Loss: 0.196 | Acc: 93.332% (6033/6464)
Loss: 0.189 | Acc: 93.688% (12052/12864)
Loss: 0.197 | Acc: 93.376% (17988/19264)
Loss: 0.205 | Acc: 93.099% (23893/25664)
Loss: 0.205 | Acc: 93.132% (29862/32064)
Loss: 0.207 | Acc: 93.058% (35794/38464)
Loss: 0.206 | Acc: 93.046% (41744/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3700, Accuracy: 8802/10000 (88.02%)

Epoch: 127
Loss: 0.285 | Acc: 92.188% (59/64)
Loss: 0.204 | Acc: 93.023% (6013/6464)
Loss: 0.205 | Acc: 92.879% (11948/12864)
Loss: 0.199 | Acc: 93.065% (17928/19264)
Loss: 0.199 | Acc: 93.107% (23895/25664)
Loss: 0.200 | Acc: 93.098% (29851/32064)
Loss: 0.199 | Acc: 93.165% (35835/38464)
Loss: 0.197 | Acc: 93.255% (41838/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5209, Accuracy: 6476/10000 (64.76%)

Epoch: 128
Loss: 0.400 | Acc: 85.938% (55/64)
Loss: 0.177 | Acc: 93.951% (6073/6464)
Loss: 0.175 | Acc: 94.084% (12103/12864)
Loss: 0.178 | Acc: 93.916% (18092/19264)
Loss: 0.180 | Acc: 93.844% (24084/25664)
Loss: 0.180 | Acc: 93.875% (30100/32064)
Loss: 0.182 | Acc: 93.755% (36062/38464)
Loss: 0.185 | Acc: 93.717% (42045/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3858, Accuracy: 8813/10000 (88.13%)

Epoch: 129
Loss: 0.153 | Acc: 96.875% (62/64)
Loss: 0.166 | Acc: 94.168% (6087/6464)
Loss: 0.161 | Acc: 94.450% (12150/12864)
Loss: 0.161 | Acc: 94.492% (18203/19264)
Loss: 0.164 | Acc: 94.428% (24234/25664)
Loss: 0.166 | Acc: 94.352% (30253/32064)
Loss: 0.170 | Acc: 94.262% (36257/38464)
Loss: 0.168 | Acc: 94.289% (42302/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9420, Accuracy: 7628/10000 (76.28%)

Epoch: 130
Loss: 0.222 | Acc: 92.188% (59/64)
Loss: 0.167 | Acc: 94.183% (6088/6464)
Loss: 0.160 | Acc: 94.520% (12159/12864)
Loss: 0.153 | Acc: 94.814% (18265/19264)
Loss: 0.156 | Acc: 94.736% (24313/25664)
Loss: 0.156 | Acc: 94.779% (30390/32064)
Loss: 0.160 | Acc: 94.660% (36410/38464)
Loss: 0.160 | Acc: 94.668% (42472/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4023, Accuracy: 8769/10000 (87.69%)

Epoch: 131
Loss: 0.381 | Acc: 92.188% (59/64)
Loss: 0.129 | Acc: 95.823% (6194/6464)
Loss: 0.135 | Acc: 95.421% (12275/12864)
Loss: 0.136 | Acc: 95.406% (18379/19264)
Loss: 0.142 | Acc: 95.188% (24429/25664)
Loss: 0.141 | Acc: 95.197% (30524/32064)
Loss: 0.141 | Acc: 95.149% (36598/38464)
Loss: 0.143 | Acc: 95.061% (42648/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3307, Accuracy: 8966/10000 (89.66%)

Epoch: 132
Loss: 0.089 | Acc: 98.438% (63/64)
Loss: 0.116 | Acc: 95.931% (6201/6464)
Loss: 0.119 | Acc: 96.028% (12353/12864)
Loss: 0.123 | Acc: 95.925% (18479/19264)
Loss: 0.127 | Acc: 95.784% (24582/25664)
Loss: 0.129 | Acc: 95.662% (30673/32064)
Loss: 0.130 | Acc: 95.593% (36769/38464)
Loss: 0.131 | Acc: 95.562% (42873/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6853, Accuracy: 8097/10000 (80.97%)

Epoch: 133
Loss: 0.238 | Acc: 90.625% (58/64)
Loss: 0.115 | Acc: 96.040% (6208/6464)
Loss: 0.118 | Acc: 95.934% (12341/12864)
Loss: 0.116 | Acc: 95.977% (18489/19264)
Loss: 0.118 | Acc: 96.002% (24638/25664)
Loss: 0.117 | Acc: 96.005% (30783/32064)
Loss: 0.120 | Acc: 95.897% (36886/38464)
Loss: 0.121 | Acc: 95.827% (42992/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0113, Accuracy: 7717/10000 (77.17%)

Epoch: 134
Loss: 0.254 | Acc: 92.188% (59/64)
Loss: 0.101 | Acc: 96.643% (6247/6464)
Loss: 0.103 | Acc: 96.580% (12424/12864)
Loss: 0.099 | Acc: 96.657% (18620/19264)
Loss: 0.100 | Acc: 96.661% (24807/25664)
Loss: 0.101 | Acc: 96.632% (30984/32064)
Loss: 0.104 | Acc: 96.482% (37111/38464)
Loss: 0.105 | Acc: 96.425% (43260/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2682, Accuracy: 9172/10000 (91.72%)

Epoch: 135
Loss: 0.057 | Acc: 98.438% (63/64)
Loss: 0.087 | Acc: 97.107% (6277/6464)
Loss: 0.086 | Acc: 97.155% (12498/12864)
Loss: 0.086 | Acc: 97.124% (18710/19264)
Loss: 0.091 | Acc: 97.007% (24896/25664)
Loss: 0.091 | Acc: 96.969% (31092/32064)
Loss: 0.091 | Acc: 96.963% (37296/38464)
Loss: 0.091 | Acc: 96.971% (43505/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3008, Accuracy: 9099/10000 (90.99%)

Epoch: 136
Loss: 0.211 | Acc: 93.750% (60/64)
Loss: 0.094 | Acc: 96.798% (6257/6464)
Loss: 0.084 | Acc: 97.256% (12511/12864)
Loss: 0.081 | Acc: 97.404% (18764/19264)
Loss: 0.079 | Acc: 97.424% (25003/25664)
Loss: 0.078 | Acc: 97.430% (31240/32064)
Loss: 0.079 | Acc: 97.395% (37462/38464)
Loss: 0.078 | Acc: 97.443% (43717/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2238, Accuracy: 9322/10000 (93.22%)

Epoch: 137
Loss: 0.063 | Acc: 96.875% (62/64)
Loss: 0.055 | Acc: 98.113% (6342/6464)
Loss: 0.061 | Acc: 98.041% (12612/12864)
Loss: 0.059 | Acc: 98.064% (18891/19264)
Loss: 0.059 | Acc: 98.052% (25164/25664)
Loss: 0.059 | Acc: 98.088% (31451/32064)
Loss: 0.060 | Acc: 98.027% (37705/38464)
Loss: 0.061 | Acc: 97.976% (43956/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2593, Accuracy: 9247/10000 (92.47%)

Epoch: 138
Loss: 0.030 | Acc: 100.000% (64/64)
Loss: 0.056 | Acc: 98.190% (6347/6464)
Loss: 0.054 | Acc: 98.290% (12644/12864)
Loss: 0.052 | Acc: 98.380% (18952/19264)
Loss: 0.051 | Acc: 98.344% (25239/25664)
Loss: 0.052 | Acc: 98.319% (31525/32064)
Loss: 0.050 | Acc: 98.352% (37830/38464)
Loss: 0.050 | Acc: 98.371% (44133/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2625, Accuracy: 9264/10000 (92.64%)

Epoch: 139
Loss: 0.042 | Acc: 98.438% (63/64)
Loss: 0.044 | Acc: 98.484% (6366/6464)
Loss: 0.043 | Acc: 98.570% (12680/12864)
Loss: 0.041 | Acc: 98.656% (19005/19264)
Loss: 0.041 | Acc: 98.656% (25319/25664)
Loss: 0.041 | Acc: 98.659% (31634/32064)
Loss: 0.040 | Acc: 98.710% (37968/38464)
Loss: 0.040 | Acc: 98.745% (44301/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2188, Accuracy: 9385/10000 (93.85%)

Epoch: 140
Loss: 0.008 | Acc: 100.000% (64/64)
Loss: 0.030 | Acc: 99.134% (6408/6464)
Loss: 0.029 | Acc: 99.114% (12750/12864)
Loss: 0.029 | Acc: 99.118% (19094/19264)
Loss: 0.030 | Acc: 99.100% (25433/25664)
Loss: 0.030 | Acc: 99.074% (31767/32064)
Loss: 0.029 | Acc: 99.106% (38120/38464)
Loss: 0.030 | Acc: 99.082% (44452/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2037, Accuracy: 9416/10000 (94.16%)

Epoch: 141
Loss: 0.034 | Acc: 98.438% (63/64)
Loss: 0.019 | Acc: 99.459% (6429/6464)
Loss: 0.019 | Acc: 99.502% (12800/12864)
Loss: 0.019 | Acc: 99.476% (19163/19264)
Loss: 0.021 | Acc: 99.419% (25515/25664)
Loss: 0.020 | Acc: 99.429% (31881/32064)
Loss: 0.020 | Acc: 99.412% (38238/38464)
Loss: 0.021 | Acc: 99.396% (44593/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2147, Accuracy: 9408/10000 (94.08%)

Epoch: 142
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.013 | Acc: 99.660% (6442/6464)
Loss: 0.015 | Acc: 99.635% (12817/12864)
Loss: 0.016 | Acc: 99.600% (19187/19264)
Loss: 0.017 | Acc: 99.575% (25555/25664)
Loss: 0.016 | Acc: 99.591% (31933/32064)
Loss: 0.016 | Acc: 99.600% (38310/38464)
Loss: 0.016 | Acc: 99.581% (44676/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2061, Accuracy: 9419/10000 (94.19%)

Epoch: 143
Loss: 0.010 | Acc: 100.000% (64/64)
Loss: 0.014 | Acc: 99.613% (6439/6464)
Loss: 0.014 | Acc: 99.627% (12816/12864)
Loss: 0.013 | Acc: 99.626% (19192/19264)
Loss: 0.013 | Acc: 99.634% (25570/25664)
Loss: 0.013 | Acc: 99.641% (31949/32064)
Loss: 0.013 | Acc: 99.654% (38331/38464)
Loss: 0.012 | Acc: 99.659% (44711/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2213, Accuracy: 9396/10000 (93.96%)

Epoch: 144
Loss: 0.021 | Acc: 100.000% (64/64)
Loss: 0.012 | Acc: 99.706% (6445/6464)
Loss: 0.012 | Acc: 99.705% (12826/12864)
Loss: 0.012 | Acc: 99.689% (19204/19264)
Loss: 0.012 | Acc: 99.696% (25586/25664)
Loss: 0.012 | Acc: 99.694% (31966/32064)
Loss: 0.011 | Acc: 99.701% (38349/38464)
Loss: 0.011 | Acc: 99.708% (44733/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2038, Accuracy: 9454/10000 (94.54%)

Epoch: 145
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.768% (6449/6464)
Loss: 0.010 | Acc: 99.775% (12835/12864)
Loss: 0.010 | Acc: 99.751% (19216/19264)
Loss: 0.010 | Acc: 99.739% (25597/25664)
Loss: 0.010 | Acc: 99.750% (31984/32064)
Loss: 0.010 | Acc: 99.748% (38367/38464)
Loss: 0.010 | Acc: 99.753% (44753/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2000, Accuracy: 9463/10000 (94.63%)

Epoch: 146
Loss: 0.013 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.814% (6452/6464)
Loss: 0.008 | Acc: 99.845% (12844/12864)
Loss: 0.008 | Acc: 99.834% (19232/19264)
Loss: 0.009 | Acc: 99.832% (25621/25664)
Loss: 0.008 | Acc: 99.844% (32014/32064)
Loss: 0.009 | Acc: 99.841% (38403/38464)
Loss: 0.009 | Acc: 99.826% (44786/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1972, Accuracy: 9469/10000 (94.69%)

Epoch: 147
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.876% (6456/6464)
Loss: 0.008 | Acc: 99.845% (12844/12864)
Loss: 0.008 | Acc: 99.834% (19232/19264)
Loss: 0.008 | Acc: 99.821% (25618/25664)
Loss: 0.008 | Acc: 99.832% (32010/32064)
Loss: 0.008 | Acc: 99.834% (38400/38464)
Loss: 0.008 | Acc: 99.826% (44786/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1956, Accuracy: 9466/10000 (94.66%)
torch.Size([100, 10])
Test set: Average loss: 0.1956, Accuracy: 9466/10000 (94.66%)

Epoch: 148
Loss: 0.022 | Acc: 98.438% (63/64)
Loss: 0.007 | Acc: 99.892% (6457/6464)
Loss: 0.007 | Acc: 99.883% (12849/12864)
Loss: 0.007 | Acc: 99.886% (19242/19264)
Loss: 0.007 | Acc: 99.891% (25636/25664)
Loss: 0.007 | Acc: 99.897% (32031/32064)
Loss: 0.007 | Acc: 99.901% (38426/38464)
Loss: 0.007 | Acc: 99.902% (44820/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1953, Accuracy: 9461/10000 (94.61%)
torch.Size([100, 10])
Test set: Average loss: 0.1953, Accuracy: 9461/10000 (94.61%)

Epoch: 149
Loss: 0.011 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.830% (6453/6464)
Loss: 0.008 | Acc: 99.837% (12843/12864)
Loss: 0.008 | Acc: 99.844% (19234/19264)
Loss: 0.008 | Acc: 99.875% (25632/25664)
Loss: 0.007 | Acc: 99.872% (32023/32064)
Loss: 0.007 | Acc: 99.873% (38415/38464)
Loss: 0.007 | Acc: 99.877% (44809/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1960, Accuracy: 9466/10000 (94.66%)
torch.Size([100, 10])
Test set: Average loss: 0.1960, Accuracy: 9466/10000 (94.66%)

Epoch: 150
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 1.781 | Acc: 35.659% (2305/6464)
Loss: 1.315 | Acc: 53.374% (6866/12864)
Loss: 1.087 | Acc: 61.903% (11925/19264)
Loss: 0.950 | Acc: 66.786% (17140/25664)
Loss: 0.863 | Acc: 69.951% (22429/32064)
Loss: 0.796 | Acc: 72.382% (27841/38464)
Loss: 0.749 | Acc: 74.104% (33246/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5521, Accuracy: 6269/10000 (62.69%)

Epoch: 151
Loss: 0.736 | Acc: 79.688% (51/64)
Loss: 0.424 | Acc: 85.953% (5556/6464)
Loss: 0.427 | Acc: 85.393% (10985/12864)
Loss: 0.430 | Acc: 85.309% (16434/19264)
Loss: 0.422 | Acc: 85.692% (21992/25664)
Loss: 0.413 | Acc: 85.934% (27554/32064)
Loss: 0.412 | Acc: 86.073% (33107/38464)
Loss: 0.407 | Acc: 86.218% (38681/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0156, Accuracy: 5195/10000 (51.95%)

Epoch: 152
Loss: 0.764 | Acc: 70.312% (45/64)
Loss: 0.368 | Acc: 87.732% (5671/6464)
Loss: 0.369 | Acc: 87.570% (11265/12864)
Loss: 0.371 | Acc: 87.573% (16870/19264)
Loss: 0.379 | Acc: 87.118% (22358/25664)
Loss: 0.376 | Acc: 87.194% (27958/32064)
Loss: 0.375 | Acc: 87.193% (33538/38464)
Loss: 0.373 | Acc: 87.226% (39133/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3892, Accuracy: 6415/10000 (64.15%)

Epoch: 153
Loss: 0.848 | Acc: 75.000% (48/64)
Loss: 0.363 | Acc: 87.933% (5684/6464)
Loss: 0.347 | Acc: 88.433% (11376/12864)
Loss: 0.346 | Acc: 88.382% (17026/19264)
Loss: 0.345 | Acc: 88.388% (22684/25664)
Loss: 0.345 | Acc: 88.401% (28345/32064)
Loss: 0.348 | Acc: 88.337% (33978/38464)
Loss: 0.347 | Acc: 88.334% (39630/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0653, Accuracy: 7180/10000 (71.80%)

Epoch: 154
Loss: 0.320 | Acc: 89.062% (57/64)
Loss: 0.348 | Acc: 87.995% (5688/6464)
Loss: 0.354 | Acc: 88.013% (11322/12864)
Loss: 0.353 | Acc: 88.024% (16957/19264)
Loss: 0.350 | Acc: 88.123% (22616/25664)
Loss: 0.349 | Acc: 88.171% (28271/32064)
Loss: 0.348 | Acc: 88.238% (33940/38464)
Loss: 0.347 | Acc: 88.271% (39602/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1680, Accuracy: 5796/10000 (57.96%)

Epoch: 155
Loss: 1.150 | Acc: 73.438% (47/64)
Loss: 0.347 | Acc: 88.041% (5691/6464)
Loss: 0.346 | Acc: 88.231% (11350/12864)
Loss: 0.334 | Acc: 88.616% (17071/19264)
Loss: 0.342 | Acc: 88.459% (22702/25664)
Loss: 0.341 | Acc: 88.436% (28356/32064)
Loss: 0.342 | Acc: 88.433% (34015/38464)
Loss: 0.344 | Acc: 88.349% (39637/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7834, Accuracy: 7628/10000 (76.28%)

Epoch: 156
Loss: 0.298 | Acc: 89.062% (57/64)
Loss: 0.325 | Acc: 89.202% (5766/6464)
Loss: 0.333 | Acc: 88.759% (11418/12864)
Loss: 0.331 | Acc: 88.767% (17100/19264)
Loss: 0.329 | Acc: 88.805% (22791/25664)
Loss: 0.334 | Acc: 88.626% (28417/32064)
Loss: 0.334 | Acc: 88.699% (34117/38464)
Loss: 0.334 | Acc: 88.721% (39804/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4505, Accuracy: 6061/10000 (60.61%)

Epoch: 157
Loss: 0.419 | Acc: 90.625% (58/64)
Loss: 0.331 | Acc: 88.877% (5745/6464)
Loss: 0.326 | Acc: 88.985% (11447/12864)
Loss: 0.325 | Acc: 89.037% (17152/19264)
Loss: 0.327 | Acc: 89.027% (22848/25664)
Loss: 0.329 | Acc: 89.009% (28540/32064)
Loss: 0.329 | Acc: 89.013% (34238/38464)
Loss: 0.330 | Acc: 88.960% (39911/44864)
torch.Size([100, 10])
Test set: Average loss: 2.7062, Accuracy: 5588/10000 (55.88%)

Epoch: 158
Loss: 0.624 | Acc: 82.812% (53/64)
Loss: 0.322 | Acc: 89.248% (5769/6464)
Loss: 0.329 | Acc: 88.907% (11437/12864)
Loss: 0.322 | Acc: 88.964% (17138/19264)
Loss: 0.322 | Acc: 89.094% (22865/25664)
Loss: 0.326 | Acc: 89.059% (28556/32064)
Loss: 0.326 | Acc: 89.026% (34243/38464)
Loss: 0.328 | Acc: 88.940% (39902/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7138, Accuracy: 7855/10000 (78.55%)

Epoch: 159
Loss: 0.532 | Acc: 84.375% (54/64)
Loss: 0.305 | Acc: 89.279% (5771/6464)
Loss: 0.315 | Acc: 89.218% (11477/12864)
Loss: 0.316 | Acc: 89.187% (17181/19264)
Loss: 0.318 | Acc: 89.055% (22855/25664)
Loss: 0.317 | Acc: 89.091% (28566/32064)
Loss: 0.321 | Acc: 89.003% (34234/38464)
Loss: 0.323 | Acc: 88.938% (39901/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4006, Accuracy: 6566/10000 (65.66%)

Epoch: 160
Loss: 0.623 | Acc: 79.688% (51/64)
Loss: 0.307 | Acc: 89.743% (5801/6464)
Loss: 0.315 | Acc: 89.335% (11492/12864)
Loss: 0.318 | Acc: 89.177% (17179/19264)
Loss: 0.319 | Acc: 89.109% (22869/25664)
Loss: 0.312 | Acc: 89.377% (28658/32064)
Loss: 0.313 | Acc: 89.335% (34362/38464)
Loss: 0.314 | Acc: 89.332% (40078/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5448, Accuracy: 8238/10000 (82.38%)

Epoch: 161
Loss: 0.337 | Acc: 90.625% (58/64)
Loss: 0.298 | Acc: 90.006% (5818/6464)
Loss: 0.303 | Acc: 89.754% (11546/12864)
Loss: 0.307 | Acc: 89.654% (17271/19264)
Loss: 0.309 | Acc: 89.460% (22959/25664)
Loss: 0.311 | Acc: 89.399% (28665/32064)
Loss: 0.311 | Acc: 89.372% (34376/38464)
Loss: 0.312 | Acc: 89.299% (40063/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7208, Accuracy: 6043/10000 (60.43%)

Epoch: 162
Loss: 0.423 | Acc: 87.500% (56/64)
Loss: 0.305 | Acc: 89.558% (5789/6464)
Loss: 0.297 | Acc: 89.840% (11557/12864)
Loss: 0.301 | Acc: 89.722% (17284/19264)
Loss: 0.302 | Acc: 89.787% (23043/25664)
Loss: 0.305 | Acc: 89.627% (28738/32064)
Loss: 0.307 | Acc: 89.486% (34420/38464)
Loss: 0.309 | Acc: 89.397% (40107/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4345, Accuracy: 8622/10000 (86.22%)

Epoch: 163
Loss: 0.286 | Acc: 92.188% (59/64)
Loss: 0.285 | Acc: 90.408% (5844/6464)
Loss: 0.293 | Acc: 90.096% (11590/12864)
Loss: 0.298 | Acc: 90.059% (17349/19264)
Loss: 0.298 | Acc: 90.033% (23106/25664)
Loss: 0.302 | Acc: 89.886% (28821/32064)
Loss: 0.301 | Acc: 89.835% (34554/38464)
Loss: 0.302 | Acc: 89.789% (40283/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7276, Accuracy: 7769/10000 (77.69%)

Epoch: 164
Loss: 0.300 | Acc: 87.500% (56/64)
Loss: 0.278 | Acc: 90.130% (5826/6464)
Loss: 0.282 | Acc: 90.205% (11604/12864)
Loss: 0.289 | Acc: 89.992% (17336/19264)
Loss: 0.291 | Acc: 89.974% (23091/25664)
Loss: 0.292 | Acc: 89.986% (28853/32064)
Loss: 0.292 | Acc: 89.946% (34597/38464)
Loss: 0.296 | Acc: 89.865% (40317/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2743, Accuracy: 6840/10000 (68.40%)

Epoch: 165
Loss: 0.462 | Acc: 85.938% (55/64)
Loss: 0.293 | Acc: 90.053% (5821/6464)
Loss: 0.298 | Acc: 89.770% (11548/12864)
Loss: 0.289 | Acc: 90.153% (17367/19264)
Loss: 0.290 | Acc: 90.126% (23130/25664)
Loss: 0.289 | Acc: 90.207% (28924/32064)
Loss: 0.287 | Acc: 90.245% (34712/38464)
Loss: 0.289 | Acc: 90.117% (40430/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2882, Accuracy: 6651/10000 (66.51%)

Epoch: 166
Loss: 0.966 | Acc: 68.750% (44/64)
Loss: 0.276 | Acc: 90.718% (5864/6464)
Loss: 0.277 | Acc: 90.586% (11653/12864)
Loss: 0.281 | Acc: 90.454% (17425/19264)
Loss: 0.283 | Acc: 90.395% (23199/25664)
Loss: 0.283 | Acc: 90.410% (28989/32064)
Loss: 0.287 | Acc: 90.292% (34730/38464)
Loss: 0.285 | Acc: 90.375% (40546/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3911, Accuracy: 6621/10000 (66.21%)

Epoch: 167
Loss: 0.324 | Acc: 89.062% (57/64)
Loss: 0.280 | Acc: 90.656% (5860/6464)
Loss: 0.272 | Acc: 90.850% (11687/12864)
Loss: 0.268 | Acc: 90.900% (17511/19264)
Loss: 0.271 | Acc: 90.816% (23307/25664)
Loss: 0.272 | Acc: 90.756% (29100/32064)
Loss: 0.277 | Acc: 90.576% (34839/38464)
Loss: 0.278 | Acc: 90.565% (40631/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6739, Accuracy: 8001/10000 (80.01%)

Epoch: 168
Loss: 0.328 | Acc: 89.062% (57/64)
Loss: 0.248 | Acc: 91.491% (5914/6464)
Loss: 0.253 | Acc: 91.301% (11745/12864)
Loss: 0.262 | Acc: 90.968% (17524/19264)
Loss: 0.264 | Acc: 90.933% (23337/25664)
Loss: 0.265 | Acc: 90.974% (29170/32064)
Loss: 0.268 | Acc: 90.885% (34958/38464)
Loss: 0.268 | Acc: 90.899% (40781/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7238, Accuracy: 7951/10000 (79.51%)

Epoch: 169
Loss: 0.316 | Acc: 89.062% (57/64)
Loss: 0.257 | Acc: 91.120% (5890/6464)
Loss: 0.256 | Acc: 91.185% (11730/12864)
Loss: 0.259 | Acc: 91.123% (17554/19264)
Loss: 0.258 | Acc: 91.221% (23411/25664)
Loss: 0.260 | Acc: 91.168% (29232/32064)
Loss: 0.262 | Acc: 91.129% (35052/38464)
Loss: 0.264 | Acc: 91.033% (40841/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5417, Accuracy: 8313/10000 (83.13%)

Epoch: 170
Loss: 0.290 | Acc: 89.062% (57/64)
Loss: 0.254 | Acc: 91.337% (5904/6464)
Loss: 0.250 | Acc: 91.519% (11773/12864)
Loss: 0.252 | Acc: 91.476% (17622/19264)
Loss: 0.247 | Acc: 91.693% (23532/25664)
Loss: 0.253 | Acc: 91.439% (29319/32064)
Loss: 0.254 | Acc: 91.369% (35144/38464)
Loss: 0.255 | Acc: 91.334% (40976/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5561, Accuracy: 8248/10000 (82.48%)

Epoch: 171
Loss: 0.367 | Acc: 85.938% (55/64)
Loss: 0.229 | Acc: 92.249% (5963/6464)
Loss: 0.228 | Acc: 92.281% (11871/12864)
Loss: 0.240 | Acc: 91.918% (17707/19264)
Loss: 0.238 | Acc: 91.950% (23598/25664)
Loss: 0.241 | Acc: 91.863% (29455/32064)
Loss: 0.241 | Acc: 91.912% (35353/38464)
Loss: 0.243 | Acc: 91.853% (41209/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5066, Accuracy: 8445/10000 (84.45%)

Epoch: 172
Loss: 0.278 | Acc: 90.625% (58/64)
Loss: 0.244 | Acc: 91.383% (5907/6464)
Loss: 0.232 | Acc: 91.939% (11827/12864)
Loss: 0.230 | Acc: 92.068% (17736/19264)
Loss: 0.232 | Acc: 91.977% (23605/25664)
Loss: 0.231 | Acc: 92.063% (29519/32064)
Loss: 0.231 | Acc: 92.003% (35388/38464)
Loss: 0.231 | Acc: 92.031% (41289/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1111, Accuracy: 6022/10000 (60.22%)

Epoch: 173
Loss: 0.371 | Acc: 85.938% (55/64)
Loss: 0.249 | Acc: 91.414% (5909/6464)
Loss: 0.233 | Acc: 92.001% (11835/12864)
Loss: 0.229 | Acc: 92.265% (17774/19264)
Loss: 0.231 | Acc: 92.238% (23672/25664)
Loss: 0.227 | Acc: 92.343% (29609/32064)
Loss: 0.229 | Acc: 92.265% (35489/38464)
Loss: 0.227 | Acc: 92.312% (41415/44864)
torch.Size([100, 10])
Test set: Average loss: 2.6658, Accuracy: 4828/10000 (48.28%)

Epoch: 174
Loss: 0.457 | Acc: 79.688% (51/64)
Loss: 0.240 | Acc: 91.832% (5936/6464)
Loss: 0.230 | Acc: 92.242% (11866/12864)
Loss: 0.230 | Acc: 92.125% (17747/19264)
Loss: 0.228 | Acc: 92.188% (23659/25664)
Loss: 0.226 | Acc: 92.284% (29590/32064)
Loss: 0.221 | Acc: 92.460% (35564/38464)
Loss: 0.222 | Acc: 92.435% (41470/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9381, Accuracy: 7554/10000 (75.54%)

Epoch: 175
Loss: 0.319 | Acc: 89.062% (57/64)
Loss: 0.214 | Acc: 92.420% (5974/6464)
Loss: 0.200 | Acc: 93.035% (11968/12864)
Loss: 0.198 | Acc: 93.257% (17965/19264)
Loss: 0.204 | Acc: 93.041% (23878/25664)
Loss: 0.207 | Acc: 92.895% (29786/32064)
Loss: 0.206 | Acc: 92.934% (35746/38464)
Loss: 0.205 | Acc: 92.954% (41703/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5580, Accuracy: 8265/10000 (82.65%)

Epoch: 176
Loss: 0.217 | Acc: 93.750% (60/64)
Loss: 0.172 | Acc: 94.137% (6085/6464)
Loss: 0.184 | Acc: 93.804% (12067/12864)
Loss: 0.192 | Acc: 93.496% (18011/19264)
Loss: 0.191 | Acc: 93.438% (23980/25664)
Loss: 0.193 | Acc: 93.385% (29943/32064)
Loss: 0.191 | Acc: 93.443% (35942/38464)
Loss: 0.192 | Acc: 93.380% (41894/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4796, Accuracy: 8519/10000 (85.19%)

Epoch: 177
Loss: 0.216 | Acc: 90.625% (58/64)
Loss: 0.180 | Acc: 94.168% (6087/6464)
Loss: 0.177 | Acc: 94.154% (12112/12864)
Loss: 0.172 | Acc: 94.300% (18166/19264)
Loss: 0.180 | Acc: 93.984% (24120/25664)
Loss: 0.183 | Acc: 93.940% (30121/32064)
Loss: 0.187 | Acc: 93.831% (36091/38464)
Loss: 0.186 | Acc: 93.835% (42098/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4693, Accuracy: 6378/10000 (63.78%)

Epoch: 178
Loss: 0.281 | Acc: 92.188% (59/64)
Loss: 0.172 | Acc: 94.199% (6089/6464)
Loss: 0.164 | Acc: 94.496% (12156/12864)
Loss: 0.173 | Acc: 94.160% (18139/19264)
Loss: 0.176 | Acc: 94.066% (24141/25664)
Loss: 0.174 | Acc: 94.127% (30181/32064)
Loss: 0.176 | Acc: 94.005% (36158/38464)
Loss: 0.175 | Acc: 94.049% (42194/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6910, Accuracy: 8007/10000 (80.07%)

Epoch: 179
Loss: 0.111 | Acc: 98.438% (63/64)
Loss: 0.168 | Acc: 94.338% (6098/6464)
Loss: 0.161 | Acc: 94.488% (12155/12864)
Loss: 0.157 | Acc: 94.669% (18237/19264)
Loss: 0.161 | Acc: 94.436% (24236/25664)
Loss: 0.161 | Acc: 94.436% (30280/32064)
Loss: 0.161 | Acc: 94.400% (36310/38464)
Loss: 0.162 | Acc: 94.352% (42330/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3741, Accuracy: 8826/10000 (88.26%)

Epoch: 180
Loss: 0.123 | Acc: 95.312% (61/64)
Loss: 0.153 | Acc: 94.632% (6117/6464)
Loss: 0.146 | Acc: 94.893% (12207/12864)
Loss: 0.142 | Acc: 94.965% (18294/19264)
Loss: 0.144 | Acc: 94.981% (24376/25664)
Loss: 0.145 | Acc: 94.979% (30454/32064)
Loss: 0.146 | Acc: 94.949% (36521/38464)
Loss: 0.147 | Acc: 94.938% (42593/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4252, Accuracy: 8713/10000 (87.13%)

Epoch: 181
Loss: 0.249 | Acc: 90.625% (58/64)
Loss: 0.138 | Acc: 95.498% (6173/6464)
Loss: 0.135 | Acc: 95.460% (12280/12864)
Loss: 0.136 | Acc: 95.458% (18389/19264)
Loss: 0.134 | Acc: 95.425% (24490/25664)
Loss: 0.135 | Acc: 95.403% (30590/32064)
Loss: 0.138 | Acc: 95.299% (36656/38464)
Loss: 0.137 | Acc: 95.292% (42752/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9514, Accuracy: 7834/10000 (78.34%)

Epoch: 182
Loss: 0.267 | Acc: 92.188% (59/64)
Loss: 0.114 | Acc: 96.101% (6212/6464)
Loss: 0.120 | Acc: 95.833% (12328/12864)
Loss: 0.123 | Acc: 95.738% (18443/19264)
Loss: 0.122 | Acc: 95.792% (24584/25664)
Loss: 0.124 | Acc: 95.762% (30705/32064)
Loss: 0.125 | Acc: 95.710% (36814/38464)
Loss: 0.127 | Acc: 95.669% (42921/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2720, Accuracy: 9157/10000 (91.57%)

Epoch: 183
Loss: 0.077 | Acc: 95.312% (61/64)
Loss: 0.113 | Acc: 96.101% (6212/6464)
Loss: 0.108 | Acc: 96.424% (12404/12864)
Loss: 0.111 | Acc: 96.237% (18539/19264)
Loss: 0.111 | Acc: 96.228% (24696/25664)
Loss: 0.112 | Acc: 96.155% (30831/32064)
Loss: 0.113 | Acc: 96.173% (36992/38464)
Loss: 0.112 | Acc: 96.182% (43151/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2992, Accuracy: 9085/10000 (90.85%)

Epoch: 184
Loss: 0.118 | Acc: 95.312% (61/64)
Loss: 0.087 | Acc: 96.860% (6261/6464)
Loss: 0.088 | Acc: 96.852% (12459/12864)
Loss: 0.092 | Acc: 96.844% (18656/19264)
Loss: 0.091 | Acc: 96.867% (24860/25664)
Loss: 0.094 | Acc: 96.741% (31019/32064)
Loss: 0.096 | Acc: 96.714% (37200/38464)
Loss: 0.095 | Acc: 96.741% (43402/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3226, Accuracy: 9085/10000 (90.85%)

Epoch: 185
Loss: 0.165 | Acc: 93.750% (60/64)
Loss: 0.084 | Acc: 97.045% (6273/6464)
Loss: 0.080 | Acc: 97.287% (12515/12864)
Loss: 0.081 | Acc: 97.228% (18730/19264)
Loss: 0.084 | Acc: 97.117% (24924/25664)
Loss: 0.088 | Acc: 96.965% (31091/32064)
Loss: 0.085 | Acc: 97.057% (37332/38464)
Loss: 0.085 | Acc: 97.064% (43547/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2570, Accuracy: 9214/10000 (92.14%)

Epoch: 186
Loss: 0.039 | Acc: 98.438% (63/64)
Loss: 0.071 | Acc: 97.757% (6319/6464)
Loss: 0.070 | Acc: 97.730% (12572/12864)
Loss: 0.069 | Acc: 97.763% (18833/19264)
Loss: 0.070 | Acc: 97.724% (25080/25664)
Loss: 0.071 | Acc: 97.686% (31322/32064)
Loss: 0.072 | Acc: 97.613% (37546/38464)
Loss: 0.074 | Acc: 97.599% (43787/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2324, Accuracy: 9269/10000 (92.69%)

Epoch: 187
Loss: 0.029 | Acc: 98.438% (63/64)
Loss: 0.058 | Acc: 98.097% (6341/6464)
Loss: 0.053 | Acc: 98.344% (12651/12864)
Loss: 0.054 | Acc: 98.328% (18942/19264)
Loss: 0.053 | Acc: 98.321% (25233/25664)
Loss: 0.054 | Acc: 98.285% (31514/32064)
Loss: 0.054 | Acc: 98.263% (37796/38464)
Loss: 0.054 | Acc: 98.255% (44081/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2532, Accuracy: 9282/10000 (92.82%)

Epoch: 188
Loss: 0.070 | Acc: 98.438% (63/64)
Loss: 0.055 | Acc: 98.159% (6345/6464)
Loss: 0.051 | Acc: 98.228% (12636/12864)
Loss: 0.049 | Acc: 98.277% (18932/19264)
Loss: 0.048 | Acc: 98.352% (25241/25664)
Loss: 0.049 | Acc: 98.300% (31519/32064)
Loss: 0.049 | Acc: 98.302% (37811/38464)
Loss: 0.049 | Acc: 98.295% (44099/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2297, Accuracy: 9322/10000 (93.22%)

Epoch: 189
Loss: 0.025 | Acc: 98.438% (63/64)
Loss: 0.040 | Acc: 98.762% (6384/6464)
Loss: 0.038 | Acc: 98.795% (12709/12864)
Loss: 0.037 | Acc: 98.822% (19037/19264)
Loss: 0.036 | Acc: 98.874% (25375/25664)
Loss: 0.036 | Acc: 98.868% (31701/32064)
Loss: 0.037 | Acc: 98.825% (38012/38464)
Loss: 0.037 | Acc: 98.843% (44345/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2137, Accuracy: 9409/10000 (94.09%)

Epoch: 190
Loss: 0.015 | Acc: 100.000% (64/64)
Loss: 0.022 | Acc: 99.304% (6419/6464)
Loss: 0.023 | Acc: 99.363% (12782/12864)
Loss: 0.024 | Acc: 99.320% (19133/19264)
Loss: 0.024 | Acc: 99.291% (25482/25664)
Loss: 0.025 | Acc: 99.283% (31834/32064)
Loss: 0.024 | Acc: 99.288% (38190/38464)
Loss: 0.024 | Acc: 99.287% (44544/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2094, Accuracy: 9422/10000 (94.22%)

Epoch: 191
Loss: 0.020 | Acc: 98.438% (63/64)
Loss: 0.021 | Acc: 99.366% (6423/6464)
Loss: 0.022 | Acc: 99.378% (12784/12864)
Loss: 0.021 | Acc: 99.377% (19144/19264)
Loss: 0.022 | Acc: 99.377% (25504/25664)
Loss: 0.022 | Acc: 99.345% (31854/32064)
Loss: 0.022 | Acc: 99.334% (38208/38464)
Loss: 0.022 | Acc: 99.336% (44566/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2438, Accuracy: 9375/10000 (93.75%)

Epoch: 192
Loss: 0.018 | Acc: 98.438% (63/64)
Loss: 0.020 | Acc: 99.474% (6430/6464)
Loss: 0.017 | Acc: 99.510% (12801/12864)
Loss: 0.016 | Acc: 99.580% (19183/19264)
Loss: 0.015 | Acc: 99.599% (25561/25664)
Loss: 0.016 | Acc: 99.582% (31930/32064)
Loss: 0.016 | Acc: 99.579% (38302/38464)
Loss: 0.015 | Acc: 99.572% (44672/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2036, Accuracy: 9455/10000 (94.55%)

Epoch: 193
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.660% (6442/6464)
Loss: 0.014 | Acc: 99.565% (12808/12864)
Loss: 0.013 | Acc: 99.616% (19190/19264)
Loss: 0.012 | Acc: 99.665% (25578/25664)
Loss: 0.012 | Acc: 99.682% (31962/32064)
Loss: 0.012 | Acc: 99.693% (38346/38464)
Loss: 0.011 | Acc: 99.712% (44735/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1919, Accuracy: 9476/10000 (94.76%)

Epoch: 194
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.830% (6453/6464)
Loss: 0.008 | Acc: 99.852% (12845/12864)
Loss: 0.008 | Acc: 99.834% (19232/19264)
Loss: 0.008 | Acc: 99.832% (25621/25664)
Loss: 0.008 | Acc: 99.822% (32007/32064)
Loss: 0.008 | Acc: 99.818% (38394/38464)
Loss: 0.009 | Acc: 99.797% (44773/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1927, Accuracy: 9487/10000 (94.87%)

Epoch: 195
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.861% (6455/6464)
Loss: 0.008 | Acc: 99.845% (12844/12864)
Loss: 0.008 | Acc: 99.829% (19231/19264)
Loss: 0.008 | Acc: 99.836% (25622/25664)
Loss: 0.008 | Acc: 99.841% (32013/32064)
Loss: 0.008 | Acc: 99.839% (38402/38464)
Loss: 0.008 | Acc: 99.848% (44796/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1885, Accuracy: 9487/10000 (94.87%)

Epoch: 196
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 0.006 | Acc: 99.938% (6460/6464)
Loss: 0.007 | Acc: 99.899% (12851/12864)
Loss: 0.007 | Acc: 99.896% (19244/19264)
Loss: 0.007 | Acc: 99.887% (25635/25664)
Loss: 0.007 | Acc: 99.888% (32028/32064)
Loss: 0.007 | Acc: 99.878% (38417/38464)
Loss: 0.007 | Acc: 99.877% (44809/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1889, Accuracy: 9495/10000 (94.95%)

Epoch: 197
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.752% (6448/6464)
Loss: 0.009 | Acc: 99.806% (12839/12864)
Loss: 0.008 | Acc: 99.818% (19229/19264)
Loss: 0.008 | Acc: 99.829% (25620/25664)
Loss: 0.008 | Acc: 99.828% (32009/32064)
Loss: 0.008 | Acc: 99.818% (38394/38464)
Loss: 0.008 | Acc: 99.833% (44789/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1864, Accuracy: 9502/10000 (95.02%)
torch.Size([100, 10])
Test set: Average loss: 0.1864, Accuracy: 9502/10000 (95.02%)

Epoch: 198
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.907% (6458/6464)
Loss: 0.008 | Acc: 99.860% (12846/12864)
Loss: 0.007 | Acc: 99.886% (19242/19264)
Loss: 0.007 | Acc: 99.875% (25632/25664)
Loss: 0.007 | Acc: 99.857% (32018/32064)
Loss: 0.007 | Acc: 99.860% (38410/38464)
Loss: 0.007 | Acc: 99.866% (44804/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1865, Accuracy: 9499/10000 (94.99%)
torch.Size([100, 10])
Test set: Average loss: 0.1865, Accuracy: 9499/10000 (94.99%)

Epoch: 199
Loss: 0.008 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.783% (6450/6464)
Loss: 0.007 | Acc: 99.813% (12840/12864)
Loss: 0.007 | Acc: 99.824% (19230/19264)
Loss: 0.007 | Acc: 99.832% (25621/25664)
Loss: 0.007 | Acc: 99.835% (32011/32064)
Loss: 0.007 | Acc: 99.839% (38402/38464)
Loss: 0.007 | Acc: 99.846% (44795/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1865, Accuracy: 9493/10000 (94.93%)
torch.Size([100, 10])
Test set: Average loss: 0.1865, Accuracy: 9493/10000 (94.93%)
9570
10000
-0.14071881771087646
