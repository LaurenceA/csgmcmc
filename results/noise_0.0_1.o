==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.361 | Acc: 15.625% (10/64)
Loss: 2.815 | Acc: 16.801% (1086/6464)
Loss: 2.414 | Acc: 20.017% (2575/12864)
Loss: 2.251 | Acc: 22.301% (4296/19264)
Loss: 2.151 | Acc: 24.209% (6213/25664)
Loss: 2.072 | Acc: 26.129% (8378/32064)
Loss: 2.008 | Acc: 27.935% (10745/38464)
Loss: 1.955 | Acc: 29.549% (13257/44864)
torch.Size([100, 10])
Test set: Average loss: 3.0159, Accuracy: 2250/10000 (22.50%)

Epoch: 1
Loss: 2.073 | Acc: 34.375% (22/64)
Loss: 1.545 | Acc: 42.435% (2743/6464)
Loss: 1.525 | Acc: 43.330% (5574/12864)
Loss: 1.511 | Acc: 43.719% (8422/19264)
Loss: 1.494 | Acc: 44.635% (11455/25664)
Loss: 1.469 | Acc: 45.796% (14684/32064)
Loss: 1.450 | Acc: 46.493% (17883/38464)
Loss: 1.428 | Acc: 47.388% (21260/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7301, Accuracy: 4448/10000 (44.48%)

Epoch: 2
Loss: 1.248 | Acc: 59.375% (38/64)
Loss: 1.221 | Acc: 55.848% (3610/6464)
Loss: 1.211 | Acc: 56.522% (7271/12864)
Loss: 1.185 | Acc: 57.408% (11059/19264)
Loss: 1.160 | Acc: 58.346% (14974/25664)
Loss: 1.141 | Acc: 59.154% (18967/32064)
Loss: 1.126 | Acc: 59.653% (22945/38464)
Loss: 1.111 | Acc: 60.211% (27013/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3078, Accuracy: 5461/10000 (54.61%)

Epoch: 3
Loss: 1.039 | Acc: 65.625% (42/64)
Loss: 0.975 | Acc: 65.347% (4224/6464)
Loss: 0.971 | Acc: 65.672% (8448/12864)
Loss: 0.952 | Acc: 66.326% (12777/19264)
Loss: 0.937 | Acc: 66.934% (17178/25664)
Loss: 0.923 | Acc: 67.471% (21634/32064)
Loss: 0.910 | Acc: 67.926% (26127/38464)
Loss: 0.899 | Acc: 68.335% (30658/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1786, Accuracy: 6092/10000 (60.92%)

Epoch: 4
Loss: 1.167 | Acc: 60.938% (39/64)
Loss: 0.767 | Acc: 73.700% (4764/6464)
Loss: 0.769 | Acc: 73.352% (9436/12864)
Loss: 0.764 | Acc: 73.505% (14160/19264)
Loss: 0.757 | Acc: 73.695% (18913/25664)
Loss: 0.751 | Acc: 73.937% (23707/32064)
Loss: 0.742 | Acc: 74.254% (28561/38464)
Loss: 0.736 | Acc: 74.543% (33443/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1116, Accuracy: 6323/10000 (63.23%)

Epoch: 5
Loss: 0.979 | Acc: 68.750% (44/64)
Loss: 0.656 | Acc: 77.754% (5026/6464)
Loss: 0.660 | Acc: 77.581% (9980/12864)
Loss: 0.656 | Acc: 77.798% (14987/19264)
Loss: 0.655 | Acc: 77.638% (19925/25664)
Loss: 0.651 | Acc: 77.732% (24924/32064)
Loss: 0.649 | Acc: 77.771% (29914/38464)
Loss: 0.647 | Acc: 77.782% (34896/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8862, Accuracy: 7071/10000 (70.71%)

Epoch: 6
Loss: 0.564 | Acc: 78.125% (50/64)
Loss: 0.600 | Acc: 79.425% (5134/6464)
Loss: 0.601 | Acc: 79.283% (10199/12864)
Loss: 0.597 | Acc: 79.366% (15289/19264)
Loss: 0.595 | Acc: 79.415% (20381/25664)
Loss: 0.591 | Acc: 79.581% (25517/32064)
Loss: 0.591 | Acc: 79.721% (30664/38464)
Loss: 0.590 | Acc: 79.783% (35794/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2364, Accuracy: 6299/10000 (62.99%)

Epoch: 7
Loss: 0.523 | Acc: 82.812% (53/64)
Loss: 0.542 | Acc: 81.405% (5262/6464)
Loss: 0.556 | Acc: 80.962% (10415/12864)
Loss: 0.554 | Acc: 81.027% (15609/19264)
Loss: 0.552 | Acc: 80.930% (20770/25664)
Loss: 0.552 | Acc: 80.979% (25965/32064)
Loss: 0.554 | Acc: 80.891% (31114/38464)
Loss: 0.554 | Acc: 80.907% (36298/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9229, Accuracy: 7136/10000 (71.36%)

Epoch: 8
Loss: 0.655 | Acc: 79.688% (51/64)
Loss: 0.540 | Acc: 81.621% (5276/6464)
Loss: 0.528 | Acc: 81.670% (10506/12864)
Loss: 0.522 | Acc: 81.966% (15790/19264)
Loss: 0.521 | Acc: 82.002% (21045/25664)
Loss: 0.519 | Acc: 82.092% (26322/32064)
Loss: 0.523 | Acc: 81.929% (31513/38464)
Loss: 0.521 | Acc: 81.965% (36773/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9122, Accuracy: 7159/10000 (71.59%)

Epoch: 9
Loss: 0.545 | Acc: 82.812% (53/64)
Loss: 0.499 | Acc: 83.153% (5375/6464)
Loss: 0.495 | Acc: 83.131% (10694/12864)
Loss: 0.503 | Acc: 82.693% (15930/19264)
Loss: 0.502 | Acc: 82.680% (21219/25664)
Loss: 0.498 | Acc: 82.878% (26574/32064)
Loss: 0.501 | Acc: 82.854% (31869/38464)
Loss: 0.498 | Acc: 83.006% (37240/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0195, Accuracy: 6687/10000 (66.87%)

Epoch: 10
Loss: 0.576 | Acc: 79.688% (51/64)
Loss: 0.481 | Acc: 83.524% (5399/6464)
Loss: 0.467 | Acc: 84.173% (10828/12864)
Loss: 0.477 | Acc: 83.840% (16151/19264)
Loss: 0.476 | Acc: 83.759% (21496/25664)
Loss: 0.471 | Acc: 83.814% (26874/32064)
Loss: 0.474 | Acc: 83.806% (32235/38464)
Loss: 0.475 | Acc: 83.769% (37582/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5974, Accuracy: 7992/10000 (79.92%)

Epoch: 11
Loss: 0.642 | Acc: 79.688% (51/64)
Loss: 0.452 | Acc: 84.777% (5480/6464)
Loss: 0.453 | Acc: 84.725% (10899/12864)
Loss: 0.451 | Acc: 84.738% (16324/19264)
Loss: 0.456 | Acc: 84.609% (21714/25664)
Loss: 0.456 | Acc: 84.621% (27133/32064)
Loss: 0.456 | Acc: 84.604% (32542/38464)
Loss: 0.457 | Acc: 84.544% (37930/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6437, Accuracy: 7957/10000 (79.57%)

Epoch: 12
Loss: 0.537 | Acc: 82.812% (53/64)
Loss: 0.428 | Acc: 85.458% (5524/6464)
Loss: 0.426 | Acc: 85.440% (10991/12864)
Loss: 0.431 | Acc: 85.107% (16395/19264)
Loss: 0.434 | Acc: 85.096% (21839/25664)
Loss: 0.437 | Acc: 84.930% (27232/32064)
Loss: 0.438 | Acc: 84.952% (32676/38464)
Loss: 0.439 | Acc: 84.908% (38093/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9808, Accuracy: 6978/10000 (69.78%)

Epoch: 13
Loss: 0.563 | Acc: 84.375% (54/64)
Loss: 0.422 | Acc: 85.458% (5524/6464)
Loss: 0.425 | Acc: 85.541% (11004/12864)
Loss: 0.427 | Acc: 85.216% (16416/19264)
Loss: 0.426 | Acc: 85.353% (21905/25664)
Loss: 0.423 | Acc: 85.442% (27396/32064)
Loss: 0.423 | Acc: 85.503% (32888/38464)
Loss: 0.422 | Acc: 85.518% (38367/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0456, Accuracy: 5243/10000 (52.43%)

Epoch: 14
Loss: 0.925 | Acc: 67.188% (43/64)
Loss: 0.428 | Acc: 84.963% (5492/6464)
Loss: 0.414 | Acc: 85.627% (11015/12864)
Loss: 0.415 | Acc: 85.725% (16514/19264)
Loss: 0.412 | Acc: 85.860% (22035/25664)
Loss: 0.404 | Acc: 86.100% (27607/32064)
Loss: 0.407 | Acc: 85.961% (33064/38464)
Loss: 0.405 | Acc: 85.982% (38575/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5870, Accuracy: 5596/10000 (55.96%)

Epoch: 15
Loss: 0.885 | Acc: 67.188% (43/64)
Loss: 0.402 | Acc: 86.448% (5588/6464)
Loss: 0.390 | Acc: 86.762% (11161/12864)
Loss: 0.395 | Acc: 86.602% (16683/19264)
Loss: 0.390 | Acc: 86.803% (22277/25664)
Loss: 0.391 | Acc: 86.677% (27792/32064)
Loss: 0.391 | Acc: 86.665% (33335/38464)
Loss: 0.392 | Acc: 86.593% (38849/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3072, Accuracy: 6634/10000 (66.34%)

Epoch: 16
Loss: 0.542 | Acc: 81.250% (52/64)
Loss: 0.363 | Acc: 87.500% (5656/6464)
Loss: 0.369 | Acc: 87.189% (11216/12864)
Loss: 0.370 | Acc: 87.142% (16787/19264)
Loss: 0.376 | Acc: 86.845% (22288/25664)
Loss: 0.374 | Acc: 86.995% (27894/32064)
Loss: 0.375 | Acc: 86.985% (33458/38464)
Loss: 0.375 | Acc: 87.001% (39032/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8353, Accuracy: 7446/10000 (74.46%)

Epoch: 17
Loss: 0.431 | Acc: 82.812% (53/64)
Loss: 0.342 | Acc: 87.902% (5682/6464)
Loss: 0.361 | Acc: 87.391% (11242/12864)
Loss: 0.364 | Acc: 87.516% (16859/19264)
Loss: 0.364 | Acc: 87.539% (22466/25664)
Loss: 0.362 | Acc: 87.606% (28090/32064)
Loss: 0.364 | Acc: 87.523% (33665/38464)
Loss: 0.364 | Acc: 87.562% (39284/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6035, Accuracy: 8045/10000 (80.45%)

Epoch: 18
Loss: 0.559 | Acc: 82.812% (53/64)
Loss: 0.344 | Acc: 87.949% (5685/6464)
Loss: 0.342 | Acc: 88.145% (11339/12864)
Loss: 0.341 | Acc: 88.284% (17007/19264)
Loss: 0.342 | Acc: 88.260% (22651/25664)
Loss: 0.344 | Acc: 88.252% (28297/32064)
Loss: 0.349 | Acc: 87.986% (33843/38464)
Loss: 0.353 | Acc: 87.874% (39424/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5271, Accuracy: 8294/10000 (82.94%)

Epoch: 19
Loss: 0.283 | Acc: 87.500% (56/64)
Loss: 0.331 | Acc: 87.794% (5675/6464)
Loss: 0.331 | Acc: 88.262% (11354/12864)
Loss: 0.327 | Acc: 88.507% (17050/19264)
Loss: 0.330 | Acc: 88.412% (22690/25664)
Loss: 0.331 | Acc: 88.433% (28355/32064)
Loss: 0.333 | Acc: 88.426% (34012/38464)
Loss: 0.335 | Acc: 88.387% (39654/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9722, Accuracy: 7092/10000 (70.92%)

Epoch: 20
Loss: 0.305 | Acc: 85.938% (55/64)
Loss: 0.307 | Acc: 89.434% (5781/6464)
Loss: 0.316 | Acc: 89.171% (11471/12864)
Loss: 0.318 | Acc: 89.265% (17196/19264)
Loss: 0.318 | Acc: 89.269% (22910/25664)
Loss: 0.320 | Acc: 89.165% (28590/32064)
Loss: 0.320 | Acc: 89.166% (34297/38464)
Loss: 0.318 | Acc: 89.216% (40026/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6084, Accuracy: 5744/10000 (57.44%)

Epoch: 21
Loss: 0.446 | Acc: 85.938% (55/64)
Loss: 0.323 | Acc: 88.923% (5748/6464)
Loss: 0.323 | Acc: 89.078% (11459/12864)
Loss: 0.320 | Acc: 89.099% (17164/19264)
Loss: 0.323 | Acc: 88.969% (22833/25664)
Loss: 0.318 | Acc: 89.150% (28585/32064)
Loss: 0.317 | Acc: 89.156% (34293/38464)
Loss: 0.314 | Acc: 89.214% (40025/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5183, Accuracy: 8257/10000 (82.57%)

Epoch: 22
Loss: 0.263 | Acc: 89.062% (57/64)
Loss: 0.274 | Acc: 90.486% (5849/6464)
Loss: 0.292 | Acc: 89.863% (11560/12864)
Loss: 0.297 | Acc: 89.685% (17277/19264)
Loss: 0.299 | Acc: 89.616% (22999/25664)
Loss: 0.301 | Acc: 89.565% (28718/32064)
Loss: 0.300 | Acc: 89.616% (34470/38464)
Loss: 0.301 | Acc: 89.626% (40210/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6384, Accuracy: 8088/10000 (80.88%)

Epoch: 23
Loss: 0.349 | Acc: 89.062% (57/64)
Loss: 0.257 | Acc: 90.826% (5871/6464)
Loss: 0.277 | Acc: 90.532% (11646/12864)
Loss: 0.277 | Acc: 90.490% (17432/19264)
Loss: 0.282 | Acc: 90.399% (23200/25664)
Loss: 0.285 | Acc: 90.298% (28953/32064)
Loss: 0.283 | Acc: 90.394% (34769/38464)
Loss: 0.285 | Acc: 90.293% (40509/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2595, Accuracy: 6657/10000 (66.57%)

Epoch: 24
Loss: 0.504 | Acc: 81.250% (52/64)
Loss: 0.298 | Acc: 89.697% (5798/6464)
Loss: 0.294 | Acc: 89.840% (11557/12864)
Loss: 0.286 | Acc: 90.194% (17375/19264)
Loss: 0.284 | Acc: 90.305% (23176/25664)
Loss: 0.283 | Acc: 90.419% (28992/32064)
Loss: 0.283 | Acc: 90.375% (34762/38464)
Loss: 0.284 | Acc: 90.355% (40537/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9521, Accuracy: 7362/10000 (73.62%)

Epoch: 25
Loss: 0.292 | Acc: 92.188% (59/64)
Loss: 0.254 | Acc: 91.460% (5912/6464)
Loss: 0.265 | Acc: 90.998% (11706/12864)
Loss: 0.263 | Acc: 90.968% (17524/19264)
Loss: 0.258 | Acc: 91.038% (23364/25664)
Loss: 0.258 | Acc: 91.105% (29212/32064)
Loss: 0.261 | Acc: 91.038% (35017/38464)
Loss: 0.264 | Acc: 90.930% (40795/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2792, Accuracy: 6739/10000 (67.39%)

Epoch: 26
Loss: 0.386 | Acc: 81.250% (52/64)
Loss: 0.239 | Acc: 91.631% (5923/6464)
Loss: 0.242 | Acc: 91.643% (11789/12864)
Loss: 0.242 | Acc: 91.611% (17648/19264)
Loss: 0.244 | Acc: 91.533% (23491/25664)
Loss: 0.247 | Acc: 91.514% (29343/32064)
Loss: 0.247 | Acc: 91.506% (35197/38464)
Loss: 0.245 | Acc: 91.581% (41087/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4022, Accuracy: 8661/10000 (86.61%)

Epoch: 27
Loss: 0.313 | Acc: 84.375% (54/64)
Loss: 0.229 | Acc: 92.017% (5948/6464)
Loss: 0.233 | Acc: 91.962% (11830/12864)
Loss: 0.237 | Acc: 91.819% (17688/19264)
Loss: 0.239 | Acc: 91.786% (23556/25664)
Loss: 0.239 | Acc: 91.804% (29436/32064)
Loss: 0.239 | Acc: 91.777% (35301/38464)
Loss: 0.237 | Acc: 91.907% (41233/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6440, Accuracy: 8052/10000 (80.52%)

Epoch: 28
Loss: 0.596 | Acc: 79.688% (51/64)
Loss: 0.215 | Acc: 92.358% (5970/6464)
Loss: 0.220 | Acc: 92.343% (11879/12864)
Loss: 0.216 | Acc: 92.535% (17826/19264)
Loss: 0.217 | Acc: 92.456% (23728/25664)
Loss: 0.219 | Acc: 92.428% (29636/32064)
Loss: 0.221 | Acc: 92.411% (35545/38464)
Loss: 0.219 | Acc: 92.477% (41489/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7531, Accuracy: 7938/10000 (79.38%)

Epoch: 29
Loss: 0.139 | Acc: 92.188% (59/64)
Loss: 0.209 | Acc: 92.497% (5979/6464)
Loss: 0.210 | Acc: 92.724% (11928/12864)
Loss: 0.207 | Acc: 92.857% (17888/19264)
Loss: 0.206 | Acc: 92.994% (23866/25664)
Loss: 0.205 | Acc: 93.020% (29826/32064)
Loss: 0.207 | Acc: 92.983% (35765/38464)
Loss: 0.207 | Acc: 92.945% (41699/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3661, Accuracy: 8764/10000 (87.64%)

Epoch: 30
Loss: 0.179 | Acc: 95.312% (61/64)
Loss: 0.190 | Acc: 93.502% (6044/6464)
Loss: 0.182 | Acc: 93.890% (12078/12864)
Loss: 0.192 | Acc: 93.589% (18029/19264)
Loss: 0.194 | Acc: 93.477% (23990/25664)
Loss: 0.193 | Acc: 93.507% (29982/32064)
Loss: 0.193 | Acc: 93.516% (35970/38464)
Loss: 0.195 | Acc: 93.471% (41935/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7383, Accuracy: 8038/10000 (80.38%)

Epoch: 31
Loss: 0.236 | Acc: 89.062% (57/64)
Loss: 0.173 | Acc: 94.059% (6080/6464)
Loss: 0.173 | Acc: 94.123% (12108/12864)
Loss: 0.176 | Acc: 94.036% (18115/19264)
Loss: 0.175 | Acc: 94.120% (24155/25664)
Loss: 0.176 | Acc: 94.081% (30166/32064)
Loss: 0.175 | Acc: 94.070% (36183/38464)
Loss: 0.177 | Acc: 94.011% (42177/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2958, Accuracy: 9039/10000 (90.39%)

Epoch: 32
Loss: 0.174 | Acc: 96.875% (62/64)
Loss: 0.144 | Acc: 95.127% (6149/6464)
Loss: 0.154 | Acc: 94.652% (12176/12864)
Loss: 0.153 | Acc: 94.757% (18254/19264)
Loss: 0.159 | Acc: 94.529% (24260/25664)
Loss: 0.162 | Acc: 94.396% (30267/32064)
Loss: 0.163 | Acc: 94.319% (36279/38464)
Loss: 0.163 | Acc: 94.327% (42319/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4590, Accuracy: 8597/10000 (85.97%)

Epoch: 33
Loss: 0.062 | Acc: 98.438% (63/64)
Loss: 0.152 | Acc: 94.864% (6132/6464)
Loss: 0.142 | Acc: 95.180% (12244/12864)
Loss: 0.142 | Acc: 95.178% (18335/19264)
Loss: 0.145 | Acc: 95.067% (24398/25664)
Loss: 0.144 | Acc: 95.107% (30495/32064)
Loss: 0.145 | Acc: 95.068% (36567/38464)
Loss: 0.145 | Acc: 95.105% (42668/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4197, Accuracy: 8750/10000 (87.50%)

Epoch: 34
Loss: 0.135 | Acc: 95.312% (61/64)
Loss: 0.139 | Acc: 95.173% (6152/6464)
Loss: 0.137 | Acc: 95.180% (12244/12864)
Loss: 0.132 | Acc: 95.427% (18383/19264)
Loss: 0.132 | Acc: 95.496% (24508/25664)
Loss: 0.131 | Acc: 95.525% (30629/32064)
Loss: 0.130 | Acc: 95.505% (36735/38464)
Loss: 0.130 | Acc: 95.511% (42850/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2777, Accuracy: 9163/10000 (91.63%)

Epoch: 35
Loss: 0.041 | Acc: 100.000% (64/64)
Loss: 0.121 | Acc: 96.071% (6210/6464)
Loss: 0.115 | Acc: 96.113% (12364/12864)
Loss: 0.111 | Acc: 96.278% (18547/19264)
Loss: 0.110 | Acc: 96.294% (24713/25664)
Loss: 0.110 | Acc: 96.289% (30874/32064)
Loss: 0.114 | Acc: 96.191% (36999/38464)
Loss: 0.116 | Acc: 96.081% (43106/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3129, Accuracy: 9076/10000 (90.76%)

Epoch: 36
Loss: 0.147 | Acc: 92.188% (59/64)
Loss: 0.094 | Acc: 96.952% (6267/6464)
Loss: 0.096 | Acc: 96.867% (12461/12864)
Loss: 0.095 | Acc: 96.901% (18667/19264)
Loss: 0.096 | Acc: 96.813% (24846/25664)
Loss: 0.097 | Acc: 96.772% (31029/32064)
Loss: 0.097 | Acc: 96.755% (37216/38464)
Loss: 0.097 | Acc: 96.746% (43404/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2480, Accuracy: 9234/10000 (92.34%)

Epoch: 37
Loss: 0.069 | Acc: 96.875% (62/64)
Loss: 0.081 | Acc: 97.293% (6289/6464)
Loss: 0.081 | Acc: 97.303% (12517/12864)
Loss: 0.079 | Acc: 97.399% (18763/19264)
Loss: 0.081 | Acc: 97.339% (24981/25664)
Loss: 0.084 | Acc: 97.196% (31165/32064)
Loss: 0.085 | Acc: 97.153% (37369/38464)
Loss: 0.085 | Acc: 97.147% (43584/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2311, Accuracy: 9286/10000 (92.86%)

Epoch: 38
Loss: 0.070 | Acc: 100.000% (64/64)
Loss: 0.070 | Acc: 97.679% (6314/6464)
Loss: 0.065 | Acc: 97.893% (12593/12864)
Loss: 0.064 | Acc: 97.934% (18866/19264)
Loss: 0.064 | Acc: 97.939% (25135/25664)
Loss: 0.066 | Acc: 97.889% (31387/32064)
Loss: 0.067 | Acc: 97.819% (37625/38464)
Loss: 0.067 | Acc: 97.827% (43889/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2410, Accuracy: 9272/10000 (92.72%)

Epoch: 39
Loss: 0.025 | Acc: 100.000% (64/64)
Loss: 0.059 | Acc: 98.051% (6338/6464)
Loss: 0.056 | Acc: 98.189% (12631/12864)
Loss: 0.054 | Acc: 98.194% (18916/19264)
Loss: 0.055 | Acc: 98.188% (25199/25664)
Loss: 0.054 | Acc: 98.197% (31486/32064)
Loss: 0.054 | Acc: 98.211% (37776/38464)
Loss: 0.055 | Acc: 98.161% (44039/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3319, Accuracy: 9047/10000 (90.47%)

Epoch: 40
Loss: 0.091 | Acc: 96.875% (62/64)
Loss: 0.049 | Acc: 98.561% (6371/6464)
Loss: 0.046 | Acc: 98.609% (12685/12864)
Loss: 0.045 | Acc: 98.614% (18997/19264)
Loss: 0.047 | Acc: 98.535% (25288/25664)
Loss: 0.046 | Acc: 98.544% (31597/32064)
Loss: 0.044 | Acc: 98.614% (37931/38464)
Loss: 0.045 | Acc: 98.580% (44227/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2268, Accuracy: 9374/10000 (93.74%)

Epoch: 41
Loss: 0.037 | Acc: 98.438% (63/64)
Loss: 0.029 | Acc: 99.134% (6408/6464)
Loss: 0.032 | Acc: 99.036% (12740/12864)
Loss: 0.032 | Acc: 98.998% (19071/19264)
Loss: 0.033 | Acc: 98.971% (25400/25664)
Loss: 0.032 | Acc: 98.977% (31736/32064)
Loss: 0.033 | Acc: 98.970% (38068/38464)
Loss: 0.033 | Acc: 98.961% (44398/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2125, Accuracy: 9413/10000 (94.13%)

Epoch: 42
Loss: 0.021 | Acc: 100.000% (64/64)
Loss: 0.023 | Acc: 99.412% (6426/6464)
Loss: 0.024 | Acc: 99.331% (12778/12864)
Loss: 0.025 | Acc: 99.310% (19131/19264)
Loss: 0.025 | Acc: 99.283% (25480/25664)
Loss: 0.025 | Acc: 99.283% (31834/32064)
Loss: 0.025 | Acc: 99.269% (38183/38464)
Loss: 0.025 | Acc: 99.271% (44537/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2161, Accuracy: 9378/10000 (93.78%)

Epoch: 43
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 0.019 | Acc: 99.443% (6428/6464)
Loss: 0.020 | Acc: 99.440% (12792/12864)
Loss: 0.019 | Acc: 99.450% (19158/19264)
Loss: 0.020 | Acc: 99.396% (25509/25664)
Loss: 0.020 | Acc: 99.426% (31880/32064)
Loss: 0.020 | Acc: 99.410% (38237/38464)
Loss: 0.019 | Acc: 99.420% (44604/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2440, Accuracy: 9354/10000 (93.54%)

Epoch: 44
Loss: 0.029 | Acc: 100.000% (64/64)
Loss: 0.016 | Acc: 99.520% (6433/6464)
Loss: 0.015 | Acc: 99.596% (12812/12864)
Loss: 0.015 | Acc: 99.626% (19192/19264)
Loss: 0.015 | Acc: 99.618% (25566/25664)
Loss: 0.016 | Acc: 99.582% (31930/32064)
Loss: 0.016 | Acc: 99.563% (38296/38464)
Loss: 0.016 | Acc: 99.588% (44679/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2106, Accuracy: 9426/10000 (94.26%)

Epoch: 45
Loss: 0.015 | Acc: 100.000% (64/64)
Loss: 0.019 | Acc: 99.582% (6437/6464)
Loss: 0.030 | Acc: 99.347% (12780/12864)
Loss: 0.042 | Acc: 99.055% (19082/19264)
Loss: 0.055 | Acc: 98.765% (25347/25664)
Loss: 0.070 | Acc: 98.456% (31569/32064)
Loss: 0.082 | Acc: 98.149% (37752/38464)
Loss: 0.094 | Acc: 97.865% (43906/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2683, Accuracy: 9149/10000 (91.49%)

Epoch: 46
Loss: 0.173 | Acc: 95.312% (61/64)
Loss: 0.188 | Acc: 95.514% (6174/6464)
Loss: 0.196 | Acc: 95.243% (12252/12864)
Loss: 0.202 | Acc: 94.887% (18279/19264)
Loss: 0.209 | Acc: 94.564% (24269/25664)
Loss: 0.213 | Acc: 94.427% (30277/32064)
Loss: 0.217 | Acc: 94.241% (36249/38464)
Loss: 0.221 | Acc: 94.078% (42207/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3068, Accuracy: 8999/10000 (89.99%)

Epoch: 47
Loss: 0.162 | Acc: 96.875% (62/64)
Loss: 0.251 | Acc: 92.683% (5991/6464)
Loss: 0.253 | Acc: 92.662% (11920/12864)
Loss: 0.253 | Acc: 92.707% (17859/19264)
Loss: 0.256 | Acc: 92.675% (23784/25664)
Loss: 0.259 | Acc: 92.587% (29687/32064)
Loss: 0.260 | Acc: 92.494% (35577/38464)
Loss: 0.262 | Acc: 92.475% (41488/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3298, Accuracy: 8930/10000 (89.30%)
torch.Size([100, 10])
Test set: Average loss: 0.3298, Accuracy: 8930/10000 (89.30%)

Epoch: 48
Loss: 0.236 | Acc: 93.750% (60/64)
Loss: 0.274 | Acc: 92.249% (5963/6464)
Loss: 0.275 | Acc: 92.094% (11847/12864)
Loss: 0.274 | Acc: 91.975% (17718/19264)
Loss: 0.275 | Acc: 91.962% (23601/25664)
Loss: 0.277 | Acc: 91.826% (29443/32064)
Loss: 0.277 | Acc: 91.798% (35309/38464)
Loss: 0.278 | Acc: 91.822% (41195/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3273, Accuracy: 8922/10000 (89.22%)
torch.Size([100, 10])
Test set: Average loss: 0.3273, Accuracy: 8922/10000 (89.22%)

Epoch: 49
Loss: 0.246 | Acc: 95.312% (61/64)
Loss: 0.281 | Acc: 91.894% (5940/6464)
Loss: 0.285 | Acc: 91.604% (11784/12864)
Loss: 0.280 | Acc: 91.788% (17682/19264)
Loss: 0.280 | Acc: 91.837% (23569/25664)
Loss: 0.279 | Acc: 91.854% (29452/32064)
Loss: 0.279 | Acc: 91.852% (35330/38464)
Loss: 0.279 | Acc: 91.864% (41214/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3291, Accuracy: 8927/10000 (89.27%)
torch.Size([100, 10])
Test set: Average loss: 0.3291, Accuracy: 8927/10000 (89.27%)

Epoch: 50
Loss: 0.400 | Acc: 85.938% (55/64)
Loss: 2.093 | Acc: 24.969% (1614/6464)
Loss: 1.862 | Acc: 32.160% (4137/12864)
Loss: 1.683 | Acc: 38.751% (7465/19264)
Loss: 1.539 | Acc: 44.058% (11307/25664)
Loss: 1.423 | Acc: 48.394% (15517/32064)
Loss: 1.327 | Acc: 52.192% (20075/38464)
Loss: 1.243 | Acc: 55.416% (24862/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4304, Accuracy: 5865/10000 (58.65%)

Epoch: 51
Loss: 1.031 | Acc: 70.312% (45/64)
Loss: 0.644 | Acc: 78.218% (5056/6464)
Loss: 0.625 | Acc: 78.692% (10123/12864)
Loss: 0.608 | Acc: 79.335% (15283/19264)
Loss: 0.596 | Acc: 79.769% (20472/25664)
Loss: 0.585 | Acc: 80.099% (25683/32064)
Loss: 0.573 | Acc: 80.522% (30972/38464)
Loss: 0.565 | Acc: 80.786% (36244/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9849, Accuracy: 4598/10000 (45.98%)

Epoch: 52
Loss: 0.752 | Acc: 70.312% (45/64)
Loss: 0.486 | Acc: 83.431% (5393/6464)
Loss: 0.476 | Acc: 83.621% (10757/12864)
Loss: 0.471 | Acc: 83.752% (16134/19264)
Loss: 0.470 | Acc: 83.919% (21537/25664)
Loss: 0.467 | Acc: 84.051% (26950/32064)
Loss: 0.464 | Acc: 84.032% (32322/38464)
Loss: 0.461 | Acc: 84.145% (37751/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8757, Accuracy: 7406/10000 (74.06%)

Epoch: 53
Loss: 0.527 | Acc: 78.125% (50/64)
Loss: 0.416 | Acc: 86.015% (5560/6464)
Loss: 0.411 | Acc: 86.085% (11074/12864)
Loss: 0.416 | Acc: 85.880% (16544/19264)
Loss: 0.416 | Acc: 85.782% (22015/25664)
Loss: 0.418 | Acc: 85.710% (27482/32064)
Loss: 0.418 | Acc: 85.693% (32961/38464)
Loss: 0.420 | Acc: 85.659% (38430/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4423, Accuracy: 5981/10000 (59.81%)

Epoch: 54
Loss: 0.542 | Acc: 84.375% (54/64)
Loss: 0.401 | Acc: 86.139% (5568/6464)
Loss: 0.394 | Acc: 86.241% (11094/12864)
Loss: 0.392 | Acc: 86.384% (16641/19264)
Loss: 0.397 | Acc: 86.366% (22165/25664)
Loss: 0.401 | Acc: 86.190% (27636/32064)
Loss: 0.404 | Acc: 86.070% (33106/38464)
Loss: 0.404 | Acc: 86.114% (38634/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7232, Accuracy: 7686/10000 (76.86%)

Epoch: 55
Loss: 0.453 | Acc: 84.375% (54/64)
Loss: 0.390 | Acc: 86.757% (5608/6464)
Loss: 0.384 | Acc: 86.948% (11185/12864)
Loss: 0.382 | Acc: 87.038% (16767/19264)
Loss: 0.387 | Acc: 86.849% (22289/25664)
Loss: 0.385 | Acc: 86.858% (27850/32064)
Loss: 0.387 | Acc: 86.803% (33388/38464)
Loss: 0.386 | Acc: 86.834% (38957/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9350, Accuracy: 7143/10000 (71.43%)

Epoch: 56
Loss: 0.284 | Acc: 90.625% (58/64)
Loss: 0.368 | Acc: 87.809% (5676/6464)
Loss: 0.373 | Acc: 87.422% (11246/12864)
Loss: 0.374 | Acc: 87.334% (16824/19264)
Loss: 0.371 | Acc: 87.449% (22443/25664)
Loss: 0.372 | Acc: 87.425% (28032/32064)
Loss: 0.376 | Acc: 87.292% (33576/38464)
Loss: 0.378 | Acc: 87.188% (39116/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5456, Accuracy: 8207/10000 (82.07%)

Epoch: 57
Loss: 0.505 | Acc: 79.688% (51/64)
Loss: 0.366 | Acc: 87.871% (5680/6464)
Loss: 0.357 | Acc: 87.873% (11304/12864)
Loss: 0.360 | Acc: 87.817% (16917/19264)
Loss: 0.361 | Acc: 87.870% (22551/25664)
Loss: 0.365 | Acc: 87.731% (28130/32064)
Loss: 0.366 | Acc: 87.648% (33713/38464)
Loss: 0.367 | Acc: 87.589% (39296/44864)
torch.Size([100, 10])
Test set: Average loss: 3.1268, Accuracy: 4428/10000 (44.28%)

Epoch: 58
Loss: 0.846 | Acc: 71.875% (46/64)
Loss: 0.361 | Acc: 88.243% (5704/6464)
Loss: 0.357 | Acc: 88.176% (11343/12864)
Loss: 0.357 | Acc: 88.123% (16976/19264)
Loss: 0.359 | Acc: 88.010% (22587/25664)
Loss: 0.358 | Acc: 88.118% (28254/32064)
Loss: 0.362 | Acc: 87.877% (33801/38464)
Loss: 0.362 | Acc: 87.832% (39405/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6554, Accuracy: 7873/10000 (78.73%)

Epoch: 59
Loss: 0.195 | Acc: 92.188% (59/64)
Loss: 0.348 | Acc: 88.351% (5711/6464)
Loss: 0.350 | Acc: 88.153% (11340/12864)
Loss: 0.350 | Acc: 88.102% (16972/19264)
Loss: 0.348 | Acc: 88.116% (22614/25664)
Loss: 0.351 | Acc: 88.030% (28226/32064)
Loss: 0.353 | Acc: 87.971% (33837/38464)
Loss: 0.352 | Acc: 88.064% (39509/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4080, Accuracy: 8629/10000 (86.29%)

Epoch: 60
Loss: 0.257 | Acc: 92.188% (59/64)
Loss: 0.345 | Acc: 88.243% (5704/6464)
Loss: 0.348 | Acc: 88.005% (11321/12864)
Loss: 0.352 | Acc: 87.786% (16911/19264)
Loss: 0.350 | Acc: 87.886% (22555/25664)
Loss: 0.346 | Acc: 88.002% (28217/32064)
Loss: 0.346 | Acc: 88.064% (33873/38464)
Loss: 0.347 | Acc: 88.037% (39497/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8775, Accuracy: 7438/10000 (74.38%)

Epoch: 61
Loss: 0.382 | Acc: 89.062% (57/64)
Loss: 0.338 | Acc: 88.629% (5729/6464)
Loss: 0.339 | Acc: 88.736% (11415/12864)
Loss: 0.342 | Acc: 88.471% (17043/19264)
Loss: 0.341 | Acc: 88.490% (22710/25664)
Loss: 0.340 | Acc: 88.595% (28407/32064)
Loss: 0.339 | Acc: 88.615% (34085/38464)
Loss: 0.340 | Acc: 88.539% (39722/44864)
torch.Size([100, 10])
Test set: Average loss: 4.0010, Accuracy: 4060/10000 (40.60%)

Epoch: 62
Loss: 0.482 | Acc: 85.938% (55/64)
Loss: 0.316 | Acc: 89.805% (5805/6464)
Loss: 0.318 | Acc: 89.335% (11492/12864)
Loss: 0.321 | Acc: 89.083% (17161/19264)
Loss: 0.323 | Acc: 89.066% (22858/25664)
Loss: 0.327 | Acc: 88.925% (28513/32064)
Loss: 0.328 | Acc: 88.870% (34183/38464)
Loss: 0.332 | Acc: 88.742% (39813/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4847, Accuracy: 8424/10000 (84.24%)

Epoch: 63
Loss: 0.178 | Acc: 90.625% (58/64)
Loss: 0.311 | Acc: 89.449% (5782/6464)
Loss: 0.323 | Acc: 88.946% (11442/12864)
Loss: 0.318 | Acc: 89.094% (17163/19264)
Loss: 0.325 | Acc: 88.922% (22821/25664)
Loss: 0.324 | Acc: 89.025% (28545/32064)
Loss: 0.325 | Acc: 88.946% (34212/38464)
Loss: 0.327 | Acc: 88.911% (39889/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4627, Accuracy: 8525/10000 (85.25%)

Epoch: 64
Loss: 0.372 | Acc: 87.500% (56/64)
Loss: 0.316 | Acc: 89.434% (5781/6464)
Loss: 0.311 | Acc: 89.591% (11525/12864)
Loss: 0.314 | Acc: 89.436% (17229/19264)
Loss: 0.314 | Acc: 89.417% (22948/25664)
Loss: 0.314 | Acc: 89.396% (28664/32064)
Loss: 0.315 | Acc: 89.348% (34367/38464)
Loss: 0.319 | Acc: 89.194% (40016/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0986, Accuracy: 5668/10000 (56.68%)

Epoch: 65
Loss: 0.457 | Acc: 87.500% (56/64)
Loss: 0.331 | Acc: 88.923% (5748/6464)
Loss: 0.310 | Acc: 89.428% (11504/12864)
Loss: 0.309 | Acc: 89.332% (17209/19264)
Loss: 0.312 | Acc: 89.207% (22894/25664)
Loss: 0.312 | Acc: 89.200% (28601/32064)
Loss: 0.312 | Acc: 89.198% (34309/38464)
Loss: 0.312 | Acc: 89.219% (40027/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9965, Accuracy: 7424/10000 (74.24%)

Epoch: 66
Loss: 0.672 | Acc: 85.938% (55/64)
Loss: 0.292 | Acc: 90.362% (5841/6464)
Loss: 0.297 | Acc: 89.887% (11563/12864)
Loss: 0.304 | Acc: 89.727% (17285/19264)
Loss: 0.305 | Acc: 89.616% (22999/25664)
Loss: 0.301 | Acc: 89.783% (28788/32064)
Loss: 0.302 | Acc: 89.790% (34537/38464)
Loss: 0.303 | Acc: 89.776% (40277/44864)
torch.Size([100, 10])
Test set: Average loss: 3.3631, Accuracy: 3621/10000 (36.21%)

Epoch: 67
Loss: 0.382 | Acc: 85.938% (55/64)
Loss: 0.296 | Acc: 89.960% (5815/6464)
Loss: 0.290 | Acc: 90.205% (11604/12864)
Loss: 0.287 | Acc: 90.246% (17385/19264)
Loss: 0.290 | Acc: 90.146% (23135/25664)
Loss: 0.293 | Acc: 90.020% (28864/32064)
Loss: 0.296 | Acc: 89.902% (34580/38464)
Loss: 0.298 | Acc: 89.865% (40317/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6737, Accuracy: 7915/10000 (79.15%)

Epoch: 68
Loss: 0.261 | Acc: 89.062% (57/64)
Loss: 0.304 | Acc: 89.712% (5799/6464)
Loss: 0.291 | Acc: 89.949% (11571/12864)
Loss: 0.290 | Acc: 89.981% (17334/19264)
Loss: 0.293 | Acc: 89.818% (23051/25664)
Loss: 0.291 | Acc: 89.961% (28845/32064)
Loss: 0.289 | Acc: 90.017% (34624/38464)
Loss: 0.288 | Acc: 90.003% (40379/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1567, Accuracy: 6738/10000 (67.38%)

Epoch: 69
Loss: 0.384 | Acc: 84.375% (54/64)
Loss: 0.274 | Acc: 90.780% (5868/6464)
Loss: 0.273 | Acc: 90.672% (11664/12864)
Loss: 0.279 | Acc: 90.438% (17422/19264)
Loss: 0.280 | Acc: 90.380% (23195/25664)
Loss: 0.283 | Acc: 90.310% (28957/32064)
Loss: 0.282 | Acc: 90.308% (34736/38464)
Loss: 0.280 | Acc: 90.353% (40536/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2659, Accuracy: 5969/10000 (59.69%)

Epoch: 70
Loss: 0.287 | Acc: 89.062% (57/64)
Loss: 0.256 | Acc: 91.352% (5905/6464)
Loss: 0.262 | Acc: 91.107% (11720/12864)
Loss: 0.264 | Acc: 91.045% (17539/19264)
Loss: 0.261 | Acc: 91.155% (23394/25664)
Loss: 0.264 | Acc: 91.102% (29211/32064)
Loss: 0.269 | Acc: 90.875% (34954/38464)
Loss: 0.271 | Acc: 90.855% (40761/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6068, Accuracy: 8161/10000 (81.61%)

Epoch: 71
Loss: 0.502 | Acc: 81.250% (52/64)
Loss: 0.232 | Acc: 92.002% (5947/6464)
Loss: 0.258 | Acc: 91.216% (11734/12864)
Loss: 0.257 | Acc: 91.248% (17578/19264)
Loss: 0.258 | Acc: 91.272% (23424/25664)
Loss: 0.258 | Acc: 91.267% (29264/32064)
Loss: 0.260 | Acc: 91.241% (35095/38464)
Loss: 0.262 | Acc: 91.151% (40894/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8033, Accuracy: 7707/10000 (77.07%)

Epoch: 72
Loss: 0.366 | Acc: 84.375% (54/64)
Loss: 0.259 | Acc: 91.182% (5894/6464)
Loss: 0.254 | Acc: 91.395% (11757/12864)
Loss: 0.260 | Acc: 91.274% (17583/19264)
Loss: 0.262 | Acc: 91.132% (23388/25664)
Loss: 0.257 | Acc: 91.292% (29272/32064)
Loss: 0.256 | Acc: 91.317% (35124/38464)
Loss: 0.255 | Acc: 91.309% (40965/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5865, Accuracy: 8298/10000 (82.98%)

Epoch: 73
Loss: 0.207 | Acc: 92.188% (59/64)
Loss: 0.231 | Acc: 92.064% (5951/6464)
Loss: 0.238 | Acc: 91.853% (11816/12864)
Loss: 0.240 | Acc: 91.829% (17690/19264)
Loss: 0.239 | Acc: 91.856% (23574/25664)
Loss: 0.240 | Acc: 91.795% (29433/32064)
Loss: 0.239 | Acc: 91.808% (35313/38464)
Loss: 0.242 | Acc: 91.702% (41141/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7740, Accuracy: 7966/10000 (79.66%)

Epoch: 74
Loss: 0.281 | Acc: 89.062% (57/64)
Loss: 0.212 | Acc: 92.698% (5992/6464)
Loss: 0.213 | Acc: 92.856% (11945/12864)
Loss: 0.220 | Acc: 92.618% (17842/19264)
Loss: 0.222 | Acc: 92.577% (23759/25664)
Loss: 0.224 | Acc: 92.568% (29681/32064)
Loss: 0.228 | Acc: 92.385% (35535/38464)
Loss: 0.229 | Acc: 92.303% (41411/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1794, Accuracy: 7033/10000 (70.33%)

Epoch: 75
Loss: 0.329 | Acc: 90.625% (58/64)
Loss: 0.229 | Acc: 92.311% (5967/6464)
Loss: 0.218 | Acc: 92.592% (11911/12864)
Loss: 0.223 | Acc: 92.406% (17801/19264)
Loss: 0.222 | Acc: 92.417% (23718/25664)
Loss: 0.221 | Acc: 92.431% (29637/32064)
Loss: 0.220 | Acc: 92.447% (35559/38464)
Loss: 0.221 | Acc: 92.404% (41456/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2922, Accuracy: 9036/10000 (90.36%)

Epoch: 76
Loss: 0.187 | Acc: 93.750% (60/64)
Loss: 0.195 | Acc: 93.379% (6036/6464)
Loss: 0.196 | Acc: 93.299% (12002/12864)
Loss: 0.198 | Acc: 93.252% (17964/19264)
Loss: 0.204 | Acc: 93.006% (23869/25664)
Loss: 0.208 | Acc: 92.908% (29790/32064)
Loss: 0.213 | Acc: 92.715% (35662/38464)
Loss: 0.213 | Acc: 92.734% (41604/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3967, Accuracy: 8744/10000 (87.44%)

Epoch: 77
Loss: 0.243 | Acc: 90.625% (58/64)
Loss: 0.189 | Acc: 93.456% (6041/6464)
Loss: 0.188 | Acc: 93.431% (12019/12864)
Loss: 0.197 | Acc: 93.060% (17927/19264)
Loss: 0.198 | Acc: 92.982% (23863/25664)
Loss: 0.198 | Acc: 93.026% (29828/32064)
Loss: 0.199 | Acc: 93.004% (35773/38464)
Loss: 0.198 | Acc: 93.079% (41759/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3493, Accuracy: 8874/10000 (88.74%)

Epoch: 78
Loss: 0.133 | Acc: 93.750% (60/64)
Loss: 0.162 | Acc: 94.431% (6104/6464)
Loss: 0.173 | Acc: 94.022% (12095/12864)
Loss: 0.179 | Acc: 93.838% (18077/19264)
Loss: 0.183 | Acc: 93.695% (24046/25664)
Loss: 0.185 | Acc: 93.641% (30025/32064)
Loss: 0.186 | Acc: 93.610% (36006/38464)
Loss: 0.188 | Acc: 93.585% (41986/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4002, Accuracy: 8779/10000 (87.79%)

Epoch: 79
Loss: 0.099 | Acc: 98.438% (63/64)
Loss: 0.154 | Acc: 94.585% (6114/6464)
Loss: 0.158 | Acc: 94.543% (12162/12864)
Loss: 0.165 | Acc: 94.425% (18190/19264)
Loss: 0.168 | Acc: 94.264% (24192/25664)
Loss: 0.168 | Acc: 94.305% (30238/32064)
Loss: 0.168 | Acc: 94.299% (36271/38464)
Loss: 0.170 | Acc: 94.180% (42253/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0405, Accuracy: 7302/10000 (73.02%)

Epoch: 80
Loss: 0.609 | Acc: 79.688% (51/64)
Loss: 0.177 | Acc: 93.889% (6069/6464)
Loss: 0.169 | Acc: 94.201% (12118/12864)
Loss: 0.167 | Acc: 94.316% (18169/19264)
Loss: 0.166 | Acc: 94.315% (24205/25664)
Loss: 0.166 | Acc: 94.311% (30240/32064)
Loss: 0.165 | Acc: 94.345% (36289/38464)
Loss: 0.165 | Acc: 94.365% (42336/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4503, Accuracy: 8614/10000 (86.14%)

Epoch: 81
Loss: 0.104 | Acc: 95.312% (61/64)
Loss: 0.144 | Acc: 95.251% (6157/6464)
Loss: 0.146 | Acc: 95.149% (12240/12864)
Loss: 0.146 | Acc: 95.094% (18319/19264)
Loss: 0.145 | Acc: 95.106% (24408/25664)
Loss: 0.146 | Acc: 95.075% (30485/32064)
Loss: 0.149 | Acc: 94.928% (36513/38464)
Loss: 0.151 | Acc: 94.869% (42562/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2987, Accuracy: 9035/10000 (90.35%)

Epoch: 82
Loss: 0.192 | Acc: 93.750% (60/64)
Loss: 0.132 | Acc: 95.885% (6198/6464)
Loss: 0.133 | Acc: 95.787% (12322/12864)
Loss: 0.133 | Acc: 95.629% (18422/19264)
Loss: 0.131 | Acc: 95.679% (24555/25664)
Loss: 0.133 | Acc: 95.584% (30648/32064)
Loss: 0.133 | Acc: 95.559% (36756/38464)
Loss: 0.133 | Acc: 95.560% (42872/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2993, Accuracy: 9057/10000 (90.57%)

Epoch: 83
Loss: 0.151 | Acc: 96.875% (62/64)
Loss: 0.102 | Acc: 96.705% (6251/6464)
Loss: 0.107 | Acc: 96.463% (12409/12864)
Loss: 0.113 | Acc: 96.278% (18547/19264)
Loss: 0.113 | Acc: 96.283% (24710/25664)
Loss: 0.117 | Acc: 96.130% (30823/32064)
Loss: 0.117 | Acc: 96.072% (36953/38464)
Loss: 0.118 | Acc: 96.015% (43076/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2712, Accuracy: 9144/10000 (91.44%)

Epoch: 84
Loss: 0.117 | Acc: 95.312% (61/64)
Loss: 0.108 | Acc: 96.303% (6225/6464)
Loss: 0.101 | Acc: 96.541% (12419/12864)
Loss: 0.107 | Acc: 96.408% (18572/19264)
Loss: 0.106 | Acc: 96.392% (24738/25664)
Loss: 0.106 | Acc: 96.395% (30908/32064)
Loss: 0.106 | Acc: 96.402% (37080/38464)
Loss: 0.107 | Acc: 96.402% (43250/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3779, Accuracy: 8864/10000 (88.64%)

Epoch: 85
Loss: 0.069 | Acc: 96.875% (62/64)
Loss: 0.098 | Acc: 96.767% (6255/6464)
Loss: 0.093 | Acc: 96.875% (12462/12864)
Loss: 0.093 | Acc: 96.844% (18656/19264)
Loss: 0.094 | Acc: 96.809% (24845/25664)
Loss: 0.091 | Acc: 96.922% (31077/32064)
Loss: 0.092 | Acc: 96.904% (37273/38464)
Loss: 0.092 | Acc: 96.877% (43463/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3236, Accuracy: 9066/10000 (90.66%)

Epoch: 86
Loss: 0.019 | Acc: 100.000% (64/64)
Loss: 0.084 | Acc: 97.277% (6288/6464)
Loss: 0.077 | Acc: 97.582% (12553/12864)
Loss: 0.078 | Acc: 97.482% (18779/19264)
Loss: 0.079 | Acc: 97.401% (24997/25664)
Loss: 0.078 | Acc: 97.427% (31239/32064)
Loss: 0.077 | Acc: 97.450% (37483/38464)
Loss: 0.077 | Acc: 97.466% (43727/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2975, Accuracy: 9120/10000 (91.20%)

Epoch: 87
Loss: 0.045 | Acc: 98.438% (63/64)
Loss: 0.066 | Acc: 97.803% (6322/6464)
Loss: 0.065 | Acc: 97.808% (12582/12864)
Loss: 0.064 | Acc: 97.773% (18835/19264)
Loss: 0.065 | Acc: 97.787% (25096/25664)
Loss: 0.067 | Acc: 97.742% (31340/32064)
Loss: 0.067 | Acc: 97.743% (37596/38464)
Loss: 0.066 | Acc: 97.773% (43865/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2719, Accuracy: 9238/10000 (92.38%)

Epoch: 88
Loss: 0.070 | Acc: 98.438% (63/64)
Loss: 0.055 | Acc: 98.221% (6349/6464)
Loss: 0.053 | Acc: 98.266% (12641/12864)
Loss: 0.054 | Acc: 98.214% (18920/19264)
Loss: 0.053 | Acc: 98.262% (25218/25664)
Loss: 0.052 | Acc: 98.275% (31511/32064)
Loss: 0.052 | Acc: 98.250% (37791/38464)
Loss: 0.052 | Acc: 98.261% (44084/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2593, Accuracy: 9250/10000 (92.50%)

Epoch: 89
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.045 | Acc: 98.515% (6368/6464)
Loss: 0.048 | Acc: 98.368% (12654/12864)
Loss: 0.047 | Acc: 98.417% (18959/19264)
Loss: 0.047 | Acc: 98.422% (25259/25664)
Loss: 0.046 | Acc: 98.428% (31560/32064)
Loss: 0.045 | Acc: 98.471% (37876/38464)
Loss: 0.043 | Acc: 98.540% (44209/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2181, Accuracy: 9387/10000 (93.87%)

Epoch: 90
Loss: 0.034 | Acc: 98.438% (63/64)
Loss: 0.031 | Acc: 99.149% (6409/6464)
Loss: 0.030 | Acc: 99.153% (12755/12864)
Loss: 0.029 | Acc: 99.169% (19104/19264)
Loss: 0.030 | Acc: 99.073% (25426/25664)
Loss: 0.030 | Acc: 99.083% (31770/32064)
Loss: 0.030 | Acc: 99.064% (38104/38464)
Loss: 0.030 | Acc: 99.077% (44450/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2163, Accuracy: 9407/10000 (94.07%)

Epoch: 91
Loss: 0.009 | Acc: 100.000% (64/64)
Loss: 0.024 | Acc: 99.288% (6418/6464)
Loss: 0.026 | Acc: 99.168% (12757/12864)
Loss: 0.026 | Acc: 99.175% (19105/19264)
Loss: 0.026 | Acc: 99.217% (25463/25664)
Loss: 0.024 | Acc: 99.273% (31831/32064)
Loss: 0.024 | Acc: 99.275% (38185/38464)
Loss: 0.024 | Acc: 99.280% (44541/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1994, Accuracy: 9440/10000 (94.40%)

Epoch: 92
Loss: 0.046 | Acc: 96.875% (62/64)
Loss: 0.020 | Acc: 99.397% (6425/6464)
Loss: 0.018 | Acc: 99.440% (12792/12864)
Loss: 0.017 | Acc: 99.481% (19164/19264)
Loss: 0.017 | Acc: 99.525% (25542/25664)
Loss: 0.017 | Acc: 99.517% (31909/32064)
Loss: 0.017 | Acc: 99.522% (38280/38464)
Loss: 0.017 | Acc: 99.516% (44647/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2395, Accuracy: 9390/10000 (93.90%)

Epoch: 93
Loss: 0.008 | Acc: 100.000% (64/64)
Loss: 0.015 | Acc: 99.598% (6438/6464)
Loss: 0.015 | Acc: 99.596% (12812/12864)
Loss: 0.015 | Acc: 99.631% (19193/19264)
Loss: 0.015 | Acc: 99.599% (25561/25664)
Loss: 0.015 | Acc: 99.598% (31935/32064)
Loss: 0.015 | Acc: 99.618% (38317/38464)
Loss: 0.015 | Acc: 99.619% (44693/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2079, Accuracy: 9444/10000 (94.44%)

Epoch: 94
Loss: 0.061 | Acc: 98.438% (63/64)
Loss: 0.013 | Acc: 99.660% (6442/6464)
Loss: 0.013 | Acc: 99.674% (12822/12864)
Loss: 0.012 | Acc: 99.699% (19206/19264)
Loss: 0.012 | Acc: 99.708% (25589/25664)
Loss: 0.012 | Acc: 99.691% (31965/32064)
Loss: 0.012 | Acc: 99.696% (38347/38464)
Loss: 0.011 | Acc: 99.701% (44730/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2004, Accuracy: 9470/10000 (94.70%)

Epoch: 95
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.014 | Acc: 99.737% (6447/6464)
Loss: 0.022 | Acc: 99.479% (12797/12864)
Loss: 0.030 | Acc: 99.367% (19142/19264)
Loss: 0.039 | Acc: 99.143% (25444/25664)
Loss: 0.049 | Acc: 98.902% (31712/32064)
Loss: 0.059 | Acc: 98.666% (37951/38464)
Loss: 0.069 | Acc: 98.451% (44169/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2586, Accuracy: 9148/10000 (91.48%)

Epoch: 96
Loss: 0.106 | Acc: 100.000% (64/64)
Loss: 0.160 | Acc: 96.132% (6214/6464)
Loss: 0.162 | Acc: 96.082% (12360/12864)
Loss: 0.167 | Acc: 95.873% (18469/19264)
Loss: 0.172 | Acc: 95.792% (24584/25664)
Loss: 0.176 | Acc: 95.634% (30664/32064)
Loss: 0.179 | Acc: 95.528% (36744/38464)
Loss: 0.185 | Acc: 95.301% (42756/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2929, Accuracy: 9060/10000 (90.60%)

Epoch: 97
Loss: 0.178 | Acc: 95.312% (61/64)
Loss: 0.216 | Acc: 93.920% (6071/6464)
Loss: 0.213 | Acc: 94.178% (12115/12864)
Loss: 0.213 | Acc: 94.217% (18150/19264)
Loss: 0.219 | Acc: 94.042% (24135/25664)
Loss: 0.222 | Acc: 93.881% (30102/32064)
Loss: 0.224 | Acc: 93.844% (36096/38464)
Loss: 0.225 | Acc: 93.779% (42073/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3074, Accuracy: 8983/10000 (89.83%)
torch.Size([100, 10])
Test set: Average loss: 0.3074, Accuracy: 8983/10000 (89.83%)

Epoch: 98
Loss: 0.197 | Acc: 96.875% (62/64)
Loss: 0.233 | Acc: 93.595% (6050/6464)
Loss: 0.232 | Acc: 93.501% (12028/12864)
Loss: 0.234 | Acc: 93.350% (17983/19264)
Loss: 0.235 | Acc: 93.243% (23930/25664)
Loss: 0.235 | Acc: 93.245% (29898/32064)
Loss: 0.236 | Acc: 93.204% (35850/38464)
Loss: 0.234 | Acc: 93.309% (41862/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3090, Accuracy: 8957/10000 (89.57%)
torch.Size([100, 10])
Test set: Average loss: 0.3090, Accuracy: 8957/10000 (89.57%)

Epoch: 99
Loss: 0.158 | Acc: 98.438% (63/64)
Loss: 0.230 | Acc: 93.472% (6042/6464)
Loss: 0.234 | Acc: 93.307% (12003/12864)
Loss: 0.236 | Acc: 93.195% (17953/19264)
Loss: 0.236 | Acc: 93.251% (23932/25664)
Loss: 0.233 | Acc: 93.398% (29947/32064)
Loss: 0.235 | Acc: 93.318% (35894/38464)
Loss: 0.235 | Acc: 93.358% (41884/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3090, Accuracy: 8971/10000 (89.71%)
torch.Size([100, 10])
Test set: Average loss: 0.3090, Accuracy: 8971/10000 (89.71%)

Epoch: 100
Loss: 0.320 | Acc: 87.500% (56/64)
Loss: 2.079 | Acc: 24.551% (1587/6464)
Loss: 1.865 | Acc: 31.538% (4057/12864)
Loss: 1.681 | Acc: 38.554% (7427/19264)
Loss: 1.516 | Acc: 44.814% (11501/25664)
Loss: 1.383 | Acc: 49.994% (16030/32064)
Loss: 1.279 | Acc: 54.040% (20786/38464)
Loss: 1.192 | Acc: 57.302% (25708/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9064, Accuracy: 5698/10000 (56.98%)

Epoch: 101
Loss: 0.913 | Acc: 65.625% (42/64)
Loss: 0.565 | Acc: 80.739% (5219/6464)
Loss: 0.573 | Acc: 80.628% (10372/12864)
Loss: 0.557 | Acc: 81.022% (15608/19264)
Loss: 0.543 | Acc: 81.437% (20900/25664)
Loss: 0.531 | Acc: 81.855% (26246/32064)
Loss: 0.524 | Acc: 82.092% (31576/38464)
Loss: 0.519 | Acc: 82.244% (36898/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8796, Accuracy: 7212/10000 (72.12%)

Epoch: 102
Loss: 0.412 | Acc: 85.938% (55/64)
Loss: 0.424 | Acc: 85.721% (5541/6464)
Loss: 0.436 | Acc: 85.277% (10970/12864)
Loss: 0.433 | Acc: 85.226% (16418/19264)
Loss: 0.430 | Acc: 85.287% (21888/25664)
Loss: 0.430 | Acc: 85.342% (27364/32064)
Loss: 0.426 | Acc: 85.441% (32864/38464)
Loss: 0.426 | Acc: 85.523% (38369/44864)
torch.Size([100, 10])
Test set: Average loss: 5.7364, Accuracy: 3544/10000 (35.44%)

Epoch: 103
Loss: 0.770 | Acc: 75.000% (48/64)
Loss: 0.414 | Acc: 85.814% (5547/6464)
Loss: 0.400 | Acc: 86.614% (11142/12864)
Loss: 0.400 | Acc: 86.509% (16665/19264)
Loss: 0.394 | Acc: 86.670% (22243/25664)
Loss: 0.392 | Acc: 86.901% (27864/32064)
Loss: 0.390 | Acc: 86.980% (33456/38464)
Loss: 0.391 | Acc: 86.845% (38962/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5947, Accuracy: 5813/10000 (58.13%)

Epoch: 104
Loss: 0.836 | Acc: 75.000% (48/64)
Loss: 0.389 | Acc: 86.742% (5607/6464)
Loss: 0.383 | Acc: 86.971% (11188/12864)
Loss: 0.376 | Acc: 87.220% (16802/19264)
Loss: 0.377 | Acc: 87.103% (22354/25664)
Loss: 0.373 | Acc: 87.257% (27978/32064)
Loss: 0.374 | Acc: 87.193% (33538/38464)
Loss: 0.374 | Acc: 87.233% (39136/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6025, Accuracy: 8057/10000 (80.57%)

Epoch: 105
Loss: 0.540 | Acc: 81.250% (52/64)
Loss: 0.363 | Acc: 87.902% (5682/6464)
Loss: 0.357 | Acc: 87.803% (11295/12864)
Loss: 0.359 | Acc: 87.837% (16921/19264)
Loss: 0.363 | Acc: 87.722% (22513/25664)
Loss: 0.363 | Acc: 87.700% (28120/32064)
Loss: 0.363 | Acc: 87.692% (33730/38464)
Loss: 0.363 | Acc: 87.718% (39354/44864)
torch.Size([100, 10])
Test set: Average loss: 6.3994, Accuracy: 2527/10000 (25.27%)

Epoch: 106
Loss: 1.081 | Acc: 64.062% (41/64)
Loss: 0.377 | Acc: 87.252% (5640/6464)
Loss: 0.354 | Acc: 87.881% (11305/12864)
Loss: 0.346 | Acc: 88.227% (16996/19264)
Loss: 0.351 | Acc: 88.038% (22594/25664)
Loss: 0.353 | Acc: 88.036% (28228/32064)
Loss: 0.355 | Acc: 87.976% (33839/38464)
Loss: 0.357 | Acc: 87.895% (39433/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0961, Accuracy: 5311/10000 (53.11%)

Epoch: 107
Loss: 0.727 | Acc: 78.125% (50/64)
Loss: 0.335 | Acc: 88.830% (5742/6464)
Loss: 0.336 | Acc: 88.682% (11408/12864)
Loss: 0.340 | Acc: 88.476% (17044/19264)
Loss: 0.341 | Acc: 88.439% (22697/25664)
Loss: 0.345 | Acc: 88.289% (28309/32064)
Loss: 0.346 | Acc: 88.306% (33966/38464)
Loss: 0.341 | Acc: 88.421% (39669/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8979, Accuracy: 5307/10000 (53.07%)

Epoch: 108
Loss: 0.689 | Acc: 75.000% (48/64)
Loss: 0.340 | Acc: 88.196% (5701/6464)
Loss: 0.333 | Acc: 88.588% (11396/12864)
Loss: 0.336 | Acc: 88.481% (17045/19264)
Loss: 0.341 | Acc: 88.400% (22687/25664)
Loss: 0.339 | Acc: 88.386% (28340/32064)
Loss: 0.342 | Acc: 88.285% (33958/38464)
Loss: 0.344 | Acc: 88.218% (39578/44864)
torch.Size([100, 10])
Test set: Average loss: 5.3558, Accuracy: 3221/10000 (32.21%)

Epoch: 109
Loss: 0.831 | Acc: 79.688% (51/64)
Loss: 0.347 | Acc: 88.335% (5710/6464)
Loss: 0.344 | Acc: 88.410% (11373/12864)
Loss: 0.342 | Acc: 88.372% (17024/19264)
Loss: 0.339 | Acc: 88.412% (22690/25664)
Loss: 0.342 | Acc: 88.373% (28336/32064)
Loss: 0.340 | Acc: 88.496% (34039/38464)
Loss: 0.338 | Acc: 88.514% (39711/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4406, Accuracy: 6283/10000 (62.83%)

Epoch: 110
Loss: 0.717 | Acc: 81.250% (52/64)
Loss: 0.334 | Acc: 88.753% (5737/6464)
Loss: 0.325 | Acc: 88.907% (11437/12864)
Loss: 0.327 | Acc: 88.684% (17084/19264)
Loss: 0.329 | Acc: 88.657% (22753/25664)
Loss: 0.330 | Acc: 88.679% (28434/32064)
Loss: 0.330 | Acc: 88.654% (34100/38464)
Loss: 0.329 | Acc: 88.664% (39778/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9570, Accuracy: 7332/10000 (73.32%)

Epoch: 111
Loss: 0.354 | Acc: 87.500% (56/64)
Loss: 0.305 | Acc: 89.929% (5813/6464)
Loss: 0.322 | Acc: 89.132% (11466/12864)
Loss: 0.321 | Acc: 89.130% (17170/19264)
Loss: 0.316 | Acc: 89.308% (22920/25664)
Loss: 0.320 | Acc: 89.103% (28570/32064)
Loss: 0.321 | Acc: 89.008% (34236/38464)
Loss: 0.322 | Acc: 88.987% (39923/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0819, Accuracy: 6996/10000 (69.96%)

Epoch: 112
Loss: 0.692 | Acc: 76.562% (49/64)
Loss: 0.293 | Acc: 90.223% (5832/6464)
Loss: 0.305 | Acc: 89.669% (11535/12864)
Loss: 0.313 | Acc: 89.281% (17199/19264)
Loss: 0.310 | Acc: 89.413% (22947/25664)
Loss: 0.315 | Acc: 89.243% (28615/32064)
Loss: 0.316 | Acc: 89.250% (34329/38464)
Loss: 0.315 | Acc: 89.234% (40034/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6135, Accuracy: 6137/10000 (61.37%)

Epoch: 113
Loss: 0.482 | Acc: 85.938% (55/64)
Loss: 0.319 | Acc: 88.954% (5750/6464)
Loss: 0.309 | Acc: 89.350% (11494/12864)
Loss: 0.306 | Acc: 89.436% (17229/19264)
Loss: 0.305 | Acc: 89.456% (22958/25664)
Loss: 0.305 | Acc: 89.437% (28677/32064)
Loss: 0.307 | Acc: 89.356% (34370/38464)
Loss: 0.308 | Acc: 89.352% (40087/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4264, Accuracy: 6682/10000 (66.82%)

Epoch: 114
Loss: 0.434 | Acc: 81.250% (52/64)
Loss: 0.295 | Acc: 89.991% (5817/6464)
Loss: 0.300 | Acc: 89.638% (11531/12864)
Loss: 0.304 | Acc: 89.628% (17266/19264)
Loss: 0.304 | Acc: 89.694% (23019/25664)
Loss: 0.301 | Acc: 89.789% (28790/32064)
Loss: 0.305 | Acc: 89.671% (34491/38464)
Loss: 0.305 | Acc: 89.689% (40238/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3912, Accuracy: 4891/10000 (48.91%)

Epoch: 115
Loss: 0.593 | Acc: 78.125% (50/64)
Loss: 0.269 | Acc: 90.842% (5872/6464)
Loss: 0.279 | Acc: 90.423% (11632/12864)
Loss: 0.287 | Acc: 90.205% (17377/19264)
Loss: 0.286 | Acc: 90.294% (23173/25664)
Loss: 0.291 | Acc: 90.017% (28863/32064)
Loss: 0.295 | Acc: 89.881% (34572/38464)
Loss: 0.298 | Acc: 89.762% (40271/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5575, Accuracy: 8232/10000 (82.32%)

Epoch: 116
Loss: 0.253 | Acc: 95.312% (61/64)
Loss: 0.271 | Acc: 90.903% (5876/6464)
Loss: 0.273 | Acc: 90.633% (11659/12864)
Loss: 0.284 | Acc: 90.168% (17370/19264)
Loss: 0.284 | Acc: 90.263% (23165/25664)
Loss: 0.286 | Acc: 90.257% (28940/32064)
Loss: 0.285 | Acc: 90.295% (34731/38464)
Loss: 0.291 | Acc: 90.123% (40433/44864)
torch.Size([100, 10])
Test set: Average loss: 3.3353, Accuracy: 4758/10000 (47.58%)

Epoch: 117
Loss: 0.884 | Acc: 79.688% (51/64)
Loss: 0.307 | Acc: 89.697% (5798/6464)
Loss: 0.286 | Acc: 90.267% (11612/12864)
Loss: 0.283 | Acc: 90.417% (17418/19264)
Loss: 0.283 | Acc: 90.380% (23195/25664)
Loss: 0.285 | Acc: 90.207% (28924/32064)
Loss: 0.287 | Acc: 90.212% (34699/38464)
Loss: 0.286 | Acc: 90.215% (40474/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7726, Accuracy: 7746/10000 (77.46%)

Epoch: 118
Loss: 0.313 | Acc: 90.625% (58/64)
Loss: 0.264 | Acc: 90.842% (5872/6464)
Loss: 0.259 | Acc: 91.029% (11710/12864)
Loss: 0.265 | Acc: 90.853% (17502/19264)
Loss: 0.270 | Acc: 90.687% (23274/25664)
Loss: 0.271 | Acc: 90.653% (29067/32064)
Loss: 0.273 | Acc: 90.586% (34843/38464)
Loss: 0.273 | Acc: 90.607% (40650/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4540, Accuracy: 6418/10000 (64.18%)

Epoch: 119
Loss: 0.450 | Acc: 82.812% (53/64)
Loss: 0.272 | Acc: 90.331% (5839/6464)
Loss: 0.265 | Acc: 90.804% (11681/12864)
Loss: 0.266 | Acc: 90.822% (17496/19264)
Loss: 0.267 | Acc: 90.765% (23294/25664)
Loss: 0.266 | Acc: 90.825% (29122/32064)
Loss: 0.267 | Acc: 90.773% (34915/38464)
Loss: 0.268 | Acc: 90.752% (40715/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7459, Accuracy: 6758/10000 (67.58%)

Epoch: 120
Loss: 0.426 | Acc: 87.500% (56/64)
Loss: 0.274 | Acc: 90.950% (5879/6464)
Loss: 0.261 | Acc: 91.294% (11744/12864)
Loss: 0.260 | Acc: 91.284% (17585/19264)
Loss: 0.260 | Acc: 91.147% (23392/25664)
Loss: 0.257 | Acc: 91.230% (29252/32064)
Loss: 0.257 | Acc: 91.213% (35084/38464)
Loss: 0.259 | Acc: 91.138% (40888/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3878, Accuracy: 5624/10000 (56.24%)

Epoch: 121
Loss: 0.335 | Acc: 90.625% (58/64)
Loss: 0.234 | Acc: 92.141% (5956/6464)
Loss: 0.245 | Acc: 91.659% (11791/12864)
Loss: 0.253 | Acc: 91.331% (17594/19264)
Loss: 0.253 | Acc: 91.276% (23425/25664)
Loss: 0.252 | Acc: 91.320% (29281/32064)
Loss: 0.252 | Acc: 91.343% (35134/38464)
Loss: 0.251 | Acc: 91.318% (40969/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4308, Accuracy: 8600/10000 (86.00%)

Epoch: 122
Loss: 0.365 | Acc: 87.500% (56/64)
Loss: 0.227 | Acc: 92.033% (5949/6464)
Loss: 0.222 | Acc: 92.405% (11887/12864)
Loss: 0.228 | Acc: 92.125% (17747/19264)
Loss: 0.230 | Acc: 92.078% (23631/25664)
Loss: 0.234 | Acc: 91.969% (29489/32064)
Loss: 0.235 | Acc: 91.993% (35384/38464)
Loss: 0.236 | Acc: 91.947% (41251/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5709, Accuracy: 8245/10000 (82.45%)

Epoch: 123
Loss: 0.388 | Acc: 85.938% (55/64)
Loss: 0.219 | Acc: 92.450% (5976/6464)
Loss: 0.223 | Acc: 92.281% (11871/12864)
Loss: 0.231 | Acc: 91.902% (17704/19264)
Loss: 0.228 | Acc: 92.036% (23620/25664)
Loss: 0.231 | Acc: 91.941% (29480/32064)
Loss: 0.231 | Acc: 91.928% (35359/38464)
Loss: 0.231 | Acc: 91.960% (41257/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3908, Accuracy: 8731/10000 (87.31%)

Epoch: 124
Loss: 0.124 | Acc: 95.312% (61/64)
Loss: 0.209 | Acc: 93.131% (6020/6464)
Loss: 0.212 | Acc: 93.012% (11965/12864)
Loss: 0.206 | Acc: 93.169% (17948/19264)
Loss: 0.213 | Acc: 92.901% (23842/25664)
Loss: 0.218 | Acc: 92.771% (29746/32064)
Loss: 0.217 | Acc: 92.715% (35662/38464)
Loss: 0.218 | Acc: 92.687% (41583/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4343, Accuracy: 8640/10000 (86.40%)

Epoch: 125
Loss: 0.142 | Acc: 95.312% (61/64)
Loss: 0.208 | Acc: 92.729% (5994/6464)
Loss: 0.207 | Acc: 92.895% (11950/12864)
Loss: 0.210 | Acc: 92.774% (17872/19264)
Loss: 0.209 | Acc: 92.725% (23797/25664)
Loss: 0.207 | Acc: 92.899% (29787/32064)
Loss: 0.209 | Acc: 92.759% (35679/38464)
Loss: 0.210 | Acc: 92.731% (41603/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6836, Accuracy: 7967/10000 (79.67%)

Epoch: 126
Loss: 0.213 | Acc: 93.750% (60/64)
Loss: 0.185 | Acc: 93.472% (6042/6464)
Loss: 0.187 | Acc: 93.540% (12033/12864)
Loss: 0.191 | Acc: 93.454% (18003/19264)
Loss: 0.199 | Acc: 93.158% (23908/25664)
Loss: 0.202 | Acc: 93.033% (29830/32064)
Loss: 0.202 | Acc: 93.012% (35776/38464)
Loss: 0.202 | Acc: 93.019% (41732/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3846, Accuracy: 8755/10000 (87.55%)

Epoch: 127
Loss: 0.324 | Acc: 89.062% (57/64)
Loss: 0.175 | Acc: 94.183% (6088/6464)
Loss: 0.185 | Acc: 93.587% (12039/12864)
Loss: 0.188 | Acc: 93.558% (18023/19264)
Loss: 0.186 | Acc: 93.668% (24039/25664)
Loss: 0.189 | Acc: 93.578% (30005/32064)
Loss: 0.190 | Acc: 93.498% (35963/38464)
Loss: 0.189 | Acc: 93.612% (41998/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3137, Accuracy: 8985/10000 (89.85%)

Epoch: 128
Loss: 0.107 | Acc: 96.875% (62/64)
Loss: 0.151 | Acc: 95.019% (6142/6464)
Loss: 0.161 | Acc: 94.527% (12160/12864)
Loss: 0.169 | Acc: 94.243% (18155/19264)
Loss: 0.168 | Acc: 94.257% (24190/25664)
Loss: 0.170 | Acc: 94.205% (30206/32064)
Loss: 0.173 | Acc: 94.091% (36191/38464)
Loss: 0.175 | Acc: 93.982% (42164/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8213, Accuracy: 7910/10000 (79.10%)

Epoch: 129
Loss: 0.340 | Acc: 90.625% (58/64)
Loss: 0.184 | Acc: 93.781% (6062/6464)
Loss: 0.164 | Acc: 94.387% (12142/12864)
Loss: 0.167 | Acc: 94.243% (18155/19264)
Loss: 0.167 | Acc: 94.198% (24175/25664)
Loss: 0.167 | Acc: 94.227% (30213/32064)
Loss: 0.169 | Acc: 94.158% (36217/38464)
Loss: 0.167 | Acc: 94.220% (42271/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9318, Accuracy: 7621/10000 (76.21%)

Epoch: 130
Loss: 0.255 | Acc: 90.625% (58/64)
Loss: 0.158 | Acc: 94.554% (6112/6464)
Loss: 0.152 | Acc: 94.745% (12188/12864)
Loss: 0.148 | Acc: 94.928% (18287/19264)
Loss: 0.146 | Acc: 95.009% (24383/25664)
Loss: 0.146 | Acc: 95.051% (30477/32064)
Loss: 0.150 | Acc: 94.951% (36522/38464)
Loss: 0.152 | Acc: 94.907% (42579/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9552, Accuracy: 7695/10000 (76.95%)

Epoch: 131
Loss: 0.356 | Acc: 85.938% (55/64)
Loss: 0.132 | Acc: 95.390% (6166/6464)
Loss: 0.137 | Acc: 95.173% (12243/12864)
Loss: 0.137 | Acc: 95.250% (18349/19264)
Loss: 0.139 | Acc: 95.180% (24427/25664)
Loss: 0.137 | Acc: 95.244% (30539/32064)
Loss: 0.136 | Acc: 95.276% (36647/38464)
Loss: 0.139 | Acc: 95.181% (42702/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1153, Accuracy: 7683/10000 (76.83%)

Epoch: 132
Loss: 0.603 | Acc: 87.500% (56/64)
Loss: 0.121 | Acc: 95.715% (6187/6464)
Loss: 0.121 | Acc: 95.740% (12316/12864)
Loss: 0.123 | Acc: 95.774% (18450/19264)
Loss: 0.125 | Acc: 95.675% (24554/25664)
Loss: 0.128 | Acc: 95.599% (30653/32064)
Loss: 0.127 | Acc: 95.606% (36774/38464)
Loss: 0.127 | Acc: 95.629% (42903/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3047, Accuracy: 9025/10000 (90.25%)

Epoch: 133
Loss: 0.121 | Acc: 93.750% (60/64)
Loss: 0.116 | Acc: 96.055% (6209/6464)
Loss: 0.115 | Acc: 96.168% (12371/12864)
Loss: 0.114 | Acc: 96.133% (18519/19264)
Loss: 0.111 | Acc: 96.216% (24693/25664)
Loss: 0.112 | Acc: 96.211% (30849/32064)
Loss: 0.113 | Acc: 96.152% (36984/38464)
Loss: 0.115 | Acc: 96.110% (43119/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3971, Accuracy: 8856/10000 (88.56%)

Epoch: 134
Loss: 0.103 | Acc: 95.312% (61/64)
Loss: 0.099 | Acc: 96.535% (6240/6464)
Loss: 0.099 | Acc: 96.580% (12424/12864)
Loss: 0.099 | Acc: 96.574% (18604/19264)
Loss: 0.101 | Acc: 96.517% (24770/25664)
Loss: 0.101 | Acc: 96.563% (30962/32064)
Loss: 0.101 | Acc: 96.592% (37153/38464)
Loss: 0.101 | Acc: 96.590% (43334/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3054, Accuracy: 9075/10000 (90.75%)

Epoch: 135
Loss: 0.032 | Acc: 100.000% (64/64)
Loss: 0.087 | Acc: 97.308% (6290/6464)
Loss: 0.084 | Acc: 97.186% (12502/12864)
Loss: 0.087 | Acc: 97.083% (18702/19264)
Loss: 0.090 | Acc: 96.965% (24885/25664)
Loss: 0.089 | Acc: 96.997% (31101/32064)
Loss: 0.088 | Acc: 97.028% (37321/38464)
Loss: 0.089 | Acc: 96.995% (43516/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2489, Accuracy: 9203/10000 (92.03%)

Epoch: 136
Loss: 0.112 | Acc: 93.750% (60/64)
Loss: 0.074 | Acc: 97.447% (6299/6464)
Loss: 0.072 | Acc: 97.528% (12546/12864)
Loss: 0.072 | Acc: 97.519% (18786/19264)
Loss: 0.070 | Acc: 97.584% (25044/25664)
Loss: 0.071 | Acc: 97.583% (31289/32064)
Loss: 0.071 | Acc: 97.551% (37522/38464)
Loss: 0.071 | Acc: 97.584% (43780/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2307, Accuracy: 9305/10000 (93.05%)

Epoch: 137
Loss: 0.043 | Acc: 98.438% (63/64)
Loss: 0.062 | Acc: 97.927% (6330/6464)
Loss: 0.060 | Acc: 98.025% (12610/12864)
Loss: 0.057 | Acc: 98.048% (18888/19264)
Loss: 0.058 | Acc: 98.032% (25159/25664)
Loss: 0.058 | Acc: 98.057% (31441/32064)
Loss: 0.058 | Acc: 98.074% (37723/38464)
Loss: 0.059 | Acc: 98.059% (43993/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3994, Accuracy: 8947/10000 (89.47%)

Epoch: 138
Loss: 0.031 | Acc: 100.000% (64/64)
Loss: 0.057 | Acc: 98.221% (6349/6464)
Loss: 0.054 | Acc: 98.290% (12644/12864)
Loss: 0.051 | Acc: 98.401% (18956/19264)
Loss: 0.050 | Acc: 98.402% (25254/25664)
Loss: 0.050 | Acc: 98.353% (31536/32064)
Loss: 0.049 | Acc: 98.393% (37846/38464)
Loss: 0.049 | Acc: 98.393% (44143/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2094, Accuracy: 9398/10000 (93.98%)

Epoch: 139
Loss: 0.027 | Acc: 100.000% (64/64)
Loss: 0.028 | Acc: 99.103% (6406/6464)
Loss: 0.034 | Acc: 98.873% (12719/12864)
Loss: 0.034 | Acc: 98.899% (19052/19264)
Loss: 0.034 | Acc: 98.905% (25383/25664)
Loss: 0.034 | Acc: 98.902% (31712/32064)
Loss: 0.034 | Acc: 98.866% (38028/38464)
Loss: 0.034 | Acc: 98.870% (44357/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2584, Accuracy: 9298/10000 (92.98%)

Epoch: 140
Loss: 0.079 | Acc: 96.875% (62/64)
Loss: 0.027 | Acc: 99.165% (6410/6464)
Loss: 0.027 | Acc: 99.122% (12751/12864)
Loss: 0.028 | Acc: 99.133% (19097/19264)
Loss: 0.027 | Acc: 99.174% (25452/25664)
Loss: 0.027 | Acc: 99.161% (31795/32064)
Loss: 0.027 | Acc: 99.139% (38133/38464)
Loss: 0.028 | Acc: 99.128% (44473/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2071, Accuracy: 9413/10000 (94.13%)

Epoch: 141
Loss: 0.011 | Acc: 100.000% (64/64)
Loss: 0.018 | Acc: 99.489% (6431/6464)
Loss: 0.018 | Acc: 99.479% (12797/12864)
Loss: 0.019 | Acc: 99.455% (19159/19264)
Loss: 0.020 | Acc: 99.427% (25517/25664)
Loss: 0.020 | Acc: 99.395% (31870/32064)
Loss: 0.020 | Acc: 99.405% (38235/38464)
Loss: 0.020 | Acc: 99.418% (44603/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2009, Accuracy: 9443/10000 (94.43%)

Epoch: 142
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.016 | Acc: 99.520% (6433/6464)
Loss: 0.015 | Acc: 99.565% (12808/12864)
Loss: 0.017 | Acc: 99.564% (19180/19264)
Loss: 0.018 | Acc: 99.521% (25541/25664)
Loss: 0.017 | Acc: 99.535% (31915/32064)
Loss: 0.017 | Acc: 99.558% (38294/38464)
Loss: 0.016 | Acc: 99.565% (44669/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1922, Accuracy: 9477/10000 (94.77%)

Epoch: 143
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 0.012 | Acc: 99.691% (6444/6464)
Loss: 0.013 | Acc: 99.642% (12818/12864)
Loss: 0.011 | Acc: 99.704% (19207/19264)
Loss: 0.012 | Acc: 99.708% (25589/25664)
Loss: 0.012 | Acc: 99.694% (31966/32064)
Loss: 0.012 | Acc: 99.675% (38339/38464)
Loss: 0.012 | Acc: 99.672% (44717/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1863, Accuracy: 9475/10000 (94.75%)

Epoch: 144
Loss: 0.014 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.783% (6450/6464)
Loss: 0.010 | Acc: 99.736% (12830/12864)
Loss: 0.010 | Acc: 99.730% (19212/19264)
Loss: 0.010 | Acc: 99.755% (25601/25664)
Loss: 0.010 | Acc: 99.744% (31982/32064)
Loss: 0.010 | Acc: 99.750% (38368/38464)
Loss: 0.010 | Acc: 99.762% (44757/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1836, Accuracy: 9491/10000 (94.91%)

Epoch: 145
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.013 | Acc: 99.660% (6442/6464)
Loss: 0.019 | Acc: 99.572% (12809/12864)
Loss: 0.026 | Acc: 99.419% (19152/19264)
Loss: 0.034 | Acc: 99.271% (25477/25664)
Loss: 0.043 | Acc: 99.077% (31768/32064)
Loss: 0.051 | Acc: 98.887% (38036/38464)
Loss: 0.060 | Acc: 98.658% (44262/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2415, Accuracy: 9198/10000 (91.98%)

Epoch: 146
Loss: 0.097 | Acc: 96.875% (62/64)
Loss: 0.132 | Acc: 96.689% (6250/6464)
Loss: 0.139 | Acc: 96.463% (12409/12864)
Loss: 0.143 | Acc: 96.423% (18575/19264)
Loss: 0.147 | Acc: 96.357% (24729/25664)
Loss: 0.151 | Acc: 96.204% (30847/32064)
Loss: 0.157 | Acc: 95.965% (36912/38464)
Loss: 0.162 | Acc: 95.810% (42984/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2767, Accuracy: 9113/10000 (91.13%)

Epoch: 147
Loss: 0.217 | Acc: 92.188% (59/64)
Loss: 0.197 | Acc: 94.276% (6094/6464)
Loss: 0.198 | Acc: 94.372% (12140/12864)
Loss: 0.200 | Acc: 94.357% (18177/19264)
Loss: 0.199 | Acc: 94.362% (24217/25664)
Loss: 0.202 | Acc: 94.290% (30233/32064)
Loss: 0.203 | Acc: 94.254% (36254/38464)
Loss: 0.204 | Acc: 94.238% (42279/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2939, Accuracy: 9061/10000 (90.61%)
torch.Size([100, 10])
Test set: Average loss: 0.2939, Accuracy: 9061/10000 (90.61%)

Epoch: 148
Loss: 0.134 | Acc: 95.312% (61/64)
Loss: 0.210 | Acc: 94.199% (6089/6464)
Loss: 0.210 | Acc: 94.185% (12116/12864)
Loss: 0.212 | Acc: 94.108% (18129/19264)
Loss: 0.214 | Acc: 93.980% (24119/25664)
Loss: 0.215 | Acc: 93.912% (30112/32064)
Loss: 0.215 | Acc: 93.872% (36107/38464)
Loss: 0.216 | Acc: 93.837% (42099/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2961, Accuracy: 9035/10000 (90.35%)
torch.Size([100, 10])
Test set: Average loss: 0.2961, Accuracy: 9035/10000 (90.35%)

Epoch: 149
Loss: 0.115 | Acc: 96.875% (62/64)
Loss: 0.214 | Acc: 93.905% (6070/6464)
Loss: 0.217 | Acc: 93.688% (12052/12864)
Loss: 0.220 | Acc: 93.662% (18043/19264)
Loss: 0.220 | Acc: 93.715% (24051/25664)
Loss: 0.221 | Acc: 93.635% (30023/32064)
Loss: 0.223 | Acc: 93.615% (36008/38464)
Loss: 0.223 | Acc: 93.574% (41981/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2967, Accuracy: 9037/10000 (90.37%)
torch.Size([100, 10])
Test set: Average loss: 0.2967, Accuracy: 9037/10000 (90.37%)

Epoch: 150
Loss: 0.193 | Acc: 96.875% (62/64)
Loss: 1.952 | Acc: 29.981% (1938/6464)
Loss: 1.619 | Acc: 41.744% (5370/12864)
Loss: 1.395 | Acc: 50.234% (9677/19264)
Loss: 1.234 | Acc: 56.312% (14452/25664)
Loss: 1.121 | Acc: 60.407% (19369/32064)
Loss: 1.036 | Acc: 63.530% (24436/38464)
Loss: 0.972 | Acc: 65.908% (29569/44864)
torch.Size([100, 10])
Test set: Average loss: 6.0051, Accuracy: 2179/10000 (21.79%)

Epoch: 151
Loss: 0.837 | Acc: 73.438% (47/64)
Loss: 0.514 | Acc: 82.534% (5335/6464)
Loss: 0.504 | Acc: 82.774% (10648/12864)
Loss: 0.498 | Acc: 82.885% (15967/19264)
Loss: 0.489 | Acc: 83.300% (21378/25664)
Loss: 0.475 | Acc: 83.798% (26869/32064)
Loss: 0.468 | Acc: 84.060% (32333/38464)
Loss: 0.462 | Acc: 84.145% (37751/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3068, Accuracy: 4880/10000 (48.80%)

Epoch: 152
Loss: 0.771 | Acc: 78.125% (50/64)
Loss: 0.401 | Acc: 86.448% (5588/6464)
Loss: 0.402 | Acc: 86.544% (11133/12864)
Loss: 0.401 | Acc: 86.545% (16672/19264)
Loss: 0.407 | Acc: 86.269% (22140/25664)
Loss: 0.405 | Acc: 86.299% (27671/32064)
Loss: 0.403 | Acc: 86.359% (33217/38464)
Loss: 0.402 | Acc: 86.401% (38763/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7198, Accuracy: 6009/10000 (60.09%)

Epoch: 153
Loss: 1.330 | Acc: 65.625% (42/64)
Loss: 0.389 | Acc: 86.556% (5595/6464)
Loss: 0.377 | Acc: 86.831% (11170/12864)
Loss: 0.376 | Acc: 86.976% (16755/19264)
Loss: 0.374 | Acc: 87.122% (22359/25664)
Loss: 0.375 | Acc: 87.110% (27931/32064)
Loss: 0.375 | Acc: 87.180% (33533/38464)
Loss: 0.374 | Acc: 87.190% (39117/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8891, Accuracy: 7349/10000 (73.49%)

Epoch: 154
Loss: 0.372 | Acc: 84.375% (54/64)
Loss: 0.362 | Acc: 87.376% (5648/6464)
Loss: 0.368 | Acc: 87.414% (11245/12864)
Loss: 0.367 | Acc: 87.656% (16886/19264)
Loss: 0.366 | Acc: 87.609% (22484/25664)
Loss: 0.363 | Acc: 87.787% (28148/32064)
Loss: 0.362 | Acc: 87.726% (33743/38464)
Loss: 0.362 | Acc: 87.723% (39356/44864)
torch.Size([100, 10])
Test set: Average loss: 13.0751, Accuracy: 1168/10000 (11.68%)

Epoch: 155
Loss: 1.267 | Acc: 65.625% (42/64)
Loss: 0.364 | Acc: 87.717% (5670/6464)
Loss: 0.353 | Acc: 88.262% (11354/12864)
Loss: 0.349 | Acc: 88.232% (16997/19264)
Loss: 0.351 | Acc: 88.162% (22626/25664)
Loss: 0.352 | Acc: 88.080% (28242/32064)
Loss: 0.354 | Acc: 88.012% (33853/38464)
Loss: 0.355 | Acc: 88.030% (39494/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7464, Accuracy: 7941/10000 (79.41%)

Epoch: 156
Loss: 0.247 | Acc: 93.750% (60/64)
Loss: 0.328 | Acc: 89.109% (5760/6464)
Loss: 0.330 | Acc: 88.907% (11437/12864)
Loss: 0.332 | Acc: 88.746% (17096/19264)
Loss: 0.331 | Acc: 88.782% (22785/25664)
Loss: 0.336 | Acc: 88.607% (28411/32064)
Loss: 0.337 | Acc: 88.550% (34060/38464)
Loss: 0.339 | Acc: 88.485% (39698/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5150, Accuracy: 8366/10000 (83.66%)

Epoch: 157
Loss: 0.199 | Acc: 92.188% (59/64)
Loss: 0.336 | Acc: 88.351% (5711/6464)
Loss: 0.327 | Acc: 88.837% (11428/12864)
Loss: 0.337 | Acc: 88.678% (17083/19264)
Loss: 0.337 | Acc: 88.665% (22755/25664)
Loss: 0.339 | Acc: 88.576% (28401/32064)
Loss: 0.339 | Acc: 88.504% (34042/38464)
Loss: 0.339 | Acc: 88.519% (39713/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4635, Accuracy: 6469/10000 (64.69%)

Epoch: 158
Loss: 0.614 | Acc: 82.812% (53/64)
Loss: 0.326 | Acc: 88.939% (5749/6464)
Loss: 0.333 | Acc: 88.549% (11391/12864)
Loss: 0.331 | Acc: 88.678% (17083/19264)
Loss: 0.328 | Acc: 88.692% (22762/25664)
Loss: 0.332 | Acc: 88.651% (28425/32064)
Loss: 0.330 | Acc: 88.732% (34130/38464)
Loss: 0.333 | Acc: 88.672% (39782/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6239, Accuracy: 7954/10000 (79.54%)

Epoch: 159
Loss: 0.344 | Acc: 93.750% (60/64)
Loss: 0.303 | Acc: 89.558% (5789/6464)
Loss: 0.322 | Acc: 88.876% (11433/12864)
Loss: 0.321 | Acc: 89.037% (17152/19264)
Loss: 0.322 | Acc: 88.996% (22840/25664)
Loss: 0.324 | Acc: 88.907% (28507/32064)
Loss: 0.326 | Acc: 88.865% (34181/38464)
Loss: 0.329 | Acc: 88.784% (39832/44864)
torch.Size([100, 10])
Test set: Average loss: 3.0967, Accuracy: 4474/10000 (44.74%)

Epoch: 160
Loss: 0.737 | Acc: 76.562% (49/64)
Loss: 0.319 | Acc: 89.356% (5776/6464)
Loss: 0.318 | Acc: 89.257% (11482/12864)
Loss: 0.316 | Acc: 89.384% (17219/19264)
Loss: 0.314 | Acc: 89.265% (22909/25664)
Loss: 0.312 | Acc: 89.359% (28652/32064)
Loss: 0.315 | Acc: 89.221% (34318/38464)
Loss: 0.318 | Acc: 89.194% (40016/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9636, Accuracy: 7085/10000 (70.85%)

Epoch: 161
Loss: 0.461 | Acc: 84.375% (54/64)
Loss: 0.312 | Acc: 89.109% (5760/6464)
Loss: 0.308 | Acc: 89.234% (11479/12864)
Loss: 0.309 | Acc: 89.400% (17222/19264)
Loss: 0.312 | Acc: 89.199% (22892/25664)
Loss: 0.314 | Acc: 89.165% (28590/32064)
Loss: 0.313 | Acc: 89.229% (34321/38464)
Loss: 0.316 | Acc: 89.116% (39981/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2272, Accuracy: 5475/10000 (54.75%)

Epoch: 162
Loss: 0.776 | Acc: 79.688% (51/64)
Loss: 0.295 | Acc: 90.022% (5819/6464)
Loss: 0.301 | Acc: 89.770% (11548/12864)
Loss: 0.304 | Acc: 89.758% (17291/19264)
Loss: 0.303 | Acc: 89.779% (23041/25664)
Loss: 0.308 | Acc: 89.608% (28732/32064)
Loss: 0.308 | Acc: 89.562% (34449/38464)
Loss: 0.312 | Acc: 89.390% (40104/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4008, Accuracy: 8637/10000 (86.37%)

Epoch: 163
Loss: 0.295 | Acc: 90.625% (58/64)
Loss: 0.290 | Acc: 90.161% (5828/6464)
Loss: 0.296 | Acc: 90.026% (11581/12864)
Loss: 0.299 | Acc: 89.950% (17328/19264)
Loss: 0.302 | Acc: 89.951% (23085/25664)
Loss: 0.306 | Acc: 89.820% (28800/32064)
Loss: 0.305 | Acc: 89.832% (34553/38464)
Loss: 0.305 | Acc: 89.805% (40290/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3315, Accuracy: 6689/10000 (66.89%)

Epoch: 164
Loss: 0.279 | Acc: 90.625% (58/64)
Loss: 0.284 | Acc: 90.269% (5835/6464)
Loss: 0.290 | Acc: 90.127% (11594/12864)
Loss: 0.291 | Acc: 90.205% (17377/19264)
Loss: 0.297 | Acc: 89.873% (23065/25664)
Loss: 0.298 | Acc: 89.764% (28782/32064)
Loss: 0.297 | Acc: 89.788% (34536/38464)
Loss: 0.301 | Acc: 89.678% (40233/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7669, Accuracy: 6880/10000 (68.80%)

Epoch: 165
Loss: 0.501 | Acc: 85.938% (55/64)
Loss: 0.285 | Acc: 90.579% (5855/6464)
Loss: 0.292 | Acc: 90.042% (11583/12864)
Loss: 0.288 | Acc: 90.355% (17406/19264)
Loss: 0.290 | Acc: 90.267% (23166/25664)
Loss: 0.289 | Acc: 90.279% (28947/32064)
Loss: 0.285 | Acc: 90.352% (34753/38464)
Loss: 0.288 | Acc: 90.246% (40488/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0042, Accuracy: 7118/10000 (71.18%)

Epoch: 166
Loss: 0.851 | Acc: 75.000% (48/64)
Loss: 0.279 | Acc: 90.347% (5840/6464)
Loss: 0.280 | Acc: 90.322% (11619/12864)
Loss: 0.283 | Acc: 90.256% (17387/19264)
Loss: 0.284 | Acc: 90.259% (23164/25664)
Loss: 0.284 | Acc: 90.294% (28952/32064)
Loss: 0.286 | Acc: 90.196% (34693/38464)
Loss: 0.286 | Acc: 90.253% (40491/44864)
torch.Size([100, 10])
Test set: Average loss: 2.8979, Accuracy: 4527/10000 (45.27%)

Epoch: 167
Loss: 0.528 | Acc: 84.375% (54/64)
Loss: 0.283 | Acc: 90.114% (5825/6464)
Loss: 0.272 | Acc: 90.625% (11658/12864)
Loss: 0.268 | Acc: 90.817% (17495/19264)
Loss: 0.270 | Acc: 90.785% (23299/25664)
Loss: 0.274 | Acc: 90.619% (29056/32064)
Loss: 0.279 | Acc: 90.482% (34803/38464)
Loss: 0.277 | Acc: 90.558% (40628/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7924, Accuracy: 6719/10000 (67.19%)

Epoch: 168
Loss: 0.599 | Acc: 82.812% (53/64)
Loss: 0.257 | Acc: 91.429% (5910/6464)
Loss: 0.263 | Acc: 91.107% (11720/12864)
Loss: 0.270 | Acc: 90.843% (17500/19264)
Loss: 0.267 | Acc: 90.941% (23339/25664)
Loss: 0.267 | Acc: 90.931% (29156/32064)
Loss: 0.269 | Acc: 90.877% (34955/38464)
Loss: 0.267 | Acc: 90.942% (40800/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4572, Accuracy: 8511/10000 (85.11%)

Epoch: 169
Loss: 0.297 | Acc: 90.625% (58/64)
Loss: 0.259 | Acc: 91.259% (5899/6464)
Loss: 0.258 | Acc: 91.130% (11723/12864)
Loss: 0.262 | Acc: 91.051% (17540/19264)
Loss: 0.263 | Acc: 90.995% (23353/25664)
Loss: 0.263 | Acc: 91.021% (29185/32064)
Loss: 0.263 | Acc: 91.038% (35017/38464)
Loss: 0.264 | Acc: 91.031% (40840/44864)
torch.Size([100, 10])
Test set: Average loss: 4.6083, Accuracy: 3339/10000 (33.39%)

Epoch: 170
Loss: 0.692 | Acc: 81.250% (52/64)
Loss: 0.269 | Acc: 90.795% (5869/6464)
Loss: 0.256 | Acc: 91.177% (11729/12864)
Loss: 0.258 | Acc: 91.118% (17553/19264)
Loss: 0.251 | Acc: 91.389% (23454/25664)
Loss: 0.254 | Acc: 91.302% (29275/32064)
Loss: 0.253 | Acc: 91.384% (35150/38464)
Loss: 0.257 | Acc: 91.276% (40950/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9524, Accuracy: 7419/10000 (74.19%)

Epoch: 171
Loss: 0.525 | Acc: 82.812% (53/64)
Loss: 0.230 | Acc: 92.141% (5956/6464)
Loss: 0.235 | Acc: 91.706% (11797/12864)
Loss: 0.242 | Acc: 91.611% (17648/19264)
Loss: 0.244 | Acc: 91.556% (23497/25664)
Loss: 0.243 | Acc: 91.635% (29382/32064)
Loss: 0.242 | Acc: 91.657% (35255/38464)
Loss: 0.243 | Acc: 91.621% (41105/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4846, Accuracy: 8519/10000 (85.19%)

Epoch: 172
Loss: 0.353 | Acc: 90.625% (58/64)
Loss: 0.250 | Acc: 91.708% (5928/6464)
Loss: 0.238 | Acc: 91.877% (11819/12864)
Loss: 0.233 | Acc: 92.037% (17730/19264)
Loss: 0.238 | Acc: 91.880% (23580/25664)
Loss: 0.236 | Acc: 91.891% (29464/32064)
Loss: 0.236 | Acc: 91.857% (35332/38464)
Loss: 0.236 | Acc: 91.844% (41205/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8906, Accuracy: 6072/10000 (60.72%)

Epoch: 173
Loss: 0.316 | Acc: 90.625% (58/64)
Loss: 0.249 | Acc: 91.522% (5916/6464)
Loss: 0.230 | Acc: 92.172% (11857/12864)
Loss: 0.228 | Acc: 92.307% (17782/19264)
Loss: 0.225 | Acc: 92.390% (23711/25664)
Loss: 0.227 | Acc: 92.368% (29617/32064)
Loss: 0.228 | Acc: 92.385% (35535/38464)
Loss: 0.228 | Acc: 92.328% (41422/44864)
torch.Size([100, 10])
Test set: Average loss: 3.3458, Accuracy: 4555/10000 (45.55%)

Epoch: 174
Loss: 0.482 | Acc: 82.812% (53/64)
Loss: 0.245 | Acc: 91.553% (5918/6464)
Loss: 0.234 | Acc: 91.915% (11824/12864)
Loss: 0.224 | Acc: 92.239% (17769/19264)
Loss: 0.223 | Acc: 92.203% (23663/25664)
Loss: 0.219 | Acc: 92.290% (29592/32064)
Loss: 0.219 | Acc: 92.320% (35510/38464)
Loss: 0.219 | Acc: 92.366% (41439/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5181, Accuracy: 8385/10000 (83.85%)

Epoch: 175
Loss: 0.149 | Acc: 93.750% (60/64)
Loss: 0.203 | Acc: 92.884% (6004/6464)
Loss: 0.200 | Acc: 93.058% (11971/12864)
Loss: 0.200 | Acc: 93.184% (17951/19264)
Loss: 0.207 | Acc: 92.904% (23843/25664)
Loss: 0.207 | Acc: 92.836% (29767/32064)
Loss: 0.206 | Acc: 92.832% (35707/38464)
Loss: 0.205 | Acc: 92.928% (41691/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5740, Accuracy: 8259/10000 (82.59%)

Epoch: 176
Loss: 0.255 | Acc: 90.625% (58/64)
Loss: 0.185 | Acc: 93.781% (6062/6464)
Loss: 0.193 | Acc: 93.563% (12036/12864)
Loss: 0.191 | Acc: 93.631% (18037/19264)
Loss: 0.194 | Acc: 93.540% (24006/25664)
Loss: 0.196 | Acc: 93.485% (29975/32064)
Loss: 0.195 | Acc: 93.412% (35930/38464)
Loss: 0.195 | Acc: 93.400% (41903/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4593, Accuracy: 5318/10000 (53.18%)

Epoch: 177
Loss: 0.416 | Acc: 84.375% (54/64)
Loss: 0.199 | Acc: 93.317% (6032/6464)
Loss: 0.196 | Acc: 93.315% (12004/12864)
Loss: 0.185 | Acc: 93.755% (18061/19264)
Loss: 0.187 | Acc: 93.625% (24028/25664)
Loss: 0.191 | Acc: 93.513% (29984/32064)
Loss: 0.192 | Acc: 93.433% (35938/38464)
Loss: 0.191 | Acc: 93.451% (41926/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9695, Accuracy: 7601/10000 (76.01%)

Epoch: 178
Loss: 0.200 | Acc: 93.750% (60/64)
Loss: 0.166 | Acc: 94.353% (6099/6464)
Loss: 0.164 | Acc: 94.442% (12149/12864)
Loss: 0.170 | Acc: 94.145% (18136/19264)
Loss: 0.173 | Acc: 94.031% (24132/25664)
Loss: 0.174 | Acc: 94.003% (30141/32064)
Loss: 0.175 | Acc: 93.963% (36142/38464)
Loss: 0.175 | Acc: 93.986% (42166/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7644, Accuracy: 7781/10000 (77.81%)

Epoch: 179
Loss: 0.139 | Acc: 93.750% (60/64)
Loss: 0.156 | Acc: 94.725% (6123/6464)
Loss: 0.160 | Acc: 94.372% (12140/12864)
Loss: 0.160 | Acc: 94.352% (18176/19264)
Loss: 0.161 | Acc: 94.307% (24203/25664)
Loss: 0.162 | Acc: 94.349% (30252/32064)
Loss: 0.163 | Acc: 94.335% (36285/38464)
Loss: 0.164 | Acc: 94.265% (42291/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5400, Accuracy: 8347/10000 (83.47%)

Epoch: 180
Loss: 0.242 | Acc: 90.625% (58/64)
Loss: 0.152 | Acc: 94.601% (6115/6464)
Loss: 0.148 | Acc: 94.869% (12204/12864)
Loss: 0.145 | Acc: 94.970% (18295/19264)
Loss: 0.146 | Acc: 94.958% (24370/25664)
Loss: 0.146 | Acc: 94.966% (30450/32064)
Loss: 0.148 | Acc: 94.886% (36497/38464)
Loss: 0.149 | Acc: 94.853% (42555/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4148, Accuracy: 8731/10000 (87.31%)

Epoch: 181
Loss: 0.164 | Acc: 96.875% (62/64)
Loss: 0.142 | Acc: 95.204% (6154/6464)
Loss: 0.139 | Acc: 95.118% (12236/12864)
Loss: 0.138 | Acc: 95.141% (18328/19264)
Loss: 0.138 | Acc: 95.145% (24418/25664)
Loss: 0.135 | Acc: 95.259% (30544/32064)
Loss: 0.134 | Acc: 95.299% (36656/38464)
Loss: 0.134 | Acc: 95.330% (42769/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6231, Accuracy: 8352/10000 (83.52%)

Epoch: 182
Loss: 0.151 | Acc: 93.750% (60/64)
Loss: 0.125 | Acc: 95.637% (6182/6464)
Loss: 0.122 | Acc: 95.857% (12331/12864)
Loss: 0.124 | Acc: 95.712% (18438/19264)
Loss: 0.122 | Acc: 95.831% (24594/25664)
Loss: 0.121 | Acc: 95.865% (30738/32064)
Loss: 0.125 | Acc: 95.734% (36823/38464)
Loss: 0.124 | Acc: 95.765% (42964/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2692, Accuracy: 9192/10000 (91.92%)

Epoch: 183
Loss: 0.075 | Acc: 98.438% (63/64)
Loss: 0.107 | Acc: 96.627% (6246/6464)
Loss: 0.106 | Acc: 96.486% (12412/12864)
Loss: 0.105 | Acc: 96.449% (18580/19264)
Loss: 0.105 | Acc: 96.384% (24736/25664)
Loss: 0.105 | Acc: 96.367% (30899/32064)
Loss: 0.107 | Acc: 96.319% (37048/38464)
Loss: 0.108 | Acc: 96.269% (43190/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2691, Accuracy: 9174/10000 (91.74%)

Epoch: 184
Loss: 0.106 | Acc: 95.312% (61/64)
Loss: 0.088 | Acc: 96.829% (6259/6464)
Loss: 0.094 | Acc: 96.595% (12426/12864)
Loss: 0.098 | Acc: 96.465% (18583/19264)
Loss: 0.096 | Acc: 96.517% (24770/25664)
Loss: 0.098 | Acc: 96.470% (30932/32064)
Loss: 0.098 | Acc: 96.480% (37110/38464)
Loss: 0.098 | Acc: 96.478% (43284/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2849, Accuracy: 9139/10000 (91.39%)

Epoch: 185
Loss: 0.172 | Acc: 95.312% (61/64)
Loss: 0.101 | Acc: 96.550% (6241/6464)
Loss: 0.090 | Acc: 97.062% (12486/12864)
Loss: 0.088 | Acc: 97.051% (18696/19264)
Loss: 0.087 | Acc: 97.082% (24915/25664)
Loss: 0.087 | Acc: 97.090% (31131/32064)
Loss: 0.086 | Acc: 97.151% (37368/38464)
Loss: 0.086 | Acc: 97.142% (43582/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2512, Accuracy: 9223/10000 (92.23%)

Epoch: 186
Loss: 0.062 | Acc: 96.875% (62/64)
Loss: 0.072 | Acc: 97.432% (6298/6464)
Loss: 0.069 | Acc: 97.598% (12555/12864)
Loss: 0.069 | Acc: 97.628% (18807/19264)
Loss: 0.070 | Acc: 97.615% (25052/25664)
Loss: 0.068 | Acc: 97.658% (31313/32064)
Loss: 0.069 | Acc: 97.671% (37568/38464)
Loss: 0.068 | Acc: 97.673% (43820/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2580, Accuracy: 9224/10000 (92.24%)

Epoch: 187
Loss: 0.069 | Acc: 96.875% (62/64)
Loss: 0.059 | Acc: 98.082% (6340/6464)
Loss: 0.059 | Acc: 98.088% (12618/12864)
Loss: 0.059 | Acc: 98.090% (18896/19264)
Loss: 0.058 | Acc: 98.145% (25188/25664)
Loss: 0.057 | Acc: 98.160% (31474/32064)
Loss: 0.057 | Acc: 98.170% (37760/38464)
Loss: 0.056 | Acc: 98.183% (44049/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2505, Accuracy: 9269/10000 (92.69%)

Epoch: 188
Loss: 0.057 | Acc: 98.438% (63/64)
Loss: 0.054 | Acc: 98.298% (6354/6464)
Loss: 0.055 | Acc: 98.220% (12635/12864)
Loss: 0.051 | Acc: 98.328% (18942/19264)
Loss: 0.050 | Acc: 98.402% (25254/25664)
Loss: 0.050 | Acc: 98.391% (31548/32064)
Loss: 0.049 | Acc: 98.406% (37851/38464)
Loss: 0.049 | Acc: 98.435% (44162/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2301, Accuracy: 9314/10000 (93.14%)

Epoch: 189
Loss: 0.039 | Acc: 98.438% (63/64)
Loss: 0.036 | Acc: 98.855% (6390/6464)
Loss: 0.037 | Acc: 98.826% (12713/12864)
Loss: 0.036 | Acc: 98.931% (19058/19264)
Loss: 0.034 | Acc: 98.983% (25403/25664)
Loss: 0.033 | Acc: 99.002% (31744/32064)
Loss: 0.034 | Acc: 98.968% (38067/38464)
Loss: 0.034 | Acc: 98.952% (44394/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2091, Accuracy: 9391/10000 (93.91%)

Epoch: 190
Loss: 0.027 | Acc: 98.438% (63/64)
Loss: 0.030 | Acc: 98.979% (6398/6464)
Loss: 0.027 | Acc: 99.145% (12754/12864)
Loss: 0.028 | Acc: 99.123% (19095/19264)
Loss: 0.029 | Acc: 99.077% (25427/25664)
Loss: 0.029 | Acc: 99.074% (31767/32064)
Loss: 0.029 | Acc: 99.085% (38112/38464)
Loss: 0.028 | Acc: 99.091% (44456/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2102, Accuracy: 9402/10000 (94.02%)

Epoch: 191
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 0.020 | Acc: 99.474% (6430/6464)
Loss: 0.021 | Acc: 99.433% (12791/12864)
Loss: 0.022 | Acc: 99.372% (19143/19264)
Loss: 0.021 | Acc: 99.427% (25517/25664)
Loss: 0.021 | Acc: 99.414% (31876/32064)
Loss: 0.021 | Acc: 99.428% (38244/38464)
Loss: 0.021 | Acc: 99.425% (44606/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2021, Accuracy: 9427/10000 (94.27%)

Epoch: 192
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.016 | Acc: 99.536% (6434/6464)
Loss: 0.015 | Acc: 99.557% (12807/12864)
Loss: 0.015 | Acc: 99.569% (19181/19264)
Loss: 0.015 | Acc: 99.591% (25559/25664)
Loss: 0.015 | Acc: 99.595% (31934/32064)
Loss: 0.015 | Acc: 99.589% (38306/38464)
Loss: 0.015 | Acc: 99.594% (44682/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1952, Accuracy: 9455/10000 (94.55%)

Epoch: 193
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.706% (6445/6464)
Loss: 0.011 | Acc: 99.658% (12820/12864)
Loss: 0.012 | Acc: 99.663% (19199/19264)
Loss: 0.011 | Acc: 99.696% (25586/25664)
Loss: 0.011 | Acc: 99.704% (31969/32064)
Loss: 0.011 | Acc: 99.701% (38349/38464)
Loss: 0.011 | Acc: 99.710% (44734/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1890, Accuracy: 9486/10000 (94.86%)

Epoch: 194
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.722% (6446/6464)
Loss: 0.009 | Acc: 99.712% (12827/12864)
Loss: 0.009 | Acc: 99.735% (19213/19264)
Loss: 0.009 | Acc: 99.751% (25600/25664)
Loss: 0.009 | Acc: 99.747% (31983/32064)
Loss: 0.009 | Acc: 99.727% (38359/38464)
Loss: 0.010 | Acc: 99.719% (44738/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1886, Accuracy: 9479/10000 (94.79%)

Epoch: 195
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.014 | Acc: 99.644% (6441/6464)
Loss: 0.018 | Acc: 99.549% (12806/12864)
Loss: 0.026 | Acc: 99.393% (19147/19264)
Loss: 0.032 | Acc: 99.228% (25466/25664)
Loss: 0.039 | Acc: 99.033% (31754/32064)
Loss: 0.047 | Acc: 98.833% (38015/38464)
Loss: 0.054 | Acc: 98.680% (44272/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2403, Accuracy: 9204/10000 (92.04%)

Epoch: 196
Loss: 0.085 | Acc: 98.438% (63/64)
Loss: 0.116 | Acc: 97.045% (6273/6464)
Loss: 0.125 | Acc: 96.797% (12452/12864)
Loss: 0.131 | Acc: 96.527% (18595/19264)
Loss: 0.137 | Acc: 96.361% (24730/25664)
Loss: 0.142 | Acc: 96.254% (30863/32064)
Loss: 0.146 | Acc: 96.113% (36969/38464)
Loss: 0.150 | Acc: 96.032% (43084/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2778, Accuracy: 9101/10000 (91.01%)

Epoch: 197
Loss: 0.178 | Acc: 95.312% (61/64)
Loss: 0.178 | Acc: 94.926% (6136/6464)
Loss: 0.183 | Acc: 94.854% (12202/12864)
Loss: 0.185 | Acc: 94.814% (18265/19264)
Loss: 0.189 | Acc: 94.705% (24305/25664)
Loss: 0.192 | Acc: 94.573% (30324/32064)
Loss: 0.192 | Acc: 94.569% (36375/38464)
Loss: 0.194 | Acc: 94.477% (42386/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2961, Accuracy: 9036/10000 (90.36%)
torch.Size([100, 10])
Test set: Average loss: 0.2961, Accuracy: 9036/10000 (90.36%)

Epoch: 198
Loss: 0.168 | Acc: 92.188% (59/64)
Loss: 0.197 | Acc: 94.322% (6097/6464)
Loss: 0.204 | Acc: 94.053% (12099/12864)
Loss: 0.202 | Acc: 94.067% (18121/19264)
Loss: 0.203 | Acc: 94.159% (24165/25664)
Loss: 0.205 | Acc: 94.099% (30172/32064)
Loss: 0.205 | Acc: 94.140% (36210/38464)
Loss: 0.206 | Acc: 94.131% (42231/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2972, Accuracy: 9051/10000 (90.51%)
torch.Size([100, 10])
Test set: Average loss: 0.2972, Accuracy: 9051/10000 (90.51%)

Epoch: 199
Loss: 0.176 | Acc: 95.312% (61/64)
Loss: 0.203 | Acc: 93.905% (6070/6464)
Loss: 0.206 | Acc: 93.952% (12086/12864)
Loss: 0.207 | Acc: 94.041% (18116/19264)
Loss: 0.206 | Acc: 94.034% (24133/25664)
Loss: 0.206 | Acc: 94.099% (30172/32064)
Loss: 0.205 | Acc: 94.148% (36213/38464)
Loss: 0.206 | Acc: 94.109% (42221/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2983, Accuracy: 9022/10000 (90.22%)
torch.Size([100, 10])
Test set: Average loss: 0.2983, Accuracy: 9022/10000 (90.22%)
9293
10000
-0.25229597091674805
