==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.418 | Acc: 12.500% (8/64)
Loss: 2.922 | Acc: 11.603% (750/6464)
Loss: 2.599 | Acc: 13.044% (1678/12864)
Loss: 2.488 | Acc: 13.865% (2671/19264)
Loss: 2.425 | Acc: 14.760% (3788/25664)
Loss: 2.387 | Acc: 15.354% (4923/32064)
Loss: 2.361 | Acc: 15.810% (6081/38464)
Loss: 2.339 | Acc: 16.340% (7331/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3227, Accuracy: 1808/10000 (18.08%)

Epoch: 1
Loss: 2.383 | Acc: 10.938% (7/64)
Loss: 2.203 | Acc: 19.817% (1281/6464)
Loss: 2.196 | Acc: 20.732% (2667/12864)
Loss: 2.194 | Acc: 21.018% (4049/19264)
Loss: 2.193 | Acc: 21.084% (5411/25664)
Loss: 2.191 | Acc: 21.233% (6808/32064)
Loss: 2.186 | Acc: 21.529% (8281/38464)
Loss: 2.185 | Acc: 21.688% (9730/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2878, Accuracy: 2072/10000 (20.72%)

Epoch: 2
Loss: 2.093 | Acc: 20.312% (13/64)
Loss: 2.155 | Acc: 23.283% (1505/6464)
Loss: 2.158 | Acc: 23.438% (3015/12864)
Loss: 2.156 | Acc: 23.749% (4575/19264)
Loss: 2.153 | Acc: 24.084% (6181/25664)
Loss: 2.153 | Acc: 24.130% (7737/32064)
Loss: 2.152 | Acc: 24.251% (9328/38464)
Loss: 2.150 | Acc: 24.418% (10955/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1375, Accuracy: 2548/10000 (25.48%)

Epoch: 3
Loss: 2.432 | Acc: 10.938% (7/64)
Loss: 2.138 | Acc: 25.541% (1651/6464)
Loss: 2.140 | Acc: 25.544% (3286/12864)
Loss: 2.134 | Acc: 25.690% (4949/19264)
Loss: 2.133 | Acc: 25.865% (6638/25664)
Loss: 2.133 | Acc: 25.945% (8319/32064)
Loss: 2.131 | Acc: 26.128% (10050/38464)
Loss: 2.128 | Acc: 26.364% (11828/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2041, Accuracy: 2380/10000 (23.80%)

Epoch: 4
Loss: 2.021 | Acc: 35.938% (23/64)
Loss: 2.102 | Acc: 28.311% (1830/6464)
Loss: 2.093 | Acc: 28.444% (3659/12864)
Loss: 2.100 | Acc: 28.156% (5424/19264)
Loss: 2.099 | Acc: 28.176% (7231/25664)
Loss: 2.101 | Acc: 28.063% (8998/32064)
Loss: 2.099 | Acc: 28.271% (10874/38464)
Loss: 2.097 | Acc: 28.439% (12759/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1382, Accuracy: 2577/10000 (25.77%)

Epoch: 5
Loss: 2.004 | Acc: 29.688% (19/64)
Loss: 2.064 | Acc: 30.538% (1974/6464)
Loss: 2.079 | Acc: 29.734% (3825/12864)
Loss: 2.078 | Acc: 29.594% (5701/19264)
Loss: 2.075 | Acc: 29.871% (7666/25664)
Loss: 2.073 | Acc: 30.227% (9692/32064)
Loss: 2.073 | Acc: 30.345% (11672/38464)
Loss: 2.071 | Acc: 30.517% (13691/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0955, Accuracy: 2997/10000 (29.97%)

Epoch: 6
Loss: 1.925 | Acc: 35.938% (23/64)
Loss: 2.038 | Acc: 32.735% (2116/6464)
Loss: 2.044 | Acc: 32.478% (4178/12864)
Loss: 2.050 | Acc: 32.319% (6226/19264)
Loss: 2.048 | Acc: 32.345% (8301/25664)
Loss: 2.043 | Acc: 32.401% (10389/32064)
Loss: 2.044 | Acc: 32.459% (12485/38464)
Loss: 2.043 | Acc: 32.614% (14632/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0906, Accuracy: 3032/10000 (30.32%)

Epoch: 7
Loss: 1.987 | Acc: 37.500% (24/64)
Loss: 2.023 | Acc: 33.540% (2168/6464)
Loss: 2.018 | Acc: 34.002% (4374/12864)
Loss: 2.019 | Acc: 34.261% (6600/19264)
Loss: 2.017 | Acc: 34.328% (8810/25664)
Loss: 2.017 | Acc: 34.425% (11038/32064)
Loss: 2.017 | Acc: 34.432% (13244/38464)
Loss: 2.016 | Acc: 34.502% (15479/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0811, Accuracy: 3065/10000 (30.65%)

Epoch: 8
Loss: 2.136 | Acc: 32.812% (21/64)
Loss: 1.998 | Acc: 35.195% (2275/6464)
Loss: 1.995 | Acc: 35.417% (4556/12864)
Loss: 1.992 | Acc: 35.631% (6864/19264)
Loss: 1.997 | Acc: 35.606% (9138/25664)
Loss: 1.993 | Acc: 35.825% (11487/32064)
Loss: 1.995 | Acc: 35.678% (13723/38464)
Loss: 1.995 | Acc: 35.706% (16019/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1203, Accuracy: 3133/10000 (31.33%)

Epoch: 9
Loss: 2.081 | Acc: 29.688% (19/64)
Loss: 1.970 | Acc: 37.082% (2397/6464)
Loss: 1.979 | Acc: 36.544% (4701/12864)
Loss: 1.981 | Acc: 36.602% (7051/19264)
Loss: 1.981 | Acc: 36.647% (9405/25664)
Loss: 1.981 | Acc: 36.661% (11755/32064)
Loss: 1.982 | Acc: 36.663% (14102/38464)
Loss: 1.982 | Acc: 36.760% (16492/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1687, Accuracy: 2814/10000 (28.14%)

Epoch: 10
Loss: 1.932 | Acc: 40.625% (26/64)
Loss: 1.973 | Acc: 37.144% (2401/6464)
Loss: 1.974 | Acc: 37.251% (4792/12864)
Loss: 1.969 | Acc: 37.334% (7192/19264)
Loss: 1.970 | Acc: 37.340% (9583/25664)
Loss: 1.966 | Acc: 37.587% (12052/32064)
Loss: 1.967 | Acc: 37.594% (14460/38464)
Loss: 1.966 | Acc: 37.587% (16863/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0951, Accuracy: 3053/10000 (30.53%)

Epoch: 11
Loss: 1.968 | Acc: 34.375% (22/64)
Loss: 1.944 | Acc: 39.109% (2528/6464)
Loss: 1.956 | Acc: 38.425% (4943/12864)
Loss: 1.956 | Acc: 38.481% (7413/19264)
Loss: 1.956 | Acc: 38.556% (9895/25664)
Loss: 1.956 | Acc: 38.585% (12372/32064)
Loss: 1.955 | Acc: 38.641% (14863/38464)
Loss: 1.953 | Acc: 38.715% (17369/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0652, Accuracy: 3277/10000 (32.77%)

Epoch: 12
Loss: 1.962 | Acc: 40.625% (26/64)
Loss: 1.955 | Acc: 38.923% (2516/6464)
Loss: 1.947 | Acc: 39.350% (5062/12864)
Loss: 1.941 | Acc: 39.519% (7613/19264)
Loss: 1.942 | Acc: 39.542% (10148/25664)
Loss: 1.940 | Acc: 39.586% (12693/32064)
Loss: 1.937 | Acc: 39.699% (15270/38464)
Loss: 1.938 | Acc: 39.615% (17773/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9739, Accuracy: 3732/10000 (37.32%)

Epoch: 13
Loss: 2.161 | Acc: 34.375% (22/64)
Loss: 1.925 | Acc: 40.965% (2648/6464)
Loss: 1.925 | Acc: 40.726% (5239/12864)
Loss: 1.925 | Acc: 40.573% (7816/19264)
Loss: 1.925 | Acc: 40.508% (10396/25664)
Loss: 1.927 | Acc: 40.391% (12951/32064)
Loss: 1.927 | Acc: 40.360% (15524/38464)
Loss: 1.926 | Acc: 40.469% (18156/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0035, Accuracy: 3613/10000 (36.13%)

Epoch: 14
Loss: 1.890 | Acc: 40.625% (26/64)
Loss: 1.913 | Acc: 40.702% (2631/6464)
Loss: 1.913 | Acc: 41.037% (5279/12864)
Loss: 1.913 | Acc: 40.983% (7895/19264)
Loss: 1.913 | Acc: 41.100% (10548/25664)
Loss: 1.913 | Acc: 41.093% (13176/32064)
Loss: 1.913 | Acc: 41.122% (15817/38464)
Loss: 1.912 | Acc: 41.147% (18460/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0922, Accuracy: 3022/10000 (30.22%)

Epoch: 15
Loss: 1.945 | Acc: 39.062% (25/64)
Loss: 1.916 | Acc: 41.074% (2655/6464)
Loss: 1.910 | Acc: 41.682% (5362/12864)
Loss: 1.911 | Acc: 41.523% (7999/19264)
Loss: 1.909 | Acc: 41.502% (10651/25664)
Loss: 1.906 | Acc: 41.745% (13385/32064)
Loss: 1.904 | Acc: 41.764% (16064/38464)
Loss: 1.907 | Acc: 41.597% (18662/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1176, Accuracy: 3293/10000 (32.93%)

Epoch: 16
Loss: 2.091 | Acc: 34.375% (22/64)
Loss: 1.885 | Acc: 42.698% (2760/6464)
Loss: 1.894 | Acc: 42.048% (5409/12864)
Loss: 1.899 | Acc: 41.860% (8064/19264)
Loss: 1.903 | Acc: 41.634% (10685/25664)
Loss: 1.902 | Acc: 41.776% (13395/32064)
Loss: 1.900 | Acc: 41.886% (16111/38464)
Loss: 1.895 | Acc: 42.085% (18881/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0692, Accuracy: 3433/10000 (34.33%)

Epoch: 17
Loss: 1.874 | Acc: 40.625% (26/64)
Loss: 1.886 | Acc: 43.069% (2784/6464)
Loss: 1.894 | Acc: 42.498% (5467/12864)
Loss: 1.895 | Acc: 42.457% (8179/19264)
Loss: 1.890 | Acc: 42.764% (10975/25664)
Loss: 1.893 | Acc: 42.618% (13665/32064)
Loss: 1.892 | Acc: 42.632% (16398/38464)
Loss: 1.890 | Acc: 42.656% (19137/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9931, Accuracy: 3809/10000 (38.09%)

Epoch: 18
Loss: 1.933 | Acc: 42.188% (27/64)
Loss: 1.861 | Acc: 43.951% (2841/6464)
Loss: 1.877 | Acc: 43.315% (5572/12864)
Loss: 1.879 | Acc: 43.272% (8336/19264)
Loss: 1.879 | Acc: 43.095% (11060/25664)
Loss: 1.879 | Acc: 43.132% (13830/32064)
Loss: 1.879 | Acc: 43.092% (16575/38464)
Loss: 1.878 | Acc: 43.231% (19395/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0396, Accuracy: 3682/10000 (36.82%)

Epoch: 19
Loss: 2.184 | Acc: 29.688% (19/64)
Loss: 1.863 | Acc: 44.075% (2849/6464)
Loss: 1.864 | Acc: 43.882% (5645/12864)
Loss: 1.860 | Acc: 44.139% (8503/19264)
Loss: 1.864 | Acc: 44.120% (11323/25664)
Loss: 1.868 | Acc: 43.912% (14080/32064)
Loss: 1.872 | Acc: 43.745% (16826/38464)
Loss: 1.871 | Acc: 43.797% (19649/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0651, Accuracy: 3311/10000 (33.11%)

Epoch: 20
Loss: 1.838 | Acc: 39.062% (25/64)
Loss: 1.866 | Acc: 43.936% (2840/6464)
Loss: 1.856 | Acc: 44.450% (5718/12864)
Loss: 1.859 | Acc: 44.098% (8495/19264)
Loss: 1.862 | Acc: 43.941% (11277/25664)
Loss: 1.862 | Acc: 44.049% (14124/32064)
Loss: 1.864 | Acc: 44.054% (16945/38464)
Loss: 1.865 | Acc: 44.053% (19764/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0107, Accuracy: 3658/10000 (36.58%)

Epoch: 21
Loss: 1.923 | Acc: 42.188% (27/64)
Loss: 1.858 | Acc: 44.090% (2850/6464)
Loss: 1.857 | Acc: 43.960% (5655/12864)
Loss: 1.854 | Acc: 44.378% (8549/19264)
Loss: 1.857 | Acc: 44.366% (11386/25664)
Loss: 1.857 | Acc: 44.417% (14242/32064)
Loss: 1.859 | Acc: 44.270% (17028/38464)
Loss: 1.856 | Acc: 44.414% (19926/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9502, Accuracy: 4029/10000 (40.29%)

Epoch: 22
Loss: 1.691 | Acc: 53.125% (34/64)
Loss: 1.836 | Acc: 45.003% (2909/6464)
Loss: 1.850 | Acc: 44.512% (5726/12864)
Loss: 1.849 | Acc: 44.669% (8605/19264)
Loss: 1.854 | Acc: 44.385% (11391/25664)
Loss: 1.852 | Acc: 44.492% (14266/32064)
Loss: 1.851 | Acc: 44.527% (17127/38464)
Loss: 1.849 | Acc: 44.635% (20025/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0476, Accuracy: 3500/10000 (35.00%)

Epoch: 23
Loss: 1.768 | Acc: 48.438% (31/64)
Loss: 1.830 | Acc: 45.947% (2970/6464)
Loss: 1.840 | Acc: 45.141% (5807/12864)
Loss: 1.844 | Acc: 45.188% (8705/19264)
Loss: 1.846 | Acc: 45.009% (11551/25664)
Loss: 1.846 | Acc: 44.998% (14428/32064)
Loss: 1.847 | Acc: 44.917% (17277/38464)
Loss: 1.844 | Acc: 45.070% (20220/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0334, Accuracy: 3512/10000 (35.12%)

Epoch: 24
Loss: 1.732 | Acc: 51.562% (33/64)
Loss: 1.850 | Acc: 45.003% (2909/6464)
Loss: 1.840 | Acc: 45.359% (5835/12864)
Loss: 1.839 | Acc: 45.396% (8745/19264)
Loss: 1.844 | Acc: 45.196% (11599/25664)
Loss: 1.837 | Acc: 45.412% (14561/32064)
Loss: 1.837 | Acc: 45.432% (17475/38464)
Loss: 1.839 | Acc: 45.321% (20333/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9396, Accuracy: 4052/10000 (40.52%)

Epoch: 25
Loss: 1.849 | Acc: 45.312% (29/64)
Loss: 1.809 | Acc: 46.658% (3016/6464)
Loss: 1.820 | Acc: 45.989% (5916/12864)
Loss: 1.824 | Acc: 46.013% (8864/19264)
Loss: 1.825 | Acc: 46.026% (11812/25664)
Loss: 1.827 | Acc: 45.840% (14698/32064)
Loss: 1.829 | Acc: 45.739% (17593/38464)
Loss: 1.830 | Acc: 45.769% (20534/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9621, Accuracy: 3893/10000 (38.93%)

Epoch: 26
Loss: 2.052 | Acc: 35.938% (23/64)
Loss: 1.843 | Acc: 44.678% (2888/6464)
Loss: 1.840 | Acc: 45.126% (5805/12864)
Loss: 1.831 | Acc: 45.665% (8797/19264)
Loss: 1.829 | Acc: 45.764% (11745/25664)
Loss: 1.829 | Acc: 45.824% (14693/32064)
Loss: 1.826 | Acc: 45.916% (17661/38464)
Loss: 1.823 | Acc: 46.068% (20668/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8908, Accuracy: 4289/10000 (42.89%)

Epoch: 27
Loss: 1.911 | Acc: 39.062% (25/64)
Loss: 1.838 | Acc: 44.787% (2895/6464)
Loss: 1.818 | Acc: 45.989% (5916/12864)
Loss: 1.812 | Acc: 46.164% (8893/19264)
Loss: 1.818 | Acc: 46.057% (11820/25664)
Loss: 1.816 | Acc: 46.282% (14840/32064)
Loss: 1.812 | Acc: 46.446% (17865/38464)
Loss: 1.812 | Acc: 46.496% (20860/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9203, Accuracy: 4177/10000 (41.77%)

Epoch: 28
Loss: 1.759 | Acc: 48.438% (31/64)
Loss: 1.807 | Acc: 46.674% (3017/6464)
Loss: 1.812 | Acc: 46.634% (5999/12864)
Loss: 1.805 | Acc: 46.958% (9046/19264)
Loss: 1.810 | Acc: 46.739% (11995/25664)
Loss: 1.808 | Acc: 46.791% (15003/32064)
Loss: 1.809 | Acc: 46.680% (17955/38464)
Loss: 1.806 | Acc: 46.813% (21002/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9010, Accuracy: 4258/10000 (42.58%)

Epoch: 29
Loss: 1.898 | Acc: 39.062% (25/64)
Loss: 1.790 | Acc: 47.463% (3068/6464)
Loss: 1.785 | Acc: 47.831% (6153/12864)
Loss: 1.786 | Acc: 47.929% (9233/19264)
Loss: 1.791 | Acc: 47.721% (12247/25664)
Loss: 1.789 | Acc: 47.851% (15343/32064)
Loss: 1.793 | Acc: 47.694% (18345/38464)
Loss: 1.793 | Acc: 47.700% (21400/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8788, Accuracy: 4353/10000 (43.53%)

Epoch: 30
Loss: 2.071 | Acc: 35.938% (23/64)
Loss: 1.767 | Acc: 48.639% (3144/6464)
Loss: 1.771 | Acc: 48.150% (6194/12864)
Loss: 1.776 | Acc: 47.903% (9228/19264)
Loss: 1.780 | Acc: 47.740% (12252/25664)
Loss: 1.784 | Acc: 47.664% (15283/32064)
Loss: 1.787 | Acc: 47.611% (18313/38464)
Loss: 1.787 | Acc: 47.689% (21395/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8727, Accuracy: 4421/10000 (44.21%)

Epoch: 31
Loss: 1.756 | Acc: 50.000% (32/64)
Loss: 1.763 | Acc: 48.871% (3159/6464)
Loss: 1.774 | Acc: 48.336% (6218/12864)
Loss: 1.778 | Acc: 48.235% (9292/19264)
Loss: 1.778 | Acc: 48.235% (12379/25664)
Loss: 1.777 | Acc: 48.263% (15475/32064)
Loss: 1.777 | Acc: 48.274% (18568/38464)
Loss: 1.779 | Acc: 48.119% (21588/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8975, Accuracy: 4312/10000 (43.12%)

Epoch: 32
Loss: 1.621 | Acc: 53.125% (34/64)
Loss: 1.757 | Acc: 49.149% (3177/6464)
Loss: 1.765 | Acc: 48.531% (6243/12864)
Loss: 1.770 | Acc: 48.292% (9303/19264)
Loss: 1.767 | Acc: 48.496% (12446/25664)
Loss: 1.766 | Acc: 48.637% (15595/32064)
Loss: 1.767 | Acc: 48.562% (18679/38464)
Loss: 1.768 | Acc: 48.627% (21816/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8808, Accuracy: 4435/10000 (44.35%)

Epoch: 33
Loss: 1.752 | Acc: 50.000% (32/64)
Loss: 1.731 | Acc: 49.876% (3224/6464)
Loss: 1.742 | Acc: 49.409% (6356/12864)
Loss: 1.740 | Acc: 49.424% (9521/19264)
Loss: 1.750 | Acc: 49.100% (12601/25664)
Loss: 1.750 | Acc: 49.161% (15763/32064)
Loss: 1.755 | Acc: 48.983% (18841/38464)
Loss: 1.757 | Acc: 48.912% (21944/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9008, Accuracy: 4312/10000 (43.12%)

Epoch: 34
Loss: 1.744 | Acc: 51.562% (33/64)
Loss: 1.733 | Acc: 50.217% (3246/6464)
Loss: 1.731 | Acc: 50.148% (6451/12864)
Loss: 1.736 | Acc: 49.865% (9606/19264)
Loss: 1.741 | Acc: 49.529% (12711/25664)
Loss: 1.745 | Acc: 49.376% (15832/32064)
Loss: 1.746 | Acc: 49.345% (18980/38464)
Loss: 1.747 | Acc: 49.293% (22115/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8954, Accuracy: 4378/10000 (43.78%)

Epoch: 35
Loss: 1.559 | Acc: 57.812% (37/64)
Loss: 1.680 | Acc: 52.058% (3365/6464)
Loss: 1.702 | Acc: 51.322% (6602/12864)
Loss: 1.715 | Acc: 50.633% (9754/19264)
Loss: 1.718 | Acc: 50.499% (12960/25664)
Loss: 1.722 | Acc: 50.399% (16160/32064)
Loss: 1.723 | Acc: 50.338% (19362/38464)
Loss: 1.728 | Acc: 50.138% (22494/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8641, Accuracy: 4519/10000 (45.19%)

Epoch: 36
Loss: 1.790 | Acc: 48.438% (31/64)
Loss: 1.724 | Acc: 50.015% (3233/6464)
Loss: 1.718 | Acc: 50.350% (6477/12864)
Loss: 1.716 | Acc: 50.519% (9732/19264)
Loss: 1.716 | Acc: 50.452% (12948/25664)
Loss: 1.715 | Acc: 50.493% (16190/32064)
Loss: 1.716 | Acc: 50.426% (19396/38464)
Loss: 1.716 | Acc: 50.446% (22632/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8722, Accuracy: 4533/10000 (45.33%)

Epoch: 37
Loss: 1.696 | Acc: 51.562% (33/64)
Loss: 1.687 | Acc: 51.346% (3319/6464)
Loss: 1.690 | Acc: 51.384% (6610/12864)
Loss: 1.694 | Acc: 51.033% (9831/19264)
Loss: 1.700 | Acc: 50.896% (13062/25664)
Loss: 1.706 | Acc: 50.711% (16260/32064)
Loss: 1.708 | Acc: 50.632% (19475/38464)
Loss: 1.705 | Acc: 50.762% (22774/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8872, Accuracy: 4498/10000 (44.98%)

Epoch: 38
Loss: 1.804 | Acc: 45.312% (29/64)
Loss: 1.670 | Acc: 51.980% (3360/6464)
Loss: 1.676 | Acc: 51.827% (6667/12864)
Loss: 1.683 | Acc: 51.630% (9946/19264)
Loss: 1.688 | Acc: 51.294% (13164/25664)
Loss: 1.686 | Acc: 51.388% (16477/32064)
Loss: 1.681 | Acc: 51.599% (19847/38464)
Loss: 1.684 | Acc: 51.442% (23079/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8724, Accuracy: 4517/10000 (45.17%)

Epoch: 39
Loss: 1.741 | Acc: 45.312% (29/64)
Loss: 1.650 | Acc: 52.382% (3386/6464)
Loss: 1.643 | Acc: 52.814% (6794/12864)
Loss: 1.658 | Acc: 52.217% (10059/19264)
Loss: 1.653 | Acc: 52.408% (13450/25664)
Loss: 1.655 | Acc: 52.445% (16816/32064)
Loss: 1.656 | Acc: 52.397% (20154/38464)
Loss: 1.664 | Acc: 52.071% (23361/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8917, Accuracy: 4482/10000 (44.82%)

Epoch: 40
Loss: 1.640 | Acc: 53.125% (34/64)
Loss: 1.633 | Acc: 52.707% (3407/6464)
Loss: 1.631 | Acc: 53.063% (6826/12864)
Loss: 1.635 | Acc: 53.000% (10210/19264)
Loss: 1.635 | Acc: 53.031% (13610/25664)
Loss: 1.635 | Acc: 53.103% (17027/32064)
Loss: 1.640 | Acc: 52.855% (20330/38464)
Loss: 1.640 | Acc: 52.880% (23724/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8885, Accuracy: 4561/10000 (45.61%)

Epoch: 41
Loss: 1.694 | Acc: 46.875% (30/64)
Loss: 1.596 | Acc: 54.223% (3505/6464)
Loss: 1.609 | Acc: 53.638% (6900/12864)
Loss: 1.605 | Acc: 53.623% (10330/19264)
Loss: 1.608 | Acc: 53.565% (13747/25664)
Loss: 1.609 | Acc: 53.543% (17168/32064)
Loss: 1.612 | Acc: 53.388% (20535/38464)
Loss: 1.613 | Acc: 53.314% (23919/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9131, Accuracy: 4576/10000 (45.76%)

Epoch: 42
Loss: 1.453 | Acc: 64.062% (41/64)
Loss: 1.591 | Acc: 53.697% (3471/6464)
Loss: 1.591 | Acc: 53.630% (6899/12864)
Loss: 1.585 | Acc: 53.873% (10378/19264)
Loss: 1.586 | Acc: 53.935% (13842/25664)
Loss: 1.585 | Acc: 53.973% (17306/32064)
Loss: 1.582 | Acc: 54.196% (20846/38464)
Loss: 1.581 | Acc: 54.199% (24316/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9479, Accuracy: 4465/10000 (44.65%)

Epoch: 43
Loss: 1.524 | Acc: 56.250% (36/64)
Loss: 1.497 | Acc: 56.822% (3673/6464)
Loss: 1.520 | Acc: 55.784% (7176/12864)
Loss: 1.528 | Acc: 55.617% (10714/19264)
Loss: 1.532 | Acc: 55.603% (14270/25664)
Loss: 1.532 | Acc: 55.648% (17843/32064)
Loss: 1.534 | Acc: 55.597% (21385/38464)
Loss: 1.537 | Acc: 55.499% (24899/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9591, Accuracy: 4448/10000 (44.48%)

Epoch: 44
Loss: 1.461 | Acc: 62.500% (40/64)
Loss: 1.471 | Acc: 57.101% (3691/6464)
Loss: 1.482 | Acc: 56.817% (7309/12864)
Loss: 1.481 | Acc: 56.977% (10976/19264)
Loss: 1.486 | Acc: 56.749% (14564/25664)
Loss: 1.495 | Acc: 56.453% (18101/32064)
Loss: 1.497 | Acc: 56.396% (21692/38464)
Loss: 1.498 | Acc: 56.415% (25310/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9965, Accuracy: 4440/10000 (44.40%)

Epoch: 45
Loss: 1.471 | Acc: 56.250% (36/64)
Loss: 1.456 | Acc: 57.132% (3693/6464)
Loss: 1.443 | Acc: 57.626% (7413/12864)
Loss: 1.451 | Acc: 57.278% (11034/19264)
Loss: 1.457 | Acc: 57.072% (14647/25664)
Loss: 1.454 | Acc: 57.242% (18354/32064)
Loss: 1.446 | Acc: 57.581% (22148/38464)
Loss: 1.443 | Acc: 57.701% (25887/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0231, Accuracy: 4343/10000 (43.43%)

Epoch: 46
Loss: 1.387 | Acc: 59.375% (38/64)
Loss: 1.393 | Acc: 58.988% (3813/6464)
Loss: 1.382 | Acc: 59.414% (7643/12864)
Loss: 1.381 | Acc: 59.313% (11426/19264)
Loss: 1.379 | Acc: 59.437% (15254/25664)
Loss: 1.377 | Acc: 59.702% (19143/32064)
Loss: 1.380 | Acc: 59.609% (22928/38464)
Loss: 1.378 | Acc: 59.669% (26770/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0503, Accuracy: 4310/10000 (43.10%)

Epoch: 47
Loss: 1.185 | Acc: 70.312% (45/64)
Loss: 1.317 | Acc: 61.262% (3960/6464)
Loss: 1.321 | Acc: 61.210% (7874/12864)
Loss: 1.312 | Acc: 61.420% (11832/19264)
Loss: 1.311 | Acc: 61.522% (15789/25664)
Loss: 1.323 | Acc: 61.100% (19591/32064)
Loss: 1.324 | Acc: 61.008% (23466/38464)
Loss: 1.326 | Acc: 60.929% (27335/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0679, Accuracy: 4258/10000 (42.58%)
torch.Size([100, 10])
Test set: Average loss: 2.0679, Accuracy: 4258/10000 (42.58%)

Epoch: 48
Loss: 1.469 | Acc: 56.250% (36/64)
Loss: 1.291 | Acc: 62.005% (4008/6464)
Loss: 1.290 | Acc: 61.979% (7973/12864)
Loss: 1.298 | Acc: 61.514% (11850/19264)
Loss: 1.298 | Acc: 61.541% (15794/25664)
Loss: 1.292 | Acc: 61.758% (19802/32064)
Loss: 1.289 | Acc: 61.832% (23783/38464)
Loss: 1.289 | Acc: 61.787% (27720/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0864, Accuracy: 4276/10000 (42.76%)
torch.Size([100, 10])
Test set: Average loss: 2.0864, Accuracy: 4276/10000 (42.76%)

Epoch: 49
Loss: 1.309 | Acc: 60.938% (39/64)
Loss: 1.293 | Acc: 61.247% (3959/6464)
Loss: 1.289 | Acc: 61.567% (7920/12864)
Loss: 1.278 | Acc: 61.752% (11896/19264)
Loss: 1.273 | Acc: 62.032% (15920/25664)
Loss: 1.269 | Acc: 62.188% (19940/32064)
Loss: 1.270 | Acc: 62.214% (23930/38464)
Loss: 1.269 | Acc: 62.273% (27938/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0961, Accuracy: 4263/10000 (42.63%)
torch.Size([100, 10])
Test set: Average loss: 2.0961, Accuracy: 4263/10000 (42.63%)

Epoch: 50
Loss: 1.122 | Acc: 68.750% (44/64)
Loss: 2.115 | Acc: 28.280% (1828/6464)
Loss: 2.040 | Acc: 33.256% (4278/12864)
Loss: 2.002 | Acc: 35.673% (6872/19264)
Loss: 1.984 | Acc: 36.810% (9447/25664)
Loss: 1.969 | Acc: 37.821% (12127/32064)
Loss: 1.957 | Acc: 38.574% (14837/38464)
Loss: 1.949 | Acc: 39.145% (17562/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0528, Accuracy: 3434/10000 (34.34%)

Epoch: 51
Loss: 1.887 | Acc: 45.312% (29/64)
Loss: 1.885 | Acc: 43.069% (2784/6464)
Loss: 1.892 | Acc: 42.638% (5485/12864)
Loss: 1.890 | Acc: 42.800% (8245/19264)
Loss: 1.887 | Acc: 42.928% (11017/25664)
Loss: 1.883 | Acc: 43.192% (13849/32064)
Loss: 1.882 | Acc: 43.285% (16649/38464)
Loss: 1.880 | Acc: 43.360% (19453/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0790, Accuracy: 3369/10000 (33.69%)

Epoch: 52
Loss: 1.686 | Acc: 48.438% (31/64)
Loss: 1.861 | Acc: 44.059% (2848/6464)
Loss: 1.864 | Acc: 43.797% (5634/12864)
Loss: 1.863 | Acc: 43.942% (8465/19264)
Loss: 1.869 | Acc: 43.660% (11205/25664)
Loss: 1.868 | Acc: 43.691% (14009/32064)
Loss: 1.866 | Acc: 43.825% (16857/38464)
Loss: 1.868 | Acc: 43.746% (19626/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9840, Accuracy: 3821/10000 (38.21%)

Epoch: 53
Loss: 1.730 | Acc: 48.438% (31/64)
Loss: 1.851 | Acc: 44.493% (2876/6464)
Loss: 1.855 | Acc: 44.341% (5704/12864)
Loss: 1.864 | Acc: 44.056% (8487/19264)
Loss: 1.866 | Acc: 43.937% (11276/25664)
Loss: 1.870 | Acc: 43.890% (14073/32064)
Loss: 1.870 | Acc: 43.875% (16876/38464)
Loss: 1.870 | Acc: 43.882% (19687/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1218, Accuracy: 3418/10000 (34.18%)

Epoch: 54
Loss: 1.732 | Acc: 53.125% (34/64)
Loss: 1.862 | Acc: 44.276% (2862/6464)
Loss: 1.863 | Acc: 44.014% (5662/12864)
Loss: 1.862 | Acc: 44.108% (8497/19264)
Loss: 1.858 | Acc: 44.331% (11377/25664)
Loss: 1.861 | Acc: 44.115% (14145/32064)
Loss: 1.861 | Acc: 44.132% (16975/38464)
Loss: 1.862 | Acc: 44.149% (19807/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9832, Accuracy: 3835/10000 (38.35%)

Epoch: 55
Loss: 1.730 | Acc: 50.000% (32/64)
Loss: 1.854 | Acc: 44.632% (2885/6464)
Loss: 1.856 | Acc: 44.566% (5733/12864)
Loss: 1.853 | Acc: 44.721% (8615/19264)
Loss: 1.856 | Acc: 44.479% (11415/25664)
Loss: 1.856 | Acc: 44.520% (14275/32064)
Loss: 1.856 | Acc: 44.551% (17136/38464)
Loss: 1.858 | Acc: 44.428% (19932/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0511, Accuracy: 3641/10000 (36.41%)

Epoch: 56
Loss: 2.157 | Acc: 31.250% (20/64)
Loss: 1.865 | Acc: 44.276% (2862/6464)
Loss: 1.857 | Acc: 44.543% (5730/12864)
Loss: 1.855 | Acc: 44.726% (8616/19264)
Loss: 1.865 | Acc: 44.147% (11330/25664)
Loss: 1.861 | Acc: 44.265% (14193/32064)
Loss: 1.859 | Acc: 44.390% (17074/38464)
Loss: 1.859 | Acc: 44.459% (19946/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0150, Accuracy: 3810/10000 (38.10%)

Epoch: 57
Loss: 1.979 | Acc: 42.188% (27/64)
Loss: 1.835 | Acc: 45.699% (2954/6464)
Loss: 1.842 | Acc: 45.328% (5831/12864)
Loss: 1.853 | Acc: 44.902% (8650/19264)
Loss: 1.853 | Acc: 44.880% (11518/25664)
Loss: 1.853 | Acc: 44.954% (14414/32064)
Loss: 1.854 | Acc: 44.904% (17272/38464)
Loss: 1.853 | Acc: 44.927% (20156/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9922, Accuracy: 3704/10000 (37.04%)

Epoch: 58
Loss: 1.715 | Acc: 50.000% (32/64)
Loss: 1.840 | Acc: 45.034% (2911/6464)
Loss: 1.850 | Acc: 44.636% (5742/12864)
Loss: 1.851 | Acc: 44.612% (8594/19264)
Loss: 1.851 | Acc: 44.732% (11480/25664)
Loss: 1.852 | Acc: 44.695% (14331/32064)
Loss: 1.852 | Acc: 44.702% (17194/38464)
Loss: 1.852 | Acc: 44.764% (20083/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0001, Accuracy: 3731/10000 (37.31%)

Epoch: 59
Loss: 1.816 | Acc: 50.000% (32/64)
Loss: 1.858 | Acc: 44.895% (2902/6464)
Loss: 1.843 | Acc: 45.289% (5826/12864)
Loss: 1.848 | Acc: 44.939% (8657/19264)
Loss: 1.845 | Acc: 45.129% (11582/25664)
Loss: 1.847 | Acc: 44.985% (14424/32064)
Loss: 1.848 | Acc: 44.904% (17272/38464)
Loss: 1.851 | Acc: 44.822% (20109/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0270, Accuracy: 3480/10000 (34.80%)

Epoch: 60
Loss: 1.937 | Acc: 39.062% (25/64)
Loss: 1.849 | Acc: 44.926% (2904/6464)
Loss: 1.855 | Acc: 44.714% (5752/12864)
Loss: 1.855 | Acc: 44.871% (8644/19264)
Loss: 1.849 | Acc: 45.137% (11584/25664)
Loss: 1.849 | Acc: 45.088% (14457/32064)
Loss: 1.849 | Acc: 45.138% (17362/38464)
Loss: 1.850 | Acc: 45.076% (20223/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0857, Accuracy: 3587/10000 (35.87%)

Epoch: 61
Loss: 1.868 | Acc: 45.312% (29/64)
Loss: 1.833 | Acc: 45.838% (2963/6464)
Loss: 1.833 | Acc: 45.833% (5896/12864)
Loss: 1.841 | Acc: 45.499% (8765/19264)
Loss: 1.847 | Acc: 45.090% (11572/25664)
Loss: 1.846 | Acc: 45.088% (14457/32064)
Loss: 1.846 | Acc: 45.209% (17389/38464)
Loss: 1.845 | Acc: 45.188% (20273/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0623, Accuracy: 3610/10000 (36.10%)

Epoch: 62
Loss: 1.836 | Acc: 43.750% (28/64)
Loss: 1.830 | Acc: 46.132% (2982/6464)
Loss: 1.833 | Acc: 45.872% (5901/12864)
Loss: 1.833 | Acc: 45.837% (8830/19264)
Loss: 1.833 | Acc: 45.768% (11746/25664)
Loss: 1.840 | Acc: 45.497% (14588/32064)
Loss: 1.841 | Acc: 45.380% (17455/38464)
Loss: 1.842 | Acc: 45.368% (20354/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9369, Accuracy: 4149/10000 (41.49%)

Epoch: 63
Loss: 1.646 | Acc: 56.250% (36/64)
Loss: 1.824 | Acc: 46.086% (2979/6464)
Loss: 1.827 | Acc: 45.950% (5911/12864)
Loss: 1.821 | Acc: 46.351% (8929/19264)
Loss: 1.827 | Acc: 46.057% (11820/25664)
Loss: 1.833 | Acc: 45.709% (14656/32064)
Loss: 1.839 | Acc: 45.398% (17462/38464)
Loss: 1.840 | Acc: 45.406% (20371/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0063, Accuracy: 3669/10000 (36.69%)

Epoch: 64
Loss: 1.942 | Acc: 45.312% (29/64)
Loss: 1.827 | Acc: 45.823% (2962/6464)
Loss: 1.832 | Acc: 45.336% (5832/12864)
Loss: 1.827 | Acc: 45.712% (8806/19264)
Loss: 1.833 | Acc: 45.550% (11690/25664)
Loss: 1.833 | Acc: 45.712% (14657/32064)
Loss: 1.834 | Acc: 45.640% (17555/38464)
Loss: 1.837 | Acc: 45.500% (20413/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9329, Accuracy: 4066/10000 (40.66%)

Epoch: 65
Loss: 1.589 | Acc: 57.812% (37/64)
Loss: 1.820 | Acc: 46.024% (2975/6464)
Loss: 1.819 | Acc: 46.206% (5944/12864)
Loss: 1.831 | Acc: 45.707% (8805/19264)
Loss: 1.835 | Acc: 45.659% (11718/25664)
Loss: 1.836 | Acc: 45.612% (14625/32064)
Loss: 1.838 | Acc: 45.528% (17512/38464)
Loss: 1.835 | Acc: 45.676% (20492/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0178, Accuracy: 3591/10000 (35.91%)

Epoch: 66
Loss: 1.913 | Acc: 42.188% (27/64)
Loss: 1.833 | Acc: 45.854% (2964/6464)
Loss: 1.837 | Acc: 45.709% (5880/12864)
Loss: 1.841 | Acc: 45.614% (8787/19264)
Loss: 1.837 | Acc: 45.780% (11749/25664)
Loss: 1.836 | Acc: 45.774% (14677/32064)
Loss: 1.834 | Acc: 45.843% (17633/38464)
Loss: 1.830 | Acc: 46.001% (20638/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3863, Accuracy: 2343/10000 (23.43%)

Epoch: 67
Loss: 1.684 | Acc: 50.000% (32/64)
Loss: 1.838 | Acc: 45.730% (2956/6464)
Loss: 1.839 | Acc: 45.647% (5872/12864)
Loss: 1.832 | Acc: 45.930% (8848/19264)
Loss: 1.831 | Acc: 45.940% (11790/25664)
Loss: 1.828 | Acc: 46.042% (14763/32064)
Loss: 1.828 | Acc: 45.988% (17689/38464)
Loss: 1.827 | Acc: 46.068% (20668/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9836, Accuracy: 4050/10000 (40.50%)

Epoch: 68
Loss: 1.876 | Acc: 45.312% (29/64)
Loss: 1.827 | Acc: 46.071% (2978/6464)
Loss: 1.815 | Acc: 46.720% (6010/12864)
Loss: 1.822 | Acc: 46.392% (8937/19264)
Loss: 1.813 | Acc: 46.766% (12002/25664)
Loss: 1.814 | Acc: 46.679% (14967/32064)
Loss: 1.819 | Acc: 46.451% (17867/38464)
Loss: 1.819 | Acc: 46.518% (20870/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9098, Accuracy: 4304/10000 (43.04%)

Epoch: 69
Loss: 1.906 | Acc: 43.750% (28/64)
Loss: 1.782 | Acc: 47.958% (3100/6464)
Loss: 1.791 | Acc: 47.707% (6137/12864)
Loss: 1.807 | Acc: 47.088% (9071/19264)
Loss: 1.813 | Acc: 46.859% (12026/25664)
Loss: 1.814 | Acc: 46.725% (14982/32064)
Loss: 1.815 | Acc: 46.732% (17975/38464)
Loss: 1.816 | Acc: 46.630% (20920/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9842, Accuracy: 3822/10000 (38.22%)

Epoch: 70
Loss: 1.925 | Acc: 40.625% (26/64)
Loss: 1.791 | Acc: 47.509% (3071/6464)
Loss: 1.798 | Acc: 47.108% (6060/12864)
Loss: 1.809 | Acc: 46.610% (8979/19264)
Loss: 1.809 | Acc: 46.665% (11976/25664)
Loss: 1.813 | Acc: 46.569% (14932/32064)
Loss: 1.813 | Acc: 46.633% (17937/38464)
Loss: 1.812 | Acc: 46.650% (20929/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0472, Accuracy: 3596/10000 (35.96%)

Epoch: 71
Loss: 1.857 | Acc: 45.312% (29/64)
Loss: 1.780 | Acc: 47.989% (3102/6464)
Loss: 1.792 | Acc: 47.606% (6124/12864)
Loss: 1.798 | Acc: 47.379% (9127/19264)
Loss: 1.802 | Acc: 47.304% (12140/25664)
Loss: 1.805 | Acc: 47.215% (15139/32064)
Loss: 1.805 | Acc: 47.132% (18129/38464)
Loss: 1.806 | Acc: 47.024% (21097/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9735, Accuracy: 3830/10000 (38.30%)

Epoch: 72
Loss: 1.814 | Acc: 46.875% (30/64)
Loss: 1.787 | Acc: 47.772% (3088/6464)
Loss: 1.799 | Acc: 46.976% (6043/12864)
Loss: 1.806 | Acc: 46.735% (9003/19264)
Loss: 1.804 | Acc: 46.902% (12037/25664)
Loss: 1.804 | Acc: 46.947% (15053/32064)
Loss: 1.800 | Acc: 47.145% (18134/38464)
Loss: 1.801 | Acc: 47.171% (21163/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0170, Accuracy: 3720/10000 (37.20%)

Epoch: 73
Loss: 1.637 | Acc: 51.562% (33/64)
Loss: 1.806 | Acc: 46.983% (3037/6464)
Loss: 1.796 | Acc: 47.536% (6115/12864)
Loss: 1.801 | Acc: 47.368% (9125/19264)
Loss: 1.801 | Acc: 47.452% (12178/25664)
Loss: 1.801 | Acc: 47.486% (15226/32064)
Loss: 1.799 | Acc: 47.499% (18270/38464)
Loss: 1.795 | Acc: 47.655% (21380/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9117, Accuracy: 4231/10000 (42.31%)

Epoch: 74
Loss: 1.734 | Acc: 48.438% (31/64)
Loss: 1.791 | Acc: 47.633% (3079/6464)
Loss: 1.789 | Acc: 47.839% (6154/12864)
Loss: 1.789 | Acc: 47.918% (9231/19264)
Loss: 1.791 | Acc: 47.896% (12292/25664)
Loss: 1.786 | Acc: 48.116% (15428/32064)
Loss: 1.790 | Acc: 47.933% (18437/38464)
Loss: 1.790 | Acc: 47.918% (21498/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9310, Accuracy: 4095/10000 (40.95%)

Epoch: 75
Loss: 1.592 | Acc: 50.000% (32/64)
Loss: 1.762 | Acc: 48.608% (3142/6464)
Loss: 1.769 | Acc: 48.492% (6238/12864)
Loss: 1.778 | Acc: 48.245% (9294/19264)
Loss: 1.780 | Acc: 48.091% (12342/25664)
Loss: 1.780 | Acc: 48.119% (15429/32064)
Loss: 1.781 | Acc: 47.983% (18456/38464)
Loss: 1.782 | Acc: 48.003% (21536/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8900, Accuracy: 4374/10000 (43.74%)

Epoch: 76
Loss: 1.670 | Acc: 54.688% (35/64)
Loss: 1.768 | Acc: 48.670% (3146/6464)
Loss: 1.761 | Acc: 48.912% (6292/12864)
Loss: 1.773 | Acc: 48.495% (9342/19264)
Loss: 1.776 | Acc: 48.367% (12413/25664)
Loss: 1.777 | Acc: 48.222% (15462/32064)
Loss: 1.780 | Acc: 48.100% (18501/38464)
Loss: 1.776 | Acc: 48.319% (21678/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9649, Accuracy: 3945/10000 (39.45%)

Epoch: 77
Loss: 1.761 | Acc: 51.562% (33/64)
Loss: 1.775 | Acc: 48.066% (3107/6464)
Loss: 1.767 | Acc: 48.585% (6250/12864)
Loss: 1.769 | Acc: 48.448% (9333/19264)
Loss: 1.776 | Acc: 48.200% (12370/25664)
Loss: 1.773 | Acc: 48.360% (15506/32064)
Loss: 1.770 | Acc: 48.443% (18633/38464)
Loss: 1.771 | Acc: 48.429% (21727/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9794, Accuracy: 3856/10000 (38.56%)

Epoch: 78
Loss: 1.874 | Acc: 43.750% (28/64)
Loss: 1.762 | Acc: 48.747% (3151/6464)
Loss: 1.769 | Acc: 48.360% (6221/12864)
Loss: 1.764 | Acc: 48.630% (9368/19264)
Loss: 1.762 | Acc: 48.796% (12523/25664)
Loss: 1.760 | Acc: 48.908% (15682/32064)
Loss: 1.760 | Acc: 48.900% (18809/38464)
Loss: 1.763 | Acc: 48.848% (21915/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8715, Accuracy: 4534/10000 (45.34%)

Epoch: 79
Loss: 1.592 | Acc: 56.250% (36/64)
Loss: 1.741 | Acc: 49.861% (3223/6464)
Loss: 1.750 | Acc: 49.316% (6344/12864)
Loss: 1.746 | Acc: 49.642% (9563/19264)
Loss: 1.748 | Acc: 49.560% (12719/25664)
Loss: 1.750 | Acc: 49.379% (15833/32064)
Loss: 1.751 | Acc: 49.308% (18966/38464)
Loss: 1.750 | Acc: 49.400% (22163/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8804, Accuracy: 4403/10000 (44.03%)

Epoch: 80
Loss: 1.861 | Acc: 40.625% (26/64)
Loss: 1.761 | Acc: 48.468% (3133/6464)
Loss: 1.744 | Acc: 49.277% (6339/12864)
Loss: 1.739 | Acc: 49.574% (9550/19264)
Loss: 1.739 | Acc: 49.688% (12752/25664)
Loss: 1.742 | Acc: 49.607% (15906/32064)
Loss: 1.743 | Acc: 49.639% (19093/38464)
Loss: 1.745 | Acc: 49.496% (22206/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8728, Accuracy: 4497/10000 (44.97%)

Epoch: 81
Loss: 1.894 | Acc: 45.312% (29/64)
Loss: 1.722 | Acc: 50.217% (3246/6464)
Loss: 1.730 | Acc: 49.977% (6429/12864)
Loss: 1.731 | Acc: 49.881% (9609/19264)
Loss: 1.735 | Acc: 49.770% (12773/25664)
Loss: 1.733 | Acc: 49.894% (15998/32064)
Loss: 1.730 | Acc: 50.055% (19253/38464)
Loss: 1.731 | Acc: 50.009% (22436/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8898, Accuracy: 4334/10000 (43.34%)

Epoch: 82
Loss: 1.682 | Acc: 54.688% (35/64)
Loss: 1.723 | Acc: 50.155% (3242/6464)
Loss: 1.723 | Acc: 50.233% (6462/12864)
Loss: 1.719 | Acc: 50.457% (9720/19264)
Loss: 1.718 | Acc: 50.565% (12977/25664)
Loss: 1.720 | Acc: 50.527% (16201/32064)
Loss: 1.723 | Acc: 50.361% (19371/38464)
Loss: 1.722 | Acc: 50.464% (22640/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8801, Accuracy: 4495/10000 (44.95%)

Epoch: 83
Loss: 1.852 | Acc: 46.875% (30/64)
Loss: 1.687 | Acc: 51.825% (3350/6464)
Loss: 1.689 | Acc: 51.609% (6639/12864)
Loss: 1.693 | Acc: 51.433% (9908/19264)
Loss: 1.704 | Acc: 51.033% (13097/25664)
Loss: 1.704 | Acc: 51.039% (16365/32064)
Loss: 1.706 | Acc: 50.957% (19600/38464)
Loss: 1.706 | Acc: 50.963% (22864/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8951, Accuracy: 4378/10000 (43.78%)

Epoch: 84
Loss: 1.898 | Acc: 43.750% (28/64)
Loss: 1.693 | Acc: 51.562% (3333/6464)
Loss: 1.681 | Acc: 51.975% (6686/12864)
Loss: 1.691 | Acc: 51.505% (9922/19264)
Loss: 1.698 | Acc: 51.138% (13124/25664)
Loss: 1.696 | Acc: 51.201% (16417/32064)
Loss: 1.697 | Acc: 51.170% (19682/38464)
Loss: 1.695 | Acc: 51.264% (22999/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8951, Accuracy: 4435/10000 (44.35%)

Epoch: 85
Loss: 1.620 | Acc: 54.688% (35/64)
Loss: 1.683 | Acc: 51.330% (3318/6464)
Loss: 1.677 | Acc: 51.524% (6628/12864)
Loss: 1.670 | Acc: 51.827% (9984/19264)
Loss: 1.669 | Acc: 51.964% (13336/25664)
Loss: 1.670 | Acc: 51.881% (16635/32064)
Loss: 1.676 | Acc: 51.682% (19879/38464)
Loss: 1.680 | Acc: 51.574% (23138/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9161, Accuracy: 4428/10000 (44.28%)

Epoch: 86
Loss: 1.655 | Acc: 51.562% (33/64)
Loss: 1.643 | Acc: 52.831% (3415/6464)
Loss: 1.639 | Acc: 53.008% (6819/12864)
Loss: 1.637 | Acc: 53.151% (10239/19264)
Loss: 1.647 | Acc: 52.880% (13571/25664)
Loss: 1.654 | Acc: 52.614% (16870/32064)
Loss: 1.659 | Acc: 52.423% (20164/38464)
Loss: 1.658 | Acc: 52.463% (23537/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8806, Accuracy: 4553/10000 (45.53%)

Epoch: 87
Loss: 1.394 | Acc: 64.062% (41/64)
Loss: 1.618 | Acc: 53.713% (3472/6464)
Loss: 1.623 | Acc: 53.553% (6889/12864)
Loss: 1.633 | Acc: 53.104% (10230/19264)
Loss: 1.636 | Acc: 53.047% (13614/25664)
Loss: 1.635 | Acc: 53.066% (17015/32064)
Loss: 1.635 | Acc: 53.078% (20416/38464)
Loss: 1.633 | Acc: 53.178% (23858/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9144, Accuracy: 4521/10000 (45.21%)

Epoch: 88
Loss: 1.767 | Acc: 51.562% (33/64)
Loss: 1.609 | Acc: 53.481% (3457/6464)
Loss: 1.617 | Acc: 53.273% (6853/12864)
Loss: 1.617 | Acc: 53.291% (10266/19264)
Loss: 1.616 | Acc: 53.324% (13685/25664)
Loss: 1.618 | Acc: 53.203% (17059/32064)
Loss: 1.611 | Acc: 53.559% (20601/38464)
Loss: 1.611 | Acc: 53.615% (24054/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9405, Accuracy: 4396/10000 (43.96%)

Epoch: 89
Loss: 1.442 | Acc: 57.812% (37/64)
Loss: 1.579 | Acc: 54.378% (3515/6464)
Loss: 1.559 | Acc: 55.387% (7125/12864)
Loss: 1.568 | Acc: 54.978% (10591/19264)
Loss: 1.572 | Acc: 54.882% (14085/25664)
Loss: 1.573 | Acc: 54.884% (17598/32064)
Loss: 1.577 | Acc: 54.703% (21041/38464)
Loss: 1.580 | Acc: 54.612% (24501/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9310, Accuracy: 4546/10000 (45.46%)

Epoch: 90
Loss: 1.675 | Acc: 54.688% (35/64)
Loss: 1.518 | Acc: 56.900% (3678/6464)
Loss: 1.539 | Acc: 55.846% (7184/12864)
Loss: 1.548 | Acc: 55.456% (10683/19264)
Loss: 1.549 | Acc: 55.381% (14213/25664)
Loss: 1.551 | Acc: 55.258% (17718/32064)
Loss: 1.554 | Acc: 55.174% (21222/38464)
Loss: 1.553 | Acc: 55.115% (24727/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9653, Accuracy: 4392/10000 (43.92%)

Epoch: 91
Loss: 1.636 | Acc: 51.562% (33/64)
Loss: 1.517 | Acc: 55.817% (3608/6464)
Loss: 1.516 | Acc: 55.830% (7182/12864)
Loss: 1.516 | Acc: 55.721% (10734/19264)
Loss: 1.512 | Acc: 55.966% (14363/25664)
Loss: 1.514 | Acc: 55.904% (17925/32064)
Loss: 1.512 | Acc: 56.047% (21558/38464)
Loss: 1.512 | Acc: 56.094% (25166/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9594, Accuracy: 4437/10000 (44.37%)

Epoch: 92
Loss: 1.488 | Acc: 59.375% (38/64)
Loss: 1.461 | Acc: 57.132% (3693/6464)
Loss: 1.447 | Acc: 57.758% (7430/12864)
Loss: 1.450 | Acc: 57.787% (11132/19264)
Loss: 1.456 | Acc: 57.700% (14808/25664)
Loss: 1.464 | Acc: 57.416% (18410/32064)
Loss: 1.462 | Acc: 57.477% (22108/38464)
Loss: 1.462 | Acc: 57.480% (25788/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0603, Accuracy: 4342/10000 (43.42%)

Epoch: 93
Loss: 1.344 | Acc: 60.938% (39/64)
Loss: 1.400 | Acc: 58.369% (3773/6464)
Loss: 1.396 | Acc: 58.870% (7573/12864)
Loss: 1.399 | Acc: 58.913% (11349/19264)
Loss: 1.404 | Acc: 58.752% (15078/25664)
Loss: 1.400 | Acc: 58.910% (18889/32064)
Loss: 1.405 | Acc: 58.712% (22583/38464)
Loss: 1.407 | Acc: 58.686% (26329/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0687, Accuracy: 4321/10000 (43.21%)

Epoch: 94
Loss: 1.377 | Acc: 54.688% (35/64)
Loss: 1.319 | Acc: 61.541% (3978/6464)
Loss: 1.328 | Acc: 61.280% (7883/12864)
Loss: 1.334 | Acc: 60.995% (11750/19264)
Loss: 1.338 | Acc: 60.914% (15633/25664)
Loss: 1.340 | Acc: 60.769% (19485/32064)
Loss: 1.341 | Acc: 60.732% (23360/38464)
Loss: 1.342 | Acc: 60.628% (27200/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1169, Accuracy: 4218/10000 (42.18%)

Epoch: 95
Loss: 0.977 | Acc: 75.000% (48/64)
Loss: 1.259 | Acc: 62.345% (4030/6464)
Loss: 1.271 | Acc: 62.111% (7990/12864)
Loss: 1.274 | Acc: 61.976% (11939/19264)
Loss: 1.278 | Acc: 61.923% (15892/25664)
Loss: 1.281 | Acc: 61.776% (19808/32064)
Loss: 1.280 | Acc: 61.827% (23781/38464)
Loss: 1.277 | Acc: 62.032% (27830/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1765, Accuracy: 4166/10000 (41.66%)

Epoch: 96
Loss: 1.081 | Acc: 68.750% (44/64)
Loss: 1.230 | Acc: 63.490% (4104/6464)
Loss: 1.214 | Acc: 64.078% (8243/12864)
Loss: 1.218 | Acc: 63.621% (12256/19264)
Loss: 1.217 | Acc: 63.618% (16327/25664)
Loss: 1.211 | Acc: 63.894% (20487/32064)
Loss: 1.210 | Acc: 63.964% (24603/38464)
Loss: 1.210 | Acc: 63.996% (28711/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2013, Accuracy: 4154/10000 (41.54%)

Epoch: 97
Loss: 1.308 | Acc: 60.938% (39/64)
Loss: 1.136 | Acc: 65.656% (4244/6464)
Loss: 1.137 | Acc: 65.835% (8469/12864)
Loss: 1.143 | Acc: 65.641% (12645/19264)
Loss: 1.141 | Acc: 65.882% (16908/25664)
Loss: 1.142 | Acc: 65.800% (21098/32064)
Loss: 1.141 | Acc: 65.859% (25332/38464)
Loss: 1.142 | Acc: 65.770% (29507/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2284, Accuracy: 4091/10000 (40.91%)
torch.Size([100, 10])
Test set: Average loss: 2.2284, Accuracy: 4091/10000 (40.91%)

Epoch: 98
Loss: 0.977 | Acc: 79.688% (51/64)
Loss: 1.094 | Acc: 67.497% (4363/6464)
Loss: 1.107 | Acc: 66.814% (8595/12864)
Loss: 1.107 | Acc: 66.871% (12882/19264)
Loss: 1.108 | Acc: 66.825% (17150/25664)
Loss: 1.108 | Acc: 66.757% (21405/32064)
Loss: 1.102 | Acc: 67.034% (25784/38464)
Loss: 1.099 | Acc: 67.081% (30095/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2669, Accuracy: 4056/10000 (40.56%)
torch.Size([100, 10])
Test set: Average loss: 2.2669, Accuracy: 4056/10000 (40.56%)

Epoch: 99
Loss: 1.160 | Acc: 68.750% (44/64)
Loss: 1.076 | Acc: 68.007% (4396/6464)
Loss: 1.083 | Acc: 67.545% (8689/12864)
Loss: 1.080 | Acc: 67.530% (13009/19264)
Loss: 1.080 | Acc: 67.554% (17337/25664)
Loss: 1.079 | Acc: 67.537% (21655/32064)
Loss: 1.078 | Acc: 67.629% (26013/38464)
Loss: 1.079 | Acc: 67.636% (30344/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2853, Accuracy: 4048/10000 (40.48%)
torch.Size([100, 10])
Test set: Average loss: 2.2853, Accuracy: 4048/10000 (40.48%)

Epoch: 100
Loss: 1.082 | Acc: 65.625% (42/64)
Loss: 2.177 | Acc: 23.407% (1513/6464)
Loss: 2.080 | Acc: 30.364% (3906/12864)
Loss: 2.027 | Acc: 34.012% (6552/19264)
Loss: 1.992 | Acc: 36.206% (9292/25664)
Loss: 1.973 | Acc: 37.347% (11975/32064)
Loss: 1.956 | Acc: 38.309% (14735/38464)
Loss: 1.944 | Acc: 38.984% (17490/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0514, Accuracy: 3488/10000 (34.88%)

Epoch: 101
Loss: 2.070 | Acc: 29.688% (19/64)
Loss: 1.848 | Acc: 44.787% (2895/6464)
Loss: 1.850 | Acc: 44.403% (5712/12864)
Loss: 1.843 | Acc: 44.757% (8622/19264)
Loss: 1.848 | Acc: 44.615% (11450/25664)
Loss: 1.847 | Acc: 44.667% (14322/32064)
Loss: 1.846 | Acc: 44.811% (17236/38464)
Loss: 1.849 | Acc: 44.691% (20050/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0804, Accuracy: 3350/10000 (33.50%)

Epoch: 102
Loss: 1.884 | Acc: 35.938% (23/64)
Loss: 1.841 | Acc: 45.715% (2955/6464)
Loss: 1.840 | Acc: 45.507% (5854/12864)
Loss: 1.844 | Acc: 45.333% (8733/19264)
Loss: 1.842 | Acc: 45.453% (11665/25664)
Loss: 1.841 | Acc: 45.475% (14581/32064)
Loss: 1.845 | Acc: 45.258% (17408/38464)
Loss: 1.847 | Acc: 45.203% (20280/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1961, Accuracy: 3176/10000 (31.76%)

Epoch: 103
Loss: 2.002 | Acc: 34.375% (22/64)
Loss: 1.851 | Acc: 44.771% (2894/6464)
Loss: 1.850 | Acc: 44.729% (5754/12864)
Loss: 1.847 | Acc: 45.058% (8680/19264)
Loss: 1.847 | Acc: 45.063% (11565/25664)
Loss: 1.845 | Acc: 45.203% (14494/32064)
Loss: 1.844 | Acc: 45.276% (17415/38464)
Loss: 1.845 | Acc: 45.203% (20280/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5665, Accuracy: 2268/10000 (22.68%)

Epoch: 104
Loss: 1.922 | Acc: 39.062% (25/64)
Loss: 1.830 | Acc: 45.931% (2969/6464)
Loss: 1.835 | Acc: 45.608% (5867/12864)
Loss: 1.830 | Acc: 45.847% (8832/19264)
Loss: 1.834 | Acc: 45.698% (11728/25664)
Loss: 1.837 | Acc: 45.562% (14609/32064)
Loss: 1.842 | Acc: 45.359% (17447/38464)
Loss: 1.841 | Acc: 45.377% (20358/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0290, Accuracy: 3611/10000 (36.11%)

Epoch: 105
Loss: 2.067 | Acc: 31.250% (20/64)
Loss: 1.854 | Acc: 44.585% (2882/6464)
Loss: 1.832 | Acc: 45.725% (5882/12864)
Loss: 1.838 | Acc: 45.344% (8735/19264)
Loss: 1.835 | Acc: 45.500% (11677/25664)
Loss: 1.836 | Acc: 45.500% (14589/32064)
Loss: 1.838 | Acc: 45.476% (17492/38464)
Loss: 1.838 | Acc: 45.393% (20365/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1737, Accuracy: 2871/10000 (28.71%)

Epoch: 106
Loss: 2.123 | Acc: 34.375% (22/64)
Loss: 1.842 | Acc: 45.498% (2941/6464)
Loss: 1.852 | Acc: 44.924% (5779/12864)
Loss: 1.848 | Acc: 45.094% (8687/19264)
Loss: 1.847 | Acc: 45.250% (11613/25664)
Loss: 1.846 | Acc: 45.394% (14555/32064)
Loss: 1.846 | Acc: 45.406% (17465/38464)
Loss: 1.844 | Acc: 45.515% (20420/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0139, Accuracy: 3575/10000 (35.75%)

Epoch: 107
Loss: 2.032 | Acc: 35.938% (23/64)
Loss: 1.815 | Acc: 46.597% (3012/6464)
Loss: 1.827 | Acc: 45.802% (5892/12864)
Loss: 1.827 | Acc: 45.837% (8830/19264)
Loss: 1.832 | Acc: 45.574% (11696/25664)
Loss: 1.831 | Acc: 45.671% (14644/32064)
Loss: 1.835 | Acc: 45.497% (17500/38464)
Loss: 1.837 | Acc: 45.444% (20388/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0477, Accuracy: 3546/10000 (35.46%)

Epoch: 108
Loss: 1.991 | Acc: 37.500% (24/64)
Loss: 1.828 | Acc: 46.256% (2990/6464)
Loss: 1.822 | Acc: 46.276% (5953/12864)
Loss: 1.824 | Acc: 46.242% (8908/19264)
Loss: 1.828 | Acc: 46.018% (11810/25664)
Loss: 1.829 | Acc: 45.893% (14715/32064)
Loss: 1.833 | Acc: 45.749% (17597/38464)
Loss: 1.834 | Acc: 45.687% (20497/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1053, Accuracy: 3458/10000 (34.58%)

Epoch: 109
Loss: 1.723 | Acc: 50.000% (32/64)
Loss: 1.846 | Acc: 45.374% (2933/6464)
Loss: 1.826 | Acc: 46.253% (5950/12864)
Loss: 1.831 | Acc: 46.076% (8876/19264)
Loss: 1.831 | Acc: 45.983% (11801/25664)
Loss: 1.834 | Acc: 45.774% (14677/32064)
Loss: 1.835 | Acc: 45.697% (17577/38464)
Loss: 1.835 | Acc: 45.747% (20524/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9321, Accuracy: 4187/10000 (41.87%)

Epoch: 110
Loss: 1.889 | Acc: 43.750% (28/64)
Loss: 1.839 | Acc: 45.637% (2950/6464)
Loss: 1.831 | Acc: 46.105% (5931/12864)
Loss: 1.831 | Acc: 46.034% (8868/19264)
Loss: 1.831 | Acc: 46.088% (11828/25664)
Loss: 1.832 | Acc: 45.974% (14741/32064)
Loss: 1.832 | Acc: 45.892% (17652/38464)
Loss: 1.830 | Acc: 45.961% (20620/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0617, Accuracy: 3505/10000 (35.05%)

Epoch: 111
Loss: 1.826 | Acc: 43.750% (28/64)
Loss: 1.811 | Acc: 46.426% (3001/6464)
Loss: 1.812 | Acc: 46.440% (5974/12864)
Loss: 1.817 | Acc: 46.237% (8907/19264)
Loss: 1.821 | Acc: 46.232% (11865/25664)
Loss: 1.826 | Acc: 46.077% (14774/32064)
Loss: 1.829 | Acc: 46.009% (17697/38464)
Loss: 1.830 | Acc: 45.983% (20630/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0004, Accuracy: 3933/10000 (39.33%)

Epoch: 112
Loss: 1.910 | Acc: 39.062% (25/64)
Loss: 1.811 | Acc: 47.045% (3041/6464)
Loss: 1.818 | Acc: 46.479% (5979/12864)
Loss: 1.822 | Acc: 46.351% (8929/19264)
Loss: 1.827 | Acc: 46.135% (11840/25664)
Loss: 1.827 | Acc: 46.130% (14791/32064)
Loss: 1.831 | Acc: 45.994% (17691/38464)
Loss: 1.828 | Acc: 46.104% (20684/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9543, Accuracy: 3957/10000 (39.57%)

Epoch: 113
Loss: 1.747 | Acc: 51.562% (33/64)
Loss: 1.805 | Acc: 46.890% (3031/6464)
Loss: 1.813 | Acc: 46.308% (5957/12864)
Loss: 1.819 | Acc: 46.211% (8902/19264)
Loss: 1.820 | Acc: 46.146% (11843/25664)
Loss: 1.822 | Acc: 46.164% (14802/32064)
Loss: 1.828 | Acc: 45.931% (17667/38464)
Loss: 1.827 | Acc: 46.066% (20667/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0442, Accuracy: 3539/10000 (35.39%)

Epoch: 114
Loss: 1.743 | Acc: 51.562% (33/64)
Loss: 1.814 | Acc: 46.937% (3034/6464)
Loss: 1.817 | Acc: 46.657% (6002/12864)
Loss: 1.816 | Acc: 46.673% (8991/19264)
Loss: 1.813 | Acc: 46.680% (11980/25664)
Loss: 1.817 | Acc: 46.557% (14928/32064)
Loss: 1.820 | Acc: 46.428% (17858/38464)
Loss: 1.822 | Acc: 46.338% (20789/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2337, Accuracy: 2968/10000 (29.68%)

Epoch: 115
Loss: 1.736 | Acc: 50.000% (32/64)
Loss: 1.788 | Acc: 47.447% (3067/6464)
Loss: 1.816 | Acc: 46.362% (5964/12864)
Loss: 1.814 | Acc: 46.538% (8965/19264)
Loss: 1.818 | Acc: 46.427% (11915/25664)
Loss: 1.820 | Acc: 46.348% (14861/32064)
Loss: 1.818 | Acc: 46.469% (17874/38464)
Loss: 1.817 | Acc: 46.530% (20875/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9252, Accuracy: 4148/10000 (41.48%)

Epoch: 116
Loss: 1.605 | Acc: 59.375% (38/64)
Loss: 1.806 | Acc: 47.138% (3047/6464)
Loss: 1.807 | Acc: 47.038% (6051/12864)
Loss: 1.813 | Acc: 46.792% (9014/19264)
Loss: 1.814 | Acc: 46.891% (12034/25664)
Loss: 1.811 | Acc: 47.009% (15073/32064)
Loss: 1.811 | Acc: 46.979% (18070/38464)
Loss: 1.814 | Acc: 46.837% (21013/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1987, Accuracy: 2785/10000 (27.85%)

Epoch: 117
Loss: 1.660 | Acc: 51.562% (33/64)
Loss: 1.801 | Acc: 46.968% (3036/6464)
Loss: 1.809 | Acc: 46.782% (6018/12864)
Loss: 1.811 | Acc: 46.730% (9002/19264)
Loss: 1.816 | Acc: 46.602% (11960/25664)
Loss: 1.816 | Acc: 46.591% (14939/32064)
Loss: 1.817 | Acc: 46.568% (17912/38464)
Loss: 1.815 | Acc: 46.690% (20947/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0507, Accuracy: 3447/10000 (34.47%)

Epoch: 118
Loss: 1.992 | Acc: 42.188% (27/64)
Loss: 1.797 | Acc: 47.494% (3070/6464)
Loss: 1.800 | Acc: 47.497% (6110/12864)
Loss: 1.803 | Acc: 47.368% (9125/19264)
Loss: 1.804 | Acc: 47.311% (12142/25664)
Loss: 1.805 | Acc: 47.262% (15154/32064)
Loss: 1.804 | Acc: 47.247% (18173/38464)
Loss: 1.805 | Acc: 47.158% (21157/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0539, Accuracy: 3586/10000 (35.86%)

Epoch: 119
Loss: 1.701 | Acc: 51.562% (33/64)
Loss: 1.815 | Acc: 46.798% (3025/6464)
Loss: 1.806 | Acc: 47.178% (6069/12864)
Loss: 1.794 | Acc: 47.524% (9155/19264)
Loss: 1.798 | Acc: 47.448% (12177/25664)
Loss: 1.799 | Acc: 47.508% (15233/32064)
Loss: 1.802 | Acc: 47.403% (18233/38464)
Loss: 1.803 | Acc: 47.292% (21217/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9815, Accuracy: 3810/10000 (38.10%)

Epoch: 120
Loss: 1.621 | Acc: 54.688% (35/64)
Loss: 1.814 | Acc: 46.736% (3021/6464)
Loss: 1.809 | Acc: 47.093% (6058/12864)
Loss: 1.799 | Acc: 47.462% (9143/19264)
Loss: 1.798 | Acc: 47.530% (12198/25664)
Loss: 1.799 | Acc: 47.583% (15257/32064)
Loss: 1.798 | Acc: 47.574% (18299/38464)
Loss: 1.801 | Acc: 47.419% (21274/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9627, Accuracy: 4052/10000 (40.52%)

Epoch: 121
Loss: 1.774 | Acc: 50.000% (32/64)
Loss: 1.789 | Acc: 48.144% (3112/6464)
Loss: 1.789 | Acc: 47.847% (6155/12864)
Loss: 1.786 | Acc: 47.944% (9236/19264)
Loss: 1.792 | Acc: 47.693% (12240/25664)
Loss: 1.789 | Acc: 47.857% (15345/32064)
Loss: 1.792 | Acc: 47.749% (18366/38464)
Loss: 1.793 | Acc: 47.695% (21398/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9194, Accuracy: 4194/10000 (41.94%)

Epoch: 122
Loss: 1.927 | Acc: 42.188% (27/64)
Loss: 1.781 | Acc: 47.927% (3098/6464)
Loss: 1.788 | Acc: 47.847% (6155/12864)
Loss: 1.787 | Acc: 47.877% (9223/19264)
Loss: 1.783 | Acc: 48.102% (12345/25664)
Loss: 1.786 | Acc: 47.960% (15378/32064)
Loss: 1.785 | Acc: 48.035% (18476/38464)
Loss: 1.788 | Acc: 47.903% (21491/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8694, Accuracy: 4468/10000 (44.68%)

Epoch: 123
Loss: 1.821 | Acc: 43.750% (28/64)
Loss: 1.774 | Acc: 48.314% (3123/6464)
Loss: 1.781 | Acc: 48.391% (6225/12864)
Loss: 1.778 | Acc: 48.318% (9308/19264)
Loss: 1.774 | Acc: 48.461% (12437/25664)
Loss: 1.774 | Acc: 48.534% (15562/32064)
Loss: 1.777 | Acc: 48.445% (18634/38464)
Loss: 1.780 | Acc: 48.313% (21675/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8606, Accuracy: 4496/10000 (44.96%)

Epoch: 124
Loss: 1.681 | Acc: 54.688% (35/64)
Loss: 1.770 | Acc: 48.716% (3149/6464)
Loss: 1.762 | Acc: 49.223% (6332/12864)
Loss: 1.764 | Acc: 49.076% (9454/19264)
Loss: 1.763 | Acc: 49.002% (12576/25664)
Loss: 1.769 | Acc: 48.687% (15611/32064)
Loss: 1.773 | Acc: 48.505% (18657/38464)
Loss: 1.777 | Acc: 48.388% (21709/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9573, Accuracy: 4065/10000 (40.65%)

Epoch: 125
Loss: 1.777 | Acc: 50.000% (32/64)
Loss: 1.775 | Acc: 48.608% (3142/6464)
Loss: 1.760 | Acc: 49.129% (6320/12864)
Loss: 1.761 | Acc: 48.998% (9439/19264)
Loss: 1.757 | Acc: 49.092% (12599/25664)
Loss: 1.765 | Acc: 48.768% (15637/32064)
Loss: 1.765 | Acc: 48.700% (18732/38464)
Loss: 1.766 | Acc: 48.727% (21861/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8765, Accuracy: 4403/10000 (44.03%)

Epoch: 126
Loss: 1.647 | Acc: 51.562% (33/64)
Loss: 1.732 | Acc: 50.139% (3241/6464)
Loss: 1.754 | Acc: 49.129% (6320/12864)
Loss: 1.755 | Acc: 49.060% (9451/19264)
Loss: 1.761 | Acc: 48.788% (12521/25664)
Loss: 1.765 | Acc: 48.603% (15584/32064)
Loss: 1.758 | Acc: 49.015% (18853/38464)
Loss: 1.759 | Acc: 49.015% (21990/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9367, Accuracy: 4214/10000 (42.14%)

Epoch: 127
Loss: 1.744 | Acc: 54.688% (35/64)
Loss: 1.758 | Acc: 49.010% (3168/6464)
Loss: 1.753 | Acc: 49.417% (6357/12864)
Loss: 1.756 | Acc: 49.336% (9504/19264)
Loss: 1.755 | Acc: 49.396% (12677/25664)
Loss: 1.757 | Acc: 49.264% (15796/32064)
Loss: 1.753 | Acc: 49.415% (19007/38464)
Loss: 1.751 | Acc: 49.434% (22178/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9352, Accuracy: 4065/10000 (40.65%)

Epoch: 128
Loss: 2.150 | Acc: 31.250% (20/64)
Loss: 1.730 | Acc: 50.402% (3258/6464)
Loss: 1.736 | Acc: 49.914% (6421/12864)
Loss: 1.735 | Acc: 50.000% (9632/19264)
Loss: 1.741 | Acc: 49.829% (12788/25664)
Loss: 1.742 | Acc: 49.797% (15967/32064)
Loss: 1.743 | Acc: 49.693% (19114/38464)
Loss: 1.744 | Acc: 49.634% (22268/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9117, Accuracy: 4285/10000 (42.85%)

Epoch: 129
Loss: 1.749 | Acc: 51.562% (33/64)
Loss: 1.725 | Acc: 50.804% (3284/6464)
Loss: 1.721 | Acc: 50.847% (6541/12864)
Loss: 1.721 | Acc: 50.664% (9760/19264)
Loss: 1.722 | Acc: 50.479% (12955/25664)
Loss: 1.729 | Acc: 50.147% (16079/32064)
Loss: 1.733 | Acc: 50.070% (19259/38464)
Loss: 1.735 | Acc: 50.025% (22443/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9461, Accuracy: 4067/10000 (40.67%)

Epoch: 130
Loss: 1.871 | Acc: 46.875% (30/64)
Loss: 1.720 | Acc: 50.480% (3263/6464)
Loss: 1.725 | Acc: 50.264% (6466/12864)
Loss: 1.729 | Acc: 50.073% (9646/19264)
Loss: 1.729 | Acc: 50.023% (12838/25664)
Loss: 1.727 | Acc: 50.168% (16086/32064)
Loss: 1.728 | Acc: 50.169% (19297/38464)
Loss: 1.725 | Acc: 50.263% (22550/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9509, Accuracy: 4155/10000 (41.55%)

Epoch: 131
Loss: 1.857 | Acc: 45.312% (29/64)
Loss: 1.690 | Acc: 51.609% (3336/6464)
Loss: 1.704 | Acc: 50.948% (6554/12864)
Loss: 1.702 | Acc: 51.189% (9861/19264)
Loss: 1.702 | Acc: 51.149% (13127/25664)
Loss: 1.707 | Acc: 51.004% (16354/32064)
Loss: 1.712 | Acc: 50.835% (19553/38464)
Loss: 1.716 | Acc: 50.666% (22731/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8863, Accuracy: 4417/10000 (44.17%)

Epoch: 132
Loss: 2.199 | Acc: 29.688% (19/64)
Loss: 1.693 | Acc: 51.377% (3321/6464)
Loss: 1.690 | Acc: 51.493% (6624/12864)
Loss: 1.696 | Acc: 51.189% (9861/19264)
Loss: 1.696 | Acc: 51.188% (13137/25664)
Loss: 1.698 | Acc: 51.207% (16419/32064)
Loss: 1.702 | Acc: 51.053% (19637/38464)
Loss: 1.701 | Acc: 51.117% (22933/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9125, Accuracy: 4293/10000 (42.93%)

Epoch: 133
Loss: 1.694 | Acc: 50.000% (32/64)
Loss: 1.647 | Acc: 53.171% (3437/6464)
Loss: 1.679 | Acc: 51.726% (6654/12864)
Loss: 1.695 | Acc: 50.981% (9821/19264)
Loss: 1.693 | Acc: 51.149% (13127/25664)
Loss: 1.693 | Acc: 51.182% (16411/32064)
Loss: 1.690 | Acc: 51.266% (19719/38464)
Loss: 1.688 | Acc: 51.360% (23042/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9287, Accuracy: 4358/10000 (43.58%)

Epoch: 134
Loss: 1.544 | Acc: 59.375% (38/64)
Loss: 1.666 | Acc: 52.073% (3366/6464)
Loss: 1.676 | Acc: 51.640% (6643/12864)
Loss: 1.677 | Acc: 51.729% (9965/19264)
Loss: 1.675 | Acc: 51.820% (13299/25664)
Loss: 1.677 | Acc: 51.718% (16583/32064)
Loss: 1.672 | Acc: 51.965% (19988/38464)
Loss: 1.670 | Acc: 52.026% (23341/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9010, Accuracy: 4437/10000 (44.37%)

Epoch: 135
Loss: 1.810 | Acc: 45.312% (29/64)
Loss: 1.651 | Acc: 52.413% (3388/6464)
Loss: 1.640 | Acc: 52.775% (6789/12864)
Loss: 1.643 | Acc: 52.663% (10145/19264)
Loss: 1.647 | Acc: 52.642% (13510/25664)
Loss: 1.647 | Acc: 52.863% (16950/32064)
Loss: 1.651 | Acc: 52.745% (20288/38464)
Loss: 1.653 | Acc: 52.715% (23650/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9303, Accuracy: 4283/10000 (42.83%)

Epoch: 136
Loss: 2.020 | Acc: 34.375% (22/64)
Loss: 1.632 | Acc: 53.125% (3434/6464)
Loss: 1.621 | Acc: 53.599% (6895/12864)
Loss: 1.621 | Acc: 53.670% (10339/19264)
Loss: 1.631 | Acc: 53.207% (13655/25664)
Loss: 1.634 | Acc: 53.122% (17033/32064)
Loss: 1.636 | Acc: 53.063% (20410/38464)
Loss: 1.634 | Acc: 53.147% (23844/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9128, Accuracy: 4462/10000 (44.62%)

Epoch: 137
Loss: 1.602 | Acc: 50.000% (32/64)
Loss: 1.576 | Acc: 55.121% (3563/6464)
Loss: 1.584 | Acc: 54.874% (7059/12864)
Loss: 1.598 | Acc: 54.246% (10450/19264)
Loss: 1.595 | Acc: 54.411% (13964/25664)
Loss: 1.597 | Acc: 54.360% (17430/32064)
Loss: 1.601 | Acc: 54.118% (20816/38464)
Loss: 1.604 | Acc: 54.017% (24234/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9457, Accuracy: 4336/10000 (43.36%)

Epoch: 138
Loss: 1.671 | Acc: 50.000% (32/64)
Loss: 1.558 | Acc: 55.384% (3580/6464)
Loss: 1.562 | Acc: 55.131% (7092/12864)
Loss: 1.567 | Acc: 54.963% (10588/19264)
Loss: 1.574 | Acc: 54.684% (14034/25664)
Loss: 1.576 | Acc: 54.625% (17515/32064)
Loss: 1.575 | Acc: 54.674% (21030/38464)
Loss: 1.572 | Acc: 54.792% (24582/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9199, Accuracy: 4422/10000 (44.22%)

Epoch: 139
Loss: 1.534 | Acc: 54.688% (35/64)
Loss: 1.521 | Acc: 56.296% (3639/6464)
Loss: 1.526 | Acc: 55.993% (7203/12864)
Loss: 1.527 | Acc: 56.089% (10805/19264)
Loss: 1.532 | Acc: 55.966% (14363/25664)
Loss: 1.537 | Acc: 55.751% (17876/32064)
Loss: 1.539 | Acc: 55.649% (21405/38464)
Loss: 1.545 | Acc: 55.501% (24900/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9391, Accuracy: 4452/10000 (44.52%)

Epoch: 140
Loss: 1.640 | Acc: 50.000% (32/64)
Loss: 1.480 | Acc: 57.689% (3729/6464)
Loss: 1.493 | Acc: 56.849% (7313/12864)
Loss: 1.495 | Acc: 57.018% (10984/19264)
Loss: 1.499 | Acc: 56.807% (14579/25664)
Loss: 1.499 | Acc: 56.746% (18195/32064)
Loss: 1.504 | Acc: 56.562% (21756/38464)
Loss: 1.506 | Acc: 56.529% (25361/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9773, Accuracy: 4433/10000 (44.33%)

Epoch: 141
Loss: 1.472 | Acc: 59.375% (38/64)
Loss: 1.436 | Acc: 58.416% (3776/6464)
Loss: 1.445 | Acc: 58.209% (7488/12864)
Loss: 1.450 | Acc: 58.114% (11195/19264)
Loss: 1.459 | Acc: 57.676% (14802/25664)
Loss: 1.459 | Acc: 57.728% (18510/32064)
Loss: 1.459 | Acc: 57.729% (22205/38464)
Loss: 1.461 | Acc: 57.708% (25890/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0174, Accuracy: 4407/10000 (44.07%)

Epoch: 142
Loss: 1.209 | Acc: 70.312% (45/64)
Loss: 1.411 | Acc: 58.524% (3783/6464)
Loss: 1.407 | Acc: 59.095% (7602/12864)
Loss: 1.414 | Acc: 58.804% (11328/19264)
Loss: 1.413 | Acc: 58.779% (15085/25664)
Loss: 1.417 | Acc: 58.792% (18851/32064)
Loss: 1.413 | Acc: 58.871% (22644/38464)
Loss: 1.415 | Acc: 58.865% (26409/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0657, Accuracy: 4290/10000 (42.90%)

Epoch: 143
Loss: 1.201 | Acc: 67.188% (43/64)
Loss: 1.339 | Acc: 60.907% (3937/6464)
Loss: 1.349 | Acc: 60.432% (7774/12864)
Loss: 1.346 | Acc: 60.673% (11688/19264)
Loss: 1.352 | Acc: 60.291% (15473/25664)
Loss: 1.352 | Acc: 60.342% (19348/32064)
Loss: 1.355 | Acc: 60.282% (23187/38464)
Loss: 1.356 | Acc: 60.175% (26997/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1131, Accuracy: 4254/10000 (42.54%)

Epoch: 144
Loss: 1.325 | Acc: 62.500% (40/64)
Loss: 1.275 | Acc: 62.113% (4015/6464)
Loss: 1.284 | Acc: 61.808% (7951/12864)
Loss: 1.279 | Acc: 62.090% (11961/19264)
Loss: 1.283 | Acc: 62.169% (15955/25664)
Loss: 1.282 | Acc: 62.250% (19960/32064)
Loss: 1.282 | Acc: 62.222% (23933/38464)
Loss: 1.284 | Acc: 62.117% (27868/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2047, Accuracy: 4249/10000 (42.49%)

Epoch: 145
Loss: 1.099 | Acc: 64.062% (41/64)
Loss: 1.206 | Acc: 63.830% (4126/6464)
Loss: 1.207 | Acc: 63.961% (8228/12864)
Loss: 1.207 | Acc: 64.146% (12357/19264)
Loss: 1.210 | Acc: 64.039% (16435/25664)
Loss: 1.211 | Acc: 64.069% (20543/32064)
Loss: 1.215 | Acc: 63.852% (24560/38464)
Loss: 1.216 | Acc: 63.866% (28653/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2319, Accuracy: 4025/10000 (40.25%)

Epoch: 146
Loss: 1.273 | Acc: 59.375% (38/64)
Loss: 1.117 | Acc: 66.522% (4300/6464)
Loss: 1.124 | Acc: 66.449% (8548/12864)
Loss: 1.131 | Acc: 66.071% (12728/19264)
Loss: 1.133 | Acc: 66.124% (16970/25664)
Loss: 1.131 | Acc: 66.149% (21210/32064)
Loss: 1.136 | Acc: 65.976% (25377/38464)
Loss: 1.137 | Acc: 66.008% (29614/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2918, Accuracy: 4115/10000 (41.15%)

Epoch: 147
Loss: 1.023 | Acc: 68.750% (44/64)
Loss: 1.076 | Acc: 67.543% (4366/6464)
Loss: 1.079 | Acc: 67.825% (8725/12864)
Loss: 1.079 | Acc: 67.722% (13046/19264)
Loss: 1.076 | Acc: 67.834% (17409/25664)
Loss: 1.077 | Acc: 67.824% (21747/32064)
Loss: 1.081 | Acc: 67.653% (26022/38464)
Loss: 1.079 | Acc: 67.743% (30392/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3202, Accuracy: 4022/10000 (40.22%)
torch.Size([100, 10])
Test set: Average loss: 2.3202, Accuracy: 4022/10000 (40.22%)

Epoch: 148
Loss: 0.894 | Acc: 71.875% (46/64)
Loss: 1.012 | Acc: 69.183% (4472/6464)
Loss: 1.037 | Acc: 68.789% (8849/12864)
Loss: 1.033 | Acc: 69.061% (13304/19264)
Loss: 1.033 | Acc: 69.147% (17746/25664)
Loss: 1.033 | Acc: 69.081% (22150/32064)
Loss: 1.036 | Acc: 69.005% (26542/38464)
Loss: 1.035 | Acc: 69.031% (30970/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3404, Accuracy: 3990/10000 (39.90%)
torch.Size([100, 10])
Test set: Average loss: 2.3404, Accuracy: 3990/10000 (39.90%)

Epoch: 149
Loss: 1.066 | Acc: 68.750% (44/64)
Loss: 1.012 | Acc: 69.771% (4510/6464)
Loss: 1.018 | Acc: 69.737% (8971/12864)
Loss: 1.017 | Acc: 69.581% (13404/19264)
Loss: 1.022 | Acc: 69.323% (17791/25664)
Loss: 1.020 | Acc: 69.452% (22269/32064)
Loss: 1.020 | Acc: 69.499% (26732/38464)
Loss: 1.019 | Acc: 69.472% (31168/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3585, Accuracy: 4021/10000 (40.21%)
torch.Size([100, 10])
Test set: Average loss: 2.3585, Accuracy: 4021/10000 (40.21%)

Epoch: 150
Loss: 1.017 | Acc: 68.750% (44/64)
Loss: 2.279 | Acc: 14.790% (956/6464)
Loss: 2.193 | Acc: 21.230% (2731/12864)
Loss: 2.123 | Acc: 26.594% (5123/19264)
Loss: 2.069 | Acc: 30.494% (7826/25664)
Loss: 2.030 | Acc: 33.068% (10603/32064)
Loss: 2.005 | Acc: 34.762% (13371/38464)
Loss: 1.984 | Acc: 36.145% (16216/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5514, Accuracy: 1957/10000 (19.57%)

Epoch: 151
Loss: 1.937 | Acc: 39.062% (25/64)
Loss: 1.852 | Acc: 44.725% (2891/6464)
Loss: 1.843 | Acc: 45.375% (5837/12864)
Loss: 1.847 | Acc: 45.193% (8706/19264)
Loss: 1.848 | Acc: 45.102% (11575/25664)
Loss: 1.851 | Acc: 44.973% (14420/32064)
Loss: 1.852 | Acc: 44.993% (17306/38464)
Loss: 1.853 | Acc: 44.931% (20158/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2193, Accuracy: 3179/10000 (31.79%)

Epoch: 152
Loss: 1.605 | Acc: 57.812% (37/64)
Loss: 1.822 | Acc: 45.838% (2963/6464)
Loss: 1.831 | Acc: 45.927% (5908/12864)
Loss: 1.835 | Acc: 45.671% (8798/19264)
Loss: 1.839 | Acc: 45.476% (11671/25664)
Loss: 1.841 | Acc: 45.303% (14526/32064)
Loss: 1.841 | Acc: 45.320% (17432/38464)
Loss: 1.841 | Acc: 45.339% (20341/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0349, Accuracy: 3502/10000 (35.02%)

Epoch: 153
Loss: 1.761 | Acc: 46.875% (30/64)
Loss: 1.844 | Acc: 45.436% (2937/6464)
Loss: 1.833 | Acc: 45.903% (5905/12864)
Loss: 1.839 | Acc: 45.463% (8758/19264)
Loss: 1.830 | Acc: 46.037% (11815/25664)
Loss: 1.832 | Acc: 45.971% (14740/32064)
Loss: 1.836 | Acc: 45.788% (17612/38464)
Loss: 1.836 | Acc: 45.776% (20537/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9976, Accuracy: 3686/10000 (36.86%)

Epoch: 154
Loss: 2.145 | Acc: 29.688% (19/64)
Loss: 1.829 | Acc: 46.055% (2977/6464)
Loss: 1.827 | Acc: 46.028% (5921/12864)
Loss: 1.832 | Acc: 45.790% (8821/19264)
Loss: 1.833 | Acc: 45.811% (11757/25664)
Loss: 1.830 | Acc: 45.911% (14721/32064)
Loss: 1.830 | Acc: 45.944% (17672/38464)
Loss: 1.831 | Acc: 45.954% (20617/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0782, Accuracy: 3256/10000 (32.56%)

Epoch: 155
Loss: 1.827 | Acc: 48.438% (31/64)
Loss: 1.842 | Acc: 45.251% (2925/6464)
Loss: 1.841 | Acc: 45.289% (5826/12864)
Loss: 1.832 | Acc: 45.873% (8837/19264)
Loss: 1.829 | Acc: 46.096% (11830/25664)
Loss: 1.829 | Acc: 46.176% (14806/32064)
Loss: 1.830 | Acc: 45.996% (17692/38464)
Loss: 1.831 | Acc: 45.934% (20608/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0313, Accuracy: 3635/10000 (36.35%)

Epoch: 156
Loss: 1.593 | Acc: 56.250% (36/64)
Loss: 1.834 | Acc: 45.931% (2969/6464)
Loss: 1.835 | Acc: 45.802% (5892/12864)
Loss: 1.827 | Acc: 46.242% (8908/19264)
Loss: 1.827 | Acc: 46.216% (11861/25664)
Loss: 1.831 | Acc: 46.020% (14756/32064)
Loss: 1.831 | Acc: 46.017% (17700/38464)
Loss: 1.831 | Acc: 46.084% (20675/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9478, Accuracy: 3963/10000 (39.63%)

Epoch: 157
Loss: 1.919 | Acc: 43.750% (28/64)
Loss: 1.834 | Acc: 45.374% (2933/6464)
Loss: 1.828 | Acc: 45.833% (5896/12864)
Loss: 1.830 | Acc: 45.858% (8834/19264)
Loss: 1.830 | Acc: 45.792% (11752/25664)
Loss: 1.832 | Acc: 45.749% (14669/32064)
Loss: 1.833 | Acc: 45.804% (17618/38464)
Loss: 1.832 | Acc: 45.847% (20569/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0004, Accuracy: 3894/10000 (38.94%)

Epoch: 158
Loss: 1.945 | Acc: 45.312% (29/64)
Loss: 1.824 | Acc: 46.287% (2992/6464)
Loss: 1.824 | Acc: 46.020% (5920/12864)
Loss: 1.828 | Acc: 45.878% (8838/19264)
Loss: 1.828 | Acc: 45.940% (11790/25664)
Loss: 1.828 | Acc: 46.030% (14759/32064)
Loss: 1.826 | Acc: 46.228% (17781/38464)
Loss: 1.826 | Acc: 46.204% (20729/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9781, Accuracy: 3985/10000 (39.85%)

Epoch: 159
Loss: 1.687 | Acc: 51.562% (33/64)
Loss: 1.819 | Acc: 46.334% (2995/6464)
Loss: 1.821 | Acc: 46.416% (5971/12864)
Loss: 1.822 | Acc: 46.278% (8915/19264)
Loss: 1.825 | Acc: 46.193% (11855/25664)
Loss: 1.826 | Acc: 46.198% (14813/32064)
Loss: 1.828 | Acc: 46.111% (17736/38464)
Loss: 1.828 | Acc: 46.188% (20722/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1681, Accuracy: 2982/10000 (29.82%)

Epoch: 160
Loss: 1.853 | Acc: 46.875% (30/64)
Loss: 1.813 | Acc: 46.689% (3018/6464)
Loss: 1.817 | Acc: 46.634% (5999/12864)
Loss: 1.815 | Acc: 46.735% (9003/19264)
Loss: 1.822 | Acc: 46.481% (11929/25664)
Loss: 1.821 | Acc: 46.473% (14901/32064)
Loss: 1.822 | Acc: 46.438% (17862/38464)
Loss: 1.825 | Acc: 46.302% (20773/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0310, Accuracy: 3542/10000 (35.42%)

Epoch: 161
Loss: 2.052 | Acc: 39.062% (25/64)
Loss: 1.830 | Acc: 46.334% (2995/6464)
Loss: 1.818 | Acc: 46.595% (5994/12864)
Loss: 1.825 | Acc: 46.330% (8925/19264)
Loss: 1.827 | Acc: 46.224% (11863/25664)
Loss: 1.826 | Acc: 46.276% (14838/32064)
Loss: 1.825 | Acc: 46.345% (17826/38464)
Loss: 1.824 | Acc: 46.360% (20799/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9548, Accuracy: 3972/10000 (39.72%)

Epoch: 162
Loss: 1.731 | Acc: 54.688% (35/64)
Loss: 1.814 | Acc: 46.581% (3011/6464)
Loss: 1.811 | Acc: 46.797% (6020/12864)
Loss: 1.813 | Acc: 46.896% (9034/19264)
Loss: 1.816 | Acc: 46.723% (11991/25664)
Loss: 1.822 | Acc: 46.417% (14883/32064)
Loss: 1.819 | Acc: 46.592% (17921/38464)
Loss: 1.820 | Acc: 46.472% (20849/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2301, Accuracy: 2857/10000 (28.57%)

Epoch: 163
Loss: 1.862 | Acc: 43.750% (28/64)
Loss: 1.797 | Acc: 47.386% (3063/6464)
Loss: 1.800 | Acc: 47.365% (6093/12864)
Loss: 1.809 | Acc: 46.948% (9044/19264)
Loss: 1.814 | Acc: 46.622% (11965/25664)
Loss: 1.816 | Acc: 46.601% (14942/32064)
Loss: 1.817 | Acc: 46.586% (17919/38464)
Loss: 1.819 | Acc: 46.561% (20889/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9457, Accuracy: 4105/10000 (41.05%)

Epoch: 164
Loss: 2.009 | Acc: 37.500% (24/64)
Loss: 1.811 | Acc: 47.184% (3050/6464)
Loss: 1.804 | Acc: 47.373% (6094/12864)
Loss: 1.808 | Acc: 47.207% (9094/19264)
Loss: 1.814 | Acc: 46.820% (12016/25664)
Loss: 1.814 | Acc: 46.794% (15004/32064)
Loss: 1.816 | Acc: 46.688% (17958/38464)
Loss: 1.818 | Acc: 46.610% (20911/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9969, Accuracy: 3863/10000 (38.63%)

Epoch: 165
Loss: 1.976 | Acc: 39.062% (25/64)
Loss: 1.828 | Acc: 46.473% (3004/6464)
Loss: 1.823 | Acc: 46.339% (5961/12864)
Loss: 1.818 | Acc: 46.595% (8976/19264)
Loss: 1.815 | Acc: 46.754% (11999/25664)
Loss: 1.812 | Acc: 46.900% (15038/32064)
Loss: 1.811 | Acc: 46.984% (18072/38464)
Loss: 1.811 | Acc: 46.951% (21064/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9748, Accuracy: 3851/10000 (38.51%)

Epoch: 166
Loss: 1.885 | Acc: 40.625% (26/64)
Loss: 1.794 | Acc: 47.416% (3065/6464)
Loss: 1.795 | Acc: 47.544% (6116/12864)
Loss: 1.795 | Acc: 47.493% (9149/19264)
Loss: 1.804 | Acc: 47.082% (12083/25664)
Loss: 1.807 | Acc: 46.956% (15056/32064)
Loss: 1.808 | Acc: 46.911% (18044/38464)
Loss: 1.809 | Acc: 46.926% (21053/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9213, Accuracy: 4248/10000 (42.48%)

Epoch: 167
Loss: 2.033 | Acc: 42.188% (27/64)
Loss: 1.804 | Acc: 47.107% (3045/6464)
Loss: 1.804 | Acc: 47.062% (6054/12864)
Loss: 1.806 | Acc: 47.098% (9073/19264)
Loss: 1.800 | Acc: 47.370% (12157/25664)
Loss: 1.802 | Acc: 47.202% (15135/32064)
Loss: 1.804 | Acc: 47.200% (18155/38464)
Loss: 1.805 | Acc: 47.165% (21160/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9358, Accuracy: 4193/10000 (41.93%)

Epoch: 168
Loss: 1.750 | Acc: 50.000% (32/64)
Loss: 1.798 | Acc: 47.324% (3059/6464)
Loss: 1.804 | Acc: 47.170% (6068/12864)
Loss: 1.802 | Acc: 47.353% (9122/19264)
Loss: 1.795 | Acc: 47.522% (12196/25664)
Loss: 1.798 | Acc: 47.346% (15181/32064)
Loss: 1.797 | Acc: 47.411% (18236/38464)
Loss: 1.800 | Acc: 47.278% (21211/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0342, Accuracy: 3449/10000 (34.49%)

Epoch: 169
Loss: 1.935 | Acc: 40.625% (26/64)
Loss: 1.804 | Acc: 47.246% (3054/6464)
Loss: 1.803 | Acc: 47.248% (6078/12864)
Loss: 1.801 | Acc: 47.384% (9128/19264)
Loss: 1.802 | Acc: 47.370% (12157/25664)
Loss: 1.801 | Acc: 47.362% (15186/32064)
Loss: 1.799 | Acc: 47.457% (18254/38464)
Loss: 1.800 | Acc: 47.408% (21269/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0528, Accuracy: 3561/10000 (35.61%)

Epoch: 170
Loss: 1.897 | Acc: 45.312% (29/64)
Loss: 1.786 | Acc: 47.942% (3099/6464)
Loss: 1.794 | Acc: 47.536% (6115/12864)
Loss: 1.793 | Acc: 47.664% (9182/19264)
Loss: 1.793 | Acc: 47.670% (12234/25664)
Loss: 1.793 | Acc: 47.680% (15288/32064)
Loss: 1.792 | Acc: 47.723% (18356/38464)
Loss: 1.795 | Acc: 47.655% (21380/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9324, Accuracy: 4131/10000 (41.31%)

Epoch: 171
Loss: 1.828 | Acc: 48.438% (31/64)
Loss: 1.766 | Acc: 49.056% (3171/6464)
Loss: 1.774 | Acc: 48.772% (6274/12864)
Loss: 1.776 | Acc: 48.609% (9364/19264)
Loss: 1.781 | Acc: 48.344% (12407/25664)
Loss: 1.780 | Acc: 48.344% (15501/32064)
Loss: 1.782 | Acc: 48.276% (18569/38464)
Loss: 1.787 | Acc: 48.114% (21586/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9743, Accuracy: 3860/10000 (38.60%)

Epoch: 172
Loss: 1.862 | Acc: 43.750% (28/64)
Loss: 1.785 | Acc: 47.834% (3092/6464)
Loss: 1.776 | Acc: 48.228% (6204/12864)
Loss: 1.773 | Acc: 48.354% (9315/19264)
Loss: 1.774 | Acc: 48.441% (12432/25664)
Loss: 1.778 | Acc: 48.356% (15505/32064)
Loss: 1.780 | Acc: 48.237% (18554/38464)
Loss: 1.781 | Acc: 48.188% (21619/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9872, Accuracy: 3906/10000 (39.06%)

Epoch: 173
Loss: 1.840 | Acc: 45.312% (29/64)
Loss: 1.803 | Acc: 47.045% (3041/6464)
Loss: 1.788 | Acc: 47.730% (6140/12864)
Loss: 1.784 | Acc: 48.074% (9261/19264)
Loss: 1.781 | Acc: 48.173% (12363/25664)
Loss: 1.777 | Acc: 48.366% (15508/32064)
Loss: 1.780 | Acc: 48.245% (18557/38464)
Loss: 1.777 | Acc: 48.388% (21709/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9527, Accuracy: 4034/10000 (40.34%)

Epoch: 174
Loss: 1.823 | Acc: 46.875% (30/64)
Loss: 1.758 | Acc: 48.762% (3152/6464)
Loss: 1.768 | Acc: 48.391% (6225/12864)
Loss: 1.757 | Acc: 49.066% (9452/19264)
Loss: 1.761 | Acc: 48.905% (12551/25664)
Loss: 1.766 | Acc: 48.756% (15633/32064)
Loss: 1.768 | Acc: 48.656% (18715/38464)
Loss: 1.770 | Acc: 48.562% (21787/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8924, Accuracy: 4444/10000 (44.44%)

Epoch: 175
Loss: 1.661 | Acc: 51.562% (33/64)
Loss: 1.757 | Acc: 49.165% (3178/6464)
Loss: 1.755 | Acc: 49.324% (6345/12864)
Loss: 1.754 | Acc: 49.445% (9525/19264)
Loss: 1.755 | Acc: 49.419% (12683/25664)
Loss: 1.752 | Acc: 49.526% (15880/32064)
Loss: 1.755 | Acc: 49.337% (18977/38464)
Loss: 1.759 | Acc: 49.184% (22066/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8983, Accuracy: 4325/10000 (43.25%)

Epoch: 176
Loss: 1.884 | Acc: 42.188% (27/64)
Loss: 1.759 | Acc: 48.685% (3147/6464)
Loss: 1.762 | Acc: 48.865% (6286/12864)
Loss: 1.761 | Acc: 48.884% (9417/19264)
Loss: 1.765 | Acc: 48.854% (12538/25664)
Loss: 1.764 | Acc: 48.937% (15691/32064)
Loss: 1.757 | Acc: 49.282% (18956/38464)
Loss: 1.754 | Acc: 49.385% (22156/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9180, Accuracy: 4240/10000 (42.40%)

Epoch: 177
Loss: 1.748 | Acc: 48.438% (31/64)
Loss: 1.761 | Acc: 49.304% (3187/6464)
Loss: 1.740 | Acc: 50.140% (6450/12864)
Loss: 1.742 | Acc: 49.969% (9626/19264)
Loss: 1.746 | Acc: 49.793% (12779/25664)
Loss: 1.748 | Acc: 49.676% (15928/32064)
Loss: 1.747 | Acc: 49.600% (19078/38464)
Loss: 1.746 | Acc: 49.663% (22281/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9361, Accuracy: 4115/10000 (41.15%)

Epoch: 178
Loss: 1.734 | Acc: 46.875% (30/64)
Loss: 1.706 | Acc: 50.804% (3284/6464)
Loss: 1.737 | Acc: 49.619% (6383/12864)
Loss: 1.733 | Acc: 49.849% (9603/19264)
Loss: 1.737 | Acc: 49.879% (12801/25664)
Loss: 1.736 | Acc: 50.037% (16044/32064)
Loss: 1.734 | Acc: 50.120% (19278/38464)
Loss: 1.738 | Acc: 50.004% (22434/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9383, Accuracy: 4210/10000 (42.10%)

Epoch: 179
Loss: 1.730 | Acc: 50.000% (32/64)
Loss: 1.727 | Acc: 50.108% (3239/6464)
Loss: 1.716 | Acc: 50.676% (6519/12864)
Loss: 1.718 | Acc: 50.576% (9743/19264)
Loss: 1.720 | Acc: 50.503% (12961/25664)
Loss: 1.720 | Acc: 50.642% (16238/32064)
Loss: 1.721 | Acc: 50.564% (19449/38464)
Loss: 1.725 | Acc: 50.374% (22600/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9336, Accuracy: 4149/10000 (41.49%)

Epoch: 180
Loss: 1.798 | Acc: 50.000% (32/64)
Loss: 1.704 | Acc: 50.835% (3286/6464)
Loss: 1.709 | Acc: 50.731% (6526/12864)
Loss: 1.708 | Acc: 50.841% (9794/19264)
Loss: 1.707 | Acc: 50.935% (13072/25664)
Loss: 1.716 | Acc: 50.667% (16246/32064)
Loss: 1.717 | Acc: 50.658% (19485/38464)
Loss: 1.718 | Acc: 50.662% (22729/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8788, Accuracy: 4523/10000 (45.23%)

Epoch: 181
Loss: 1.620 | Acc: 53.125% (34/64)
Loss: 1.685 | Acc: 51.934% (3357/6464)
Loss: 1.689 | Acc: 51.601% (6638/12864)
Loss: 1.685 | Acc: 51.765% (9972/19264)
Loss: 1.690 | Acc: 51.559% (13232/25664)
Loss: 1.695 | Acc: 51.375% (16473/32064)
Loss: 1.702 | Acc: 51.144% (19672/38464)
Loss: 1.704 | Acc: 51.019% (22889/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8966, Accuracy: 4344/10000 (43.44%)

Epoch: 182
Loss: 1.964 | Acc: 39.062% (25/64)
Loss: 1.691 | Acc: 51.067% (3301/6464)
Loss: 1.678 | Acc: 51.842% (6669/12864)
Loss: 1.676 | Acc: 51.967% (10011/19264)
Loss: 1.681 | Acc: 51.831% (13302/25664)
Loss: 1.686 | Acc: 51.675% (16569/32064)
Loss: 1.686 | Acc: 51.789% (19920/38464)
Loss: 1.689 | Acc: 51.625% (23161/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8763, Accuracy: 4518/10000 (45.18%)

Epoch: 183
Loss: 1.647 | Acc: 59.375% (38/64)
Loss: 1.669 | Acc: 52.522% (3395/6464)
Loss: 1.673 | Acc: 52.021% (6692/12864)
Loss: 1.675 | Acc: 51.900% (9998/19264)
Loss: 1.681 | Acc: 51.707% (13270/25664)
Loss: 1.684 | Acc: 51.538% (16525/32064)
Loss: 1.682 | Acc: 51.614% (19853/38464)
Loss: 1.682 | Acc: 51.647% (23171/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9083, Accuracy: 4546/10000 (45.46%)

Epoch: 184
Loss: 1.545 | Acc: 56.250% (36/64)
Loss: 1.644 | Acc: 53.125% (3434/6464)
Loss: 1.649 | Acc: 52.651% (6773/12864)
Loss: 1.650 | Acc: 52.658% (10144/19264)
Loss: 1.649 | Acc: 52.630% (13507/25664)
Loss: 1.652 | Acc: 52.561% (16853/32064)
Loss: 1.656 | Acc: 52.475% (20184/38464)
Loss: 1.662 | Acc: 52.327% (23476/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9116, Accuracy: 4461/10000 (44.61%)

Epoch: 185
Loss: 1.672 | Acc: 51.562% (33/64)
Loss: 1.614 | Acc: 53.450% (3455/6464)
Loss: 1.625 | Acc: 53.304% (6857/12864)
Loss: 1.629 | Acc: 53.224% (10253/19264)
Loss: 1.634 | Acc: 53.195% (13652/25664)
Loss: 1.636 | Acc: 53.119% (17032/32064)
Loss: 1.632 | Acc: 53.330% (20513/38464)
Loss: 1.637 | Acc: 53.161% (23850/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9095, Accuracy: 4421/10000 (44.21%)

Epoch: 186
Loss: 1.571 | Acc: 56.250% (36/64)
Loss: 1.606 | Acc: 53.945% (3487/6464)
Loss: 1.608 | Acc: 53.856% (6928/12864)
Loss: 1.615 | Acc: 53.545% (10315/19264)
Loss: 1.616 | Acc: 53.565% (13747/25664)
Loss: 1.615 | Acc: 53.599% (17186/32064)
Loss: 1.619 | Acc: 53.453% (20560/38464)
Loss: 1.619 | Acc: 53.491% (23998/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9082, Accuracy: 4428/10000 (44.28%)

Epoch: 187
Loss: 1.448 | Acc: 60.938% (39/64)
Loss: 1.598 | Acc: 54.100% (3497/6464)
Loss: 1.587 | Acc: 54.260% (6980/12864)
Loss: 1.587 | Acc: 54.231% (10447/19264)
Loss: 1.595 | Acc: 53.994% (13857/25664)
Loss: 1.595 | Acc: 54.014% (17319/32064)
Loss: 1.596 | Acc: 54.129% (20820/38464)
Loss: 1.596 | Acc: 54.170% (24303/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9471, Accuracy: 4326/10000 (43.26%)

Epoch: 188
Loss: 1.478 | Acc: 62.500% (40/64)
Loss: 1.556 | Acc: 55.183% (3567/6464)
Loss: 1.565 | Acc: 54.851% (7056/12864)
Loss: 1.563 | Acc: 54.947% (10585/19264)
Loss: 1.565 | Acc: 54.867% (14081/25664)
Loss: 1.567 | Acc: 54.825% (17579/32064)
Loss: 1.564 | Acc: 54.960% (21140/38464)
Loss: 1.568 | Acc: 54.890% (24626/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9340, Accuracy: 4462/10000 (44.62%)

Epoch: 189
Loss: 1.565 | Acc: 51.562% (33/64)
Loss: 1.511 | Acc: 56.204% (3633/6464)
Loss: 1.517 | Acc: 56.180% (7227/12864)
Loss: 1.516 | Acc: 56.250% (10836/19264)
Loss: 1.521 | Acc: 56.121% (14403/25664)
Loss: 1.527 | Acc: 55.960% (17943/32064)
Loss: 1.529 | Acc: 55.928% (21512/38464)
Loss: 1.533 | Acc: 55.691% (24985/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9746, Accuracy: 4484/10000 (44.84%)

Epoch: 190
Loss: 1.562 | Acc: 56.250% (36/64)
Loss: 1.472 | Acc: 57.735% (3732/6464)
Loss: 1.485 | Acc: 57.160% (7353/12864)
Loss: 1.486 | Acc: 57.044% (10989/19264)
Loss: 1.485 | Acc: 57.146% (14666/25664)
Loss: 1.486 | Acc: 57.179% (18334/32064)
Loss: 1.490 | Acc: 56.942% (21902/38464)
Loss: 1.491 | Acc: 56.979% (25563/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9563, Accuracy: 4438/10000 (44.38%)

Epoch: 191
Loss: 1.683 | Acc: 50.000% (32/64)
Loss: 1.428 | Acc: 58.246% (3765/6464)
Loss: 1.429 | Acc: 58.380% (7510/12864)
Loss: 1.438 | Acc: 58.072% (11187/19264)
Loss: 1.443 | Acc: 58.000% (14885/25664)
Loss: 1.440 | Acc: 58.209% (18664/32064)
Loss: 1.443 | Acc: 58.114% (22353/38464)
Loss: 1.444 | Acc: 58.084% (26059/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0481, Accuracy: 4303/10000 (43.03%)

Epoch: 192
Loss: 1.456 | Acc: 56.250% (36/64)
Loss: 1.406 | Acc: 58.462% (3779/6464)
Loss: 1.394 | Acc: 59.196% (7615/12864)
Loss: 1.388 | Acc: 59.520% (11466/19264)
Loss: 1.395 | Acc: 59.367% (15236/25664)
Loss: 1.402 | Acc: 59.069% (18940/32064)
Loss: 1.402 | Acc: 59.159% (22755/38464)
Loss: 1.399 | Acc: 59.268% (26590/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0936, Accuracy: 4321/10000 (43.21%)

Epoch: 193
Loss: 1.128 | Acc: 67.188% (43/64)
Loss: 1.316 | Acc: 61.510% (3976/6464)
Loss: 1.325 | Acc: 61.458% (7906/12864)
Loss: 1.321 | Acc: 61.441% (11836/19264)
Loss: 1.329 | Acc: 61.202% (15707/25664)
Loss: 1.329 | Acc: 61.199% (19623/32064)
Loss: 1.330 | Acc: 61.122% (23510/38464)
Loss: 1.330 | Acc: 61.116% (27419/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1064, Accuracy: 4274/10000 (42.74%)

Epoch: 194
Loss: 1.072 | Acc: 76.562% (49/64)
Loss: 1.255 | Acc: 63.196% (4085/6464)
Loss: 1.247 | Acc: 63.293% (8142/12864)
Loss: 1.245 | Acc: 63.294% (12193/19264)
Loss: 1.254 | Acc: 63.030% (16176/25664)
Loss: 1.258 | Acc: 62.896% (20167/32064)
Loss: 1.261 | Acc: 62.796% (24154/38464)
Loss: 1.260 | Acc: 62.919% (28228/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1663, Accuracy: 4299/10000 (42.99%)

Epoch: 195
Loss: 1.154 | Acc: 68.750% (44/64)
Loss: 1.188 | Acc: 64.573% (4174/6464)
Loss: 1.194 | Acc: 64.451% (8291/12864)
Loss: 1.193 | Acc: 64.390% (12404/19264)
Loss: 1.192 | Acc: 64.425% (16534/25664)
Loss: 1.197 | Acc: 64.353% (20634/32064)
Loss: 1.197 | Acc: 64.338% (24747/38464)
Loss: 1.196 | Acc: 64.415% (28899/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1995, Accuracy: 4149/10000 (41.49%)

Epoch: 196
Loss: 1.085 | Acc: 65.625% (42/64)
Loss: 1.118 | Acc: 66.584% (4304/6464)
Loss: 1.117 | Acc: 66.737% (8585/12864)
Loss: 1.131 | Acc: 65.962% (12707/19264)
Loss: 1.125 | Acc: 66.272% (17008/25664)
Loss: 1.122 | Acc: 66.411% (21294/32064)
Loss: 1.122 | Acc: 66.379% (25532/38464)
Loss: 1.122 | Acc: 66.423% (29800/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2862, Accuracy: 4070/10000 (40.70%)

Epoch: 197
Loss: 1.137 | Acc: 64.062% (41/64)
Loss: 1.067 | Acc: 67.961% (4393/6464)
Loss: 1.065 | Acc: 68.105% (8761/12864)
Loss: 1.057 | Acc: 68.309% (13159/19264)
Loss: 1.060 | Acc: 68.158% (17492/25664)
Loss: 1.061 | Acc: 68.001% (21804/32064)
Loss: 1.062 | Acc: 68.051% (26175/38464)
Loss: 1.062 | Acc: 68.052% (30531/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3401, Accuracy: 4017/10000 (40.17%)
torch.Size([100, 10])
Test set: Average loss: 2.3401, Accuracy: 4017/10000 (40.17%)

Epoch: 198
Loss: 0.805 | Acc: 79.688% (51/64)
Loss: 1.006 | Acc: 70.080% (4530/6464)
Loss: 1.007 | Acc: 70.095% (9017/12864)
Loss: 1.008 | Acc: 70.043% (13493/19264)
Loss: 1.011 | Acc: 69.907% (17941/25664)
Loss: 1.016 | Acc: 69.601% (22317/32064)
Loss: 1.019 | Acc: 69.509% (26736/38464)
Loss: 1.019 | Acc: 69.570% (31212/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3186, Accuracy: 4024/10000 (40.24%)
torch.Size([100, 10])
Test set: Average loss: 2.3186, Accuracy: 4024/10000 (40.24%)

Epoch: 199
Loss: 1.113 | Acc: 68.750% (44/64)
Loss: 1.005 | Acc: 70.065% (4529/6464)
Loss: 1.005 | Acc: 70.017% (9007/12864)
Loss: 0.999 | Acc: 70.110% (13506/19264)
Loss: 0.997 | Acc: 70.164% (18007/25664)
Loss: 0.996 | Acc: 70.200% (22509/32064)
Loss: 0.995 | Acc: 70.268% (27028/38464)
Loss: 0.997 | Acc: 70.270% (31526/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3407, Accuracy: 4023/10000 (40.23%)
torch.Size([100, 10])
Test set: Average loss: 2.3407, Accuracy: 4023/10000 (40.23%)
4546
10000
-1.9985917806625366
