==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.403 | Acc: 12.500% (8/64)
Loss: 2.838 | Acc: 14.960% (967/6464)
Loss: 2.489 | Acc: 17.685% (2275/12864)
Loss: 2.353 | Acc: 19.991% (3851/19264)
Loss: 2.272 | Acc: 21.719% (5574/25664)
Loss: 2.217 | Acc: 23.157% (7425/32064)
Loss: 2.179 | Acc: 24.186% (9303/38464)
Loss: 2.144 | Acc: 25.227% (11318/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1170, Accuracy: 2769/10000 (27.69%)

Epoch: 1
Loss: 2.180 | Acc: 20.312% (13/64)
Loss: 1.879 | Acc: 34.097% (2204/6464)
Loss: 1.882 | Acc: 34.126% (4390/12864)
Loss: 1.875 | Acc: 34.468% (6640/19264)
Loss: 1.866 | Acc: 35.022% (8988/25664)
Loss: 1.861 | Acc: 35.308% (11321/32064)
Loss: 1.851 | Acc: 35.776% (13761/38464)
Loss: 1.844 | Acc: 36.243% (16260/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8536, Accuracy: 3706/10000 (37.06%)

Epoch: 2
Loss: 1.572 | Acc: 43.750% (28/64)
Loss: 1.759 | Acc: 40.842% (2640/6464)
Loss: 1.751 | Acc: 41.387% (5324/12864)
Loss: 1.738 | Acc: 42.167% (8123/19264)
Loss: 1.730 | Acc: 42.456% (10896/25664)
Loss: 1.719 | Acc: 43.045% (13802/32064)
Loss: 1.715 | Acc: 43.344% (16672/38464)
Loss: 1.711 | Acc: 43.607% (19564/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7782, Accuracy: 4284/10000 (42.84%)

Epoch: 3
Loss: 1.913 | Acc: 34.375% (22/64)
Loss: 1.640 | Acc: 47.200% (3051/6464)
Loss: 1.652 | Acc: 47.116% (6061/12864)
Loss: 1.635 | Acc: 47.783% (9205/19264)
Loss: 1.629 | Acc: 48.219% (12375/25664)
Loss: 1.624 | Acc: 48.515% (15556/32064)
Loss: 1.615 | Acc: 48.820% (18778/38464)
Loss: 1.607 | Acc: 49.220% (22082/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1149, Accuracy: 3187/10000 (31.87%)

Epoch: 4
Loss: 1.872 | Acc: 39.062% (25/64)
Loss: 1.554 | Acc: 52.197% (3374/6464)
Loss: 1.549 | Acc: 52.037% (6694/12864)
Loss: 1.541 | Acc: 52.601% (10133/19264)
Loss: 1.533 | Acc: 52.930% (13584/25664)
Loss: 1.530 | Acc: 52.950% (16978/32064)
Loss: 1.525 | Acc: 53.115% (20430/38464)
Loss: 1.519 | Acc: 53.381% (23949/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6354, Accuracy: 4943/10000 (49.43%)

Epoch: 5
Loss: 1.792 | Acc: 50.000% (32/64)
Loss: 1.467 | Acc: 55.724% (3602/6464)
Loss: 1.476 | Acc: 55.333% (7118/12864)
Loss: 1.466 | Acc: 55.939% (10776/19264)
Loss: 1.464 | Acc: 55.950% (14359/25664)
Loss: 1.455 | Acc: 56.337% (18064/32064)
Loss: 1.455 | Acc: 56.351% (21675/38464)
Loss: 1.451 | Acc: 56.546% (25369/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7583, Accuracy: 4543/10000 (45.43%)

Epoch: 6
Loss: 1.397 | Acc: 57.812% (37/64)
Loss: 1.410 | Acc: 58.849% (3804/6464)
Loss: 1.410 | Acc: 58.854% (7571/12864)
Loss: 1.409 | Acc: 58.726% (11313/19264)
Loss: 1.398 | Acc: 59.184% (15189/25664)
Loss: 1.391 | Acc: 59.422% (19053/32064)
Loss: 1.389 | Acc: 59.487% (22881/38464)
Loss: 1.389 | Acc: 59.493% (26691/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9450, Accuracy: 3781/10000 (37.81%)

Epoch: 7
Loss: 1.511 | Acc: 54.688% (35/64)
Loss: 1.368 | Acc: 60.752% (3927/6464)
Loss: 1.356 | Acc: 60.953% (7841/12864)
Loss: 1.358 | Acc: 60.880% (11728/19264)
Loss: 1.352 | Acc: 61.249% (15719/25664)
Loss: 1.348 | Acc: 61.452% (19704/32064)
Loss: 1.347 | Acc: 61.543% (23672/38464)
Loss: 1.341 | Acc: 61.689% (27676/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4794, Accuracy: 5697/10000 (56.97%)

Epoch: 8
Loss: 1.296 | Acc: 64.062% (41/64)
Loss: 1.326 | Acc: 62.005% (4008/6464)
Loss: 1.318 | Acc: 62.352% (8021/12864)
Loss: 1.314 | Acc: 62.656% (12070/19264)
Loss: 1.315 | Acc: 62.683% (16087/25664)
Loss: 1.309 | Acc: 62.865% (20157/32064)
Loss: 1.308 | Acc: 62.919% (24201/38464)
Loss: 1.306 | Acc: 63.006% (28267/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5634, Accuracy: 5498/10000 (54.98%)

Epoch: 9
Loss: 1.513 | Acc: 51.562% (33/64)
Loss: 1.266 | Acc: 64.542% (4172/6464)
Loss: 1.279 | Acc: 64.366% (8280/12864)
Loss: 1.290 | Acc: 63.902% (12310/19264)
Loss: 1.288 | Acc: 63.844% (16385/25664)
Loss: 1.288 | Acc: 63.925% (20497/32064)
Loss: 1.286 | Acc: 64.003% (24618/38464)
Loss: 1.280 | Acc: 64.158% (28784/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5112, Accuracy: 5500/10000 (55.00%)

Epoch: 10
Loss: 1.126 | Acc: 65.625% (42/64)
Loss: 1.252 | Acc: 65.470% (4232/6464)
Loss: 1.254 | Acc: 65.633% (8443/12864)
Loss: 1.256 | Acc: 65.324% (12584/19264)
Loss: 1.251 | Acc: 65.477% (16804/25664)
Loss: 1.254 | Acc: 65.510% (21005/32064)
Loss: 1.258 | Acc: 65.349% (25136/38464)
Loss: 1.257 | Acc: 65.364% (29325/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5264, Accuracy: 5689/10000 (56.89%)

Epoch: 11
Loss: 1.426 | Acc: 51.562% (33/64)
Loss: 1.242 | Acc: 65.873% (4258/6464)
Loss: 1.247 | Acc: 65.633% (8443/12864)
Loss: 1.239 | Acc: 65.921% (12699/19264)
Loss: 1.248 | Acc: 65.695% (16860/25664)
Loss: 1.246 | Acc: 65.678% (21059/32064)
Loss: 1.241 | Acc: 65.872% (25337/38464)
Loss: 1.241 | Acc: 65.850% (29543/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4182, Accuracy: 5974/10000 (59.74%)

Epoch: 12
Loss: 1.247 | Acc: 62.500% (40/64)
Loss: 1.225 | Acc: 66.197% (4279/6464)
Loss: 1.229 | Acc: 66.340% (8534/12864)
Loss: 1.226 | Acc: 66.559% (12822/19264)
Loss: 1.227 | Acc: 66.654% (17106/25664)
Loss: 1.229 | Acc: 66.617% (21360/32064)
Loss: 1.227 | Acc: 66.678% (25647/38464)
Loss: 1.228 | Acc: 66.606% (29882/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4855, Accuracy: 5703/10000 (57.03%)

Epoch: 13
Loss: 1.334 | Acc: 68.750% (44/64)
Loss: 1.206 | Acc: 68.007% (4396/6464)
Loss: 1.209 | Acc: 67.848% (8728/12864)
Loss: 1.205 | Acc: 67.836% (13068/19264)
Loss: 1.211 | Acc: 67.616% (17353/25664)
Loss: 1.210 | Acc: 67.615% (21680/32064)
Loss: 1.212 | Acc: 67.525% (25973/38464)
Loss: 1.213 | Acc: 67.446% (30259/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8392, Accuracy: 4787/10000 (47.87%)

Epoch: 14
Loss: 1.323 | Acc: 62.500% (40/64)
Loss: 1.227 | Acc: 66.429% (4294/6464)
Loss: 1.207 | Acc: 67.250% (8651/12864)
Loss: 1.204 | Acc: 67.317% (12968/19264)
Loss: 1.202 | Acc: 67.585% (17345/25664)
Loss: 1.201 | Acc: 67.624% (21683/32064)
Loss: 1.200 | Acc: 67.676% (26031/38464)
Loss: 1.201 | Acc: 67.611% (30333/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6737, Accuracy: 5024/10000 (50.24%)

Epoch: 15
Loss: 1.460 | Acc: 59.375% (38/64)
Loss: 1.200 | Acc: 67.466% (4361/6464)
Loss: 1.193 | Acc: 68.105% (8761/12864)
Loss: 1.196 | Acc: 67.888% (13078/19264)
Loss: 1.193 | Acc: 67.998% (17451/25664)
Loss: 1.188 | Acc: 68.161% (21855/32064)
Loss: 1.191 | Acc: 68.110% (26198/38464)
Loss: 1.189 | Acc: 68.130% (30566/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3879, Accuracy: 6136/10000 (61.36%)

Epoch: 16
Loss: 1.366 | Acc: 60.938% (39/64)
Loss: 1.160 | Acc: 69.647% (4502/6464)
Loss: 1.160 | Acc: 69.387% (8926/12864)
Loss: 1.167 | Acc: 69.311% (13352/19264)
Loss: 1.176 | Acc: 68.953% (17696/25664)
Loss: 1.173 | Acc: 69.077% (22149/32064)
Loss: 1.177 | Acc: 68.992% (26537/38464)
Loss: 1.170 | Acc: 69.095% (30999/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4435, Accuracy: 5974/10000 (59.74%)

Epoch: 17
Loss: 1.154 | Acc: 65.625% (42/64)
Loss: 1.154 | Acc: 69.740% (4508/6464)
Loss: 1.170 | Acc: 69.139% (8894/12864)
Loss: 1.168 | Acc: 69.103% (13312/19264)
Loss: 1.162 | Acc: 69.249% (17772/25664)
Loss: 1.163 | Acc: 69.246% (22203/32064)
Loss: 1.164 | Acc: 69.257% (26639/38464)
Loss: 1.163 | Acc: 69.258% (31072/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3916, Accuracy: 6108/10000 (61.08%)

Epoch: 18
Loss: 1.139 | Acc: 68.750% (44/64)
Loss: 1.110 | Acc: 70.730% (4572/6464)
Loss: 1.120 | Acc: 70.546% (9075/12864)
Loss: 1.139 | Acc: 69.991% (13483/19264)
Loss: 1.143 | Acc: 69.958% (17954/25664)
Loss: 1.144 | Acc: 69.910% (22416/32064)
Loss: 1.150 | Acc: 69.707% (26812/38464)
Loss: 1.149 | Acc: 69.653% (31249/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3012, Accuracy: 6445/10000 (64.45%)

Epoch: 19
Loss: 1.683 | Acc: 56.250% (36/64)
Loss: 1.131 | Acc: 70.343% (4547/6464)
Loss: 1.139 | Acc: 70.040% (9010/12864)
Loss: 1.129 | Acc: 70.401% (13562/19264)
Loss: 1.125 | Acc: 70.655% (18133/25664)
Loss: 1.131 | Acc: 70.534% (22616/32064)
Loss: 1.134 | Acc: 70.510% (27121/38464)
Loss: 1.136 | Acc: 70.435% (31600/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3387, Accuracy: 6277/10000 (62.77%)

Epoch: 20
Loss: 0.922 | Acc: 78.125% (50/64)
Loss: 1.102 | Acc: 71.999% (4654/6464)
Loss: 1.114 | Acc: 71.432% (9189/12864)
Loss: 1.117 | Acc: 71.127% (13702/19264)
Loss: 1.116 | Acc: 71.049% (18234/25664)
Loss: 1.123 | Acc: 70.812% (22705/32064)
Loss: 1.124 | Acc: 70.884% (27265/38464)
Loss: 1.124 | Acc: 70.879% (31799/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5630, Accuracy: 5623/10000 (56.23%)

Epoch: 21
Loss: 1.003 | Acc: 73.438% (47/64)
Loss: 1.103 | Acc: 71.241% (4605/6464)
Loss: 1.107 | Acc: 71.245% (9165/12864)
Loss: 1.104 | Acc: 71.283% (13732/19264)
Loss: 1.111 | Acc: 71.014% (18225/25664)
Loss: 1.112 | Acc: 71.058% (22784/32064)
Loss: 1.115 | Acc: 71.017% (27316/38464)
Loss: 1.115 | Acc: 71.059% (31880/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6548, Accuracy: 5309/10000 (53.09%)

Epoch: 22
Loss: 0.966 | Acc: 79.688% (51/64)
Loss: 1.099 | Acc: 71.906% (4648/6464)
Loss: 1.110 | Acc: 71.385% (9183/12864)
Loss: 1.107 | Acc: 71.595% (13792/19264)
Loss: 1.110 | Acc: 71.497% (18349/25664)
Loss: 1.101 | Acc: 71.650% (22974/32064)
Loss: 1.102 | Acc: 71.675% (27569/38464)
Loss: 1.100 | Acc: 71.681% (32159/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7229, Accuracy: 4994/10000 (49.94%)

Epoch: 23
Loss: 1.073 | Acc: 71.875% (46/64)
Loss: 1.076 | Acc: 72.726% (4701/6464)
Loss: 1.088 | Acc: 72.100% (9275/12864)
Loss: 1.093 | Acc: 72.072% (13884/19264)
Loss: 1.097 | Acc: 71.824% (18433/25664)
Loss: 1.097 | Acc: 71.785% (23017/32064)
Loss: 1.093 | Acc: 71.883% (27649/38464)
Loss: 1.092 | Acc: 71.897% (32256/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3665, Accuracy: 6119/10000 (61.19%)

Epoch: 24
Loss: 1.165 | Acc: 71.875% (46/64)
Loss: 1.085 | Acc: 71.921% (4649/6464)
Loss: 1.094 | Acc: 71.751% (9230/12864)
Loss: 1.084 | Acc: 72.067% (13883/19264)
Loss: 1.090 | Acc: 72.015% (18482/25664)
Loss: 1.085 | Acc: 72.143% (23132/32064)
Loss: 1.082 | Acc: 72.281% (27802/38464)
Loss: 1.082 | Acc: 72.254% (32416/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3385, Accuracy: 6348/10000 (63.48%)

Epoch: 25
Loss: 1.178 | Acc: 68.750% (44/64)
Loss: 1.056 | Acc: 73.267% (4736/6464)
Loss: 1.065 | Acc: 73.235% (9421/12864)
Loss: 1.067 | Acc: 73.121% (14086/19264)
Loss: 1.065 | Acc: 73.145% (18772/25664)
Loss: 1.068 | Acc: 73.010% (23410/32064)
Loss: 1.072 | Acc: 72.936% (28054/38464)
Loss: 1.072 | Acc: 72.876% (32695/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2404, Accuracy: 6697/10000 (66.97%)

Epoch: 26
Loss: 0.968 | Acc: 75.000% (48/64)
Loss: 1.070 | Acc: 72.649% (4696/6464)
Loss: 1.069 | Acc: 72.893% (9377/12864)
Loss: 1.059 | Acc: 73.344% (14129/19264)
Loss: 1.067 | Acc: 72.982% (18730/25664)
Loss: 1.071 | Acc: 72.951% (23391/32064)
Loss: 1.063 | Acc: 73.097% (28116/38464)
Loss: 1.059 | Acc: 73.157% (32821/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3684, Accuracy: 6241/10000 (62.41%)

Epoch: 27
Loss: 1.330 | Acc: 57.812% (37/64)
Loss: 1.078 | Acc: 72.571% (4691/6464)
Loss: 1.047 | Acc: 73.733% (9485/12864)
Loss: 1.046 | Acc: 73.718% (14201/19264)
Loss: 1.044 | Acc: 73.683% (18910/25664)
Loss: 1.042 | Acc: 73.759% (23650/32064)
Loss: 1.039 | Acc: 73.898% (28424/38464)
Loss: 1.042 | Acc: 73.761% (33092/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2445, Accuracy: 6704/10000 (67.04%)

Epoch: 28
Loss: 1.188 | Acc: 67.188% (43/64)
Loss: 1.035 | Acc: 73.902% (4777/6464)
Loss: 1.043 | Acc: 73.865% (9502/12864)
Loss: 1.030 | Acc: 74.169% (14288/19264)
Loss: 1.034 | Acc: 74.092% (19015/25664)
Loss: 1.029 | Acc: 74.333% (23834/32064)
Loss: 1.034 | Acc: 74.116% (28508/38464)
Loss: 1.036 | Acc: 74.079% (33235/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4016, Accuracy: 6071/10000 (60.71%)

Epoch: 29
Loss: 0.880 | Acc: 81.250% (52/64)
Loss: 1.005 | Acc: 74.768% (4833/6464)
Loss: 1.018 | Acc: 74.433% (9575/12864)
Loss: 1.007 | Acc: 74.907% (14430/19264)
Loss: 1.013 | Acc: 74.716% (19175/25664)
Loss: 1.016 | Acc: 74.526% (23896/32064)
Loss: 1.019 | Acc: 74.524% (28665/38464)
Loss: 1.015 | Acc: 74.630% (33482/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2006, Accuracy: 6828/10000 (68.28%)

Epoch: 30
Loss: 1.473 | Acc: 60.938% (39/64)
Loss: 0.984 | Acc: 75.681% (4892/6464)
Loss: 0.999 | Acc: 75.155% (9668/12864)
Loss: 0.998 | Acc: 75.239% (14494/19264)
Loss: 0.998 | Acc: 75.171% (19292/25664)
Loss: 1.006 | Acc: 74.991% (24045/32064)
Loss: 1.009 | Acc: 74.945% (28827/38464)
Loss: 1.009 | Acc: 74.924% (33614/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2498, Accuracy: 6730/10000 (67.30%)

Epoch: 31
Loss: 0.646 | Acc: 85.938% (55/64)
Loss: 0.968 | Acc: 76.176% (4924/6464)
Loss: 0.982 | Acc: 75.731% (9742/12864)
Loss: 0.986 | Acc: 75.711% (14585/19264)
Loss: 0.987 | Acc: 75.627% (19409/25664)
Loss: 0.993 | Acc: 75.437% (24188/32064)
Loss: 0.990 | Acc: 75.473% (29030/38464)
Loss: 0.994 | Acc: 75.379% (33818/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1964, Accuracy: 6992/10000 (69.92%)

Epoch: 32
Loss: 1.003 | Acc: 71.875% (46/64)
Loss: 0.972 | Acc: 75.851% (4903/6464)
Loss: 0.978 | Acc: 75.832% (9755/12864)
Loss: 0.981 | Acc: 75.784% (14599/19264)
Loss: 0.978 | Acc: 75.896% (19478/25664)
Loss: 0.977 | Acc: 75.917% (24342/32064)
Loss: 0.978 | Acc: 75.985% (29227/38464)
Loss: 0.977 | Acc: 76.023% (34107/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2182, Accuracy: 6852/10000 (68.52%)

Epoch: 33
Loss: 0.982 | Acc: 78.125% (50/64)
Loss: 0.923 | Acc: 77.259% (4994/6464)
Loss: 0.935 | Acc: 77.068% (9914/12864)
Loss: 0.932 | Acc: 77.128% (14858/19264)
Loss: 0.944 | Acc: 76.707% (19686/25664)
Loss: 0.944 | Acc: 76.800% (24625/32064)
Loss: 0.950 | Acc: 76.612% (29468/38464)
Loss: 0.953 | Acc: 76.623% (34376/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2279, Accuracy: 6794/10000 (67.94%)

Epoch: 34
Loss: 1.052 | Acc: 73.438% (47/64)
Loss: 0.919 | Acc: 77.537% (5012/6464)
Loss: 0.914 | Acc: 77.799% (10008/12864)
Loss: 0.918 | Acc: 77.673% (14963/19264)
Loss: 0.922 | Acc: 77.572% (19908/25664)
Loss: 0.927 | Acc: 77.380% (24811/32064)
Loss: 0.931 | Acc: 77.350% (29752/38464)
Loss: 0.936 | Acc: 77.274% (34668/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2421, Accuracy: 6733/10000 (67.33%)

Epoch: 35
Loss: 0.902 | Acc: 78.125% (50/64)
Loss: 0.878 | Acc: 78.713% (5088/6464)
Loss: 0.895 | Acc: 78.242% (10065/12864)
Loss: 0.899 | Acc: 78.255% (15075/19264)
Loss: 0.900 | Acc: 78.172% (20062/25664)
Loss: 0.906 | Acc: 78.038% (25022/32064)
Loss: 0.911 | Acc: 77.899% (29963/38464)
Loss: 0.915 | Acc: 77.786% (34898/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1748, Accuracy: 7047/10000 (70.47%)

Epoch: 36
Loss: 0.939 | Acc: 76.562% (49/64)
Loss: 0.892 | Acc: 78.140% (5051/6464)
Loss: 0.890 | Acc: 78.343% (10078/12864)
Loss: 0.889 | Acc: 78.447% (15112/19264)
Loss: 0.891 | Acc: 78.429% (20128/25664)
Loss: 0.897 | Acc: 78.215% (25079/32064)
Loss: 0.896 | Acc: 78.273% (30107/38464)
Loss: 0.895 | Acc: 78.319% (35137/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2445, Accuracy: 6834/10000 (68.34%)

Epoch: 37
Loss: 0.741 | Acc: 82.812% (53/64)
Loss: 0.859 | Acc: 79.084% (5112/6464)
Loss: 0.859 | Acc: 79.198% (10188/12864)
Loss: 0.858 | Acc: 79.210% (15259/19264)
Loss: 0.854 | Acc: 79.333% (20360/25664)
Loss: 0.859 | Acc: 79.129% (25372/32064)
Loss: 0.867 | Acc: 78.915% (30354/38464)
Loss: 0.870 | Acc: 78.887% (35392/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1928, Accuracy: 7079/10000 (70.79%)

Epoch: 38
Loss: 0.850 | Acc: 79.688% (51/64)
Loss: 0.835 | Acc: 79.533% (5141/6464)
Loss: 0.828 | Acc: 79.827% (10269/12864)
Loss: 0.830 | Acc: 79.688% (15351/19264)
Loss: 0.840 | Acc: 79.364% (20368/25664)
Loss: 0.843 | Acc: 79.316% (25432/32064)
Loss: 0.842 | Acc: 79.331% (30514/38464)
Loss: 0.842 | Acc: 79.367% (35607/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2295, Accuracy: 6907/10000 (69.07%)

Epoch: 39
Loss: 1.056 | Acc: 70.312% (45/64)
Loss: 0.785 | Acc: 80.863% (5227/6464)
Loss: 0.786 | Acc: 80.830% (10398/12864)
Loss: 0.796 | Acc: 80.570% (15521/19264)
Loss: 0.798 | Acc: 80.510% (20662/25664)
Loss: 0.804 | Acc: 80.424% (25787/32064)
Loss: 0.806 | Acc: 80.408% (30928/38464)
Loss: 0.810 | Acc: 80.316% (36033/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2055, Accuracy: 7102/10000 (71.02%)

Epoch: 40
Loss: 0.607 | Acc: 84.375% (54/64)
Loss: 0.774 | Acc: 80.894% (5229/6464)
Loss: 0.771 | Acc: 81.063% (10428/12864)
Loss: 0.778 | Acc: 81.063% (15616/19264)
Loss: 0.783 | Acc: 80.927% (20769/25664)
Loss: 0.786 | Acc: 80.813% (25912/32064)
Loss: 0.787 | Acc: 80.691% (31037/38464)
Loss: 0.785 | Acc: 80.775% (36239/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2074, Accuracy: 7168/10000 (71.68%)

Epoch: 41
Loss: 0.837 | Acc: 79.688% (51/64)
Loss: 0.738 | Acc: 81.761% (5285/6464)
Loss: 0.739 | Acc: 81.887% (10534/12864)
Loss: 0.739 | Acc: 81.863% (15770/19264)
Loss: 0.743 | Acc: 81.647% (20954/25664)
Loss: 0.742 | Acc: 81.630% (26174/32064)
Loss: 0.745 | Acc: 81.557% (31370/38464)
Loss: 0.745 | Acc: 81.538% (36581/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2462, Accuracy: 7132/10000 (71.32%)

Epoch: 42
Loss: 0.489 | Acc: 87.500% (56/64)
Loss: 0.698 | Acc: 82.225% (5315/6464)
Loss: 0.698 | Acc: 82.346% (10593/12864)
Loss: 0.699 | Acc: 82.345% (15863/19264)
Loss: 0.701 | Acc: 82.290% (21119/25664)
Loss: 0.705 | Acc: 82.192% (26354/32064)
Loss: 0.704 | Acc: 82.345% (31673/38464)
Loss: 0.701 | Acc: 82.494% (37010/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2711, Accuracy: 7164/10000 (71.64%)

Epoch: 43
Loss: 0.581 | Acc: 87.500% (56/64)
Loss: 0.646 | Acc: 83.911% (5424/6464)
Loss: 0.656 | Acc: 83.380% (10726/12864)
Loss: 0.655 | Acc: 83.342% (16055/19264)
Loss: 0.650 | Acc: 83.557% (21444/25664)
Loss: 0.648 | Acc: 83.620% (26812/32064)
Loss: 0.654 | Acc: 83.543% (32134/38464)
Loss: 0.656 | Acc: 83.506% (37464/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2661, Accuracy: 7188/10000 (71.88%)

Epoch: 44
Loss: 0.505 | Acc: 87.500% (56/64)
Loss: 0.615 | Acc: 84.174% (5441/6464)
Loss: 0.613 | Acc: 84.313% (10846/12864)
Loss: 0.609 | Acc: 84.354% (16250/19264)
Loss: 0.610 | Acc: 84.418% (21665/25664)
Loss: 0.613 | Acc: 84.210% (27001/32064)
Loss: 0.608 | Acc: 84.349% (32444/38464)
Loss: 0.608 | Acc: 84.319% (37829/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3162, Accuracy: 7166/10000 (71.66%)

Epoch: 45
Loss: 0.442 | Acc: 92.188% (59/64)
Loss: 0.602 | Acc: 84.530% (5464/6464)
Loss: 0.655 | Acc: 83.574% (10751/12864)
Loss: 0.701 | Acc: 82.600% (15912/19264)
Loss: 0.739 | Acc: 81.819% (20998/25664)
Loss: 0.767 | Acc: 81.262% (26056/32064)
Loss: 0.790 | Acc: 80.766% (31066/38464)
Loss: 0.809 | Acc: 80.341% (36044/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1749, Accuracy: 7120/10000 (71.20%)

Epoch: 46
Loss: 0.934 | Acc: 70.312% (45/64)
Loss: 0.988 | Acc: 75.758% (4897/6464)
Loss: 0.982 | Acc: 76.213% (9804/12864)
Loss: 0.988 | Acc: 76.241% (14687/19264)
Loss: 0.995 | Acc: 76.052% (19518/25664)
Loss: 0.999 | Acc: 75.973% (24360/32064)
Loss: 1.002 | Acc: 75.840% (29171/38464)
Loss: 1.008 | Acc: 75.691% (33958/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1874, Accuracy: 7024/10000 (70.24%)

Epoch: 47
Loss: 0.619 | Acc: 89.062% (57/64)
Loss: 1.057 | Acc: 74.226% (4798/6464)
Loss: 1.052 | Acc: 73.951% (9513/12864)
Loss: 1.053 | Acc: 74.024% (14260/19264)
Loss: 1.052 | Acc: 74.119% (19022/25664)
Loss: 1.060 | Acc: 73.830% (23673/32064)
Loss: 1.060 | Acc: 73.770% (28375/38464)
Loss: 1.062 | Acc: 73.752% (33088/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1991, Accuracy: 6988/10000 (69.88%)
torch.Size([100, 10])
Test set: Average loss: 1.1991, Accuracy: 6988/10000 (69.88%)

Epoch: 48
Loss: 0.929 | Acc: 78.125% (50/64)
Loss: 1.056 | Acc: 74.273% (4801/6464)
Loss: 1.068 | Acc: 73.912% (9508/12864)
Loss: 1.078 | Acc: 73.661% (14190/19264)
Loss: 1.084 | Acc: 73.430% (18845/25664)
Loss: 1.078 | Acc: 73.515% (23572/32064)
Loss: 1.077 | Acc: 73.528% (28282/38464)
Loss: 1.077 | Acc: 73.469% (32961/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2021, Accuracy: 6980/10000 (69.80%)
torch.Size([100, 10])
Test set: Average loss: 1.2021, Accuracy: 6980/10000 (69.80%)

Epoch: 49
Loss: 1.152 | Acc: 71.875% (46/64)
Loss: 1.078 | Acc: 73.020% (4720/6464)
Loss: 1.092 | Acc: 72.691% (9351/12864)
Loss: 1.093 | Acc: 72.934% (14050/19264)
Loss: 1.088 | Acc: 73.044% (18746/25664)
Loss: 1.087 | Acc: 73.035% (23418/32064)
Loss: 1.082 | Acc: 73.126% (28127/38464)
Loss: 1.082 | Acc: 73.141% (32814/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2030, Accuracy: 6960/10000 (69.60%)
torch.Size([100, 10])
Test set: Average loss: 1.2030, Accuracy: 6960/10000 (69.60%)

Epoch: 50
Loss: 0.884 | Acc: 78.125% (50/64)
Loss: 1.708 | Acc: 45.684% (2953/6464)
Loss: 1.553 | Acc: 52.558% (6761/12864)
Loss: 1.477 | Acc: 55.996% (10787/19264)
Loss: 1.438 | Acc: 57.672% (14801/25664)
Loss: 1.406 | Acc: 59.113% (18954/32064)
Loss: 1.381 | Acc: 60.194% (23153/38464)
Loss: 1.364 | Acc: 60.926% (27334/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0180, Accuracy: 4079/10000 (40.79%)

Epoch: 51
Loss: 1.299 | Acc: 59.375% (38/64)
Loss: 1.224 | Acc: 66.708% (4312/6464)
Loss: 1.212 | Acc: 67.576% (8693/12864)
Loss: 1.216 | Acc: 67.188% (12943/19264)
Loss: 1.214 | Acc: 67.300% (17272/25664)
Loss: 1.209 | Acc: 67.449% (21627/32064)
Loss: 1.204 | Acc: 67.653% (26022/38464)
Loss: 1.202 | Acc: 67.720% (30382/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3233, Accuracy: 6418/10000 (64.18%)

Epoch: 52
Loss: 1.180 | Acc: 68.750% (44/64)
Loss: 1.170 | Acc: 68.920% (4455/6464)
Loss: 1.172 | Acc: 68.843% (8856/12864)
Loss: 1.167 | Acc: 69.103% (13312/19264)
Loss: 1.170 | Acc: 68.988% (17705/25664)
Loss: 1.172 | Acc: 68.915% (22097/32064)
Loss: 1.171 | Acc: 68.911% (26506/38464)
Loss: 1.173 | Acc: 68.832% (30881/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3997, Accuracy: 6123/10000 (61.23%)

Epoch: 53
Loss: 1.368 | Acc: 60.938% (39/64)
Loss: 1.148 | Acc: 69.941% (4521/6464)
Loss: 1.152 | Acc: 69.784% (8977/12864)
Loss: 1.159 | Acc: 69.487% (13386/19264)
Loss: 1.162 | Acc: 69.373% (17804/25664)
Loss: 1.164 | Acc: 69.477% (22277/32064)
Loss: 1.159 | Acc: 69.585% (26765/38464)
Loss: 1.162 | Acc: 69.465% (31165/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0459, Accuracy: 4379/10000 (43.79%)

Epoch: 54
Loss: 1.118 | Acc: 67.188% (43/64)
Loss: 1.148 | Acc: 69.446% (4489/6464)
Loss: 1.155 | Acc: 69.442% (8933/12864)
Loss: 1.152 | Acc: 69.653% (13418/19264)
Loss: 1.149 | Acc: 69.673% (17881/25664)
Loss: 1.154 | Acc: 69.555% (22302/32064)
Loss: 1.156 | Acc: 69.444% (26711/38464)
Loss: 1.156 | Acc: 69.474% (31169/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0415, Accuracy: 4611/10000 (46.11%)

Epoch: 55
Loss: 1.420 | Acc: 59.375% (38/64)
Loss: 1.139 | Acc: 70.096% (4531/6464)
Loss: 1.148 | Acc: 69.768% (8975/12864)
Loss: 1.148 | Acc: 69.980% (13481/19264)
Loss: 1.152 | Acc: 69.744% (17899/25664)
Loss: 1.148 | Acc: 69.923% (22420/32064)
Loss: 1.147 | Acc: 69.962% (26910/38464)
Loss: 1.148 | Acc: 69.864% (31344/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5095, Accuracy: 5659/10000 (56.59%)

Epoch: 56
Loss: 1.514 | Acc: 57.812% (37/64)
Loss: 1.144 | Acc: 70.189% (4537/6464)
Loss: 1.147 | Acc: 69.932% (8996/12864)
Loss: 1.144 | Acc: 70.089% (13502/19264)
Loss: 1.145 | Acc: 69.985% (17961/25664)
Loss: 1.147 | Acc: 69.994% (22443/32064)
Loss: 1.148 | Acc: 69.907% (26889/38464)
Loss: 1.147 | Acc: 70.009% (31409/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4023, Accuracy: 6154/10000 (61.54%)

Epoch: 57
Loss: 1.440 | Acc: 60.938% (39/64)
Loss: 1.135 | Acc: 69.524% (4494/6464)
Loss: 1.142 | Acc: 69.667% (8962/12864)
Loss: 1.144 | Acc: 69.788% (13444/19264)
Loss: 1.141 | Acc: 69.864% (17930/25664)
Loss: 1.139 | Acc: 69.935% (22424/32064)
Loss: 1.146 | Acc: 69.837% (26862/38464)
Loss: 1.141 | Acc: 69.942% (31379/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6321, Accuracy: 5317/10000 (53.17%)

Epoch: 58
Loss: 1.298 | Acc: 62.500% (40/64)
Loss: 1.138 | Acc: 70.529% (4559/6464)
Loss: 1.147 | Acc: 70.180% (9028/12864)
Loss: 1.137 | Acc: 70.328% (13548/19264)
Loss: 1.139 | Acc: 70.305% (18043/25664)
Loss: 1.143 | Acc: 70.157% (22495/32064)
Loss: 1.141 | Acc: 70.224% (27011/38464)
Loss: 1.139 | Acc: 70.344% (31559/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5129, Accuracy: 5779/10000 (57.79%)

Epoch: 59
Loss: 0.975 | Acc: 70.312% (45/64)
Loss: 1.139 | Acc: 70.405% (4551/6464)
Loss: 1.134 | Acc: 70.608% (9083/12864)
Loss: 1.133 | Acc: 70.619% (13604/19264)
Loss: 1.127 | Acc: 70.862% (18186/25664)
Loss: 1.130 | Acc: 70.665% (22658/32064)
Loss: 1.132 | Acc: 70.645% (27173/38464)
Loss: 1.137 | Acc: 70.522% (31639/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3594, Accuracy: 6216/10000 (62.16%)

Epoch: 60
Loss: 1.098 | Acc: 71.875% (46/64)
Loss: 1.130 | Acc: 70.606% (4564/6464)
Loss: 1.123 | Acc: 70.880% (9118/12864)
Loss: 1.138 | Acc: 70.364% (13555/19264)
Loss: 1.139 | Acc: 70.394% (18066/25664)
Loss: 1.136 | Acc: 70.565% (22626/32064)
Loss: 1.132 | Acc: 70.697% (27193/38464)
Loss: 1.132 | Acc: 70.642% (31693/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3817, Accuracy: 6344/10000 (63.44%)

Epoch: 61
Loss: 1.193 | Acc: 70.312% (45/64)
Loss: 1.116 | Acc: 70.854% (4580/6464)
Loss: 1.113 | Acc: 71.168% (9155/12864)
Loss: 1.122 | Acc: 70.821% (13643/19264)
Loss: 1.129 | Acc: 70.585% (18115/25664)
Loss: 1.126 | Acc: 70.718% (22675/32064)
Loss: 1.129 | Acc: 70.593% (27153/38464)
Loss: 1.126 | Acc: 70.689% (31714/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4189, Accuracy: 5974/10000 (59.74%)

Epoch: 62
Loss: 1.266 | Acc: 70.312% (45/64)
Loss: 1.116 | Acc: 71.473% (4620/6464)
Loss: 1.108 | Acc: 71.813% (9238/12864)
Loss: 1.121 | Acc: 71.356% (13746/19264)
Loss: 1.115 | Acc: 71.341% (18309/25664)
Loss: 1.120 | Acc: 71.223% (22837/32064)
Loss: 1.121 | Acc: 71.196% (27385/38464)
Loss: 1.122 | Acc: 71.061% (31881/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7633, Accuracy: 4995/10000 (49.95%)

Epoch: 63
Loss: 0.914 | Acc: 75.000% (48/64)
Loss: 1.110 | Acc: 71.163% (4600/6464)
Loss: 1.110 | Acc: 71.284% (9170/12864)
Loss: 1.104 | Acc: 71.486% (13771/19264)
Loss: 1.112 | Acc: 71.205% (18274/25664)
Loss: 1.111 | Acc: 71.257% (22848/32064)
Loss: 1.115 | Acc: 71.238% (27401/38464)
Loss: 1.117 | Acc: 71.213% (31949/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3819, Accuracy: 6207/10000 (62.07%)

Epoch: 64
Loss: 1.014 | Acc: 75.000% (48/64)
Loss: 1.122 | Acc: 70.854% (4580/6464)
Loss: 1.114 | Acc: 71.152% (9153/12864)
Loss: 1.103 | Acc: 71.621% (13797/19264)
Loss: 1.106 | Acc: 71.622% (18381/25664)
Loss: 1.109 | Acc: 71.594% (22956/32064)
Loss: 1.109 | Acc: 71.519% (27509/38464)
Loss: 1.111 | Acc: 71.365% (32017/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7734, Accuracy: 4498/10000 (44.98%)

Epoch: 65
Loss: 1.129 | Acc: 71.875% (46/64)
Loss: 1.092 | Acc: 72.416% (4681/6464)
Loss: 1.094 | Acc: 72.194% (9287/12864)
Loss: 1.107 | Acc: 71.745% (13821/19264)
Loss: 1.104 | Acc: 71.891% (18450/25664)
Loss: 1.106 | Acc: 71.666% (22979/32064)
Loss: 1.107 | Acc: 71.685% (27573/38464)
Loss: 1.105 | Acc: 71.668% (32153/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3221, Accuracy: 6325/10000 (63.25%)

Epoch: 66
Loss: 0.971 | Acc: 75.000% (48/64)
Loss: 1.062 | Acc: 72.834% (4708/6464)
Loss: 1.089 | Acc: 71.953% (9256/12864)
Loss: 1.095 | Acc: 71.802% (13832/19264)
Loss: 1.099 | Acc: 71.715% (18405/25664)
Loss: 1.101 | Acc: 71.672% (22981/32064)
Loss: 1.101 | Acc: 71.633% (27553/38464)
Loss: 1.098 | Acc: 71.708% (32171/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8015, Accuracy: 4772/10000 (47.72%)

Epoch: 67
Loss: 1.449 | Acc: 60.938% (39/64)
Loss: 1.098 | Acc: 71.829% (4643/6464)
Loss: 1.085 | Acc: 72.349% (9307/12864)
Loss: 1.086 | Acc: 72.472% (13961/19264)
Loss: 1.091 | Acc: 72.366% (18572/25664)
Loss: 1.089 | Acc: 72.293% (23180/32064)
Loss: 1.089 | Acc: 72.270% (27798/38464)
Loss: 1.090 | Acc: 72.245% (32412/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6061, Accuracy: 5403/10000 (54.03%)

Epoch: 68
Loss: 1.098 | Acc: 67.188% (43/64)
Loss: 1.092 | Acc: 72.246% (4670/6464)
Loss: 1.072 | Acc: 72.870% (9374/12864)
Loss: 1.077 | Acc: 72.628% (13991/19264)
Loss: 1.077 | Acc: 72.744% (18669/25664)
Loss: 1.081 | Acc: 72.627% (23287/32064)
Loss: 1.086 | Acc: 72.447% (27866/38464)
Loss: 1.082 | Acc: 72.539% (32544/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3881, Accuracy: 6221/10000 (62.21%)

Epoch: 69
Loss: 1.220 | Acc: 67.188% (43/64)
Loss: 1.035 | Acc: 74.366% (4807/6464)
Loss: 1.051 | Acc: 73.531% (9459/12864)
Loss: 1.067 | Acc: 72.965% (14056/19264)
Loss: 1.075 | Acc: 72.752% (18671/25664)
Loss: 1.074 | Acc: 72.751% (23327/32064)
Loss: 1.072 | Acc: 72.746% (27981/38464)
Loss: 1.074 | Acc: 72.733% (32631/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3267, Accuracy: 6448/10000 (64.48%)

Epoch: 70
Loss: 1.053 | Acc: 73.438% (47/64)
Loss: 1.028 | Acc: 74.304% (4803/6464)
Loss: 1.038 | Acc: 73.741% (9486/12864)
Loss: 1.047 | Acc: 73.692% (14196/19264)
Loss: 1.049 | Acc: 73.738% (18924/25664)
Loss: 1.058 | Acc: 73.381% (23529/32064)
Loss: 1.063 | Acc: 73.217% (28162/38464)
Loss: 1.067 | Acc: 73.105% (32798/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3690, Accuracy: 6153/10000 (61.53%)

Epoch: 71
Loss: 1.171 | Acc: 70.312% (45/64)
Loss: 1.031 | Acc: 74.165% (4794/6464)
Loss: 1.033 | Acc: 74.098% (9532/12864)
Loss: 1.047 | Acc: 73.609% (14180/19264)
Loss: 1.049 | Acc: 73.625% (18895/25664)
Loss: 1.050 | Acc: 73.693% (23629/32064)
Loss: 1.053 | Acc: 73.573% (28299/38464)
Loss: 1.053 | Acc: 73.562% (33003/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6946, Accuracy: 4937/10000 (49.37%)

Epoch: 72
Loss: 1.090 | Acc: 65.625% (42/64)
Loss: 1.040 | Acc: 73.515% (4752/6464)
Loss: 1.048 | Acc: 73.414% (9444/12864)
Loss: 1.056 | Acc: 73.256% (14112/19264)
Loss: 1.054 | Acc: 73.332% (18820/25664)
Loss: 1.052 | Acc: 73.522% (23574/32064)
Loss: 1.051 | Acc: 73.521% (28279/38464)
Loss: 1.053 | Acc: 73.522% (32985/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2946, Accuracy: 6579/10000 (65.79%)

Epoch: 73
Loss: 1.048 | Acc: 71.875% (46/64)
Loss: 1.037 | Acc: 73.747% (4767/6464)
Loss: 1.042 | Acc: 73.795% (9493/12864)
Loss: 1.046 | Acc: 73.816% (14220/19264)
Loss: 1.048 | Acc: 73.784% (18936/25664)
Loss: 1.046 | Acc: 73.868% (23685/32064)
Loss: 1.043 | Acc: 73.890% (28421/38464)
Loss: 1.043 | Acc: 73.870% (33141/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2506, Accuracy: 6763/10000 (67.63%)

Epoch: 74
Loss: 1.121 | Acc: 71.875% (46/64)
Loss: 1.021 | Acc: 74.459% (4813/6464)
Loss: 1.020 | Acc: 74.697% (9609/12864)
Loss: 1.029 | Acc: 74.377% (14328/19264)
Loss: 1.033 | Acc: 74.201% (19043/25664)
Loss: 1.029 | Acc: 74.323% (23831/32064)
Loss: 1.036 | Acc: 74.132% (28514/38464)
Loss: 1.036 | Acc: 74.146% (33265/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2410, Accuracy: 6732/10000 (67.32%)

Epoch: 75
Loss: 0.876 | Acc: 82.812% (53/64)
Loss: 1.020 | Acc: 74.969% (4846/6464)
Loss: 1.020 | Acc: 74.891% (9634/12864)
Loss: 1.023 | Acc: 74.683% (14387/19264)
Loss: 1.020 | Acc: 74.716% (19175/25664)
Loss: 1.020 | Acc: 74.669% (23942/32064)
Loss: 1.023 | Acc: 74.657% (28716/38464)
Loss: 1.023 | Acc: 74.683% (33506/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2910, Accuracy: 6513/10000 (65.13%)

Epoch: 76
Loss: 0.922 | Acc: 76.562% (49/64)
Loss: 0.989 | Acc: 75.356% (4871/6464)
Loss: 0.984 | Acc: 75.910% (9765/12864)
Loss: 1.000 | Acc: 75.369% (14519/19264)
Loss: 1.006 | Acc: 75.148% (19286/25664)
Loss: 1.013 | Acc: 74.972% (24039/32064)
Loss: 1.013 | Acc: 74.961% (28833/38464)
Loss: 1.010 | Acc: 75.029% (33661/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0759, Accuracy: 4986/10000 (49.86%)

Epoch: 77
Loss: 1.056 | Acc: 73.438% (47/64)
Loss: 1.002 | Acc: 75.139% (4857/6464)
Loss: 1.006 | Acc: 75.109% (9662/12864)
Loss: 1.003 | Acc: 75.135% (14474/19264)
Loss: 1.004 | Acc: 75.156% (19288/25664)
Loss: 1.005 | Acc: 75.100% (24080/32064)
Loss: 1.003 | Acc: 75.156% (28908/38464)
Loss: 1.003 | Acc: 75.201% (33738/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5585, Accuracy: 5663/10000 (56.63%)

Epoch: 78
Loss: 0.925 | Acc: 71.875% (46/64)
Loss: 0.981 | Acc: 76.052% (4916/6464)
Loss: 0.987 | Acc: 75.762% (9746/12864)
Loss: 1.000 | Acc: 75.420% (14529/19264)
Loss: 0.997 | Acc: 75.487% (19373/25664)
Loss: 0.998 | Acc: 75.396% (24175/32064)
Loss: 0.991 | Acc: 75.543% (29057/38464)
Loss: 0.992 | Acc: 75.526% (33884/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1839, Accuracy: 6963/10000 (69.63%)

Epoch: 79
Loss: 1.067 | Acc: 75.000% (48/64)
Loss: 0.950 | Acc: 77.058% (4981/6464)
Loss: 0.956 | Acc: 76.897% (9892/12864)
Loss: 0.961 | Acc: 76.682% (14772/19264)
Loss: 0.968 | Acc: 76.496% (19632/25664)
Loss: 0.973 | Acc: 76.350% (24481/32064)
Loss: 0.972 | Acc: 76.386% (29381/38464)
Loss: 0.971 | Acc: 76.371% (34263/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5361, Accuracy: 5635/10000 (56.35%)

Epoch: 80
Loss: 1.315 | Acc: 64.062% (41/64)
Loss: 0.990 | Acc: 75.449% (4877/6464)
Loss: 0.972 | Acc: 76.042% (9782/12864)
Loss: 0.968 | Acc: 76.116% (14663/19264)
Loss: 0.966 | Acc: 76.212% (19559/25664)
Loss: 0.963 | Acc: 76.357% (24483/32064)
Loss: 0.965 | Acc: 76.355% (29369/38464)
Loss: 0.965 | Acc: 76.404% (34278/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4172, Accuracy: 6222/10000 (62.22%)

Epoch: 81
Loss: 0.947 | Acc: 76.562% (49/64)
Loss: 0.955 | Acc: 76.238% (4928/6464)
Loss: 0.957 | Acc: 76.384% (9826/12864)
Loss: 0.956 | Acc: 76.495% (14736/19264)
Loss: 0.956 | Acc: 76.570% (19651/25664)
Loss: 0.951 | Acc: 76.765% (24614/32064)
Loss: 0.948 | Acc: 76.906% (29581/38464)
Loss: 0.951 | Acc: 76.832% (34470/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4122, Accuracy: 6231/10000 (62.31%)

Epoch: 82
Loss: 0.865 | Acc: 78.125% (50/64)
Loss: 0.946 | Acc: 76.516% (4946/6464)
Loss: 0.936 | Acc: 77.068% (9914/12864)
Loss: 0.924 | Acc: 77.538% (14937/19264)
Loss: 0.923 | Acc: 77.603% (19916/25664)
Loss: 0.926 | Acc: 77.464% (24838/32064)
Loss: 0.930 | Acc: 77.436% (29785/38464)
Loss: 0.932 | Acc: 77.378% (34715/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2239, Accuracy: 6892/10000 (68.92%)

Epoch: 83
Loss: 1.204 | Acc: 70.312% (45/64)
Loss: 0.891 | Acc: 78.342% (5064/6464)
Loss: 0.902 | Acc: 78.063% (10042/12864)
Loss: 0.899 | Acc: 78.234% (15071/19264)
Loss: 0.913 | Acc: 77.922% (19998/25664)
Loss: 0.912 | Acc: 77.941% (24991/32064)
Loss: 0.914 | Acc: 77.922% (29972/38464)
Loss: 0.916 | Acc: 77.893% (34946/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4765, Accuracy: 6040/10000 (60.40%)

Epoch: 84
Loss: 0.836 | Acc: 76.562% (49/64)
Loss: 0.899 | Acc: 78.450% (5071/6464)
Loss: 0.905 | Acc: 78.319% (10075/12864)
Loss: 0.905 | Acc: 78.333% (15090/19264)
Loss: 0.903 | Acc: 78.347% (20107/25664)
Loss: 0.896 | Acc: 78.449% (25154/32064)
Loss: 0.895 | Acc: 78.440% (30171/38464)
Loss: 0.897 | Acc: 78.332% (35143/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1572, Accuracy: 7165/10000 (71.65%)

Epoch: 85
Loss: 0.931 | Acc: 76.562% (49/64)
Loss: 0.865 | Acc: 79.486% (5138/6464)
Loss: 0.864 | Acc: 79.299% (10201/12864)
Loss: 0.866 | Acc: 79.220% (15261/19264)
Loss: 0.865 | Acc: 79.212% (20329/25664)
Loss: 0.862 | Acc: 79.276% (25419/32064)
Loss: 0.868 | Acc: 79.168% (30451/38464)
Loss: 0.873 | Acc: 79.052% (35466/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3497, Accuracy: 6500/10000 (65.00%)

Epoch: 86
Loss: 0.896 | Acc: 76.562% (49/64)
Loss: 0.843 | Acc: 79.657% (5149/6464)
Loss: 0.836 | Acc: 79.734% (10257/12864)
Loss: 0.830 | Acc: 79.880% (15388/19264)
Loss: 0.843 | Acc: 79.512% (20406/25664)
Loss: 0.847 | Acc: 79.466% (25480/32064)
Loss: 0.853 | Acc: 79.352% (30522/38464)
Loss: 0.855 | Acc: 79.262% (35560/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1334, Accuracy: 7248/10000 (72.48%)

Epoch: 87
Loss: 0.606 | Acc: 85.938% (55/64)
Loss: 0.816 | Acc: 80.446% (5200/6464)
Loss: 0.803 | Acc: 80.861% (10402/12864)
Loss: 0.820 | Acc: 80.259% (15461/19264)
Loss: 0.824 | Acc: 80.194% (20581/25664)
Loss: 0.826 | Acc: 80.152% (25700/32064)
Loss: 0.824 | Acc: 80.236% (30862/38464)
Loss: 0.822 | Acc: 80.318% (36034/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1855, Accuracy: 7170/10000 (71.70%)

Epoch: 88
Loss: 0.566 | Acc: 85.938% (55/64)
Loss: 0.788 | Acc: 80.770% (5221/6464)
Loss: 0.790 | Acc: 80.916% (10409/12864)
Loss: 0.791 | Acc: 80.819% (15569/19264)
Loss: 0.795 | Acc: 80.790% (20734/25664)
Loss: 0.796 | Acc: 80.770% (25898/32064)
Loss: 0.796 | Acc: 80.764% (31065/38464)
Loss: 0.799 | Acc: 80.715% (36212/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2230, Accuracy: 7101/10000 (71.01%)

Epoch: 89
Loss: 0.637 | Acc: 82.812% (53/64)
Loss: 0.748 | Acc: 81.683% (5280/6464)
Loss: 0.757 | Acc: 81.608% (10498/12864)
Loss: 0.760 | Acc: 81.546% (15709/19264)
Loss: 0.763 | Acc: 81.371% (20883/25664)
Loss: 0.763 | Acc: 81.400% (26100/32064)
Loss: 0.762 | Acc: 81.479% (31340/38464)
Loss: 0.764 | Acc: 81.428% (36532/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2212, Accuracy: 7174/10000 (71.74%)

Epoch: 90
Loss: 0.737 | Acc: 81.250% (52/64)
Loss: 0.698 | Acc: 82.998% (5365/6464)
Loss: 0.727 | Acc: 82.331% (10591/12864)
Loss: 0.725 | Acc: 82.460% (15885/19264)
Loss: 0.725 | Acc: 82.407% (21149/25664)
Loss: 0.729 | Acc: 82.245% (26371/32064)
Loss: 0.734 | Acc: 82.077% (31570/38464)
Loss: 0.732 | Acc: 82.150% (36856/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2205, Accuracy: 7243/10000 (72.43%)

Epoch: 91
Loss: 0.515 | Acc: 89.062% (57/64)
Loss: 0.689 | Acc: 82.720% (5347/6464)
Loss: 0.687 | Acc: 83.053% (10684/12864)
Loss: 0.697 | Acc: 82.735% (15938/19264)
Loss: 0.694 | Acc: 82.883% (21271/25664)
Loss: 0.695 | Acc: 82.850% (26565/32064)
Loss: 0.694 | Acc: 82.893% (31884/38464)
Loss: 0.692 | Acc: 82.928% (37205/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2340, Accuracy: 7222/10000 (72.22%)

Epoch: 92
Loss: 0.809 | Acc: 79.688% (51/64)
Loss: 0.634 | Acc: 84.097% (5436/6464)
Loss: 0.637 | Acc: 84.010% (10807/12864)
Loss: 0.637 | Acc: 84.048% (16191/19264)
Loss: 0.642 | Acc: 83.884% (21528/25664)
Loss: 0.652 | Acc: 83.655% (26823/32064)
Loss: 0.650 | Acc: 83.728% (32205/38464)
Loss: 0.648 | Acc: 83.798% (37595/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2813, Accuracy: 7167/10000 (71.67%)

Epoch: 93
Loss: 0.641 | Acc: 82.812% (53/64)
Loss: 0.593 | Acc: 84.994% (5494/6464)
Loss: 0.589 | Acc: 85.277% (10970/12864)
Loss: 0.590 | Acc: 85.174% (16408/19264)
Loss: 0.597 | Acc: 84.878% (21783/25664)
Loss: 0.593 | Acc: 84.952% (27239/32064)
Loss: 0.599 | Acc: 84.765% (32604/38464)
Loss: 0.601 | Acc: 84.707% (38003/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2973, Accuracy: 7181/10000 (71.81%)

Epoch: 94
Loss: 0.410 | Acc: 92.188% (59/64)
Loss: 0.550 | Acc: 85.705% (5540/6464)
Loss: 0.552 | Acc: 85.619% (11014/12864)
Loss: 0.555 | Acc: 85.538% (16478/19264)
Loss: 0.555 | Acc: 85.513% (21946/25664)
Loss: 0.556 | Acc: 85.541% (27428/32064)
Loss: 0.554 | Acc: 85.607% (32928/38464)
Loss: 0.551 | Acc: 85.703% (38450/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3221, Accuracy: 7221/10000 (72.21%)

Epoch: 95
Loss: 0.388 | Acc: 89.062% (57/64)
Loss: 0.537 | Acc: 86.030% (5561/6464)
Loss: 0.587 | Acc: 85.075% (10944/12864)
Loss: 0.623 | Acc: 84.219% (16224/19264)
Loss: 0.654 | Acc: 83.596% (21454/25664)
Loss: 0.686 | Acc: 82.968% (26603/32064)
Loss: 0.712 | Acc: 82.389% (31690/38464)
Loss: 0.730 | Acc: 81.979% (36779/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1757, Accuracy: 7110/10000 (71.10%)

Epoch: 96
Loss: 0.819 | Acc: 81.250% (52/64)
Loss: 0.924 | Acc: 77.522% (5011/6464)
Loss: 0.918 | Acc: 77.674% (9992/12864)
Loss: 0.930 | Acc: 77.362% (14903/19264)
Loss: 0.933 | Acc: 77.330% (19846/25664)
Loss: 0.929 | Acc: 77.423% (24825/32064)
Loss: 0.933 | Acc: 77.296% (29731/38464)
Loss: 0.938 | Acc: 77.178% (34625/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1775, Accuracy: 7096/10000 (70.96%)

Epoch: 97
Loss: 1.109 | Acc: 75.000% (48/64)
Loss: 0.991 | Acc: 75.727% (4895/6464)
Loss: 0.988 | Acc: 75.941% (9769/12864)
Loss: 0.985 | Acc: 76.095% (14659/19264)
Loss: 0.984 | Acc: 76.029% (19512/25664)
Loss: 0.987 | Acc: 75.873% (24328/32064)
Loss: 0.984 | Acc: 75.988% (29228/38464)
Loss: 0.988 | Acc: 75.858% (34033/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1867, Accuracy: 7033/10000 (70.33%)
torch.Size([100, 10])
Test set: Average loss: 1.1867, Accuracy: 7033/10000 (70.33%)

Epoch: 98
Loss: 0.721 | Acc: 82.812% (53/64)
Loss: 1.000 | Acc: 75.356% (4871/6464)
Loss: 1.015 | Acc: 74.837% (9627/12864)
Loss: 1.014 | Acc: 74.896% (14428/19264)
Loss: 1.017 | Acc: 74.875% (19216/25664)
Loss: 1.014 | Acc: 74.981% (24042/32064)
Loss: 1.015 | Acc: 74.979% (28840/38464)
Loss: 1.014 | Acc: 75.027% (33660/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1817, Accuracy: 7054/10000 (70.54%)
torch.Size([100, 10])
Test set: Average loss: 1.1817, Accuracy: 7054/10000 (70.54%)

Epoch: 99
Loss: 0.793 | Acc: 84.375% (54/64)
Loss: 1.010 | Acc: 74.907% (4842/6464)
Loss: 1.012 | Acc: 74.899% (9635/12864)
Loss: 1.010 | Acc: 75.114% (14470/19264)
Loss: 1.009 | Acc: 75.109% (19276/25664)
Loss: 1.011 | Acc: 75.059% (24067/32064)
Loss: 1.011 | Acc: 75.029% (28859/38464)
Loss: 1.011 | Acc: 75.053% (33672/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1794, Accuracy: 7068/10000 (70.68%)
torch.Size([100, 10])
Test set: Average loss: 1.1794, Accuracy: 7068/10000 (70.68%)

Epoch: 100
Loss: 0.945 | Acc: 76.562% (49/64)
Loss: 1.819 | Acc: 39.759% (2570/6464)
Loss: 1.643 | Acc: 48.057% (6182/12864)
Loss: 1.533 | Acc: 53.052% (10220/19264)
Loss: 1.470 | Acc: 55.810% (14323/25664)
Loss: 1.426 | Acc: 57.878% (18558/32064)
Loss: 1.395 | Acc: 59.188% (22766/38464)
Loss: 1.372 | Acc: 60.235% (27024/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5571, Accuracy: 5496/10000 (54.96%)

Epoch: 101
Loss: 1.331 | Acc: 68.750% (44/64)
Loss: 1.180 | Acc: 68.518% (4429/6464)
Loss: 1.187 | Acc: 68.097% (8760/12864)
Loss: 1.183 | Acc: 68.174% (13133/19264)
Loss: 1.181 | Acc: 68.372% (17547/25664)
Loss: 1.180 | Acc: 68.538% (21976/32064)
Loss: 1.175 | Acc: 68.685% (26419/38464)
Loss: 1.177 | Acc: 68.663% (30805/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3458, Accuracy: 6290/10000 (62.90%)

Epoch: 102
Loss: 0.918 | Acc: 78.125% (50/64)
Loss: 1.151 | Acc: 70.003% (4525/6464)
Loss: 1.146 | Acc: 69.947% (8998/12864)
Loss: 1.149 | Acc: 69.913% (13468/19264)
Loss: 1.146 | Acc: 69.974% (17958/25664)
Loss: 1.145 | Acc: 70.038% (22457/32064)
Loss: 1.150 | Acc: 69.899% (26886/38464)
Loss: 1.148 | Acc: 70.023% (31415/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9423, Accuracy: 4441/10000 (44.41%)

Epoch: 103
Loss: 1.348 | Acc: 62.500% (40/64)
Loss: 1.156 | Acc: 69.817% (4513/6464)
Loss: 1.152 | Acc: 69.846% (8985/12864)
Loss: 1.145 | Acc: 70.120% (13508/19264)
Loss: 1.138 | Acc: 70.238% (18026/25664)
Loss: 1.140 | Acc: 70.194% (22507/32064)
Loss: 1.143 | Acc: 70.102% (26964/38464)
Loss: 1.143 | Acc: 70.143% (31469/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7445, Accuracy: 5118/10000 (51.18%)

Epoch: 104
Loss: 1.176 | Acc: 65.625% (42/64)
Loss: 1.097 | Acc: 71.117% (4597/6464)
Loss: 1.120 | Acc: 70.717% (9097/12864)
Loss: 1.118 | Acc: 71.055% (13688/19264)
Loss: 1.126 | Acc: 70.796% (18169/25664)
Loss: 1.129 | Acc: 70.724% (22677/32064)
Loss: 1.134 | Acc: 70.640% (27171/38464)
Loss: 1.136 | Acc: 70.498% (31628/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5938, Accuracy: 5390/10000 (53.90%)

Epoch: 105
Loss: 1.616 | Acc: 56.250% (36/64)
Loss: 1.141 | Acc: 70.854% (4580/6464)
Loss: 1.125 | Acc: 71.004% (9134/12864)
Loss: 1.128 | Acc: 70.863% (13651/19264)
Loss: 1.118 | Acc: 71.045% (18233/25664)
Loss: 1.122 | Acc: 70.980% (22759/32064)
Loss: 1.126 | Acc: 70.897% (27270/38464)
Loss: 1.128 | Acc: 70.847% (31785/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6450, Accuracy: 5205/10000 (52.05%)

Epoch: 106
Loss: 1.133 | Acc: 68.750% (44/64)
Loss: 1.123 | Acc: 71.163% (4600/6464)
Loss: 1.132 | Acc: 70.771% (9104/12864)
Loss: 1.127 | Acc: 70.811% (13641/19264)
Loss: 1.126 | Acc: 70.897% (18195/25664)
Loss: 1.127 | Acc: 70.840% (22714/32064)
Loss: 1.130 | Acc: 70.801% (27233/38464)
Loss: 1.131 | Acc: 70.696% (31717/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0346, Accuracy: 4339/10000 (43.39%)

Epoch: 107
Loss: 1.220 | Acc: 68.750% (44/64)
Loss: 1.080 | Acc: 71.875% (4646/6464)
Loss: 1.097 | Acc: 71.494% (9197/12864)
Loss: 1.110 | Acc: 71.122% (13701/19264)
Loss: 1.118 | Acc: 70.893% (18194/25664)
Loss: 1.119 | Acc: 70.942% (22747/32064)
Loss: 1.123 | Acc: 70.791% (27229/38464)
Loss: 1.124 | Acc: 70.856% (31789/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8665, Accuracy: 4547/10000 (45.47%)

Epoch: 108
Loss: 1.579 | Acc: 53.125% (34/64)
Loss: 1.123 | Acc: 71.132% (4598/6464)
Loss: 1.113 | Acc: 71.486% (9196/12864)
Loss: 1.117 | Acc: 71.330% (13741/19264)
Loss: 1.118 | Acc: 71.400% (18324/25664)
Loss: 1.117 | Acc: 71.248% (22845/32064)
Loss: 1.123 | Acc: 71.095% (27346/38464)
Loss: 1.122 | Acc: 71.206% (31946/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9140, Accuracy: 4419/10000 (44.19%)

Epoch: 109
Loss: 1.253 | Acc: 65.625% (42/64)
Loss: 1.139 | Acc: 70.189% (4537/6464)
Loss: 1.119 | Acc: 70.888% (9119/12864)
Loss: 1.119 | Acc: 70.837% (13646/19264)
Loss: 1.116 | Acc: 71.096% (18246/25664)
Loss: 1.117 | Acc: 71.011% (22769/32064)
Loss: 1.119 | Acc: 70.983% (27303/38464)
Loss: 1.119 | Acc: 71.015% (31860/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5582, Accuracy: 5390/10000 (53.90%)

Epoch: 110
Loss: 1.445 | Acc: 62.500% (40/64)
Loss: 1.115 | Acc: 70.900% (4583/6464)
Loss: 1.107 | Acc: 71.129% (9150/12864)
Loss: 1.103 | Acc: 71.371% (13749/19264)
Loss: 1.107 | Acc: 71.341% (18309/25664)
Loss: 1.110 | Acc: 71.301% (22862/32064)
Loss: 1.112 | Acc: 71.319% (27432/38464)
Loss: 1.112 | Acc: 71.351% (32011/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3323, Accuracy: 6341/10000 (63.41%)

Epoch: 111
Loss: 1.084 | Acc: 71.875% (46/64)
Loss: 1.097 | Acc: 71.983% (4653/6464)
Loss: 1.102 | Acc: 71.914% (9251/12864)
Loss: 1.103 | Acc: 71.782% (13828/19264)
Loss: 1.097 | Acc: 71.902% (18453/25664)
Loss: 1.104 | Acc: 71.772% (23013/32064)
Loss: 1.106 | Acc: 71.766% (27604/38464)
Loss: 1.107 | Acc: 71.719% (32176/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7806, Accuracy: 4774/10000 (47.74%)

Epoch: 112
Loss: 1.374 | Acc: 60.938% (39/64)
Loss: 1.103 | Acc: 71.968% (4652/6464)
Loss: 1.084 | Acc: 72.411% (9315/12864)
Loss: 1.090 | Acc: 72.192% (13907/19264)
Loss: 1.093 | Acc: 72.101% (18504/25664)
Loss: 1.094 | Acc: 71.947% (23069/32064)
Loss: 1.101 | Acc: 71.789% (27613/38464)
Loss: 1.105 | Acc: 71.665% (32152/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6238, Accuracy: 5103/10000 (51.03%)

Epoch: 113
Loss: 1.130 | Acc: 75.000% (48/64)
Loss: 1.082 | Acc: 72.618% (4694/6464)
Loss: 1.089 | Acc: 72.225% (9291/12864)
Loss: 1.088 | Acc: 72.373% (13942/19264)
Loss: 1.086 | Acc: 72.475% (18600/25664)
Loss: 1.087 | Acc: 72.365% (23203/32064)
Loss: 1.092 | Acc: 72.158% (27755/38464)
Loss: 1.097 | Acc: 71.998% (32301/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5188, Accuracy: 5664/10000 (56.64%)

Epoch: 114
Loss: 1.044 | Acc: 68.750% (44/64)
Loss: 1.073 | Acc: 72.556% (4690/6464)
Loss: 1.077 | Acc: 72.419% (9316/12864)
Loss: 1.081 | Acc: 72.166% (13902/19264)
Loss: 1.083 | Acc: 72.253% (18543/25664)
Loss: 1.088 | Acc: 72.165% (23139/32064)
Loss: 1.095 | Acc: 71.937% (27670/38464)
Loss: 1.096 | Acc: 71.933% (32272/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9501, Accuracy: 4846/10000 (48.46%)

Epoch: 115
Loss: 0.877 | Acc: 79.688% (51/64)
Loss: 1.054 | Acc: 73.159% (4729/6464)
Loss: 1.074 | Acc: 72.676% (9349/12864)
Loss: 1.089 | Acc: 72.103% (13890/19264)
Loss: 1.093 | Acc: 72.054% (18492/25664)
Loss: 1.092 | Acc: 72.062% (23106/32064)
Loss: 1.090 | Acc: 72.174% (27761/38464)
Loss: 1.089 | Acc: 72.263% (32420/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6284, Accuracy: 5496/10000 (54.96%)

Epoch: 116
Loss: 1.182 | Acc: 64.062% (41/64)
Loss: 1.073 | Acc: 72.556% (4690/6464)
Loss: 1.076 | Acc: 72.458% (9321/12864)
Loss: 1.079 | Acc: 72.410% (13949/19264)
Loss: 1.083 | Acc: 72.276% (18549/25664)
Loss: 1.086 | Acc: 72.218% (23156/32064)
Loss: 1.084 | Acc: 72.309% (27813/38464)
Loss: 1.084 | Acc: 72.258% (32418/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4473, Accuracy: 5853/10000 (58.53%)

Epoch: 117
Loss: 0.869 | Acc: 79.688% (51/64)
Loss: 1.087 | Acc: 72.602% (4693/6464)
Loss: 1.092 | Acc: 72.310% (9302/12864)
Loss: 1.081 | Acc: 72.633% (13992/19264)
Loss: 1.079 | Acc: 72.783% (18679/25664)
Loss: 1.086 | Acc: 72.517% (23252/32064)
Loss: 1.081 | Acc: 72.616% (27931/38464)
Loss: 1.077 | Acc: 72.633% (32586/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2575, Accuracy: 6645/10000 (66.45%)

Epoch: 118
Loss: 1.305 | Acc: 73.438% (47/64)
Loss: 1.043 | Acc: 73.530% (4753/6464)
Loss: 1.057 | Acc: 73.235% (9421/12864)
Loss: 1.065 | Acc: 73.053% (14073/19264)
Loss: 1.065 | Acc: 72.982% (18730/25664)
Loss: 1.071 | Acc: 72.776% (23335/32064)
Loss: 1.070 | Acc: 72.816% (28008/38464)
Loss: 1.070 | Acc: 72.840% (32679/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2871, Accuracy: 6591/10000 (65.91%)

Epoch: 119
Loss: 0.970 | Acc: 78.125% (50/64)
Loss: 1.053 | Acc: 73.561% (4755/6464)
Loss: 1.054 | Acc: 73.461% (9450/12864)
Loss: 1.052 | Acc: 73.427% (14145/19264)
Loss: 1.061 | Acc: 73.208% (18788/25664)
Loss: 1.065 | Acc: 73.104% (23440/32064)
Loss: 1.064 | Acc: 73.133% (28130/38464)
Loss: 1.063 | Acc: 73.105% (32798/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5374, Accuracy: 5750/10000 (57.50%)

Epoch: 120
Loss: 1.013 | Acc: 71.875% (46/64)
Loss: 1.068 | Acc: 73.082% (4724/6464)
Loss: 1.057 | Acc: 73.422% (9445/12864)
Loss: 1.052 | Acc: 73.645% (14187/19264)
Loss: 1.053 | Acc: 73.617% (18893/25664)
Loss: 1.051 | Acc: 73.724% (23639/32064)
Loss: 1.053 | Acc: 73.682% (28341/38464)
Loss: 1.058 | Acc: 73.527% (32987/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3394, Accuracy: 6456/10000 (64.56%)

Epoch: 121
Loss: 1.205 | Acc: 70.312% (45/64)
Loss: 1.010 | Acc: 74.752% (4832/6464)
Loss: 1.036 | Acc: 73.842% (9499/12864)
Loss: 1.049 | Acc: 73.614% (14181/19264)
Loss: 1.054 | Acc: 73.496% (18862/25664)
Loss: 1.046 | Acc: 73.787% (23659/32064)
Loss: 1.051 | Acc: 73.692% (28345/38464)
Loss: 1.053 | Acc: 73.656% (33045/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3444, Accuracy: 6268/10000 (62.68%)

Epoch: 122
Loss: 1.135 | Acc: 68.750% (44/64)
Loss: 1.033 | Acc: 74.242% (4799/6464)
Loss: 1.028 | Acc: 74.238% (9550/12864)
Loss: 1.031 | Acc: 74.258% (14305/19264)
Loss: 1.028 | Acc: 74.419% (19099/25664)
Loss: 1.033 | Acc: 74.239% (23804/32064)
Loss: 1.034 | Acc: 74.158% (28524/38464)
Loss: 1.037 | Acc: 74.035% (33215/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7998, Accuracy: 4727/10000 (47.27%)

Epoch: 123
Loss: 0.980 | Acc: 76.562% (49/64)
Loss: 1.025 | Acc: 73.809% (4771/6464)
Loss: 1.025 | Acc: 74.223% (9548/12864)
Loss: 1.028 | Acc: 74.040% (14263/19264)
Loss: 1.024 | Acc: 74.279% (19063/25664)
Loss: 1.027 | Acc: 74.198% (23791/32064)
Loss: 1.031 | Acc: 74.155% (28523/38464)
Loss: 1.032 | Acc: 74.166% (33274/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2868, Accuracy: 6577/10000 (65.77%)

Epoch: 124
Loss: 0.880 | Acc: 79.688% (51/64)
Loss: 1.019 | Acc: 75.170% (4859/6464)
Loss: 1.014 | Acc: 74.953% (9642/12864)
Loss: 1.021 | Acc: 74.803% (14410/19264)
Loss: 1.016 | Acc: 74.926% (19229/25664)
Loss: 1.019 | Acc: 74.797% (23983/32064)
Loss: 1.017 | Acc: 74.841% (28787/38464)
Loss: 1.023 | Acc: 74.614% (33475/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1859, Accuracy: 6979/10000 (69.79%)

Epoch: 125
Loss: 1.038 | Acc: 73.438% (47/64)
Loss: 0.997 | Acc: 75.433% (4876/6464)
Loss: 0.994 | Acc: 75.474% (9709/12864)
Loss: 1.011 | Acc: 74.933% (14435/19264)
Loss: 1.011 | Acc: 74.961% (19238/25664)
Loss: 1.014 | Acc: 74.919% (24022/32064)
Loss: 1.012 | Acc: 74.995% (28846/38464)
Loss: 1.015 | Acc: 74.846% (33579/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2502, Accuracy: 6677/10000 (66.77%)

Epoch: 126
Loss: 0.777 | Acc: 82.812% (53/64)
Loss: 0.967 | Acc: 76.253% (4929/6464)
Loss: 0.972 | Acc: 76.220% (9805/12864)
Loss: 0.986 | Acc: 75.908% (14623/19264)
Loss: 0.990 | Acc: 75.822% (19459/25664)
Loss: 0.993 | Acc: 75.708% (24275/32064)
Loss: 0.994 | Acc: 75.658% (29101/38464)
Loss: 0.997 | Acc: 75.555% (33897/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1895, Accuracy: 6954/10000 (69.54%)

Epoch: 127
Loss: 0.890 | Acc: 79.688% (51/64)
Loss: 0.970 | Acc: 76.052% (4916/6464)
Loss: 0.983 | Acc: 75.824% (9754/12864)
Loss: 0.987 | Acc: 75.799% (14602/19264)
Loss: 0.993 | Acc: 75.553% (19390/25664)
Loss: 0.998 | Acc: 75.396% (24175/32064)
Loss: 0.993 | Acc: 75.562% (29064/38464)
Loss: 0.989 | Acc: 75.724% (33973/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2101, Accuracy: 6874/10000 (68.74%)

Epoch: 128
Loss: 1.248 | Acc: 71.875% (46/64)
Loss: 0.950 | Acc: 76.903% (4971/6464)
Loss: 0.966 | Acc: 76.555% (9848/12864)
Loss: 0.966 | Acc: 76.485% (14734/19264)
Loss: 0.970 | Acc: 76.411% (19610/25664)
Loss: 0.974 | Acc: 76.276% (24457/32064)
Loss: 0.976 | Acc: 76.225% (29319/38464)
Loss: 0.978 | Acc: 76.139% (34159/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3124, Accuracy: 6502/10000 (65.02%)

Epoch: 129
Loss: 0.939 | Acc: 76.562% (49/64)
Loss: 0.945 | Acc: 77.290% (4996/6464)
Loss: 0.952 | Acc: 77.099% (9918/12864)
Loss: 0.946 | Acc: 77.076% (14848/19264)
Loss: 0.949 | Acc: 76.940% (19746/25664)
Loss: 0.962 | Acc: 76.631% (24571/32064)
Loss: 0.967 | Acc: 76.492% (29422/38464)
Loss: 0.968 | Acc: 76.464% (34305/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3263, Accuracy: 6595/10000 (65.95%)

Epoch: 130
Loss: 1.124 | Acc: 73.438% (47/64)
Loss: 0.955 | Acc: 76.733% (4960/6464)
Loss: 0.968 | Acc: 76.461% (9836/12864)
Loss: 0.962 | Acc: 76.677% (14771/19264)
Loss: 0.960 | Acc: 76.679% (19679/25664)
Loss: 0.955 | Acc: 76.803% (24626/32064)
Loss: 0.954 | Acc: 76.817% (29547/38464)
Loss: 0.953 | Acc: 76.837% (34472/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4909, Accuracy: 5922/10000 (59.22%)

Epoch: 131
Loss: 1.042 | Acc: 70.312% (45/64)
Loss: 0.921 | Acc: 77.754% (5026/6464)
Loss: 0.917 | Acc: 78.008% (10035/12864)
Loss: 0.922 | Acc: 77.917% (15010/19264)
Loss: 0.924 | Acc: 77.786% (19963/25664)
Loss: 0.931 | Acc: 77.604% (24883/32064)
Loss: 0.931 | Acc: 77.569% (29836/38464)
Loss: 0.936 | Acc: 77.347% (34701/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2184, Accuracy: 6890/10000 (68.90%)

Epoch: 132
Loss: 1.087 | Acc: 73.438% (47/64)
Loss: 0.913 | Acc: 77.754% (5026/6464)
Loss: 0.919 | Acc: 77.472% (9966/12864)
Loss: 0.912 | Acc: 77.710% (14970/19264)
Loss: 0.916 | Acc: 77.681% (19936/25664)
Loss: 0.922 | Acc: 77.592% (24879/32064)
Loss: 0.921 | Acc: 77.660% (29871/38464)
Loss: 0.923 | Acc: 77.632% (34829/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1655, Accuracy: 7118/10000 (71.18%)

Epoch: 133
Loss: 0.927 | Acc: 78.125% (50/64)
Loss: 0.867 | Acc: 79.285% (5125/6464)
Loss: 0.891 | Acc: 78.607% (10112/12864)
Loss: 0.902 | Acc: 78.343% (15092/19264)
Loss: 0.905 | Acc: 78.386% (20117/25664)
Loss: 0.908 | Acc: 78.219% (25080/32064)
Loss: 0.907 | Acc: 78.182% (30072/38464)
Loss: 0.904 | Acc: 78.288% (35123/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2121, Accuracy: 6976/10000 (69.76%)

Epoch: 134
Loss: 0.966 | Acc: 75.000% (48/64)
Loss: 0.879 | Acc: 78.914% (5101/6464)
Loss: 0.883 | Acc: 78.646% (10117/12864)
Loss: 0.882 | Acc: 78.706% (15162/19264)
Loss: 0.883 | Acc: 78.694% (20196/25664)
Loss: 0.887 | Acc: 78.596% (25201/32064)
Loss: 0.887 | Acc: 78.637% (30247/38464)
Loss: 0.885 | Acc: 78.702% (35309/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1553, Accuracy: 7148/10000 (71.48%)

Epoch: 135
Loss: 0.903 | Acc: 78.125% (50/64)
Loss: 0.832 | Acc: 80.492% (5203/6464)
Loss: 0.836 | Acc: 80.325% (10333/12864)
Loss: 0.848 | Acc: 79.926% (15397/19264)
Loss: 0.855 | Acc: 79.629% (20436/25664)
Loss: 0.856 | Acc: 79.594% (25521/32064)
Loss: 0.863 | Acc: 79.313% (30507/38464)
Loss: 0.862 | Acc: 79.353% (35601/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1984, Accuracy: 7065/10000 (70.65%)

Epoch: 136
Loss: 1.178 | Acc: 70.312% (45/64)
Loss: 0.841 | Acc: 79.425% (5134/6464)
Loss: 0.837 | Acc: 79.664% (10248/12864)
Loss: 0.828 | Acc: 80.020% (15415/19264)
Loss: 0.835 | Acc: 79.867% (20497/25664)
Loss: 0.836 | Acc: 79.868% (25609/32064)
Loss: 0.841 | Acc: 79.674% (30646/38464)
Loss: 0.841 | Acc: 79.714% (35763/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2082, Accuracy: 7048/10000 (70.48%)

Epoch: 137
Loss: 0.791 | Acc: 82.812% (53/64)
Loss: 0.803 | Acc: 80.786% (5222/6464)
Loss: 0.797 | Acc: 80.908% (10408/12864)
Loss: 0.806 | Acc: 80.554% (15518/19264)
Loss: 0.803 | Acc: 80.736% (20720/25664)
Loss: 0.810 | Acc: 80.542% (25825/32064)
Loss: 0.814 | Acc: 80.447% (30943/38464)
Loss: 0.813 | Acc: 80.463% (36099/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2064, Accuracy: 7125/10000 (71.25%)

Epoch: 138
Loss: 0.923 | Acc: 76.562% (49/64)
Loss: 0.769 | Acc: 81.482% (5267/6464)
Loss: 0.779 | Acc: 81.126% (10436/12864)
Loss: 0.779 | Acc: 81.203% (15643/19264)
Loss: 0.775 | Acc: 81.351% (20878/25664)
Loss: 0.781 | Acc: 81.138% (26016/32064)
Loss: 0.777 | Acc: 81.232% (31245/38464)
Loss: 0.779 | Acc: 81.221% (36439/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1937, Accuracy: 7137/10000 (71.37%)

Epoch: 139
Loss: 0.705 | Acc: 81.250% (52/64)
Loss: 0.734 | Acc: 82.271% (5318/6464)
Loss: 0.738 | Acc: 82.206% (10575/12864)
Loss: 0.739 | Acc: 82.195% (15834/19264)
Loss: 0.748 | Acc: 81.893% (21017/25664)
Loss: 0.751 | Acc: 81.824% (26236/32064)
Loss: 0.752 | Acc: 81.861% (31487/38464)
Loss: 0.755 | Acc: 81.796% (36697/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2030, Accuracy: 7160/10000 (71.60%)

Epoch: 140
Loss: 0.492 | Acc: 85.938% (55/64)
Loss: 0.685 | Acc: 83.787% (5416/6464)
Loss: 0.700 | Acc: 82.968% (10673/12864)
Loss: 0.702 | Acc: 82.916% (15973/19264)
Loss: 0.708 | Acc: 82.785% (21246/25664)
Loss: 0.706 | Acc: 82.834% (26560/32064)
Loss: 0.712 | Acc: 82.646% (31789/38464)
Loss: 0.715 | Acc: 82.545% (37033/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2276, Accuracy: 7183/10000 (71.83%)

Epoch: 141
Loss: 0.506 | Acc: 90.625% (58/64)
Loss: 0.661 | Acc: 83.741% (5413/6464)
Loss: 0.669 | Acc: 83.567% (10750/12864)
Loss: 0.680 | Acc: 83.264% (16040/19264)
Loss: 0.685 | Acc: 83.109% (21329/25664)
Loss: 0.681 | Acc: 83.159% (26664/32064)
Loss: 0.677 | Acc: 83.283% (32034/38464)
Loss: 0.682 | Acc: 83.142% (37301/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2354, Accuracy: 7233/10000 (72.33%)

Epoch: 142
Loss: 0.587 | Acc: 87.500% (56/64)
Loss: 0.641 | Acc: 84.004% (5430/6464)
Loss: 0.635 | Acc: 84.111% (10820/12864)
Loss: 0.639 | Acc: 83.970% (16176/19264)
Loss: 0.636 | Acc: 84.052% (21571/25664)
Loss: 0.634 | Acc: 84.097% (26965/32064)
Loss: 0.637 | Acc: 84.110% (32352/38464)
Loss: 0.639 | Acc: 84.027% (37698/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2871, Accuracy: 7146/10000 (71.46%)

Epoch: 143
Loss: 0.559 | Acc: 87.500% (56/64)
Loss: 0.579 | Acc: 85.288% (5513/6464)
Loss: 0.587 | Acc: 85.075% (10944/12864)
Loss: 0.580 | Acc: 85.403% (16452/19264)
Loss: 0.589 | Acc: 85.030% (21822/25664)
Loss: 0.588 | Acc: 85.074% (27278/32064)
Loss: 0.589 | Acc: 85.051% (32714/38464)
Loss: 0.589 | Acc: 85.021% (38144/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2976, Accuracy: 7108/10000 (71.08%)

Epoch: 144
Loss: 0.559 | Acc: 89.062% (57/64)
Loss: 0.550 | Acc: 85.814% (5547/6464)
Loss: 0.554 | Acc: 85.759% (11032/12864)
Loss: 0.555 | Acc: 85.745% (16518/19264)
Loss: 0.554 | Acc: 85.875% (22039/25664)
Loss: 0.549 | Acc: 86.003% (27576/32064)
Loss: 0.548 | Acc: 85.938% (33055/38464)
Loss: 0.549 | Acc: 85.922% (38548/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3556, Accuracy: 7115/10000 (71.15%)

Epoch: 145
Loss: 0.462 | Acc: 87.500% (56/64)
Loss: 0.537 | Acc: 85.999% (5559/6464)
Loss: 0.574 | Acc: 85.137% (10952/12864)
Loss: 0.605 | Acc: 84.531% (16284/19264)
Loss: 0.635 | Acc: 83.970% (21550/25664)
Loss: 0.660 | Acc: 83.421% (26748/32064)
Loss: 0.688 | Acc: 82.755% (31831/38464)
Loss: 0.707 | Acc: 82.387% (36962/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2003, Accuracy: 7023/10000 (70.23%)

Epoch: 146
Loss: 0.947 | Acc: 76.562% (49/64)
Loss: 0.839 | Acc: 79.796% (5158/6464)
Loss: 0.864 | Acc: 79.244% (10194/12864)
Loss: 0.876 | Acc: 78.826% (15185/19264)
Loss: 0.880 | Acc: 78.799% (20223/25664)
Loss: 0.888 | Acc: 78.515% (25175/32064)
Loss: 0.901 | Acc: 78.117% (30047/38464)
Loss: 0.905 | Acc: 77.980% (34985/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1808, Accuracy: 7101/10000 (71.01%)

Epoch: 147
Loss: 0.825 | Acc: 78.125% (50/64)
Loss: 0.922 | Acc: 77.645% (5019/6464)
Loss: 0.918 | Acc: 77.837% (10013/12864)
Loss: 0.941 | Acc: 77.056% (14844/19264)
Loss: 0.936 | Acc: 77.315% (19842/25664)
Loss: 0.945 | Acc: 77.018% (24695/32064)
Loss: 0.951 | Acc: 76.794% (29538/38464)
Loss: 0.954 | Acc: 76.694% (34408/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1870, Accuracy: 7068/10000 (70.68%)
torch.Size([100, 10])
Test set: Average loss: 1.1870, Accuracy: 7068/10000 (70.68%)

Epoch: 148
Loss: 0.679 | Acc: 84.375% (54/64)
Loss: 0.977 | Acc: 76.052% (4916/6464)
Loss: 0.973 | Acc: 76.166% (9798/12864)
Loss: 0.975 | Acc: 76.080% (14656/19264)
Loss: 0.976 | Acc: 75.861% (19469/25664)
Loss: 0.976 | Acc: 75.957% (24355/32064)
Loss: 0.980 | Acc: 75.842% (29172/38464)
Loss: 0.981 | Acc: 75.867% (34037/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1836, Accuracy: 7044/10000 (70.44%)
torch.Size([100, 10])
Test set: Average loss: 1.1836, Accuracy: 7044/10000 (70.44%)

Epoch: 149
Loss: 0.783 | Acc: 82.812% (53/64)
Loss: 0.988 | Acc: 75.665% (4891/6464)
Loss: 0.976 | Acc: 76.026% (9780/12864)
Loss: 0.977 | Acc: 76.054% (14651/19264)
Loss: 0.980 | Acc: 75.873% (19472/25664)
Loss: 0.975 | Acc: 75.992% (24366/32064)
Loss: 0.984 | Acc: 75.725% (29127/38464)
Loss: 0.980 | Acc: 75.880% (34043/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1834, Accuracy: 7073/10000 (70.73%)
torch.Size([100, 10])
Test set: Average loss: 1.1834, Accuracy: 7073/10000 (70.73%)

Epoch: 150
Loss: 0.860 | Acc: 79.688% (51/64)
Loss: 1.683 | Acc: 47.153% (3048/6464)
Loss: 1.527 | Acc: 54.112% (6961/12864)
Loss: 1.456 | Acc: 57.184% (11016/19264)
Loss: 1.408 | Acc: 59.262% (15209/25664)
Loss: 1.369 | Acc: 60.888% (19523/32064)
Loss: 1.342 | Acc: 61.946% (23827/38464)
Loss: 1.322 | Acc: 62.794% (28172/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8711, Accuracy: 4483/10000 (44.83%)

Epoch: 151
Loss: 1.048 | Acc: 70.312% (45/64)
Loss: 1.175 | Acc: 68.533% (4430/6464)
Loss: 1.173 | Acc: 68.781% (8848/12864)
Loss: 1.179 | Acc: 68.620% (13219/19264)
Loss: 1.175 | Acc: 68.781% (17652/25664)
Loss: 1.170 | Acc: 69.009% (22127/32064)
Loss: 1.166 | Acc: 69.174% (26607/38464)
Loss: 1.166 | Acc: 69.216% (31053/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9182, Accuracy: 2568/10000 (25.68%)

Epoch: 152
Loss: 1.257 | Acc: 64.062% (41/64)
Loss: 1.121 | Acc: 70.823% (4578/6464)
Loss: 1.114 | Acc: 71.113% (9148/12864)
Loss: 1.132 | Acc: 70.598% (13600/19264)
Loss: 1.137 | Acc: 70.340% (18052/25664)
Loss: 1.140 | Acc: 70.272% (22532/32064)
Loss: 1.143 | Acc: 70.245% (27019/38464)
Loss: 1.139 | Acc: 70.362% (31567/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4084, Accuracy: 6059/10000 (60.59%)

Epoch: 153
Loss: 0.963 | Acc: 75.000% (48/64)
Loss: 1.125 | Acc: 71.055% (4593/6464)
Loss: 1.102 | Acc: 71.572% (9207/12864)
Loss: 1.116 | Acc: 71.304% (13736/19264)
Loss: 1.115 | Acc: 71.427% (18331/25664)
Loss: 1.121 | Acc: 71.208% (22832/32064)
Loss: 1.125 | Acc: 71.007% (27312/38464)
Loss: 1.128 | Acc: 70.890% (31804/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2960, Accuracy: 6460/10000 (64.60%)

Epoch: 154
Loss: 1.283 | Acc: 65.625% (42/64)
Loss: 1.105 | Acc: 71.055% (4593/6464)
Loss: 1.114 | Acc: 70.950% (9127/12864)
Loss: 1.118 | Acc: 70.946% (13667/19264)
Loss: 1.120 | Acc: 71.065% (18238/25664)
Loss: 1.126 | Acc: 70.949% (22749/32064)
Loss: 1.125 | Acc: 70.942% (27287/38464)
Loss: 1.125 | Acc: 70.952% (31832/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3457, Accuracy: 3067/10000 (30.67%)

Epoch: 155
Loss: 1.403 | Acc: 51.562% (33/64)
Loss: 1.141 | Acc: 70.467% (4555/6464)
Loss: 1.134 | Acc: 70.600% (9082/12864)
Loss: 1.116 | Acc: 71.081% (13693/19264)
Loss: 1.118 | Acc: 71.041% (18232/25664)
Loss: 1.117 | Acc: 71.077% (22790/32064)
Loss: 1.121 | Acc: 70.973% (27299/38464)
Loss: 1.121 | Acc: 70.995% (31851/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3404, Accuracy: 6300/10000 (63.00%)

Epoch: 156
Loss: 0.909 | Acc: 73.438% (47/64)
Loss: 1.117 | Acc: 71.303% (4609/6464)
Loss: 1.106 | Acc: 71.323% (9175/12864)
Loss: 1.098 | Acc: 71.595% (13792/19264)
Loss: 1.101 | Acc: 71.536% (18359/25664)
Loss: 1.107 | Acc: 71.323% (22869/32064)
Loss: 1.112 | Acc: 71.212% (27391/38464)
Loss: 1.116 | Acc: 71.066% (31883/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3280, Accuracy: 6388/10000 (63.88%)

Epoch: 157
Loss: 1.012 | Acc: 78.125% (50/64)
Loss: 1.108 | Acc: 71.024% (4591/6464)
Loss: 1.104 | Acc: 71.385% (9183/12864)
Loss: 1.113 | Acc: 71.226% (13721/19264)
Loss: 1.115 | Acc: 71.236% (18282/25664)
Loss: 1.117 | Acc: 71.214% (22834/32064)
Loss: 1.116 | Acc: 71.191% (27383/38464)
Loss: 1.115 | Acc: 71.099% (31898/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3711, Accuracy: 6320/10000 (63.20%)

Epoch: 158
Loss: 1.481 | Acc: 57.812% (37/64)
Loss: 1.113 | Acc: 71.411% (4616/6464)
Loss: 1.109 | Acc: 71.432% (9189/12864)
Loss: 1.106 | Acc: 71.496% (13773/19264)
Loss: 1.105 | Acc: 71.431% (18332/25664)
Loss: 1.108 | Acc: 71.420% (22900/32064)
Loss: 1.108 | Acc: 71.425% (27473/38464)
Loss: 1.111 | Acc: 71.380% (32024/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3725, Accuracy: 6235/10000 (62.35%)

Epoch: 159
Loss: 1.069 | Acc: 75.000% (48/64)
Loss: 1.088 | Acc: 71.999% (4654/6464)
Loss: 1.095 | Acc: 71.681% (9221/12864)
Loss: 1.094 | Acc: 71.922% (13855/19264)
Loss: 1.101 | Acc: 71.563% (18366/25664)
Loss: 1.099 | Acc: 71.666% (22979/32064)
Loss: 1.104 | Acc: 71.482% (27495/38464)
Loss: 1.108 | Acc: 71.380% (32024/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5127, Accuracy: 5714/10000 (57.14%)

Epoch: 160
Loss: 1.182 | Acc: 64.062% (41/64)
Loss: 1.104 | Acc: 71.906% (4648/6464)
Loss: 1.100 | Acc: 72.054% (9269/12864)
Loss: 1.094 | Acc: 72.171% (13903/19264)
Loss: 1.095 | Acc: 72.035% (18487/25664)
Loss: 1.093 | Acc: 72.112% (23122/32064)
Loss: 1.098 | Acc: 71.969% (27682/38464)
Loss: 1.103 | Acc: 71.813% (32218/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6385, Accuracy: 5236/10000 (52.36%)

Epoch: 161
Loss: 1.583 | Acc: 60.938% (39/64)
Loss: 1.115 | Acc: 71.179% (4601/6464)
Loss: 1.104 | Acc: 71.797% (9236/12864)
Loss: 1.112 | Acc: 71.460% (13766/19264)
Loss: 1.111 | Acc: 71.540% (18360/25664)
Loss: 1.110 | Acc: 71.541% (22939/32064)
Loss: 1.112 | Acc: 71.524% (27511/38464)
Loss: 1.109 | Acc: 71.558% (32104/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7181, Accuracy: 5038/10000 (50.38%)

Epoch: 162
Loss: 1.112 | Acc: 71.875% (46/64)
Loss: 1.076 | Acc: 72.447% (4683/6464)
Loss: 1.079 | Acc: 72.738% (9357/12864)
Loss: 1.078 | Acc: 72.565% (13979/19264)
Loss: 1.088 | Acc: 72.311% (18558/25664)
Loss: 1.094 | Acc: 72.134% (23129/32064)
Loss: 1.096 | Acc: 72.083% (27726/38464)
Loss: 1.098 | Acc: 72.009% (32306/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4888, Accuracy: 5993/10000 (59.93%)

Epoch: 163
Loss: 1.037 | Acc: 73.438% (47/64)
Loss: 1.063 | Acc: 72.927% (4714/6464)
Loss: 1.076 | Acc: 72.652% (9346/12864)
Loss: 1.084 | Acc: 72.332% (13934/19264)
Loss: 1.089 | Acc: 72.156% (18518/25664)
Loss: 1.091 | Acc: 72.084% (23113/32064)
Loss: 1.095 | Acc: 72.002% (27695/38464)
Loss: 1.096 | Acc: 71.995% (32300/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4166, Accuracy: 6050/10000 (60.50%)

Epoch: 164
Loss: 1.170 | Acc: 71.875% (46/64)
Loss: 1.077 | Acc: 72.850% (4709/6464)
Loss: 1.060 | Acc: 73.228% (9420/12864)
Loss: 1.076 | Acc: 72.752% (14015/19264)
Loss: 1.083 | Acc: 72.463% (18597/25664)
Loss: 1.081 | Acc: 72.533% (23257/32064)
Loss: 1.086 | Acc: 72.411% (27852/38464)
Loss: 1.089 | Acc: 72.281% (32428/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2439, Accuracy: 6679/10000 (66.79%)

Epoch: 165
Loss: 1.306 | Acc: 71.875% (46/64)
Loss: 1.091 | Acc: 71.875% (4646/6464)
Loss: 1.084 | Acc: 72.256% (9295/12864)
Loss: 1.079 | Acc: 72.591% (13984/19264)
Loss: 1.079 | Acc: 72.592% (18630/25664)
Loss: 1.084 | Acc: 72.433% (23225/32064)
Loss: 1.080 | Acc: 72.564% (27911/38464)
Loss: 1.081 | Acc: 72.541% (32545/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3210, Accuracy: 6345/10000 (63.45%)

Epoch: 166
Loss: 1.191 | Acc: 70.312% (45/64)
Loss: 1.052 | Acc: 73.314% (4739/6464)
Loss: 1.059 | Acc: 73.204% (9417/12864)
Loss: 1.058 | Acc: 73.142% (14090/19264)
Loss: 1.069 | Acc: 72.841% (18694/25664)
Loss: 1.073 | Acc: 72.758% (23329/32064)
Loss: 1.077 | Acc: 72.647% (27943/38464)
Loss: 1.078 | Acc: 72.637% (32588/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3401, Accuracy: 6318/10000 (63.18%)

Epoch: 167
Loss: 0.912 | Acc: 76.562% (49/64)
Loss: 1.065 | Acc: 73.190% (4731/6464)
Loss: 1.075 | Acc: 72.862% (9373/12864)
Loss: 1.072 | Acc: 72.991% (14061/19264)
Loss: 1.068 | Acc: 73.173% (18779/25664)
Loss: 1.069 | Acc: 73.032% (23417/32064)
Loss: 1.068 | Acc: 73.048% (28097/38464)
Loss: 1.072 | Acc: 72.961% (32733/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4469, Accuracy: 5997/10000 (59.97%)

Epoch: 168
Loss: 0.749 | Acc: 82.812% (53/64)
Loss: 1.045 | Acc: 73.654% (4761/6464)
Loss: 1.060 | Acc: 73.057% (9398/12864)
Loss: 1.062 | Acc: 72.981% (14059/19264)
Loss: 1.064 | Acc: 72.966% (18726/25664)
Loss: 1.065 | Acc: 73.016% (23412/32064)
Loss: 1.066 | Acc: 73.009% (28082/38464)
Loss: 1.067 | Acc: 72.992% (32747/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1559, Accuracy: 4570/10000 (45.70%)

Epoch: 169
Loss: 1.222 | Acc: 62.500% (40/64)
Loss: 1.048 | Acc: 73.515% (4752/6464)
Loss: 1.059 | Acc: 73.134% (9408/12864)
Loss: 1.068 | Acc: 72.996% (14062/19264)
Loss: 1.060 | Acc: 73.266% (18803/25664)
Loss: 1.065 | Acc: 73.207% (23473/32064)
Loss: 1.061 | Acc: 73.315% (28200/38464)
Loss: 1.063 | Acc: 73.244% (32860/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3512, Accuracy: 6251/10000 (62.51%)

Epoch: 170
Loss: 1.434 | Acc: 65.625% (42/64)
Loss: 1.036 | Acc: 74.180% (4795/6464)
Loss: 1.043 | Acc: 73.811% (9495/12864)
Loss: 1.052 | Acc: 73.624% (14183/19264)
Loss: 1.052 | Acc: 73.683% (18910/25664)
Loss: 1.052 | Acc: 73.653% (23616/32064)
Loss: 1.049 | Acc: 73.788% (28382/38464)
Loss: 1.053 | Acc: 73.651% (33043/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6140, Accuracy: 5580/10000 (55.80%)

Epoch: 171
Loss: 1.119 | Acc: 70.312% (45/64)
Loss: 1.022 | Acc: 74.443% (4812/6464)
Loss: 1.029 | Acc: 74.339% (9563/12864)
Loss: 1.028 | Acc: 74.263% (14306/19264)
Loss: 1.037 | Acc: 74.022% (18997/25664)
Loss: 1.041 | Acc: 73.893% (23693/32064)
Loss: 1.043 | Acc: 73.765% (28373/38464)
Loss: 1.044 | Acc: 73.814% (33116/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2921, Accuracy: 6512/10000 (65.12%)

Epoch: 172
Loss: 1.234 | Acc: 67.188% (43/64)
Loss: 1.033 | Acc: 73.855% (4774/6464)
Loss: 1.029 | Acc: 74.417% (9573/12864)
Loss: 1.027 | Acc: 74.455% (14343/19264)
Loss: 1.030 | Acc: 74.291% (19066/25664)
Loss: 1.031 | Acc: 74.283% (23818/32064)
Loss: 1.033 | Acc: 74.207% (28543/38464)
Loss: 1.034 | Acc: 74.224% (33300/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7641, Accuracy: 4905/10000 (49.05%)

Epoch: 173
Loss: 0.824 | Acc: 81.250% (52/64)
Loss: 1.025 | Acc: 74.226% (4798/6464)
Loss: 1.022 | Acc: 74.541% (9589/12864)
Loss: 1.027 | Acc: 74.491% (14350/19264)
Loss: 1.029 | Acc: 74.408% (19096/25664)
Loss: 1.028 | Acc: 74.498% (23887/32064)
Loss: 1.028 | Acc: 74.459% (28640/38464)
Loss: 1.028 | Acc: 74.510% (33428/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3463, Accuracy: 6431/10000 (64.31%)

Epoch: 174
Loss: 1.201 | Acc: 67.188% (43/64)
Loss: 1.008 | Acc: 75.449% (4877/6464)
Loss: 1.011 | Acc: 75.303% (9687/12864)
Loss: 1.002 | Acc: 75.306% (14507/19264)
Loss: 1.012 | Acc: 75.051% (19261/25664)
Loss: 1.013 | Acc: 75.019% (24054/32064)
Loss: 1.012 | Acc: 75.052% (28868/38464)
Loss: 1.015 | Acc: 74.918% (33611/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2552, Accuracy: 6682/10000 (66.82%)

Epoch: 175
Loss: 1.271 | Acc: 67.188% (43/64)
Loss: 0.995 | Acc: 75.248% (4864/6464)
Loss: 0.989 | Acc: 75.490% (9711/12864)
Loss: 0.997 | Acc: 75.306% (14507/19264)
Loss: 1.003 | Acc: 75.195% (19298/25664)
Loss: 0.998 | Acc: 75.312% (24148/32064)
Loss: 1.000 | Acc: 75.265% (28950/38464)
Loss: 1.005 | Acc: 75.165% (33722/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2876, Accuracy: 6547/10000 (65.47%)

Epoch: 176
Loss: 1.185 | Acc: 68.750% (44/64)
Loss: 1.002 | Acc: 75.309% (4868/6464)
Loss: 1.007 | Acc: 75.179% (9671/12864)
Loss: 1.003 | Acc: 75.400% (14525/19264)
Loss: 1.003 | Acc: 75.312% (19328/25664)
Loss: 1.004 | Acc: 75.278% (24137/32064)
Loss: 0.999 | Acc: 75.452% (29022/38464)
Loss: 0.998 | Acc: 75.459% (33854/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3771, Accuracy: 6317/10000 (63.17%)

Epoch: 177
Loss: 0.884 | Acc: 79.688% (51/64)
Loss: 0.998 | Acc: 75.093% (4854/6464)
Loss: 0.979 | Acc: 75.777% (9748/12864)
Loss: 0.982 | Acc: 75.805% (14603/19264)
Loss: 0.983 | Acc: 75.779% (19448/25664)
Loss: 0.987 | Acc: 75.742% (24286/32064)
Loss: 0.990 | Acc: 75.676% (29108/38464)
Loss: 0.987 | Acc: 75.771% (33994/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3033, Accuracy: 6493/10000 (64.93%)

Epoch: 178
Loss: 0.785 | Acc: 79.688% (51/64)
Loss: 0.929 | Acc: 77.135% (4986/6464)
Loss: 0.952 | Acc: 76.749% (9873/12864)
Loss: 0.963 | Acc: 76.402% (14718/19264)
Loss: 0.966 | Acc: 76.301% (19582/25664)
Loss: 0.969 | Acc: 76.288% (24461/32064)
Loss: 0.968 | Acc: 76.357% (29370/38464)
Loss: 0.973 | Acc: 76.259% (34213/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3925, Accuracy: 6271/10000 (62.71%)

Epoch: 179
Loss: 1.068 | Acc: 71.875% (46/64)
Loss: 0.977 | Acc: 76.207% (4926/6464)
Loss: 0.968 | Acc: 76.477% (9838/12864)
Loss: 0.961 | Acc: 76.672% (14770/19264)
Loss: 0.961 | Acc: 76.640% (19669/25664)
Loss: 0.958 | Acc: 76.725% (24601/32064)
Loss: 0.954 | Acc: 76.877% (29570/38464)
Loss: 0.957 | Acc: 76.817% (34463/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1732, Accuracy: 7066/10000 (70.66%)

Epoch: 180
Loss: 0.742 | Acc: 81.250% (52/64)
Loss: 0.938 | Acc: 77.491% (5009/6464)
Loss: 0.943 | Acc: 77.130% (9922/12864)
Loss: 0.934 | Acc: 77.518% (14933/19264)
Loss: 0.934 | Acc: 77.502% (19890/25664)
Loss: 0.940 | Acc: 77.314% (24790/32064)
Loss: 0.943 | Acc: 77.246% (29712/38464)
Loss: 0.945 | Acc: 77.182% (34627/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2661, Accuracy: 6672/10000 (66.72%)

Epoch: 181
Loss: 0.997 | Acc: 75.000% (48/64)
Loss: 0.908 | Acc: 77.939% (5038/6464)
Loss: 0.902 | Acc: 78.156% (10054/12864)
Loss: 0.912 | Acc: 77.954% (15017/19264)
Loss: 0.923 | Acc: 77.673% (19934/25664)
Loss: 0.921 | Acc: 77.670% (24904/32064)
Loss: 0.927 | Acc: 77.587% (29843/38464)
Loss: 0.931 | Acc: 77.501% (34770/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3498, Accuracy: 6325/10000 (63.25%)

Epoch: 182
Loss: 1.198 | Acc: 62.500% (40/64)
Loss: 0.922 | Acc: 77.305% (4997/6464)
Loss: 0.890 | Acc: 78.109% (10048/12864)
Loss: 0.901 | Acc: 77.959% (15018/19264)
Loss: 0.905 | Acc: 77.965% (20009/25664)
Loss: 0.911 | Acc: 77.857% (24964/32064)
Loss: 0.912 | Acc: 77.849% (29944/38464)
Loss: 0.915 | Acc: 77.791% (34900/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1540, Accuracy: 7143/10000 (71.43%)

Epoch: 183
Loss: 0.931 | Acc: 81.250% (52/64)
Loss: 0.873 | Acc: 78.883% (5099/6464)
Loss: 0.879 | Acc: 78.848% (10143/12864)
Loss: 0.893 | Acc: 78.431% (15109/19264)
Loss: 0.894 | Acc: 78.417% (20125/25664)
Loss: 0.898 | Acc: 78.337% (25118/32064)
Loss: 0.898 | Acc: 78.315% (30123/38464)
Loss: 0.899 | Acc: 78.341% (35147/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1524, Accuracy: 7194/10000 (71.94%)

Epoch: 184
Loss: 0.809 | Acc: 81.250% (52/64)
Loss: 0.862 | Acc: 79.146% (5116/6464)
Loss: 0.876 | Acc: 78.708% (10125/12864)
Loss: 0.882 | Acc: 78.665% (15154/19264)
Loss: 0.879 | Acc: 78.893% (20247/25664)
Loss: 0.878 | Acc: 78.980% (25324/32064)
Loss: 0.877 | Acc: 78.991% (30383/38464)
Loss: 0.877 | Acc: 78.994% (35440/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1678, Accuracy: 7188/10000 (71.88%)

Epoch: 185
Loss: 1.048 | Acc: 71.875% (46/64)
Loss: 0.825 | Acc: 80.043% (5174/6464)
Loss: 0.832 | Acc: 79.796% (10265/12864)
Loss: 0.836 | Acc: 79.911% (15394/19264)
Loss: 0.847 | Acc: 79.645% (20440/25664)
Loss: 0.850 | Acc: 79.566% (25512/32064)
Loss: 0.851 | Acc: 79.565% (30604/38464)
Loss: 0.854 | Acc: 79.518% (35675/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1830, Accuracy: 7101/10000 (71.01%)

Epoch: 186
Loss: 0.476 | Acc: 92.188% (59/64)
Loss: 0.805 | Acc: 80.770% (5221/6464)
Loss: 0.818 | Acc: 80.395% (10342/12864)
Loss: 0.827 | Acc: 80.248% (15459/19264)
Loss: 0.833 | Acc: 80.101% (20557/25664)
Loss: 0.837 | Acc: 80.015% (25656/32064)
Loss: 0.834 | Acc: 80.007% (30774/38464)
Loss: 0.835 | Acc: 79.924% (35857/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1727, Accuracy: 7228/10000 (72.28%)

Epoch: 187
Loss: 0.587 | Acc: 89.062% (57/64)
Loss: 0.806 | Acc: 80.461% (5201/6464)
Loss: 0.802 | Acc: 80.690% (10380/12864)
Loss: 0.802 | Acc: 80.653% (15537/19264)
Loss: 0.806 | Acc: 80.560% (20675/25664)
Loss: 0.808 | Acc: 80.483% (25806/32064)
Loss: 0.812 | Acc: 80.452% (30945/38464)
Loss: 0.814 | Acc: 80.405% (36073/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1915, Accuracy: 7193/10000 (71.93%)

Epoch: 188
Loss: 0.693 | Acc: 85.938% (55/64)
Loss: 0.783 | Acc: 80.832% (5225/6464)
Loss: 0.777 | Acc: 81.250% (10452/12864)
Loss: 0.782 | Acc: 81.167% (15636/19264)
Loss: 0.780 | Acc: 81.188% (20836/25664)
Loss: 0.781 | Acc: 81.141% (26017/32064)
Loss: 0.780 | Acc: 81.188% (31228/38464)
Loss: 0.784 | Acc: 81.085% (36378/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2036, Accuracy: 7176/10000 (71.76%)

Epoch: 189
Loss: 0.651 | Acc: 87.500% (56/64)
Loss: 0.733 | Acc: 82.395% (5326/6464)
Loss: 0.735 | Acc: 82.307% (10588/12864)
Loss: 0.737 | Acc: 82.231% (15841/19264)
Loss: 0.741 | Acc: 82.146% (21082/25664)
Loss: 0.742 | Acc: 82.105% (26326/32064)
Loss: 0.748 | Acc: 81.910% (31506/38464)
Loss: 0.753 | Acc: 81.760% (36681/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2248, Accuracy: 7228/10000 (72.28%)

Epoch: 190
Loss: 0.763 | Acc: 75.000% (48/64)
Loss: 0.698 | Acc: 82.921% (5360/6464)
Loss: 0.701 | Acc: 83.007% (10678/12864)
Loss: 0.711 | Acc: 82.771% (15945/19264)
Loss: 0.713 | Acc: 82.735% (21233/25664)
Loss: 0.709 | Acc: 82.856% (26567/32064)
Loss: 0.712 | Acc: 82.748% (31828/38464)
Loss: 0.714 | Acc: 82.723% (37113/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2179, Accuracy: 7213/10000 (72.13%)

Epoch: 191
Loss: 0.893 | Acc: 76.562% (49/64)
Loss: 0.657 | Acc: 83.818% (5418/6464)
Loss: 0.651 | Acc: 84.204% (10832/12864)
Loss: 0.658 | Acc: 84.027% (16187/19264)
Loss: 0.663 | Acc: 83.857% (21521/25664)
Loss: 0.667 | Acc: 83.761% (26857/32064)
Loss: 0.672 | Acc: 83.590% (32152/38464)
Loss: 0.673 | Acc: 83.508% (37465/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2571, Accuracy: 7167/10000 (71.67%)

Epoch: 192
Loss: 0.780 | Acc: 79.688% (51/64)
Loss: 0.632 | Acc: 84.097% (5436/6464)
Loss: 0.621 | Acc: 84.507% (10871/12864)
Loss: 0.624 | Acc: 84.437% (16266/19264)
Loss: 0.630 | Acc: 84.317% (21639/25664)
Loss: 0.636 | Acc: 84.132% (26976/32064)
Loss: 0.636 | Acc: 84.172% (32376/38464)
Loss: 0.638 | Acc: 84.110% (37735/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3177, Accuracy: 7168/10000 (71.68%)

Epoch: 193
Loss: 0.473 | Acc: 87.500% (56/64)
Loss: 0.580 | Acc: 85.412% (5521/6464)
Loss: 0.594 | Acc: 84.989% (10933/12864)
Loss: 0.595 | Acc: 84.946% (16364/19264)
Loss: 0.597 | Acc: 84.917% (21793/25664)
Loss: 0.594 | Acc: 84.989% (27251/32064)
Loss: 0.592 | Acc: 85.038% (32709/38464)
Loss: 0.593 | Acc: 84.986% (38128/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3206, Accuracy: 7132/10000 (71.32%)

Epoch: 194
Loss: 0.624 | Acc: 85.938% (55/64)
Loss: 0.549 | Acc: 85.628% (5535/6464)
Loss: 0.546 | Acc: 85.953% (11057/12864)
Loss: 0.549 | Acc: 85.927% (16553/19264)
Loss: 0.552 | Acc: 85.844% (22031/25664)
Loss: 0.549 | Acc: 85.975% (27567/32064)
Loss: 0.550 | Acc: 85.927% (33051/38464)
Loss: 0.550 | Acc: 85.926% (38550/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3575, Accuracy: 7176/10000 (71.76%)

Epoch: 195
Loss: 0.513 | Acc: 89.062% (57/64)
Loss: 0.535 | Acc: 86.170% (5570/6464)
Loss: 0.565 | Acc: 85.790% (11036/12864)
Loss: 0.603 | Acc: 84.697% (16316/19264)
Loss: 0.630 | Acc: 84.059% (21573/25664)
Loss: 0.658 | Acc: 83.424% (26749/32064)
Loss: 0.680 | Acc: 82.929% (31898/38464)
Loss: 0.701 | Acc: 82.438% (36985/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1968, Accuracy: 7114/10000 (71.14%)

Epoch: 196
Loss: 1.199 | Acc: 70.312% (45/64)
Loss: 0.820 | Acc: 79.827% (5160/6464)
Loss: 0.836 | Acc: 79.345% (10207/12864)
Loss: 0.859 | Acc: 78.789% (15178/19264)
Loss: 0.866 | Acc: 78.632% (20180/25664)
Loss: 0.871 | Acc: 78.590% (25199/32064)
Loss: 0.879 | Acc: 78.323% (30126/38464)
Loss: 0.882 | Acc: 78.281% (35120/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1867, Accuracy: 7099/10000 (70.99%)

Epoch: 197
Loss: 0.823 | Acc: 81.250% (52/64)
Loss: 0.925 | Acc: 77.243% (4993/6464)
Loss: 0.925 | Acc: 77.184% (9929/12864)
Loss: 0.926 | Acc: 77.227% (14877/19264)
Loss: 0.937 | Acc: 76.964% (19752/25664)
Loss: 0.945 | Acc: 76.775% (24617/32064)
Loss: 0.942 | Acc: 76.872% (29568/38464)
Loss: 0.943 | Acc: 76.826% (34467/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1839, Accuracy: 7090/10000 (70.90%)
torch.Size([100, 10])
Test set: Average loss: 1.1839, Accuracy: 7090/10000 (70.90%)

Epoch: 198
Loss: 0.903 | Acc: 79.688% (51/64)
Loss: 0.956 | Acc: 76.238% (4928/6464)
Loss: 0.951 | Acc: 76.461% (9836/12864)
Loss: 0.951 | Acc: 76.485% (14734/19264)
Loss: 0.959 | Acc: 76.255% (19570/25664)
Loss: 0.962 | Acc: 76.244% (24447/32064)
Loss: 0.961 | Acc: 76.256% (29331/38464)
Loss: 0.961 | Acc: 76.302% (34232/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1866, Accuracy: 7086/10000 (70.86%)
torch.Size([100, 10])
Test set: Average loss: 1.1866, Accuracy: 7086/10000 (70.86%)

Epoch: 199
Loss: 0.760 | Acc: 79.688% (51/64)
Loss: 0.974 | Acc: 75.944% (4909/6464)
Loss: 0.961 | Acc: 76.112% (9791/12864)
Loss: 0.968 | Acc: 76.007% (14642/19264)
Loss: 0.964 | Acc: 76.126% (19537/25664)
Loss: 0.966 | Acc: 76.151% (24417/32064)
Loss: 0.958 | Acc: 76.349% (29367/38464)
Loss: 0.957 | Acc: 76.438% (34293/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1855, Accuracy: 7102/10000 (71.02%)
torch.Size([100, 10])
Test set: Average loss: 1.1855, Accuracy: 7102/10000 (71.02%)
7413
10000
-1.1100598573684692
