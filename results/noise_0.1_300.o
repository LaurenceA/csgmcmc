==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.358 | Acc: 15.625% (10/64)
Loss: 3.122 | Acc: 14.124% (913/6464)
Loss: 2.625 | Acc: 16.845% (2167/12864)
Loss: 2.445 | Acc: 18.272% (3520/19264)
Loss: 2.340 | Acc: 19.822% (5087/25664)
Loss: 2.270 | Acc: 21.049% (6749/32064)
Loss: 2.221 | Acc: 22.083% (8494/38464)
Loss: 2.176 | Acc: 23.197% (10407/44864)
torch.Size([100, 10])
Test set: Average loss: 15.4859, Accuracy: 1090/10000 (10.90%)

Epoch: 1
Loss: 3.059 | Acc: 20.312% (13/64)
Loss: 1.970 | Acc: 27.785% (1796/6464)
Loss: 1.924 | Acc: 29.882% (3844/12864)
Loss: 1.895 | Acc: 30.845% (5942/19264)
Loss: 1.880 | Acc: 31.647% (8122/25664)
Loss: 1.866 | Acc: 32.351% (10373/32064)
Loss: 1.853 | Acc: 32.870% (12643/38464)
Loss: 1.841 | Acc: 33.530% (15043/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8406, Accuracy: 3502/10000 (35.02%)

Epoch: 2
Loss: 1.478 | Acc: 59.375% (38/64)
Loss: 1.716 | Acc: 39.093% (2527/6464)
Loss: 1.718 | Acc: 39.016% (5019/12864)
Loss: 1.707 | Acc: 39.784% (7664/19264)
Loss: 1.695 | Acc: 40.446% (10380/25664)
Loss: 1.684 | Acc: 41.046% (13161/32064)
Loss: 1.677 | Acc: 41.501% (15963/38464)
Loss: 1.669 | Acc: 41.791% (18749/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6220, Accuracy: 4514/10000 (45.14%)

Epoch: 3
Loss: 1.580 | Acc: 48.438% (31/64)
Loss: 1.565 | Acc: 46.627% (3014/6464)
Loss: 1.568 | Acc: 46.696% (6007/12864)
Loss: 1.546 | Acc: 47.799% (9208/19264)
Loss: 1.527 | Acc: 48.687% (12495/25664)
Loss: 1.510 | Acc: 49.273% (15799/32064)
Loss: 1.493 | Acc: 49.943% (19210/38464)
Loss: 1.480 | Acc: 50.595% (22699/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0556, Accuracy: 3605/10000 (36.05%)

Epoch: 4
Loss: 1.862 | Acc: 42.188% (27/64)
Loss: 1.377 | Acc: 55.538% (3590/6464)
Loss: 1.351 | Acc: 56.242% (7235/12864)
Loss: 1.340 | Acc: 56.790% (10940/19264)
Loss: 1.332 | Acc: 57.240% (14690/25664)
Loss: 1.324 | Acc: 57.591% (18466/32064)
Loss: 1.313 | Acc: 58.046% (22327/38464)
Loss: 1.309 | Acc: 58.316% (26163/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3471, Accuracy: 5748/10000 (57.48%)

Epoch: 5
Loss: 1.478 | Acc: 51.562% (33/64)
Loss: 1.207 | Acc: 61.510% (3976/6464)
Loss: 1.224 | Acc: 61.497% (7911/12864)
Loss: 1.218 | Acc: 61.836% (11912/19264)
Loss: 1.213 | Acc: 62.052% (15925/25664)
Loss: 1.201 | Acc: 62.556% (20058/32064)
Loss: 1.198 | Acc: 62.880% (24186/38464)
Loss: 1.193 | Acc: 63.166% (28339/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7421, Accuracy: 4686/10000 (46.86%)

Epoch: 6
Loss: 1.300 | Acc: 68.750% (44/64)
Loss: 1.143 | Acc: 65.501% (4234/6464)
Loss: 1.139 | Acc: 65.773% (8461/12864)
Loss: 1.128 | Acc: 66.289% (12770/19264)
Loss: 1.124 | Acc: 66.517% (17071/25664)
Loss: 1.114 | Acc: 66.717% (21392/32064)
Loss: 1.114 | Acc: 66.787% (25689/38464)
Loss: 1.112 | Acc: 66.797% (29968/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7809, Accuracy: 4539/10000 (45.39%)

Epoch: 7
Loss: 1.225 | Acc: 57.812% (37/64)
Loss: 1.063 | Acc: 68.425% (4423/6464)
Loss: 1.071 | Acc: 68.680% (8835/12864)
Loss: 1.074 | Acc: 68.864% (13266/19264)
Loss: 1.070 | Acc: 69.054% (17722/25664)
Loss: 1.062 | Acc: 69.224% (22196/32064)
Loss: 1.062 | Acc: 69.273% (26645/38464)
Loss: 1.056 | Acc: 69.274% (31079/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1498, Accuracy: 6612/10000 (66.12%)

Epoch: 8
Loss: 1.048 | Acc: 70.312% (45/64)
Loss: 1.028 | Acc: 69.833% (4514/6464)
Loss: 1.027 | Acc: 70.126% (9021/12864)
Loss: 1.027 | Acc: 70.276% (13538/19264)
Loss: 1.024 | Acc: 70.371% (18060/25664)
Loss: 1.019 | Acc: 70.534% (22616/32064)
Loss: 1.020 | Acc: 70.487% (27112/38464)
Loss: 1.017 | Acc: 70.665% (31703/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1193, Accuracy: 6737/10000 (67.37%)

Epoch: 9
Loss: 1.218 | Acc: 62.500% (40/64)
Loss: 0.982 | Acc: 71.844% (4644/6464)
Loss: 0.994 | Acc: 71.642% (9216/12864)
Loss: 0.994 | Acc: 71.621% (13797/19264)
Loss: 0.988 | Acc: 71.824% (18433/25664)
Loss: 0.992 | Acc: 71.850% (23038/32064)
Loss: 0.989 | Acc: 71.857% (27639/38464)
Loss: 0.985 | Acc: 72.018% (32310/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7877, Accuracy: 4856/10000 (48.56%)

Epoch: 10
Loss: 0.974 | Acc: 71.875% (46/64)
Loss: 0.980 | Acc: 72.123% (4662/6464)
Loss: 0.962 | Acc: 72.862% (9373/12864)
Loss: 0.968 | Acc: 72.680% (14001/19264)
Loss: 0.959 | Acc: 72.997% (18734/25664)
Loss: 0.962 | Acc: 73.094% (23437/32064)
Loss: 0.963 | Acc: 73.032% (28091/38464)
Loss: 0.963 | Acc: 73.043% (32770/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1154, Accuracy: 6823/10000 (68.23%)

Epoch: 11
Loss: 1.148 | Acc: 67.188% (43/64)
Loss: 0.955 | Acc: 73.422% (4746/6464)
Loss: 0.954 | Acc: 73.515% (9457/12864)
Loss: 0.941 | Acc: 73.749% (14207/19264)
Loss: 0.943 | Acc: 73.749% (18927/25664)
Loss: 0.943 | Acc: 73.699% (23631/32064)
Loss: 0.944 | Acc: 73.682% (28341/38464)
Loss: 0.947 | Acc: 73.607% (33023/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0982, Accuracy: 6856/10000 (68.56%)

Epoch: 12
Loss: 0.914 | Acc: 75.000% (48/64)
Loss: 0.921 | Acc: 74.381% (4808/6464)
Loss: 0.924 | Acc: 74.705% (9610/12864)
Loss: 0.924 | Acc: 74.580% (14367/19264)
Loss: 0.924 | Acc: 74.439% (19104/25664)
Loss: 0.924 | Acc: 74.414% (23860/32064)
Loss: 0.924 | Acc: 74.392% (28614/38464)
Loss: 0.928 | Acc: 74.320% (33343/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8677, Accuracy: 4053/10000 (40.53%)

Epoch: 13
Loss: 1.366 | Acc: 57.812% (37/64)
Loss: 0.923 | Acc: 75.000% (4848/6464)
Loss: 0.917 | Acc: 75.194% (9673/12864)
Loss: 0.915 | Acc: 75.171% (14481/19264)
Loss: 0.916 | Acc: 75.082% (19269/25664)
Loss: 0.907 | Acc: 75.327% (24153/32064)
Loss: 0.906 | Acc: 75.322% (28972/38464)
Loss: 0.908 | Acc: 75.301% (33783/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1952, Accuracy: 6520/10000 (65.20%)

Epoch: 14
Loss: 1.137 | Acc: 67.188% (43/64)
Loss: 0.929 | Acc: 73.685% (4763/6464)
Loss: 0.915 | Acc: 74.510% (9585/12864)
Loss: 0.904 | Acc: 74.766% (14403/19264)
Loss: 0.900 | Acc: 75.109% (19276/25664)
Loss: 0.897 | Acc: 75.315% (24149/32064)
Loss: 0.894 | Acc: 75.408% (29005/38464)
Loss: 0.896 | Acc: 75.386% (33821/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4675, Accuracy: 5464/10000 (54.64%)

Epoch: 15
Loss: 1.211 | Acc: 64.062% (41/64)
Loss: 0.860 | Acc: 76.671% (4956/6464)
Loss: 0.872 | Acc: 76.430% (9832/12864)
Loss: 0.884 | Acc: 76.194% (14678/19264)
Loss: 0.879 | Acc: 76.372% (19600/25664)
Loss: 0.879 | Acc: 76.310% (24468/32064)
Loss: 0.880 | Acc: 76.256% (29331/38464)
Loss: 0.878 | Acc: 76.279% (34222/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1746, Accuracy: 6667/10000 (66.67%)

Epoch: 16
Loss: 0.965 | Acc: 67.188% (43/64)
Loss: 0.857 | Acc: 77.073% (4982/6464)
Loss: 0.853 | Acc: 76.959% (9900/12864)
Loss: 0.853 | Acc: 77.087% (14850/19264)
Loss: 0.860 | Acc: 76.827% (19717/25664)
Loss: 0.861 | Acc: 76.881% (24651/32064)
Loss: 0.863 | Acc: 76.796% (29539/38464)
Loss: 0.860 | Acc: 76.812% (34461/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3461, Accuracy: 6057/10000 (60.57%)

Epoch: 17
Loss: 0.896 | Acc: 76.562% (49/64)
Loss: 0.834 | Acc: 78.001% (5042/6464)
Loss: 0.850 | Acc: 77.394% (9956/12864)
Loss: 0.855 | Acc: 77.243% (14880/19264)
Loss: 0.852 | Acc: 77.307% (19840/25664)
Loss: 0.849 | Acc: 77.451% (24834/32064)
Loss: 0.850 | Acc: 77.335% (29746/38464)
Loss: 0.848 | Acc: 77.378% (34715/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4103, Accuracy: 6012/10000 (60.12%)

Epoch: 18
Loss: 0.763 | Acc: 81.250% (52/64)
Loss: 0.810 | Acc: 78.434% (5070/6464)
Loss: 0.816 | Acc: 78.288% (10071/12864)
Loss: 0.826 | Acc: 78.052% (15036/19264)
Loss: 0.831 | Acc: 77.918% (19997/25664)
Loss: 0.831 | Acc: 77.925% (24986/32064)
Loss: 0.833 | Acc: 77.857% (29947/38464)
Loss: 0.834 | Acc: 77.808% (34908/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0429, Accuracy: 7059/10000 (70.59%)

Epoch: 19
Loss: 1.122 | Acc: 70.312% (45/64)
Loss: 0.817 | Acc: 78.403% (5068/6464)
Loss: 0.811 | Acc: 78.708% (10125/12864)
Loss: 0.807 | Acc: 78.841% (15188/19264)
Loss: 0.810 | Acc: 78.639% (20182/25664)
Loss: 0.815 | Acc: 78.512% (25174/32064)
Loss: 0.815 | Acc: 78.473% (30184/38464)
Loss: 0.816 | Acc: 78.475% (35207/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3725, Accuracy: 5934/10000 (59.34%)

Epoch: 20
Loss: 0.815 | Acc: 79.688% (51/64)
Loss: 0.797 | Acc: 79.177% (5118/6464)
Loss: 0.801 | Acc: 79.097% (10175/12864)
Loss: 0.801 | Acc: 79.059% (15230/19264)
Loss: 0.801 | Acc: 79.068% (20292/25664)
Loss: 0.799 | Acc: 79.089% (25359/32064)
Loss: 0.802 | Acc: 79.051% (30406/38464)
Loss: 0.804 | Acc: 78.985% (35436/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6441, Accuracy: 5369/10000 (53.69%)

Epoch: 21
Loss: 0.914 | Acc: 73.438% (47/64)
Loss: 0.783 | Acc: 79.486% (5138/6464)
Loss: 0.794 | Acc: 78.887% (10148/12864)
Loss: 0.788 | Acc: 79.288% (15274/19264)
Loss: 0.795 | Acc: 79.080% (20295/25664)
Loss: 0.794 | Acc: 79.282% (25421/32064)
Loss: 0.793 | Acc: 79.417% (30547/38464)
Loss: 0.793 | Acc: 79.407% (35625/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1013, Accuracy: 6993/10000 (69.93%)

Epoch: 22
Loss: 0.712 | Acc: 81.250% (52/64)
Loss: 0.784 | Acc: 79.904% (5165/6464)
Loss: 0.792 | Acc: 79.501% (10227/12864)
Loss: 0.784 | Acc: 79.765% (15366/19264)
Loss: 0.790 | Acc: 79.532% (20411/25664)
Loss: 0.781 | Acc: 79.772% (25578/32064)
Loss: 0.779 | Acc: 79.882% (30726/38464)
Loss: 0.778 | Acc: 79.888% (35841/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3209, Accuracy: 6209/10000 (62.09%)

Epoch: 23
Loss: 0.872 | Acc: 79.688% (51/64)
Loss: 0.740 | Acc: 81.142% (5245/6464)
Loss: 0.763 | Acc: 80.550% (10362/12864)
Loss: 0.770 | Acc: 80.404% (15489/19264)
Loss: 0.766 | Acc: 80.393% (20632/25664)
Loss: 0.768 | Acc: 80.211% (25719/32064)
Loss: 0.767 | Acc: 80.244% (30865/38464)
Loss: 0.766 | Acc: 80.318% (36034/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1438, Accuracy: 6701/10000 (67.01%)

Epoch: 24
Loss: 0.846 | Acc: 78.125% (50/64)
Loss: 0.753 | Acc: 80.755% (5220/6464)
Loss: 0.763 | Acc: 80.434% (10347/12864)
Loss: 0.761 | Acc: 80.502% (15508/19264)
Loss: 0.762 | Acc: 80.514% (20663/25664)
Loss: 0.760 | Acc: 80.514% (25816/32064)
Loss: 0.758 | Acc: 80.579% (30994/38464)
Loss: 0.759 | Acc: 80.572% (36148/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0083, Accuracy: 7282/10000 (72.82%)

Epoch: 25
Loss: 0.852 | Acc: 75.000% (48/64)
Loss: 0.738 | Acc: 81.374% (5260/6464)
Loss: 0.749 | Acc: 81.133% (10437/12864)
Loss: 0.742 | Acc: 81.271% (15656/19264)
Loss: 0.740 | Acc: 81.312% (20868/25664)
Loss: 0.740 | Acc: 81.231% (26046/32064)
Loss: 0.742 | Acc: 81.247% (31251/38464)
Loss: 0.742 | Acc: 81.190% (36425/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5293, Accuracy: 5503/10000 (55.03%)

Epoch: 26
Loss: 0.590 | Acc: 87.500% (56/64)
Loss: 0.739 | Acc: 80.894% (5229/6464)
Loss: 0.736 | Acc: 81.234% (10450/12864)
Loss: 0.728 | Acc: 81.380% (15677/19264)
Loss: 0.737 | Acc: 81.149% (20826/25664)
Loss: 0.736 | Acc: 81.228% (26045/32064)
Loss: 0.731 | Acc: 81.458% (31332/38464)
Loss: 0.729 | Acc: 81.542% (36583/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0038, Accuracy: 7330/10000 (73.30%)

Epoch: 27
Loss: 0.702 | Acc: 76.562% (49/64)
Loss: 0.739 | Acc: 81.559% (5272/6464)
Loss: 0.715 | Acc: 82.066% (10557/12864)
Loss: 0.713 | Acc: 82.117% (15819/19264)
Loss: 0.715 | Acc: 82.088% (21067/25664)
Loss: 0.710 | Acc: 82.273% (26380/32064)
Loss: 0.711 | Acc: 82.298% (31655/38464)
Loss: 0.714 | Acc: 82.235% (36894/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0373, Accuracy: 7219/10000 (72.19%)

Epoch: 28
Loss: 0.947 | Acc: 73.438% (47/64)
Loss: 0.690 | Acc: 82.642% (5342/6464)
Loss: 0.707 | Acc: 82.214% (10576/12864)
Loss: 0.694 | Acc: 82.646% (15921/19264)
Loss: 0.698 | Acc: 82.567% (21190/25664)
Loss: 0.694 | Acc: 82.775% (26541/32064)
Loss: 0.700 | Acc: 82.651% (31791/38464)
Loss: 0.700 | Acc: 82.739% (37120/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1952, Accuracy: 6523/10000 (65.23%)

Epoch: 29
Loss: 0.644 | Acc: 87.500% (56/64)
Loss: 0.659 | Acc: 83.756% (5414/6464)
Loss: 0.670 | Acc: 83.660% (10762/12864)
Loss: 0.670 | Acc: 83.679% (16120/19264)
Loss: 0.680 | Acc: 83.467% (21421/25664)
Loss: 0.679 | Acc: 83.455% (26759/32064)
Loss: 0.681 | Acc: 83.358% (32063/38464)
Loss: 0.681 | Acc: 83.334% (37387/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9133, Accuracy: 7564/10000 (75.64%)

Epoch: 30
Loss: 1.008 | Acc: 75.000% (48/64)
Loss: 0.651 | Acc: 84.375% (5454/6464)
Loss: 0.668 | Acc: 83.722% (10770/12864)
Loss: 0.664 | Acc: 83.944% (16171/19264)
Loss: 0.661 | Acc: 83.974% (21551/25664)
Loss: 0.668 | Acc: 83.801% (26870/32064)
Loss: 0.669 | Acc: 83.751% (32214/38464)
Loss: 0.672 | Acc: 83.691% (37547/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9177, Accuracy: 7603/10000 (76.03%)

Epoch: 31
Loss: 0.439 | Acc: 85.938% (55/64)
Loss: 0.620 | Acc: 85.210% (5508/6464)
Loss: 0.641 | Acc: 84.701% (10896/12864)
Loss: 0.653 | Acc: 84.437% (16266/19264)
Loss: 0.653 | Acc: 84.278% (21629/25664)
Loss: 0.655 | Acc: 84.166% (26987/32064)
Loss: 0.653 | Acc: 84.258% (32409/38464)
Loss: 0.656 | Acc: 84.177% (37765/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8162, Accuracy: 7953/10000 (79.53%)

Epoch: 32
Loss: 0.751 | Acc: 82.812% (53/64)
Loss: 0.642 | Acc: 84.468% (5460/6464)
Loss: 0.640 | Acc: 84.717% (10898/12864)
Loss: 0.638 | Acc: 84.697% (16316/19264)
Loss: 0.633 | Acc: 84.788% (21760/25664)
Loss: 0.633 | Acc: 84.812% (27194/32064)
Loss: 0.635 | Acc: 84.814% (32623/38464)
Loss: 0.635 | Acc: 84.832% (38059/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8635, Accuracy: 7802/10000 (78.02%)

Epoch: 33
Loss: 0.535 | Acc: 85.938% (55/64)
Loss: 0.581 | Acc: 86.231% (5574/6464)
Loss: 0.605 | Acc: 85.689% (11023/12864)
Loss: 0.605 | Acc: 85.621% (16494/19264)
Loss: 0.611 | Acc: 85.326% (21898/25664)
Loss: 0.607 | Acc: 85.445% (27397/32064)
Loss: 0.613 | Acc: 85.285% (32804/38464)
Loss: 0.615 | Acc: 85.262% (38252/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8627, Accuracy: 7844/10000 (78.44%)

Epoch: 34
Loss: 0.668 | Acc: 87.500% (56/64)
Loss: 0.585 | Acc: 85.876% (5551/6464)
Loss: 0.586 | Acc: 85.914% (11052/12864)
Loss: 0.587 | Acc: 85.917% (16551/19264)
Loss: 0.593 | Acc: 85.766% (22011/25664)
Loss: 0.597 | Acc: 85.785% (27506/32064)
Loss: 0.596 | Acc: 85.888% (33036/38464)
Loss: 0.600 | Acc: 85.741% (38467/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8035, Accuracy: 8071/10000 (80.71%)

Epoch: 35
Loss: 0.508 | Acc: 89.062% (57/64)
Loss: 0.546 | Acc: 86.835% (5613/6464)
Loss: 0.568 | Acc: 86.357% (11109/12864)
Loss: 0.572 | Acc: 86.534% (16670/19264)
Loss: 0.568 | Acc: 86.627% (22232/25664)
Loss: 0.570 | Acc: 86.621% (27774/32064)
Loss: 0.575 | Acc: 86.517% (33278/38464)
Loss: 0.577 | Acc: 86.426% (38774/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8195, Accuracy: 8006/10000 (80.06%)

Epoch: 36
Loss: 0.546 | Acc: 89.062% (57/64)
Loss: 0.538 | Acc: 87.794% (5675/6464)
Loss: 0.554 | Acc: 87.259% (11225/12864)
Loss: 0.552 | Acc: 87.121% (16783/19264)
Loss: 0.555 | Acc: 87.009% (22330/25664)
Loss: 0.557 | Acc: 86.967% (27885/32064)
Loss: 0.558 | Acc: 86.941% (33441/38464)
Loss: 0.560 | Acc: 86.929% (39000/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7796, Accuracy: 8165/10000 (81.65%)

Epoch: 37
Loss: 0.584 | Acc: 84.375% (54/64)
Loss: 0.520 | Acc: 88.289% (5707/6464)
Loss: 0.521 | Acc: 88.161% (11341/12864)
Loss: 0.520 | Acc: 88.024% (16957/19264)
Loss: 0.515 | Acc: 88.092% (22608/25664)
Loss: 0.525 | Acc: 87.796% (28151/32064)
Loss: 0.529 | Acc: 87.692% (33730/38464)
Loss: 0.536 | Acc: 87.525% (39267/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8439, Accuracy: 7972/10000 (79.72%)

Epoch: 38
Loss: 0.719 | Acc: 85.938% (55/64)
Loss: 0.515 | Acc: 87.871% (5680/6464)
Loss: 0.510 | Acc: 88.021% (11323/12864)
Loss: 0.506 | Acc: 88.190% (16989/19264)
Loss: 0.505 | Acc: 88.240% (22646/25664)
Loss: 0.508 | Acc: 88.195% (28279/32064)
Loss: 0.510 | Acc: 88.064% (33873/38464)
Loss: 0.509 | Acc: 88.169% (39556/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8126, Accuracy: 8075/10000 (80.75%)

Epoch: 39
Loss: 0.396 | Acc: 90.625% (58/64)
Loss: 0.465 | Acc: 89.171% (5764/6464)
Loss: 0.463 | Acc: 89.187% (11473/12864)
Loss: 0.467 | Acc: 89.161% (17176/19264)
Loss: 0.469 | Acc: 89.051% (22854/25664)
Loss: 0.476 | Acc: 88.888% (28501/32064)
Loss: 0.476 | Acc: 88.925% (34204/38464)
Loss: 0.481 | Acc: 88.813% (39845/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8278, Accuracy: 8059/10000 (80.59%)

Epoch: 40
Loss: 0.371 | Acc: 93.750% (60/64)
Loss: 0.454 | Acc: 89.217% (5767/6464)
Loss: 0.444 | Acc: 89.467% (11509/12864)
Loss: 0.449 | Acc: 89.493% (17240/19264)
Loss: 0.456 | Acc: 89.401% (22944/25664)
Loss: 0.452 | Acc: 89.455% (28683/32064)
Loss: 0.451 | Acc: 89.447% (34405/38464)
Loss: 0.454 | Acc: 89.346% (40084/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8300, Accuracy: 8113/10000 (81.13%)

Epoch: 41
Loss: 0.594 | Acc: 82.812% (53/64)
Loss: 0.402 | Acc: 90.161% (5828/6464)
Loss: 0.429 | Acc: 89.646% (11532/12864)
Loss: 0.421 | Acc: 89.992% (17336/19264)
Loss: 0.419 | Acc: 90.095% (23122/25664)
Loss: 0.417 | Acc: 90.160% (28909/32064)
Loss: 0.418 | Acc: 90.095% (34654/38464)
Loss: 0.419 | Acc: 90.097% (40421/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8530, Accuracy: 8145/10000 (81.45%)

Epoch: 42
Loss: 0.380 | Acc: 90.625% (58/64)
Loss: 0.371 | Acc: 91.414% (5909/6464)
Loss: 0.381 | Acc: 90.905% (11694/12864)
Loss: 0.381 | Acc: 90.921% (17515/19264)
Loss: 0.385 | Acc: 90.843% (23314/25664)
Loss: 0.387 | Acc: 90.762% (29102/32064)
Loss: 0.388 | Acc: 90.817% (34932/38464)
Loss: 0.386 | Acc: 90.852% (40760/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8662, Accuracy: 8142/10000 (81.42%)

Epoch: 43
Loss: 0.301 | Acc: 90.625% (58/64)
Loss: 0.349 | Acc: 91.259% (5899/6464)
Loss: 0.351 | Acc: 91.247% (11738/12864)
Loss: 0.349 | Acc: 91.409% (17609/19264)
Loss: 0.346 | Acc: 91.517% (23487/25664)
Loss: 0.347 | Acc: 91.467% (29328/32064)
Loss: 0.350 | Acc: 91.405% (35158/38464)
Loss: 0.350 | Acc: 91.441% (41024/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8649, Accuracy: 8196/10000 (81.96%)

Epoch: 44
Loss: 0.249 | Acc: 95.312% (61/64)
Loss: 0.298 | Acc: 92.729% (5994/6464)
Loss: 0.314 | Acc: 92.211% (11862/12864)
Loss: 0.310 | Acc: 92.307% (17782/19264)
Loss: 0.314 | Acc: 92.188% (23659/25664)
Loss: 0.317 | Acc: 92.094% (29529/32064)
Loss: 0.314 | Acc: 92.185% (35458/38464)
Loss: 0.312 | Acc: 92.239% (41382/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8883, Accuracy: 8236/10000 (82.36%)

Epoch: 45
Loss: 0.487 | Acc: 89.062% (57/64)
Loss: 0.275 | Acc: 93.023% (6013/6464)
Loss: 0.284 | Acc: 92.763% (11933/12864)
Loss: 0.280 | Acc: 92.831% (17883/19264)
Loss: 0.284 | Acc: 92.647% (23777/25664)
Loss: 0.284 | Acc: 92.740% (29736/32064)
Loss: 0.282 | Acc: 92.804% (35696/38464)
Loss: 0.281 | Acc: 92.870% (41665/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9026, Accuracy: 8188/10000 (81.88%)

Epoch: 46
Loss: 0.172 | Acc: 95.312% (61/64)
Loss: 0.275 | Acc: 93.023% (6013/6464)
Loss: 0.273 | Acc: 93.097% (11976/12864)
Loss: 0.266 | Acc: 93.298% (17973/19264)
Loss: 0.261 | Acc: 93.423% (23976/25664)
Loss: 0.258 | Acc: 93.476% (29972/32064)
Loss: 0.257 | Acc: 93.524% (35973/38464)
Loss: 0.255 | Acc: 93.574% (41981/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8976, Accuracy: 8198/10000 (81.98%)

Epoch: 47
Loss: 0.107 | Acc: 98.438% (63/64)
Loss: 0.238 | Acc: 93.673% (6055/6464)
Loss: 0.235 | Acc: 93.890% (12078/12864)
Loss: 0.237 | Acc: 93.916% (18092/19264)
Loss: 0.234 | Acc: 93.929% (24106/25664)
Loss: 0.239 | Acc: 93.831% (30086/32064)
Loss: 0.237 | Acc: 93.906% (36120/38464)
Loss: 0.235 | Acc: 93.955% (42152/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9118, Accuracy: 8193/10000 (81.93%)
torch.Size([100, 10])
Test set: Average loss: 0.9118, Accuracy: 8193/10000 (81.93%)

Epoch: 48
Loss: 0.360 | Acc: 92.188% (59/64)
Loss: 0.223 | Acc: 94.369% (6100/6464)
Loss: 0.217 | Acc: 94.364% (12139/12864)
Loss: 0.222 | Acc: 94.222% (18151/19264)
Loss: 0.223 | Acc: 94.179% (24170/25664)
Loss: 0.222 | Acc: 94.202% (30205/32064)
Loss: 0.225 | Acc: 94.104% (36196/38464)
Loss: 0.224 | Acc: 94.129% (42230/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9132, Accuracy: 8179/10000 (81.79%)
torch.Size([100, 10])
Test set: Average loss: 0.9132, Accuracy: 8179/10000 (81.79%)

Epoch: 49
Loss: 0.253 | Acc: 93.750% (60/64)
Loss: 0.225 | Acc: 93.936% (6072/6464)
Loss: 0.229 | Acc: 93.921% (12082/12864)
Loss: 0.226 | Acc: 94.051% (18118/19264)
Loss: 0.225 | Acc: 94.046% (24136/25664)
Loss: 0.224 | Acc: 94.112% (30176/32064)
Loss: 0.224 | Acc: 94.085% (36189/38464)
Loss: 0.223 | Acc: 94.107% (42220/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9140, Accuracy: 8186/10000 (81.86%)
torch.Size([100, 10])
Test set: Average loss: 0.9140, Accuracy: 8186/10000 (81.86%)

Epoch: 50
Loss: 0.189 | Acc: 96.875% (62/64)
Loss: 1.383 | Acc: 56.405% (3646/6464)
Loss: 1.203 | Acc: 63.386% (8154/12864)
Loss: 1.119 | Acc: 66.580% (12826/19264)
Loss: 1.084 | Acc: 68.103% (17478/25664)
Loss: 1.055 | Acc: 69.399% (22252/32064)
Loss: 1.032 | Acc: 70.232% (27014/38464)
Loss: 1.015 | Acc: 70.943% (31828/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0972, Accuracy: 4266/10000 (42.66%)

Epoch: 51
Loss: 1.048 | Acc: 68.750% (44/64)
Loss: 0.888 | Acc: 75.603% (4887/6464)
Loss: 0.882 | Acc: 76.306% (9816/12864)
Loss: 0.881 | Acc: 76.225% (14684/19264)
Loss: 0.879 | Acc: 76.231% (19564/25664)
Loss: 0.877 | Acc: 76.304% (24466/32064)
Loss: 0.870 | Acc: 76.435% (29400/38464)
Loss: 0.868 | Acc: 76.569% (34352/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2034, Accuracy: 6674/10000 (66.74%)

Epoch: 52
Loss: 0.907 | Acc: 71.875% (46/64)
Loss: 0.845 | Acc: 77.382% (5002/6464)
Loss: 0.838 | Acc: 77.565% (9978/12864)
Loss: 0.830 | Acc: 77.803% (14988/19264)
Loss: 0.832 | Acc: 77.728% (19948/25664)
Loss: 0.831 | Acc: 77.838% (24958/32064)
Loss: 0.832 | Acc: 77.821% (29933/38464)
Loss: 0.837 | Acc: 77.710% (34864/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9508, Accuracy: 7414/10000 (74.14%)

Epoch: 53
Loss: 1.187 | Acc: 67.188% (43/64)
Loss: 0.806 | Acc: 78.434% (5070/6464)
Loss: 0.819 | Acc: 78.242% (10065/12864)
Loss: 0.827 | Acc: 78.161% (15057/19264)
Loss: 0.826 | Acc: 78.156% (20058/25664)
Loss: 0.830 | Acc: 78.060% (25029/32064)
Loss: 0.826 | Acc: 78.237% (30093/38464)
Loss: 0.828 | Acc: 78.150% (35061/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0205, Accuracy: 4606/10000 (46.06%)

Epoch: 54
Loss: 0.822 | Acc: 76.562% (49/64)
Loss: 0.774 | Acc: 79.749% (5155/6464)
Loss: 0.813 | Acc: 78.762% (10132/12864)
Loss: 0.810 | Acc: 78.769% (15174/19264)
Loss: 0.817 | Acc: 78.526% (20153/25664)
Loss: 0.820 | Acc: 78.331% (25116/32064)
Loss: 0.822 | Acc: 78.208% (30082/38464)
Loss: 0.823 | Acc: 78.290% (35124/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3540, Accuracy: 6199/10000 (61.99%)

Epoch: 55
Loss: 0.951 | Acc: 73.438% (47/64)
Loss: 0.808 | Acc: 78.589% (5080/6464)
Loss: 0.806 | Acc: 78.910% (10151/12864)
Loss: 0.812 | Acc: 78.779% (15176/19264)
Loss: 0.814 | Acc: 78.628% (20179/25664)
Loss: 0.812 | Acc: 78.693% (25232/32064)
Loss: 0.815 | Acc: 78.580% (30225/38464)
Loss: 0.817 | Acc: 78.535% (35234/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2181, Accuracy: 6593/10000 (65.93%)

Epoch: 56
Loss: 1.116 | Acc: 71.875% (46/64)
Loss: 0.809 | Acc: 78.976% (5105/6464)
Loss: 0.812 | Acc: 78.786% (10135/12864)
Loss: 0.803 | Acc: 79.007% (15220/19264)
Loss: 0.802 | Acc: 79.017% (20279/25664)
Loss: 0.805 | Acc: 78.992% (25328/32064)
Loss: 0.809 | Acc: 78.913% (30353/38464)
Loss: 0.810 | Acc: 78.816% (35360/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1512, Accuracy: 6835/10000 (68.35%)

Epoch: 57
Loss: 0.981 | Acc: 78.125% (50/64)
Loss: 0.803 | Acc: 78.481% (5073/6464)
Loss: 0.802 | Acc: 78.887% (10148/12864)
Loss: 0.799 | Acc: 79.091% (15236/19264)
Loss: 0.810 | Acc: 78.815% (20227/25664)
Loss: 0.810 | Acc: 78.867% (25288/32064)
Loss: 0.814 | Acc: 78.775% (30300/38464)
Loss: 0.808 | Acc: 78.945% (35418/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2930, Accuracy: 6238/10000 (62.38%)

Epoch: 58
Loss: 0.909 | Acc: 76.562% (49/64)
Loss: 0.804 | Acc: 78.899% (5100/6464)
Loss: 0.809 | Acc: 78.863% (10145/12864)
Loss: 0.802 | Acc: 79.111% (15240/19264)
Loss: 0.806 | Acc: 79.033% (20283/25664)
Loss: 0.806 | Acc: 78.958% (25317/32064)
Loss: 0.807 | Acc: 78.915% (30354/38464)
Loss: 0.806 | Acc: 78.974% (35431/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4868, Accuracy: 5881/10000 (58.81%)

Epoch: 59
Loss: 0.714 | Acc: 79.688% (51/64)
Loss: 0.815 | Acc: 78.883% (5099/6464)
Loss: 0.802 | Acc: 79.120% (10178/12864)
Loss: 0.801 | Acc: 79.075% (15233/19264)
Loss: 0.802 | Acc: 78.990% (20272/25664)
Loss: 0.801 | Acc: 79.023% (25338/32064)
Loss: 0.800 | Acc: 79.113% (30430/38464)
Loss: 0.803 | Acc: 79.070% (35474/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0180, Accuracy: 7078/10000 (70.78%)

Epoch: 60
Loss: 0.862 | Acc: 76.562% (49/64)
Loss: 0.797 | Acc: 79.332% (5128/6464)
Loss: 0.779 | Acc: 79.719% (10255/12864)
Loss: 0.799 | Acc: 79.085% (15235/19264)
Loss: 0.799 | Acc: 79.200% (20326/25664)
Loss: 0.794 | Acc: 79.444% (25473/32064)
Loss: 0.795 | Acc: 79.363% (30526/38464)
Loss: 0.794 | Acc: 79.362% (35605/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9862, Accuracy: 7380/10000 (73.80%)

Epoch: 61
Loss: 0.934 | Acc: 75.000% (48/64)
Loss: 0.768 | Acc: 80.399% (5197/6464)
Loss: 0.767 | Acc: 80.340% (10335/12864)
Loss: 0.775 | Acc: 80.004% (15412/19264)
Loss: 0.782 | Acc: 79.765% (20471/25664)
Loss: 0.786 | Acc: 79.672% (25546/32064)
Loss: 0.788 | Acc: 79.674% (30646/38464)
Loss: 0.788 | Acc: 79.694% (35754/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0638, Accuracy: 7025/10000 (70.25%)

Epoch: 62
Loss: 0.855 | Acc: 79.688% (51/64)
Loss: 0.788 | Acc: 79.718% (5153/6464)
Loss: 0.774 | Acc: 80.278% (10327/12864)
Loss: 0.781 | Acc: 80.103% (15431/19264)
Loss: 0.782 | Acc: 80.030% (20539/25664)
Loss: 0.782 | Acc: 79.931% (25629/32064)
Loss: 0.783 | Acc: 79.856% (30716/38464)
Loss: 0.786 | Acc: 79.768% (35787/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9839, Accuracy: 7346/10000 (73.46%)

Epoch: 63
Loss: 0.471 | Acc: 87.500% (56/64)
Loss: 0.764 | Acc: 80.507% (5204/6464)
Loss: 0.770 | Acc: 80.302% (10330/12864)
Loss: 0.770 | Acc: 80.191% (15448/19264)
Loss: 0.772 | Acc: 80.112% (20560/25664)
Loss: 0.769 | Acc: 80.264% (25736/32064)
Loss: 0.774 | Acc: 80.163% (30834/38464)
Loss: 0.775 | Acc: 80.185% (35974/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1632, Accuracy: 6793/10000 (67.93%)

Epoch: 64
Loss: 0.947 | Acc: 78.125% (50/64)
Loss: 0.782 | Acc: 79.827% (5160/6464)
Loss: 0.771 | Acc: 80.185% (10315/12864)
Loss: 0.764 | Acc: 80.368% (15482/19264)
Loss: 0.770 | Acc: 80.163% (20573/25664)
Loss: 0.769 | Acc: 80.289% (25744/32064)
Loss: 0.771 | Acc: 80.275% (30877/38464)
Loss: 0.774 | Acc: 80.182% (35973/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2910, Accuracy: 6198/10000 (61.98%)

Epoch: 65
Loss: 0.773 | Acc: 81.250% (52/64)
Loss: 0.746 | Acc: 81.111% (5243/6464)
Loss: 0.755 | Acc: 80.737% (10386/12864)
Loss: 0.761 | Acc: 80.534% (15514/19264)
Loss: 0.759 | Acc: 80.564% (20676/25664)
Loss: 0.765 | Acc: 80.420% (25786/32064)
Loss: 0.764 | Acc: 80.449% (30944/38464)
Loss: 0.764 | Acc: 80.499% (36115/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2099, Accuracy: 6528/10000 (65.28%)

Epoch: 66
Loss: 0.670 | Acc: 81.250% (52/64)
Loss: 0.732 | Acc: 81.111% (5243/6464)
Loss: 0.752 | Acc: 80.488% (10354/12864)
Loss: 0.756 | Acc: 80.414% (15491/19264)
Loss: 0.761 | Acc: 80.272% (20601/25664)
Loss: 0.756 | Acc: 80.492% (25809/32064)
Loss: 0.758 | Acc: 80.491% (30960/38464)
Loss: 0.755 | Acc: 80.586% (36154/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5357, Accuracy: 5629/10000 (56.29%)

Epoch: 67
Loss: 0.914 | Acc: 76.562% (49/64)
Loss: 0.753 | Acc: 81.064% (5240/6464)
Loss: 0.739 | Acc: 81.390% (10470/12864)
Loss: 0.731 | Acc: 81.733% (15745/19264)
Loss: 0.738 | Acc: 81.577% (20936/25664)
Loss: 0.740 | Acc: 81.515% (26137/32064)
Loss: 0.745 | Acc: 81.315% (31277/38464)
Loss: 0.750 | Acc: 81.161% (36412/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1470, Accuracy: 6760/10000 (67.60%)

Epoch: 68
Loss: 0.637 | Acc: 82.812% (53/64)
Loss: 0.736 | Acc: 81.033% (5238/6464)
Loss: 0.728 | Acc: 81.413% (10473/12864)
Loss: 0.739 | Acc: 81.260% (15654/19264)
Loss: 0.743 | Acc: 81.285% (20861/25664)
Loss: 0.742 | Acc: 81.325% (26076/32064)
Loss: 0.744 | Acc: 81.268% (31259/38464)
Loss: 0.740 | Acc: 81.270% (36461/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9954, Accuracy: 7340/10000 (73.40%)

Epoch: 69
Loss: 0.847 | Acc: 76.562% (49/64)
Loss: 0.699 | Acc: 82.225% (5315/6464)
Loss: 0.709 | Acc: 82.035% (10553/12864)
Loss: 0.726 | Acc: 81.634% (15726/19264)
Loss: 0.732 | Acc: 81.562% (20932/25664)
Loss: 0.735 | Acc: 81.599% (26164/32064)
Loss: 0.732 | Acc: 81.666% (31412/38464)
Loss: 0.733 | Acc: 81.680% (36645/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1357, Accuracy: 6799/10000 (67.99%)

Epoch: 70
Loss: 0.767 | Acc: 81.250% (52/64)
Loss: 0.717 | Acc: 82.039% (5303/6464)
Loss: 0.710 | Acc: 82.338% (10592/12864)
Loss: 0.710 | Acc: 82.382% (15870/19264)
Loss: 0.710 | Acc: 82.524% (21179/25664)
Loss: 0.714 | Acc: 82.416% (26426/32064)
Loss: 0.720 | Acc: 82.142% (31595/38464)
Loss: 0.725 | Acc: 81.972% (36776/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9566, Accuracy: 7425/10000 (74.25%)

Epoch: 71
Loss: 0.805 | Acc: 76.562% (49/64)
Loss: 0.699 | Acc: 82.751% (5349/6464)
Loss: 0.703 | Acc: 82.470% (10609/12864)
Loss: 0.707 | Acc: 82.345% (15863/19264)
Loss: 0.716 | Acc: 82.111% (21073/25664)
Loss: 0.719 | Acc: 82.095% (26323/32064)
Loss: 0.719 | Acc: 82.035% (31554/38464)
Loss: 0.716 | Acc: 82.117% (36841/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3862, Accuracy: 5992/10000 (59.92%)

Epoch: 72
Loss: 0.893 | Acc: 78.125% (50/64)
Loss: 0.707 | Acc: 82.287% (5319/6464)
Loss: 0.710 | Acc: 82.432% (10604/12864)
Loss: 0.716 | Acc: 82.174% (15830/19264)
Loss: 0.708 | Acc: 82.349% (21134/25664)
Loss: 0.709 | Acc: 82.373% (26412/32064)
Loss: 0.706 | Acc: 82.446% (31712/38464)
Loss: 0.709 | Acc: 82.349% (36945/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0737, Accuracy: 7070/10000 (70.70%)

Epoch: 73
Loss: 0.603 | Acc: 84.375% (54/64)
Loss: 0.671 | Acc: 83.137% (5374/6464)
Loss: 0.690 | Acc: 82.719% (10641/12864)
Loss: 0.699 | Acc: 82.600% (15912/19264)
Loss: 0.700 | Acc: 82.676% (21218/25664)
Loss: 0.703 | Acc: 82.628% (26494/32064)
Loss: 0.698 | Acc: 82.742% (31826/38464)
Loss: 0.701 | Acc: 82.679% (37093/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0247, Accuracy: 7069/10000 (70.69%)

Epoch: 74
Loss: 0.816 | Acc: 79.688% (51/64)
Loss: 0.658 | Acc: 84.019% (5431/6464)
Loss: 0.674 | Acc: 83.473% (10738/12864)
Loss: 0.685 | Acc: 83.145% (16017/19264)
Loss: 0.684 | Acc: 83.222% (21358/25664)
Loss: 0.682 | Acc: 83.343% (26723/32064)
Loss: 0.688 | Acc: 83.202% (32003/38464)
Loss: 0.687 | Acc: 83.234% (37342/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8700, Accuracy: 7696/10000 (76.96%)

Epoch: 75
Loss: 0.484 | Acc: 82.812% (53/64)
Loss: 0.641 | Acc: 84.530% (5464/6464)
Loss: 0.652 | Acc: 84.181% (10829/12864)
Loss: 0.660 | Acc: 83.949% (16172/19264)
Loss: 0.662 | Acc: 83.865% (21523/25664)
Loss: 0.666 | Acc: 83.714% (26842/32064)
Loss: 0.671 | Acc: 83.647% (32174/38464)
Loss: 0.675 | Acc: 83.535% (37477/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9666, Accuracy: 7426/10000 (74.26%)

Epoch: 76
Loss: 0.629 | Acc: 84.375% (54/64)
Loss: 0.654 | Acc: 84.561% (5466/6464)
Loss: 0.647 | Acc: 84.538% (10875/12864)
Loss: 0.662 | Acc: 84.089% (16199/19264)
Loss: 0.664 | Acc: 84.028% (21565/25664)
Loss: 0.671 | Acc: 83.848% (26885/32064)
Loss: 0.670 | Acc: 83.839% (32248/38464)
Loss: 0.669 | Acc: 83.833% (37611/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8538, Accuracy: 7840/10000 (78.40%)

Epoch: 77
Loss: 0.784 | Acc: 82.812% (53/64)
Loss: 0.646 | Acc: 84.514% (5463/6464)
Loss: 0.656 | Acc: 84.072% (10815/12864)
Loss: 0.657 | Acc: 84.022% (16186/19264)
Loss: 0.660 | Acc: 83.997% (21557/25664)
Loss: 0.660 | Acc: 84.063% (26954/32064)
Loss: 0.657 | Acc: 84.188% (32382/38464)
Loss: 0.651 | Acc: 84.344% (37840/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9088, Accuracy: 7631/10000 (76.31%)

Epoch: 78
Loss: 0.599 | Acc: 84.375% (54/64)
Loss: 0.621 | Acc: 85.412% (5521/6464)
Loss: 0.629 | Acc: 85.090% (10946/12864)
Loss: 0.635 | Acc: 85.019% (16378/19264)
Loss: 0.642 | Acc: 84.702% (21738/25664)
Loss: 0.646 | Acc: 84.556% (27112/32064)
Loss: 0.642 | Acc: 84.612% (32545/38464)
Loss: 0.642 | Acc: 84.607% (37958/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1906, Accuracy: 6745/10000 (67.45%)

Epoch: 79
Loss: 0.503 | Acc: 90.625% (58/64)
Loss: 0.608 | Acc: 85.783% (5545/6464)
Loss: 0.605 | Acc: 85.759% (11032/12864)
Loss: 0.606 | Acc: 85.657% (16501/19264)
Loss: 0.616 | Acc: 85.435% (21926/25664)
Loss: 0.619 | Acc: 85.329% (27360/32064)
Loss: 0.619 | Acc: 85.345% (32827/38464)
Loss: 0.620 | Acc: 85.296% (38267/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0883, Accuracy: 6990/10000 (69.90%)

Epoch: 80
Loss: 0.932 | Acc: 79.688% (51/64)
Loss: 0.651 | Acc: 84.205% (5443/6464)
Loss: 0.622 | Acc: 84.974% (10931/12864)
Loss: 0.613 | Acc: 85.361% (16444/19264)
Loss: 0.608 | Acc: 85.513% (21946/25664)
Loss: 0.612 | Acc: 85.473% (27406/32064)
Loss: 0.614 | Acc: 85.394% (32846/38464)
Loss: 0.615 | Acc: 85.365% (38298/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8976, Accuracy: 7615/10000 (76.15%)

Epoch: 81
Loss: 0.459 | Acc: 87.500% (56/64)
Loss: 0.584 | Acc: 86.139% (5568/6464)
Loss: 0.605 | Acc: 85.673% (11021/12864)
Loss: 0.597 | Acc: 85.917% (16551/19264)
Loss: 0.596 | Acc: 85.973% (22064/25664)
Loss: 0.594 | Acc: 86.040% (27588/32064)
Loss: 0.594 | Acc: 86.049% (33098/38464)
Loss: 0.597 | Acc: 85.975% (38572/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8632, Accuracy: 7807/10000 (78.07%)

Epoch: 82
Loss: 0.417 | Acc: 90.625% (58/64)
Loss: 0.591 | Acc: 85.968% (5557/6464)
Loss: 0.576 | Acc: 86.606% (11141/12864)
Loss: 0.569 | Acc: 86.737% (16709/19264)
Loss: 0.571 | Acc: 86.767% (22268/25664)
Loss: 0.576 | Acc: 86.552% (27752/32064)
Loss: 0.581 | Acc: 86.400% (33233/38464)
Loss: 0.580 | Acc: 86.461% (38790/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8372, Accuracy: 7980/10000 (79.80%)

Epoch: 83
Loss: 0.578 | Acc: 87.500% (56/64)
Loss: 0.549 | Acc: 87.051% (5627/6464)
Loss: 0.545 | Acc: 87.306% (11231/12864)
Loss: 0.538 | Acc: 87.422% (16841/19264)
Loss: 0.548 | Acc: 87.177% (22373/25664)
Loss: 0.549 | Acc: 87.154% (27945/32064)
Loss: 0.556 | Acc: 87.042% (33480/38464)
Loss: 0.558 | Acc: 87.074% (39065/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8798, Accuracy: 7892/10000 (78.92%)

Epoch: 84
Loss: 0.449 | Acc: 90.625% (58/64)
Loss: 0.524 | Acc: 87.655% (5666/6464)
Loss: 0.535 | Acc: 87.469% (11252/12864)
Loss: 0.547 | Acc: 87.157% (16790/19264)
Loss: 0.549 | Acc: 87.157% (22368/25664)
Loss: 0.544 | Acc: 87.279% (27985/32064)
Loss: 0.548 | Acc: 87.224% (33550/38464)
Loss: 0.547 | Acc: 87.268% (39152/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8408, Accuracy: 8009/10000 (80.09%)

Epoch: 85
Loss: 0.581 | Acc: 85.938% (55/64)
Loss: 0.522 | Acc: 87.608% (5663/6464)
Loss: 0.516 | Acc: 88.145% (11339/12864)
Loss: 0.520 | Acc: 87.884% (16930/19264)
Loss: 0.521 | Acc: 87.781% (22528/25664)
Loss: 0.519 | Acc: 87.846% (28167/32064)
Loss: 0.520 | Acc: 87.895% (33808/38464)
Loss: 0.520 | Acc: 87.874% (39424/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8435, Accuracy: 7964/10000 (79.64%)

Epoch: 86
Loss: 0.578 | Acc: 85.938% (55/64)
Loss: 0.484 | Acc: 88.598% (5727/6464)
Loss: 0.472 | Acc: 88.954% (11443/12864)
Loss: 0.485 | Acc: 88.590% (17066/19264)
Loss: 0.496 | Acc: 88.330% (22669/25664)
Loss: 0.494 | Acc: 88.461% (28364/32064)
Loss: 0.497 | Acc: 88.441% (34018/38464)
Loss: 0.498 | Acc: 88.383% (39652/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9440, Accuracy: 7634/10000 (76.34%)

Epoch: 87
Loss: 0.441 | Acc: 89.062% (57/64)
Loss: 0.481 | Acc: 88.567% (5725/6464)
Loss: 0.476 | Acc: 88.674% (11407/12864)
Loss: 0.480 | Acc: 88.595% (17067/19264)
Loss: 0.479 | Acc: 88.688% (22761/25664)
Loss: 0.481 | Acc: 88.663% (28429/32064)
Loss: 0.480 | Acc: 88.701% (34118/38464)
Loss: 0.478 | Acc: 88.817% (39847/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7890, Accuracy: 8261/10000 (82.61%)

Epoch: 88
Loss: 0.434 | Acc: 89.062% (57/64)
Loss: 0.446 | Acc: 89.248% (5769/6464)
Loss: 0.442 | Acc: 89.583% (11524/12864)
Loss: 0.447 | Acc: 89.493% (17240/19264)
Loss: 0.451 | Acc: 89.440% (22954/25664)
Loss: 0.449 | Acc: 89.474% (28689/32064)
Loss: 0.444 | Acc: 89.637% (34478/38464)
Loss: 0.445 | Acc: 89.620% (40207/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8845, Accuracy: 7961/10000 (79.61%)

Epoch: 89
Loss: 0.523 | Acc: 87.500% (56/64)
Loss: 0.413 | Acc: 90.161% (5828/6464)
Loss: 0.414 | Acc: 90.221% (11606/12864)
Loss: 0.410 | Acc: 90.334% (17402/19264)
Loss: 0.412 | Acc: 90.220% (23154/25664)
Loss: 0.417 | Acc: 90.120% (28896/32064)
Loss: 0.416 | Acc: 90.199% (34694/38464)
Loss: 0.416 | Acc: 90.217% (40475/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8549, Accuracy: 8107/10000 (81.07%)

Epoch: 90
Loss: 0.230 | Acc: 93.750% (60/64)
Loss: 0.367 | Acc: 91.460% (5912/6464)
Loss: 0.369 | Acc: 91.418% (11760/12864)
Loss: 0.375 | Acc: 91.212% (17571/19264)
Loss: 0.377 | Acc: 91.132% (23388/25664)
Loss: 0.385 | Acc: 90.965% (29167/32064)
Loss: 0.388 | Acc: 90.846% (34943/38464)
Loss: 0.388 | Acc: 90.843% (40756/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8271, Accuracy: 8252/10000 (82.52%)

Epoch: 91
Loss: 0.416 | Acc: 93.750% (60/64)
Loss: 0.357 | Acc: 91.429% (5910/6464)
Loss: 0.354 | Acc: 91.395% (11757/12864)
Loss: 0.357 | Acc: 91.315% (17591/19264)
Loss: 0.352 | Acc: 91.365% (23448/25664)
Loss: 0.355 | Acc: 91.361% (29294/32064)
Loss: 0.355 | Acc: 91.366% (35143/38464)
Loss: 0.355 | Acc: 91.358% (40987/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8705, Accuracy: 8203/10000 (82.03%)

Epoch: 92
Loss: 0.453 | Acc: 90.625% (58/64)
Loss: 0.310 | Acc: 92.280% (5965/6464)
Loss: 0.303 | Acc: 92.576% (11909/12864)
Loss: 0.308 | Acc: 92.416% (17803/19264)
Loss: 0.313 | Acc: 92.332% (23696/25664)
Loss: 0.321 | Acc: 92.103% (29532/32064)
Loss: 0.324 | Acc: 92.008% (35390/38464)
Loss: 0.322 | Acc: 92.031% (41289/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8998, Accuracy: 8210/10000 (82.10%)

Epoch: 93
Loss: 0.400 | Acc: 89.062% (57/64)
Loss: 0.278 | Acc: 92.822% (6000/6464)
Loss: 0.280 | Acc: 92.872% (11947/12864)
Loss: 0.277 | Acc: 92.831% (17883/19264)
Loss: 0.281 | Acc: 92.772% (23809/25664)
Loss: 0.280 | Acc: 92.764% (29744/32064)
Loss: 0.279 | Acc: 92.856% (35716/38464)
Loss: 0.281 | Acc: 92.798% (41633/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9002, Accuracy: 8215/10000 (82.15%)

Epoch: 94
Loss: 0.248 | Acc: 93.750% (60/64)
Loss: 0.238 | Acc: 93.688% (6056/6464)
Loss: 0.246 | Acc: 93.610% (12042/12864)
Loss: 0.248 | Acc: 93.558% (18023/19264)
Loss: 0.247 | Acc: 93.637% (24031/25664)
Loss: 0.246 | Acc: 93.653% (30029/32064)
Loss: 0.247 | Acc: 93.675% (36031/38464)
Loss: 0.246 | Acc: 93.690% (42033/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9127, Accuracy: 8197/10000 (81.97%)

Epoch: 95
Loss: 0.111 | Acc: 96.875% (62/64)
Loss: 0.205 | Acc: 94.493% (6108/6464)
Loss: 0.210 | Acc: 94.403% (12144/12864)
Loss: 0.215 | Acc: 94.264% (18159/19264)
Loss: 0.215 | Acc: 94.276% (24195/25664)
Loss: 0.217 | Acc: 94.240% (30217/32064)
Loss: 0.220 | Acc: 94.205% (36235/38464)
Loss: 0.218 | Acc: 94.247% (42283/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9511, Accuracy: 8142/10000 (81.42%)

Epoch: 96
Loss: 0.332 | Acc: 92.188% (59/64)
Loss: 0.208 | Acc: 94.554% (6112/6464)
Loss: 0.201 | Acc: 94.683% (12180/12864)
Loss: 0.207 | Acc: 94.549% (18214/19264)
Loss: 0.206 | Acc: 94.486% (24249/25664)
Loss: 0.204 | Acc: 94.595% (30331/32064)
Loss: 0.203 | Acc: 94.618% (36394/38464)
Loss: 0.202 | Acc: 94.633% (42456/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9498, Accuracy: 8193/10000 (81.93%)

Epoch: 97
Loss: 0.263 | Acc: 90.625% (58/64)
Loss: 0.185 | Acc: 94.988% (6140/6464)
Loss: 0.189 | Acc: 94.939% (12213/12864)
Loss: 0.184 | Acc: 95.074% (18315/19264)
Loss: 0.186 | Acc: 95.009% (24383/25664)
Loss: 0.183 | Acc: 95.125% (30501/32064)
Loss: 0.181 | Acc: 95.201% (36618/38464)
Loss: 0.180 | Acc: 95.185% (42704/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9471, Accuracy: 8196/10000 (81.96%)
torch.Size([100, 10])
Test set: Average loss: 0.9471, Accuracy: 8196/10000 (81.96%)

Epoch: 98
Loss: 0.051 | Acc: 100.000% (64/64)
Loss: 0.166 | Acc: 95.746% (6189/6464)
Loss: 0.169 | Acc: 95.445% (12278/12864)
Loss: 0.172 | Acc: 95.333% (18365/19264)
Loss: 0.171 | Acc: 95.355% (24472/25664)
Loss: 0.170 | Acc: 95.362% (30577/32064)
Loss: 0.172 | Acc: 95.341% (36672/38464)
Loss: 0.170 | Acc: 95.397% (42799/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9468, Accuracy: 8198/10000 (81.98%)
torch.Size([100, 10])
Test set: Average loss: 0.9468, Accuracy: 8198/10000 (81.98%)

Epoch: 99
Loss: 0.071 | Acc: 98.438% (63/64)
Loss: 0.162 | Acc: 95.606% (6180/6464)
Loss: 0.161 | Acc: 95.623% (12301/12864)
Loss: 0.160 | Acc: 95.650% (18426/19264)
Loss: 0.162 | Acc: 95.593% (24533/25664)
Loss: 0.164 | Acc: 95.550% (30637/32064)
Loss: 0.164 | Acc: 95.549% (36752/38464)
Loss: 0.164 | Acc: 95.573% (42878/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9497, Accuracy: 8196/10000 (81.96%)
torch.Size([100, 10])
Test set: Average loss: 0.9497, Accuracy: 8196/10000 (81.96%)

Epoch: 100
Loss: 0.150 | Acc: 93.750% (60/64)
Loss: 1.520 | Acc: 50.325% (3253/6464)
Loss: 1.291 | Acc: 59.810% (7694/12864)
Loss: 1.180 | Acc: 64.182% (12364/19264)
Loss: 1.118 | Acc: 66.700% (17118/25664)
Loss: 1.075 | Acc: 68.382% (21926/32064)
Loss: 1.044 | Acc: 69.590% (26767/38464)
Loss: 1.021 | Acc: 70.567% (31659/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3015, Accuracy: 6276/10000 (62.76%)

Epoch: 101
Loss: 0.927 | Acc: 71.875% (46/64)
Loss: 0.828 | Acc: 77.785% (5028/6464)
Loss: 0.838 | Acc: 77.410% (9958/12864)
Loss: 0.836 | Acc: 77.637% (14956/19264)
Loss: 0.830 | Acc: 77.868% (19984/25664)
Loss: 0.831 | Acc: 77.960% (24997/32064)
Loss: 0.830 | Acc: 78.037% (30016/38464)
Loss: 0.834 | Acc: 77.956% (34974/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5023, Accuracy: 5662/10000 (56.62%)

Epoch: 102
Loss: 0.536 | Acc: 89.062% (57/64)
Loss: 0.795 | Acc: 79.254% (5123/6464)
Loss: 0.806 | Acc: 79.081% (10173/12864)
Loss: 0.803 | Acc: 79.070% (15232/19264)
Loss: 0.805 | Acc: 78.924% (20255/25664)
Loss: 0.803 | Acc: 78.998% (25330/32064)
Loss: 0.807 | Acc: 78.918% (30355/38464)
Loss: 0.807 | Acc: 78.983% (35435/44864)
torch.Size([100, 10])
Test set: Average loss: 4.5074, Accuracy: 2346/10000 (23.46%)

Epoch: 103
Loss: 0.838 | Acc: 75.000% (48/64)
Loss: 0.801 | Acc: 79.270% (5124/6464)
Loss: 0.810 | Acc: 79.042% (10168/12864)
Loss: 0.800 | Acc: 79.283% (15273/19264)
Loss: 0.797 | Acc: 79.415% (20381/25664)
Loss: 0.799 | Acc: 79.382% (25453/32064)
Loss: 0.800 | Acc: 79.303% (30503/38464)
Loss: 0.801 | Acc: 79.182% (35524/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2147, Accuracy: 4438/10000 (44.38%)

Epoch: 104
Loss: 0.865 | Acc: 71.875% (46/64)
Loss: 0.773 | Acc: 79.657% (5149/6464)
Loss: 0.791 | Acc: 79.470% (10223/12864)
Loss: 0.791 | Acc: 79.589% (15332/19264)
Loss: 0.792 | Acc: 79.598% (20428/25664)
Loss: 0.793 | Acc: 79.641% (25536/32064)
Loss: 0.794 | Acc: 79.511% (30583/38464)
Loss: 0.792 | Acc: 79.554% (35691/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2037, Accuracy: 6808/10000 (68.08%)

Epoch: 105
Loss: 0.992 | Acc: 73.438% (47/64)
Loss: 0.777 | Acc: 79.904% (5165/6464)
Loss: 0.779 | Acc: 79.859% (10273/12864)
Loss: 0.780 | Acc: 79.838% (15380/19264)
Loss: 0.778 | Acc: 79.941% (20516/25664)
Loss: 0.782 | Acc: 79.887% (25615/32064)
Loss: 0.784 | Acc: 79.784% (30688/38464)
Loss: 0.787 | Acc: 79.683% (35749/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5828, Accuracy: 5395/10000 (53.95%)

Epoch: 106
Loss: 1.051 | Acc: 70.312% (45/64)
Loss: 0.790 | Acc: 79.734% (5154/6464)
Loss: 0.781 | Acc: 80.162% (10312/12864)
Loss: 0.778 | Acc: 80.155% (15441/19264)
Loss: 0.783 | Acc: 80.065% (20548/25664)
Loss: 0.784 | Acc: 79.971% (25642/32064)
Loss: 0.785 | Acc: 79.966% (30758/38464)
Loss: 0.789 | Acc: 79.794% (35799/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9202, Accuracy: 5166/10000 (51.66%)

Epoch: 107
Loss: 0.894 | Acc: 71.875% (46/64)
Loss: 0.774 | Acc: 80.260% (5188/6464)
Loss: 0.775 | Acc: 79.967% (10287/12864)
Loss: 0.776 | Acc: 79.963% (15404/19264)
Loss: 0.780 | Acc: 80.007% (20533/25664)
Loss: 0.783 | Acc: 79.818% (25593/32064)
Loss: 0.784 | Acc: 79.784% (30688/38464)
Loss: 0.784 | Acc: 79.835% (35817/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0621, Accuracy: 4718/10000 (47.18%)

Epoch: 108
Loss: 1.001 | Acc: 73.438% (47/64)
Loss: 0.765 | Acc: 80.538% (5206/6464)
Loss: 0.768 | Acc: 80.387% (10341/12864)
Loss: 0.779 | Acc: 80.056% (15422/19264)
Loss: 0.781 | Acc: 79.980% (20526/25664)
Loss: 0.777 | Acc: 80.093% (25681/32064)
Loss: 0.780 | Acc: 80.036% (30785/38464)
Loss: 0.782 | Acc: 79.924% (35857/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7021, Accuracy: 5153/10000 (51.53%)

Epoch: 109
Loss: 0.982 | Acc: 71.875% (46/64)
Loss: 0.789 | Acc: 79.858% (5162/6464)
Loss: 0.782 | Acc: 80.216% (10319/12864)
Loss: 0.777 | Acc: 80.326% (15474/19264)
Loss: 0.771 | Acc: 80.506% (20661/25664)
Loss: 0.775 | Acc: 80.346% (25762/32064)
Loss: 0.779 | Acc: 80.202% (30849/38464)
Loss: 0.779 | Acc: 80.240% (35999/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8064, Accuracy: 5383/10000 (53.83%)

Epoch: 110
Loss: 0.988 | Acc: 67.188% (43/64)
Loss: 0.787 | Acc: 79.858% (5162/6464)
Loss: 0.762 | Acc: 80.558% (10363/12864)
Loss: 0.762 | Acc: 80.539% (15515/19264)
Loss: 0.762 | Acc: 80.521% (20665/25664)
Loss: 0.767 | Acc: 80.333% (25758/32064)
Loss: 0.770 | Acc: 80.270% (30875/38464)
Loss: 0.769 | Acc: 80.298% (36025/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0115, Accuracy: 7277/10000 (72.77%)

Epoch: 111
Loss: 0.711 | Acc: 84.375% (54/64)
Loss: 0.773 | Acc: 80.136% (5180/6464)
Loss: 0.772 | Acc: 80.162% (10312/12864)
Loss: 0.766 | Acc: 80.264% (15462/19264)
Loss: 0.758 | Acc: 80.490% (20657/25664)
Loss: 0.766 | Acc: 80.358% (25766/32064)
Loss: 0.770 | Acc: 80.324% (30896/38464)
Loss: 0.771 | Acc: 80.296% (36024/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3421, Accuracy: 6306/10000 (63.06%)

Epoch: 112
Loss: 1.220 | Acc: 64.062% (41/64)
Loss: 0.746 | Acc: 81.173% (5247/6464)
Loss: 0.748 | Acc: 81.048% (10426/12864)
Loss: 0.757 | Acc: 80.835% (15572/19264)
Loss: 0.756 | Acc: 80.759% (20726/25664)
Loss: 0.759 | Acc: 80.695% (25874/32064)
Loss: 0.761 | Acc: 80.600% (31002/38464)
Loss: 0.764 | Acc: 80.541% (36134/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2477, Accuracy: 6231/10000 (62.31%)

Epoch: 113
Loss: 0.664 | Acc: 84.375% (54/64)
Loss: 0.751 | Acc: 81.018% (5237/6464)
Loss: 0.755 | Acc: 80.885% (10405/12864)
Loss: 0.750 | Acc: 81.058% (15615/19264)
Loss: 0.747 | Acc: 81.082% (20809/25664)
Loss: 0.745 | Acc: 80.994% (25970/32064)
Loss: 0.751 | Acc: 80.863% (31103/38464)
Loss: 0.757 | Acc: 80.711% (36210/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4615, Accuracy: 6005/10000 (60.05%)

Epoch: 114
Loss: 1.032 | Acc: 71.875% (46/64)
Loss: 0.741 | Acc: 81.405% (5262/6464)
Loss: 0.742 | Acc: 81.297% (10458/12864)
Loss: 0.748 | Acc: 80.949% (15594/19264)
Loss: 0.742 | Acc: 81.184% (20835/25664)
Loss: 0.748 | Acc: 81.000% (25972/32064)
Loss: 0.754 | Acc: 80.886% (31112/38464)
Loss: 0.755 | Acc: 80.871% (36282/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5851, Accuracy: 5493/10000 (54.93%)

Epoch: 115
Loss: 0.893 | Acc: 75.000% (48/64)
Loss: 0.705 | Acc: 82.101% (5307/6464)
Loss: 0.723 | Acc: 81.755% (10517/12864)
Loss: 0.741 | Acc: 81.229% (15648/19264)
Loss: 0.742 | Acc: 81.238% (20849/25664)
Loss: 0.743 | Acc: 81.197% (26035/32064)
Loss: 0.744 | Acc: 81.068% (31182/38464)
Loss: 0.745 | Acc: 81.054% (36364/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9757, Accuracy: 7387/10000 (73.87%)

Epoch: 116
Loss: 0.695 | Acc: 81.250% (52/64)
Loss: 0.743 | Acc: 81.389% (5261/6464)
Loss: 0.733 | Acc: 81.421% (10474/12864)
Loss: 0.734 | Acc: 81.437% (15688/19264)
Loss: 0.732 | Acc: 81.429% (20898/25664)
Loss: 0.743 | Acc: 81.147% (26019/32064)
Loss: 0.739 | Acc: 81.354% (31292/38464)
Loss: 0.741 | Acc: 81.170% (36416/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0139, Accuracy: 4649/10000 (46.49%)

Epoch: 117
Loss: 0.704 | Acc: 76.562% (49/64)
Loss: 0.757 | Acc: 80.678% (5215/6464)
Loss: 0.744 | Acc: 81.297% (10458/12864)
Loss: 0.736 | Acc: 81.536% (15707/19264)
Loss: 0.733 | Acc: 81.659% (20957/25664)
Loss: 0.741 | Acc: 81.431% (26110/32064)
Loss: 0.738 | Acc: 81.450% (31329/38464)
Loss: 0.735 | Acc: 81.500% (36564/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0017, Accuracy: 7245/10000 (72.45%)

Epoch: 118
Loss: 0.835 | Acc: 81.250% (52/64)
Loss: 0.709 | Acc: 82.379% (5325/6464)
Loss: 0.713 | Acc: 82.478% (10610/12864)
Loss: 0.710 | Acc: 82.351% (15864/19264)
Loss: 0.717 | Acc: 82.150% (21083/25664)
Loss: 0.725 | Acc: 81.833% (26239/32064)
Loss: 0.725 | Acc: 81.830% (31475/38464)
Loss: 0.728 | Acc: 81.812% (36704/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0971, Accuracy: 6961/10000 (69.61%)

Epoch: 119
Loss: 0.539 | Acc: 84.375% (54/64)
Loss: 0.730 | Acc: 81.590% (5274/6464)
Loss: 0.717 | Acc: 82.198% (10574/12864)
Loss: 0.710 | Acc: 82.299% (15854/19264)
Loss: 0.717 | Acc: 82.193% (21094/25664)
Loss: 0.718 | Acc: 82.148% (26340/32064)
Loss: 0.718 | Acc: 82.087% (31574/38464)
Loss: 0.719 | Acc: 82.072% (36821/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2242, Accuracy: 6523/10000 (65.23%)

Epoch: 120
Loss: 0.588 | Acc: 84.375% (54/64)
Loss: 0.713 | Acc: 82.689% (5345/6464)
Loss: 0.713 | Acc: 82.393% (10599/12864)
Loss: 0.710 | Acc: 82.413% (15876/19264)
Loss: 0.710 | Acc: 82.458% (21162/25664)
Loss: 0.707 | Acc: 82.522% (26460/32064)
Loss: 0.710 | Acc: 82.407% (31697/38464)
Loss: 0.710 | Acc: 82.398% (36967/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9522, Accuracy: 7495/10000 (74.95%)

Epoch: 121
Loss: 0.673 | Acc: 82.812% (53/64)
Loss: 0.661 | Acc: 83.648% (5407/6464)
Loss: 0.684 | Acc: 82.929% (10668/12864)
Loss: 0.694 | Acc: 82.703% (15932/19264)
Loss: 0.697 | Acc: 82.696% (21223/25664)
Loss: 0.697 | Acc: 82.763% (26537/32064)
Loss: 0.701 | Acc: 82.659% (31794/38464)
Loss: 0.704 | Acc: 82.648% (37079/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1227, Accuracy: 6753/10000 (67.53%)

Epoch: 122
Loss: 0.884 | Acc: 73.438% (47/64)
Loss: 0.683 | Acc: 83.075% (5370/6464)
Loss: 0.672 | Acc: 83.559% (10749/12864)
Loss: 0.674 | Acc: 83.529% (16091/19264)
Loss: 0.679 | Acc: 83.342% (21389/25664)
Loss: 0.683 | Acc: 83.299% (26709/32064)
Loss: 0.685 | Acc: 83.174% (31992/38464)
Loss: 0.688 | Acc: 83.064% (37266/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0228, Accuracy: 7301/10000 (73.01%)

Epoch: 123
Loss: 0.619 | Acc: 85.938% (55/64)
Loss: 0.674 | Acc: 83.230% (5380/6464)
Loss: 0.676 | Acc: 83.193% (10702/12864)
Loss: 0.680 | Acc: 83.274% (16042/19264)
Loss: 0.677 | Acc: 83.397% (21403/25664)
Loss: 0.679 | Acc: 83.277% (26702/32064)
Loss: 0.678 | Acc: 83.309% (32044/38464)
Loss: 0.682 | Acc: 83.243% (37346/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8382, Accuracy: 7869/10000 (78.69%)

Epoch: 124
Loss: 0.539 | Acc: 87.500% (56/64)
Loss: 0.660 | Acc: 84.004% (5430/6464)
Loss: 0.655 | Acc: 84.049% (10812/12864)
Loss: 0.659 | Acc: 84.115% (16204/19264)
Loss: 0.660 | Acc: 83.993% (21556/25664)
Loss: 0.666 | Acc: 83.826% (26878/32064)
Loss: 0.667 | Acc: 83.798% (32232/38464)
Loss: 0.672 | Acc: 83.713% (37557/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0565, Accuracy: 7085/10000 (70.85%)

Epoch: 125
Loss: 0.720 | Acc: 82.812% (53/64)
Loss: 0.646 | Acc: 84.313% (5450/6464)
Loss: 0.636 | Acc: 84.414% (10859/12864)
Loss: 0.656 | Acc: 83.939% (16170/19264)
Loss: 0.654 | Acc: 84.118% (21588/25664)
Loss: 0.657 | Acc: 84.076% (26958/32064)
Loss: 0.657 | Acc: 84.120% (32356/38464)
Loss: 0.662 | Acc: 84.025% (37697/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1371, Accuracy: 6906/10000 (69.06%)

Epoch: 126
Loss: 0.502 | Acc: 81.250% (52/64)
Loss: 0.630 | Acc: 85.071% (5499/6464)
Loss: 0.633 | Acc: 84.818% (10911/12864)
Loss: 0.652 | Acc: 84.266% (16233/19264)
Loss: 0.652 | Acc: 84.254% (21623/25664)
Loss: 0.653 | Acc: 84.222% (27005/32064)
Loss: 0.650 | Acc: 84.307% (32428/38464)
Loss: 0.652 | Acc: 84.264% (37804/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7936, Accuracy: 8073/10000 (80.73%)

Epoch: 127
Loss: 0.634 | Acc: 84.375% (54/64)
Loss: 0.625 | Acc: 84.808% (5482/6464)
Loss: 0.633 | Acc: 84.756% (10903/12864)
Loss: 0.640 | Acc: 84.676% (16312/19264)
Loss: 0.643 | Acc: 84.554% (21700/25664)
Loss: 0.643 | Acc: 84.553% (27111/32064)
Loss: 0.639 | Acc: 84.708% (32582/38464)
Loss: 0.636 | Acc: 84.814% (38051/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8248, Accuracy: 7952/10000 (79.52%)

Epoch: 128
Loss: 0.830 | Acc: 78.125% (50/64)
Loss: 0.598 | Acc: 85.551% (5530/6464)
Loss: 0.608 | Acc: 85.378% (10983/12864)
Loss: 0.615 | Acc: 85.180% (16409/19264)
Loss: 0.618 | Acc: 85.178% (21860/25664)
Loss: 0.624 | Acc: 85.027% (27263/32064)
Loss: 0.627 | Acc: 85.012% (32699/38464)
Loss: 0.628 | Acc: 84.941% (38108/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8448, Accuracy: 7968/10000 (79.68%)

Epoch: 129
Loss: 0.518 | Acc: 89.062% (57/64)
Loss: 0.589 | Acc: 85.736% (5542/6464)
Loss: 0.599 | Acc: 85.759% (11032/12864)
Loss: 0.593 | Acc: 85.943% (16556/19264)
Loss: 0.600 | Acc: 85.747% (22006/25664)
Loss: 0.609 | Acc: 85.532% (27425/32064)
Loss: 0.614 | Acc: 85.418% (32855/38464)
Loss: 0.615 | Acc: 85.420% (38323/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1854, Accuracy: 6914/10000 (69.14%)

Epoch: 130
Loss: 0.885 | Acc: 78.125% (50/64)
Loss: 0.613 | Acc: 85.427% (5522/6464)
Loss: 0.622 | Acc: 85.401% (10986/12864)
Loss: 0.606 | Acc: 85.709% (16511/19264)
Loss: 0.602 | Acc: 85.770% (22012/25664)
Loss: 0.598 | Acc: 85.881% (27537/32064)
Loss: 0.600 | Acc: 85.831% (33014/38464)
Loss: 0.598 | Acc: 85.880% (38529/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8401, Accuracy: 7903/10000 (79.03%)

Epoch: 131
Loss: 0.550 | Acc: 82.812% (53/64)
Loss: 0.567 | Acc: 87.036% (5626/6464)
Loss: 0.566 | Acc: 86.933% (11183/12864)
Loss: 0.563 | Acc: 86.862% (16733/19264)
Loss: 0.569 | Acc: 86.728% (22258/25664)
Loss: 0.575 | Acc: 86.599% (27767/32064)
Loss: 0.575 | Acc: 86.616% (33316/38464)
Loss: 0.579 | Acc: 86.419% (38771/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8903, Accuracy: 7772/10000 (77.72%)

Epoch: 132
Loss: 0.802 | Acc: 78.125% (50/64)
Loss: 0.544 | Acc: 87.515% (5657/6464)
Loss: 0.553 | Acc: 87.158% (11212/12864)
Loss: 0.556 | Acc: 86.908% (16742/19264)
Loss: 0.563 | Acc: 86.783% (22272/25664)
Loss: 0.567 | Acc: 86.680% (27793/32064)
Loss: 0.568 | Acc: 86.702% (33349/38464)
Loss: 0.568 | Acc: 86.682% (38889/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7863, Accuracy: 8103/10000 (81.03%)

Epoch: 133
Loss: 0.461 | Acc: 90.625% (58/64)
Loss: 0.488 | Acc: 88.428% (5716/6464)
Loss: 0.513 | Acc: 88.029% (11324/12864)
Loss: 0.528 | Acc: 87.702% (16895/19264)
Loss: 0.532 | Acc: 87.609% (22484/25664)
Loss: 0.541 | Acc: 87.419% (28030/32064)
Loss: 0.546 | Acc: 87.321% (33587/38464)
Loss: 0.546 | Acc: 87.368% (39197/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8259, Accuracy: 8055/10000 (80.55%)

Epoch: 134
Loss: 0.422 | Acc: 89.062% (57/64)
Loss: 0.534 | Acc: 87.732% (5671/6464)
Loss: 0.526 | Acc: 87.959% (11315/12864)
Loss: 0.518 | Acc: 88.206% (16992/19264)
Loss: 0.518 | Acc: 88.096% (22609/25664)
Loss: 0.526 | Acc: 87.918% (28190/32064)
Loss: 0.525 | Acc: 87.939% (33825/38464)
Loss: 0.521 | Acc: 88.022% (39490/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9130, Accuracy: 7676/10000 (76.76%)

Epoch: 135
Loss: 0.523 | Acc: 85.938% (55/64)
Loss: 0.465 | Acc: 89.109% (5760/6464)
Loss: 0.468 | Acc: 89.125% (11465/12864)
Loss: 0.477 | Acc: 88.813% (17109/19264)
Loss: 0.491 | Acc: 88.498% (22712/25664)
Loss: 0.496 | Acc: 88.439% (28357/32064)
Loss: 0.505 | Acc: 88.259% (33948/38464)
Loss: 0.504 | Acc: 88.311% (39620/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8292, Accuracy: 8046/10000 (80.46%)

Epoch: 136
Loss: 0.390 | Acc: 89.062% (57/64)
Loss: 0.491 | Acc: 88.366% (5712/6464)
Loss: 0.485 | Acc: 88.643% (11403/12864)
Loss: 0.475 | Acc: 88.948% (17135/19264)
Loss: 0.476 | Acc: 88.996% (22840/25664)
Loss: 0.478 | Acc: 88.978% (28530/32064)
Loss: 0.482 | Acc: 88.839% (34171/38464)
Loss: 0.481 | Acc: 88.857% (39865/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8425, Accuracy: 8039/10000 (80.39%)

Epoch: 137
Loss: 0.605 | Acc: 84.375% (54/64)
Loss: 0.447 | Acc: 89.511% (5786/6464)
Loss: 0.444 | Acc: 89.614% (11528/12864)
Loss: 0.447 | Acc: 89.592% (17259/19264)
Loss: 0.447 | Acc: 89.550% (22982/25664)
Loss: 0.450 | Acc: 89.487% (28693/32064)
Loss: 0.453 | Acc: 89.465% (34412/38464)
Loss: 0.453 | Acc: 89.479% (40144/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9351, Accuracy: 7749/10000 (77.49%)

Epoch: 138
Loss: 0.353 | Acc: 87.500% (56/64)
Loss: 0.430 | Acc: 89.418% (5780/6464)
Loss: 0.433 | Acc: 89.599% (11526/12864)
Loss: 0.424 | Acc: 89.997% (17337/19264)
Loss: 0.421 | Acc: 90.009% (23100/25664)
Loss: 0.425 | Acc: 89.964% (28846/32064)
Loss: 0.421 | Acc: 90.089% (34652/38464)
Loss: 0.426 | Acc: 89.961% (40360/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8543, Accuracy: 8126/10000 (81.26%)

Epoch: 139
Loss: 0.464 | Acc: 87.500% (56/64)
Loss: 0.378 | Acc: 91.213% (5896/6464)
Loss: 0.385 | Acc: 90.951% (11700/12864)
Loss: 0.388 | Acc: 90.869% (17505/19264)
Loss: 0.397 | Acc: 90.606% (23253/25664)
Loss: 0.401 | Acc: 90.475% (29010/32064)
Loss: 0.400 | Acc: 90.518% (34817/38464)
Loss: 0.400 | Acc: 90.534% (40617/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8473, Accuracy: 8194/10000 (81.94%)

Epoch: 140
Loss: 0.305 | Acc: 89.062% (57/64)
Loss: 0.362 | Acc: 91.166% (5893/6464)
Loss: 0.362 | Acc: 91.123% (11722/12864)
Loss: 0.358 | Acc: 91.373% (17602/19264)
Loss: 0.361 | Acc: 91.280% (23426/25664)
Loss: 0.359 | Acc: 91.345% (29289/32064)
Loss: 0.360 | Acc: 91.348% (35136/38464)
Loss: 0.362 | Acc: 91.298% (40960/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8674, Accuracy: 8203/10000 (82.03%)

Epoch: 141
Loss: 0.379 | Acc: 90.625% (58/64)
Loss: 0.314 | Acc: 92.234% (5962/6464)
Loss: 0.332 | Acc: 91.690% (11795/12864)
Loss: 0.331 | Acc: 91.798% (17684/19264)
Loss: 0.330 | Acc: 91.919% (23590/25664)
Loss: 0.326 | Acc: 92.047% (29514/32064)
Loss: 0.322 | Acc: 92.099% (35425/38464)
Loss: 0.328 | Acc: 92.005% (41277/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8750, Accuracy: 8201/10000 (82.01%)

Epoch: 142
Loss: 0.260 | Acc: 95.312% (61/64)
Loss: 0.292 | Acc: 92.621% (5987/6464)
Loss: 0.288 | Acc: 92.724% (11928/12864)
Loss: 0.290 | Acc: 92.598% (17838/19264)
Loss: 0.291 | Acc: 92.573% (23758/25664)
Loss: 0.289 | Acc: 92.674% (29715/32064)
Loss: 0.291 | Acc: 92.684% (35650/38464)
Loss: 0.292 | Acc: 92.691% (41585/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9047, Accuracy: 8211/10000 (82.11%)

Epoch: 143
Loss: 0.386 | Acc: 87.500% (56/64)
Loss: 0.271 | Acc: 92.915% (6006/6464)
Loss: 0.272 | Acc: 92.825% (11941/12864)
Loss: 0.261 | Acc: 93.205% (17955/19264)
Loss: 0.262 | Acc: 93.247% (23931/25664)
Loss: 0.263 | Acc: 93.242% (29897/32064)
Loss: 0.260 | Acc: 93.311% (35891/38464)
Loss: 0.263 | Acc: 93.228% (41826/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9193, Accuracy: 8211/10000 (82.11%)

Epoch: 144
Loss: 0.302 | Acc: 93.750% (60/64)
Loss: 0.229 | Acc: 93.858% (6067/6464)
Loss: 0.229 | Acc: 93.913% (12081/12864)
Loss: 0.230 | Acc: 93.838% (18077/19264)
Loss: 0.229 | Acc: 93.882% (24094/25664)
Loss: 0.227 | Acc: 93.950% (30124/32064)
Loss: 0.227 | Acc: 93.974% (36146/38464)
Loss: 0.229 | Acc: 93.937% (42144/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9344, Accuracy: 8198/10000 (81.98%)

Epoch: 145
Loss: 0.182 | Acc: 95.312% (61/64)
Loss: 0.193 | Acc: 94.771% (6126/6464)
Loss: 0.196 | Acc: 94.644% (12175/12864)
Loss: 0.198 | Acc: 94.721% (18247/19264)
Loss: 0.200 | Acc: 94.673% (24297/25664)
Loss: 0.199 | Acc: 94.636% (30344/32064)
Loss: 0.200 | Acc: 94.618% (36394/38464)
Loss: 0.200 | Acc: 94.646% (42462/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9473, Accuracy: 8159/10000 (81.59%)

Epoch: 146
Loss: 0.334 | Acc: 89.062% (57/64)
Loss: 0.172 | Acc: 95.498% (6173/6464)
Loss: 0.180 | Acc: 95.173% (12243/12864)
Loss: 0.183 | Acc: 95.084% (18317/19264)
Loss: 0.178 | Acc: 95.266% (24449/25664)
Loss: 0.178 | Acc: 95.266% (30546/32064)
Loss: 0.179 | Acc: 95.170% (36606/38464)
Loss: 0.180 | Acc: 95.132% (42680/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9545, Accuracy: 8207/10000 (82.07%)

Epoch: 147
Loss: 0.054 | Acc: 100.000% (64/64)
Loss: 0.161 | Acc: 95.514% (6174/6464)
Loss: 0.165 | Acc: 95.468% (12281/12864)
Loss: 0.169 | Acc: 95.287% (18356/19264)
Loss: 0.165 | Acc: 95.441% (24494/25664)
Loss: 0.165 | Acc: 95.462% (30609/32064)
Loss: 0.167 | Acc: 95.445% (36712/38464)
Loss: 0.166 | Acc: 95.491% (42841/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9506, Accuracy: 8190/10000 (81.90%)
torch.Size([100, 10])
Test set: Average loss: 0.9506, Accuracy: 8190/10000 (81.90%)

Epoch: 148
Loss: 0.035 | Acc: 100.000% (64/64)
Loss: 0.148 | Acc: 95.838% (6195/6464)
Loss: 0.150 | Acc: 95.841% (12329/12864)
Loss: 0.154 | Acc: 95.712% (18438/19264)
Loss: 0.154 | Acc: 95.741% (24571/25664)
Loss: 0.155 | Acc: 95.777% (30710/32064)
Loss: 0.157 | Acc: 95.708% (36813/38464)
Loss: 0.156 | Acc: 95.727% (42947/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9562, Accuracy: 8197/10000 (81.97%)
torch.Size([100, 10])
Test set: Average loss: 0.9562, Accuracy: 8197/10000 (81.97%)

Epoch: 149
Loss: 0.164 | Acc: 95.312% (61/64)
Loss: 0.152 | Acc: 95.606% (6180/6464)
Loss: 0.148 | Acc: 95.857% (12331/12864)
Loss: 0.148 | Acc: 95.930% (18480/19264)
Loss: 0.147 | Acc: 95.967% (24629/25664)
Loss: 0.148 | Acc: 95.936% (30761/32064)
Loss: 0.150 | Acc: 95.822% (36857/38464)
Loss: 0.150 | Acc: 95.861% (43007/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9681, Accuracy: 8191/10000 (81.91%)
torch.Size([100, 10])
Test set: Average loss: 0.9681, Accuracy: 8191/10000 (81.91%)

Epoch: 150
Loss: 0.047 | Acc: 98.438% (63/64)
Loss: 1.339 | Acc: 57.611% (3724/6464)
Loss: 1.169 | Acc: 64.498% (8297/12864)
Loss: 1.096 | Acc: 67.447% (12993/19264)
Loss: 1.050 | Acc: 69.412% (17814/25664)
Loss: 1.013 | Acc: 70.865% (22722/32064)
Loss: 0.988 | Acc: 71.823% (27626/38464)
Loss: 0.971 | Acc: 72.577% (32561/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3187, Accuracy: 6091/10000 (60.91%)

Epoch: 151
Loss: 0.819 | Acc: 79.688% (51/64)
Loss: 0.810 | Acc: 78.605% (5081/6464)
Loss: 0.812 | Acc: 78.382% (10083/12864)
Loss: 0.826 | Acc: 78.141% (15053/19264)
Loss: 0.823 | Acc: 78.219% (20074/25664)
Loss: 0.816 | Acc: 78.424% (25146/32064)
Loss: 0.816 | Acc: 78.471% (30183/38464)
Loss: 0.816 | Acc: 78.482% (35210/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0123, Accuracy: 4568/10000 (45.68%)

Epoch: 152
Loss: 0.911 | Acc: 70.312% (45/64)
Loss: 0.789 | Acc: 79.471% (5137/6464)
Loss: 0.775 | Acc: 79.812% (10267/12864)
Loss: 0.787 | Acc: 79.392% (15294/19264)
Loss: 0.790 | Acc: 79.263% (20342/25664)
Loss: 0.796 | Acc: 79.148% (25378/32064)
Loss: 0.799 | Acc: 79.160% (30448/38464)
Loss: 0.796 | Acc: 79.266% (35562/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3346, Accuracy: 6098/10000 (60.98%)

Epoch: 153
Loss: 0.812 | Acc: 75.000% (48/64)
Loss: 0.778 | Acc: 79.548% (5142/6464)
Loss: 0.768 | Acc: 79.936% (10283/12864)
Loss: 0.777 | Acc: 79.739% (15361/19264)
Loss: 0.776 | Acc: 79.875% (20499/25664)
Loss: 0.780 | Acc: 79.925% (25627/32064)
Loss: 0.785 | Acc: 79.752% (30676/38464)
Loss: 0.787 | Acc: 79.770% (35788/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3310, Accuracy: 6128/10000 (61.28%)

Epoch: 154
Loss: 0.875 | Acc: 81.250% (52/64)
Loss: 0.774 | Acc: 80.322% (5192/6464)
Loss: 0.786 | Acc: 79.882% (10276/12864)
Loss: 0.783 | Acc: 79.693% (15352/19264)
Loss: 0.782 | Acc: 79.777% (20474/25664)
Loss: 0.784 | Acc: 79.769% (25577/32064)
Loss: 0.783 | Acc: 79.846% (30712/38464)
Loss: 0.782 | Acc: 79.881% (35838/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7331, Accuracy: 5110/10000 (51.10%)

Epoch: 155
Loss: 1.082 | Acc: 68.750% (44/64)
Loss: 0.800 | Acc: 79.285% (5125/6464)
Loss: 0.788 | Acc: 79.703% (10253/12864)
Loss: 0.778 | Acc: 80.092% (15429/19264)
Loss: 0.776 | Acc: 80.151% (20570/25664)
Loss: 0.774 | Acc: 80.308% (25750/32064)
Loss: 0.777 | Acc: 80.291% (30883/38464)
Loss: 0.780 | Acc: 80.138% (35953/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2894, Accuracy: 6311/10000 (63.11%)

Epoch: 156
Loss: 0.601 | Acc: 84.375% (54/64)
Loss: 0.759 | Acc: 80.739% (5219/6464)
Loss: 0.761 | Acc: 80.581% (10366/12864)
Loss: 0.757 | Acc: 80.643% (15535/19264)
Loss: 0.759 | Acc: 80.634% (20694/25664)
Loss: 0.764 | Acc: 80.417% (25785/32064)
Loss: 0.769 | Acc: 80.192% (30845/38464)
Loss: 0.769 | Acc: 80.225% (35992/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9985, Accuracy: 7237/10000 (72.37%)

Epoch: 157
Loss: 0.675 | Acc: 89.062% (57/64)
Loss: 0.772 | Acc: 80.446% (5200/6464)
Loss: 0.758 | Acc: 80.613% (10370/12864)
Loss: 0.771 | Acc: 80.310% (15471/19264)
Loss: 0.776 | Acc: 80.155% (20571/25664)
Loss: 0.776 | Acc: 80.118% (25689/32064)
Loss: 0.771 | Acc: 80.189% (30844/38464)
Loss: 0.774 | Acc: 80.082% (35928/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7775, Accuracy: 5725/10000 (57.25%)

Epoch: 158
Loss: 0.888 | Acc: 73.438% (47/64)
Loss: 0.770 | Acc: 80.152% (5181/6464)
Loss: 0.764 | Acc: 80.107% (10305/12864)
Loss: 0.765 | Acc: 80.305% (15470/19264)
Loss: 0.762 | Acc: 80.517% (20664/25664)
Loss: 0.770 | Acc: 80.289% (25744/32064)
Loss: 0.769 | Acc: 80.283% (30880/38464)
Loss: 0.772 | Acc: 80.256% (36006/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1718, Accuracy: 6692/10000 (66.92%)

Epoch: 159
Loss: 0.923 | Acc: 76.562% (49/64)
Loss: 0.747 | Acc: 80.755% (5220/6464)
Loss: 0.755 | Acc: 80.589% (10367/12864)
Loss: 0.754 | Acc: 80.721% (15550/19264)
Loss: 0.756 | Acc: 80.732% (20719/25664)
Loss: 0.758 | Acc: 80.695% (25874/32064)
Loss: 0.761 | Acc: 80.613% (31007/38464)
Loss: 0.765 | Acc: 80.503% (36117/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7904, Accuracy: 5680/10000 (56.80%)

Epoch: 160
Loss: 0.962 | Acc: 78.125% (50/64)
Loss: 0.767 | Acc: 80.523% (5205/6464)
Loss: 0.774 | Acc: 80.317% (10332/12864)
Loss: 0.759 | Acc: 80.617% (15530/19264)
Loss: 0.759 | Acc: 80.506% (20661/25664)
Loss: 0.757 | Acc: 80.626% (25852/32064)
Loss: 0.765 | Acc: 80.449% (30944/38464)
Loss: 0.765 | Acc: 80.430% (36084/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7274, Accuracy: 5515/10000 (55.15%)

Epoch: 161
Loss: 1.307 | Acc: 67.188% (43/64)
Loss: 0.723 | Acc: 81.528% (5270/6464)
Loss: 0.740 | Acc: 81.118% (10435/12864)
Loss: 0.753 | Acc: 80.881% (15581/19264)
Loss: 0.754 | Acc: 80.872% (20755/25664)
Loss: 0.757 | Acc: 80.866% (25929/32064)
Loss: 0.758 | Acc: 80.865% (31104/38464)
Loss: 0.759 | Acc: 80.829% (36263/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5071, Accuracy: 3719/10000 (37.19%)

Epoch: 162
Loss: 0.786 | Acc: 82.812% (53/64)
Loss: 0.732 | Acc: 81.714% (5282/6464)
Loss: 0.738 | Acc: 81.538% (10489/12864)
Loss: 0.738 | Acc: 81.541% (15708/19264)
Loss: 0.744 | Acc: 81.379% (20885/25664)
Loss: 0.749 | Acc: 81.222% (26043/32064)
Loss: 0.751 | Acc: 81.185% (31227/38464)
Loss: 0.752 | Acc: 81.163% (36413/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0456, Accuracy: 7145/10000 (71.45%)

Epoch: 163
Loss: 0.622 | Acc: 82.812% (53/64)
Loss: 0.729 | Acc: 81.946% (5297/6464)
Loss: 0.739 | Acc: 81.553% (10491/12864)
Loss: 0.741 | Acc: 81.359% (15673/19264)
Loss: 0.746 | Acc: 81.121% (20819/25664)
Loss: 0.748 | Acc: 81.107% (26006/32064)
Loss: 0.749 | Acc: 81.063% (31180/38464)
Loss: 0.752 | Acc: 80.974% (36328/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2615, Accuracy: 6435/10000 (64.35%)

Epoch: 164
Loss: 1.003 | Acc: 73.438% (47/64)
Loss: 0.732 | Acc: 81.420% (5263/6464)
Loss: 0.713 | Acc: 82.043% (10554/12864)
Loss: 0.719 | Acc: 82.013% (15799/19264)
Loss: 0.735 | Acc: 81.484% (20912/25664)
Loss: 0.735 | Acc: 81.471% (26123/32064)
Loss: 0.740 | Acc: 81.286% (31266/38464)
Loss: 0.743 | Acc: 81.136% (36401/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0528, Accuracy: 7081/10000 (70.81%)

Epoch: 165
Loss: 0.734 | Acc: 84.375% (54/64)
Loss: 0.746 | Acc: 81.173% (5247/6464)
Loss: 0.734 | Acc: 81.810% (10524/12864)
Loss: 0.734 | Acc: 81.852% (15768/19264)
Loss: 0.735 | Acc: 81.776% (20987/25664)
Loss: 0.736 | Acc: 81.646% (26179/32064)
Loss: 0.733 | Acc: 81.695% (31423/38464)
Loss: 0.734 | Acc: 81.714% (36660/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1168, Accuracy: 6922/10000 (69.22%)

Epoch: 166
Loss: 0.995 | Acc: 73.438% (47/64)
Loss: 0.731 | Acc: 81.528% (5270/6464)
Loss: 0.728 | Acc: 81.615% (10499/12864)
Loss: 0.723 | Acc: 81.499% (15700/19264)
Loss: 0.730 | Acc: 81.394% (20889/25664)
Loss: 0.731 | Acc: 81.450% (26116/32064)
Loss: 0.736 | Acc: 81.294% (31269/38464)
Loss: 0.735 | Acc: 81.373% (36507/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1990, Accuracy: 6695/10000 (66.95%)

Epoch: 167
Loss: 0.646 | Acc: 81.250% (52/64)
Loss: 0.701 | Acc: 82.379% (5325/6464)
Loss: 0.707 | Acc: 82.416% (10602/12864)
Loss: 0.717 | Acc: 82.278% (15850/19264)
Loss: 0.714 | Acc: 82.337% (21131/25664)
Loss: 0.717 | Acc: 82.260% (26376/32064)
Loss: 0.721 | Acc: 82.121% (31587/38464)
Loss: 0.723 | Acc: 82.097% (36832/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2363, Accuracy: 6553/10000 (65.53%)

Epoch: 168
Loss: 0.589 | Acc: 76.562% (49/64)
Loss: 0.698 | Acc: 82.379% (5325/6464)
Loss: 0.713 | Acc: 82.090% (10560/12864)
Loss: 0.718 | Acc: 81.831% (15764/19264)
Loss: 0.717 | Acc: 81.885% (21015/25664)
Loss: 0.719 | Acc: 81.936% (26272/32064)
Loss: 0.721 | Acc: 81.908% (31505/38464)
Loss: 0.720 | Acc: 81.981% (36780/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2244, Accuracy: 6592/10000 (65.92%)

Epoch: 169
Loss: 0.804 | Acc: 75.000% (48/64)
Loss: 0.692 | Acc: 82.627% (5341/6464)
Loss: 0.705 | Acc: 82.346% (10593/12864)
Loss: 0.710 | Acc: 82.252% (15845/19264)
Loss: 0.711 | Acc: 82.201% (21096/25664)
Loss: 0.715 | Acc: 82.186% (26352/32064)
Loss: 0.715 | Acc: 82.280% (31648/38464)
Loss: 0.714 | Acc: 82.273% (36911/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1039, Accuracy: 6962/10000 (69.62%)

Epoch: 170
Loss: 1.030 | Acc: 75.000% (48/64)
Loss: 0.703 | Acc: 82.580% (5338/6464)
Loss: 0.697 | Acc: 82.649% (10632/12864)
Loss: 0.711 | Acc: 82.454% (15884/19264)
Loss: 0.710 | Acc: 82.466% (21164/25664)
Loss: 0.711 | Acc: 82.426% (26429/32064)
Loss: 0.706 | Acc: 82.550% (31752/38464)
Loss: 0.710 | Acc: 82.507% (37016/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3811, Accuracy: 6303/10000 (63.03%)

Epoch: 171
Loss: 1.041 | Acc: 68.750% (44/64)
Loss: 0.673 | Acc: 83.509% (5398/6464)
Loss: 0.682 | Acc: 83.349% (10722/12864)
Loss: 0.688 | Acc: 83.124% (16013/19264)
Loss: 0.693 | Acc: 82.933% (21284/25664)
Loss: 0.690 | Acc: 82.956% (26599/32064)
Loss: 0.693 | Acc: 82.935% (31900/38464)
Loss: 0.692 | Acc: 83.009% (37241/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0378, Accuracy: 7267/10000 (72.67%)

Epoch: 172
Loss: 1.128 | Acc: 73.438% (47/64)
Loss: 0.689 | Acc: 82.704% (5346/6464)
Loss: 0.678 | Acc: 83.333% (10720/12864)
Loss: 0.671 | Acc: 83.596% (16104/19264)
Loss: 0.672 | Acc: 83.588% (21452/25664)
Loss: 0.673 | Acc: 83.626% (26814/32064)
Loss: 0.677 | Acc: 83.473% (32107/38464)
Loss: 0.681 | Acc: 83.410% (37421/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6850, Accuracy: 5272/10000 (52.72%)

Epoch: 173
Loss: 0.677 | Acc: 84.375% (54/64)
Loss: 0.680 | Acc: 83.122% (5373/6464)
Loss: 0.663 | Acc: 83.675% (10764/12864)
Loss: 0.670 | Acc: 83.622% (16109/19264)
Loss: 0.670 | Acc: 83.658% (21470/25664)
Loss: 0.672 | Acc: 83.667% (26827/32064)
Loss: 0.673 | Acc: 83.644% (32173/38464)
Loss: 0.673 | Acc: 83.666% (37536/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6997, Accuracy: 5306/10000 (53.06%)

Epoch: 174
Loss: 0.824 | Acc: 75.000% (48/64)
Loss: 0.660 | Acc: 84.066% (5434/6464)
Loss: 0.664 | Acc: 83.854% (10787/12864)
Loss: 0.659 | Acc: 84.064% (16194/19264)
Loss: 0.668 | Acc: 83.818% (21511/25664)
Loss: 0.665 | Acc: 83.923% (26909/32064)
Loss: 0.664 | Acc: 83.930% (32283/38464)
Loss: 0.667 | Acc: 83.865% (37625/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8312, Accuracy: 7885/10000 (78.85%)

Epoch: 175
Loss: 0.617 | Acc: 82.812% (53/64)
Loss: 0.639 | Acc: 84.684% (5474/6464)
Loss: 0.631 | Acc: 84.771% (10905/12864)
Loss: 0.636 | Acc: 84.671% (16311/19264)
Loss: 0.645 | Acc: 84.535% (21695/25664)
Loss: 0.640 | Acc: 84.665% (27147/32064)
Loss: 0.645 | Acc: 84.560% (32525/38464)
Loss: 0.649 | Acc: 84.498% (37909/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6007, Accuracy: 5767/10000 (57.67%)

Epoch: 176
Loss: 0.757 | Acc: 82.812% (53/64)
Loss: 0.642 | Acc: 84.623% (5470/6464)
Loss: 0.647 | Acc: 84.499% (10870/12864)
Loss: 0.645 | Acc: 84.479% (16274/19264)
Loss: 0.648 | Acc: 84.383% (21656/25664)
Loss: 0.646 | Acc: 84.469% (27084/32064)
Loss: 0.644 | Acc: 84.497% (32501/38464)
Loss: 0.643 | Acc: 84.457% (37891/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1090, Accuracy: 7050/10000 (70.50%)

Epoch: 177
Loss: 0.554 | Acc: 87.500% (56/64)
Loss: 0.655 | Acc: 84.499% (5462/6464)
Loss: 0.632 | Acc: 85.075% (10944/12864)
Loss: 0.633 | Acc: 84.946% (16364/19264)
Loss: 0.632 | Acc: 84.917% (21793/25664)
Loss: 0.633 | Acc: 84.899% (27222/32064)
Loss: 0.638 | Acc: 84.770% (32606/38464)
Loss: 0.635 | Acc: 84.850% (38067/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9395, Accuracy: 7566/10000 (75.66%)

Epoch: 178
Loss: 0.567 | Acc: 87.500% (56/64)
Loss: 0.584 | Acc: 86.061% (5563/6464)
Loss: 0.600 | Acc: 85.875% (11047/12864)
Loss: 0.606 | Acc: 85.636% (16497/19264)
Loss: 0.610 | Acc: 85.532% (21951/25664)
Loss: 0.616 | Acc: 85.407% (27385/32064)
Loss: 0.617 | Acc: 85.379% (32840/38464)
Loss: 0.616 | Acc: 85.487% (38353/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2126, Accuracy: 6692/10000 (66.92%)

Epoch: 179
Loss: 0.658 | Acc: 82.812% (53/64)
Loss: 0.623 | Acc: 84.808% (5482/6464)
Loss: 0.608 | Acc: 85.424% (10989/12864)
Loss: 0.600 | Acc: 85.662% (16502/19264)
Loss: 0.599 | Acc: 85.750% (22007/25664)
Loss: 0.603 | Acc: 85.713% (27483/32064)
Loss: 0.599 | Acc: 85.828% (33013/38464)
Loss: 0.600 | Acc: 85.828% (38506/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8023, Accuracy: 8061/10000 (80.61%)

Epoch: 180
Loss: 0.460 | Acc: 89.062% (57/64)
Loss: 0.587 | Acc: 86.092% (5565/6464)
Loss: 0.596 | Acc: 85.665% (11020/12864)
Loss: 0.592 | Acc: 85.917% (16551/19264)
Loss: 0.585 | Acc: 86.222% (22128/25664)
Loss: 0.589 | Acc: 86.134% (27618/32064)
Loss: 0.591 | Acc: 86.104% (33119/38464)
Loss: 0.588 | Acc: 86.194% (38670/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9598, Accuracy: 7532/10000 (75.32%)

Epoch: 181
Loss: 0.699 | Acc: 85.938% (55/64)
Loss: 0.565 | Acc: 86.696% (5604/6464)
Loss: 0.550 | Acc: 87.002% (11192/12864)
Loss: 0.560 | Acc: 86.778% (16717/19264)
Loss: 0.566 | Acc: 86.608% (22227/25664)
Loss: 0.567 | Acc: 86.602% (27768/32064)
Loss: 0.572 | Acc: 86.481% (33264/38464)
Loss: 0.575 | Acc: 86.452% (38786/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8196, Accuracy: 8020/10000 (80.20%)

Epoch: 182
Loss: 0.697 | Acc: 82.812% (53/64)
Loss: 0.540 | Acc: 87.314% (5644/6464)
Loss: 0.527 | Acc: 87.741% (11287/12864)
Loss: 0.541 | Acc: 87.458% (16848/19264)
Loss: 0.541 | Acc: 87.504% (22457/25664)
Loss: 0.549 | Acc: 87.300% (27992/32064)
Loss: 0.551 | Acc: 87.237% (33555/38464)
Loss: 0.553 | Acc: 87.215% (39128/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7799, Accuracy: 8201/10000 (82.01%)

Epoch: 183
Loss: 0.480 | Acc: 92.188% (59/64)
Loss: 0.501 | Acc: 88.382% (5713/6464)
Loss: 0.520 | Acc: 88.200% (11346/12864)
Loss: 0.530 | Acc: 87.848% (16923/19264)
Loss: 0.532 | Acc: 87.792% (22531/25664)
Loss: 0.529 | Acc: 87.852% (28169/32064)
Loss: 0.531 | Acc: 87.789% (33767/38464)
Loss: 0.533 | Acc: 87.723% (39356/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9363, Accuracy: 7710/10000 (77.10%)

Epoch: 184
Loss: 0.663 | Acc: 85.938% (55/64)
Loss: 0.504 | Acc: 88.212% (5702/6464)
Loss: 0.512 | Acc: 87.990% (11319/12864)
Loss: 0.514 | Acc: 87.962% (16945/19264)
Loss: 0.514 | Acc: 88.003% (22585/25664)
Loss: 0.515 | Acc: 87.902% (28185/32064)
Loss: 0.516 | Acc: 87.885% (33804/38464)
Loss: 0.516 | Acc: 87.903% (39437/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8408, Accuracy: 8012/10000 (80.12%)

Epoch: 185
Loss: 0.502 | Acc: 85.938% (55/64)
Loss: 0.480 | Acc: 88.830% (5742/6464)
Loss: 0.477 | Acc: 88.868% (11432/12864)
Loss: 0.485 | Acc: 88.730% (17093/19264)
Loss: 0.498 | Acc: 88.353% (22675/25664)
Loss: 0.497 | Acc: 88.404% (28346/32064)
Loss: 0.497 | Acc: 88.454% (34023/38464)
Loss: 0.499 | Acc: 88.445% (39680/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4689, Accuracy: 6526/10000 (65.26%)

Epoch: 186
Loss: 0.407 | Acc: 90.625% (58/64)
Loss: 0.472 | Acc: 88.908% (5747/6464)
Loss: 0.471 | Acc: 88.954% (11443/12864)
Loss: 0.474 | Acc: 88.834% (17113/19264)
Loss: 0.477 | Acc: 88.911% (22818/25664)
Loss: 0.479 | Acc: 88.919% (28511/32064)
Loss: 0.479 | Acc: 88.847% (34174/38464)
Loss: 0.477 | Acc: 88.840% (39857/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8703, Accuracy: 7995/10000 (79.95%)

Epoch: 187
Loss: 0.313 | Acc: 95.312% (61/64)
Loss: 0.435 | Acc: 89.867% (5809/6464)
Loss: 0.433 | Acc: 90.081% (11588/12864)
Loss: 0.441 | Acc: 89.722% (17284/19264)
Loss: 0.446 | Acc: 89.627% (23002/25664)
Loss: 0.445 | Acc: 89.605% (28731/32064)
Loss: 0.449 | Acc: 89.520% (34433/38464)
Loss: 0.449 | Acc: 89.479% (40144/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8233, Accuracy: 8169/10000 (81.69%)

Epoch: 188
Loss: 0.627 | Acc: 87.500% (56/64)
Loss: 0.419 | Acc: 89.743% (5801/6464)
Loss: 0.416 | Acc: 89.925% (11568/12864)
Loss: 0.417 | Acc: 90.054% (17348/19264)
Loss: 0.422 | Acc: 89.982% (23093/25664)
Loss: 0.424 | Acc: 89.961% (28845/32064)
Loss: 0.423 | Acc: 90.053% (34638/38464)
Loss: 0.423 | Acc: 90.032% (40392/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8331, Accuracy: 8138/10000 (81.38%)

Epoch: 189
Loss: 0.200 | Acc: 96.875% (62/64)
Loss: 0.364 | Acc: 91.569% (5919/6464)
Loss: 0.376 | Acc: 91.107% (11720/12864)
Loss: 0.383 | Acc: 90.942% (17519/19264)
Loss: 0.385 | Acc: 90.925% (23335/25664)
Loss: 0.388 | Acc: 90.809% (29117/32064)
Loss: 0.390 | Acc: 90.791% (34922/38464)
Loss: 0.391 | Acc: 90.745% (40712/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8607, Accuracy: 8158/10000 (81.58%)

Epoch: 190
Loss: 0.328 | Acc: 92.188% (59/64)
Loss: 0.347 | Acc: 91.723% (5929/6464)
Loss: 0.342 | Acc: 91.830% (11813/12864)
Loss: 0.353 | Acc: 91.606% (17647/19264)
Loss: 0.355 | Acc: 91.517% (23487/25664)
Loss: 0.353 | Acc: 91.589% (29367/32064)
Loss: 0.355 | Acc: 91.512% (35199/38464)
Loss: 0.356 | Acc: 91.450% (41028/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9014, Accuracy: 8080/10000 (80.80%)

Epoch: 191
Loss: 0.318 | Acc: 92.188% (59/64)
Loss: 0.304 | Acc: 92.512% (5980/6464)
Loss: 0.307 | Acc: 92.444% (11892/12864)
Loss: 0.314 | Acc: 92.286% (17778/19264)
Loss: 0.314 | Acc: 92.273% (23681/25664)
Loss: 0.315 | Acc: 92.259% (29582/32064)
Loss: 0.320 | Acc: 92.120% (35433/38464)
Loss: 0.320 | Acc: 92.134% (41335/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8761, Accuracy: 8197/10000 (81.97%)

Epoch: 192
Loss: 0.155 | Acc: 98.438% (63/64)
Loss: 0.288 | Acc: 92.946% (6008/6464)
Loss: 0.276 | Acc: 93.097% (11976/12864)
Loss: 0.278 | Acc: 93.002% (17916/19264)
Loss: 0.282 | Acc: 92.846% (23828/25664)
Loss: 0.285 | Acc: 92.808% (29758/32064)
Loss: 0.284 | Acc: 92.819% (35702/38464)
Loss: 0.286 | Acc: 92.771% (41621/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9545, Accuracy: 8143/10000 (81.43%)

Epoch: 193
Loss: 0.168 | Acc: 96.875% (62/64)
Loss: 0.262 | Acc: 93.502% (6044/6464)
Loss: 0.256 | Acc: 93.517% (12030/12864)
Loss: 0.254 | Acc: 93.589% (18029/19264)
Loss: 0.257 | Acc: 93.493% (23994/25664)
Loss: 0.253 | Acc: 93.597% (30011/32064)
Loss: 0.252 | Acc: 93.638% (36017/38464)
Loss: 0.251 | Acc: 93.665% (42022/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9474, Accuracy: 8179/10000 (81.79%)

Epoch: 194
Loss: 0.220 | Acc: 93.750% (60/64)
Loss: 0.208 | Acc: 94.493% (6108/6464)
Loss: 0.219 | Acc: 94.317% (12133/12864)
Loss: 0.216 | Acc: 94.357% (18177/19264)
Loss: 0.218 | Acc: 94.268% (24193/25664)
Loss: 0.220 | Acc: 94.265% (30225/32064)
Loss: 0.221 | Acc: 94.249% (36252/38464)
Loss: 0.220 | Acc: 94.296% (42305/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9645, Accuracy: 8190/10000 (81.90%)

Epoch: 195
Loss: 0.244 | Acc: 92.188% (59/64)
Loss: 0.193 | Acc: 94.926% (6136/6464)
Loss: 0.188 | Acc: 94.924% (12211/12864)
Loss: 0.191 | Acc: 94.814% (18265/19264)
Loss: 0.192 | Acc: 94.829% (24337/25664)
Loss: 0.194 | Acc: 94.760% (30384/32064)
Loss: 0.193 | Acc: 94.816% (36470/38464)
Loss: 0.194 | Acc: 94.809% (42535/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9658, Accuracy: 8245/10000 (82.45%)

Epoch: 196
Loss: 0.323 | Acc: 90.625% (58/64)
Loss: 0.169 | Acc: 95.545% (6176/6464)
Loss: 0.171 | Acc: 95.390% (12271/12864)
Loss: 0.177 | Acc: 95.193% (18338/19264)
Loss: 0.174 | Acc: 95.274% (24451/25664)
Loss: 0.171 | Acc: 95.403% (30590/32064)
Loss: 0.172 | Acc: 95.362% (36680/38464)
Loss: 0.171 | Acc: 95.346% (42776/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9710, Accuracy: 8222/10000 (82.22%)

Epoch: 197
Loss: 0.087 | Acc: 98.438% (63/64)
Loss: 0.152 | Acc: 95.900% (6199/6464)
Loss: 0.159 | Acc: 95.779% (12321/12864)
Loss: 0.160 | Acc: 95.697% (18435/19264)
Loss: 0.159 | Acc: 95.745% (24572/25664)
Loss: 0.160 | Acc: 95.677% (30678/32064)
Loss: 0.160 | Acc: 95.705% (36812/38464)
Loss: 0.161 | Acc: 95.618% (42898/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9798, Accuracy: 8227/10000 (82.27%)
torch.Size([100, 10])
Test set: Average loss: 0.9798, Accuracy: 8227/10000 (82.27%)

Epoch: 198
Loss: 0.256 | Acc: 92.188% (59/64)
Loss: 0.162 | Acc: 95.622% (6181/6464)
Loss: 0.155 | Acc: 95.903% (12337/12864)
Loss: 0.153 | Acc: 95.852% (18465/19264)
Loss: 0.153 | Acc: 95.823% (24592/25664)
Loss: 0.152 | Acc: 95.830% (30727/32064)
Loss: 0.152 | Acc: 95.825% (36858/38464)
Loss: 0.152 | Acc: 95.834% (42995/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9779, Accuracy: 8211/10000 (82.11%)
torch.Size([100, 10])
Test set: Average loss: 0.9779, Accuracy: 8211/10000 (82.11%)

Epoch: 199
Loss: 0.065 | Acc: 98.438% (63/64)
Loss: 0.159 | Acc: 95.545% (6176/6464)
Loss: 0.152 | Acc: 95.787% (12322/12864)
Loss: 0.151 | Acc: 95.769% (18449/19264)
Loss: 0.151 | Acc: 95.772% (24579/25664)
Loss: 0.152 | Acc: 95.768% (30707/32064)
Loss: 0.150 | Acc: 95.856% (36870/38464)
Loss: 0.149 | Acc: 95.872% (43012/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9850, Accuracy: 8204/10000 (82.04%)
torch.Size([100, 10])
Test set: Average loss: 0.9850, Accuracy: 8204/10000 (82.04%)
8471
10000
-0.7860364317893982
