==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.403 | Acc: 12.500% (8/64)
Loss: 2.884 | Acc: 13.923% (900/6464)
Loss: 2.521 | Acc: 17.110% (2201/12864)
Loss: 2.383 | Acc: 19.030% (3666/19264)
Loss: 2.300 | Acc: 20.519% (5266/25664)
Loss: 2.246 | Acc: 21.735% (6969/32064)
Loss: 2.209 | Acc: 22.650% (8712/38464)
Loss: 2.174 | Acc: 23.752% (10656/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4353, Accuracy: 2300/10000 (23.00%)

Epoch: 1
Loss: 2.360 | Acc: 15.625% (10/64)
Loss: 1.923 | Acc: 32.147% (2078/6464)
Loss: 1.922 | Acc: 32.455% (4175/12864)
Loss: 1.912 | Acc: 33.062% (6369/19264)
Loss: 1.905 | Acc: 33.366% (8563/25664)
Loss: 1.898 | Acc: 33.832% (10848/32064)
Loss: 1.889 | Acc: 34.305% (13195/38464)
Loss: 1.882 | Acc: 34.765% (15597/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0126, Accuracy: 3383/10000 (33.83%)

Epoch: 2
Loss: 1.609 | Acc: 42.188% (27/64)
Loss: 1.812 | Acc: 38.057% (2460/6464)
Loss: 1.804 | Acc: 38.386% (4938/12864)
Loss: 1.793 | Acc: 39.073% (7527/19264)
Loss: 1.786 | Acc: 39.518% (10142/25664)
Loss: 1.777 | Acc: 39.951% (12810/32064)
Loss: 1.773 | Acc: 40.430% (15551/38464)
Loss: 1.768 | Acc: 40.618% (18223/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9027, Accuracy: 3773/10000 (37.73%)

Epoch: 3
Loss: 2.126 | Acc: 21.875% (14/64)
Loss: 1.699 | Acc: 43.441% (2808/6464)
Loss: 1.713 | Acc: 43.758% (5629/12864)
Loss: 1.694 | Acc: 44.747% (8620/19264)
Loss: 1.688 | Acc: 45.114% (11578/25664)
Loss: 1.682 | Acc: 45.347% (14540/32064)
Loss: 1.672 | Acc: 45.851% (17636/38464)
Loss: 1.662 | Acc: 46.266% (20757/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8937, Accuracy: 3748/10000 (37.48%)

Epoch: 4
Loss: 1.722 | Acc: 39.062% (25/64)
Loss: 1.585 | Acc: 50.789% (3283/6464)
Loss: 1.581 | Acc: 50.396% (6483/12864)
Loss: 1.578 | Acc: 50.763% (9779/19264)
Loss: 1.570 | Acc: 50.970% (13081/25664)
Loss: 1.568 | Acc: 51.048% (16368/32064)
Loss: 1.561 | Acc: 51.321% (19740/38464)
Loss: 1.556 | Acc: 51.507% (23108/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5985, Accuracy: 5120/10000 (51.20%)

Epoch: 5
Loss: 1.858 | Acc: 46.875% (30/64)
Loss: 1.507 | Acc: 53.868% (3482/6464)
Loss: 1.518 | Acc: 53.335% (6861/12864)
Loss: 1.508 | Acc: 53.654% (10336/19264)
Loss: 1.504 | Acc: 53.787% (13804/25664)
Loss: 1.495 | Acc: 54.173% (17370/32064)
Loss: 1.496 | Acc: 54.095% (20807/38464)
Loss: 1.492 | Acc: 54.293% (24358/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3896, Accuracy: 2991/10000 (29.91%)

Epoch: 6
Loss: 1.664 | Acc: 48.438% (31/64)
Loss: 1.465 | Acc: 56.405% (3646/6464)
Loss: 1.464 | Acc: 56.025% (7207/12864)
Loss: 1.461 | Acc: 56.151% (10817/19264)
Loss: 1.450 | Acc: 56.468% (14492/25664)
Loss: 1.444 | Acc: 56.721% (18187/32064)
Loss: 1.444 | Acc: 56.718% (21816/38464)
Loss: 1.443 | Acc: 56.758% (25464/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1284, Accuracy: 3238/10000 (32.38%)

Epoch: 7
Loss: 1.639 | Acc: 45.312% (29/64)
Loss: 1.429 | Acc: 57.859% (3740/6464)
Loss: 1.412 | Acc: 58.193% (7486/12864)
Loss: 1.409 | Acc: 58.337% (11238/19264)
Loss: 1.403 | Acc: 58.642% (15050/25664)
Loss: 1.399 | Acc: 58.864% (18874/32064)
Loss: 1.399 | Acc: 58.881% (22648/38464)
Loss: 1.393 | Acc: 59.079% (26505/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4986, Accuracy: 5589/10000 (55.89%)

Epoch: 8
Loss: 1.286 | Acc: 60.938% (39/64)
Loss: 1.376 | Acc: 59.793% (3865/6464)
Loss: 1.361 | Acc: 60.347% (7763/12864)
Loss: 1.357 | Acc: 60.616% (11677/19264)
Loss: 1.357 | Acc: 60.754% (15592/25664)
Loss: 1.349 | Acc: 61.022% (19566/32064)
Loss: 1.348 | Acc: 61.112% (23506/38464)
Loss: 1.345 | Acc: 61.198% (27456/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7863, Accuracy: 4774/10000 (47.74%)

Epoch: 9
Loss: 1.491 | Acc: 54.688% (35/64)
Loss: 1.294 | Acc: 63.134% (4081/6464)
Loss: 1.312 | Acc: 62.500% (8040/12864)
Loss: 1.321 | Acc: 62.235% (11989/19264)
Loss: 1.319 | Acc: 62.383% (16010/25664)
Loss: 1.320 | Acc: 62.459% (20027/32064)
Loss: 1.319 | Acc: 62.425% (24011/38464)
Loss: 1.314 | Acc: 62.600% (28085/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5262, Accuracy: 5328/10000 (53.28%)

Epoch: 10
Loss: 1.144 | Acc: 71.875% (46/64)
Loss: 1.284 | Acc: 63.954% (4134/6464)
Loss: 1.288 | Acc: 63.775% (8204/12864)
Loss: 1.288 | Acc: 63.813% (12293/19264)
Loss: 1.282 | Acc: 64.090% (16448/25664)
Loss: 1.285 | Acc: 64.109% (20556/32064)
Loss: 1.289 | Acc: 64.000% (24617/38464)
Loss: 1.287 | Acc: 63.980% (28704/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4890, Accuracy: 5706/10000 (57.06%)

Epoch: 11
Loss: 1.246 | Acc: 65.625% (42/64)
Loss: 1.270 | Acc: 64.511% (4170/6464)
Loss: 1.272 | Acc: 64.894% (8348/12864)
Loss: 1.268 | Acc: 64.966% (12515/19264)
Loss: 1.273 | Acc: 64.846% (16642/25664)
Loss: 1.271 | Acc: 64.842% (20791/32064)
Loss: 1.266 | Acc: 64.988% (24997/38464)
Loss: 1.266 | Acc: 64.943% (29136/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4571, Accuracy: 5781/10000 (57.81%)

Epoch: 12
Loss: 1.299 | Acc: 59.375% (38/64)
Loss: 1.250 | Acc: 64.898% (4195/6464)
Loss: 1.250 | Acc: 65.322% (8403/12864)
Loss: 1.250 | Acc: 65.412% (12601/19264)
Loss: 1.250 | Acc: 65.418% (16789/25664)
Loss: 1.253 | Acc: 65.410% (20973/32064)
Loss: 1.250 | Acc: 65.529% (25205/38464)
Loss: 1.252 | Acc: 65.489% (29381/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4177, Accuracy: 5887/10000 (58.87%)

Epoch: 13
Loss: 1.376 | Acc: 65.625% (42/64)
Loss: 1.230 | Acc: 66.708% (4312/6464)
Loss: 1.234 | Acc: 66.379% (8539/12864)
Loss: 1.229 | Acc: 66.476% (12806/19264)
Loss: 1.235 | Acc: 66.334% (17024/25664)
Loss: 1.231 | Acc: 66.526% (21331/32064)
Loss: 1.233 | Acc: 66.405% (25542/38464)
Loss: 1.235 | Acc: 66.336% (29761/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5296, Accuracy: 5585/10000 (55.85%)

Epoch: 14
Loss: 1.375 | Acc: 64.062% (41/64)
Loss: 1.243 | Acc: 65.996% (4266/6464)
Loss: 1.225 | Acc: 66.325% (8532/12864)
Loss: 1.228 | Acc: 66.217% (12756/19264)
Loss: 1.227 | Acc: 66.439% (17051/25664)
Loss: 1.224 | Acc: 66.504% (21324/32064)
Loss: 1.221 | Acc: 66.582% (25610/38464)
Loss: 1.223 | Acc: 66.554% (29859/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7247, Accuracy: 4740/10000 (47.40%)

Epoch: 15
Loss: 1.463 | Acc: 59.375% (38/64)
Loss: 1.211 | Acc: 66.723% (4313/6464)
Loss: 1.209 | Acc: 67.040% (8624/12864)
Loss: 1.210 | Acc: 67.032% (12913/19264)
Loss: 1.209 | Acc: 67.117% (17225/25664)
Loss: 1.202 | Acc: 67.294% (21577/32064)
Loss: 1.207 | Acc: 67.180% (25840/38464)
Loss: 1.206 | Acc: 67.192% (30145/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5689, Accuracy: 5416/10000 (54.16%)

Epoch: 16
Loss: 1.545 | Acc: 53.125% (34/64)
Loss: 1.187 | Acc: 67.837% (4385/6464)
Loss: 1.178 | Acc: 68.284% (8784/12864)
Loss: 1.186 | Acc: 68.054% (13110/19264)
Loss: 1.194 | Acc: 67.714% (17378/25664)
Loss: 1.191 | Acc: 67.839% (21752/32064)
Loss: 1.195 | Acc: 67.843% (26095/38464)
Loss: 1.188 | Acc: 67.923% (30473/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4112, Accuracy: 5975/10000 (59.75%)

Epoch: 17
Loss: 1.162 | Acc: 65.625% (42/64)
Loss: 1.166 | Acc: 69.756% (4509/6464)
Loss: 1.183 | Acc: 68.563% (8820/12864)
Loss: 1.184 | Acc: 68.366% (13170/19264)
Loss: 1.179 | Acc: 68.536% (17589/25664)
Loss: 1.179 | Acc: 68.535% (21975/32064)
Loss: 1.180 | Acc: 68.589% (26382/38464)
Loss: 1.178 | Acc: 68.598% (30776/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4835, Accuracy: 5773/10000 (57.73%)

Epoch: 18
Loss: 1.208 | Acc: 67.188% (43/64)
Loss: 1.131 | Acc: 69.910% (4519/6464)
Loss: 1.141 | Acc: 69.675% (8963/12864)
Loss: 1.155 | Acc: 69.472% (13383/19264)
Loss: 1.159 | Acc: 69.401% (17811/25664)
Loss: 1.159 | Acc: 69.299% (22220/32064)
Loss: 1.165 | Acc: 69.000% (26540/38464)
Loss: 1.165 | Acc: 68.995% (30954/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4142, Accuracy: 6087/10000 (60.87%)

Epoch: 19
Loss: 1.674 | Acc: 54.688% (35/64)
Loss: 1.157 | Acc: 69.075% (4465/6464)
Loss: 1.156 | Acc: 69.372% (8924/12864)
Loss: 1.146 | Acc: 69.700% (13427/19264)
Loss: 1.142 | Acc: 69.977% (17959/25664)
Loss: 1.148 | Acc: 69.698% (22348/32064)
Loss: 1.152 | Acc: 69.665% (26796/38464)
Loss: 1.152 | Acc: 69.671% (31257/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4532, Accuracy: 5747/10000 (57.47%)

Epoch: 20
Loss: 1.084 | Acc: 71.875% (46/64)
Loss: 1.125 | Acc: 70.637% (4566/6464)
Loss: 1.134 | Acc: 70.180% (9028/12864)
Loss: 1.135 | Acc: 70.126% (13509/19264)
Loss: 1.134 | Acc: 70.250% (18029/25664)
Loss: 1.140 | Acc: 70.166% (22498/32064)
Loss: 1.141 | Acc: 70.144% (26980/38464)
Loss: 1.142 | Acc: 70.130% (31463/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5246, Accuracy: 5595/10000 (55.95%)

Epoch: 21
Loss: 1.039 | Acc: 73.438% (47/64)
Loss: 1.125 | Acc: 70.312% (4545/6464)
Loss: 1.123 | Acc: 70.227% (9034/12864)
Loss: 1.123 | Acc: 70.432% (13568/19264)
Loss: 1.130 | Acc: 70.223% (18022/25664)
Loss: 1.130 | Acc: 70.300% (22541/32064)
Loss: 1.133 | Acc: 70.214% (27007/38464)
Loss: 1.133 | Acc: 70.263% (31523/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4036, Accuracy: 6092/10000 (60.92%)

Epoch: 22
Loss: 0.966 | Acc: 78.125% (50/64)
Loss: 1.110 | Acc: 71.225% (4604/6464)
Loss: 1.121 | Acc: 70.911% (9122/12864)
Loss: 1.119 | Acc: 71.013% (13680/19264)
Loss: 1.123 | Acc: 70.913% (18199/25664)
Loss: 1.115 | Acc: 71.070% (22788/32064)
Loss: 1.117 | Acc: 71.027% (27320/38464)
Loss: 1.114 | Acc: 71.095% (31896/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7130, Accuracy: 5022/10000 (50.22%)

Epoch: 23
Loss: 1.031 | Acc: 73.438% (47/64)
Loss: 1.086 | Acc: 72.447% (4683/6464)
Loss: 1.095 | Acc: 71.976% (9259/12864)
Loss: 1.103 | Acc: 71.828% (13837/19264)
Loss: 1.106 | Acc: 71.668% (18393/25664)
Loss: 1.108 | Acc: 71.445% (22908/32064)
Loss: 1.104 | Acc: 71.529% (27513/38464)
Loss: 1.104 | Acc: 71.485% (32071/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3504, Accuracy: 6239/10000 (62.39%)

Epoch: 24
Loss: 1.166 | Acc: 71.875% (46/64)
Loss: 1.098 | Acc: 71.612% (4629/6464)
Loss: 1.109 | Acc: 71.354% (9179/12864)
Loss: 1.101 | Acc: 71.673% (13807/19264)
Loss: 1.106 | Acc: 71.610% (18378/25664)
Loss: 1.101 | Acc: 71.691% (22987/32064)
Loss: 1.098 | Acc: 71.703% (27580/38464)
Loss: 1.099 | Acc: 71.674% (32156/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3274, Accuracy: 6428/10000 (64.28%)

Epoch: 25
Loss: 1.231 | Acc: 67.188% (43/64)
Loss: 1.066 | Acc: 72.803% (4706/6464)
Loss: 1.080 | Acc: 72.388% (9312/12864)
Loss: 1.080 | Acc: 72.379% (13943/19264)
Loss: 1.078 | Acc: 72.510% (18609/25664)
Loss: 1.082 | Acc: 72.418% (23220/32064)
Loss: 1.086 | Acc: 72.262% (27795/38464)
Loss: 1.085 | Acc: 72.278% (32427/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2702, Accuracy: 6633/10000 (66.33%)

Epoch: 26
Loss: 1.002 | Acc: 75.000% (48/64)
Loss: 1.090 | Acc: 71.798% (4641/6464)
Loss: 1.084 | Acc: 72.062% (9270/12864)
Loss: 1.076 | Acc: 72.316% (13931/19264)
Loss: 1.082 | Acc: 72.117% (18508/25664)
Loss: 1.083 | Acc: 72.193% (23148/32064)
Loss: 1.076 | Acc: 72.424% (27857/38464)
Loss: 1.072 | Acc: 72.555% (32551/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2544, Accuracy: 6693/10000 (66.93%)

Epoch: 27
Loss: 1.291 | Acc: 62.500% (40/64)
Loss: 1.089 | Acc: 72.447% (4683/6464)
Loss: 1.059 | Acc: 73.197% (9416/12864)
Loss: 1.063 | Acc: 73.033% (14069/19264)
Loss: 1.060 | Acc: 73.036% (18744/25664)
Loss: 1.058 | Acc: 73.144% (23453/32064)
Loss: 1.054 | Acc: 73.282% (28187/38464)
Loss: 1.057 | Acc: 73.217% (32848/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5745, Accuracy: 5769/10000 (57.69%)

Epoch: 28
Loss: 1.297 | Acc: 60.938% (39/64)
Loss: 1.043 | Acc: 73.778% (4769/6464)
Loss: 1.052 | Acc: 73.585% (9466/12864)
Loss: 1.036 | Acc: 73.988% (14253/19264)
Loss: 1.039 | Acc: 73.847% (18952/25664)
Loss: 1.036 | Acc: 73.899% (23695/32064)
Loss: 1.043 | Acc: 73.679% (28340/38464)
Loss: 1.044 | Acc: 73.663% (33048/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3967, Accuracy: 6038/10000 (60.38%)

Epoch: 29
Loss: 1.006 | Acc: 71.875% (46/64)
Loss: 1.006 | Acc: 74.799% (4835/6464)
Loss: 1.023 | Acc: 74.316% (9560/12864)
Loss: 1.015 | Acc: 74.517% (14355/19264)
Loss: 1.025 | Acc: 74.232% (19051/25664)
Loss: 1.028 | Acc: 74.145% (23774/32064)
Loss: 1.029 | Acc: 74.113% (28507/38464)
Loss: 1.024 | Acc: 74.233% (33304/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2524, Accuracy: 6683/10000 (66.83%)

Epoch: 30
Loss: 1.318 | Acc: 64.062% (41/64)
Loss: 0.993 | Acc: 75.232% (4863/6464)
Loss: 1.005 | Acc: 74.681% (9607/12864)
Loss: 1.004 | Acc: 74.751% (14400/19264)
Loss: 1.003 | Acc: 74.790% (19194/25664)
Loss: 1.011 | Acc: 74.638% (23932/32064)
Loss: 1.016 | Acc: 74.506% (28658/38464)
Loss: 1.015 | Acc: 74.617% (33476/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1872, Accuracy: 6945/10000 (69.45%)

Epoch: 31
Loss: 0.620 | Acc: 84.375% (54/64)
Loss: 0.977 | Acc: 75.712% (4894/6464)
Loss: 0.992 | Acc: 75.070% (9657/12864)
Loss: 0.994 | Acc: 75.171% (14481/19264)
Loss: 0.995 | Acc: 75.105% (19275/25664)
Loss: 0.999 | Acc: 74.994% (24046/32064)
Loss: 0.996 | Acc: 75.075% (28877/38464)
Loss: 1.000 | Acc: 74.971% (33635/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1746, Accuracy: 7054/10000 (70.54%)

Epoch: 32
Loss: 0.920 | Acc: 76.562% (49/64)
Loss: 0.972 | Acc: 76.021% (4914/6464)
Loss: 0.980 | Acc: 75.389% (9698/12864)
Loss: 0.985 | Acc: 75.389% (14523/19264)
Loss: 0.983 | Acc: 75.409% (19353/25664)
Loss: 0.981 | Acc: 75.499% (24208/32064)
Loss: 0.982 | Acc: 75.536% (29054/38464)
Loss: 0.983 | Acc: 75.504% (33874/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2539, Accuracy: 6716/10000 (67.16%)

Epoch: 33
Loss: 0.982 | Acc: 73.438% (47/64)
Loss: 0.928 | Acc: 76.872% (4969/6464)
Loss: 0.946 | Acc: 76.461% (9836/12864)
Loss: 0.942 | Acc: 76.588% (14754/19264)
Loss: 0.952 | Acc: 76.337% (19591/25664)
Loss: 0.950 | Acc: 76.416% (24502/32064)
Loss: 0.956 | Acc: 76.245% (29327/38464)
Loss: 0.960 | Acc: 76.237% (34203/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2199, Accuracy: 6862/10000 (68.62%)

Epoch: 34
Loss: 1.050 | Acc: 76.562% (49/64)
Loss: 0.924 | Acc: 77.506% (5010/6464)
Loss: 0.925 | Acc: 77.387% (9955/12864)
Loss: 0.928 | Acc: 77.227% (14877/19264)
Loss: 0.932 | Acc: 77.178% (19807/25664)
Loss: 0.935 | Acc: 77.043% (24703/32064)
Loss: 0.940 | Acc: 76.893% (29576/38464)
Loss: 0.943 | Acc: 76.868% (34486/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2318, Accuracy: 6848/10000 (68.48%)

Epoch: 35
Loss: 0.843 | Acc: 79.688% (51/64)
Loss: 0.871 | Acc: 78.434% (5070/6464)
Loss: 0.895 | Acc: 77.954% (10028/12864)
Loss: 0.899 | Acc: 77.829% (14993/19264)
Loss: 0.901 | Acc: 77.774% (19960/25664)
Loss: 0.907 | Acc: 77.657% (24900/32064)
Loss: 0.911 | Acc: 77.563% (29834/38464)
Loss: 0.914 | Acc: 77.499% (34769/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3041, Accuracy: 6601/10000 (66.01%)

Epoch: 36
Loss: 1.092 | Acc: 67.188% (43/64)
Loss: 0.889 | Acc: 77.738% (5025/6464)
Loss: 0.896 | Acc: 77.799% (10008/12864)
Loss: 0.890 | Acc: 78.083% (15042/19264)
Loss: 0.894 | Acc: 77.883% (19988/25664)
Loss: 0.899 | Acc: 77.751% (24930/32064)
Loss: 0.899 | Acc: 77.813% (29930/38464)
Loss: 0.899 | Acc: 77.817% (34912/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1924, Accuracy: 7069/10000 (70.69%)

Epoch: 37
Loss: 0.834 | Acc: 79.688% (51/64)
Loss: 0.865 | Acc: 78.666% (5085/6464)
Loss: 0.863 | Acc: 78.762% (10132/12864)
Loss: 0.857 | Acc: 78.826% (15185/19264)
Loss: 0.855 | Acc: 78.850% (20236/25664)
Loss: 0.861 | Acc: 78.702% (25235/32064)
Loss: 0.868 | Acc: 78.570% (30221/38464)
Loss: 0.871 | Acc: 78.484% (35211/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2168, Accuracy: 6964/10000 (69.64%)

Epoch: 38
Loss: 0.927 | Acc: 75.000% (48/64)
Loss: 0.831 | Acc: 78.991% (5106/6464)
Loss: 0.825 | Acc: 79.563% (10235/12864)
Loss: 0.830 | Acc: 79.464% (15308/19264)
Loss: 0.841 | Acc: 79.130% (20308/25664)
Loss: 0.843 | Acc: 79.098% (25362/32064)
Loss: 0.840 | Acc: 79.220% (30471/38464)
Loss: 0.842 | Acc: 79.202% (35533/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2552, Accuracy: 6872/10000 (68.72%)

Epoch: 39
Loss: 1.117 | Acc: 65.625% (42/64)
Loss: 0.783 | Acc: 80.569% (5208/6464)
Loss: 0.785 | Acc: 80.628% (10372/12864)
Loss: 0.793 | Acc: 80.362% (15481/19264)
Loss: 0.795 | Acc: 80.260% (20598/25664)
Loss: 0.802 | Acc: 80.015% (25656/32064)
Loss: 0.804 | Acc: 79.992% (30768/38464)
Loss: 0.810 | Acc: 79.886% (35840/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2281, Accuracy: 6988/10000 (69.88%)

Epoch: 40
Loss: 0.543 | Acc: 87.500% (56/64)
Loss: 0.761 | Acc: 80.848% (5226/6464)
Loss: 0.761 | Acc: 81.048% (10426/12864)
Loss: 0.768 | Acc: 80.892% (15583/19264)
Loss: 0.768 | Acc: 80.810% (20739/25664)
Loss: 0.772 | Acc: 80.720% (25882/32064)
Loss: 0.773 | Acc: 80.644% (31019/38464)
Loss: 0.771 | Acc: 80.713% (36211/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2349, Accuracy: 7147/10000 (71.47%)

Epoch: 41
Loss: 0.936 | Acc: 75.000% (48/64)
Loss: 0.717 | Acc: 82.008% (5301/6464)
Loss: 0.724 | Acc: 81.833% (10527/12864)
Loss: 0.722 | Acc: 81.733% (15745/19264)
Loss: 0.729 | Acc: 81.554% (20930/25664)
Loss: 0.730 | Acc: 81.553% (26149/32064)
Loss: 0.733 | Acc: 81.507% (31351/38464)
Loss: 0.733 | Acc: 81.460% (36546/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2898, Accuracy: 7040/10000 (70.40%)

Epoch: 42
Loss: 0.558 | Acc: 85.938% (55/64)
Loss: 0.687 | Acc: 82.116% (5308/6464)
Loss: 0.681 | Acc: 82.315% (10589/12864)
Loss: 0.682 | Acc: 82.241% (15843/19264)
Loss: 0.686 | Acc: 82.154% (21084/25664)
Loss: 0.686 | Acc: 82.245% (26371/32064)
Loss: 0.686 | Acc: 82.306% (31658/38464)
Loss: 0.683 | Acc: 82.438% (36985/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3240, Accuracy: 7043/10000 (70.43%)

Epoch: 43
Loss: 0.652 | Acc: 82.812% (53/64)
Loss: 0.642 | Acc: 83.215% (5379/6464)
Loss: 0.644 | Acc: 83.147% (10696/12864)
Loss: 0.642 | Acc: 83.140% (16016/19264)
Loss: 0.637 | Acc: 83.339% (21388/25664)
Loss: 0.636 | Acc: 83.365% (26730/32064)
Loss: 0.639 | Acc: 83.283% (32034/38464)
Loss: 0.640 | Acc: 83.323% (37382/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3537, Accuracy: 6995/10000 (69.95%)

Epoch: 44
Loss: 0.467 | Acc: 85.938% (55/64)
Loss: 0.589 | Acc: 83.973% (5428/6464)
Loss: 0.588 | Acc: 84.391% (10856/12864)
Loss: 0.587 | Acc: 84.567% (16291/19264)
Loss: 0.590 | Acc: 84.437% (21670/25664)
Loss: 0.592 | Acc: 84.272% (27021/32064)
Loss: 0.587 | Acc: 84.372% (32453/38464)
Loss: 0.588 | Acc: 84.404% (37867/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3574, Accuracy: 7037/10000 (70.37%)

Epoch: 45
Loss: 0.485 | Acc: 90.625% (58/64)
Loss: 0.530 | Acc: 86.092% (5565/6464)
Loss: 0.529 | Acc: 86.039% (11068/12864)
Loss: 0.535 | Acc: 85.828% (16534/19264)
Loss: 0.540 | Acc: 85.680% (21989/25664)
Loss: 0.538 | Acc: 85.735% (27490/32064)
Loss: 0.534 | Acc: 85.815% (33008/38464)
Loss: 0.533 | Acc: 85.855% (38518/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3892, Accuracy: 7032/10000 (70.32%)

Epoch: 46
Loss: 0.314 | Acc: 90.625% (58/64)
Loss: 0.492 | Acc: 86.402% (5585/6464)
Loss: 0.489 | Acc: 86.707% (11154/12864)
Loss: 0.486 | Acc: 86.758% (16713/19264)
Loss: 0.488 | Acc: 86.740% (22261/25664)
Loss: 0.487 | Acc: 86.858% (27850/32064)
Loss: 0.489 | Acc: 86.798% (33386/38464)
Loss: 0.490 | Acc: 86.749% (38919/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4044, Accuracy: 6975/10000 (69.75%)

Epoch: 47
Loss: 0.208 | Acc: 96.875% (62/64)
Loss: 0.479 | Acc: 86.603% (5598/6464)
Loss: 0.467 | Acc: 87.127% (11208/12864)
Loss: 0.467 | Acc: 87.147% (16788/19264)
Loss: 0.462 | Acc: 87.325% (22411/25664)
Loss: 0.464 | Acc: 87.282% (27986/32064)
Loss: 0.463 | Acc: 87.328% (33590/38464)
Loss: 0.460 | Acc: 87.406% (39214/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4220, Accuracy: 6988/10000 (69.88%)
torch.Size([100, 10])
Test set: Average loss: 1.4220, Accuracy: 6988/10000 (69.88%)

Epoch: 48
Loss: 0.460 | Acc: 87.500% (56/64)
Loss: 0.428 | Acc: 88.428% (5716/6464)
Loss: 0.437 | Acc: 87.928% (11311/12864)
Loss: 0.443 | Acc: 87.728% (16900/19264)
Loss: 0.444 | Acc: 87.742% (22518/25664)
Loss: 0.441 | Acc: 87.859% (28171/32064)
Loss: 0.442 | Acc: 87.765% (33758/38464)
Loss: 0.441 | Acc: 87.799% (39390/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4249, Accuracy: 6987/10000 (69.87%)
torch.Size([100, 10])
Test set: Average loss: 1.4249, Accuracy: 6987/10000 (69.87%)

Epoch: 49
Loss: 0.451 | Acc: 85.938% (55/64)
Loss: 0.440 | Acc: 88.103% (5695/6464)
Loss: 0.439 | Acc: 87.990% (11319/12864)
Loss: 0.436 | Acc: 87.983% (16949/19264)
Loss: 0.432 | Acc: 88.096% (22609/25664)
Loss: 0.431 | Acc: 88.136% (28260/32064)
Loss: 0.430 | Acc: 88.179% (33917/38464)
Loss: 0.429 | Acc: 88.173% (39558/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4312, Accuracy: 6988/10000 (69.88%)
torch.Size([100, 10])
Test set: Average loss: 1.4312, Accuracy: 6988/10000 (69.88%)

Epoch: 50
Loss: 0.270 | Acc: 92.188% (59/64)
Loss: 1.756 | Acc: 41.955% (2712/6464)
Loss: 1.547 | Acc: 51.850% (6670/12864)
Loss: 1.456 | Acc: 56.032% (10794/19264)
Loss: 1.411 | Acc: 58.303% (14963/25664)
Loss: 1.379 | Acc: 59.805% (19176/32064)
Loss: 1.352 | Acc: 60.919% (23432/38464)
Loss: 1.336 | Acc: 61.680% (27672/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5685, Accuracy: 5566/10000 (55.66%)

Epoch: 51
Loss: 1.235 | Acc: 59.375% (38/64)
Loss: 1.196 | Acc: 67.327% (4352/6464)
Loss: 1.193 | Acc: 67.778% (8719/12864)
Loss: 1.199 | Acc: 67.603% (13023/19264)
Loss: 1.199 | Acc: 67.639% (17359/25664)
Loss: 1.195 | Acc: 67.793% (21737/32064)
Loss: 1.191 | Acc: 67.926% (26127/38464)
Loss: 1.188 | Acc: 68.081% (30544/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3746, Accuracy: 6326/10000 (63.26%)

Epoch: 52
Loss: 1.145 | Acc: 73.438% (47/64)
Loss: 1.160 | Acc: 69.369% (4484/6464)
Loss: 1.165 | Acc: 68.874% (8860/12864)
Loss: 1.159 | Acc: 69.030% (13298/19264)
Loss: 1.162 | Acc: 69.034% (17717/25664)
Loss: 1.164 | Acc: 68.978% (22117/32064)
Loss: 1.163 | Acc: 68.976% (26531/38464)
Loss: 1.167 | Acc: 68.980% (30947/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5919, Accuracy: 5502/10000 (55.02%)

Epoch: 53
Loss: 1.296 | Acc: 65.625% (42/64)
Loss: 1.147 | Acc: 69.678% (4504/6464)
Loss: 1.149 | Acc: 69.761% (8974/12864)
Loss: 1.153 | Acc: 69.627% (13413/19264)
Loss: 1.157 | Acc: 69.537% (17846/25664)
Loss: 1.159 | Acc: 69.396% (22251/32064)
Loss: 1.155 | Acc: 69.442% (26710/38464)
Loss: 1.158 | Acc: 69.345% (31111/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7784, Accuracy: 5034/10000 (50.34%)

Epoch: 54
Loss: 1.166 | Acc: 67.188% (43/64)
Loss: 1.143 | Acc: 69.787% (4511/6464)
Loss: 1.153 | Acc: 69.558% (8948/12864)
Loss: 1.151 | Acc: 69.658% (13419/19264)
Loss: 1.147 | Acc: 69.701% (17888/25664)
Loss: 1.149 | Acc: 69.683% (22343/32064)
Loss: 1.151 | Acc: 69.639% (26786/38464)
Loss: 1.151 | Acc: 69.673% (31258/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7241, Accuracy: 4870/10000 (48.70%)

Epoch: 55
Loss: 1.413 | Acc: 53.125% (34/64)
Loss: 1.137 | Acc: 70.297% (4544/6464)
Loss: 1.145 | Acc: 70.297% (9043/12864)
Loss: 1.147 | Acc: 70.105% (13505/19264)
Loss: 1.149 | Acc: 69.946% (17951/25664)
Loss: 1.147 | Acc: 69.901% (22413/32064)
Loss: 1.146 | Acc: 69.871% (26875/38464)
Loss: 1.147 | Acc: 69.860% (31342/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3969, Accuracy: 6047/10000 (60.47%)

Epoch: 56
Loss: 1.421 | Acc: 65.625% (42/64)
Loss: 1.138 | Acc: 70.096% (4531/6464)
Loss: 1.141 | Acc: 69.831% (8983/12864)
Loss: 1.137 | Acc: 70.105% (13505/19264)
Loss: 1.138 | Acc: 70.180% (18011/25664)
Loss: 1.143 | Acc: 70.051% (22461/32064)
Loss: 1.144 | Acc: 69.962% (26910/38464)
Loss: 1.144 | Acc: 69.947% (31381/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4586, Accuracy: 5957/10000 (59.57%)

Epoch: 57
Loss: 1.401 | Acc: 65.625% (42/64)
Loss: 1.129 | Acc: 70.390% (4550/6464)
Loss: 1.135 | Acc: 70.382% (9054/12864)
Loss: 1.139 | Acc: 70.328% (13548/19264)
Loss: 1.140 | Acc: 70.250% (18029/25664)
Loss: 1.137 | Acc: 70.206% (22511/32064)
Loss: 1.143 | Acc: 70.105% (26965/38464)
Loss: 1.138 | Acc: 70.239% (31512/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6012, Accuracy: 5411/10000 (54.11%)

Epoch: 58
Loss: 1.363 | Acc: 60.938% (39/64)
Loss: 1.138 | Acc: 69.848% (4515/6464)
Loss: 1.145 | Acc: 69.877% (8989/12864)
Loss: 1.136 | Acc: 70.250% (13533/19264)
Loss: 1.136 | Acc: 70.363% (18058/25664)
Loss: 1.142 | Acc: 70.210% (22512/32064)
Loss: 1.141 | Acc: 70.157% (26985/38464)
Loss: 1.138 | Acc: 70.250% (31517/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5105, Accuracy: 5757/10000 (57.57%)

Epoch: 59
Loss: 0.998 | Acc: 71.875% (46/64)
Loss: 1.133 | Acc: 69.972% (4523/6464)
Loss: 1.129 | Acc: 70.165% (9026/12864)
Loss: 1.130 | Acc: 70.287% (13540/19264)
Loss: 1.124 | Acc: 70.484% (18089/25664)
Loss: 1.128 | Acc: 70.409% (22576/32064)
Loss: 1.132 | Acc: 70.253% (27022/38464)
Loss: 1.138 | Acc: 70.085% (31443/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3577, Accuracy: 6215/10000 (62.15%)

Epoch: 60
Loss: 1.075 | Acc: 67.188% (43/64)
Loss: 1.133 | Acc: 70.312% (4545/6464)
Loss: 1.123 | Acc: 70.662% (9090/12864)
Loss: 1.137 | Acc: 70.323% (13547/19264)
Loss: 1.138 | Acc: 70.332% (18050/25664)
Loss: 1.135 | Acc: 70.475% (22597/32064)
Loss: 1.132 | Acc: 70.572% (27145/38464)
Loss: 1.132 | Acc: 70.509% (31633/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3583, Accuracy: 6298/10000 (62.98%)

Epoch: 61
Loss: 1.195 | Acc: 65.625% (42/64)
Loss: 1.111 | Acc: 71.086% (4595/6464)
Loss: 1.109 | Acc: 71.245% (9165/12864)
Loss: 1.117 | Acc: 70.915% (13661/19264)
Loss: 1.124 | Acc: 70.741% (18155/25664)
Loss: 1.123 | Acc: 70.893% (22731/32064)
Loss: 1.125 | Acc: 70.882% (27264/38464)
Loss: 1.122 | Acc: 70.912% (31814/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5612, Accuracy: 5759/10000 (57.59%)

Epoch: 62
Loss: 1.256 | Acc: 67.188% (43/64)
Loss: 1.117 | Acc: 71.318% (4610/6464)
Loss: 1.111 | Acc: 71.603% (9211/12864)
Loss: 1.125 | Acc: 71.164% (13709/19264)
Loss: 1.119 | Acc: 71.213% (18276/25664)
Loss: 1.123 | Acc: 70.992% (22763/32064)
Loss: 1.123 | Acc: 70.942% (27287/38464)
Loss: 1.124 | Acc: 70.883% (31801/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5736, Accuracy: 5513/10000 (55.13%)

Epoch: 63
Loss: 0.922 | Acc: 75.000% (48/64)
Loss: 1.107 | Acc: 71.535% (4624/6464)
Loss: 1.106 | Acc: 71.517% (9200/12864)
Loss: 1.100 | Acc: 71.652% (13803/19264)
Loss: 1.108 | Acc: 71.302% (18299/25664)
Loss: 1.109 | Acc: 71.248% (22845/32064)
Loss: 1.114 | Acc: 71.217% (27393/38464)
Loss: 1.116 | Acc: 71.162% (31926/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4274, Accuracy: 5958/10000 (59.58%)

Epoch: 64
Loss: 1.190 | Acc: 65.625% (42/64)
Loss: 1.118 | Acc: 71.163% (4600/6464)
Loss: 1.111 | Acc: 71.401% (9185/12864)
Loss: 1.101 | Acc: 71.776% (13827/19264)
Loss: 1.106 | Acc: 71.598% (18375/25664)
Loss: 1.109 | Acc: 71.473% (22917/32064)
Loss: 1.108 | Acc: 71.521% (27510/38464)
Loss: 1.110 | Acc: 71.402% (32034/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4327, Accuracy: 5935/10000 (59.35%)

Epoch: 65
Loss: 0.999 | Acc: 75.000% (48/64)
Loss: 1.090 | Acc: 72.030% (4656/6464)
Loss: 1.090 | Acc: 72.155% (9282/12864)
Loss: 1.104 | Acc: 71.709% (13814/19264)
Loss: 1.104 | Acc: 71.598% (18375/25664)
Loss: 1.105 | Acc: 71.535% (22937/32064)
Loss: 1.106 | Acc: 71.545% (27519/38464)
Loss: 1.103 | Acc: 71.674% (32156/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3488, Accuracy: 6279/10000 (62.79%)

Epoch: 66
Loss: 0.993 | Acc: 73.438% (47/64)
Loss: 1.053 | Acc: 73.453% (4748/6464)
Loss: 1.080 | Acc: 72.318% (9303/12864)
Loss: 1.092 | Acc: 71.885% (13848/19264)
Loss: 1.096 | Acc: 71.785% (18423/25664)
Loss: 1.096 | Acc: 71.847% (23037/32064)
Loss: 1.097 | Acc: 71.828% (27628/38464)
Loss: 1.096 | Acc: 71.837% (32229/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6928, Accuracy: 5081/10000 (50.81%)

Epoch: 67
Loss: 1.300 | Acc: 64.062% (41/64)
Loss: 1.112 | Acc: 71.457% (4619/6464)
Loss: 1.089 | Acc: 72.341% (9306/12864)
Loss: 1.089 | Acc: 72.508% (13968/19264)
Loss: 1.093 | Acc: 72.346% (18567/25664)
Loss: 1.092 | Acc: 72.252% (23167/32064)
Loss: 1.091 | Acc: 72.223% (27780/38464)
Loss: 1.092 | Acc: 72.169% (32378/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5323, Accuracy: 5554/10000 (55.54%)

Epoch: 68
Loss: 0.908 | Acc: 73.438% (47/64)
Loss: 1.095 | Acc: 72.184% (4666/6464)
Loss: 1.072 | Acc: 72.660% (9347/12864)
Loss: 1.079 | Acc: 72.565% (13979/19264)
Loss: 1.078 | Acc: 72.534% (18615/25664)
Loss: 1.080 | Acc: 72.436% (23226/32064)
Loss: 1.083 | Acc: 72.374% (27838/38464)
Loss: 1.079 | Acc: 72.428% (32494/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4041, Accuracy: 6169/10000 (61.69%)

Epoch: 69
Loss: 1.175 | Acc: 65.625% (42/64)
Loss: 1.045 | Acc: 73.314% (4739/6464)
Loss: 1.055 | Acc: 72.994% (9390/12864)
Loss: 1.067 | Acc: 72.737% (14012/19264)
Loss: 1.072 | Acc: 72.611% (18635/25664)
Loss: 1.070 | Acc: 72.726% (23319/32064)
Loss: 1.069 | Acc: 72.775% (27992/38464)
Loss: 1.070 | Acc: 72.791% (32657/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2321, Accuracy: 6775/10000 (67.75%)

Epoch: 70
Loss: 1.102 | Acc: 75.000% (48/64)
Loss: 1.008 | Acc: 74.598% (4822/6464)
Loss: 1.025 | Acc: 74.192% (9544/12864)
Loss: 1.039 | Acc: 73.983% (14252/19264)
Loss: 1.041 | Acc: 73.917% (18970/25664)
Loss: 1.053 | Acc: 73.600% (23599/32064)
Loss: 1.057 | Acc: 73.438% (28247/38464)
Loss: 1.062 | Acc: 73.210% (32845/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5567, Accuracy: 5528/10000 (55.28%)

Epoch: 71
Loss: 1.052 | Acc: 68.750% (44/64)
Loss: 1.024 | Acc: 74.056% (4787/6464)
Loss: 1.029 | Acc: 73.896% (9506/12864)
Loss: 1.040 | Acc: 73.609% (14180/19264)
Loss: 1.045 | Acc: 73.625% (18895/25664)
Loss: 1.047 | Acc: 73.662% (23619/32064)
Loss: 1.051 | Acc: 73.443% (28249/38464)
Loss: 1.051 | Acc: 73.435% (32946/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5812, Accuracy: 5586/10000 (55.86%)

Epoch: 72
Loss: 1.207 | Acc: 59.375% (38/64)
Loss: 1.027 | Acc: 73.871% (4775/6464)
Loss: 1.043 | Acc: 73.609% (9469/12864)
Loss: 1.050 | Acc: 73.469% (14153/19264)
Loss: 1.050 | Acc: 73.445% (18849/25664)
Loss: 1.049 | Acc: 73.522% (23574/32064)
Loss: 1.046 | Acc: 73.609% (28313/38464)
Loss: 1.049 | Acc: 73.538% (32992/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4411, Accuracy: 5967/10000 (59.67%)

Epoch: 73
Loss: 1.191 | Acc: 67.188% (43/64)
Loss: 1.036 | Acc: 73.840% (4773/6464)
Loss: 1.038 | Acc: 73.951% (9513/12864)
Loss: 1.044 | Acc: 73.739% (14205/19264)
Loss: 1.045 | Acc: 73.738% (18924/25664)
Loss: 1.043 | Acc: 73.849% (23679/32064)
Loss: 1.040 | Acc: 73.918% (28432/38464)
Loss: 1.042 | Acc: 73.803% (33111/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2692, Accuracy: 6738/10000 (67.38%)

Epoch: 74
Loss: 1.064 | Acc: 75.000% (48/64)
Loss: 1.017 | Acc: 74.474% (4814/6464)
Loss: 1.017 | Acc: 74.743% (9615/12864)
Loss: 1.022 | Acc: 74.600% (14371/19264)
Loss: 1.026 | Acc: 74.490% (19117/25664)
Loss: 1.023 | Acc: 74.579% (23913/32064)
Loss: 1.030 | Acc: 74.298% (28578/38464)
Loss: 1.031 | Acc: 74.244% (33309/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4986, Accuracy: 5767/10000 (57.67%)

Epoch: 75
Loss: 1.074 | Acc: 73.438% (47/64)
Loss: 1.014 | Acc: 75.093% (4854/6464)
Loss: 1.016 | Acc: 74.953% (9642/12864)
Loss: 1.021 | Acc: 74.699% (14390/19264)
Loss: 1.021 | Acc: 74.560% (19135/25664)
Loss: 1.019 | Acc: 74.582% (23914/32064)
Loss: 1.020 | Acc: 74.568% (28682/38464)
Loss: 1.021 | Acc: 74.556% (33449/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2306, Accuracy: 6846/10000 (68.46%)

Epoch: 76
Loss: 0.777 | Acc: 79.688% (51/64)
Loss: 0.984 | Acc: 75.743% (4896/6464)
Loss: 0.983 | Acc: 75.599% (9725/12864)
Loss: 0.994 | Acc: 75.322% (14510/19264)
Loss: 1.001 | Acc: 75.132% (19282/25664)
Loss: 1.007 | Acc: 74.959% (24035/32064)
Loss: 1.007 | Acc: 74.867% (28797/38464)
Loss: 1.006 | Acc: 74.940% (33621/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1866, Accuracy: 6972/10000 (69.72%)

Epoch: 77
Loss: 0.991 | Acc: 76.562% (49/64)
Loss: 0.978 | Acc: 75.402% (4874/6464)
Loss: 0.990 | Acc: 75.257% (9681/12864)
Loss: 0.991 | Acc: 75.228% (14492/19264)
Loss: 0.993 | Acc: 75.269% (19317/25664)
Loss: 0.996 | Acc: 75.175% (24104/32064)
Loss: 0.993 | Acc: 75.328% (28974/38464)
Loss: 0.994 | Acc: 75.319% (33791/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1995, Accuracy: 6953/10000 (69.53%)

Epoch: 78
Loss: 0.850 | Acc: 79.688% (51/64)
Loss: 0.966 | Acc: 76.392% (4938/6464)
Loss: 0.976 | Acc: 76.073% (9786/12864)
Loss: 0.986 | Acc: 75.825% (14607/19264)
Loss: 0.986 | Acc: 75.760% (19443/25664)
Loss: 0.986 | Acc: 75.724% (24280/32064)
Loss: 0.982 | Acc: 75.819% (29163/38464)
Loss: 0.985 | Acc: 75.698% (33961/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1958, Accuracy: 6937/10000 (69.37%)

Epoch: 79
Loss: 0.993 | Acc: 73.438% (47/64)
Loss: 0.939 | Acc: 77.011% (4978/6464)
Loss: 0.951 | Acc: 76.664% (9862/12864)
Loss: 0.954 | Acc: 76.521% (14741/19264)
Loss: 0.962 | Acc: 76.298% (19581/25664)
Loss: 0.965 | Acc: 76.194% (24431/32064)
Loss: 0.965 | Acc: 76.248% (29328/38464)
Loss: 0.962 | Acc: 76.369% (34262/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5102, Accuracy: 5684/10000 (56.84%)

Epoch: 80
Loss: 1.283 | Acc: 60.938% (39/64)
Loss: 0.974 | Acc: 75.897% (4906/6464)
Loss: 0.960 | Acc: 76.236% (9807/12864)
Loss: 0.958 | Acc: 76.329% (14704/19264)
Loss: 0.955 | Acc: 76.399% (19607/25664)
Loss: 0.953 | Acc: 76.453% (24514/32064)
Loss: 0.955 | Acc: 76.448% (29405/38464)
Loss: 0.955 | Acc: 76.427% (34288/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2573, Accuracy: 6759/10000 (67.59%)

Epoch: 81
Loss: 0.874 | Acc: 76.562% (49/64)
Loss: 0.929 | Acc: 76.841% (4967/6464)
Loss: 0.938 | Acc: 76.726% (9870/12864)
Loss: 0.938 | Acc: 76.781% (14791/19264)
Loss: 0.943 | Acc: 76.761% (19700/25664)
Loss: 0.938 | Acc: 76.965% (24678/32064)
Loss: 0.938 | Acc: 77.002% (29618/38464)
Loss: 0.941 | Acc: 76.917% (34508/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2799, Accuracy: 6644/10000 (66.44%)

Epoch: 82
Loss: 0.802 | Acc: 81.250% (52/64)
Loss: 0.934 | Acc: 76.748% (4961/6464)
Loss: 0.930 | Acc: 77.107% (9919/12864)
Loss: 0.917 | Acc: 77.419% (14914/19264)
Loss: 0.916 | Acc: 77.579% (19910/25664)
Loss: 0.920 | Acc: 77.383% (24812/32064)
Loss: 0.924 | Acc: 77.374% (29761/38464)
Loss: 0.924 | Acc: 77.430% (34738/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2077, Accuracy: 6995/10000 (69.95%)

Epoch: 83
Loss: 1.137 | Acc: 70.312% (45/64)
Loss: 0.871 | Acc: 78.883% (5099/6464)
Loss: 0.883 | Acc: 78.475% (10095/12864)
Loss: 0.884 | Acc: 78.296% (15083/19264)
Loss: 0.896 | Acc: 77.981% (20013/25664)
Loss: 0.895 | Acc: 77.932% (24988/32064)
Loss: 0.899 | Acc: 77.849% (29944/38464)
Loss: 0.902 | Acc: 77.849% (34926/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4912, Accuracy: 6047/10000 (60.47%)

Epoch: 84
Loss: 0.744 | Acc: 81.250% (52/64)
Loss: 0.880 | Acc: 78.048% (5045/6464)
Loss: 0.887 | Acc: 77.845% (10014/12864)
Loss: 0.889 | Acc: 77.954% (15017/19264)
Loss: 0.890 | Acc: 78.063% (20034/25664)
Loss: 0.883 | Acc: 78.278% (25099/32064)
Loss: 0.883 | Acc: 78.349% (30136/38464)
Loss: 0.886 | Acc: 78.272% (35116/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1727, Accuracy: 7156/10000 (71.56%)

Epoch: 85
Loss: 0.893 | Acc: 78.125% (50/64)
Loss: 0.845 | Acc: 79.208% (5120/6464)
Loss: 0.850 | Acc: 78.902% (10150/12864)
Loss: 0.853 | Acc: 78.930% (15205/19264)
Loss: 0.848 | Acc: 79.025% (20281/25664)
Loss: 0.847 | Acc: 79.207% (25397/32064)
Loss: 0.851 | Acc: 79.129% (30436/38464)
Loss: 0.856 | Acc: 79.003% (35444/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2478, Accuracy: 6882/10000 (68.82%)

Epoch: 86
Loss: 0.832 | Acc: 78.125% (50/64)
Loss: 0.800 | Acc: 80.260% (5188/6464)
Loss: 0.804 | Acc: 80.255% (10324/12864)
Loss: 0.802 | Acc: 80.331% (15475/19264)
Loss: 0.815 | Acc: 79.991% (20529/25664)
Loss: 0.822 | Acc: 79.812% (25591/32064)
Loss: 0.828 | Acc: 79.680% (30648/38464)
Loss: 0.830 | Acc: 79.587% (35706/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1762, Accuracy: 7232/10000 (72.32%)

Epoch: 87
Loss: 0.691 | Acc: 84.375% (54/64)
Loss: 0.802 | Acc: 80.043% (5174/6464)
Loss: 0.785 | Acc: 80.620% (10371/12864)
Loss: 0.799 | Acc: 80.217% (15453/19264)
Loss: 0.803 | Acc: 80.073% (20550/25664)
Loss: 0.803 | Acc: 80.093% (25681/32064)
Loss: 0.803 | Acc: 80.025% (30781/38464)
Loss: 0.799 | Acc: 80.200% (35981/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2396, Accuracy: 7101/10000 (71.01%)

Epoch: 88
Loss: 0.550 | Acc: 82.812% (53/64)
Loss: 0.760 | Acc: 80.832% (5225/6464)
Loss: 0.762 | Acc: 80.861% (10402/12864)
Loss: 0.761 | Acc: 80.949% (15594/19264)
Loss: 0.765 | Acc: 80.911% (20765/25664)
Loss: 0.768 | Acc: 80.795% (25906/32064)
Loss: 0.769 | Acc: 80.769% (31067/38464)
Loss: 0.771 | Acc: 80.713% (36211/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2112, Accuracy: 7141/10000 (71.41%)

Epoch: 89
Loss: 0.577 | Acc: 85.938% (55/64)
Loss: 0.710 | Acc: 82.225% (5315/6464)
Loss: 0.721 | Acc: 81.988% (10547/12864)
Loss: 0.728 | Acc: 81.722% (15743/19264)
Loss: 0.730 | Acc: 81.608% (20944/25664)
Loss: 0.730 | Acc: 81.652% (26181/32064)
Loss: 0.730 | Acc: 81.645% (31404/38464)
Loss: 0.732 | Acc: 81.629% (36622/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2818, Accuracy: 7129/10000 (71.29%)

Epoch: 90
Loss: 0.696 | Acc: 82.812% (53/64)
Loss: 0.668 | Acc: 83.246% (5381/6464)
Loss: 0.684 | Acc: 82.680% (10636/12864)
Loss: 0.686 | Acc: 82.532% (15899/19264)
Loss: 0.686 | Acc: 82.505% (21174/25664)
Loss: 0.690 | Acc: 82.432% (26431/32064)
Loss: 0.694 | Acc: 82.298% (31655/38464)
Loss: 0.693 | Acc: 82.422% (36978/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2663, Accuracy: 7214/10000 (72.14%)

Epoch: 91
Loss: 0.491 | Acc: 87.500% (56/64)
Loss: 0.629 | Acc: 84.236% (5445/6464)
Loss: 0.631 | Acc: 83.909% (10794/12864)
Loss: 0.645 | Acc: 83.596% (16104/19264)
Loss: 0.639 | Acc: 83.709% (21483/25664)
Loss: 0.643 | Acc: 83.577% (26798/32064)
Loss: 0.643 | Acc: 83.608% (32159/38464)
Loss: 0.644 | Acc: 83.546% (37482/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2974, Accuracy: 7157/10000 (71.57%)

Epoch: 92
Loss: 0.784 | Acc: 82.812% (53/64)
Loss: 0.577 | Acc: 84.824% (5483/6464)
Loss: 0.577 | Acc: 84.756% (10903/12864)
Loss: 0.580 | Acc: 84.759% (16328/19264)
Loss: 0.585 | Acc: 84.585% (21708/25664)
Loss: 0.595 | Acc: 84.303% (27031/32064)
Loss: 0.593 | Acc: 84.346% (32443/38464)
Loss: 0.594 | Acc: 84.304% (37822/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3631, Accuracy: 7110/10000 (71.10%)

Epoch: 93
Loss: 0.422 | Acc: 89.062% (57/64)
Loss: 0.524 | Acc: 85.845% (5549/6464)
Loss: 0.517 | Acc: 86.101% (11076/12864)
Loss: 0.520 | Acc: 86.156% (16597/19264)
Loss: 0.527 | Acc: 85.934% (22054/25664)
Loss: 0.526 | Acc: 85.875% (27535/32064)
Loss: 0.531 | Acc: 85.743% (32980/38464)
Loss: 0.533 | Acc: 85.692% (38445/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3972, Accuracy: 7114/10000 (71.14%)

Epoch: 94
Loss: 0.280 | Acc: 90.625% (58/64)
Loss: 0.482 | Acc: 86.819% (5612/6464)
Loss: 0.488 | Acc: 86.793% (11165/12864)
Loss: 0.489 | Acc: 86.664% (16695/19264)
Loss: 0.489 | Acc: 86.596% (22224/25664)
Loss: 0.488 | Acc: 86.714% (27804/32064)
Loss: 0.486 | Acc: 86.832% (33399/38464)
Loss: 0.481 | Acc: 86.998% (39031/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4352, Accuracy: 7080/10000 (70.80%)

Epoch: 95
Loss: 0.282 | Acc: 92.188% (59/64)
Loss: 0.421 | Acc: 88.815% (5741/6464)
Loss: 0.431 | Acc: 88.293% (11358/12864)
Loss: 0.437 | Acc: 88.076% (16967/19264)
Loss: 0.436 | Acc: 88.186% (22632/25664)
Loss: 0.440 | Acc: 87.993% (28214/32064)
Loss: 0.442 | Acc: 87.976% (33839/38464)
Loss: 0.441 | Acc: 87.926% (39447/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4515, Accuracy: 7113/10000 (71.13%)

Epoch: 96
Loss: 0.293 | Acc: 93.750% (60/64)
Loss: 0.419 | Acc: 88.567% (5725/6464)
Loss: 0.407 | Acc: 88.728% (11414/12864)
Loss: 0.412 | Acc: 88.533% (17055/19264)
Loss: 0.411 | Acc: 88.560% (22728/25664)
Loss: 0.408 | Acc: 88.766% (28462/32064)
Loss: 0.407 | Acc: 88.719% (34125/38464)
Loss: 0.405 | Acc: 88.735% (39810/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4782, Accuracy: 7088/10000 (70.88%)

Epoch: 97
Loss: 0.380 | Acc: 87.500% (56/64)
Loss: 0.371 | Acc: 89.217% (5767/6464)
Loss: 0.375 | Acc: 89.335% (11492/12864)
Loss: 0.377 | Acc: 89.358% (17214/19264)
Loss: 0.371 | Acc: 89.608% (22997/25664)
Loss: 0.371 | Acc: 89.586% (28725/32064)
Loss: 0.369 | Acc: 89.692% (34499/38464)
Loss: 0.369 | Acc: 89.651% (40221/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4880, Accuracy: 7104/10000 (71.04%)
torch.Size([100, 10])
Test set: Average loss: 1.4880, Accuracy: 7104/10000 (71.04%)

Epoch: 98
Loss: 0.270 | Acc: 93.750% (60/64)
Loss: 0.357 | Acc: 89.867% (5809/6464)
Loss: 0.362 | Acc: 89.630% (11530/12864)
Loss: 0.358 | Acc: 89.919% (17322/19264)
Loss: 0.356 | Acc: 89.869% (23064/25664)
Loss: 0.354 | Acc: 89.901% (28826/32064)
Loss: 0.354 | Acc: 89.928% (34590/38464)
Loss: 0.354 | Acc: 89.925% (40344/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4886, Accuracy: 7108/10000 (71.08%)
torch.Size([100, 10])
Test set: Average loss: 1.4886, Accuracy: 7108/10000 (71.08%)

Epoch: 99
Loss: 0.179 | Acc: 96.875% (62/64)
Loss: 0.339 | Acc: 90.192% (5830/6464)
Loss: 0.343 | Acc: 90.127% (11594/12864)
Loss: 0.341 | Acc: 90.142% (17365/19264)
Loss: 0.342 | Acc: 90.091% (23121/25664)
Loss: 0.344 | Acc: 90.098% (28889/32064)
Loss: 0.344 | Acc: 90.219% (34702/38464)
Loss: 0.344 | Acc: 90.184% (40460/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4990, Accuracy: 7102/10000 (71.02%)
torch.Size([100, 10])
Test set: Average loss: 1.4990, Accuracy: 7102/10000 (71.02%)

Epoch: 100
Loss: 0.192 | Acc: 95.312% (61/64)
Loss: 1.718 | Acc: 44.787% (2895/6464)
Loss: 1.533 | Acc: 53.117% (6833/12864)
Loss: 1.432 | Acc: 57.345% (11047/19264)
Loss: 1.379 | Acc: 59.663% (15312/25664)
Loss: 1.344 | Acc: 61.171% (19614/32064)
Loss: 1.318 | Acc: 62.289% (23959/38464)
Loss: 1.300 | Acc: 63.064% (28293/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7883, Accuracy: 4628/10000 (46.28%)

Epoch: 101
Loss: 1.515 | Acc: 57.812% (37/64)
Loss: 1.150 | Acc: 69.663% (4503/6464)
Loss: 1.158 | Acc: 69.139% (8894/12864)
Loss: 1.151 | Acc: 69.451% (13379/19264)
Loss: 1.151 | Acc: 69.650% (17875/25664)
Loss: 1.151 | Acc: 69.670% (22339/32064)
Loss: 1.147 | Acc: 69.787% (26843/38464)
Loss: 1.149 | Acc: 69.784% (31308/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5944, Accuracy: 5413/10000 (54.13%)

Epoch: 102
Loss: 0.883 | Acc: 81.250% (52/64)
Loss: 1.129 | Acc: 70.204% (4538/6464)
Loss: 1.124 | Acc: 70.468% (9065/12864)
Loss: 1.127 | Acc: 70.515% (13584/19264)
Loss: 1.127 | Acc: 70.519% (18098/25664)
Loss: 1.128 | Acc: 70.503% (22606/32064)
Loss: 1.132 | Acc: 70.429% (27090/38464)
Loss: 1.130 | Acc: 70.513% (31635/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8063, Accuracy: 4798/10000 (47.98%)

Epoch: 103
Loss: 1.279 | Acc: 57.812% (37/64)
Loss: 1.142 | Acc: 69.585% (4498/6464)
Loss: 1.135 | Acc: 70.320% (9046/12864)
Loss: 1.131 | Acc: 70.458% (13573/19264)
Loss: 1.124 | Acc: 70.753% (18158/25664)
Loss: 1.125 | Acc: 70.787% (22697/32064)
Loss: 1.128 | Acc: 70.689% (27190/38464)
Loss: 1.128 | Acc: 70.694% (31716/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0236, Accuracy: 4715/10000 (47.15%)

Epoch: 104
Loss: 1.371 | Acc: 65.625% (42/64)
Loss: 1.099 | Acc: 71.256% (4606/6464)
Loss: 1.117 | Acc: 70.989% (9132/12864)
Loss: 1.115 | Acc: 71.102% (13697/19264)
Loss: 1.119 | Acc: 70.959% (18211/25664)
Loss: 1.122 | Acc: 70.818% (22707/32064)
Loss: 1.125 | Acc: 70.783% (27226/38464)
Loss: 1.126 | Acc: 70.756% (31744/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3827, Accuracy: 6297/10000 (62.97%)

Epoch: 105
Loss: 1.595 | Acc: 54.688% (35/64)
Loss: 1.131 | Acc: 70.823% (4578/6464)
Loss: 1.111 | Acc: 71.183% (9157/12864)
Loss: 1.118 | Acc: 70.956% (13669/19264)
Loss: 1.109 | Acc: 71.244% (18284/25664)
Loss: 1.112 | Acc: 71.236% (22841/32064)
Loss: 1.116 | Acc: 71.209% (27390/38464)
Loss: 1.117 | Acc: 71.173% (31931/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3584, Accuracy: 3319/10000 (33.19%)

Epoch: 106
Loss: 1.356 | Acc: 60.938% (39/64)
Loss: 1.122 | Acc: 70.622% (4565/6464)
Loss: 1.131 | Acc: 70.546% (9075/12864)
Loss: 1.120 | Acc: 71.060% (13689/19264)
Loss: 1.120 | Acc: 71.096% (18246/25664)
Loss: 1.119 | Acc: 71.024% (22773/32064)
Loss: 1.122 | Acc: 70.947% (27289/38464)
Loss: 1.124 | Acc: 70.854% (31788/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4488, Accuracy: 5970/10000 (59.70%)

Epoch: 107
Loss: 1.125 | Acc: 67.188% (43/64)
Loss: 1.064 | Acc: 72.896% (4712/6464)
Loss: 1.087 | Acc: 71.945% (9255/12864)
Loss: 1.098 | Acc: 71.704% (13813/19264)
Loss: 1.107 | Acc: 71.376% (18318/25664)
Loss: 1.108 | Acc: 71.335% (22873/32064)
Loss: 1.112 | Acc: 71.251% (27406/38464)
Loss: 1.114 | Acc: 71.217% (31951/44864)
torch.Size([100, 10])
Test set: Average loss: 2.6243, Accuracy: 3167/10000 (31.67%)

Epoch: 108
Loss: 1.528 | Acc: 56.250% (36/64)
Loss: 1.108 | Acc: 71.457% (4619/6464)
Loss: 1.101 | Acc: 71.789% (9235/12864)
Loss: 1.108 | Acc: 71.517% (13777/19264)
Loss: 1.108 | Acc: 71.602% (18376/25664)
Loss: 1.107 | Acc: 71.703% (22991/32064)
Loss: 1.112 | Acc: 71.568% (27528/38464)
Loss: 1.112 | Acc: 71.474% (32066/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3423, Accuracy: 3887/10000 (38.87%)

Epoch: 109
Loss: 1.456 | Acc: 60.938% (39/64)
Loss: 1.117 | Acc: 71.241% (4605/6464)
Loss: 1.108 | Acc: 71.409% (9186/12864)
Loss: 1.107 | Acc: 71.491% (13772/19264)
Loss: 1.107 | Acc: 71.478% (18344/25664)
Loss: 1.108 | Acc: 71.379% (22887/32064)
Loss: 1.110 | Acc: 71.332% (27437/38464)
Loss: 1.111 | Acc: 71.320% (31997/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6642, Accuracy: 5471/10000 (54.71%)

Epoch: 110
Loss: 1.468 | Acc: 54.688% (35/64)
Loss: 1.104 | Acc: 71.767% (4639/6464)
Loss: 1.094 | Acc: 71.891% (9248/12864)
Loss: 1.092 | Acc: 71.891% (13849/19264)
Loss: 1.095 | Acc: 71.828% (18434/25664)
Loss: 1.100 | Acc: 71.700% (22990/32064)
Loss: 1.102 | Acc: 71.690% (27575/38464)
Loss: 1.102 | Acc: 71.641% (32141/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3161, Accuracy: 6409/10000 (64.09%)

Epoch: 111
Loss: 0.995 | Acc: 79.688% (51/64)
Loss: 1.092 | Acc: 71.705% (4635/6464)
Loss: 1.098 | Acc: 71.758% (9231/12864)
Loss: 1.097 | Acc: 71.724% (13817/19264)
Loss: 1.092 | Acc: 71.859% (18442/25664)
Loss: 1.099 | Acc: 71.747% (23005/32064)
Loss: 1.101 | Acc: 71.670% (27567/38464)
Loss: 1.103 | Acc: 71.612% (32128/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4374, Accuracy: 5959/10000 (59.59%)

Epoch: 112
Loss: 1.245 | Acc: 65.625% (42/64)
Loss: 1.088 | Acc: 72.602% (4693/6464)
Loss: 1.076 | Acc: 72.753% (9359/12864)
Loss: 1.085 | Acc: 72.321% (13932/19264)
Loss: 1.087 | Acc: 72.358% (18570/25664)
Loss: 1.086 | Acc: 72.249% (23166/32064)
Loss: 1.093 | Acc: 72.054% (27715/38464)
Loss: 1.096 | Acc: 71.935% (32273/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5426, Accuracy: 5313/10000 (53.13%)

Epoch: 113
Loss: 1.092 | Acc: 75.000% (48/64)
Loss: 1.072 | Acc: 72.633% (4695/6464)
Loss: 1.085 | Acc: 72.085% (9273/12864)
Loss: 1.084 | Acc: 72.197% (13908/19264)
Loss: 1.085 | Acc: 72.214% (18533/25664)
Loss: 1.084 | Acc: 72.209% (23153/32064)
Loss: 1.089 | Acc: 72.177% (27762/38464)
Loss: 1.092 | Acc: 72.107% (32350/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2209, Accuracy: 3482/10000 (34.82%)

Epoch: 114
Loss: 1.075 | Acc: 70.312% (45/64)
Loss: 1.073 | Acc: 72.262% (4671/6464)
Loss: 1.074 | Acc: 72.077% (9272/12864)
Loss: 1.078 | Acc: 72.046% (13879/19264)
Loss: 1.079 | Acc: 72.226% (18536/25664)
Loss: 1.082 | Acc: 72.284% (23177/32064)
Loss: 1.090 | Acc: 72.078% (27724/38464)
Loss: 1.091 | Acc: 72.029% (32315/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5212, Accuracy: 5676/10000 (56.76%)

Epoch: 115
Loss: 0.952 | Acc: 73.438% (47/64)
Loss: 1.053 | Acc: 73.468% (4749/6464)
Loss: 1.067 | Acc: 73.033% (9395/12864)
Loss: 1.079 | Acc: 72.669% (13999/19264)
Loss: 1.083 | Acc: 72.619% (18637/25664)
Loss: 1.083 | Acc: 72.439% (23227/32064)
Loss: 1.080 | Acc: 72.468% (27874/38464)
Loss: 1.079 | Acc: 72.497% (32525/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3790, Accuracy: 6286/10000 (62.86%)

Epoch: 116
Loss: 0.949 | Acc: 71.875% (46/64)
Loss: 1.062 | Acc: 72.973% (4717/6464)
Loss: 1.065 | Acc: 73.212% (9418/12864)
Loss: 1.068 | Acc: 73.095% (14081/19264)
Loss: 1.073 | Acc: 72.950% (18722/25664)
Loss: 1.077 | Acc: 72.826% (23351/32064)
Loss: 1.075 | Acc: 72.923% (28049/38464)
Loss: 1.076 | Acc: 72.833% (32676/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6165, Accuracy: 5360/10000 (53.60%)

Epoch: 117
Loss: 1.048 | Acc: 68.750% (44/64)
Loss: 1.091 | Acc: 71.674% (4633/6464)
Loss: 1.091 | Acc: 71.922% (9252/12864)
Loss: 1.078 | Acc: 72.347% (13937/19264)
Loss: 1.077 | Acc: 72.495% (18605/25664)
Loss: 1.086 | Acc: 72.277% (23175/32064)
Loss: 1.080 | Acc: 72.418% (27855/38464)
Loss: 1.073 | Acc: 72.648% (32593/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4734, Accuracy: 5856/10000 (58.56%)

Epoch: 118
Loss: 1.389 | Acc: 65.625% (42/64)
Loss: 1.039 | Acc: 73.639% (4760/6464)
Loss: 1.047 | Acc: 73.593% (9467/12864)
Loss: 1.054 | Acc: 73.474% (14154/19264)
Loss: 1.055 | Acc: 73.453% (18851/25664)
Loss: 1.060 | Acc: 73.222% (23478/32064)
Loss: 1.061 | Acc: 73.188% (28151/38464)
Loss: 1.063 | Acc: 73.154% (32820/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4158, Accuracy: 5950/10000 (59.50%)

Epoch: 119
Loss: 0.903 | Acc: 79.688% (51/64)
Loss: 1.038 | Acc: 74.242% (4799/6464)
Loss: 1.039 | Acc: 74.184% (9543/12864)
Loss: 1.043 | Acc: 73.972% (14250/19264)
Loss: 1.051 | Acc: 73.683% (18910/25664)
Loss: 1.054 | Acc: 73.656% (23617/32064)
Loss: 1.054 | Acc: 73.687% (28343/38464)
Loss: 1.052 | Acc: 73.705% (33067/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5171, Accuracy: 5732/10000 (57.32%)

Epoch: 120
Loss: 0.997 | Acc: 71.875% (46/64)
Loss: 1.059 | Acc: 73.004% (4719/6464)
Loss: 1.052 | Acc: 73.554% (9462/12864)
Loss: 1.047 | Acc: 73.697% (14197/19264)
Loss: 1.046 | Acc: 73.625% (18895/25664)
Loss: 1.045 | Acc: 73.749% (23647/32064)
Loss: 1.046 | Acc: 73.708% (28351/38464)
Loss: 1.048 | Acc: 73.658% (33046/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4193, Accuracy: 6103/10000 (61.03%)

Epoch: 121
Loss: 1.315 | Acc: 64.062% (41/64)
Loss: 1.005 | Acc: 74.799% (4835/6464)
Loss: 1.031 | Acc: 74.028% (9523/12864)
Loss: 1.039 | Acc: 73.609% (14180/19264)
Loss: 1.044 | Acc: 73.543% (18874/25664)
Loss: 1.036 | Acc: 73.893% (23693/32064)
Loss: 1.042 | Acc: 73.760% (28371/38464)
Loss: 1.044 | Acc: 73.743% (33084/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2242, Accuracy: 6821/10000 (68.21%)

Epoch: 122
Loss: 1.027 | Acc: 73.438% (47/64)
Loss: 1.022 | Acc: 74.629% (4824/6464)
Loss: 1.012 | Acc: 74.712% (9611/12864)
Loss: 1.015 | Acc: 74.668% (14384/19264)
Loss: 1.014 | Acc: 74.684% (19167/25664)
Loss: 1.019 | Acc: 74.573% (23911/32064)
Loss: 1.022 | Acc: 74.454% (28638/38464)
Loss: 1.026 | Acc: 74.347% (33355/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3018, Accuracy: 6496/10000 (64.96%)

Epoch: 123
Loss: 0.932 | Acc: 78.125% (50/64)
Loss: 0.993 | Acc: 75.015% (4849/6464)
Loss: 1.007 | Acc: 74.883% (9633/12864)
Loss: 1.013 | Acc: 74.834% (14416/19264)
Loss: 1.012 | Acc: 74.891% (19220/25664)
Loss: 1.017 | Acc: 74.760% (23971/32064)
Loss: 1.021 | Acc: 74.633% (28707/38464)
Loss: 1.023 | Acc: 74.603% (33470/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3001, Accuracy: 6599/10000 (65.99%)

Epoch: 124
Loss: 0.898 | Acc: 81.250% (52/64)
Loss: 0.998 | Acc: 75.294% (4867/6464)
Loss: 0.996 | Acc: 75.233% (9678/12864)
Loss: 1.006 | Acc: 75.010% (14450/19264)
Loss: 1.003 | Acc: 75.121% (19279/25664)
Loss: 1.007 | Acc: 75.059% (24067/32064)
Loss: 1.005 | Acc: 75.143% (28903/38464)
Loss: 1.013 | Acc: 74.880% (33594/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2602, Accuracy: 6753/10000 (67.53%)

Epoch: 125
Loss: 1.040 | Acc: 70.312% (45/64)
Loss: 0.990 | Acc: 75.464% (4878/6464)
Loss: 0.986 | Acc: 75.529% (9716/12864)
Loss: 1.002 | Acc: 75.073% (14462/19264)
Loss: 1.002 | Acc: 75.132% (19282/25664)
Loss: 1.005 | Acc: 75.175% (24104/32064)
Loss: 1.003 | Acc: 75.190% (28921/38464)
Loss: 1.005 | Acc: 75.105% (33695/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4157, Accuracy: 6030/10000 (60.30%)

Epoch: 126
Loss: 0.914 | Acc: 78.125% (50/64)
Loss: 0.959 | Acc: 76.176% (4924/6464)
Loss: 0.967 | Acc: 76.073% (9786/12864)
Loss: 0.980 | Acc: 75.732% (14589/19264)
Loss: 0.985 | Acc: 75.635% (19411/25664)
Loss: 0.988 | Acc: 75.633% (24251/32064)
Loss: 0.988 | Acc: 75.629% (29090/38464)
Loss: 0.990 | Acc: 75.548% (33894/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1986, Accuracy: 6992/10000 (69.92%)

Epoch: 127
Loss: 0.917 | Acc: 78.125% (50/64)
Loss: 0.950 | Acc: 76.748% (4961/6464)
Loss: 0.972 | Acc: 76.073% (9786/12864)
Loss: 0.977 | Acc: 75.908% (14623/19264)
Loss: 0.982 | Acc: 75.736% (19437/25664)
Loss: 0.986 | Acc: 75.699% (24272/32064)
Loss: 0.981 | Acc: 75.788% (29151/38464)
Loss: 0.978 | Acc: 75.916% (34059/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2457, Accuracy: 6735/10000 (67.35%)

Epoch: 128
Loss: 1.273 | Acc: 65.625% (42/64)
Loss: 0.942 | Acc: 76.887% (4970/6464)
Loss: 0.961 | Acc: 76.399% (9828/12864)
Loss: 0.959 | Acc: 76.329% (14704/19264)
Loss: 0.962 | Acc: 76.235% (19565/25664)
Loss: 0.965 | Acc: 76.188% (24429/32064)
Loss: 0.966 | Acc: 76.206% (29312/38464)
Loss: 0.968 | Acc: 76.108% (34145/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2721, Accuracy: 6735/10000 (67.35%)

Epoch: 129
Loss: 0.973 | Acc: 71.875% (46/64)
Loss: 0.934 | Acc: 77.042% (4980/6464)
Loss: 0.936 | Acc: 77.169% (9927/12864)
Loss: 0.928 | Acc: 77.388% (14908/19264)
Loss: 0.934 | Acc: 77.178% (19807/25664)
Loss: 0.948 | Acc: 76.868% (24647/32064)
Loss: 0.951 | Acc: 76.825% (29550/38464)
Loss: 0.952 | Acc: 76.805% (34458/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2978, Accuracy: 6723/10000 (67.23%)

Epoch: 130
Loss: 1.053 | Acc: 71.875% (46/64)
Loss: 0.929 | Acc: 77.058% (4981/6464)
Loss: 0.952 | Acc: 76.632% (9858/12864)
Loss: 0.948 | Acc: 76.817% (14798/19264)
Loss: 0.945 | Acc: 76.917% (19740/25664)
Loss: 0.943 | Acc: 76.893% (24655/32064)
Loss: 0.942 | Acc: 76.955% (29600/38464)
Loss: 0.942 | Acc: 76.959% (34527/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2675, Accuracy: 6739/10000 (67.39%)

Epoch: 131
Loss: 0.852 | Acc: 79.688% (51/64)
Loss: 0.904 | Acc: 77.924% (5037/6464)
Loss: 0.903 | Acc: 77.954% (10028/12864)
Loss: 0.908 | Acc: 77.886% (15004/19264)
Loss: 0.912 | Acc: 77.654% (19929/25664)
Loss: 0.918 | Acc: 77.595% (24880/32064)
Loss: 0.919 | Acc: 77.540% (29825/38464)
Loss: 0.924 | Acc: 77.414% (34731/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1686, Accuracy: 7074/10000 (70.74%)

Epoch: 132
Loss: 1.063 | Acc: 75.000% (48/64)
Loss: 0.898 | Acc: 77.924% (5037/6464)
Loss: 0.900 | Acc: 77.915% (10023/12864)
Loss: 0.898 | Acc: 77.938% (15014/19264)
Loss: 0.901 | Acc: 77.868% (19984/25664)
Loss: 0.906 | Acc: 77.723% (24921/32064)
Loss: 0.906 | Acc: 77.792% (29922/38464)
Loss: 0.907 | Acc: 77.820% (34913/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2489, Accuracy: 6838/10000 (68.38%)

Epoch: 133
Loss: 0.913 | Acc: 76.562% (49/64)
Loss: 0.845 | Acc: 79.440% (5135/6464)
Loss: 0.870 | Acc: 78.778% (10134/12864)
Loss: 0.884 | Acc: 78.296% (15083/19264)
Loss: 0.887 | Acc: 78.277% (20089/25664)
Loss: 0.892 | Acc: 78.169% (25064/32064)
Loss: 0.891 | Acc: 78.109% (30044/38464)
Loss: 0.887 | Acc: 78.348% (35150/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2237, Accuracy: 6973/10000 (69.73%)

Epoch: 134
Loss: 0.894 | Acc: 78.125% (50/64)
Loss: 0.852 | Acc: 79.053% (5110/6464)
Loss: 0.855 | Acc: 79.050% (10169/12864)
Loss: 0.858 | Acc: 79.049% (15228/19264)
Loss: 0.857 | Acc: 79.080% (20295/25664)
Loss: 0.862 | Acc: 78.927% (25307/32064)
Loss: 0.862 | Acc: 78.931% (30360/38464)
Loss: 0.861 | Acc: 78.930% (35411/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1970, Accuracy: 7131/10000 (71.31%)

Epoch: 135
Loss: 1.035 | Acc: 73.438% (47/64)
Loss: 0.795 | Acc: 80.585% (5209/6464)
Loss: 0.807 | Acc: 80.208% (10318/12864)
Loss: 0.817 | Acc: 80.051% (15421/19264)
Loss: 0.824 | Acc: 79.855% (20494/25664)
Loss: 0.828 | Acc: 79.784% (25582/32064)
Loss: 0.836 | Acc: 79.628% (30628/38464)
Loss: 0.834 | Acc: 79.659% (35738/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1685, Accuracy: 7261/10000 (72.61%)

Epoch: 136
Loss: 1.168 | Acc: 70.312% (45/64)
Loss: 0.800 | Acc: 79.935% (5167/6464)
Loss: 0.803 | Acc: 79.905% (10279/12864)
Loss: 0.797 | Acc: 80.233% (15456/19264)
Loss: 0.807 | Acc: 79.960% (20521/25664)
Loss: 0.809 | Acc: 79.915% (25624/32064)
Loss: 0.815 | Acc: 79.843% (30711/38464)
Loss: 0.814 | Acc: 79.939% (35864/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2719, Accuracy: 6876/10000 (68.76%)

Epoch: 137
Loss: 0.719 | Acc: 82.812% (53/64)
Loss: 0.767 | Acc: 80.848% (5226/6464)
Loss: 0.767 | Acc: 80.745% (10387/12864)
Loss: 0.775 | Acc: 80.669% (15540/19264)
Loss: 0.774 | Acc: 80.736% (20720/25664)
Loss: 0.777 | Acc: 80.679% (25869/32064)
Loss: 0.784 | Acc: 80.577% (30993/38464)
Loss: 0.783 | Acc: 80.666% (36190/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2335, Accuracy: 7062/10000 (70.62%)

Epoch: 138
Loss: 0.733 | Acc: 78.125% (50/64)
Loss: 0.738 | Acc: 81.668% (5279/6464)
Loss: 0.738 | Acc: 81.631% (10501/12864)
Loss: 0.741 | Acc: 81.520% (15704/19264)
Loss: 0.734 | Acc: 81.721% (20973/25664)
Loss: 0.740 | Acc: 81.553% (26149/32064)
Loss: 0.737 | Acc: 81.648% (31405/38464)
Loss: 0.740 | Acc: 81.558% (36590/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2373, Accuracy: 7200/10000 (72.00%)

Epoch: 139
Loss: 0.569 | Acc: 84.375% (54/64)
Loss: 0.691 | Acc: 82.441% (5329/6464)
Loss: 0.697 | Acc: 82.424% (10603/12864)
Loss: 0.697 | Acc: 82.392% (15872/19264)
Loss: 0.703 | Acc: 82.290% (21119/25664)
Loss: 0.707 | Acc: 82.198% (26356/32064)
Loss: 0.707 | Acc: 82.228% (31628/38464)
Loss: 0.710 | Acc: 82.200% (36878/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2531, Accuracy: 7165/10000 (71.65%)

Epoch: 140
Loss: 0.496 | Acc: 85.938% (55/64)
Loss: 0.636 | Acc: 83.849% (5420/6464)
Loss: 0.646 | Acc: 83.567% (10750/12864)
Loss: 0.654 | Acc: 83.394% (16065/19264)
Loss: 0.661 | Acc: 83.206% (21354/25664)
Loss: 0.657 | Acc: 83.287% (26705/32064)
Loss: 0.661 | Acc: 83.124% (31973/38464)
Loss: 0.662 | Acc: 83.120% (37291/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3072, Accuracy: 7122/10000 (71.22%)

Epoch: 141
Loss: 0.520 | Acc: 89.062% (57/64)
Loss: 0.592 | Acc: 84.499% (5462/6464)
Loss: 0.609 | Acc: 84.087% (10817/12864)
Loss: 0.616 | Acc: 83.830% (16149/19264)
Loss: 0.623 | Acc: 83.713% (21484/25664)
Loss: 0.622 | Acc: 83.817% (26875/32064)
Loss: 0.618 | Acc: 83.907% (32274/38464)
Loss: 0.624 | Acc: 83.746% (37572/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3627, Accuracy: 7088/10000 (70.88%)

Epoch: 142
Loss: 0.552 | Acc: 89.062% (57/64)
Loss: 0.572 | Acc: 84.653% (5472/6464)
Loss: 0.567 | Acc: 84.927% (10925/12864)
Loss: 0.571 | Acc: 84.806% (16337/19264)
Loss: 0.566 | Acc: 84.956% (21803/25664)
Loss: 0.563 | Acc: 85.042% (27268/32064)
Loss: 0.563 | Acc: 85.077% (32724/38464)
Loss: 0.566 | Acc: 84.990% (38130/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3770, Accuracy: 7110/10000 (71.10%)

Epoch: 143
Loss: 0.370 | Acc: 92.188% (59/64)
Loss: 0.500 | Acc: 86.618% (5599/6464)
Loss: 0.505 | Acc: 86.427% (11118/12864)
Loss: 0.506 | Acc: 86.524% (16668/19264)
Loss: 0.510 | Acc: 86.362% (22164/25664)
Loss: 0.509 | Acc: 86.359% (27690/32064)
Loss: 0.511 | Acc: 86.268% (33182/38464)
Loss: 0.512 | Acc: 86.154% (38652/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4172, Accuracy: 7025/10000 (70.25%)

Epoch: 144
Loss: 0.475 | Acc: 85.938% (55/64)
Loss: 0.450 | Acc: 87.608% (5663/6464)
Loss: 0.460 | Acc: 87.181% (11215/12864)
Loss: 0.461 | Acc: 87.126% (16784/19264)
Loss: 0.461 | Acc: 87.177% (22373/25664)
Loss: 0.459 | Acc: 87.291% (27989/32064)
Loss: 0.460 | Acc: 87.227% (33551/38464)
Loss: 0.462 | Acc: 87.230% (39135/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4696, Accuracy: 7089/10000 (70.89%)

Epoch: 145
Loss: 0.316 | Acc: 93.750% (60/64)
Loss: 0.402 | Acc: 88.769% (5738/6464)
Loss: 0.403 | Acc: 88.643% (11403/12864)
Loss: 0.408 | Acc: 88.621% (17072/19264)
Loss: 0.409 | Acc: 88.560% (22728/25664)
Loss: 0.409 | Acc: 88.607% (28411/32064)
Loss: 0.412 | Acc: 88.524% (34050/38464)
Loss: 0.411 | Acc: 88.528% (39717/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4962, Accuracy: 7042/10000 (70.42%)

Epoch: 146
Loss: 0.551 | Acc: 79.688% (51/64)
Loss: 0.361 | Acc: 89.666% (5796/6464)
Loss: 0.377 | Acc: 89.288% (11486/12864)
Loss: 0.377 | Acc: 89.281% (17199/19264)
Loss: 0.376 | Acc: 89.335% (22927/25664)
Loss: 0.377 | Acc: 89.337% (28645/32064)
Loss: 0.379 | Acc: 89.229% (34321/38464)
Loss: 0.377 | Acc: 89.346% (40084/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5171, Accuracy: 7027/10000 (70.27%)

Epoch: 147
Loss: 0.196 | Acc: 93.750% (60/64)
Loss: 0.330 | Acc: 90.857% (5873/6464)
Loss: 0.334 | Acc: 90.641% (11660/12864)
Loss: 0.345 | Acc: 90.215% (17379/19264)
Loss: 0.342 | Acc: 90.255% (23163/25664)
Loss: 0.343 | Acc: 90.285% (28949/32064)
Loss: 0.344 | Acc: 90.230% (34706/38464)
Loss: 0.346 | Acc: 90.179% (40458/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5177, Accuracy: 7056/10000 (70.56%)
torch.Size([100, 10])
Test set: Average loss: 1.5177, Accuracy: 7056/10000 (70.56%)

Epoch: 148
Loss: 0.208 | Acc: 93.750% (60/64)
Loss: 0.334 | Acc: 90.548% (5853/6464)
Loss: 0.326 | Acc: 90.812% (11682/12864)
Loss: 0.327 | Acc: 90.750% (17482/19264)
Loss: 0.329 | Acc: 90.668% (23269/25664)
Loss: 0.329 | Acc: 90.656% (29068/32064)
Loss: 0.332 | Acc: 90.513% (34815/38464)
Loss: 0.333 | Acc: 90.500% (40602/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5226, Accuracy: 7062/10000 (70.62%)
torch.Size([100, 10])
Test set: Average loss: 1.5226, Accuracy: 7062/10000 (70.62%)

Epoch: 149
Loss: 0.310 | Acc: 93.750% (60/64)
Loss: 0.333 | Acc: 90.285% (5836/6464)
Loss: 0.325 | Acc: 90.695% (11667/12864)
Loss: 0.322 | Acc: 90.760% (17484/19264)
Loss: 0.321 | Acc: 90.750% (23290/25664)
Loss: 0.321 | Acc: 90.778% (29107/32064)
Loss: 0.325 | Acc: 90.695% (34885/38464)
Loss: 0.322 | Acc: 90.774% (40725/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5346, Accuracy: 7072/10000 (70.72%)
torch.Size([100, 10])
Test set: Average loss: 1.5346, Accuracy: 7072/10000 (70.72%)

Epoch: 150
Loss: 0.269 | Acc: 92.188% (59/64)
Loss: 1.758 | Acc: 43.363% (2803/6464)
Loss: 1.533 | Acc: 53.529% (6886/12864)
Loss: 1.439 | Acc: 57.262% (11031/19264)
Loss: 1.386 | Acc: 59.730% (15329/25664)
Loss: 1.342 | Acc: 61.486% (19715/32064)
Loss: 1.312 | Acc: 62.809% (24159/38464)
Loss: 1.291 | Acc: 63.733% (28593/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7305, Accuracy: 4980/10000 (49.80%)

Epoch: 151
Loss: 0.925 | Acc: 75.000% (48/64)
Loss: 1.139 | Acc: 69.756% (4509/6464)
Loss: 1.139 | Acc: 70.025% (9008/12864)
Loss: 1.148 | Acc: 69.638% (13415/19264)
Loss: 1.145 | Acc: 69.802% (17914/25664)
Loss: 1.142 | Acc: 69.935% (22424/32064)
Loss: 1.139 | Acc: 70.071% (26952/38464)
Loss: 1.138 | Acc: 70.119% (31458/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9480, Accuracy: 4513/10000 (45.13%)

Epoch: 152
Loss: 1.205 | Acc: 65.625% (42/64)
Loss: 1.104 | Acc: 71.457% (4619/6464)
Loss: 1.098 | Acc: 71.517% (9200/12864)
Loss: 1.117 | Acc: 71.018% (13681/19264)
Loss: 1.120 | Acc: 70.772% (18163/25664)
Loss: 1.124 | Acc: 70.634% (22648/32064)
Loss: 1.124 | Acc: 70.658% (27178/38464)
Loss: 1.120 | Acc: 70.796% (31762/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6543, Accuracy: 4944/10000 (49.44%)

Epoch: 153
Loss: 1.150 | Acc: 67.188% (43/64)
Loss: 1.121 | Acc: 70.885% (4582/6464)
Loss: 1.097 | Acc: 71.681% (9221/12864)
Loss: 1.110 | Acc: 71.491% (13772/19264)
Loss: 1.107 | Acc: 71.641% (18386/25664)
Loss: 1.110 | Acc: 71.476% (22918/32064)
Loss: 1.113 | Acc: 71.334% (27438/38464)
Loss: 1.115 | Acc: 71.293% (31985/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2779, Accuracy: 6552/10000 (65.52%)

Epoch: 154
Loss: 1.221 | Acc: 70.312% (45/64)
Loss: 1.075 | Acc: 71.813% (4642/6464)
Loss: 1.094 | Acc: 71.463% (9193/12864)
Loss: 1.099 | Acc: 71.377% (13750/19264)
Loss: 1.103 | Acc: 71.446% (18336/25664)
Loss: 1.107 | Acc: 71.423% (22901/32064)
Loss: 1.108 | Acc: 71.394% (27461/38464)
Loss: 1.109 | Acc: 71.345% (32008/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4630, Accuracy: 5845/10000 (58.45%)

Epoch: 155
Loss: 1.228 | Acc: 65.625% (42/64)
Loss: 1.115 | Acc: 71.364% (4613/6464)
Loss: 1.118 | Acc: 71.377% (9182/12864)
Loss: 1.098 | Acc: 71.885% (13848/19264)
Loss: 1.104 | Acc: 71.684% (18397/25664)
Loss: 1.103 | Acc: 71.660% (22977/32064)
Loss: 1.107 | Acc: 71.550% (27521/38464)
Loss: 1.109 | Acc: 71.483% (32070/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4087, Accuracy: 5978/10000 (59.78%)

Epoch: 156
Loss: 0.843 | Acc: 78.125% (50/64)
Loss: 1.111 | Acc: 71.395% (4615/6464)
Loss: 1.098 | Acc: 71.650% (9217/12864)
Loss: 1.090 | Acc: 71.859% (13843/19264)
Loss: 1.093 | Acc: 71.793% (18425/25664)
Loss: 1.099 | Acc: 71.563% (22946/32064)
Loss: 1.104 | Acc: 71.516% (27508/38464)
Loss: 1.108 | Acc: 71.387% (32027/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6011, Accuracy: 5332/10000 (53.32%)

Epoch: 157
Loss: 1.068 | Acc: 67.188% (43/64)
Loss: 1.098 | Acc: 71.798% (4641/6464)
Loss: 1.090 | Acc: 71.898% (9249/12864)
Loss: 1.098 | Acc: 71.740% (13820/19264)
Loss: 1.103 | Acc: 71.540% (18360/25664)
Loss: 1.105 | Acc: 71.507% (22928/32064)
Loss: 1.104 | Acc: 71.529% (27513/38464)
Loss: 1.104 | Acc: 71.590% (32118/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2856, Accuracy: 6555/10000 (65.55%)

Epoch: 158
Loss: 1.435 | Acc: 62.500% (40/64)
Loss: 1.103 | Acc: 71.968% (4652/6464)
Loss: 1.097 | Acc: 72.030% (9266/12864)
Loss: 1.094 | Acc: 72.051% (13880/19264)
Loss: 1.095 | Acc: 71.972% (18471/25664)
Loss: 1.095 | Acc: 72.053% (23103/32064)
Loss: 1.097 | Acc: 71.914% (27661/38464)
Loss: 1.101 | Acc: 71.828% (32225/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3685, Accuracy: 6202/10000 (62.02%)

Epoch: 159
Loss: 1.045 | Acc: 73.438% (47/64)
Loss: 1.089 | Acc: 71.736% (4637/6464)
Loss: 1.090 | Acc: 72.163% (9283/12864)
Loss: 1.087 | Acc: 72.285% (13925/19264)
Loss: 1.093 | Acc: 72.046% (18490/25664)
Loss: 1.090 | Acc: 72.062% (23106/32064)
Loss: 1.097 | Acc: 71.818% (27624/38464)
Loss: 1.099 | Acc: 71.804% (32214/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6667, Accuracy: 5235/10000 (52.35%)

Epoch: 160
Loss: 1.207 | Acc: 65.625% (42/64)
Loss: 1.099 | Acc: 71.813% (4642/6464)
Loss: 1.093 | Acc: 71.976% (9259/12864)
Loss: 1.090 | Acc: 71.865% (13844/19264)
Loss: 1.090 | Acc: 71.910% (18455/25664)
Loss: 1.088 | Acc: 72.040% (23099/32064)
Loss: 1.091 | Acc: 72.026% (27704/38464)
Loss: 1.094 | Acc: 71.973% (32290/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8164, Accuracy: 4753/10000 (47.53%)

Epoch: 161
Loss: 1.651 | Acc: 56.250% (36/64)
Loss: 1.104 | Acc: 71.705% (4635/6464)
Loss: 1.095 | Acc: 71.883% (9247/12864)
Loss: 1.102 | Acc: 71.818% (13835/19264)
Loss: 1.104 | Acc: 71.739% (18411/25664)
Loss: 1.100 | Acc: 71.884% (23049/32064)
Loss: 1.103 | Acc: 71.784% (27611/38464)
Loss: 1.100 | Acc: 71.920% (32266/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5249, Accuracy: 5542/10000 (55.42%)

Epoch: 162
Loss: 1.144 | Acc: 70.312% (45/64)
Loss: 1.062 | Acc: 72.664% (4697/6464)
Loss: 1.067 | Acc: 72.831% (9369/12864)
Loss: 1.070 | Acc: 72.674% (14000/19264)
Loss: 1.080 | Acc: 72.491% (18604/25664)
Loss: 1.086 | Acc: 72.321% (23189/32064)
Loss: 1.088 | Acc: 72.262% (27795/38464)
Loss: 1.089 | Acc: 72.254% (32416/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6241, Accuracy: 5570/10000 (55.70%)

Epoch: 163
Loss: 0.985 | Acc: 73.438% (47/64)
Loss: 1.049 | Acc: 73.283% (4737/6464)
Loss: 1.062 | Acc: 73.119% (9406/12864)
Loss: 1.071 | Acc: 72.908% (14045/19264)
Loss: 1.077 | Acc: 72.732% (18666/25664)
Loss: 1.081 | Acc: 72.633% (23289/32064)
Loss: 1.084 | Acc: 72.538% (27901/38464)
Loss: 1.087 | Acc: 72.459% (32508/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6804, Accuracy: 5387/10000 (53.87%)

Epoch: 164
Loss: 1.096 | Acc: 68.750% (44/64)
Loss: 1.065 | Acc: 73.376% (4743/6464)
Loss: 1.051 | Acc: 73.725% (9484/12864)
Loss: 1.065 | Acc: 73.401% (14140/19264)
Loss: 1.071 | Acc: 73.137% (18770/25664)
Loss: 1.071 | Acc: 73.026% (23415/32064)
Loss: 1.075 | Acc: 72.928% (28051/38464)
Loss: 1.078 | Acc: 72.742% (32635/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4343, Accuracy: 5945/10000 (59.45%)

Epoch: 165
Loss: 1.391 | Acc: 65.625% (42/64)
Loss: 1.089 | Acc: 72.092% (4660/6464)
Loss: 1.078 | Acc: 72.536% (9331/12864)
Loss: 1.071 | Acc: 72.825% (14029/19264)
Loss: 1.071 | Acc: 72.911% (18712/25664)
Loss: 1.075 | Acc: 72.817% (23348/32064)
Loss: 1.073 | Acc: 72.829% (28013/38464)
Loss: 1.073 | Acc: 72.800% (32661/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2318, Accuracy: 6787/10000 (67.87%)

Epoch: 166
Loss: 1.284 | Acc: 59.375% (38/64)
Loss: 1.033 | Acc: 74.165% (4794/6464)
Loss: 1.045 | Acc: 73.795% (9493/12864)
Loss: 1.045 | Acc: 73.775% (14212/19264)
Loss: 1.055 | Acc: 73.457% (18852/25664)
Loss: 1.062 | Acc: 73.200% (23471/32064)
Loss: 1.068 | Acc: 72.954% (28061/38464)
Loss: 1.070 | Acc: 72.945% (32726/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4815, Accuracy: 5935/10000 (59.35%)

Epoch: 167
Loss: 0.893 | Acc: 76.562% (49/64)
Loss: 1.052 | Acc: 73.670% (4762/6464)
Loss: 1.063 | Acc: 73.290% (9428/12864)
Loss: 1.059 | Acc: 73.427% (14145/19264)
Loss: 1.058 | Acc: 73.508% (18865/25664)
Loss: 1.057 | Acc: 73.475% (23559/32064)
Loss: 1.057 | Acc: 73.469% (28259/38464)
Loss: 1.063 | Acc: 73.273% (32873/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4388, Accuracy: 6146/10000 (61.46%)

Epoch: 168
Loss: 0.699 | Acc: 82.812% (53/64)
Loss: 1.030 | Acc: 74.459% (4813/6464)
Loss: 1.051 | Acc: 73.702% (9481/12864)
Loss: 1.051 | Acc: 73.541% (14167/19264)
Loss: 1.052 | Acc: 73.547% (18875/25664)
Loss: 1.056 | Acc: 73.403% (23536/32064)
Loss: 1.057 | Acc: 73.391% (28229/38464)
Loss: 1.057 | Acc: 73.368% (32916/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4827, Accuracy: 5793/10000 (57.93%)

Epoch: 169
Loss: 1.075 | Acc: 68.750% (44/64)
Loss: 1.035 | Acc: 73.793% (4770/6464)
Loss: 1.049 | Acc: 73.492% (9454/12864)
Loss: 1.056 | Acc: 73.443% (14148/19264)
Loss: 1.048 | Acc: 73.722% (18920/25664)
Loss: 1.055 | Acc: 73.459% (23554/32064)
Loss: 1.051 | Acc: 73.567% (28297/38464)
Loss: 1.054 | Acc: 73.462% (32958/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3565, Accuracy: 6258/10000 (62.58%)

Epoch: 170
Loss: 1.466 | Acc: 64.062% (41/64)
Loss: 1.027 | Acc: 74.474% (4814/6464)
Loss: 1.035 | Acc: 74.207% (9546/12864)
Loss: 1.042 | Acc: 73.920% (14240/19264)
Loss: 1.044 | Acc: 73.815% (18944/25664)
Loss: 1.044 | Acc: 73.784% (23658/32064)
Loss: 1.040 | Acc: 73.944% (28442/38464)
Loss: 1.044 | Acc: 73.892% (33151/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7593, Accuracy: 5070/10000 (50.70%)

Epoch: 171
Loss: 1.047 | Acc: 71.875% (46/64)
Loss: 1.007 | Acc: 74.876% (4840/6464)
Loss: 1.020 | Acc: 74.611% (9598/12864)
Loss: 1.019 | Acc: 74.585% (14368/19264)
Loss: 1.028 | Acc: 74.349% (19081/25664)
Loss: 1.030 | Acc: 74.348% (23839/32064)
Loss: 1.034 | Acc: 74.243% (28557/38464)
Loss: 1.036 | Acc: 74.180% (33280/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3910, Accuracy: 6136/10000 (61.36%)

Epoch: 172
Loss: 1.364 | Acc: 65.625% (42/64)
Loss: 1.029 | Acc: 73.747% (4767/6464)
Loss: 1.024 | Acc: 74.160% (9540/12864)
Loss: 1.021 | Acc: 74.408% (14334/19264)
Loss: 1.021 | Acc: 74.322% (19074/25664)
Loss: 1.021 | Acc: 74.467% (23877/32064)
Loss: 1.023 | Acc: 74.412% (28622/38464)
Loss: 1.026 | Acc: 74.305% (33336/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2406, Accuracy: 6742/10000 (67.42%)

Epoch: 173
Loss: 0.884 | Acc: 79.688% (51/64)
Loss: 1.008 | Acc: 75.170% (4859/6464)
Loss: 1.012 | Acc: 74.821% (9625/12864)
Loss: 1.016 | Acc: 74.860% (14421/19264)
Loss: 1.019 | Acc: 74.801% (19197/25664)
Loss: 1.020 | Acc: 74.804% (23985/32064)
Loss: 1.018 | Acc: 74.810% (28775/38464)
Loss: 1.018 | Acc: 74.773% (33546/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3808, Accuracy: 6310/10000 (63.10%)

Epoch: 174
Loss: 1.174 | Acc: 62.500% (40/64)
Loss: 0.996 | Acc: 75.077% (4853/6464)
Loss: 0.999 | Acc: 75.132% (9665/12864)
Loss: 0.990 | Acc: 75.374% (14520/19264)
Loss: 0.999 | Acc: 75.082% (19269/25664)
Loss: 1.003 | Acc: 75.006% (24050/32064)
Loss: 1.002 | Acc: 75.039% (28863/38464)
Loss: 1.006 | Acc: 74.964% (33632/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3368, Accuracy: 6410/10000 (64.10%)

Epoch: 175
Loss: 1.277 | Acc: 68.750% (44/64)
Loss: 0.982 | Acc: 75.774% (4898/6464)
Loss: 0.972 | Acc: 75.979% (9774/12864)
Loss: 0.980 | Acc: 75.831% (14608/19264)
Loss: 0.987 | Acc: 75.682% (19423/25664)
Loss: 0.982 | Acc: 75.795% (24303/32064)
Loss: 0.984 | Acc: 75.712% (29122/38464)
Loss: 0.991 | Acc: 75.502% (33873/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1683, Accuracy: 7043/10000 (70.43%)

Epoch: 176
Loss: 1.120 | Acc: 71.875% (46/64)
Loss: 0.990 | Acc: 75.820% (4901/6464)
Loss: 0.991 | Acc: 75.707% (9739/12864)
Loss: 0.988 | Acc: 75.659% (14575/19264)
Loss: 0.989 | Acc: 75.549% (19389/25664)
Loss: 0.989 | Acc: 75.533% (24219/32064)
Loss: 0.986 | Acc: 75.676% (29108/38464)
Loss: 0.983 | Acc: 75.744% (33982/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2712, Accuracy: 6681/10000 (66.81%)

Epoch: 177
Loss: 0.935 | Acc: 76.562% (49/64)
Loss: 0.989 | Acc: 75.511% (4881/6464)
Loss: 0.965 | Acc: 75.964% (9772/12864)
Loss: 0.969 | Acc: 76.043% (14649/19264)
Loss: 0.972 | Acc: 75.908% (19481/25664)
Loss: 0.974 | Acc: 75.830% (24314/32064)
Loss: 0.979 | Acc: 75.697% (29116/38464)
Loss: 0.976 | Acc: 75.874% (34040/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3652, Accuracy: 6221/10000 (62.21%)

Epoch: 178
Loss: 0.772 | Acc: 78.125% (50/64)
Loss: 0.918 | Acc: 77.568% (5014/6464)
Loss: 0.935 | Acc: 77.262% (9939/12864)
Loss: 0.948 | Acc: 76.786% (14792/19264)
Loss: 0.953 | Acc: 76.481% (19628/25664)
Loss: 0.955 | Acc: 76.513% (24533/32064)
Loss: 0.956 | Acc: 76.485% (29419/38464)
Loss: 0.961 | Acc: 76.411% (34281/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3760, Accuracy: 6407/10000 (64.07%)

Epoch: 179
Loss: 1.054 | Acc: 75.000% (48/64)
Loss: 0.960 | Acc: 76.083% (4918/6464)
Loss: 0.950 | Acc: 76.438% (9833/12864)
Loss: 0.946 | Acc: 76.760% (14787/19264)
Loss: 0.946 | Acc: 76.788% (19707/25664)
Loss: 0.943 | Acc: 76.906% (24659/32064)
Loss: 0.940 | Acc: 76.973% (29607/38464)
Loss: 0.942 | Acc: 76.946% (34521/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1700, Accuracy: 7091/10000 (70.91%)

Epoch: 180
Loss: 0.657 | Acc: 81.250% (52/64)
Loss: 0.919 | Acc: 77.351% (5000/6464)
Loss: 0.928 | Acc: 77.262% (9939/12864)
Loss: 0.919 | Acc: 77.476% (14925/19264)
Loss: 0.918 | Acc: 77.579% (19910/25664)
Loss: 0.922 | Acc: 77.576% (24874/32064)
Loss: 0.928 | Acc: 77.506% (29812/38464)
Loss: 0.931 | Acc: 77.401% (34725/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2007, Accuracy: 6975/10000 (69.75%)

Epoch: 181
Loss: 0.952 | Acc: 76.562% (49/64)
Loss: 0.891 | Acc: 78.218% (5056/6464)
Loss: 0.881 | Acc: 78.296% (10072/12864)
Loss: 0.891 | Acc: 78.161% (15057/19264)
Loss: 0.900 | Acc: 77.965% (20009/25664)
Loss: 0.900 | Acc: 78.103% (25043/32064)
Loss: 0.905 | Acc: 77.953% (29984/38464)
Loss: 0.910 | Acc: 77.842% (34923/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3611, Accuracy: 6449/10000 (64.49%)

Epoch: 182
Loss: 1.218 | Acc: 70.312% (45/64)
Loss: 0.888 | Acc: 78.264% (5059/6464)
Loss: 0.863 | Acc: 79.167% (10184/12864)
Loss: 0.874 | Acc: 78.779% (15176/19264)
Loss: 0.880 | Acc: 78.577% (20166/25664)
Loss: 0.887 | Acc: 78.409% (25141/32064)
Loss: 0.891 | Acc: 78.312% (30122/38464)
Loss: 0.893 | Acc: 78.236% (35100/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1774, Accuracy: 7186/10000 (71.86%)

Epoch: 183
Loss: 0.884 | Acc: 81.250% (52/64)
Loss: 0.856 | Acc: 79.192% (5119/6464)
Loss: 0.859 | Acc: 79.151% (10182/12864)
Loss: 0.868 | Acc: 78.867% (15193/19264)
Loss: 0.871 | Acc: 78.671% (20190/25664)
Loss: 0.875 | Acc: 78.599% (25202/32064)
Loss: 0.876 | Acc: 78.577% (30224/38464)
Loss: 0.877 | Acc: 78.602% (35264/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2327, Accuracy: 6969/10000 (69.69%)

Epoch: 184
Loss: 0.815 | Acc: 78.125% (50/64)
Loss: 0.830 | Acc: 79.595% (5145/6464)
Loss: 0.847 | Acc: 79.190% (10187/12864)
Loss: 0.855 | Acc: 79.013% (15221/19264)
Loss: 0.852 | Acc: 79.185% (20322/25664)
Loss: 0.851 | Acc: 79.254% (25412/32064)
Loss: 0.850 | Acc: 79.251% (30483/38464)
Loss: 0.852 | Acc: 79.266% (35562/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2028, Accuracy: 7106/10000 (71.06%)

Epoch: 185
Loss: 1.003 | Acc: 78.125% (50/64)
Loss: 0.790 | Acc: 80.523% (5205/6464)
Loss: 0.796 | Acc: 80.488% (10354/12864)
Loss: 0.796 | Acc: 80.409% (15490/19264)
Loss: 0.810 | Acc: 80.124% (20563/25664)
Loss: 0.815 | Acc: 79.959% (25638/32064)
Loss: 0.818 | Acc: 79.997% (30770/38464)
Loss: 0.824 | Acc: 79.832% (35816/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1803, Accuracy: 7161/10000 (71.61%)

Epoch: 186
Loss: 0.417 | Acc: 93.750% (60/64)
Loss: 0.778 | Acc: 80.910% (5230/6464)
Loss: 0.786 | Acc: 80.768% (10390/12864)
Loss: 0.795 | Acc: 80.663% (15539/19264)
Loss: 0.798 | Acc: 80.619% (20690/25664)
Loss: 0.803 | Acc: 80.467% (25801/32064)
Loss: 0.802 | Acc: 80.324% (30896/38464)
Loss: 0.803 | Acc: 80.303% (36027/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2290, Accuracy: 7131/10000 (71.31%)

Epoch: 187
Loss: 0.602 | Acc: 87.500% (56/64)
Loss: 0.760 | Acc: 80.879% (5228/6464)
Loss: 0.751 | Acc: 81.273% (10455/12864)
Loss: 0.755 | Acc: 81.099% (15623/19264)
Loss: 0.763 | Acc: 81.043% (20799/25664)
Loss: 0.764 | Acc: 81.047% (25987/32064)
Loss: 0.769 | Acc: 80.995% (31154/38464)
Loss: 0.772 | Acc: 80.925% (36306/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2472, Accuracy: 7091/10000 (70.91%)

Epoch: 188
Loss: 0.731 | Acc: 82.812% (53/64)
Loss: 0.749 | Acc: 80.879% (5228/6464)
Loss: 0.741 | Acc: 81.281% (10456/12864)
Loss: 0.742 | Acc: 81.395% (15680/19264)
Loss: 0.741 | Acc: 81.433% (20899/25664)
Loss: 0.740 | Acc: 81.484% (26127/32064)
Loss: 0.737 | Acc: 81.619% (31394/38464)
Loss: 0.739 | Acc: 81.569% (36595/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2679, Accuracy: 7216/10000 (72.16%)

Epoch: 189
Loss: 0.609 | Acc: 82.812% (53/64)
Loss: 0.672 | Acc: 83.261% (5382/6464)
Loss: 0.676 | Acc: 83.053% (10684/12864)
Loss: 0.682 | Acc: 82.958% (15981/19264)
Loss: 0.684 | Acc: 82.906% (21277/25664)
Loss: 0.689 | Acc: 82.747% (26532/32064)
Loss: 0.694 | Acc: 82.592% (31768/38464)
Loss: 0.699 | Acc: 82.480% (37004/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2479, Accuracy: 7290/10000 (72.90%)

Epoch: 190
Loss: 0.589 | Acc: 82.812% (53/64)
Loss: 0.634 | Acc: 83.540% (5400/6464)
Loss: 0.638 | Acc: 83.559% (10749/12864)
Loss: 0.649 | Acc: 83.347% (16056/19264)
Loss: 0.652 | Acc: 83.300% (21378/25664)
Loss: 0.647 | Acc: 83.411% (26745/32064)
Loss: 0.651 | Acc: 83.293% (32038/38464)
Loss: 0.652 | Acc: 83.287% (37366/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3227, Accuracy: 7028/10000 (70.28%)

Epoch: 191
Loss: 0.808 | Acc: 78.125% (50/64)
Loss: 0.588 | Acc: 84.777% (5480/6464)
Loss: 0.585 | Acc: 84.981% (10932/12864)
Loss: 0.589 | Acc: 84.837% (16343/19264)
Loss: 0.594 | Acc: 84.706% (21739/25664)
Loss: 0.599 | Acc: 84.565% (27115/32064)
Loss: 0.606 | Acc: 84.318% (32432/38464)
Loss: 0.607 | Acc: 84.313% (37826/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3344, Accuracy: 7088/10000 (70.88%)

Epoch: 192
Loss: 0.638 | Acc: 81.250% (52/64)
Loss: 0.557 | Acc: 84.870% (5486/6464)
Loss: 0.547 | Acc: 85.269% (10969/12864)
Loss: 0.546 | Acc: 85.325% (16437/19264)
Loss: 0.549 | Acc: 85.260% (21881/25664)
Loss: 0.554 | Acc: 85.077% (27279/32064)
Loss: 0.553 | Acc: 85.178% (32763/38464)
Loss: 0.555 | Acc: 85.146% (38200/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3855, Accuracy: 7198/10000 (71.98%)

Epoch: 193
Loss: 0.355 | Acc: 90.625% (58/64)
Loss: 0.504 | Acc: 86.386% (5584/6464)
Loss: 0.510 | Acc: 86.039% (11068/12864)
Loss: 0.508 | Acc: 86.181% (16602/19264)
Loss: 0.509 | Acc: 86.214% (22126/25664)
Loss: 0.507 | Acc: 86.290% (27668/32064)
Loss: 0.504 | Acc: 86.400% (33233/38464)
Loss: 0.503 | Acc: 86.390% (38758/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4549, Accuracy: 7053/10000 (70.53%)

Epoch: 194
Loss: 0.622 | Acc: 84.375% (54/64)
Loss: 0.449 | Acc: 87.701% (5669/6464)
Loss: 0.449 | Acc: 87.640% (11274/12864)
Loss: 0.444 | Acc: 87.796% (16913/19264)
Loss: 0.447 | Acc: 87.656% (22496/25664)
Loss: 0.445 | Acc: 87.731% (28130/32064)
Loss: 0.447 | Acc: 87.747% (33751/38464)
Loss: 0.447 | Acc: 87.756% (39371/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4906, Accuracy: 7061/10000 (70.61%)

Epoch: 195
Loss: 0.341 | Acc: 89.062% (57/64)
Loss: 0.394 | Acc: 88.939% (5749/6464)
Loss: 0.397 | Acc: 89.078% (11459/12864)
Loss: 0.406 | Acc: 88.761% (17099/19264)
Loss: 0.406 | Acc: 88.829% (22797/25664)
Loss: 0.408 | Acc: 88.719% (28447/32064)
Loss: 0.406 | Acc: 88.696% (34116/38464)
Loss: 0.407 | Acc: 88.697% (39793/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5012, Accuracy: 7087/10000 (70.87%)

Epoch: 196
Loss: 0.515 | Acc: 82.812% (53/64)
Loss: 0.357 | Acc: 89.851% (5808/6464)
Loss: 0.357 | Acc: 89.793% (11551/12864)
Loss: 0.366 | Acc: 89.582% (17257/19264)
Loss: 0.366 | Acc: 89.631% (23003/25664)
Loss: 0.364 | Acc: 89.708% (28764/32064)
Loss: 0.364 | Acc: 89.689% (34498/38464)
Loss: 0.364 | Acc: 89.716% (40250/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5261, Accuracy: 7030/10000 (70.30%)

Epoch: 197
Loss: 0.272 | Acc: 90.625% (58/64)
Loss: 0.336 | Acc: 90.455% (5847/6464)
Loss: 0.339 | Acc: 90.314% (11618/12864)
Loss: 0.337 | Acc: 90.407% (17416/19264)
Loss: 0.340 | Acc: 90.302% (23175/25664)
Loss: 0.340 | Acc: 90.341% (28967/32064)
Loss: 0.340 | Acc: 90.339% (34748/38464)
Loss: 0.339 | Acc: 90.358% (40538/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5603, Accuracy: 7037/10000 (70.37%)
torch.Size([100, 10])
Test set: Average loss: 1.5603, Accuracy: 7037/10000 (70.37%)

Epoch: 198
Loss: 0.312 | Acc: 90.625% (58/64)
Loss: 0.336 | Acc: 90.053% (5821/6464)
Loss: 0.326 | Acc: 90.508% (11643/12864)
Loss: 0.325 | Acc: 90.687% (17470/19264)
Loss: 0.325 | Acc: 90.769% (23295/25664)
Loss: 0.325 | Acc: 90.731% (29092/32064)
Loss: 0.325 | Acc: 90.791% (34922/38464)
Loss: 0.324 | Acc: 90.826% (40748/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5434, Accuracy: 7033/10000 (70.33%)
torch.Size([100, 10])
Test set: Average loss: 1.5434, Accuracy: 7033/10000 (70.33%)

Epoch: 199
Loss: 0.242 | Acc: 93.750% (60/64)
Loss: 0.334 | Acc: 90.331% (5839/6464)
Loss: 0.324 | Acc: 90.773% (11677/12864)
Loss: 0.323 | Acc: 90.801% (17492/19264)
Loss: 0.320 | Acc: 90.847% (23315/25664)
Loss: 0.321 | Acc: 90.809% (29117/32064)
Loss: 0.317 | Acc: 90.937% (34978/38464)
Loss: 0.319 | Acc: 90.884% (40774/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5579, Accuracy: 7018/10000 (70.18%)
torch.Size([100, 10])
Test set: Average loss: 1.5579, Accuracy: 7018/10000 (70.18%)
7444
10000
-1.2495492696762085
