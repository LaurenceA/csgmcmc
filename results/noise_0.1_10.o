==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.358 | Acc: 15.625% (10/64)
Loss: 3.106 | Acc: 13.598% (879/6464)
Loss: 2.618 | Acc: 16.729% (2152/12864)
Loss: 2.441 | Acc: 18.044% (3476/19264)
Loss: 2.339 | Acc: 19.447% (4991/25664)
Loss: 2.272 | Acc: 20.715% (6642/32064)
Loss: 2.223 | Acc: 21.693% (8344/38464)
Loss: 2.178 | Acc: 22.840% (10247/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2727, Accuracy: 2570/10000 (25.70%)

Epoch: 1
Loss: 2.242 | Acc: 26.562% (17/64)
Loss: 1.843 | Acc: 32.890% (2126/6464)
Loss: 1.836 | Acc: 33.574% (4319/12864)
Loss: 1.823 | Acc: 33.918% (6534/19264)
Loss: 1.814 | Acc: 34.578% (8874/25664)
Loss: 1.802 | Acc: 35.217% (11292/32064)
Loss: 1.792 | Acc: 35.683% (13725/38464)
Loss: 1.781 | Acc: 36.334% (16301/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7418, Accuracy: 4007/10000 (40.07%)

Epoch: 2
Loss: 1.462 | Acc: 50.000% (32/64)
Loss: 1.670 | Acc: 41.074% (2655/6464)
Loss: 1.666 | Acc: 41.294% (5312/12864)
Loss: 1.654 | Acc: 42.120% (8114/19264)
Loss: 1.641 | Acc: 42.784% (10980/25664)
Loss: 1.631 | Acc: 43.214% (13856/32064)
Loss: 1.625 | Acc: 43.646% (16788/38464)
Loss: 1.620 | Acc: 43.937% (19712/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7883, Accuracy: 3916/10000 (39.16%)

Epoch: 3
Loss: 1.625 | Acc: 46.875% (30/64)
Loss: 1.546 | Acc: 47.757% (3087/6464)
Loss: 1.546 | Acc: 47.901% (6162/12864)
Loss: 1.526 | Acc: 48.801% (9401/19264)
Loss: 1.511 | Acc: 49.470% (12696/25664)
Loss: 1.499 | Acc: 50.003% (16033/32064)
Loss: 1.486 | Acc: 50.491% (19421/38464)
Loss: 1.477 | Acc: 50.992% (22877/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8297, Accuracy: 3992/10000 (39.92%)

Epoch: 4
Loss: 1.639 | Acc: 51.562% (33/64)
Loss: 1.395 | Acc: 55.291% (3574/6464)
Loss: 1.372 | Acc: 55.613% (7154/12864)
Loss: 1.363 | Acc: 56.022% (10792/19264)
Loss: 1.356 | Acc: 56.375% (14468/25664)
Loss: 1.349 | Acc: 56.718% (18186/32064)
Loss: 1.339 | Acc: 57.160% (21986/38464)
Loss: 1.333 | Acc: 57.487% (25791/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4262, Accuracy: 5339/10000 (53.39%)

Epoch: 5
Loss: 1.524 | Acc: 54.688% (35/64)
Loss: 1.243 | Acc: 60.968% (3941/6464)
Loss: 1.258 | Acc: 60.432% (7774/12864)
Loss: 1.253 | Acc: 60.834% (11719/19264)
Loss: 1.246 | Acc: 61.113% (15684/25664)
Loss: 1.235 | Acc: 61.446% (19702/32064)
Loss: 1.231 | Acc: 61.710% (23736/38464)
Loss: 1.224 | Acc: 62.032% (27830/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2774, Accuracy: 3060/10000 (30.60%)

Epoch: 6
Loss: 1.356 | Acc: 62.500% (40/64)
Loss: 1.163 | Acc: 64.295% (4156/6464)
Loss: 1.161 | Acc: 64.646% (8316/12864)
Loss: 1.150 | Acc: 65.179% (12556/19264)
Loss: 1.145 | Acc: 65.446% (16796/25664)
Loss: 1.135 | Acc: 65.690% (21063/32064)
Loss: 1.134 | Acc: 65.921% (25356/38464)
Loss: 1.131 | Acc: 66.118% (29663/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8473, Accuracy: 4600/10000 (46.00%)

Epoch: 7
Loss: 1.331 | Acc: 56.250% (36/64)
Loss: 1.073 | Acc: 68.348% (4418/6464)
Loss: 1.085 | Acc: 68.074% (8757/12864)
Loss: 1.086 | Acc: 68.179% (13134/19264)
Loss: 1.078 | Acc: 68.493% (17578/25664)
Loss: 1.070 | Acc: 68.769% (22050/32064)
Loss: 1.069 | Acc: 68.786% (26458/38464)
Loss: 1.063 | Acc: 68.984% (30949/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2311, Accuracy: 6363/10000 (63.63%)

Epoch: 8
Loss: 1.197 | Acc: 68.750% (44/64)
Loss: 1.030 | Acc: 70.699% (4570/6464)
Loss: 1.027 | Acc: 70.600% (9082/12864)
Loss: 1.026 | Acc: 70.858% (13650/19264)
Loss: 1.024 | Acc: 70.870% (18188/25664)
Loss: 1.018 | Acc: 70.921% (22740/32064)
Loss: 1.020 | Acc: 70.827% (27243/38464)
Loss: 1.017 | Acc: 70.975% (31842/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3011, Accuracy: 6172/10000 (61.72%)

Epoch: 9
Loss: 1.128 | Acc: 67.188% (43/64)
Loss: 0.980 | Acc: 71.504% (4622/6464)
Loss: 0.996 | Acc: 71.331% (9176/12864)
Loss: 0.996 | Acc: 71.252% (13726/19264)
Loss: 0.990 | Acc: 71.404% (18325/25664)
Loss: 0.994 | Acc: 71.410% (22897/32064)
Loss: 0.992 | Acc: 71.521% (27510/38464)
Loss: 0.987 | Acc: 71.730% (32181/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3917, Accuracy: 5682/10000 (56.82%)

Epoch: 10
Loss: 0.949 | Acc: 71.875% (46/64)
Loss: 0.978 | Acc: 72.308% (4674/6464)
Loss: 0.960 | Acc: 72.940% (9383/12864)
Loss: 0.967 | Acc: 72.809% (14026/19264)
Loss: 0.957 | Acc: 72.915% (18713/25664)
Loss: 0.961 | Acc: 73.004% (23408/32064)
Loss: 0.961 | Acc: 73.094% (28115/38464)
Loss: 0.961 | Acc: 73.007% (32754/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1348, Accuracy: 6736/10000 (67.36%)

Epoch: 11
Loss: 1.207 | Acc: 57.812% (37/64)
Loss: 0.948 | Acc: 73.515% (4752/6464)
Loss: 0.948 | Acc: 73.616% (9470/12864)
Loss: 0.935 | Acc: 73.977% (14251/19264)
Loss: 0.934 | Acc: 73.921% (18971/25664)
Loss: 0.935 | Acc: 73.818% (23669/32064)
Loss: 0.937 | Acc: 73.812% (28391/38464)
Loss: 0.940 | Acc: 73.792% (33106/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1080, Accuracy: 6886/10000 (68.86%)

Epoch: 12
Loss: 1.047 | Acc: 68.750% (44/64)
Loss: 0.920 | Acc: 74.814% (4836/6464)
Loss: 0.919 | Acc: 74.751% (9616/12864)
Loss: 0.920 | Acc: 74.663% (14383/19264)
Loss: 0.921 | Acc: 74.579% (19140/25664)
Loss: 0.921 | Acc: 74.635% (23931/32064)
Loss: 0.921 | Acc: 74.602% (28695/38464)
Loss: 0.926 | Acc: 74.447% (33400/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5824, Accuracy: 5187/10000 (51.87%)

Epoch: 13
Loss: 1.212 | Acc: 59.375% (38/64)
Loss: 0.915 | Acc: 75.681% (4892/6464)
Loss: 0.911 | Acc: 75.474% (9709/12864)
Loss: 0.908 | Acc: 75.384% (14522/19264)
Loss: 0.911 | Acc: 75.097% (19273/25664)
Loss: 0.903 | Acc: 75.368% (24166/32064)
Loss: 0.903 | Acc: 75.377% (28993/38464)
Loss: 0.905 | Acc: 75.288% (33777/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2426, Accuracy: 6352/10000 (63.52%)

Epoch: 14
Loss: 1.077 | Acc: 71.875% (46/64)
Loss: 0.930 | Acc: 74.226% (4798/6464)
Loss: 0.911 | Acc: 74.891% (9634/12864)
Loss: 0.896 | Acc: 75.358% (14517/19264)
Loss: 0.892 | Acc: 75.569% (19394/25664)
Loss: 0.889 | Acc: 75.833% (24315/32064)
Loss: 0.888 | Acc: 75.889% (29190/38464)
Loss: 0.888 | Acc: 75.880% (34043/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8121, Accuracy: 5051/10000 (50.51%)

Epoch: 15
Loss: 1.141 | Acc: 67.188% (43/64)
Loss: 0.866 | Acc: 76.470% (4943/6464)
Loss: 0.875 | Acc: 76.391% (9827/12864)
Loss: 0.883 | Acc: 76.054% (14651/19264)
Loss: 0.877 | Acc: 76.200% (19556/25664)
Loss: 0.877 | Acc: 76.266% (24454/32064)
Loss: 0.878 | Acc: 76.209% (29313/38464)
Loss: 0.876 | Acc: 76.266% (34216/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1172, Accuracy: 6818/10000 (68.18%)

Epoch: 16
Loss: 0.922 | Acc: 76.562% (49/64)
Loss: 0.853 | Acc: 76.748% (4961/6464)
Loss: 0.848 | Acc: 76.990% (9904/12864)
Loss: 0.849 | Acc: 77.102% (14853/19264)
Loss: 0.855 | Acc: 76.898% (19735/25664)
Loss: 0.856 | Acc: 76.902% (24658/32064)
Loss: 0.858 | Acc: 76.919% (29586/38464)
Loss: 0.854 | Acc: 76.939% (34518/44864)
torch.Size([100, 10])
Test set: Average loss: 2.6340, Accuracy: 3766/10000 (37.66%)

Epoch: 17
Loss: 0.987 | Acc: 67.188% (43/64)
Loss: 0.836 | Acc: 77.661% (5020/6464)
Loss: 0.851 | Acc: 77.456% (9964/12864)
Loss: 0.857 | Acc: 77.123% (14857/19264)
Loss: 0.850 | Acc: 77.303% (19839/25664)
Loss: 0.847 | Acc: 77.433% (24828/32064)
Loss: 0.847 | Acc: 77.410% (29775/38464)
Loss: 0.844 | Acc: 77.454% (34749/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0648, Accuracy: 7037/10000 (70.37%)

Epoch: 18
Loss: 0.724 | Acc: 78.125% (50/64)
Loss: 0.818 | Acc: 78.233% (5057/6464)
Loss: 0.821 | Acc: 78.055% (10041/12864)
Loss: 0.828 | Acc: 77.949% (15016/19264)
Loss: 0.832 | Acc: 77.841% (19977/25664)
Loss: 0.830 | Acc: 77.857% (24964/32064)
Loss: 0.832 | Acc: 77.836% (29939/38464)
Loss: 0.834 | Acc: 77.782% (34896/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0099, Accuracy: 7175/10000 (71.75%)

Epoch: 19
Loss: 1.034 | Acc: 71.875% (46/64)
Loss: 0.824 | Acc: 78.403% (5068/6464)
Loss: 0.816 | Acc: 78.537% (10103/12864)
Loss: 0.810 | Acc: 78.727% (15166/19264)
Loss: 0.810 | Acc: 78.702% (20198/25664)
Loss: 0.813 | Acc: 78.580% (25196/32064)
Loss: 0.814 | Acc: 78.554% (30215/38464)
Loss: 0.815 | Acc: 78.562% (35246/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3472, Accuracy: 6160/10000 (61.60%)

Epoch: 20
Loss: 0.740 | Acc: 79.688% (51/64)
Loss: 0.795 | Acc: 79.440% (5135/6464)
Loss: 0.802 | Acc: 79.252% (10195/12864)
Loss: 0.802 | Acc: 79.007% (15220/19264)
Loss: 0.802 | Acc: 78.986% (20271/25664)
Loss: 0.800 | Acc: 78.998% (25330/32064)
Loss: 0.803 | Acc: 79.051% (30406/38464)
Loss: 0.803 | Acc: 79.063% (35471/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8009, Accuracy: 4921/10000 (49.21%)

Epoch: 21
Loss: 0.794 | Acc: 75.000% (48/64)
Loss: 0.805 | Acc: 78.280% (5060/6464)
Loss: 0.801 | Acc: 78.615% (10113/12864)
Loss: 0.792 | Acc: 78.961% (15211/19264)
Loss: 0.799 | Acc: 78.935% (20258/25664)
Loss: 0.798 | Acc: 78.976% (25323/32064)
Loss: 0.796 | Acc: 79.077% (30416/38464)
Loss: 0.796 | Acc: 79.128% (35500/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2225, Accuracy: 6497/10000 (64.97%)

Epoch: 22
Loss: 0.711 | Acc: 82.812% (53/64)
Loss: 0.783 | Acc: 80.012% (5172/6464)
Loss: 0.797 | Acc: 79.283% (10199/12864)
Loss: 0.788 | Acc: 79.428% (15301/19264)
Loss: 0.795 | Acc: 79.267% (20343/25664)
Loss: 0.783 | Acc: 79.581% (25517/32064)
Loss: 0.781 | Acc: 79.674% (30646/38464)
Loss: 0.780 | Acc: 79.705% (35759/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2116, Accuracy: 6539/10000 (65.39%)

Epoch: 23
Loss: 0.769 | Acc: 81.250% (52/64)
Loss: 0.729 | Acc: 81.498% (5268/6464)
Loss: 0.758 | Acc: 80.581% (10366/12864)
Loss: 0.764 | Acc: 80.534% (15514/19264)
Loss: 0.763 | Acc: 80.362% (20624/25664)
Loss: 0.766 | Acc: 80.268% (25737/32064)
Loss: 0.766 | Acc: 80.322% (30895/38464)
Loss: 0.765 | Acc: 80.374% (36059/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4534, Accuracy: 5849/10000 (58.49%)

Epoch: 24
Loss: 0.953 | Acc: 76.562% (49/64)
Loss: 0.755 | Acc: 80.801% (5223/6464)
Loss: 0.765 | Acc: 80.457% (10350/12864)
Loss: 0.754 | Acc: 80.876% (15580/19264)
Loss: 0.758 | Acc: 80.751% (20724/25664)
Loss: 0.754 | Acc: 80.720% (25882/32064)
Loss: 0.754 | Acc: 80.759% (31063/38464)
Loss: 0.756 | Acc: 80.697% (36204/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2063, Accuracy: 6618/10000 (66.18%)

Epoch: 25
Loss: 0.842 | Acc: 78.125% (50/64)
Loss: 0.743 | Acc: 81.451% (5265/6464)
Loss: 0.751 | Acc: 81.118% (10435/12864)
Loss: 0.739 | Acc: 81.369% (15675/19264)
Loss: 0.739 | Acc: 81.394% (20889/25664)
Loss: 0.738 | Acc: 81.524% (26140/32064)
Loss: 0.741 | Acc: 81.440% (31325/38464)
Loss: 0.741 | Acc: 81.361% (36502/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9976, Accuracy: 7250/10000 (72.50%)

Epoch: 26
Loss: 0.585 | Acc: 84.375% (54/64)
Loss: 0.730 | Acc: 81.714% (5282/6464)
Loss: 0.730 | Acc: 81.748% (10516/12864)
Loss: 0.723 | Acc: 81.800% (15758/19264)
Loss: 0.734 | Acc: 81.495% (20915/25664)
Loss: 0.733 | Acc: 81.587% (26160/32064)
Loss: 0.728 | Acc: 81.757% (31447/38464)
Loss: 0.725 | Acc: 81.801% (36699/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0120, Accuracy: 7334/10000 (73.34%)

Epoch: 27
Loss: 0.702 | Acc: 76.562% (49/64)
Loss: 0.739 | Acc: 81.312% (5256/6464)
Loss: 0.717 | Acc: 81.911% (10537/12864)
Loss: 0.715 | Acc: 81.966% (15790/19264)
Loss: 0.713 | Acc: 82.111% (21073/25664)
Loss: 0.707 | Acc: 82.338% (26401/32064)
Loss: 0.709 | Acc: 82.355% (31677/38464)
Loss: 0.712 | Acc: 82.255% (36903/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1352, Accuracy: 6948/10000 (69.48%)

Epoch: 28
Loss: 0.995 | Acc: 73.438% (47/64)
Loss: 0.684 | Acc: 82.812% (5353/6464)
Loss: 0.698 | Acc: 82.719% (10641/12864)
Loss: 0.690 | Acc: 82.755% (15942/19264)
Loss: 0.693 | Acc: 82.707% (21226/25664)
Loss: 0.692 | Acc: 82.841% (26562/32064)
Loss: 0.699 | Acc: 82.667% (31797/38464)
Loss: 0.698 | Acc: 82.730% (37116/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0863, Accuracy: 6849/10000 (68.49%)

Epoch: 29
Loss: 0.642 | Acc: 82.812% (53/64)
Loss: 0.656 | Acc: 83.942% (5426/6464)
Loss: 0.668 | Acc: 83.598% (10754/12864)
Loss: 0.666 | Acc: 83.716% (16127/19264)
Loss: 0.679 | Acc: 83.374% (21397/25664)
Loss: 0.678 | Acc: 83.383% (26736/32064)
Loss: 0.679 | Acc: 83.377% (32070/38464)
Loss: 0.679 | Acc: 83.332% (37386/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8917, Accuracy: 7661/10000 (76.61%)

Epoch: 30
Loss: 0.991 | Acc: 76.562% (49/64)
Loss: 0.658 | Acc: 84.066% (5434/6464)
Loss: 0.665 | Acc: 83.862% (10788/12864)
Loss: 0.663 | Acc: 83.866% (16156/19264)
Loss: 0.661 | Acc: 83.767% (21498/25664)
Loss: 0.671 | Acc: 83.564% (26794/32064)
Loss: 0.673 | Acc: 83.481% (32110/38464)
Loss: 0.674 | Acc: 83.570% (37493/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9114, Accuracy: 7579/10000 (75.79%)

Epoch: 31
Loss: 0.420 | Acc: 92.188% (59/64)
Loss: 0.621 | Acc: 84.932% (5490/6464)
Loss: 0.639 | Acc: 84.515% (10872/12864)
Loss: 0.650 | Acc: 84.256% (16231/19264)
Loss: 0.650 | Acc: 84.356% (21649/25664)
Loss: 0.651 | Acc: 84.291% (27027/32064)
Loss: 0.650 | Acc: 84.357% (32447/38464)
Loss: 0.654 | Acc: 84.243% (37795/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8470, Accuracy: 7845/10000 (78.45%)

Epoch: 32
Loss: 0.746 | Acc: 84.375% (54/64)
Loss: 0.640 | Acc: 84.824% (5483/6464)
Loss: 0.640 | Acc: 84.632% (10887/12864)
Loss: 0.637 | Acc: 84.692% (16315/19264)
Loss: 0.630 | Acc: 84.843% (21774/25664)
Loss: 0.630 | Acc: 84.865% (27211/32064)
Loss: 0.633 | Acc: 84.807% (32620/38464)
Loss: 0.632 | Acc: 84.912% (38095/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8939, Accuracy: 7683/10000 (76.83%)

Epoch: 33
Loss: 0.545 | Acc: 87.500% (56/64)
Loss: 0.583 | Acc: 85.845% (5549/6464)
Loss: 0.606 | Acc: 85.339% (10978/12864)
Loss: 0.608 | Acc: 85.309% (16434/19264)
Loss: 0.615 | Acc: 85.096% (21839/25664)
Loss: 0.608 | Acc: 85.373% (27374/32064)
Loss: 0.615 | Acc: 85.212% (32776/38464)
Loss: 0.616 | Acc: 85.180% (38215/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9615, Accuracy: 7442/10000 (74.42%)

Epoch: 34
Loss: 0.776 | Acc: 79.688% (51/64)
Loss: 0.582 | Acc: 86.139% (5568/6464)
Loss: 0.578 | Acc: 86.163% (11084/12864)
Loss: 0.580 | Acc: 86.161% (16598/19264)
Loss: 0.587 | Acc: 86.015% (22075/25664)
Loss: 0.593 | Acc: 85.875% (27535/32064)
Loss: 0.594 | Acc: 85.870% (33029/38464)
Loss: 0.597 | Acc: 85.817% (38501/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8351, Accuracy: 7934/10000 (79.34%)

Epoch: 35
Loss: 0.535 | Acc: 89.062% (57/64)
Loss: 0.553 | Acc: 86.386% (5584/6464)
Loss: 0.570 | Acc: 86.326% (11105/12864)
Loss: 0.575 | Acc: 86.374% (16639/19264)
Loss: 0.571 | Acc: 86.448% (22186/25664)
Loss: 0.572 | Acc: 86.514% (27740/32064)
Loss: 0.576 | Acc: 86.431% (33245/38464)
Loss: 0.578 | Acc: 86.372% (38750/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7894, Accuracy: 8123/10000 (81.23%)

Epoch: 36
Loss: 0.510 | Acc: 85.938% (55/64)
Loss: 0.536 | Acc: 87.438% (5652/6464)
Loss: 0.556 | Acc: 86.870% (11175/12864)
Loss: 0.553 | Acc: 86.939% (16748/19264)
Loss: 0.558 | Acc: 86.810% (22279/25664)
Loss: 0.559 | Acc: 86.829% (27841/32064)
Loss: 0.558 | Acc: 86.931% (33437/38464)
Loss: 0.559 | Acc: 86.865% (38971/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8273, Accuracy: 8023/10000 (80.23%)

Epoch: 37
Loss: 0.569 | Acc: 87.500% (56/64)
Loss: 0.520 | Acc: 87.778% (5674/6464)
Loss: 0.514 | Acc: 88.137% (11338/12864)
Loss: 0.517 | Acc: 88.035% (16959/19264)
Loss: 0.514 | Acc: 88.057% (22599/25664)
Loss: 0.521 | Acc: 87.793% (28150/32064)
Loss: 0.525 | Acc: 87.627% (33705/38464)
Loss: 0.531 | Acc: 87.475% (39245/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8108, Accuracy: 8090/10000 (80.90%)

Epoch: 38
Loss: 0.733 | Acc: 79.688% (51/64)
Loss: 0.505 | Acc: 88.335% (5710/6464)
Loss: 0.505 | Acc: 88.355% (11366/12864)
Loss: 0.502 | Acc: 88.367% (17023/19264)
Loss: 0.502 | Acc: 88.353% (22675/25664)
Loss: 0.505 | Acc: 88.314% (28317/32064)
Loss: 0.506 | Acc: 88.194% (33923/38464)
Loss: 0.506 | Acc: 88.204% (39572/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8146, Accuracy: 8097/10000 (80.97%)

Epoch: 39
Loss: 0.367 | Acc: 90.625% (58/64)
Loss: 0.456 | Acc: 89.155% (5763/6464)
Loss: 0.454 | Acc: 89.280% (11485/12864)
Loss: 0.460 | Acc: 89.234% (17190/19264)
Loss: 0.462 | Acc: 89.179% (22887/25664)
Loss: 0.471 | Acc: 88.985% (28532/32064)
Loss: 0.472 | Acc: 88.953% (34215/38464)
Loss: 0.477 | Acc: 88.808% (39843/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8777, Accuracy: 7930/10000 (79.30%)

Epoch: 40
Loss: 0.401 | Acc: 92.188% (59/64)
Loss: 0.446 | Acc: 89.449% (5782/6464)
Loss: 0.433 | Acc: 89.708% (11540/12864)
Loss: 0.440 | Acc: 89.561% (17253/19264)
Loss: 0.448 | Acc: 89.398% (22943/25664)
Loss: 0.448 | Acc: 89.406% (28667/32064)
Loss: 0.447 | Acc: 89.419% (34394/38464)
Loss: 0.449 | Acc: 89.383% (40101/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8436, Accuracy: 8100/10000 (81.00%)

Epoch: 41
Loss: 0.551 | Acc: 84.375% (54/64)
Loss: 0.395 | Acc: 90.656% (5860/6464)
Loss: 0.421 | Acc: 89.964% (11573/12864)
Loss: 0.414 | Acc: 90.163% (17369/19264)
Loss: 0.417 | Acc: 90.103% (23124/25664)
Loss: 0.415 | Acc: 90.135% (28901/32064)
Loss: 0.416 | Acc: 90.100% (34656/38464)
Loss: 0.417 | Acc: 90.130% (40436/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8513, Accuracy: 8147/10000 (81.47%)

Epoch: 42
Loss: 0.316 | Acc: 92.188% (59/64)
Loss: 0.375 | Acc: 91.043% (5885/6464)
Loss: 0.377 | Acc: 90.866% (11689/12864)
Loss: 0.380 | Acc: 90.718% (17476/19264)
Loss: 0.384 | Acc: 90.672% (23270/25664)
Loss: 0.384 | Acc: 90.678% (29075/32064)
Loss: 0.383 | Acc: 90.716% (34893/38464)
Loss: 0.383 | Acc: 90.772% (40724/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8640, Accuracy: 8131/10000 (81.31%)

Epoch: 43
Loss: 0.240 | Acc: 93.750% (60/64)
Loss: 0.345 | Acc: 91.538% (5917/6464)
Loss: 0.350 | Acc: 91.356% (11752/12864)
Loss: 0.343 | Acc: 91.513% (17629/19264)
Loss: 0.340 | Acc: 91.599% (23508/25664)
Loss: 0.342 | Acc: 91.579% (29364/32064)
Loss: 0.346 | Acc: 91.535% (35208/38464)
Loss: 0.347 | Acc: 91.575% (41084/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8854, Accuracy: 8141/10000 (81.41%)

Epoch: 44
Loss: 0.209 | Acc: 96.875% (62/64)
Loss: 0.302 | Acc: 92.667% (5990/6464)
Loss: 0.320 | Acc: 92.149% (11854/12864)
Loss: 0.314 | Acc: 92.276% (17776/19264)
Loss: 0.316 | Acc: 92.242% (23673/25664)
Loss: 0.319 | Acc: 92.085% (29526/32064)
Loss: 0.316 | Acc: 92.141% (35441/38464)
Loss: 0.313 | Acc: 92.214% (41371/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8877, Accuracy: 8193/10000 (81.93%)

Epoch: 45
Loss: 0.355 | Acc: 87.500% (56/64)
Loss: 0.280 | Acc: 92.868% (6003/6464)
Loss: 0.291 | Acc: 92.576% (11909/12864)
Loss: 0.291 | Acc: 92.582% (17835/19264)
Loss: 0.297 | Acc: 92.488% (23736/25664)
Loss: 0.300 | Acc: 92.474% (29651/32064)
Loss: 0.300 | Acc: 92.479% (35571/38464)
Loss: 0.300 | Acc: 92.517% (41507/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8436, Accuracy: 8192/10000 (81.92%)

Epoch: 46
Loss: 0.228 | Acc: 92.188% (59/64)
Loss: 0.315 | Acc: 92.234% (5962/6464)
Loss: 0.315 | Acc: 92.203% (11861/12864)
Loss: 0.312 | Acc: 92.302% (17781/19264)
Loss: 0.312 | Acc: 92.351% (23701/25664)
Loss: 0.311 | Acc: 92.365% (29616/32064)
Loss: 0.311 | Acc: 92.351% (35522/38464)
Loss: 0.309 | Acc: 92.410% (41459/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8347, Accuracy: 8242/10000 (82.42%)

Epoch: 47
Loss: 0.137 | Acc: 95.312% (61/64)
Loss: 0.307 | Acc: 92.218% (5961/6464)
Loss: 0.301 | Acc: 92.460% (11894/12864)
Loss: 0.307 | Acc: 92.380% (17796/19264)
Loss: 0.304 | Acc: 92.472% (23732/25664)
Loss: 0.309 | Acc: 92.340% (29608/32064)
Loss: 0.308 | Acc: 92.372% (35530/38464)
Loss: 0.308 | Acc: 92.413% (41460/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8307, Accuracy: 8245/10000 (82.45%)
torch.Size([100, 10])
Test set: Average loss: 0.8307, Accuracy: 8245/10000 (82.45%)

Epoch: 48
Loss: 0.395 | Acc: 90.625% (58/64)
Loss: 0.309 | Acc: 92.450% (5976/6464)
Loss: 0.301 | Acc: 92.615% (11914/12864)
Loss: 0.305 | Acc: 92.426% (17805/19264)
Loss: 0.307 | Acc: 92.421% (23719/25664)
Loss: 0.306 | Acc: 92.400% (29627/32064)
Loss: 0.308 | Acc: 92.338% (35517/38464)
Loss: 0.306 | Acc: 92.379% (41445/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8317, Accuracy: 8234/10000 (82.34%)
torch.Size([100, 10])
Test set: Average loss: 0.8317, Accuracy: 8234/10000 (82.34%)

Epoch: 49
Loss: 0.267 | Acc: 92.188% (59/64)
Loss: 0.310 | Acc: 92.466% (5977/6464)
Loss: 0.313 | Acc: 92.281% (11871/12864)
Loss: 0.310 | Acc: 92.333% (17787/19264)
Loss: 0.309 | Acc: 92.320% (23693/25664)
Loss: 0.307 | Acc: 92.356% (29613/32064)
Loss: 0.306 | Acc: 92.419% (35548/38464)
Loss: 0.307 | Acc: 92.366% (41439/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8339, Accuracy: 8224/10000 (82.24%)
torch.Size([100, 10])
Test set: Average loss: 0.8339, Accuracy: 8224/10000 (82.24%)

Epoch: 50
Loss: 0.226 | Acc: 92.188% (59/64)
Loss: 1.333 | Acc: 59.004% (3814/6464)
Loss: 1.181 | Acc: 64.280% (8269/12864)
Loss: 1.105 | Acc: 67.234% (12952/19264)
Loss: 1.070 | Acc: 68.777% (17651/25664)
Loss: 1.046 | Acc: 69.795% (22379/32064)
Loss: 1.024 | Acc: 70.658% (27178/38464)
Loss: 1.008 | Acc: 71.331% (32002/44864)
torch.Size([100, 10])
Test set: Average loss: 3.9730, Accuracy: 2247/10000 (22.47%)

Epoch: 51
Loss: 0.877 | Acc: 70.312% (45/64)
Loss: 0.882 | Acc: 76.006% (4913/6464)
Loss: 0.881 | Acc: 76.166% (9798/12864)
Loss: 0.883 | Acc: 76.101% (14660/19264)
Loss: 0.883 | Acc: 76.075% (19524/25664)
Loss: 0.879 | Acc: 76.279% (24458/32064)
Loss: 0.872 | Acc: 76.453% (29407/38464)
Loss: 0.869 | Acc: 76.580% (34357/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0785, Accuracy: 6978/10000 (69.78%)

Epoch: 52
Loss: 0.854 | Acc: 79.688% (51/64)
Loss: 0.841 | Acc: 77.924% (5037/6464)
Loss: 0.832 | Acc: 78.086% (10045/12864)
Loss: 0.826 | Acc: 78.250% (15074/19264)
Loss: 0.827 | Acc: 78.063% (20034/25664)
Loss: 0.827 | Acc: 78.063% (25030/32064)
Loss: 0.829 | Acc: 78.029% (30013/38464)
Loss: 0.833 | Acc: 77.971% (34981/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1640, Accuracy: 6727/10000 (67.27%)

Epoch: 53
Loss: 1.203 | Acc: 67.188% (43/64)
Loss: 0.795 | Acc: 79.162% (5117/6464)
Loss: 0.814 | Acc: 78.708% (10125/12864)
Loss: 0.823 | Acc: 78.488% (15120/19264)
Loss: 0.824 | Acc: 78.374% (20114/25664)
Loss: 0.829 | Acc: 78.281% (25100/32064)
Loss: 0.824 | Acc: 78.401% (30156/38464)
Loss: 0.826 | Acc: 78.319% (35137/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7361, Accuracy: 5246/10000 (52.46%)

Epoch: 54
Loss: 0.884 | Acc: 73.438% (47/64)
Loss: 0.784 | Acc: 79.162% (5117/6464)
Loss: 0.815 | Acc: 78.576% (10108/12864)
Loss: 0.811 | Acc: 78.582% (15138/19264)
Loss: 0.817 | Acc: 78.433% (20129/25664)
Loss: 0.821 | Acc: 78.350% (25122/32064)
Loss: 0.823 | Acc: 78.237% (30093/38464)
Loss: 0.825 | Acc: 78.187% (35078/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5612, Accuracy: 5864/10000 (58.64%)

Epoch: 55
Loss: 0.919 | Acc: 75.000% (48/64)
Loss: 0.809 | Acc: 78.899% (5100/6464)
Loss: 0.807 | Acc: 78.832% (10141/12864)
Loss: 0.809 | Acc: 78.852% (15190/19264)
Loss: 0.812 | Acc: 78.846% (20235/25664)
Loss: 0.812 | Acc: 78.855% (25284/32064)
Loss: 0.814 | Acc: 78.741% (30287/38464)
Loss: 0.815 | Acc: 78.760% (35335/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0774, Accuracy: 6989/10000 (69.89%)

Epoch: 56
Loss: 0.903 | Acc: 76.562% (49/64)
Loss: 0.808 | Acc: 79.254% (5123/6464)
Loss: 0.807 | Acc: 78.988% (10161/12864)
Loss: 0.798 | Acc: 79.226% (15262/19264)
Loss: 0.799 | Acc: 79.134% (20309/25664)
Loss: 0.801 | Acc: 79.176% (25387/32064)
Loss: 0.805 | Acc: 78.973% (30376/38464)
Loss: 0.807 | Acc: 78.905% (35400/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0768, Accuracy: 7040/10000 (70.40%)

Epoch: 57
Loss: 0.886 | Acc: 76.562% (49/64)
Loss: 0.809 | Acc: 78.605% (5081/6464)
Loss: 0.805 | Acc: 78.941% (10155/12864)
Loss: 0.799 | Acc: 79.179% (15253/19264)
Loss: 0.807 | Acc: 78.935% (20258/25664)
Loss: 0.807 | Acc: 78.892% (25296/32064)
Loss: 0.810 | Acc: 78.835% (30323/38464)
Loss: 0.804 | Acc: 78.939% (35415/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1744, Accuracy: 6663/10000 (66.63%)

Epoch: 58
Loss: 1.011 | Acc: 67.188% (43/64)
Loss: 0.795 | Acc: 79.440% (5135/6464)
Loss: 0.801 | Acc: 79.221% (10191/12864)
Loss: 0.795 | Acc: 79.469% (15309/19264)
Loss: 0.800 | Acc: 79.356% (20366/25664)
Loss: 0.800 | Acc: 79.279% (25420/32064)
Loss: 0.803 | Acc: 79.077% (30416/38464)
Loss: 0.804 | Acc: 79.048% (35464/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0391, Accuracy: 7172/10000 (71.72%)

Epoch: 59
Loss: 0.600 | Acc: 82.812% (53/64)
Loss: 0.801 | Acc: 79.394% (5132/6464)
Loss: 0.800 | Acc: 79.190% (10187/12864)
Loss: 0.801 | Acc: 78.961% (15211/19264)
Loss: 0.801 | Acc: 78.916% (20253/25664)
Loss: 0.801 | Acc: 78.930% (25308/32064)
Loss: 0.801 | Acc: 78.983% (30380/38464)
Loss: 0.803 | Acc: 78.972% (35430/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3915, Accuracy: 5869/10000 (58.69%)

Epoch: 60
Loss: 0.980 | Acc: 75.000% (48/64)
Loss: 0.806 | Acc: 79.146% (5116/6464)
Loss: 0.785 | Acc: 79.711% (10254/12864)
Loss: 0.798 | Acc: 79.324% (15281/19264)
Loss: 0.799 | Acc: 79.232% (20334/25664)
Loss: 0.794 | Acc: 79.410% (25462/32064)
Loss: 0.792 | Acc: 79.498% (30578/38464)
Loss: 0.792 | Acc: 79.502% (35668/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1896, Accuracy: 6769/10000 (67.69%)

Epoch: 61
Loss: 0.875 | Acc: 78.125% (50/64)
Loss: 0.771 | Acc: 80.090% (5177/6464)
Loss: 0.772 | Acc: 79.991% (10290/12864)
Loss: 0.782 | Acc: 79.677% (15349/19264)
Loss: 0.787 | Acc: 79.606% (20430/25664)
Loss: 0.790 | Acc: 79.507% (25493/32064)
Loss: 0.792 | Acc: 79.524% (30588/38464)
Loss: 0.792 | Acc: 79.531% (35681/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2831, Accuracy: 6223/10000 (62.23%)

Epoch: 62
Loss: 0.940 | Acc: 76.562% (49/64)
Loss: 0.790 | Acc: 79.703% (5152/6464)
Loss: 0.776 | Acc: 79.960% (10286/12864)
Loss: 0.784 | Acc: 79.729% (15359/19264)
Loss: 0.782 | Acc: 79.859% (20495/25664)
Loss: 0.782 | Acc: 79.815% (25592/32064)
Loss: 0.781 | Acc: 79.875% (30723/38464)
Loss: 0.784 | Acc: 79.790% (35797/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9122, Accuracy: 7597/10000 (75.97%)

Epoch: 63
Loss: 0.523 | Acc: 81.250% (52/64)
Loss: 0.773 | Acc: 79.780% (5157/6464)
Loss: 0.777 | Acc: 79.827% (10269/12864)
Loss: 0.776 | Acc: 79.957% (15403/19264)
Loss: 0.777 | Acc: 79.945% (20517/25664)
Loss: 0.775 | Acc: 80.059% (25670/32064)
Loss: 0.779 | Acc: 79.914% (30738/38464)
Loss: 0.779 | Acc: 79.966% (35876/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0844, Accuracy: 7093/10000 (70.93%)

Epoch: 64
Loss: 0.965 | Acc: 73.438% (47/64)
Loss: 0.782 | Acc: 79.749% (5155/6464)
Loss: 0.771 | Acc: 80.239% (10322/12864)
Loss: 0.763 | Acc: 80.368% (15482/19264)
Loss: 0.769 | Acc: 80.206% (20584/25664)
Loss: 0.766 | Acc: 80.339% (25760/32064)
Loss: 0.768 | Acc: 80.332% (30899/38464)
Loss: 0.771 | Acc: 80.238% (35998/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3738, Accuracy: 5947/10000 (59.47%)

Epoch: 65
Loss: 0.639 | Acc: 81.250% (52/64)
Loss: 0.756 | Acc: 80.616% (5211/6464)
Loss: 0.755 | Acc: 80.620% (10371/12864)
Loss: 0.761 | Acc: 80.565% (15520/19264)
Loss: 0.764 | Acc: 80.416% (20638/25664)
Loss: 0.768 | Acc: 80.377% (25772/32064)
Loss: 0.764 | Acc: 80.512% (30968/38464)
Loss: 0.765 | Acc: 80.541% (36134/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0332, Accuracy: 7157/10000 (71.57%)

Epoch: 66
Loss: 0.808 | Acc: 81.250% (52/64)
Loss: 0.721 | Acc: 81.931% (5296/6464)
Loss: 0.750 | Acc: 80.807% (10395/12864)
Loss: 0.753 | Acc: 80.482% (15504/19264)
Loss: 0.758 | Acc: 80.369% (20626/25664)
Loss: 0.755 | Acc: 80.486% (25807/32064)
Loss: 0.757 | Acc: 80.527% (30974/38464)
Loss: 0.755 | Acc: 80.621% (36170/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4344, Accuracy: 5766/10000 (57.66%)

Epoch: 67
Loss: 0.895 | Acc: 78.125% (50/64)
Loss: 0.753 | Acc: 81.235% (5251/6464)
Loss: 0.737 | Acc: 81.289% (10457/12864)
Loss: 0.733 | Acc: 81.515% (15703/19264)
Loss: 0.740 | Acc: 81.285% (20861/25664)
Loss: 0.743 | Acc: 81.209% (26039/32064)
Loss: 0.748 | Acc: 81.037% (31170/38464)
Loss: 0.753 | Acc: 80.931% (36309/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3242, Accuracy: 6298/10000 (62.98%)

Epoch: 68
Loss: 0.661 | Acc: 78.125% (50/64)
Loss: 0.746 | Acc: 80.832% (5225/6464)
Loss: 0.738 | Acc: 81.234% (10450/12864)
Loss: 0.743 | Acc: 81.245% (15651/19264)
Loss: 0.745 | Acc: 81.153% (20827/25664)
Loss: 0.746 | Acc: 81.153% (26021/32064)
Loss: 0.747 | Acc: 81.141% (31210/38464)
Loss: 0.743 | Acc: 81.145% (36405/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9207, Accuracy: 7647/10000 (76.47%)

Epoch: 69
Loss: 0.856 | Acc: 79.688% (51/64)
Loss: 0.694 | Acc: 82.457% (5330/6464)
Loss: 0.706 | Acc: 82.261% (10582/12864)
Loss: 0.724 | Acc: 81.899% (15777/19264)
Loss: 0.729 | Acc: 81.803% (20994/25664)
Loss: 0.732 | Acc: 81.687% (26192/32064)
Loss: 0.729 | Acc: 81.767% (31451/38464)
Loss: 0.732 | Acc: 81.740% (36672/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0747, Accuracy: 7014/10000 (70.14%)

Epoch: 70
Loss: 0.696 | Acc: 84.375% (54/64)
Loss: 0.705 | Acc: 82.426% (5328/6464)
Loss: 0.706 | Acc: 82.400% (10600/12864)
Loss: 0.710 | Acc: 82.252% (15845/19264)
Loss: 0.710 | Acc: 82.407% (21149/25664)
Loss: 0.714 | Acc: 82.320% (26395/32064)
Loss: 0.719 | Acc: 82.079% (31571/38464)
Loss: 0.725 | Acc: 81.941% (36762/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1239, Accuracy: 6880/10000 (68.80%)

Epoch: 71
Loss: 0.856 | Acc: 76.562% (49/64)
Loss: 0.696 | Acc: 82.735% (5348/6464)
Loss: 0.708 | Acc: 82.307% (10588/12864)
Loss: 0.710 | Acc: 82.376% (15869/19264)
Loss: 0.721 | Acc: 82.014% (21048/25664)
Loss: 0.723 | Acc: 81.989% (26289/32064)
Loss: 0.722 | Acc: 81.947% (31520/38464)
Loss: 0.718 | Acc: 82.037% (36805/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3979, Accuracy: 6106/10000 (61.06%)

Epoch: 72
Loss: 0.922 | Acc: 76.562% (49/64)
Loss: 0.700 | Acc: 82.519% (5334/6464)
Loss: 0.704 | Acc: 82.494% (10612/12864)
Loss: 0.714 | Acc: 82.070% (15810/19264)
Loss: 0.707 | Acc: 82.325% (21128/25664)
Loss: 0.710 | Acc: 82.285% (26384/32064)
Loss: 0.706 | Acc: 82.407% (31697/38464)
Loss: 0.711 | Acc: 82.373% (36956/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3694, Accuracy: 6149/10000 (61.49%)

Epoch: 73
Loss: 0.735 | Acc: 81.250% (52/64)
Loss: 0.674 | Acc: 82.952% (5362/6464)
Loss: 0.692 | Acc: 82.735% (10643/12864)
Loss: 0.700 | Acc: 82.714% (15934/19264)
Loss: 0.704 | Acc: 82.641% (21209/25664)
Loss: 0.705 | Acc: 82.613% (26489/32064)
Loss: 0.699 | Acc: 82.667% (31797/38464)
Loss: 0.702 | Acc: 82.594% (37055/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9077, Accuracy: 7609/10000 (76.09%)

Epoch: 74
Loss: 0.792 | Acc: 78.125% (50/64)
Loss: 0.653 | Acc: 83.895% (5423/6464)
Loss: 0.666 | Acc: 83.582% (10752/12864)
Loss: 0.681 | Acc: 83.155% (16019/19264)
Loss: 0.682 | Acc: 83.268% (21370/25664)
Loss: 0.683 | Acc: 83.240% (26690/32064)
Loss: 0.690 | Acc: 83.028% (31936/38464)
Loss: 0.689 | Acc: 83.029% (37250/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8955, Accuracy: 7618/10000 (76.18%)

Epoch: 75
Loss: 0.394 | Acc: 90.625% (58/64)
Loss: 0.648 | Acc: 84.251% (5446/6464)
Loss: 0.659 | Acc: 83.738% (10772/12864)
Loss: 0.663 | Acc: 83.612% (16107/19264)
Loss: 0.665 | Acc: 83.627% (21462/25664)
Loss: 0.670 | Acc: 83.502% (26774/32064)
Loss: 0.675 | Acc: 83.356% (32062/38464)
Loss: 0.677 | Acc: 83.339% (37389/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9090, Accuracy: 7617/10000 (76.17%)

Epoch: 76
Loss: 0.586 | Acc: 87.500% (56/64)
Loss: 0.663 | Acc: 83.710% (5411/6464)
Loss: 0.649 | Acc: 84.220% (10834/12864)
Loss: 0.660 | Acc: 83.955% (16173/19264)
Loss: 0.661 | Acc: 83.931% (21540/25664)
Loss: 0.668 | Acc: 83.792% (26867/32064)
Loss: 0.668 | Acc: 83.751% (32214/38464)
Loss: 0.666 | Acc: 83.816% (37603/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8108, Accuracy: 7962/10000 (79.62%)

Epoch: 77
Loss: 0.731 | Acc: 85.938% (55/64)
Loss: 0.637 | Acc: 84.700% (5475/6464)
Loss: 0.647 | Acc: 84.453% (10864/12864)
Loss: 0.654 | Acc: 84.224% (16225/19264)
Loss: 0.657 | Acc: 84.040% (21568/25664)
Loss: 0.657 | Acc: 84.072% (26957/32064)
Loss: 0.654 | Acc: 84.219% (32394/38464)
Loss: 0.650 | Acc: 84.295% (37818/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9602, Accuracy: 7451/10000 (74.51%)

Epoch: 78
Loss: 0.667 | Acc: 81.250% (52/64)
Loss: 0.622 | Acc: 85.164% (5505/6464)
Loss: 0.631 | Acc: 84.958% (10929/12864)
Loss: 0.640 | Acc: 84.728% (16322/19264)
Loss: 0.644 | Acc: 84.656% (21726/25664)
Loss: 0.646 | Acc: 84.534% (27105/32064)
Loss: 0.642 | Acc: 84.596% (32539/38464)
Loss: 0.643 | Acc: 84.542% (37929/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1335, Accuracy: 6922/10000 (69.22%)

Epoch: 79
Loss: 0.627 | Acc: 87.500% (56/64)
Loss: 0.613 | Acc: 85.566% (5531/6464)
Loss: 0.612 | Acc: 85.564% (11007/12864)
Loss: 0.605 | Acc: 85.719% (16513/19264)
Loss: 0.617 | Acc: 85.427% (21924/25664)
Loss: 0.622 | Acc: 85.261% (27338/32064)
Loss: 0.622 | Acc: 85.295% (32808/38464)
Loss: 0.622 | Acc: 85.253% (38248/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0258, Accuracy: 7277/10000 (72.77%)

Epoch: 80
Loss: 1.001 | Acc: 73.438% (47/64)
Loss: 0.638 | Acc: 84.653% (5472/6464)
Loss: 0.618 | Acc: 84.997% (10934/12864)
Loss: 0.611 | Acc: 85.273% (16427/19264)
Loss: 0.603 | Acc: 85.509% (21945/25664)
Loss: 0.608 | Acc: 85.438% (27395/32064)
Loss: 0.611 | Acc: 85.386% (32843/38464)
Loss: 0.613 | Acc: 85.378% (38304/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8306, Accuracy: 7939/10000 (79.39%)

Epoch: 81
Loss: 0.341 | Acc: 90.625% (58/64)
Loss: 0.579 | Acc: 86.510% (5592/6464)
Loss: 0.598 | Acc: 86.132% (11080/12864)
Loss: 0.597 | Acc: 85.891% (16546/19264)
Loss: 0.596 | Acc: 85.899% (22045/25664)
Loss: 0.592 | Acc: 86.040% (27588/32064)
Loss: 0.592 | Acc: 86.039% (33094/38464)
Loss: 0.596 | Acc: 85.913% (38544/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0687, Accuracy: 7177/10000 (71.77%)

Epoch: 82
Loss: 0.472 | Acc: 85.938% (55/64)
Loss: 0.598 | Acc: 85.520% (5528/6464)
Loss: 0.584 | Acc: 86.070% (11072/12864)
Loss: 0.571 | Acc: 86.451% (16654/19264)
Loss: 0.573 | Acc: 86.510% (22202/25664)
Loss: 0.576 | Acc: 86.412% (27707/32064)
Loss: 0.581 | Acc: 86.275% (33185/38464)
Loss: 0.581 | Acc: 86.227% (38685/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8851, Accuracy: 7840/10000 (78.40%)

Epoch: 83
Loss: 0.566 | Acc: 87.500% (56/64)
Loss: 0.543 | Acc: 87.160% (5634/6464)
Loss: 0.544 | Acc: 87.321% (11233/12864)
Loss: 0.537 | Acc: 87.458% (16848/19264)
Loss: 0.548 | Acc: 87.243% (22390/25664)
Loss: 0.548 | Acc: 87.254% (27977/32064)
Loss: 0.556 | Acc: 87.074% (33492/38464)
Loss: 0.557 | Acc: 87.076% (39066/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9438, Accuracy: 7618/10000 (76.18%)

Epoch: 84
Loss: 0.439 | Acc: 90.625% (58/64)
Loss: 0.533 | Acc: 87.423% (5651/6464)
Loss: 0.538 | Acc: 87.329% (11234/12864)
Loss: 0.549 | Acc: 87.064% (16772/19264)
Loss: 0.550 | Acc: 86.978% (22322/25664)
Loss: 0.545 | Acc: 87.066% (27917/32064)
Loss: 0.547 | Acc: 87.048% (33482/38464)
Loss: 0.546 | Acc: 87.143% (39096/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8008, Accuracy: 8127/10000 (81.27%)

Epoch: 85
Loss: 0.611 | Acc: 87.500% (56/64)
Loss: 0.522 | Acc: 87.655% (5666/6464)
Loss: 0.517 | Acc: 87.881% (11305/12864)
Loss: 0.521 | Acc: 87.848% (16923/19264)
Loss: 0.522 | Acc: 87.796% (22532/25664)
Loss: 0.520 | Acc: 87.859% (28171/32064)
Loss: 0.522 | Acc: 87.825% (33781/38464)
Loss: 0.523 | Acc: 87.823% (39401/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8337, Accuracy: 7993/10000 (79.93%)

Epoch: 86
Loss: 0.559 | Acc: 84.375% (54/64)
Loss: 0.482 | Acc: 88.629% (5729/6464)
Loss: 0.470 | Acc: 89.062% (11457/12864)
Loss: 0.479 | Acc: 88.813% (17109/19264)
Loss: 0.492 | Acc: 88.466% (22704/25664)
Loss: 0.493 | Acc: 88.408% (28347/32064)
Loss: 0.499 | Acc: 88.309% (33967/38464)
Loss: 0.499 | Acc: 88.316% (39622/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8493, Accuracy: 7980/10000 (79.80%)

Epoch: 87
Loss: 0.488 | Acc: 87.500% (56/64)
Loss: 0.478 | Acc: 88.923% (5748/6464)
Loss: 0.463 | Acc: 89.358% (11495/12864)
Loss: 0.468 | Acc: 89.151% (17174/19264)
Loss: 0.470 | Acc: 89.035% (22850/25664)
Loss: 0.472 | Acc: 89.006% (28539/32064)
Loss: 0.472 | Acc: 89.047% (34251/38464)
Loss: 0.470 | Acc: 89.074% (39962/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7846, Accuracy: 8229/10000 (82.29%)

Epoch: 88
Loss: 0.409 | Acc: 89.062% (57/64)
Loss: 0.426 | Acc: 89.975% (5816/6464)
Loss: 0.435 | Acc: 89.785% (11550/12864)
Loss: 0.440 | Acc: 89.696% (17279/19264)
Loss: 0.447 | Acc: 89.577% (22989/25664)
Loss: 0.448 | Acc: 89.540% (28710/32064)
Loss: 0.444 | Acc: 89.590% (34460/38464)
Loss: 0.445 | Acc: 89.626% (40210/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8115, Accuracy: 8180/10000 (81.80%)

Epoch: 89
Loss: 0.584 | Acc: 87.500% (56/64)
Loss: 0.403 | Acc: 90.486% (5849/6464)
Loss: 0.406 | Acc: 90.446% (11635/12864)
Loss: 0.407 | Acc: 90.407% (17416/19264)
Loss: 0.405 | Acc: 90.399% (23200/25664)
Loss: 0.412 | Acc: 90.201% (28922/32064)
Loss: 0.411 | Acc: 90.232% (34707/38464)
Loss: 0.413 | Acc: 90.215% (40474/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8206, Accuracy: 8239/10000 (82.39%)

Epoch: 90
Loss: 0.274 | Acc: 93.750% (60/64)
Loss: 0.365 | Acc: 91.460% (5912/6464)
Loss: 0.372 | Acc: 91.138% (11724/12864)
Loss: 0.372 | Acc: 91.092% (17548/19264)
Loss: 0.372 | Acc: 91.058% (23369/25664)
Loss: 0.379 | Acc: 90.887% (29142/32064)
Loss: 0.381 | Acc: 90.898% (34963/38464)
Loss: 0.382 | Acc: 90.863% (40765/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8451, Accuracy: 8244/10000 (82.44%)

Epoch: 91
Loss: 0.328 | Acc: 92.188% (59/64)
Loss: 0.342 | Acc: 91.662% (5925/6464)
Loss: 0.346 | Acc: 91.472% (11767/12864)
Loss: 0.350 | Acc: 91.378% (17603/19264)
Loss: 0.347 | Acc: 91.435% (23466/25664)
Loss: 0.350 | Acc: 91.383% (29301/32064)
Loss: 0.352 | Acc: 91.353% (35138/38464)
Loss: 0.351 | Acc: 91.412% (41011/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9158, Accuracy: 8150/10000 (81.50%)

Epoch: 92
Loss: 0.440 | Acc: 89.062% (57/64)
Loss: 0.307 | Acc: 92.265% (5964/6464)
Loss: 0.306 | Acc: 92.475% (11896/12864)
Loss: 0.311 | Acc: 92.286% (17778/19264)
Loss: 0.315 | Acc: 92.195% (23661/25664)
Loss: 0.321 | Acc: 92.007% (29501/32064)
Loss: 0.321 | Acc: 91.993% (35384/38464)
Loss: 0.319 | Acc: 91.991% (41271/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8842, Accuracy: 8230/10000 (82.30%)

Epoch: 93
Loss: 0.369 | Acc: 89.062% (57/64)
Loss: 0.263 | Acc: 93.441% (6040/6464)
Loss: 0.265 | Acc: 93.354% (12009/12864)
Loss: 0.266 | Acc: 93.340% (17981/19264)
Loss: 0.275 | Acc: 93.115% (23897/25664)
Loss: 0.276 | Acc: 93.061% (29839/32064)
Loss: 0.274 | Acc: 93.118% (35817/38464)
Loss: 0.276 | Acc: 93.026% (41735/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8971, Accuracy: 8238/10000 (82.38%)

Epoch: 94
Loss: 0.172 | Acc: 93.750% (60/64)
Loss: 0.244 | Acc: 93.951% (6073/6464)
Loss: 0.250 | Acc: 93.804% (12067/12864)
Loss: 0.250 | Acc: 93.677% (18046/19264)
Loss: 0.248 | Acc: 93.688% (24044/25664)
Loss: 0.249 | Acc: 93.685% (30039/32064)
Loss: 0.247 | Acc: 93.708% (36044/38464)
Loss: 0.244 | Acc: 93.766% (42067/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9189, Accuracy: 8221/10000 (82.21%)

Epoch: 95
Loss: 0.104 | Acc: 96.875% (62/64)
Loss: 0.204 | Acc: 94.647% (6118/6464)
Loss: 0.218 | Acc: 94.395% (12143/12864)
Loss: 0.224 | Acc: 94.217% (18150/19264)
Loss: 0.228 | Acc: 94.112% (24153/25664)
Loss: 0.232 | Acc: 94.031% (30150/32064)
Loss: 0.236 | Acc: 93.953% (36138/38464)
Loss: 0.237 | Acc: 93.953% (42151/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8882, Accuracy: 8224/10000 (82.24%)

Epoch: 96
Loss: 0.229 | Acc: 93.750% (60/64)
Loss: 0.238 | Acc: 93.688% (6056/6464)
Loss: 0.232 | Acc: 93.898% (12079/12864)
Loss: 0.242 | Acc: 93.662% (18043/19264)
Loss: 0.243 | Acc: 93.606% (24023/25664)
Loss: 0.244 | Acc: 93.613% (30016/32064)
Loss: 0.245 | Acc: 93.612% (36007/38464)
Loss: 0.246 | Acc: 93.574% (41981/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8704, Accuracy: 8218/10000 (82.18%)

Epoch: 97
Loss: 0.283 | Acc: 92.188% (59/64)
Loss: 0.244 | Acc: 93.673% (6055/6464)
Loss: 0.247 | Acc: 93.688% (12052/12864)
Loss: 0.245 | Acc: 93.797% (18069/19264)
Loss: 0.247 | Acc: 93.692% (24045/25664)
Loss: 0.246 | Acc: 93.747% (30059/32064)
Loss: 0.244 | Acc: 93.786% (36074/38464)
Loss: 0.244 | Acc: 93.761% (42065/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8668, Accuracy: 8249/10000 (82.49%)
torch.Size([100, 10])
Test set: Average loss: 0.8668, Accuracy: 8249/10000 (82.49%)

Epoch: 98
Loss: 0.089 | Acc: 100.000% (64/64)
Loss: 0.246 | Acc: 93.765% (6061/6464)
Loss: 0.246 | Acc: 93.734% (12058/12864)
Loss: 0.247 | Acc: 93.646% (18040/19264)
Loss: 0.243 | Acc: 93.742% (24058/25664)
Loss: 0.243 | Acc: 93.738% (30056/32064)
Loss: 0.243 | Acc: 93.701% (36041/38464)
Loss: 0.243 | Acc: 93.663% (42021/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8619, Accuracy: 8231/10000 (82.31%)
torch.Size([100, 10])
Test set: Average loss: 0.8619, Accuracy: 8231/10000 (82.31%)

Epoch: 99
Loss: 0.105 | Acc: 98.438% (63/64)
Loss: 0.231 | Acc: 93.998% (6076/6464)
Loss: 0.232 | Acc: 93.944% (12085/12864)
Loss: 0.231 | Acc: 93.989% (18106/19264)
Loss: 0.236 | Acc: 93.797% (24072/25664)
Loss: 0.239 | Acc: 93.703% (30045/32064)
Loss: 0.238 | Acc: 93.768% (36067/38464)
Loss: 0.238 | Acc: 93.746% (42058/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8611, Accuracy: 8234/10000 (82.34%)
torch.Size([100, 10])
Test set: Average loss: 0.8611, Accuracy: 8234/10000 (82.34%)

Epoch: 100
Loss: 0.179 | Acc: 95.312% (61/64)
Loss: 1.412 | Acc: 54.533% (3525/6464)
Loss: 1.219 | Acc: 62.407% (8028/12864)
Loss: 1.128 | Acc: 66.217% (12756/19264)
Loss: 1.075 | Acc: 68.477% (17574/25664)
Loss: 1.039 | Acc: 69.926% (22421/32064)
Loss: 1.014 | Acc: 70.890% (27267/38464)
Loss: 0.995 | Acc: 71.650% (32145/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5519, Accuracy: 5245/10000 (52.45%)

Epoch: 101
Loss: 1.059 | Acc: 68.750% (44/64)
Loss: 0.832 | Acc: 77.444% (5006/6464)
Loss: 0.833 | Acc: 77.697% (9995/12864)
Loss: 0.832 | Acc: 77.829% (14993/19264)
Loss: 0.830 | Acc: 77.891% (19990/25664)
Loss: 0.830 | Acc: 77.916% (24983/32064)
Loss: 0.829 | Acc: 77.964% (29988/38464)
Loss: 0.834 | Acc: 77.878% (34939/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0745, Accuracy: 7038/10000 (70.38%)

Epoch: 102
Loss: 0.707 | Acc: 81.250% (52/64)
Loss: 0.797 | Acc: 79.192% (5119/6464)
Loss: 0.802 | Acc: 78.933% (10154/12864)
Loss: 0.801 | Acc: 78.909% (15201/19264)
Loss: 0.802 | Acc: 78.928% (20256/25664)
Loss: 0.800 | Acc: 79.086% (25358/32064)
Loss: 0.803 | Acc: 78.931% (30360/38464)
Loss: 0.802 | Acc: 78.994% (35440/44864)
torch.Size([100, 10])
Test set: Average loss: 3.0777, Accuracy: 3576/10000 (35.76%)

Epoch: 103
Loss: 1.016 | Acc: 67.188% (43/64)
Loss: 0.803 | Acc: 78.481% (5073/6464)
Loss: 0.808 | Acc: 78.879% (10147/12864)
Loss: 0.798 | Acc: 79.251% (15267/19264)
Loss: 0.798 | Acc: 79.349% (20364/25664)
Loss: 0.801 | Acc: 79.263% (25415/32064)
Loss: 0.800 | Acc: 79.282% (30495/38464)
Loss: 0.801 | Acc: 79.202% (35533/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9822, Accuracy: 4859/10000 (48.59%)

Epoch: 104
Loss: 0.821 | Acc: 82.812% (53/64)
Loss: 0.781 | Acc: 79.641% (5148/6464)
Loss: 0.789 | Acc: 79.478% (10224/12864)
Loss: 0.789 | Acc: 79.625% (15339/19264)
Loss: 0.793 | Acc: 79.481% (20398/25664)
Loss: 0.794 | Acc: 79.497% (25490/32064)
Loss: 0.794 | Acc: 79.409% (30544/38464)
Loss: 0.795 | Acc: 79.344% (35597/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3398, Accuracy: 6278/10000 (62.78%)

Epoch: 105
Loss: 0.938 | Acc: 78.125% (50/64)
Loss: 0.772 | Acc: 80.523% (5205/6464)
Loss: 0.777 | Acc: 79.944% (10284/12864)
Loss: 0.779 | Acc: 79.885% (15389/19264)
Loss: 0.778 | Acc: 79.789% (20477/25664)
Loss: 0.783 | Acc: 79.744% (25569/32064)
Loss: 0.785 | Acc: 79.716% (30662/38464)
Loss: 0.788 | Acc: 79.672% (35744/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2805, Accuracy: 6313/10000 (63.13%)

Epoch: 106
Loss: 0.889 | Acc: 78.125% (50/64)
Loss: 0.782 | Acc: 80.152% (5181/6464)
Loss: 0.785 | Acc: 79.897% (10278/12864)
Loss: 0.777 | Acc: 80.160% (15442/19264)
Loss: 0.781 | Acc: 80.062% (20547/25664)
Loss: 0.782 | Acc: 79.984% (25646/32064)
Loss: 0.784 | Acc: 79.916% (30739/38464)
Loss: 0.789 | Acc: 79.737% (35773/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0363, Accuracy: 7194/10000 (71.94%)

Epoch: 107
Loss: 0.784 | Acc: 73.438% (47/64)
Loss: 0.770 | Acc: 80.183% (5183/6464)
Loss: 0.780 | Acc: 79.781% (10263/12864)
Loss: 0.781 | Acc: 79.859% (15384/19264)
Loss: 0.783 | Acc: 79.808% (20482/25664)
Loss: 0.785 | Acc: 79.644% (25537/32064)
Loss: 0.783 | Acc: 79.698% (30655/38464)
Loss: 0.782 | Acc: 79.810% (35806/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6649, Accuracy: 5234/10000 (52.34%)

Epoch: 108
Loss: 1.192 | Acc: 67.188% (43/64)
Loss: 0.760 | Acc: 80.476% (5202/6464)
Loss: 0.763 | Acc: 80.449% (10349/12864)
Loss: 0.774 | Acc: 80.118% (15434/19264)
Loss: 0.777 | Acc: 80.065% (20548/25664)
Loss: 0.775 | Acc: 80.196% (25714/32064)
Loss: 0.780 | Acc: 79.989% (30767/38464)
Loss: 0.782 | Acc: 79.930% (35860/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9355, Accuracy: 4258/10000 (42.58%)

Epoch: 109
Loss: 0.903 | Acc: 73.438% (47/64)
Loss: 0.784 | Acc: 79.858% (5162/6464)
Loss: 0.786 | Acc: 79.804% (10266/12864)
Loss: 0.782 | Acc: 79.989% (15409/19264)
Loss: 0.777 | Acc: 80.085% (20553/25664)
Loss: 0.779 | Acc: 80.006% (25653/32064)
Loss: 0.781 | Acc: 79.958% (30755/38464)
Loss: 0.784 | Acc: 79.926% (35858/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3048, Accuracy: 6323/10000 (63.23%)

Epoch: 110
Loss: 0.836 | Acc: 75.000% (48/64)
Loss: 0.777 | Acc: 79.966% (5169/6464)
Loss: 0.761 | Acc: 80.488% (10354/12864)
Loss: 0.761 | Acc: 80.528% (15513/19264)
Loss: 0.761 | Acc: 80.607% (20687/25664)
Loss: 0.766 | Acc: 80.433% (25790/32064)
Loss: 0.770 | Acc: 80.280% (30879/38464)
Loss: 0.769 | Acc: 80.332% (36040/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0991, Accuracy: 6866/10000 (68.66%)

Epoch: 111
Loss: 0.825 | Acc: 75.000% (48/64)
Loss: 0.778 | Acc: 79.981% (5170/6464)
Loss: 0.769 | Acc: 80.271% (10326/12864)
Loss: 0.763 | Acc: 80.404% (15489/19264)
Loss: 0.757 | Acc: 80.603% (20686/25664)
Loss: 0.763 | Acc: 80.558% (25830/32064)
Loss: 0.767 | Acc: 80.447% (30943/38464)
Loss: 0.769 | Acc: 80.459% (36097/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1585, Accuracy: 6678/10000 (66.78%)

Epoch: 112
Loss: 1.191 | Acc: 68.750% (44/64)
Loss: 0.736 | Acc: 81.652% (5278/6464)
Loss: 0.743 | Acc: 81.289% (10457/12864)
Loss: 0.752 | Acc: 81.006% (15605/19264)
Loss: 0.753 | Acc: 80.966% (20779/25664)
Loss: 0.757 | Acc: 80.735% (25887/32064)
Loss: 0.761 | Acc: 80.629% (31013/38464)
Loss: 0.765 | Acc: 80.506% (36118/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2110, Accuracy: 6511/10000 (65.11%)

Epoch: 113
Loss: 0.734 | Acc: 85.938% (55/64)
Loss: 0.741 | Acc: 81.528% (5270/6464)
Loss: 0.751 | Acc: 81.025% (10423/12864)
Loss: 0.748 | Acc: 81.027% (15609/19264)
Loss: 0.748 | Acc: 81.032% (20796/25664)
Loss: 0.744 | Acc: 81.072% (25995/32064)
Loss: 0.749 | Acc: 81.006% (31158/38464)
Loss: 0.755 | Acc: 80.896% (36293/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5822, Accuracy: 5593/10000 (55.93%)

Epoch: 114
Loss: 0.865 | Acc: 76.562% (49/64)
Loss: 0.738 | Acc: 81.436% (5264/6464)
Loss: 0.743 | Acc: 81.118% (10435/12864)
Loss: 0.746 | Acc: 80.970% (15598/19264)
Loss: 0.742 | Acc: 81.133% (20822/25664)
Loss: 0.746 | Acc: 81.094% (26002/32064)
Loss: 0.751 | Acc: 80.990% (31152/38464)
Loss: 0.753 | Acc: 80.891% (36291/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1661, Accuracy: 6780/10000 (67.80%)

Epoch: 115
Loss: 0.856 | Acc: 73.438% (47/64)
Loss: 0.710 | Acc: 82.039% (5303/6464)
Loss: 0.719 | Acc: 82.121% (10564/12864)
Loss: 0.737 | Acc: 81.463% (15693/19264)
Loss: 0.739 | Acc: 81.429% (20898/25664)
Loss: 0.739 | Acc: 81.393% (26098/32064)
Loss: 0.740 | Acc: 81.279% (31263/38464)
Loss: 0.743 | Acc: 81.152% (36408/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0628, Accuracy: 7073/10000 (70.73%)

Epoch: 116
Loss: 0.682 | Acc: 81.250% (52/64)
Loss: 0.739 | Acc: 81.358% (5259/6464)
Loss: 0.740 | Acc: 81.328% (10462/12864)
Loss: 0.737 | Acc: 81.536% (15707/19264)
Loss: 0.737 | Acc: 81.511% (20919/25664)
Loss: 0.745 | Acc: 81.287% (26064/32064)
Loss: 0.741 | Acc: 81.411% (31314/38464)
Loss: 0.741 | Acc: 81.337% (36491/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8614, Accuracy: 7740/10000 (77.40%)

Epoch: 117
Loss: 0.502 | Acc: 85.938% (55/64)
Loss: 0.743 | Acc: 81.296% (5255/6464)
Loss: 0.736 | Acc: 81.631% (10501/12864)
Loss: 0.728 | Acc: 81.894% (15776/19264)
Loss: 0.727 | Acc: 81.885% (21015/25664)
Loss: 0.738 | Acc: 81.606% (26166/32064)
Loss: 0.736 | Acc: 81.648% (31405/38464)
Loss: 0.734 | Acc: 81.662% (36637/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9923, Accuracy: 7227/10000 (72.27%)

Epoch: 118
Loss: 0.776 | Acc: 82.812% (53/64)
Loss: 0.707 | Acc: 82.225% (5315/6464)
Loss: 0.711 | Acc: 82.198% (10574/12864)
Loss: 0.708 | Acc: 82.200% (15835/19264)
Loss: 0.716 | Acc: 81.998% (21044/25664)
Loss: 0.722 | Acc: 81.874% (26252/32064)
Loss: 0.722 | Acc: 81.874% (31492/38464)
Loss: 0.726 | Acc: 81.772% (36686/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8208, Accuracy: 4805/10000 (48.05%)

Epoch: 119
Loss: 0.586 | Acc: 87.500% (56/64)
Loss: 0.732 | Acc: 81.467% (5266/6464)
Loss: 0.718 | Acc: 82.152% (10568/12864)
Loss: 0.711 | Acc: 82.288% (15852/19264)
Loss: 0.715 | Acc: 82.173% (21089/25664)
Loss: 0.718 | Acc: 82.126% (26333/32064)
Loss: 0.719 | Acc: 82.142% (31595/38464)
Loss: 0.720 | Acc: 82.126% (36845/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9470, Accuracy: 7487/10000 (74.87%)

Epoch: 120
Loss: 0.448 | Acc: 92.188% (59/64)
Loss: 0.706 | Acc: 82.580% (5338/6464)
Loss: 0.711 | Acc: 82.463% (10608/12864)
Loss: 0.708 | Acc: 82.470% (15887/19264)
Loss: 0.710 | Acc: 82.481% (21168/25664)
Loss: 0.707 | Acc: 82.507% (26455/32064)
Loss: 0.710 | Acc: 82.446% (31712/38464)
Loss: 0.709 | Acc: 82.503% (37014/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9850, Accuracy: 7373/10000 (73.73%)

Epoch: 121
Loss: 0.651 | Acc: 84.375% (54/64)
Loss: 0.662 | Acc: 83.679% (5409/6464)
Loss: 0.686 | Acc: 83.108% (10691/12864)
Loss: 0.690 | Acc: 82.927% (15975/19264)
Loss: 0.696 | Acc: 82.727% (21231/25664)
Loss: 0.697 | Acc: 82.678% (26510/32064)
Loss: 0.701 | Acc: 82.675% (31800/38464)
Loss: 0.703 | Acc: 82.610% (37062/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8911, Accuracy: 7695/10000 (76.95%)

Epoch: 122
Loss: 0.910 | Acc: 75.000% (48/64)
Loss: 0.670 | Acc: 83.756% (5414/6464)
Loss: 0.666 | Acc: 83.971% (10802/12864)
Loss: 0.674 | Acc: 83.716% (16127/19264)
Loss: 0.678 | Acc: 83.557% (21444/25664)
Loss: 0.682 | Acc: 83.427% (26750/32064)
Loss: 0.684 | Acc: 83.291% (32037/38464)
Loss: 0.688 | Acc: 83.136% (37298/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0045, Accuracy: 7275/10000 (72.75%)

Epoch: 123
Loss: 0.560 | Acc: 84.375% (54/64)
Loss: 0.681 | Acc: 83.493% (5397/6464)
Loss: 0.681 | Acc: 83.442% (10734/12864)
Loss: 0.682 | Acc: 83.332% (16053/19264)
Loss: 0.681 | Acc: 83.409% (21406/25664)
Loss: 0.683 | Acc: 83.258% (26696/32064)
Loss: 0.684 | Acc: 83.239% (32017/38464)
Loss: 0.686 | Acc: 83.178% (37317/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9450, Accuracy: 7549/10000 (75.49%)

Epoch: 124
Loss: 0.654 | Acc: 81.250% (52/64)
Loss: 0.661 | Acc: 84.050% (5433/6464)
Loss: 0.657 | Acc: 84.017% (10808/12864)
Loss: 0.664 | Acc: 83.866% (16156/19264)
Loss: 0.663 | Acc: 83.794% (21505/25664)
Loss: 0.669 | Acc: 83.667% (26827/32064)
Loss: 0.671 | Acc: 83.683% (32188/38464)
Loss: 0.675 | Acc: 83.597% (37505/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8550, Accuracy: 7814/10000 (78.14%)

Epoch: 125
Loss: 0.616 | Acc: 85.938% (55/64)
Loss: 0.646 | Acc: 84.189% (5442/6464)
Loss: 0.639 | Acc: 84.546% (10876/12864)
Loss: 0.657 | Acc: 84.121% (16205/19264)
Loss: 0.656 | Acc: 84.161% (21599/25664)
Loss: 0.661 | Acc: 83.973% (26925/32064)
Loss: 0.660 | Acc: 83.949% (32290/38464)
Loss: 0.665 | Acc: 83.836% (37612/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0777, Accuracy: 6930/10000 (69.30%)

Epoch: 126
Loss: 0.576 | Acc: 79.688% (51/64)
Loss: 0.629 | Acc: 84.746% (5478/6464)
Loss: 0.630 | Acc: 84.686% (10894/12864)
Loss: 0.646 | Acc: 84.463% (16271/19264)
Loss: 0.651 | Acc: 84.289% (21632/25664)
Loss: 0.651 | Acc: 84.294% (27028/32064)
Loss: 0.650 | Acc: 84.349% (32444/38464)
Loss: 0.650 | Acc: 84.346% (37841/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8406, Accuracy: 7890/10000 (78.90%)

Epoch: 127
Loss: 0.550 | Acc: 85.938% (55/64)
Loss: 0.626 | Acc: 84.994% (5494/6464)
Loss: 0.633 | Acc: 84.748% (10902/12864)
Loss: 0.641 | Acc: 84.614% (16300/19264)
Loss: 0.643 | Acc: 84.566% (21703/25664)
Loss: 0.643 | Acc: 84.575% (27118/32064)
Loss: 0.641 | Acc: 84.656% (32562/38464)
Loss: 0.639 | Acc: 84.678% (37990/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8406, Accuracy: 7907/10000 (79.07%)

Epoch: 128
Loss: 0.764 | Acc: 81.250% (52/64)
Loss: 0.592 | Acc: 86.015% (5560/6464)
Loss: 0.601 | Acc: 85.743% (11030/12864)
Loss: 0.609 | Acc: 85.496% (16470/19264)
Loss: 0.615 | Acc: 85.349% (21904/25664)
Loss: 0.621 | Acc: 85.177% (27311/32064)
Loss: 0.624 | Acc: 85.059% (32717/38464)
Loss: 0.626 | Acc: 84.968% (38120/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0246, Accuracy: 7461/10000 (74.61%)

Epoch: 129
Loss: 0.666 | Acc: 82.812% (53/64)
Loss: 0.600 | Acc: 85.489% (5526/6464)
Loss: 0.608 | Acc: 85.417% (10988/12864)
Loss: 0.601 | Acc: 85.740% (16517/19264)
Loss: 0.606 | Acc: 85.583% (21964/25664)
Loss: 0.612 | Acc: 85.448% (27398/32064)
Loss: 0.616 | Acc: 85.392% (32845/38464)
Loss: 0.617 | Acc: 85.376% (38303/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9118, Accuracy: 7737/10000 (77.37%)

Epoch: 130
Loss: 0.762 | Acc: 82.812% (53/64)
Loss: 0.602 | Acc: 85.938% (5555/6464)
Loss: 0.616 | Acc: 85.494% (10998/12864)
Loss: 0.604 | Acc: 85.668% (16503/19264)
Loss: 0.601 | Acc: 85.727% (22001/25664)
Loss: 0.599 | Acc: 85.738% (27491/32064)
Loss: 0.602 | Acc: 85.693% (32961/38464)
Loss: 0.599 | Acc: 85.764% (38477/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9310, Accuracy: 7568/10000 (75.68%)

Epoch: 131
Loss: 0.570 | Acc: 87.500% (56/64)
Loss: 0.573 | Acc: 86.928% (5619/6464)
Loss: 0.570 | Acc: 86.707% (11154/12864)
Loss: 0.566 | Acc: 86.794% (16720/19264)
Loss: 0.573 | Acc: 86.588% (22222/25664)
Loss: 0.577 | Acc: 86.499% (27735/32064)
Loss: 0.577 | Acc: 86.556% (33293/38464)
Loss: 0.580 | Acc: 86.441% (38781/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9007, Accuracy: 7662/10000 (76.62%)

Epoch: 132
Loss: 0.773 | Acc: 81.250% (52/64)
Loss: 0.548 | Acc: 87.330% (5645/6464)
Loss: 0.560 | Acc: 86.855% (11173/12864)
Loss: 0.559 | Acc: 86.887% (16738/19264)
Loss: 0.565 | Acc: 86.795% (22275/25664)
Loss: 0.570 | Acc: 86.633% (27778/32064)
Loss: 0.571 | Acc: 86.689% (33344/38464)
Loss: 0.570 | Acc: 86.682% (38889/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9110, Accuracy: 7723/10000 (77.23%)

Epoch: 133
Loss: 0.534 | Acc: 89.062% (57/64)
Loss: 0.491 | Acc: 88.444% (5717/6464)
Loss: 0.519 | Acc: 87.819% (11297/12864)
Loss: 0.534 | Acc: 87.542% (16864/19264)
Loss: 0.535 | Acc: 87.558% (22471/25664)
Loss: 0.543 | Acc: 87.435% (28035/32064)
Loss: 0.546 | Acc: 87.380% (33610/38464)
Loss: 0.546 | Acc: 87.368% (39197/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8406, Accuracy: 7962/10000 (79.62%)

Epoch: 134
Loss: 0.353 | Acc: 90.625% (58/64)
Loss: 0.529 | Acc: 87.562% (5660/6464)
Loss: 0.524 | Acc: 87.733% (11286/12864)
Loss: 0.518 | Acc: 87.957% (16944/19264)
Loss: 0.521 | Acc: 87.835% (22542/25664)
Loss: 0.527 | Acc: 87.718% (28126/32064)
Loss: 0.527 | Acc: 87.716% (33739/38464)
Loss: 0.522 | Acc: 87.801% (39391/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8364, Accuracy: 7930/10000 (79.30%)

Epoch: 135
Loss: 0.540 | Acc: 87.500% (56/64)
Loss: 0.468 | Acc: 88.800% (5740/6464)
Loss: 0.471 | Acc: 88.938% (11441/12864)
Loss: 0.483 | Acc: 88.590% (17066/19264)
Loss: 0.493 | Acc: 88.427% (22694/25664)
Loss: 0.496 | Acc: 88.451% (28361/32064)
Loss: 0.504 | Acc: 88.303% (33965/38464)
Loss: 0.502 | Acc: 88.374% (39648/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8611, Accuracy: 7979/10000 (79.79%)

Epoch: 136
Loss: 0.418 | Acc: 89.062% (57/64)
Loss: 0.484 | Acc: 88.815% (5741/6464)
Loss: 0.480 | Acc: 88.923% (11439/12864)
Loss: 0.471 | Acc: 89.109% (17166/19264)
Loss: 0.475 | Acc: 89.062% (22857/25664)
Loss: 0.477 | Acc: 88.953% (28522/32064)
Loss: 0.482 | Acc: 88.797% (34155/38464)
Loss: 0.481 | Acc: 88.862% (39867/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9873, Accuracy: 7586/10000 (75.86%)

Epoch: 137
Loss: 0.507 | Acc: 90.625% (58/64)
Loss: 0.451 | Acc: 89.155% (5763/6464)
Loss: 0.446 | Acc: 89.459% (11508/12864)
Loss: 0.452 | Acc: 89.415% (17225/19264)
Loss: 0.451 | Acc: 89.476% (22963/25664)
Loss: 0.455 | Acc: 89.368% (28655/32064)
Loss: 0.458 | Acc: 89.312% (34353/38464)
Loss: 0.458 | Acc: 89.265% (40048/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8943, Accuracy: 7900/10000 (79.00%)

Epoch: 138
Loss: 0.454 | Acc: 90.625% (58/64)
Loss: 0.420 | Acc: 90.130% (5826/6464)
Loss: 0.427 | Acc: 89.972% (11574/12864)
Loss: 0.419 | Acc: 90.199% (17376/19264)
Loss: 0.416 | Acc: 90.181% (23144/25664)
Loss: 0.421 | Acc: 90.029% (28867/32064)
Loss: 0.418 | Acc: 90.105% (34658/38464)
Loss: 0.424 | Acc: 90.014% (40384/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8447, Accuracy: 8149/10000 (81.49%)

Epoch: 139
Loss: 0.466 | Acc: 87.500% (56/64)
Loss: 0.385 | Acc: 90.842% (5872/6464)
Loss: 0.385 | Acc: 90.796% (11680/12864)
Loss: 0.389 | Acc: 90.801% (17492/19264)
Loss: 0.395 | Acc: 90.609% (23254/25664)
Loss: 0.398 | Acc: 90.563% (29038/32064)
Loss: 0.398 | Acc: 90.594% (34846/38464)
Loss: 0.398 | Acc: 90.578% (40637/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0125, Accuracy: 7717/10000 (77.17%)

Epoch: 140
Loss: 0.377 | Acc: 85.938% (55/64)
Loss: 0.371 | Acc: 91.166% (5893/6464)
Loss: 0.370 | Acc: 91.115% (11721/12864)
Loss: 0.363 | Acc: 91.310% (17590/19264)
Loss: 0.368 | Acc: 91.108% (23382/25664)
Loss: 0.365 | Acc: 91.180% (29236/32064)
Loss: 0.367 | Acc: 91.153% (35061/38464)
Loss: 0.368 | Acc: 91.104% (40873/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8541, Accuracy: 8200/10000 (82.00%)

Epoch: 141
Loss: 0.322 | Acc: 92.188% (59/64)
Loss: 0.316 | Acc: 92.249% (5963/6464)
Loss: 0.330 | Acc: 91.822% (11812/12864)
Loss: 0.329 | Acc: 91.892% (17702/19264)
Loss: 0.331 | Acc: 91.813% (23563/25664)
Loss: 0.329 | Acc: 91.854% (29452/32064)
Loss: 0.326 | Acc: 91.912% (35353/38464)
Loss: 0.331 | Acc: 91.824% (41196/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8903, Accuracy: 8182/10000 (81.82%)

Epoch: 142
Loss: 0.221 | Acc: 95.312% (61/64)
Loss: 0.311 | Acc: 91.986% (5946/6464)
Loss: 0.300 | Acc: 92.436% (11891/12864)
Loss: 0.300 | Acc: 92.452% (17810/19264)
Loss: 0.299 | Acc: 92.523% (23745/25664)
Loss: 0.299 | Acc: 92.490% (29656/32064)
Loss: 0.300 | Acc: 92.536% (35593/38464)
Loss: 0.301 | Acc: 92.549% (41521/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8907, Accuracy: 8230/10000 (82.30%)

Epoch: 143
Loss: 0.286 | Acc: 93.750% (60/64)
Loss: 0.272 | Acc: 92.775% (5997/6464)
Loss: 0.273 | Acc: 92.786% (11936/12864)
Loss: 0.261 | Acc: 93.272% (17968/19264)
Loss: 0.263 | Acc: 93.247% (23931/25664)
Loss: 0.264 | Acc: 93.298% (29915/32064)
Loss: 0.263 | Acc: 93.360% (35910/38464)
Loss: 0.265 | Acc: 93.289% (41853/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9022, Accuracy: 8266/10000 (82.66%)

Epoch: 144
Loss: 0.265 | Acc: 92.188% (59/64)
Loss: 0.231 | Acc: 93.827% (6065/6464)
Loss: 0.226 | Acc: 94.022% (12095/12864)
Loss: 0.228 | Acc: 94.056% (18119/19264)
Loss: 0.228 | Acc: 94.085% (24146/25664)
Loss: 0.227 | Acc: 94.146% (30187/32064)
Loss: 0.229 | Acc: 94.137% (36209/38464)
Loss: 0.231 | Acc: 94.062% (42200/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9325, Accuracy: 8205/10000 (82.05%)

Epoch: 145
Loss: 0.240 | Acc: 95.312% (61/64)
Loss: 0.203 | Acc: 94.446% (6105/6464)
Loss: 0.205 | Acc: 94.395% (12143/12864)
Loss: 0.209 | Acc: 94.409% (18187/19264)
Loss: 0.210 | Acc: 94.420% (24232/25664)
Loss: 0.211 | Acc: 94.449% (30284/32064)
Loss: 0.215 | Acc: 94.319% (36279/38464)
Loss: 0.218 | Acc: 94.280% (42298/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9058, Accuracy: 8190/10000 (81.90%)

Epoch: 146
Loss: 0.367 | Acc: 85.938% (55/64)
Loss: 0.206 | Acc: 94.817% (6129/6464)
Loss: 0.220 | Acc: 94.302% (12131/12864)
Loss: 0.223 | Acc: 94.176% (18142/19264)
Loss: 0.222 | Acc: 94.171% (24168/25664)
Loss: 0.224 | Acc: 94.137% (30184/32064)
Loss: 0.227 | Acc: 94.075% (36185/38464)
Loss: 0.229 | Acc: 94.095% (42215/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8808, Accuracy: 8228/10000 (82.28%)

Epoch: 147
Loss: 0.193 | Acc: 92.188% (59/64)
Loss: 0.222 | Acc: 93.936% (6072/6464)
Loss: 0.228 | Acc: 93.929% (12083/12864)
Loss: 0.230 | Acc: 93.952% (18099/19264)
Loss: 0.224 | Acc: 94.073% (24143/25664)
Loss: 0.225 | Acc: 94.040% (30153/32064)
Loss: 0.228 | Acc: 93.979% (36148/38464)
Loss: 0.229 | Acc: 94.004% (42174/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8758, Accuracy: 8211/10000 (82.11%)
torch.Size([100, 10])
Test set: Average loss: 0.8758, Accuracy: 8211/10000 (82.11%)

Epoch: 148
Loss: 0.121 | Acc: 98.438% (63/64)
Loss: 0.220 | Acc: 94.353% (6099/6464)
Loss: 0.220 | Acc: 94.286% (12129/12864)
Loss: 0.222 | Acc: 94.165% (18140/19264)
Loss: 0.221 | Acc: 94.315% (24205/25664)
Loss: 0.221 | Acc: 94.296% (30235/32064)
Loss: 0.225 | Acc: 94.205% (36235/38464)
Loss: 0.224 | Acc: 94.182% (42254/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8707, Accuracy: 8235/10000 (82.35%)
torch.Size([100, 10])
Test set: Average loss: 0.8707, Accuracy: 8235/10000 (82.35%)

Epoch: 149
Loss: 0.357 | Acc: 89.062% (57/64)
Loss: 0.230 | Acc: 93.936% (6072/6464)
Loss: 0.223 | Acc: 94.193% (12117/12864)
Loss: 0.220 | Acc: 94.238% (18154/19264)
Loss: 0.220 | Acc: 94.237% (24185/25664)
Loss: 0.220 | Acc: 94.233% (30215/32064)
Loss: 0.223 | Acc: 94.158% (36217/38464)
Loss: 0.223 | Acc: 94.171% (42249/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8808, Accuracy: 8213/10000 (82.13%)
torch.Size([100, 10])
Test set: Average loss: 0.8808, Accuracy: 8213/10000 (82.13%)

Epoch: 150
Loss: 0.130 | Acc: 98.438% (63/64)
Loss: 1.782 | Acc: 38.103% (2463/6464)
Loss: 1.457 | Acc: 52.208% (6716/12864)
Loss: 1.306 | Acc: 58.596% (11288/19264)
Loss: 1.216 | Acc: 62.406% (16016/25664)
Loss: 1.151 | Acc: 64.976% (20834/32064)
Loss: 1.106 | Acc: 66.876% (25723/38464)
Loss: 1.074 | Acc: 68.199% (30597/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7166, Accuracy: 4872/10000 (48.72%)

Epoch: 151
Loss: 0.753 | Acc: 82.812% (53/64)
Loss: 0.830 | Acc: 77.645% (5019/6464)
Loss: 0.833 | Acc: 77.573% (9979/12864)
Loss: 0.842 | Acc: 77.466% (14923/19264)
Loss: 0.838 | Acc: 77.630% (19923/25664)
Loss: 0.833 | Acc: 77.819% (24952/32064)
Loss: 0.831 | Acc: 77.964% (29988/38464)
Loss: 0.829 | Acc: 78.049% (35016/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0226, Accuracy: 4294/10000 (42.94%)

Epoch: 152
Loss: 0.881 | Acc: 76.562% (49/64)
Loss: 0.795 | Acc: 79.595% (5145/6464)
Loss: 0.788 | Acc: 79.921% (10281/12864)
Loss: 0.799 | Acc: 79.355% (15287/19264)
Loss: 0.801 | Acc: 79.197% (20325/25664)
Loss: 0.806 | Acc: 79.104% (25364/32064)
Loss: 0.808 | Acc: 78.993% (30384/38464)
Loss: 0.804 | Acc: 79.164% (35516/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7470, Accuracy: 5060/10000 (50.60%)

Epoch: 153
Loss: 0.813 | Acc: 71.875% (46/64)
Loss: 0.783 | Acc: 79.610% (5146/6464)
Loss: 0.773 | Acc: 79.944% (10284/12864)
Loss: 0.778 | Acc: 79.854% (15383/19264)
Loss: 0.779 | Acc: 79.832% (20488/25664)
Loss: 0.784 | Acc: 79.703% (25556/32064)
Loss: 0.789 | Acc: 79.552% (30599/38464)
Loss: 0.791 | Acc: 79.505% (35669/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9880, Accuracy: 7244/10000 (72.44%)

Epoch: 154
Loss: 0.884 | Acc: 79.688% (51/64)
Loss: 0.772 | Acc: 79.811% (5159/6464)
Loss: 0.786 | Acc: 79.423% (10217/12864)
Loss: 0.784 | Acc: 79.698% (15353/19264)
Loss: 0.784 | Acc: 79.750% (20467/25664)
Loss: 0.788 | Acc: 79.634% (25534/32064)
Loss: 0.786 | Acc: 79.719% (30663/38464)
Loss: 0.786 | Acc: 79.728% (35769/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3332, Accuracy: 6040/10000 (60.40%)

Epoch: 155
Loss: 1.038 | Acc: 68.750% (44/64)
Loss: 0.782 | Acc: 79.889% (5164/6464)
Loss: 0.784 | Acc: 79.859% (10273/12864)
Loss: 0.776 | Acc: 80.056% (15422/19264)
Loss: 0.779 | Acc: 79.855% (20494/25664)
Loss: 0.777 | Acc: 80.015% (25656/32064)
Loss: 0.779 | Acc: 79.947% (30751/38464)
Loss: 0.783 | Acc: 79.857% (35827/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1563, Accuracy: 6880/10000 (68.80%)

Epoch: 156
Loss: 0.606 | Acc: 84.375% (54/64)
Loss: 0.769 | Acc: 79.811% (5159/6464)
Loss: 0.772 | Acc: 80.061% (10299/12864)
Loss: 0.765 | Acc: 80.238% (15457/19264)
Loss: 0.769 | Acc: 80.069% (20549/25664)
Loss: 0.775 | Acc: 79.937% (25631/32064)
Loss: 0.779 | Acc: 79.854% (30715/38464)
Loss: 0.779 | Acc: 79.866% (35831/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2410, Accuracy: 6409/10000 (64.09%)

Epoch: 157
Loss: 0.793 | Acc: 75.000% (48/64)
Loss: 0.789 | Acc: 79.471% (5137/6464)
Loss: 0.766 | Acc: 80.387% (10341/12864)
Loss: 0.777 | Acc: 79.999% (15411/19264)
Loss: 0.781 | Acc: 79.898% (20505/25664)
Loss: 0.781 | Acc: 79.840% (25600/32064)
Loss: 0.776 | Acc: 80.028% (30782/38464)
Loss: 0.779 | Acc: 79.995% (35889/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6707, Accuracy: 5663/10000 (56.63%)

Epoch: 158
Loss: 0.924 | Acc: 78.125% (50/64)
Loss: 0.771 | Acc: 80.538% (5206/6464)
Loss: 0.766 | Acc: 80.333% (10334/12864)
Loss: 0.768 | Acc: 80.399% (15488/19264)
Loss: 0.768 | Acc: 80.490% (20657/25664)
Loss: 0.772 | Acc: 80.430% (25789/32064)
Loss: 0.771 | Acc: 80.436% (30939/38464)
Loss: 0.774 | Acc: 80.285% (36019/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1180, Accuracy: 6799/10000 (67.99%)

Epoch: 159
Loss: 0.863 | Acc: 81.250% (52/64)
Loss: 0.753 | Acc: 81.204% (5249/6464)
Loss: 0.751 | Acc: 81.203% (10446/12864)
Loss: 0.753 | Acc: 81.120% (15627/19264)
Loss: 0.753 | Acc: 80.969% (20780/25664)
Loss: 0.755 | Acc: 80.885% (25935/32064)
Loss: 0.760 | Acc: 80.808% (31082/38464)
Loss: 0.765 | Acc: 80.628% (36173/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4682, Accuracy: 6111/10000 (61.11%)

Epoch: 160
Loss: 0.870 | Acc: 76.562% (49/64)
Loss: 0.766 | Acc: 80.662% (5214/6464)
Loss: 0.778 | Acc: 80.317% (10332/12864)
Loss: 0.763 | Acc: 80.544% (15516/19264)
Loss: 0.762 | Acc: 80.459% (20649/25664)
Loss: 0.759 | Acc: 80.576% (25836/32064)
Loss: 0.767 | Acc: 80.384% (30919/38464)
Loss: 0.765 | Acc: 80.445% (36091/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8613, Accuracy: 4783/10000 (47.83%)

Epoch: 161
Loss: 1.263 | Acc: 68.750% (44/64)
Loss: 0.733 | Acc: 81.064% (5240/6464)
Loss: 0.744 | Acc: 81.025% (10423/12864)
Loss: 0.757 | Acc: 80.757% (15557/19264)
Loss: 0.761 | Acc: 80.541% (20670/25664)
Loss: 0.763 | Acc: 80.495% (25810/32064)
Loss: 0.764 | Acc: 80.486% (30958/38464)
Loss: 0.764 | Acc: 80.497% (36114/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0048, Accuracy: 7192/10000 (71.92%)

Epoch: 162
Loss: 0.647 | Acc: 84.375% (54/64)
Loss: 0.739 | Acc: 81.111% (5243/6464)
Loss: 0.740 | Acc: 81.297% (10458/12864)
Loss: 0.745 | Acc: 81.224% (15647/19264)
Loss: 0.748 | Acc: 81.086% (20810/25664)
Loss: 0.752 | Acc: 80.997% (25971/32064)
Loss: 0.756 | Acc: 80.891% (31114/38464)
Loss: 0.757 | Acc: 80.786% (36244/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9912, Accuracy: 7312/10000 (73.12%)

Epoch: 163
Loss: 0.544 | Acc: 87.500% (56/64)
Loss: 0.721 | Acc: 81.683% (5280/6464)
Loss: 0.733 | Acc: 81.468% (10480/12864)
Loss: 0.738 | Acc: 81.317% (15665/19264)
Loss: 0.744 | Acc: 81.129% (20821/25664)
Loss: 0.749 | Acc: 81.050% (25988/32064)
Loss: 0.749 | Acc: 81.039% (31171/38464)
Loss: 0.751 | Acc: 81.049% (36362/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9231, Accuracy: 7497/10000 (74.97%)

Epoch: 164
Loss: 0.877 | Acc: 78.125% (50/64)
Loss: 0.729 | Acc: 81.513% (5269/6464)
Loss: 0.716 | Acc: 81.763% (10518/12864)
Loss: 0.725 | Acc: 81.691% (15737/19264)
Loss: 0.739 | Acc: 81.308% (20867/25664)
Loss: 0.739 | Acc: 81.241% (26049/32064)
Loss: 0.744 | Acc: 81.154% (31215/38464)
Loss: 0.747 | Acc: 81.087% (36379/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9211, Accuracy: 7466/10000 (74.66%)

Epoch: 165
Loss: 0.750 | Acc: 84.375% (54/64)
Loss: 0.747 | Acc: 80.739% (5219/6464)
Loss: 0.741 | Acc: 81.141% (10438/12864)
Loss: 0.739 | Acc: 81.271% (15656/19264)
Loss: 0.740 | Acc: 81.277% (20859/25664)
Loss: 0.740 | Acc: 81.312% (26072/32064)
Loss: 0.736 | Acc: 81.471% (31337/38464)
Loss: 0.737 | Acc: 81.482% (36556/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1889, Accuracy: 6649/10000 (66.49%)

Epoch: 166
Loss: 1.093 | Acc: 68.750% (44/64)
Loss: 0.723 | Acc: 82.085% (5306/6464)
Loss: 0.719 | Acc: 82.074% (10558/12864)
Loss: 0.714 | Acc: 82.065% (15809/19264)
Loss: 0.723 | Acc: 81.940% (21029/25664)
Loss: 0.726 | Acc: 81.811% (26232/32064)
Loss: 0.732 | Acc: 81.635% (31400/38464)
Loss: 0.730 | Acc: 81.765% (36683/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2360, Accuracy: 6634/10000 (66.34%)

Epoch: 167
Loss: 0.669 | Acc: 82.812% (53/64)
Loss: 0.709 | Acc: 82.194% (5313/6464)
Loss: 0.714 | Acc: 82.299% (10587/12864)
Loss: 0.722 | Acc: 82.153% (15826/19264)
Loss: 0.717 | Acc: 82.220% (21101/25664)
Loss: 0.720 | Acc: 82.120% (26331/32064)
Loss: 0.723 | Acc: 82.035% (31554/38464)
Loss: 0.726 | Acc: 81.916% (36751/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3352, Accuracy: 6568/10000 (65.68%)

Epoch: 168
Loss: 0.549 | Acc: 82.812% (53/64)
Loss: 0.700 | Acc: 82.751% (5349/6464)
Loss: 0.715 | Acc: 82.315% (10589/12864)
Loss: 0.719 | Acc: 82.101% (15816/19264)
Loss: 0.719 | Acc: 82.103% (21071/25664)
Loss: 0.719 | Acc: 82.105% (26326/32064)
Loss: 0.723 | Acc: 82.046% (31558/38464)
Loss: 0.721 | Acc: 82.139% (36851/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0515, Accuracy: 7185/10000 (71.85%)

Epoch: 169
Loss: 0.666 | Acc: 82.812% (53/64)
Loss: 0.697 | Acc: 82.611% (5340/6464)
Loss: 0.703 | Acc: 82.564% (10621/12864)
Loss: 0.709 | Acc: 82.527% (15898/19264)
Loss: 0.711 | Acc: 82.353% (21135/25664)
Loss: 0.716 | Acc: 82.310% (26392/32064)
Loss: 0.716 | Acc: 82.306% (31658/38464)
Loss: 0.715 | Acc: 82.269% (36909/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0561, Accuracy: 7046/10000 (70.46%)

Epoch: 170
Loss: 1.040 | Acc: 73.438% (47/64)
Loss: 0.696 | Acc: 82.720% (5347/6464)
Loss: 0.691 | Acc: 82.882% (10662/12864)
Loss: 0.706 | Acc: 82.548% (15902/19264)
Loss: 0.706 | Acc: 82.614% (21202/25664)
Loss: 0.707 | Acc: 82.463% (26441/32064)
Loss: 0.704 | Acc: 82.610% (31775/38464)
Loss: 0.708 | Acc: 82.498% (37012/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0341, Accuracy: 7209/10000 (72.09%)

Epoch: 171
Loss: 0.930 | Acc: 70.312% (45/64)
Loss: 0.681 | Acc: 82.983% (5364/6464)
Loss: 0.690 | Acc: 82.789% (10650/12864)
Loss: 0.692 | Acc: 82.818% (15954/19264)
Loss: 0.698 | Acc: 82.785% (21246/25664)
Loss: 0.695 | Acc: 82.812% (26553/32064)
Loss: 0.698 | Acc: 82.781% (31841/38464)
Loss: 0.697 | Acc: 82.848% (37169/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0367, Accuracy: 7214/10000 (72.14%)

Epoch: 172
Loss: 1.140 | Acc: 68.750% (44/64)
Loss: 0.679 | Acc: 83.091% (5371/6464)
Loss: 0.674 | Acc: 83.427% (10732/12864)
Loss: 0.672 | Acc: 83.602% (16105/19264)
Loss: 0.673 | Acc: 83.561% (21445/25664)
Loss: 0.674 | Acc: 83.583% (26800/32064)
Loss: 0.677 | Acc: 83.501% (32118/38464)
Loss: 0.680 | Acc: 83.410% (37421/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2229, Accuracy: 6529/10000 (65.29%)

Epoch: 173
Loss: 0.689 | Acc: 84.375% (54/64)
Loss: 0.685 | Acc: 83.137% (5374/6464)
Loss: 0.668 | Acc: 83.792% (10779/12864)
Loss: 0.672 | Acc: 83.669% (16118/19264)
Loss: 0.673 | Acc: 83.658% (21470/25664)
Loss: 0.675 | Acc: 83.508% (26776/32064)
Loss: 0.676 | Acc: 83.481% (32110/38464)
Loss: 0.676 | Acc: 83.526% (37473/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2930, Accuracy: 6318/10000 (63.18%)

Epoch: 174
Loss: 0.902 | Acc: 75.000% (48/64)
Loss: 0.655 | Acc: 84.189% (5442/6464)
Loss: 0.653 | Acc: 84.134% (10823/12864)
Loss: 0.657 | Acc: 84.012% (16184/19264)
Loss: 0.666 | Acc: 83.787% (21503/25664)
Loss: 0.666 | Acc: 83.801% (26870/32064)
Loss: 0.665 | Acc: 83.860% (32256/38464)
Loss: 0.669 | Acc: 83.758% (37577/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8454, Accuracy: 7857/10000 (78.57%)

Epoch: 175
Loss: 0.679 | Acc: 82.812% (53/64)
Loss: 0.630 | Acc: 84.994% (5494/6464)
Loss: 0.630 | Acc: 84.834% (10913/12864)
Loss: 0.636 | Acc: 84.661% (16309/19264)
Loss: 0.646 | Acc: 84.457% (21675/25664)
Loss: 0.640 | Acc: 84.559% (27113/32064)
Loss: 0.646 | Acc: 84.396% (32462/38464)
Loss: 0.651 | Acc: 84.301% (37821/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9042, Accuracy: 7706/10000 (77.06%)

Epoch: 176
Loss: 0.690 | Acc: 85.938% (55/64)
Loss: 0.637 | Acc: 84.793% (5481/6464)
Loss: 0.642 | Acc: 84.678% (10893/12864)
Loss: 0.643 | Acc: 84.562% (16290/19264)
Loss: 0.650 | Acc: 84.305% (21636/25664)
Loss: 0.649 | Acc: 84.359% (27049/32064)
Loss: 0.646 | Acc: 84.411% (32468/38464)
Loss: 0.646 | Acc: 84.413% (37871/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9215, Accuracy: 7585/10000 (75.85%)

Epoch: 177
Loss: 0.598 | Acc: 82.812% (53/64)
Loss: 0.650 | Acc: 84.375% (5454/6464)
Loss: 0.631 | Acc: 84.981% (10932/12864)
Loss: 0.633 | Acc: 84.941% (16363/19264)
Loss: 0.634 | Acc: 84.924% (21795/25664)
Loss: 0.636 | Acc: 84.793% (27188/32064)
Loss: 0.638 | Acc: 84.726% (32589/38464)
Loss: 0.636 | Acc: 84.754% (38024/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9125, Accuracy: 7615/10000 (76.15%)

Epoch: 178
Loss: 0.510 | Acc: 89.062% (57/64)
Loss: 0.593 | Acc: 85.876% (5551/6464)
Loss: 0.608 | Acc: 85.743% (11030/12864)
Loss: 0.608 | Acc: 85.714% (16512/19264)
Loss: 0.610 | Acc: 85.688% (21991/25664)
Loss: 0.616 | Acc: 85.501% (27415/32064)
Loss: 0.617 | Acc: 85.488% (32882/38464)
Loss: 0.618 | Acc: 85.478% (38349/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1372, Accuracy: 6843/10000 (68.43%)

Epoch: 179
Loss: 0.727 | Acc: 78.125% (50/64)
Loss: 0.626 | Acc: 84.947% (5491/6464)
Loss: 0.613 | Acc: 85.510% (11000/12864)
Loss: 0.605 | Acc: 85.719% (16513/19264)
Loss: 0.603 | Acc: 85.719% (21999/25664)
Loss: 0.606 | Acc: 85.682% (27473/32064)
Loss: 0.604 | Acc: 85.779% (32994/38464)
Loss: 0.604 | Acc: 85.777% (38483/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8299, Accuracy: 7933/10000 (79.33%)

Epoch: 180
Loss: 0.587 | Acc: 82.812% (53/64)
Loss: 0.598 | Acc: 85.396% (5520/6464)
Loss: 0.605 | Acc: 85.432% (10990/12864)
Loss: 0.597 | Acc: 85.834% (16535/19264)
Loss: 0.591 | Acc: 86.089% (22094/25664)
Loss: 0.595 | Acc: 85.984% (27570/32064)
Loss: 0.594 | Acc: 85.943% (33057/38464)
Loss: 0.592 | Acc: 86.004% (38585/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8406, Accuracy: 7894/10000 (78.94%)

Epoch: 181
Loss: 0.521 | Acc: 90.625% (58/64)
Loss: 0.561 | Acc: 87.020% (5625/6464)
Loss: 0.547 | Acc: 87.290% (11229/12864)
Loss: 0.557 | Acc: 87.085% (16776/19264)
Loss: 0.564 | Acc: 86.877% (22296/25664)
Loss: 0.565 | Acc: 86.892% (27861/32064)
Loss: 0.571 | Acc: 86.725% (33358/38464)
Loss: 0.573 | Acc: 86.664% (38881/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9113, Accuracy: 7702/10000 (77.02%)

Epoch: 182
Loss: 0.764 | Acc: 81.250% (52/64)
Loss: 0.542 | Acc: 87.237% (5639/6464)
Loss: 0.533 | Acc: 87.547% (11262/12864)
Loss: 0.544 | Acc: 87.318% (16821/19264)
Loss: 0.547 | Acc: 87.200% (22379/25664)
Loss: 0.554 | Acc: 87.076% (27920/32064)
Loss: 0.555 | Acc: 87.097% (33501/38464)
Loss: 0.557 | Acc: 87.050% (39054/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8022, Accuracy: 8126/10000 (81.26%)

Epoch: 183
Loss: 0.543 | Acc: 87.500% (56/64)
Loss: 0.503 | Acc: 88.397% (5714/6464)
Loss: 0.527 | Acc: 87.788% (11293/12864)
Loss: 0.538 | Acc: 87.479% (16852/19264)
Loss: 0.540 | Acc: 87.360% (22420/25664)
Loss: 0.538 | Acc: 87.438% (28036/32064)
Loss: 0.539 | Acc: 87.453% (33638/38464)
Loss: 0.539 | Acc: 87.471% (39243/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8340, Accuracy: 8002/10000 (80.02%)

Epoch: 184
Loss: 0.724 | Acc: 84.375% (54/64)
Loss: 0.498 | Acc: 88.428% (5716/6464)
Loss: 0.509 | Acc: 88.176% (11343/12864)
Loss: 0.514 | Acc: 87.900% (16933/19264)
Loss: 0.513 | Acc: 87.948% (22571/25664)
Loss: 0.514 | Acc: 87.934% (28195/32064)
Loss: 0.514 | Acc: 87.937% (33824/38464)
Loss: 0.515 | Acc: 87.952% (39459/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7660, Accuracy: 8218/10000 (82.18%)

Epoch: 185
Loss: 0.469 | Acc: 85.938% (55/64)
Loss: 0.482 | Acc: 88.877% (5745/6464)
Loss: 0.478 | Acc: 89.000% (11449/12864)
Loss: 0.484 | Acc: 88.813% (17109/19264)
Loss: 0.494 | Acc: 88.568% (22730/25664)
Loss: 0.494 | Acc: 88.539% (28389/32064)
Loss: 0.494 | Acc: 88.587% (34074/38464)
Loss: 0.497 | Acc: 88.541% (39723/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9215, Accuracy: 7796/10000 (77.96%)

Epoch: 186
Loss: 0.286 | Acc: 92.188% (59/64)
Loss: 0.453 | Acc: 89.325% (5774/6464)
Loss: 0.463 | Acc: 89.218% (11477/12864)
Loss: 0.468 | Acc: 88.995% (17144/19264)
Loss: 0.472 | Acc: 88.965% (22832/25664)
Loss: 0.475 | Acc: 88.935% (28516/32064)
Loss: 0.478 | Acc: 88.847% (34174/38464)
Loss: 0.476 | Acc: 88.860% (39866/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8293, Accuracy: 8143/10000 (81.43%)

Epoch: 187
Loss: 0.235 | Acc: 96.875% (62/64)
Loss: 0.431 | Acc: 90.161% (5828/6464)
Loss: 0.435 | Acc: 89.879% (11562/12864)
Loss: 0.445 | Acc: 89.597% (17260/19264)
Loss: 0.447 | Acc: 89.659% (23010/25664)
Loss: 0.446 | Acc: 89.696% (28760/32064)
Loss: 0.449 | Acc: 89.681% (34495/38464)
Loss: 0.449 | Acc: 89.682% (40235/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8603, Accuracy: 8057/10000 (80.57%)

Epoch: 188
Loss: 0.539 | Acc: 85.938% (55/64)
Loss: 0.417 | Acc: 90.362% (5841/6464)
Loss: 0.416 | Acc: 90.337% (11621/12864)
Loss: 0.418 | Acc: 90.345% (17404/19264)
Loss: 0.421 | Acc: 90.224% (23155/25664)
Loss: 0.423 | Acc: 90.145% (28904/32064)
Loss: 0.422 | Acc: 90.201% (34695/38464)
Loss: 0.422 | Acc: 90.168% (40453/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8217, Accuracy: 8216/10000 (82.16%)

Epoch: 189
Loss: 0.239 | Acc: 93.750% (60/64)
Loss: 0.354 | Acc: 91.646% (5924/6464)
Loss: 0.376 | Acc: 90.983% (11704/12864)
Loss: 0.383 | Acc: 90.853% (17502/19264)
Loss: 0.390 | Acc: 90.734% (23286/25664)
Loss: 0.392 | Acc: 90.709% (29085/32064)
Loss: 0.393 | Acc: 90.659% (34871/38464)
Loss: 0.395 | Acc: 90.592% (40643/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8375, Accuracy: 8232/10000 (82.32%)

Epoch: 190
Loss: 0.379 | Acc: 92.188% (59/64)
Loss: 0.351 | Acc: 91.878% (5939/6464)
Loss: 0.347 | Acc: 91.807% (11810/12864)
Loss: 0.353 | Acc: 91.580% (17642/19264)
Loss: 0.355 | Acc: 91.576% (23502/25664)
Loss: 0.354 | Acc: 91.632% (29381/32064)
Loss: 0.356 | Acc: 91.571% (35222/38464)
Loss: 0.357 | Acc: 91.552% (41074/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8315, Accuracy: 8252/10000 (82.52%)

Epoch: 191
Loss: 0.326 | Acc: 92.188% (59/64)
Loss: 0.319 | Acc: 92.481% (5978/6464)
Loss: 0.320 | Acc: 92.351% (11880/12864)
Loss: 0.324 | Acc: 92.094% (17741/19264)
Loss: 0.326 | Acc: 92.016% (23615/25664)
Loss: 0.324 | Acc: 92.088% (29527/32064)
Loss: 0.328 | Acc: 91.995% (35385/38464)
Loss: 0.327 | Acc: 92.038% (41292/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8627, Accuracy: 8211/10000 (82.11%)

Epoch: 192
Loss: 0.196 | Acc: 93.750% (60/64)
Loss: 0.293 | Acc: 92.559% (5983/6464)
Loss: 0.285 | Acc: 92.802% (11938/12864)
Loss: 0.287 | Acc: 92.831% (17883/19264)
Loss: 0.288 | Acc: 92.745% (23802/25664)
Loss: 0.291 | Acc: 92.711% (29727/32064)
Loss: 0.291 | Acc: 92.681% (35649/38464)
Loss: 0.293 | Acc: 92.629% (41557/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9043, Accuracy: 8175/10000 (81.75%)

Epoch: 193
Loss: 0.141 | Acc: 95.312% (61/64)
Loss: 0.273 | Acc: 93.363% (6035/6464)
Loss: 0.263 | Acc: 93.400% (12015/12864)
Loss: 0.260 | Acc: 93.397% (17992/19264)
Loss: 0.263 | Acc: 93.275% (23938/25664)
Loss: 0.261 | Acc: 93.335% (29927/32064)
Loss: 0.259 | Acc: 93.420% (35933/38464)
Loss: 0.258 | Acc: 93.467% (41933/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9099, Accuracy: 8238/10000 (82.38%)

Epoch: 194
Loss: 0.198 | Acc: 95.312% (61/64)
Loss: 0.214 | Acc: 94.524% (6110/6464)
Loss: 0.221 | Acc: 94.255% (12125/12864)
Loss: 0.220 | Acc: 94.279% (18162/19264)
Loss: 0.221 | Acc: 94.183% (24171/25664)
Loss: 0.221 | Acc: 94.177% (30197/32064)
Loss: 0.224 | Acc: 94.127% (36205/38464)
Loss: 0.224 | Acc: 94.140% (42235/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9318, Accuracy: 8237/10000 (82.37%)

Epoch: 195
Loss: 0.273 | Acc: 90.625% (58/64)
Loss: 0.204 | Acc: 94.585% (6114/6464)
Loss: 0.200 | Acc: 94.683% (12180/12864)
Loss: 0.208 | Acc: 94.420% (18189/19264)
Loss: 0.211 | Acc: 94.370% (24219/25664)
Loss: 0.215 | Acc: 94.258% (30223/32064)
Loss: 0.217 | Acc: 94.205% (36235/38464)
Loss: 0.219 | Acc: 94.182% (42254/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8926, Accuracy: 8257/10000 (82.57%)

Epoch: 196
Loss: 0.367 | Acc: 92.188% (59/64)
Loss: 0.213 | Acc: 94.477% (6107/6464)
Loss: 0.214 | Acc: 94.294% (12130/12864)
Loss: 0.222 | Acc: 94.056% (18119/19264)
Loss: 0.222 | Acc: 94.136% (24159/25664)
Loss: 0.219 | Acc: 94.265% (30225/32064)
Loss: 0.221 | Acc: 94.208% (36236/38464)
Loss: 0.222 | Acc: 94.169% (42248/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8826, Accuracy: 8213/10000 (82.13%)

Epoch: 197
Loss: 0.132 | Acc: 95.312% (61/64)
Loss: 0.220 | Acc: 94.384% (6101/6464)
Loss: 0.225 | Acc: 94.216% (12120/12864)
Loss: 0.222 | Acc: 94.295% (18165/19264)
Loss: 0.224 | Acc: 94.241% (24186/25664)
Loss: 0.225 | Acc: 94.159% (30191/32064)
Loss: 0.225 | Acc: 94.187% (36228/38464)
Loss: 0.225 | Acc: 94.109% (42221/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8812, Accuracy: 8221/10000 (82.21%)
torch.Size([100, 10])
Test set: Average loss: 0.8812, Accuracy: 8221/10000 (82.21%)

Epoch: 198
Loss: 0.303 | Acc: 89.062% (57/64)
Loss: 0.233 | Acc: 93.936% (6072/6464)
Loss: 0.226 | Acc: 93.975% (12089/12864)
Loss: 0.224 | Acc: 94.036% (18115/19264)
Loss: 0.224 | Acc: 94.116% (24154/25664)
Loss: 0.223 | Acc: 94.127% (30181/32064)
Loss: 0.224 | Acc: 94.046% (36174/38464)
Loss: 0.224 | Acc: 94.075% (42206/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8751, Accuracy: 8237/10000 (82.37%)
torch.Size([100, 10])
Test set: Average loss: 0.8751, Accuracy: 8237/10000 (82.37%)

Epoch: 199
Loss: 0.065 | Acc: 100.000% (64/64)
Loss: 0.232 | Acc: 94.013% (6077/6464)
Loss: 0.227 | Acc: 94.146% (12111/12864)
Loss: 0.224 | Acc: 94.155% (18138/19264)
Loss: 0.221 | Acc: 94.249% (24188/25664)
Loss: 0.223 | Acc: 94.174% (30196/32064)
Loss: 0.219 | Acc: 94.283% (36265/38464)
Loss: 0.220 | Acc: 94.296% (42305/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8808, Accuracy: 8241/10000 (82.41%)
torch.Size([100, 10])
Test set: Average loss: 0.8808, Accuracy: 8241/10000 (82.41%)
8488
10000
-0.7342717051506042
