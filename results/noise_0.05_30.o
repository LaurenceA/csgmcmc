==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.355 | Acc: 15.625% (10/64)
Loss: 2.902 | Acc: 15.455% (999/6464)
Loss: 2.497 | Acc: 18.664% (2401/12864)
Loss: 2.326 | Acc: 20.972% (4040/19264)
Loss: 2.225 | Acc: 22.947% (5889/25664)
Loss: 2.152 | Acc: 24.657% (7906/32064)
Loss: 2.095 | Acc: 26.212% (10082/38464)
Loss: 2.044 | Acc: 27.552% (12361/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5801, Accuracy: 2744/10000 (27.44%)

Epoch: 1
Loss: 2.135 | Acc: 31.250% (20/64)
Loss: 1.672 | Acc: 39.124% (2529/6464)
Loss: 1.651 | Acc: 40.120% (5161/12864)
Loss: 1.631 | Acc: 40.812% (7862/19264)
Loss: 1.619 | Acc: 41.502% (10651/25664)
Loss: 1.602 | Acc: 42.406% (13597/32064)
Loss: 1.585 | Acc: 43.082% (16571/38464)
Loss: 1.571 | Acc: 43.723% (19616/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6139, Accuracy: 4334/10000 (43.34%)

Epoch: 2
Loss: 1.349 | Acc: 56.250% (36/64)
Loss: 1.423 | Acc: 50.155% (3242/6464)
Loss: 1.427 | Acc: 49.930% (6423/12864)
Loss: 1.408 | Acc: 50.893% (9804/19264)
Loss: 1.390 | Acc: 51.711% (13271/25664)
Loss: 1.375 | Acc: 52.430% (16811/32064)
Loss: 1.366 | Acc: 52.917% (20354/38464)
Loss: 1.358 | Acc: 53.279% (23903/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7901, Accuracy: 4186/10000 (41.86%)

Epoch: 3
Loss: 1.163 | Acc: 60.938% (39/64)
Loss: 1.266 | Acc: 57.395% (3710/6464)
Loss: 1.259 | Acc: 58.155% (7481/12864)
Loss: 1.237 | Acc: 59.058% (11377/19264)
Loss: 1.220 | Acc: 59.535% (15279/25664)
Loss: 1.207 | Acc: 60.055% (19256/32064)
Loss: 1.195 | Acc: 60.418% (23239/38464)
Loss: 1.185 | Acc: 60.931% (27336/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1296, Accuracy: 3788/10000 (37.88%)

Epoch: 4
Loss: 1.403 | Acc: 54.688% (35/64)
Loss: 1.082 | Acc: 65.873% (4258/6464)
Loss: 1.071 | Acc: 65.897% (8477/12864)
Loss: 1.060 | Acc: 66.212% (12755/19264)
Loss: 1.051 | Acc: 66.447% (17053/25664)
Loss: 1.042 | Acc: 66.757% (21405/32064)
Loss: 1.031 | Acc: 67.143% (25826/38464)
Loss: 1.023 | Acc: 67.500% (30283/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2123, Accuracy: 6135/10000 (61.35%)

Epoch: 5
Loss: 1.305 | Acc: 65.625% (42/64)
Loss: 0.924 | Acc: 70.900% (4583/6464)
Loss: 0.932 | Acc: 70.888% (9119/12864)
Loss: 0.931 | Acc: 71.283% (13732/19264)
Loss: 0.929 | Acc: 71.345% (18310/25664)
Loss: 0.921 | Acc: 71.566% (22947/32064)
Loss: 0.920 | Acc: 71.690% (27575/38464)
Loss: 0.917 | Acc: 71.793% (32209/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2024, Accuracy: 6233/10000 (62.33%)

Epoch: 6
Loss: 0.937 | Acc: 76.562% (49/64)
Loss: 0.863 | Acc: 74.319% (4804/6464)
Loss: 0.863 | Acc: 74.285% (9556/12864)
Loss: 0.860 | Acc: 74.159% (14286/19264)
Loss: 0.858 | Acc: 74.190% (19040/25664)
Loss: 0.852 | Acc: 74.230% (23801/32064)
Loss: 0.852 | Acc: 74.280% (28571/38464)
Loss: 0.849 | Acc: 74.505% (33426/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8780, Accuracy: 5061/10000 (50.61%)

Epoch: 7
Loss: 1.065 | Acc: 71.875% (46/64)
Loss: 0.809 | Acc: 75.681% (4892/6464)
Loss: 0.814 | Acc: 75.941% (9769/12864)
Loss: 0.818 | Acc: 76.069% (14654/19264)
Loss: 0.816 | Acc: 76.165% (19547/25664)
Loss: 0.810 | Acc: 76.194% (24431/32064)
Loss: 0.812 | Acc: 76.061% (29256/38464)
Loss: 0.807 | Acc: 76.097% (34140/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1921, Accuracy: 6405/10000 (64.05%)

Epoch: 8
Loss: 1.055 | Acc: 68.750% (44/64)
Loss: 0.791 | Acc: 76.872% (4969/6464)
Loss: 0.782 | Acc: 77.068% (9914/12864)
Loss: 0.774 | Acc: 77.289% (14889/19264)
Loss: 0.774 | Acc: 77.295% (19837/25664)
Loss: 0.773 | Acc: 77.286% (24781/32064)
Loss: 0.776 | Acc: 77.283% (29726/38464)
Loss: 0.772 | Acc: 77.376% (34714/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4844, Accuracy: 5813/10000 (58.13%)

Epoch: 9
Loss: 0.911 | Acc: 71.875% (46/64)
Loss: 0.753 | Acc: 78.388% (5067/6464)
Loss: 0.757 | Acc: 78.211% (10061/12864)
Loss: 0.765 | Acc: 77.782% (14984/19264)
Loss: 0.760 | Acc: 77.782% (19962/25664)
Loss: 0.760 | Acc: 77.960% (24997/32064)
Loss: 0.758 | Acc: 78.021% (30010/38464)
Loss: 0.751 | Acc: 78.167% (35069/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5473, Accuracy: 5564/10000 (55.64%)

Epoch: 10
Loss: 0.841 | Acc: 81.250% (52/64)
Loss: 0.748 | Acc: 77.908% (5036/6464)
Loss: 0.728 | Acc: 78.599% (10111/12864)
Loss: 0.734 | Acc: 78.421% (15107/19264)
Loss: 0.727 | Acc: 78.741% (20208/25664)
Loss: 0.729 | Acc: 78.696% (25233/32064)
Loss: 0.729 | Acc: 78.715% (30277/38464)
Loss: 0.730 | Acc: 78.678% (35298/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8166, Accuracy: 7656/10000 (76.56%)

Epoch: 11
Loss: 0.973 | Acc: 70.312% (45/64)
Loss: 0.697 | Acc: 79.595% (5145/6464)
Loss: 0.715 | Acc: 79.384% (10212/12864)
Loss: 0.710 | Acc: 79.516% (15318/19264)
Loss: 0.712 | Acc: 79.387% (20374/25664)
Loss: 0.710 | Acc: 79.557% (25509/32064)
Loss: 0.709 | Acc: 79.573% (30607/38464)
Loss: 0.711 | Acc: 79.598% (35711/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0796, Accuracy: 6895/10000 (68.95%)

Epoch: 12
Loss: 0.689 | Acc: 79.688% (51/64)
Loss: 0.691 | Acc: 80.121% (5179/6464)
Loss: 0.691 | Acc: 80.519% (10358/12864)
Loss: 0.689 | Acc: 80.508% (15509/19264)
Loss: 0.691 | Acc: 80.369% (20626/25664)
Loss: 0.695 | Acc: 80.346% (25762/32064)
Loss: 0.693 | Acc: 80.405% (30927/38464)
Loss: 0.697 | Acc: 80.361% (36053/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9809, Accuracy: 4265/10000 (42.65%)

Epoch: 13
Loss: 0.906 | Acc: 73.438% (47/64)
Loss: 0.694 | Acc: 80.786% (5222/6464)
Loss: 0.685 | Acc: 80.869% (10403/12864)
Loss: 0.680 | Acc: 80.835% (15572/19264)
Loss: 0.684 | Acc: 80.720% (20716/25664)
Loss: 0.680 | Acc: 80.941% (25953/32064)
Loss: 0.682 | Acc: 80.860% (31102/38464)
Loss: 0.681 | Acc: 80.922% (36305/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3711, Accuracy: 6030/10000 (60.30%)

Epoch: 14
Loss: 0.846 | Acc: 73.438% (47/64)
Loss: 0.689 | Acc: 80.198% (5184/6464)
Loss: 0.688 | Acc: 80.045% (10297/12864)
Loss: 0.676 | Acc: 80.373% (15483/19264)
Loss: 0.671 | Acc: 80.728% (20718/25664)
Loss: 0.667 | Acc: 80.916% (25945/32064)
Loss: 0.665 | Acc: 81.034% (31169/38464)
Loss: 0.667 | Acc: 81.076% (36374/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2518, Accuracy: 6121/10000 (61.21%)

Epoch: 15
Loss: 0.968 | Acc: 68.750% (44/64)
Loss: 0.648 | Acc: 81.730% (5283/6464)
Loss: 0.646 | Acc: 81.817% (10525/12864)
Loss: 0.658 | Acc: 81.546% (15709/19264)
Loss: 0.652 | Acc: 81.718% (20972/25664)
Loss: 0.652 | Acc: 81.843% (26242/32064)
Loss: 0.652 | Acc: 81.801% (31464/38464)
Loss: 0.649 | Acc: 81.832% (36713/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9133, Accuracy: 7410/10000 (74.10%)

Epoch: 16
Loss: 0.851 | Acc: 76.562% (49/64)
Loss: 0.613 | Acc: 82.828% (5354/6464)
Loss: 0.613 | Acc: 82.828% (10655/12864)
Loss: 0.621 | Acc: 82.626% (15917/19264)
Loss: 0.629 | Acc: 82.427% (21154/25664)
Loss: 0.629 | Acc: 82.469% (26443/32064)
Loss: 0.630 | Acc: 82.514% (31738/38464)
Loss: 0.632 | Acc: 82.476% (37002/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2329, Accuracy: 6586/10000 (65.86%)

Epoch: 17
Loss: 0.647 | Acc: 78.125% (50/64)
Loss: 0.583 | Acc: 84.050% (5433/6464)
Loss: 0.615 | Acc: 83.077% (10687/12864)
Loss: 0.621 | Acc: 82.901% (15970/19264)
Loss: 0.620 | Acc: 82.863% (21266/25664)
Loss: 0.621 | Acc: 82.915% (26586/32064)
Loss: 0.622 | Acc: 82.823% (31857/38464)
Loss: 0.621 | Acc: 82.797% (37146/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7208, Accuracy: 8012/10000 (80.12%)

Epoch: 18
Loss: 0.666 | Acc: 81.250% (52/64)
Loss: 0.602 | Acc: 83.338% (5387/6464)
Loss: 0.595 | Acc: 83.396% (10728/12864)
Loss: 0.600 | Acc: 83.451% (16076/19264)
Loss: 0.602 | Acc: 83.405% (21405/25664)
Loss: 0.608 | Acc: 83.252% (26694/32064)
Loss: 0.608 | Acc: 83.223% (32011/38464)
Loss: 0.609 | Acc: 83.154% (37306/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8554, Accuracy: 7557/10000 (75.57%)

Epoch: 19
Loss: 0.624 | Acc: 81.250% (52/64)
Loss: 0.583 | Acc: 84.004% (5430/6464)
Loss: 0.581 | Acc: 84.282% (10842/12864)
Loss: 0.576 | Acc: 84.308% (16241/19264)
Loss: 0.581 | Acc: 84.141% (21594/25664)
Loss: 0.588 | Acc: 84.069% (26956/32064)
Loss: 0.592 | Acc: 83.998% (32309/38464)
Loss: 0.593 | Acc: 83.914% (37647/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6148, Accuracy: 5544/10000 (55.44%)

Epoch: 20
Loss: 0.561 | Acc: 84.375% (54/64)
Loss: 0.576 | Acc: 84.282% (5448/6464)
Loss: 0.580 | Acc: 84.251% (10838/12864)
Loss: 0.582 | Acc: 84.110% (16203/19264)
Loss: 0.581 | Acc: 84.165% (21600/25664)
Loss: 0.578 | Acc: 84.225% (27006/32064)
Loss: 0.580 | Acc: 84.281% (32418/38464)
Loss: 0.581 | Acc: 84.286% (37814/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1599, Accuracy: 4848/10000 (48.48%)

Epoch: 21
Loss: 0.579 | Acc: 79.688% (51/64)
Loss: 0.582 | Acc: 83.911% (5424/6464)
Loss: 0.579 | Acc: 84.150% (10825/12864)
Loss: 0.573 | Acc: 84.370% (16253/19264)
Loss: 0.575 | Acc: 84.379% (21655/25664)
Loss: 0.574 | Acc: 84.522% (27101/32064)
Loss: 0.573 | Acc: 84.531% (32514/38464)
Loss: 0.570 | Acc: 84.640% (37973/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0303, Accuracy: 7047/10000 (70.47%)

Epoch: 22
Loss: 0.516 | Acc: 82.812% (53/64)
Loss: 0.546 | Acc: 85.241% (5510/6464)
Loss: 0.559 | Acc: 84.950% (10928/12864)
Loss: 0.554 | Acc: 85.039% (16382/19264)
Loss: 0.561 | Acc: 84.846% (21775/25664)
Loss: 0.558 | Acc: 84.964% (27243/32064)
Loss: 0.558 | Acc: 84.981% (32687/38464)
Loss: 0.556 | Acc: 85.055% (38159/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1525, Accuracy: 6670/10000 (66.70%)

Epoch: 23
Loss: 0.564 | Acc: 82.812% (53/64)
Loss: 0.507 | Acc: 86.541% (5594/6464)
Loss: 0.532 | Acc: 85.720% (11027/12864)
Loss: 0.535 | Acc: 85.610% (16492/19264)
Loss: 0.537 | Acc: 85.552% (21956/25664)
Loss: 0.542 | Acc: 85.451% (27399/32064)
Loss: 0.541 | Acc: 85.576% (32916/38464)
Loss: 0.542 | Acc: 85.556% (38384/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9119, Accuracy: 7348/10000 (73.48%)

Epoch: 24
Loss: 0.743 | Acc: 81.250% (52/64)
Loss: 0.525 | Acc: 85.999% (5559/6464)
Loss: 0.530 | Acc: 85.875% (11047/12864)
Loss: 0.533 | Acc: 85.958% (16559/19264)
Loss: 0.536 | Acc: 85.969% (22063/25664)
Loss: 0.535 | Acc: 85.941% (27556/32064)
Loss: 0.535 | Acc: 85.945% (33058/38464)
Loss: 0.536 | Acc: 85.920% (38547/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1756, Accuracy: 6712/10000 (67.12%)

Epoch: 25
Loss: 0.693 | Acc: 79.688% (51/64)
Loss: 0.510 | Acc: 86.433% (5587/6464)
Loss: 0.521 | Acc: 86.171% (11085/12864)
Loss: 0.520 | Acc: 86.270% (16619/19264)
Loss: 0.520 | Acc: 86.296% (22147/25664)
Loss: 0.516 | Acc: 86.396% (27702/32064)
Loss: 0.519 | Acc: 86.317% (33201/38464)
Loss: 0.521 | Acc: 86.247% (38694/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0820, Accuracy: 6893/10000 (68.93%)

Epoch: 26
Loss: 0.377 | Acc: 90.625% (58/64)
Loss: 0.503 | Acc: 86.912% (5618/6464)
Loss: 0.504 | Acc: 87.166% (11213/12864)
Loss: 0.497 | Acc: 87.349% (16827/19264)
Loss: 0.506 | Acc: 87.036% (22337/25664)
Loss: 0.507 | Acc: 86.998% (27895/32064)
Loss: 0.504 | Acc: 87.066% (33489/38464)
Loss: 0.502 | Acc: 87.134% (39092/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7471, Accuracy: 7944/10000 (79.44%)

Epoch: 27
Loss: 0.442 | Acc: 82.812% (53/64)
Loss: 0.499 | Acc: 86.989% (5623/6464)
Loss: 0.487 | Acc: 87.484% (11254/12864)
Loss: 0.487 | Acc: 87.458% (16848/19264)
Loss: 0.489 | Acc: 87.305% (22406/25664)
Loss: 0.488 | Acc: 87.282% (27986/32064)
Loss: 0.492 | Acc: 87.235% (33554/38464)
Loss: 0.493 | Acc: 87.226% (39133/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7945, Accuracy: 7697/10000 (76.97%)

Epoch: 28
Loss: 0.602 | Acc: 82.812% (53/64)
Loss: 0.461 | Acc: 88.088% (5694/6464)
Loss: 0.478 | Acc: 87.764% (11290/12864)
Loss: 0.473 | Acc: 87.936% (16940/19264)
Loss: 0.479 | Acc: 87.742% (22518/25664)
Loss: 0.478 | Acc: 87.856% (28170/32064)
Loss: 0.481 | Acc: 87.729% (33744/38464)
Loss: 0.480 | Acc: 87.817% (39398/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1425, Accuracy: 6922/10000 (69.22%)

Epoch: 29
Loss: 0.359 | Acc: 89.062% (57/64)
Loss: 0.469 | Acc: 88.134% (5697/6464)
Loss: 0.461 | Acc: 88.565% (11393/12864)
Loss: 0.453 | Acc: 88.715% (17090/19264)
Loss: 0.455 | Acc: 88.673% (22757/25664)
Loss: 0.456 | Acc: 88.535% (28388/32064)
Loss: 0.460 | Acc: 88.423% (34011/38464)
Loss: 0.461 | Acc: 88.416% (39667/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6782, Accuracy: 8175/10000 (81.75%)

Epoch: 30
Loss: 0.502 | Acc: 85.938% (55/64)
Loss: 0.436 | Acc: 89.217% (5767/6464)
Loss: 0.437 | Acc: 89.164% (11470/12864)
Loss: 0.437 | Acc: 89.182% (17180/19264)
Loss: 0.439 | Acc: 89.027% (22848/25664)
Loss: 0.447 | Acc: 88.885% (28500/32064)
Loss: 0.448 | Acc: 88.878% (34186/38464)
Loss: 0.450 | Acc: 88.822% (39849/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6526, Accuracy: 8241/10000 (82.41%)

Epoch: 31
Loss: 0.439 | Acc: 89.062% (57/64)
Loss: 0.431 | Acc: 89.542% (5788/6464)
Loss: 0.432 | Acc: 89.389% (11499/12864)
Loss: 0.432 | Acc: 89.306% (17204/19264)
Loss: 0.431 | Acc: 89.250% (22905/25664)
Loss: 0.434 | Acc: 89.209% (28604/32064)
Loss: 0.430 | Acc: 89.304% (34350/38464)
Loss: 0.433 | Acc: 89.181% (40010/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6425, Accuracy: 8323/10000 (83.23%)

Epoch: 32
Loss: 0.623 | Acc: 85.938% (55/64)
Loss: 0.407 | Acc: 89.991% (5817/6464)
Loss: 0.419 | Acc: 89.599% (11526/12864)
Loss: 0.415 | Acc: 89.691% (17278/19264)
Loss: 0.411 | Acc: 89.892% (23070/25664)
Loss: 0.409 | Acc: 89.898% (28825/32064)
Loss: 0.412 | Acc: 89.796% (34539/38464)
Loss: 0.412 | Acc: 89.807% (40291/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6507, Accuracy: 8281/10000 (82.81%)

Epoch: 33
Loss: 0.360 | Acc: 92.188% (59/64)
Loss: 0.369 | Acc: 91.027% (5884/6464)
Loss: 0.401 | Acc: 90.197% (11603/12864)
Loss: 0.404 | Acc: 90.127% (17362/19264)
Loss: 0.404 | Acc: 90.056% (23112/25664)
Loss: 0.398 | Acc: 90.207% (28924/32064)
Loss: 0.399 | Acc: 90.165% (34681/38464)
Loss: 0.398 | Acc: 90.219% (40476/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7506, Accuracy: 8026/10000 (80.26%)

Epoch: 34
Loss: 0.494 | Acc: 87.500% (56/64)
Loss: 0.382 | Acc: 90.764% (5867/6464)
Loss: 0.375 | Acc: 91.091% (11718/12864)
Loss: 0.370 | Acc: 91.284% (17585/19264)
Loss: 0.370 | Acc: 91.225% (23412/25664)
Loss: 0.375 | Acc: 91.062% (29198/32064)
Loss: 0.377 | Acc: 91.062% (35026/38464)
Loss: 0.378 | Acc: 91.015% (40833/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5830, Accuracy: 8554/10000 (85.54%)

Epoch: 35
Loss: 0.295 | Acc: 95.312% (61/64)
Loss: 0.330 | Acc: 91.955% (5944/6464)
Loss: 0.348 | Acc: 91.783% (11807/12864)
Loss: 0.349 | Acc: 91.819% (17688/19264)
Loss: 0.347 | Acc: 91.864% (23576/25664)
Loss: 0.349 | Acc: 91.829% (29444/32064)
Loss: 0.354 | Acc: 91.652% (35253/38464)
Loss: 0.356 | Acc: 91.592% (41092/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5695, Accuracy: 8603/10000 (86.03%)

Epoch: 36
Loss: 0.298 | Acc: 90.625% (58/64)
Loss: 0.340 | Acc: 91.770% (5932/6464)
Loss: 0.337 | Acc: 92.040% (11840/12864)
Loss: 0.336 | Acc: 92.110% (17744/19264)
Loss: 0.339 | Acc: 91.903% (23586/25664)
Loss: 0.341 | Acc: 91.960% (29486/32064)
Loss: 0.339 | Acc: 92.006% (35389/38464)
Loss: 0.340 | Acc: 92.016% (41282/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5702, Accuracy: 8600/10000 (86.00%)

Epoch: 37
Loss: 0.282 | Acc: 93.750% (60/64)
Loss: 0.305 | Acc: 92.915% (6006/6464)
Loss: 0.306 | Acc: 92.887% (11949/12864)
Loss: 0.308 | Acc: 92.878% (17892/19264)
Loss: 0.304 | Acc: 92.904% (23843/25664)
Loss: 0.313 | Acc: 92.680% (29717/32064)
Loss: 0.318 | Acc: 92.564% (35604/38464)
Loss: 0.322 | Acc: 92.493% (41496/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6833, Accuracy: 8321/10000 (83.21%)

Epoch: 38
Loss: 0.619 | Acc: 85.938% (55/64)
Loss: 0.302 | Acc: 92.806% (5999/6464)
Loss: 0.298 | Acc: 93.128% (11980/12864)
Loss: 0.296 | Acc: 93.091% (17933/19264)
Loss: 0.296 | Acc: 93.119% (23898/25664)
Loss: 0.299 | Acc: 93.026% (29828/32064)
Loss: 0.300 | Acc: 93.030% (35783/38464)
Loss: 0.299 | Acc: 93.068% (41754/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5637, Accuracy: 8694/10000 (86.94%)

Epoch: 39
Loss: 0.170 | Acc: 95.312% (61/64)
Loss: 0.264 | Acc: 93.781% (6062/6464)
Loss: 0.261 | Acc: 94.014% (12094/12864)
Loss: 0.262 | Acc: 93.952% (18099/19264)
Loss: 0.263 | Acc: 93.921% (24104/25664)
Loss: 0.267 | Acc: 93.806% (30078/32064)
Loss: 0.266 | Acc: 93.828% (36090/38464)
Loss: 0.269 | Acc: 93.737% (42054/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6702, Accuracy: 8388/10000 (83.88%)

Epoch: 40
Loss: 0.168 | Acc: 95.312% (61/64)
Loss: 0.245 | Acc: 93.998% (6076/6464)
Loss: 0.241 | Acc: 94.185% (12116/12864)
Loss: 0.245 | Acc: 94.103% (18128/19264)
Loss: 0.251 | Acc: 94.054% (24138/25664)
Loss: 0.247 | Acc: 94.218% (30210/32064)
Loss: 0.247 | Acc: 94.213% (36238/38464)
Loss: 0.247 | Acc: 94.196% (42260/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5826, Accuracy: 8709/10000 (87.09%)

Epoch: 41
Loss: 0.292 | Acc: 92.188% (59/64)
Loss: 0.225 | Acc: 94.740% (6124/6464)
Loss: 0.225 | Acc: 94.846% (12201/12864)
Loss: 0.223 | Acc: 94.851% (18272/19264)
Loss: 0.226 | Acc: 94.790% (24327/25664)
Loss: 0.224 | Acc: 94.826% (30405/32064)
Loss: 0.224 | Acc: 94.803% (36465/38464)
Loss: 0.224 | Acc: 94.809% (42535/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6026, Accuracy: 8714/10000 (87.14%)

Epoch: 42
Loss: 0.114 | Acc: 98.438% (63/64)
Loss: 0.203 | Acc: 95.127% (6149/6464)
Loss: 0.206 | Acc: 95.149% (12240/12864)
Loss: 0.208 | Acc: 95.043% (18309/19264)
Loss: 0.204 | Acc: 95.161% (24422/25664)
Loss: 0.203 | Acc: 95.216% (30530/32064)
Loss: 0.205 | Acc: 95.172% (36607/38464)
Loss: 0.203 | Acc: 95.239% (42728/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5860, Accuracy: 8783/10000 (87.83%)

Epoch: 43
Loss: 0.140 | Acc: 96.875% (62/64)
Loss: 0.173 | Acc: 95.761% (6190/6464)
Loss: 0.175 | Acc: 95.763% (12319/12864)
Loss: 0.177 | Acc: 95.774% (18450/19264)
Loss: 0.178 | Acc: 95.764% (24577/25664)
Loss: 0.177 | Acc: 95.836% (30729/32064)
Loss: 0.180 | Acc: 95.754% (36831/38464)
Loss: 0.177 | Acc: 95.830% (42993/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6042, Accuracy: 8734/10000 (87.34%)

Epoch: 44
Loss: 0.160 | Acc: 96.875% (62/64)
Loss: 0.153 | Acc: 96.380% (6230/6464)
Loss: 0.161 | Acc: 96.183% (12373/12864)
Loss: 0.157 | Acc: 96.268% (18545/19264)
Loss: 0.159 | Acc: 96.232% (24697/25664)
Loss: 0.160 | Acc: 96.226% (30854/32064)
Loss: 0.160 | Acc: 96.217% (37009/38464)
Loss: 0.157 | Acc: 96.278% (43194/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6007, Accuracy: 8798/10000 (87.98%)

Epoch: 45
Loss: 0.095 | Acc: 98.438% (63/64)
Loss: 0.129 | Acc: 96.751% (6254/6464)
Loss: 0.140 | Acc: 96.618% (12429/12864)
Loss: 0.138 | Acc: 96.652% (18619/19264)
Loss: 0.142 | Acc: 96.544% (24777/25664)
Loss: 0.141 | Acc: 96.591% (30971/32064)
Loss: 0.142 | Acc: 96.558% (37140/38464)
Loss: 0.144 | Acc: 96.536% (43310/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5913, Accuracy: 8782/10000 (87.82%)

Epoch: 46
Loss: 0.119 | Acc: 98.438% (63/64)
Loss: 0.145 | Acc: 96.473% (6236/6464)
Loss: 0.143 | Acc: 96.533% (12418/12864)
Loss: 0.139 | Acc: 96.652% (18619/19264)
Loss: 0.137 | Acc: 96.633% (24800/25664)
Loss: 0.136 | Acc: 96.719% (31012/32064)
Loss: 0.135 | Acc: 96.716% (37201/38464)
Loss: 0.135 | Acc: 96.708% (43387/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5874, Accuracy: 8796/10000 (87.96%)

Epoch: 47
Loss: 0.029 | Acc: 100.000% (64/64)
Loss: 0.132 | Acc: 96.689% (6250/6464)
Loss: 0.131 | Acc: 96.743% (12445/12864)
Loss: 0.132 | Acc: 96.756% (18639/19264)
Loss: 0.129 | Acc: 96.836% (24852/25664)
Loss: 0.131 | Acc: 96.794% (31036/32064)
Loss: 0.131 | Acc: 96.787% (37228/38464)
Loss: 0.131 | Acc: 96.815% (43435/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5817, Accuracy: 8779/10000 (87.79%)
torch.Size([100, 10])
Test set: Average loss: 0.5817, Accuracy: 8779/10000 (87.79%)

Epoch: 48
Loss: 0.069 | Acc: 98.438% (63/64)
Loss: 0.127 | Acc: 96.983% (6269/6464)
Loss: 0.125 | Acc: 97.023% (12481/12864)
Loss: 0.128 | Acc: 96.922% (18671/19264)
Loss: 0.129 | Acc: 96.910% (24871/25664)
Loss: 0.129 | Acc: 96.878% (31063/32064)
Loss: 0.130 | Acc: 96.862% (37257/38464)
Loss: 0.129 | Acc: 96.875% (43462/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5803, Accuracy: 8794/10000 (87.94%)
torch.Size([100, 10])
Test set: Average loss: 0.5803, Accuracy: 8794/10000 (87.94%)

Epoch: 49
Loss: 0.160 | Acc: 95.312% (61/64)
Loss: 0.124 | Acc: 96.844% (6260/6464)
Loss: 0.129 | Acc: 96.782% (12450/12864)
Loss: 0.127 | Acc: 96.844% (18656/19264)
Loss: 0.125 | Acc: 96.894% (24867/25664)
Loss: 0.124 | Acc: 96.944% (31084/32064)
Loss: 0.126 | Acc: 96.914% (37277/38464)
Loss: 0.126 | Acc: 96.906% (43476/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5827, Accuracy: 8780/10000 (87.80%)
torch.Size([100, 10])
Test set: Average loss: 0.5827, Accuracy: 8780/10000 (87.80%)

Epoch: 50
Loss: 0.051 | Acc: 98.438% (63/64)
Loss: 1.243 | Acc: 59.886% (3871/6464)
Loss: 1.048 | Acc: 66.993% (8618/12864)
Loss: 0.960 | Acc: 70.203% (13524/19264)
Loss: 0.913 | Acc: 72.233% (18538/25664)
Loss: 0.881 | Acc: 73.512% (23571/32064)
Loss: 0.854 | Acc: 74.501% (28656/38464)
Loss: 0.834 | Acc: 75.261% (33765/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3754, Accuracy: 6174/10000 (61.74%)

Epoch: 51
Loss: 0.678 | Acc: 78.125% (50/64)
Loss: 0.660 | Acc: 81.683% (5280/6464)
Loss: 0.659 | Acc: 81.398% (10471/12864)
Loss: 0.669 | Acc: 81.115% (15626/19264)
Loss: 0.670 | Acc: 81.063% (20804/25664)
Loss: 0.667 | Acc: 81.300% (26068/32064)
Loss: 0.663 | Acc: 81.419% (31317/38464)
Loss: 0.662 | Acc: 81.480% (36555/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0812, Accuracy: 6898/10000 (68.98%)

Epoch: 52
Loss: 0.876 | Acc: 78.125% (50/64)
Loss: 0.638 | Acc: 82.085% (5306/6464)
Loss: 0.628 | Acc: 82.579% (10623/12864)
Loss: 0.627 | Acc: 82.584% (15909/19264)
Loss: 0.632 | Acc: 82.450% (21160/25664)
Loss: 0.632 | Acc: 82.479% (26446/32064)
Loss: 0.632 | Acc: 82.459% (31717/38464)
Loss: 0.635 | Acc: 82.353% (36947/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1538, Accuracy: 6674/10000 (66.74%)

Epoch: 53
Loss: 0.900 | Acc: 70.312% (45/64)
Loss: 0.598 | Acc: 83.292% (5384/6464)
Loss: 0.601 | Acc: 83.512% (10743/12864)
Loss: 0.609 | Acc: 83.274% (16042/19264)
Loss: 0.614 | Acc: 83.159% (21342/25664)
Loss: 0.618 | Acc: 83.090% (26642/32064)
Loss: 0.618 | Acc: 83.145% (31981/38464)
Loss: 0.618 | Acc: 83.107% (37285/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9041, Accuracy: 7464/10000 (74.64%)

Epoch: 54
Loss: 0.709 | Acc: 82.812% (53/64)
Loss: 0.588 | Acc: 83.509% (5398/6464)
Loss: 0.594 | Acc: 83.629% (10758/12864)
Loss: 0.595 | Acc: 83.451% (16076/19264)
Loss: 0.602 | Acc: 83.210% (21355/25664)
Loss: 0.610 | Acc: 83.046% (26628/32064)
Loss: 0.614 | Acc: 82.966% (31912/38464)
Loss: 0.617 | Acc: 82.966% (37222/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0443, Accuracy: 7107/10000 (71.07%)

Epoch: 55
Loss: 0.850 | Acc: 75.000% (48/64)
Loss: 0.614 | Acc: 83.308% (5385/6464)
Loss: 0.612 | Acc: 83.551% (10748/12864)
Loss: 0.607 | Acc: 83.643% (16113/19264)
Loss: 0.612 | Acc: 83.463% (21420/25664)
Loss: 0.608 | Acc: 83.533% (26784/32064)
Loss: 0.608 | Acc: 83.436% (32093/38464)
Loss: 0.610 | Acc: 83.412% (37422/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2072, Accuracy: 6616/10000 (66.16%)

Epoch: 56
Loss: 0.440 | Acc: 87.500% (56/64)
Loss: 0.595 | Acc: 84.050% (5433/6464)
Loss: 0.606 | Acc: 83.613% (10756/12864)
Loss: 0.597 | Acc: 83.747% (16133/19264)
Loss: 0.596 | Acc: 83.685% (21477/25664)
Loss: 0.599 | Acc: 83.658% (26824/32064)
Loss: 0.601 | Acc: 83.616% (32162/38464)
Loss: 0.603 | Acc: 83.521% (37471/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9577, Accuracy: 7233/10000 (72.33%)

Epoch: 57
Loss: 0.698 | Acc: 78.125% (50/64)
Loss: 0.601 | Acc: 83.369% (5389/6464)
Loss: 0.596 | Acc: 83.598% (10754/12864)
Loss: 0.596 | Acc: 83.685% (16121/19264)
Loss: 0.597 | Acc: 83.701% (21481/25664)
Loss: 0.596 | Acc: 83.736% (26849/32064)
Loss: 0.600 | Acc: 83.626% (32166/38464)
Loss: 0.599 | Acc: 83.595% (37504/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1482, Accuracy: 6750/10000 (67.50%)

Epoch: 58
Loss: 0.674 | Acc: 79.688% (51/64)
Loss: 0.588 | Acc: 83.957% (5427/6464)
Loss: 0.593 | Acc: 84.297% (10844/12864)
Loss: 0.591 | Acc: 84.271% (16234/19264)
Loss: 0.591 | Acc: 84.235% (21618/25664)
Loss: 0.589 | Acc: 84.210% (27001/32064)
Loss: 0.591 | Acc: 84.073% (32338/38464)
Loss: 0.594 | Acc: 84.036% (37702/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8500, Accuracy: 7657/10000 (76.57%)

Epoch: 59
Loss: 0.360 | Acc: 90.625% (58/64)
Loss: 0.593 | Acc: 84.081% (5435/6464)
Loss: 0.582 | Acc: 84.266% (10840/12864)
Loss: 0.584 | Acc: 84.204% (16221/19264)
Loss: 0.586 | Acc: 84.192% (21607/25664)
Loss: 0.585 | Acc: 84.179% (26991/32064)
Loss: 0.588 | Acc: 84.084% (32342/38464)
Loss: 0.590 | Acc: 84.003% (37687/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7370, Accuracy: 7930/10000 (79.30%)

Epoch: 60
Loss: 0.591 | Acc: 85.938% (55/64)
Loss: 0.567 | Acc: 84.653% (5472/6464)
Loss: 0.569 | Acc: 84.600% (10883/12864)
Loss: 0.585 | Acc: 84.147% (16210/19264)
Loss: 0.586 | Acc: 84.094% (21582/25664)
Loss: 0.582 | Acc: 84.244% (27012/32064)
Loss: 0.582 | Acc: 84.305% (32427/38464)
Loss: 0.583 | Acc: 84.272% (37808/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7230, Accuracy: 7981/10000 (79.81%)

Epoch: 61
Loss: 0.728 | Acc: 82.812% (53/64)
Loss: 0.554 | Acc: 85.458% (5524/6464)
Loss: 0.564 | Acc: 85.199% (10960/12864)
Loss: 0.576 | Acc: 84.749% (16326/19264)
Loss: 0.582 | Acc: 84.488% (21683/25664)
Loss: 0.582 | Acc: 84.425% (27070/32064)
Loss: 0.583 | Acc: 84.354% (32446/38464)
Loss: 0.583 | Acc: 84.328% (37833/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7886, Accuracy: 7733/10000 (77.33%)

Epoch: 62
Loss: 0.560 | Acc: 81.250% (52/64)
Loss: 0.546 | Acc: 85.628% (5535/6464)
Loss: 0.557 | Acc: 85.215% (10962/12864)
Loss: 0.565 | Acc: 85.039% (16382/19264)
Loss: 0.565 | Acc: 84.963% (21805/25664)
Loss: 0.569 | Acc: 84.765% (27179/32064)
Loss: 0.568 | Acc: 84.713% (32584/38464)
Loss: 0.570 | Acc: 84.627% (37967/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7032, Accuracy: 8054/10000 (80.54%)

Epoch: 63
Loss: 0.421 | Acc: 82.812% (53/64)
Loss: 0.555 | Acc: 84.963% (5492/6464)
Loss: 0.565 | Acc: 84.865% (10917/12864)
Loss: 0.565 | Acc: 84.827% (16341/19264)
Loss: 0.562 | Acc: 84.772% (21756/25664)
Loss: 0.561 | Acc: 84.796% (27189/32064)
Loss: 0.565 | Acc: 84.690% (32575/38464)
Loss: 0.565 | Acc: 84.781% (38036/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7884, Accuracy: 7880/10000 (78.80%)

Epoch: 64
Loss: 0.891 | Acc: 76.562% (49/64)
Loss: 0.564 | Acc: 85.149% (5504/6464)
Loss: 0.548 | Acc: 85.378% (10983/12864)
Loss: 0.546 | Acc: 85.335% (16439/19264)
Loss: 0.552 | Acc: 85.154% (21854/25664)
Loss: 0.553 | Acc: 85.170% (27309/32064)
Loss: 0.554 | Acc: 85.142% (32749/38464)
Loss: 0.559 | Acc: 84.963% (38118/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0810, Accuracy: 6889/10000 (68.89%)

Epoch: 65
Loss: 0.503 | Acc: 85.938% (55/64)
Loss: 0.545 | Acc: 85.365% (5518/6464)
Loss: 0.547 | Acc: 85.479% (10996/12864)
Loss: 0.551 | Acc: 85.424% (16456/19264)
Loss: 0.554 | Acc: 85.244% (21877/25664)
Loss: 0.558 | Acc: 85.195% (27317/32064)
Loss: 0.555 | Acc: 85.267% (32797/38464)
Loss: 0.557 | Acc: 85.264% (38253/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8299, Accuracy: 7708/10000 (77.08%)

Epoch: 66
Loss: 0.586 | Acc: 84.375% (54/64)
Loss: 0.523 | Acc: 85.876% (5551/6464)
Loss: 0.540 | Acc: 85.409% (10987/12864)
Loss: 0.545 | Acc: 85.392% (16450/19264)
Loss: 0.552 | Acc: 85.224% (21872/25664)
Loss: 0.545 | Acc: 85.435% (27394/32064)
Loss: 0.545 | Acc: 85.433% (32861/38464)
Loss: 0.544 | Acc: 85.443% (38333/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1178, Accuracy: 6763/10000 (67.63%)

Epoch: 67
Loss: 0.585 | Acc: 81.250% (52/64)
Loss: 0.543 | Acc: 85.690% (5539/6464)
Loss: 0.533 | Acc: 86.046% (11069/12864)
Loss: 0.533 | Acc: 86.109% (16588/19264)
Loss: 0.535 | Acc: 86.058% (22086/25664)
Loss: 0.535 | Acc: 85.953% (27560/32064)
Loss: 0.539 | Acc: 85.766% (32989/38464)
Loss: 0.545 | Acc: 85.625% (38415/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1886, Accuracy: 6771/10000 (67.71%)

Epoch: 68
Loss: 0.528 | Acc: 82.812% (53/64)
Loss: 0.530 | Acc: 85.968% (5557/6464)
Loss: 0.527 | Acc: 86.101% (11076/12864)
Loss: 0.531 | Acc: 86.005% (16568/19264)
Loss: 0.533 | Acc: 85.805% (22021/25664)
Loss: 0.533 | Acc: 85.884% (27538/32064)
Loss: 0.535 | Acc: 85.800% (33002/38464)
Loss: 0.532 | Acc: 85.826% (38505/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7796, Accuracy: 7807/10000 (78.07%)

Epoch: 69
Loss: 0.795 | Acc: 75.000% (48/64)
Loss: 0.508 | Acc: 86.324% (5580/6464)
Loss: 0.515 | Acc: 86.202% (11089/12864)
Loss: 0.524 | Acc: 86.166% (16599/19264)
Loss: 0.522 | Acc: 86.273% (22141/25664)
Loss: 0.524 | Acc: 86.296% (27670/32064)
Loss: 0.521 | Acc: 86.374% (33223/38464)
Loss: 0.521 | Acc: 86.406% (38765/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0915, Accuracy: 6866/10000 (68.66%)

Epoch: 70
Loss: 0.545 | Acc: 87.500% (56/64)
Loss: 0.505 | Acc: 87.113% (5631/6464)
Loss: 0.496 | Acc: 87.104% (11205/12864)
Loss: 0.499 | Acc: 86.929% (16746/19264)
Loss: 0.498 | Acc: 87.060% (22343/25664)
Loss: 0.504 | Acc: 86.914% (27868/32064)
Loss: 0.508 | Acc: 86.707% (33351/38464)
Loss: 0.513 | Acc: 86.628% (38865/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7076, Accuracy: 8064/10000 (80.64%)

Epoch: 71
Loss: 0.704 | Acc: 81.250% (52/64)
Loss: 0.499 | Acc: 86.974% (5622/6464)
Loss: 0.503 | Acc: 86.800% (11166/12864)
Loss: 0.499 | Acc: 86.934% (16747/19264)
Loss: 0.502 | Acc: 86.908% (22304/25664)
Loss: 0.509 | Acc: 86.727% (27808/32064)
Loss: 0.509 | Acc: 86.671% (33337/38464)
Loss: 0.508 | Acc: 86.642% (38871/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2565, Accuracy: 6357/10000 (63.57%)

Epoch: 72
Loss: 0.745 | Acc: 76.562% (49/64)
Loss: 0.498 | Acc: 86.897% (5617/6464)
Loss: 0.506 | Acc: 86.777% (11163/12864)
Loss: 0.506 | Acc: 86.664% (16695/19264)
Loss: 0.500 | Acc: 86.666% (22242/25664)
Loss: 0.500 | Acc: 86.780% (27825/32064)
Loss: 0.498 | Acc: 86.834% (33400/38464)
Loss: 0.501 | Acc: 86.847% (38963/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6995, Accuracy: 8164/10000 (81.64%)

Epoch: 73
Loss: 0.375 | Acc: 89.062% (57/64)
Loss: 0.465 | Acc: 87.995% (5688/6464)
Loss: 0.480 | Acc: 87.694% (11281/12864)
Loss: 0.484 | Acc: 87.500% (16856/19264)
Loss: 0.487 | Acc: 87.477% (22450/25664)
Loss: 0.490 | Acc: 87.335% (28003/32064)
Loss: 0.488 | Acc: 87.360% (33602/38464)
Loss: 0.490 | Acc: 87.368% (39197/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8057, Accuracy: 7750/10000 (77.50%)

Epoch: 74
Loss: 0.451 | Acc: 85.938% (55/64)
Loss: 0.449 | Acc: 88.629% (5729/6464)
Loss: 0.462 | Acc: 88.316% (11361/12864)
Loss: 0.466 | Acc: 88.138% (16979/19264)
Loss: 0.470 | Acc: 88.034% (22593/25664)
Loss: 0.474 | Acc: 88.021% (28223/32064)
Loss: 0.480 | Acc: 87.833% (33784/38464)
Loss: 0.478 | Acc: 87.870% (39422/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7192, Accuracy: 8025/10000 (80.25%)

Epoch: 75
Loss: 0.430 | Acc: 85.938% (55/64)
Loss: 0.430 | Acc: 89.001% (5753/6464)
Loss: 0.448 | Acc: 88.542% (11390/12864)
Loss: 0.453 | Acc: 88.455% (17040/19264)
Loss: 0.454 | Acc: 88.443% (22698/25664)
Loss: 0.460 | Acc: 88.283% (28307/32064)
Loss: 0.464 | Acc: 88.223% (33934/38464)
Loss: 0.462 | Acc: 88.271% (39602/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6139, Accuracy: 8400/10000 (84.00%)

Epoch: 76
Loss: 0.563 | Acc: 89.062% (57/64)
Loss: 0.457 | Acc: 88.521% (5722/6464)
Loss: 0.450 | Acc: 88.627% (11401/12864)
Loss: 0.457 | Acc: 88.528% (17054/19264)
Loss: 0.456 | Acc: 88.521% (22718/25664)
Loss: 0.457 | Acc: 88.445% (28359/32064)
Loss: 0.459 | Acc: 88.366% (33989/38464)
Loss: 0.455 | Acc: 88.458% (39686/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6095, Accuracy: 8433/10000 (84.33%)

Epoch: 77
Loss: 0.719 | Acc: 82.812% (53/64)
Loss: 0.439 | Acc: 88.954% (5750/6464)
Loss: 0.441 | Acc: 89.078% (11459/12864)
Loss: 0.442 | Acc: 88.995% (17144/19264)
Loss: 0.443 | Acc: 88.950% (22828/25664)
Loss: 0.442 | Acc: 89.009% (28540/32064)
Loss: 0.441 | Acc: 89.024% (34242/38464)
Loss: 0.438 | Acc: 89.047% (39950/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6345, Accuracy: 8361/10000 (83.61%)

Epoch: 78
Loss: 0.478 | Acc: 87.500% (56/64)
Loss: 0.414 | Acc: 89.836% (5807/6464)
Loss: 0.406 | Acc: 89.949% (11571/12864)
Loss: 0.420 | Acc: 89.659% (17272/19264)
Loss: 0.427 | Acc: 89.522% (22975/25664)
Loss: 0.432 | Acc: 89.328% (28642/32064)
Loss: 0.431 | Acc: 89.320% (34356/38464)
Loss: 0.429 | Acc: 89.341% (40082/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7659, Accuracy: 7931/10000 (79.31%)

Epoch: 79
Loss: 0.457 | Acc: 90.625% (58/64)
Loss: 0.398 | Acc: 90.563% (5854/6464)
Loss: 0.395 | Acc: 90.337% (11621/12864)
Loss: 0.397 | Acc: 90.329% (17401/19264)
Loss: 0.404 | Acc: 90.220% (23154/25664)
Loss: 0.409 | Acc: 90.101% (28890/32064)
Loss: 0.407 | Acc: 90.149% (34675/38464)
Loss: 0.409 | Acc: 90.048% (40399/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1402, Accuracy: 6946/10000 (69.46%)

Epoch: 80
Loss: 0.815 | Acc: 78.125% (50/64)
Loss: 0.440 | Acc: 89.062% (5757/6464)
Loss: 0.413 | Acc: 89.754% (11546/12864)
Loss: 0.412 | Acc: 89.836% (17306/19264)
Loss: 0.409 | Acc: 89.908% (23074/25664)
Loss: 0.408 | Acc: 90.026% (28866/32064)
Loss: 0.406 | Acc: 90.095% (34654/38464)
Loss: 0.406 | Acc: 90.121% (40432/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7117, Accuracy: 8086/10000 (80.86%)

Epoch: 81
Loss: 0.302 | Acc: 89.062% (57/64)
Loss: 0.373 | Acc: 90.718% (5864/6464)
Loss: 0.389 | Acc: 90.384% (11627/12864)
Loss: 0.395 | Acc: 90.256% (17387/19264)
Loss: 0.393 | Acc: 90.415% (23204/25664)
Loss: 0.389 | Acc: 90.535% (29029/32064)
Loss: 0.393 | Acc: 90.433% (34784/38464)
Loss: 0.392 | Acc: 90.409% (40561/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6841, Accuracy: 8270/10000 (82.70%)

Epoch: 82
Loss: 0.253 | Acc: 90.625% (58/64)
Loss: 0.387 | Acc: 90.501% (5850/6464)
Loss: 0.370 | Acc: 90.913% (11695/12864)
Loss: 0.358 | Acc: 91.295% (17587/19264)
Loss: 0.361 | Acc: 91.322% (23437/25664)
Loss: 0.366 | Acc: 91.180% (29236/32064)
Loss: 0.367 | Acc: 91.197% (35078/38464)
Loss: 0.368 | Acc: 91.222% (40926/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6034, Accuracy: 8491/10000 (84.91%)

Epoch: 83
Loss: 0.449 | Acc: 89.062% (57/64)
Loss: 0.329 | Acc: 92.172% (5958/6464)
Loss: 0.345 | Acc: 91.737% (11801/12864)
Loss: 0.337 | Acc: 91.938% (17711/19264)
Loss: 0.343 | Acc: 91.802% (23560/25664)
Loss: 0.345 | Acc: 91.729% (29412/32064)
Loss: 0.352 | Acc: 91.597% (35232/38464)
Loss: 0.354 | Acc: 91.570% (41082/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6182, Accuracy: 8499/10000 (84.99%)

Epoch: 84
Loss: 0.209 | Acc: 96.875% (62/64)
Loss: 0.334 | Acc: 92.296% (5966/6464)
Loss: 0.335 | Acc: 92.141% (11853/12864)
Loss: 0.348 | Acc: 91.741% (17673/19264)
Loss: 0.345 | Acc: 91.868% (23577/25664)
Loss: 0.341 | Acc: 91.954% (29484/32064)
Loss: 0.341 | Acc: 91.935% (35362/38464)
Loss: 0.340 | Acc: 91.969% (41261/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6457, Accuracy: 8437/10000 (84.37%)

Epoch: 85
Loss: 0.464 | Acc: 90.625% (58/64)
Loss: 0.309 | Acc: 93.069% (6016/6464)
Loss: 0.305 | Acc: 93.035% (11968/12864)
Loss: 0.309 | Acc: 92.899% (17896/19264)
Loss: 0.309 | Acc: 92.865% (23833/25664)
Loss: 0.310 | Acc: 92.883% (29782/32064)
Loss: 0.313 | Acc: 92.824% (35704/38464)
Loss: 0.316 | Acc: 92.740% (41607/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6845, Accuracy: 8298/10000 (82.98%)

Epoch: 86
Loss: 0.281 | Acc: 90.625% (58/64)
Loss: 0.292 | Acc: 93.332% (6033/6464)
Loss: 0.280 | Acc: 93.657% (12048/12864)
Loss: 0.291 | Acc: 93.345% (17982/19264)
Loss: 0.296 | Acc: 93.150% (23906/25664)
Loss: 0.295 | Acc: 93.207% (29886/32064)
Loss: 0.295 | Acc: 93.186% (35843/38464)
Loss: 0.297 | Acc: 93.186% (41807/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6337, Accuracy: 8491/10000 (84.91%)

Epoch: 87
Loss: 0.313 | Acc: 93.750% (60/64)
Loss: 0.307 | Acc: 92.868% (6003/6464)
Loss: 0.282 | Acc: 93.493% (12027/12864)
Loss: 0.278 | Acc: 93.553% (18022/19264)
Loss: 0.278 | Acc: 93.528% (24003/25664)
Loss: 0.279 | Acc: 93.519% (29986/32064)
Loss: 0.281 | Acc: 93.467% (35951/38464)
Loss: 0.279 | Acc: 93.527% (41960/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5831, Accuracy: 8675/10000 (86.75%)

Epoch: 88
Loss: 0.239 | Acc: 93.750% (60/64)
Loss: 0.258 | Acc: 94.090% (6082/6464)
Loss: 0.253 | Acc: 94.185% (12116/12864)
Loss: 0.254 | Acc: 94.202% (18147/19264)
Loss: 0.254 | Acc: 94.179% (24170/25664)
Loss: 0.252 | Acc: 94.271% (30227/32064)
Loss: 0.252 | Acc: 94.270% (36260/38464)
Loss: 0.255 | Acc: 94.160% (42244/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5767, Accuracy: 8710/10000 (87.10%)

Epoch: 89
Loss: 0.219 | Acc: 93.750% (60/64)
Loss: 0.231 | Acc: 94.601% (6115/6464)
Loss: 0.235 | Acc: 94.613% (12171/12864)
Loss: 0.237 | Acc: 94.539% (18212/19264)
Loss: 0.234 | Acc: 94.619% (24283/25664)
Loss: 0.236 | Acc: 94.520% (30307/32064)
Loss: 0.233 | Acc: 94.579% (36379/38464)
Loss: 0.233 | Acc: 94.559% (42423/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5649, Accuracy: 8788/10000 (87.88%)

Epoch: 90
Loss: 0.095 | Acc: 98.438% (63/64)
Loss: 0.206 | Acc: 95.251% (6157/6464)
Loss: 0.205 | Acc: 95.328% (12263/12864)
Loss: 0.207 | Acc: 95.240% (18347/19264)
Loss: 0.207 | Acc: 95.227% (24439/25664)
Loss: 0.210 | Acc: 95.150% (30509/32064)
Loss: 0.209 | Acc: 95.138% (36594/38464)
Loss: 0.209 | Acc: 95.143% (42685/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5819, Accuracy: 8781/10000 (87.81%)

Epoch: 91
Loss: 0.338 | Acc: 90.625% (58/64)
Loss: 0.195 | Acc: 95.715% (6187/6464)
Loss: 0.193 | Acc: 95.538% (12290/12864)
Loss: 0.188 | Acc: 95.676% (18431/19264)
Loss: 0.185 | Acc: 95.749% (24573/25664)
Loss: 0.186 | Acc: 95.646% (30668/32064)
Loss: 0.188 | Acc: 95.604% (36773/38464)
Loss: 0.188 | Acc: 95.569% (42876/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5927, Accuracy: 8750/10000 (87.50%)

Epoch: 92
Loss: 0.289 | Acc: 93.750% (60/64)
Loss: 0.155 | Acc: 96.241% (6221/6464)
Loss: 0.151 | Acc: 96.494% (12413/12864)
Loss: 0.154 | Acc: 96.397% (18570/19264)
Loss: 0.160 | Acc: 96.267% (24706/25664)
Loss: 0.162 | Acc: 96.204% (30847/32064)
Loss: 0.163 | Acc: 96.186% (36997/38464)
Loss: 0.162 | Acc: 96.186% (43153/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6006, Accuracy: 8802/10000 (88.02%)

Epoch: 93
Loss: 0.170 | Acc: 96.875% (62/64)
Loss: 0.143 | Acc: 96.349% (6228/6464)
Loss: 0.143 | Acc: 96.510% (12415/12864)
Loss: 0.140 | Acc: 96.584% (18606/19264)
Loss: 0.142 | Acc: 96.520% (24771/25664)
Loss: 0.141 | Acc: 96.535% (30953/32064)
Loss: 0.140 | Acc: 96.568% (37144/38464)
Loss: 0.141 | Acc: 96.561% (43321/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6091, Accuracy: 8820/10000 (88.20%)

Epoch: 94
Loss: 0.058 | Acc: 98.438% (63/64)
Loss: 0.133 | Acc: 96.860% (6261/6464)
Loss: 0.135 | Acc: 96.758% (12447/12864)
Loss: 0.130 | Acc: 96.828% (18653/19264)
Loss: 0.128 | Acc: 96.883% (24864/25664)
Loss: 0.127 | Acc: 96.894% (31068/32064)
Loss: 0.127 | Acc: 96.940% (37287/38464)
Loss: 0.125 | Acc: 96.966% (43503/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6046, Accuracy: 8830/10000 (88.30%)

Epoch: 95
Loss: 0.034 | Acc: 100.000% (64/64)
Loss: 0.100 | Acc: 97.339% (6292/6464)
Loss: 0.103 | Acc: 97.334% (12521/12864)
Loss: 0.104 | Acc: 97.337% (18751/19264)
Loss: 0.106 | Acc: 97.280% (24966/25664)
Loss: 0.108 | Acc: 97.259% (31185/32064)
Loss: 0.111 | Acc: 97.182% (37380/38464)
Loss: 0.111 | Acc: 97.203% (43609/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6085, Accuracy: 8845/10000 (88.45%)

Epoch: 96
Loss: 0.094 | Acc: 96.875% (62/64)
Loss: 0.103 | Acc: 97.463% (6300/6464)
Loss: 0.104 | Acc: 97.334% (12521/12864)
Loss: 0.109 | Acc: 97.192% (18723/19264)
Loss: 0.109 | Acc: 97.202% (24946/25664)
Loss: 0.107 | Acc: 97.237% (31178/32064)
Loss: 0.107 | Acc: 97.260% (37410/38464)
Loss: 0.107 | Acc: 97.290% (43648/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6073, Accuracy: 8840/10000 (88.40%)

Epoch: 97
Loss: 0.088 | Acc: 96.875% (62/64)
Loss: 0.103 | Acc: 97.308% (6290/6464)
Loss: 0.103 | Acc: 97.310% (12518/12864)
Loss: 0.101 | Acc: 97.415% (18766/19264)
Loss: 0.100 | Acc: 97.463% (25013/25664)
Loss: 0.102 | Acc: 97.424% (31238/32064)
Loss: 0.104 | Acc: 97.400% (37464/38464)
Loss: 0.103 | Acc: 97.412% (43703/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6013, Accuracy: 8823/10000 (88.23%)
torch.Size([100, 10])
Test set: Average loss: 0.6013, Accuracy: 8823/10000 (88.23%)

Epoch: 98
Loss: 0.044 | Acc: 100.000% (64/64)
Loss: 0.103 | Acc: 97.416% (6297/6464)
Loss: 0.100 | Acc: 97.427% (12533/12864)
Loss: 0.097 | Acc: 97.467% (18776/19264)
Loss: 0.098 | Acc: 97.479% (25017/25664)
Loss: 0.099 | Acc: 97.471% (31253/32064)
Loss: 0.100 | Acc: 97.444% (37481/38464)
Loss: 0.100 | Acc: 97.441% (43716/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6034, Accuracy: 8839/10000 (88.39%)
torch.Size([100, 10])
Test set: Average loss: 0.6034, Accuracy: 8839/10000 (88.39%)

Epoch: 99
Loss: 0.033 | Acc: 100.000% (64/64)
Loss: 0.101 | Acc: 97.587% (6308/6464)
Loss: 0.093 | Acc: 97.707% (12569/12864)
Loss: 0.095 | Acc: 97.685% (18818/19264)
Loss: 0.095 | Acc: 97.608% (25050/25664)
Loss: 0.096 | Acc: 97.577% (31287/32064)
Loss: 0.096 | Acc: 97.567% (37528/38464)
Loss: 0.097 | Acc: 97.546% (43763/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6034, Accuracy: 8832/10000 (88.32%)
torch.Size([100, 10])
Test set: Average loss: 0.6034, Accuracy: 8832/10000 (88.32%)

Epoch: 100
Loss: 0.064 | Acc: 98.438% (63/64)
Loss: 1.742 | Acc: 37.129% (2400/6464)
Loss: 1.356 | Acc: 53.584% (6893/12864)
Loss: 1.175 | Acc: 60.969% (11745/19264)
Loss: 1.074 | Acc: 65.185% (16729/25664)
Loss: 1.006 | Acc: 67.814% (21744/32064)
Loss: 0.959 | Acc: 69.759% (26832/38464)
Loss: 0.919 | Acc: 71.318% (31996/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3044, Accuracy: 6253/10000 (62.53%)

Epoch: 101
Loss: 0.787 | Acc: 73.438% (47/64)
Loss: 0.630 | Acc: 81.838% (5290/6464)
Loss: 0.645 | Acc: 81.569% (10493/12864)
Loss: 0.649 | Acc: 81.499% (15700/19264)
Loss: 0.641 | Acc: 81.873% (21012/25664)
Loss: 0.641 | Acc: 81.989% (26289/32064)
Loss: 0.639 | Acc: 82.126% (31589/38464)
Loss: 0.642 | Acc: 82.075% (36822/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0966, Accuracy: 6696/10000 (66.96%)

Epoch: 102
Loss: 0.463 | Acc: 85.938% (55/64)
Loss: 0.581 | Acc: 84.390% (5455/6464)
Loss: 0.596 | Acc: 83.745% (10773/12864)
Loss: 0.600 | Acc: 83.487% (16083/19264)
Loss: 0.601 | Acc: 83.494% (21428/25664)
Loss: 0.603 | Acc: 83.486% (26769/32064)
Loss: 0.607 | Acc: 83.408% (32082/38464)
Loss: 0.606 | Acc: 83.519% (37470/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3199, Accuracy: 6270/10000 (62.70%)

Epoch: 103
Loss: 0.837 | Acc: 67.188% (43/64)
Loss: 0.591 | Acc: 83.803% (5417/6464)
Loss: 0.596 | Acc: 83.714% (10769/12864)
Loss: 0.596 | Acc: 83.814% (16146/19264)
Loss: 0.598 | Acc: 83.892% (21530/25664)
Loss: 0.600 | Acc: 83.814% (26874/32064)
Loss: 0.600 | Acc: 83.754% (32215/38464)
Loss: 0.598 | Acc: 83.769% (37582/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0425, Accuracy: 6917/10000 (69.17%)

Epoch: 104
Loss: 0.602 | Acc: 82.812% (53/64)
Loss: 0.587 | Acc: 83.988% (5429/6464)
Loss: 0.597 | Acc: 83.862% (10788/12864)
Loss: 0.592 | Acc: 84.100% (16201/19264)
Loss: 0.590 | Acc: 84.067% (21575/25664)
Loss: 0.586 | Acc: 84.182% (26992/32064)
Loss: 0.588 | Acc: 84.066% (32335/38464)
Loss: 0.589 | Acc: 84.074% (37719/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0458, Accuracy: 6878/10000 (68.78%)

Epoch: 105
Loss: 0.777 | Acc: 75.000% (48/64)
Loss: 0.571 | Acc: 84.793% (5481/6464)
Loss: 0.575 | Acc: 84.507% (10871/12864)
Loss: 0.579 | Acc: 84.437% (16266/19264)
Loss: 0.576 | Acc: 84.437% (21670/25664)
Loss: 0.583 | Acc: 84.275% (27022/32064)
Loss: 0.587 | Acc: 84.157% (32370/38464)
Loss: 0.588 | Acc: 84.067% (37716/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7376, Accuracy: 5229/10000 (52.29%)

Epoch: 106
Loss: 0.612 | Acc: 87.500% (56/64)
Loss: 0.586 | Acc: 84.174% (5441/6464)
Loss: 0.575 | Acc: 84.577% (10880/12864)
Loss: 0.578 | Acc: 84.417% (16262/19264)
Loss: 0.580 | Acc: 84.348% (21647/25664)
Loss: 0.585 | Acc: 84.210% (27001/32064)
Loss: 0.585 | Acc: 84.302% (32426/38464)
Loss: 0.584 | Acc: 84.246% (37796/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0316, Accuracy: 7151/10000 (71.51%)

Epoch: 107
Loss: 0.652 | Acc: 79.688% (51/64)
Loss: 0.562 | Acc: 85.009% (5495/6464)
Loss: 0.569 | Acc: 84.546% (10876/12864)
Loss: 0.574 | Acc: 84.572% (16292/19264)
Loss: 0.580 | Acc: 84.391% (21658/25664)
Loss: 0.582 | Acc: 84.366% (27051/32064)
Loss: 0.579 | Acc: 84.393% (32461/38464)
Loss: 0.575 | Acc: 84.569% (37941/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8464, Accuracy: 5182/10000 (51.82%)

Epoch: 108
Loss: 1.041 | Acc: 70.312% (45/64)
Loss: 0.571 | Acc: 84.499% (5462/6464)
Loss: 0.571 | Acc: 84.810% (10910/12864)
Loss: 0.575 | Acc: 84.671% (16311/19264)
Loss: 0.576 | Acc: 84.574% (21705/25664)
Loss: 0.571 | Acc: 84.671% (27149/32064)
Loss: 0.577 | Acc: 84.554% (32523/38464)
Loss: 0.579 | Acc: 84.446% (37886/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9203, Accuracy: 4632/10000 (46.32%)

Epoch: 109
Loss: 0.910 | Acc: 73.438% (47/64)
Loss: 0.565 | Acc: 84.623% (5470/6464)
Loss: 0.578 | Acc: 84.468% (10866/12864)
Loss: 0.578 | Acc: 84.406% (16260/19264)
Loss: 0.570 | Acc: 84.659% (21727/25664)
Loss: 0.572 | Acc: 84.640% (27139/32064)
Loss: 0.574 | Acc: 84.638% (32555/38464)
Loss: 0.575 | Acc: 84.587% (37949/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3385, Accuracy: 6008/10000 (60.08%)

Epoch: 110
Loss: 0.685 | Acc: 79.688% (51/64)
Loss: 0.574 | Acc: 84.715% (5476/6464)
Loss: 0.563 | Acc: 84.709% (10897/12864)
Loss: 0.563 | Acc: 84.754% (16327/19264)
Loss: 0.563 | Acc: 84.695% (21736/25664)
Loss: 0.567 | Acc: 84.606% (27128/32064)
Loss: 0.568 | Acc: 84.684% (32573/38464)
Loss: 0.569 | Acc: 84.647% (37976/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9383, Accuracy: 7339/10000 (73.39%)

Epoch: 111
Loss: 0.838 | Acc: 78.125% (50/64)
Loss: 0.566 | Acc: 84.963% (5492/6464)
Loss: 0.568 | Acc: 85.044% (10940/12864)
Loss: 0.563 | Acc: 85.029% (16380/19264)
Loss: 0.562 | Acc: 85.018% (21819/25664)
Loss: 0.563 | Acc: 84.958% (27241/32064)
Loss: 0.567 | Acc: 84.760% (32602/38464)
Loss: 0.566 | Acc: 84.803% (38046/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8388, Accuracy: 5504/10000 (55.04%)

Epoch: 112
Loss: 0.892 | Acc: 73.438% (47/64)
Loss: 0.553 | Acc: 85.705% (5540/6464)
Loss: 0.541 | Acc: 85.860% (11045/12864)
Loss: 0.553 | Acc: 85.398% (16451/19264)
Loss: 0.554 | Acc: 85.314% (21895/25664)
Loss: 0.556 | Acc: 85.326% (27359/32064)
Loss: 0.558 | Acc: 85.243% (32788/38464)
Loss: 0.560 | Acc: 85.206% (38227/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8718, Accuracy: 7520/10000 (75.20%)

Epoch: 113
Loss: 0.554 | Acc: 84.375% (54/64)
Loss: 0.550 | Acc: 85.736% (5542/6464)
Loss: 0.549 | Acc: 85.627% (11015/12864)
Loss: 0.543 | Acc: 85.699% (16509/19264)
Loss: 0.542 | Acc: 85.657% (21983/25664)
Loss: 0.541 | Acc: 85.654% (27464/32064)
Loss: 0.545 | Acc: 85.548% (32905/38464)
Loss: 0.549 | Acc: 85.440% (38332/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0897, Accuracy: 6977/10000 (69.77%)

Epoch: 114
Loss: 0.537 | Acc: 82.812% (53/64)
Loss: 0.542 | Acc: 86.139% (5568/6464)
Loss: 0.539 | Acc: 86.070% (11072/12864)
Loss: 0.546 | Acc: 85.642% (16498/19264)
Loss: 0.543 | Acc: 85.715% (21998/25664)
Loss: 0.545 | Acc: 85.704% (27480/32064)
Loss: 0.546 | Acc: 85.641% (32941/38464)
Loss: 0.549 | Acc: 85.594% (38401/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5263, Accuracy: 6163/10000 (61.63%)

Epoch: 115
Loss: 0.968 | Acc: 75.000% (48/64)
Loss: 0.511 | Acc: 86.463% (5589/6464)
Loss: 0.514 | Acc: 86.590% (11139/12864)
Loss: 0.530 | Acc: 85.979% (16563/19264)
Loss: 0.533 | Acc: 85.883% (22041/25664)
Loss: 0.536 | Acc: 85.704% (27480/32064)
Loss: 0.539 | Acc: 85.597% (32924/38464)
Loss: 0.541 | Acc: 85.554% (38383/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0058, Accuracy: 7173/10000 (71.73%)

Epoch: 116
Loss: 0.580 | Acc: 82.812% (53/64)
Loss: 0.520 | Acc: 86.433% (5587/6464)
Loss: 0.530 | Acc: 85.992% (11062/12864)
Loss: 0.536 | Acc: 85.823% (16533/19264)
Loss: 0.532 | Acc: 85.941% (22056/25664)
Loss: 0.538 | Acc: 85.822% (27518/32064)
Loss: 0.535 | Acc: 85.948% (33059/38464)
Loss: 0.536 | Acc: 85.835% (38509/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9225, Accuracy: 7452/10000 (74.52%)

Epoch: 117
Loss: 0.398 | Acc: 89.062% (57/64)
Loss: 0.518 | Acc: 86.989% (5623/6464)
Loss: 0.519 | Acc: 86.629% (11144/12864)
Loss: 0.511 | Acc: 86.784% (16718/19264)
Loss: 0.515 | Acc: 86.658% (22240/25664)
Loss: 0.524 | Acc: 86.415% (27708/32064)
Loss: 0.526 | Acc: 86.270% (33183/38464)
Loss: 0.526 | Acc: 86.301% (38718/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8655, Accuracy: 7563/10000 (75.63%)

Epoch: 118
Loss: 0.623 | Acc: 85.938% (55/64)
Loss: 0.513 | Acc: 86.928% (5619/6464)
Loss: 0.515 | Acc: 86.793% (11165/12864)
Loss: 0.509 | Acc: 86.862% (16733/19264)
Loss: 0.512 | Acc: 86.670% (22243/25664)
Loss: 0.516 | Acc: 86.614% (27772/32064)
Loss: 0.517 | Acc: 86.582% (33303/38464)
Loss: 0.519 | Acc: 86.542% (38826/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3232, Accuracy: 6180/10000 (61.80%)

Epoch: 119
Loss: 0.442 | Acc: 90.625% (58/64)
Loss: 0.520 | Acc: 86.417% (5586/6464)
Loss: 0.508 | Acc: 86.715% (11155/12864)
Loss: 0.508 | Acc: 86.721% (16706/19264)
Loss: 0.508 | Acc: 86.803% (22277/25664)
Loss: 0.512 | Acc: 86.714% (27804/32064)
Loss: 0.510 | Acc: 86.806% (33389/38464)
Loss: 0.514 | Acc: 86.655% (38877/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1014, Accuracy: 7158/10000 (71.58%)

Epoch: 120
Loss: 0.509 | Acc: 85.938% (55/64)
Loss: 0.511 | Acc: 86.897% (5617/6464)
Loss: 0.506 | Acc: 86.894% (11178/12864)
Loss: 0.508 | Acc: 86.820% (16725/19264)
Loss: 0.508 | Acc: 86.993% (22326/25664)
Loss: 0.506 | Acc: 87.095% (27926/32064)
Loss: 0.507 | Acc: 87.024% (33473/38464)
Loss: 0.506 | Acc: 87.043% (39051/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2017, Accuracy: 6629/10000 (66.29%)

Epoch: 121
Loss: 0.521 | Acc: 85.938% (55/64)
Loss: 0.461 | Acc: 88.304% (5708/6464)
Loss: 0.472 | Acc: 87.757% (11289/12864)
Loss: 0.488 | Acc: 87.360% (16829/19264)
Loss: 0.493 | Acc: 87.270% (22397/25664)
Loss: 0.490 | Acc: 87.353% (28009/32064)
Loss: 0.493 | Acc: 87.276% (33570/38464)
Loss: 0.495 | Acc: 87.308% (39170/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8722, Accuracy: 7482/10000 (74.82%)

Epoch: 122
Loss: 0.589 | Acc: 79.688% (51/64)
Loss: 0.475 | Acc: 88.041% (5691/6464)
Loss: 0.462 | Acc: 88.270% (11355/12864)
Loss: 0.469 | Acc: 87.874% (16928/19264)
Loss: 0.475 | Acc: 87.855% (22547/25664)
Loss: 0.482 | Acc: 87.625% (28096/32064)
Loss: 0.479 | Acc: 87.716% (33739/38464)
Loss: 0.483 | Acc: 87.574% (39289/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1130, Accuracy: 6739/10000 (67.39%)

Epoch: 123
Loss: 0.526 | Acc: 82.812% (53/64)
Loss: 0.482 | Acc: 88.057% (5692/6464)
Loss: 0.484 | Acc: 87.795% (11294/12864)
Loss: 0.482 | Acc: 87.822% (16918/19264)
Loss: 0.478 | Acc: 87.921% (22564/25664)
Loss: 0.477 | Acc: 87.862% (28172/32064)
Loss: 0.478 | Acc: 87.825% (33781/38464)
Loss: 0.477 | Acc: 87.899% (39435/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6314, Accuracy: 8353/10000 (83.53%)

Epoch: 124
Loss: 0.456 | Acc: 89.062% (57/64)
Loss: 0.446 | Acc: 88.908% (5747/6464)
Loss: 0.455 | Acc: 88.355% (11366/12864)
Loss: 0.458 | Acc: 88.403% (17030/19264)
Loss: 0.462 | Acc: 88.272% (22654/25664)
Loss: 0.468 | Acc: 88.152% (28265/32064)
Loss: 0.468 | Acc: 88.114% (33892/38464)
Loss: 0.469 | Acc: 88.140% (39543/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6384, Accuracy: 8329/10000 (83.29%)

Epoch: 125
Loss: 0.369 | Acc: 90.625% (58/64)
Loss: 0.415 | Acc: 89.650% (5795/6464)
Loss: 0.429 | Acc: 89.257% (11482/12864)
Loss: 0.444 | Acc: 88.886% (17123/19264)
Loss: 0.443 | Acc: 88.875% (22809/25664)
Loss: 0.450 | Acc: 88.654% (28426/32064)
Loss: 0.450 | Acc: 88.631% (34091/38464)
Loss: 0.454 | Acc: 88.525% (39716/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7940, Accuracy: 7828/10000 (78.28%)

Epoch: 126
Loss: 0.420 | Acc: 89.062% (57/64)
Loss: 0.424 | Acc: 89.341% (5775/6464)
Loss: 0.429 | Acc: 89.265% (11483/12864)
Loss: 0.440 | Acc: 88.928% (17131/19264)
Loss: 0.441 | Acc: 88.969% (22833/25664)
Loss: 0.440 | Acc: 89.041% (28550/32064)
Loss: 0.440 | Acc: 88.990% (34229/38464)
Loss: 0.443 | Acc: 88.920% (39893/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6014, Accuracy: 8450/10000 (84.50%)

Epoch: 127
Loss: 0.602 | Acc: 87.500% (56/64)
Loss: 0.420 | Acc: 89.588% (5791/6464)
Loss: 0.439 | Acc: 89.125% (11465/12864)
Loss: 0.440 | Acc: 89.109% (17166/19264)
Loss: 0.438 | Acc: 89.062% (22857/25664)
Loss: 0.437 | Acc: 89.147% (28584/32064)
Loss: 0.434 | Acc: 89.213% (34315/38464)
Loss: 0.433 | Acc: 89.232% (40033/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7977, Accuracy: 7755/10000 (77.55%)

Epoch: 128
Loss: 0.593 | Acc: 87.500% (56/64)
Loss: 0.405 | Acc: 89.975% (5816/6464)
Loss: 0.415 | Acc: 89.389% (11499/12864)
Loss: 0.412 | Acc: 89.685% (17277/19264)
Loss: 0.416 | Acc: 89.596% (22994/25664)
Loss: 0.420 | Acc: 89.487% (28693/32064)
Loss: 0.421 | Acc: 89.491% (34422/38464)
Loss: 0.421 | Acc: 89.513% (40159/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5898, Accuracy: 8558/10000 (85.58%)

Epoch: 129
Loss: 0.346 | Acc: 93.750% (60/64)
Loss: 0.400 | Acc: 89.960% (5815/6464)
Loss: 0.402 | Acc: 90.065% (11586/12864)
Loss: 0.395 | Acc: 90.205% (17377/19264)
Loss: 0.399 | Acc: 90.087% (23120/25664)
Loss: 0.402 | Acc: 89.967% (28847/32064)
Loss: 0.410 | Acc: 89.832% (34553/38464)
Loss: 0.411 | Acc: 89.816% (40295/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7320, Accuracy: 8084/10000 (80.84%)

Epoch: 130
Loss: 0.436 | Acc: 87.500% (56/64)
Loss: 0.405 | Acc: 89.851% (5808/6464)
Loss: 0.405 | Acc: 90.236% (11608/12864)
Loss: 0.392 | Acc: 90.583% (17450/19264)
Loss: 0.394 | Acc: 90.551% (23239/25664)
Loss: 0.389 | Acc: 90.678% (29075/32064)
Loss: 0.393 | Acc: 90.495% (34808/38464)
Loss: 0.393 | Acc: 90.514% (40608/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6599, Accuracy: 8256/10000 (82.56%)

Epoch: 131
Loss: 0.720 | Acc: 84.375% (54/64)
Loss: 0.349 | Acc: 91.445% (5911/6464)
Loss: 0.366 | Acc: 91.192% (11731/12864)
Loss: 0.365 | Acc: 91.279% (17584/19264)
Loss: 0.369 | Acc: 91.085% (23376/25664)
Loss: 0.372 | Acc: 91.140% (29223/32064)
Loss: 0.372 | Acc: 91.153% (35061/38464)
Loss: 0.377 | Acc: 91.033% (40841/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8303, Accuracy: 7938/10000 (79.38%)

Epoch: 132
Loss: 0.345 | Acc: 90.625% (58/64)
Loss: 0.331 | Acc: 91.986% (5946/6464)
Loss: 0.352 | Acc: 91.550% (11777/12864)
Loss: 0.356 | Acc: 91.362% (17600/19264)
Loss: 0.365 | Acc: 91.171% (23398/25664)
Loss: 0.369 | Acc: 91.093% (29208/32064)
Loss: 0.368 | Acc: 91.140% (35056/38464)
Loss: 0.370 | Acc: 91.053% (40850/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7176, Accuracy: 8145/10000 (81.45%)

Epoch: 133
Loss: 0.375 | Acc: 92.188% (59/64)
Loss: 0.331 | Acc: 91.770% (5932/6464)
Loss: 0.335 | Acc: 92.001% (11835/12864)
Loss: 0.339 | Acc: 91.980% (17719/19264)
Loss: 0.341 | Acc: 91.965% (23602/25664)
Loss: 0.343 | Acc: 91.916% (29472/32064)
Loss: 0.345 | Acc: 91.852% (35330/38464)
Loss: 0.349 | Acc: 91.791% (41181/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5760, Accuracy: 8632/10000 (86.32%)

Epoch: 134
Loss: 0.196 | Acc: 93.750% (60/64)
Loss: 0.319 | Acc: 92.559% (5983/6464)
Loss: 0.320 | Acc: 92.561% (11907/12864)
Loss: 0.321 | Acc: 92.546% (17828/19264)
Loss: 0.325 | Acc: 92.449% (23726/25664)
Loss: 0.329 | Acc: 92.365% (29616/32064)
Loss: 0.331 | Acc: 92.273% (35492/38464)
Loss: 0.325 | Acc: 92.410% (41459/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5634, Accuracy: 8663/10000 (86.63%)

Epoch: 135
Loss: 0.236 | Acc: 95.312% (61/64)
Loss: 0.289 | Acc: 93.147% (6021/6464)
Loss: 0.292 | Acc: 92.957% (11958/12864)
Loss: 0.297 | Acc: 92.790% (17875/19264)
Loss: 0.306 | Acc: 92.643% (23776/25664)
Loss: 0.305 | Acc: 92.708% (29726/32064)
Loss: 0.309 | Acc: 92.661% (35641/38464)
Loss: 0.307 | Acc: 92.725% (41600/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6364, Accuracy: 8462/10000 (84.62%)

Epoch: 136
Loss: 0.230 | Acc: 93.750% (60/64)
Loss: 0.292 | Acc: 92.683% (5991/6464)
Loss: 0.291 | Acc: 92.918% (11953/12864)
Loss: 0.282 | Acc: 93.262% (17966/19264)
Loss: 0.284 | Acc: 93.224% (23925/25664)
Loss: 0.289 | Acc: 93.120% (29858/32064)
Loss: 0.291 | Acc: 93.087% (35805/38464)
Loss: 0.289 | Acc: 93.199% (41813/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9836, Accuracy: 7588/10000 (75.88%)

Epoch: 137
Loss: 0.348 | Acc: 89.062% (57/64)
Loss: 0.279 | Acc: 93.317% (6032/6464)
Loss: 0.271 | Acc: 93.688% (12052/12864)
Loss: 0.267 | Acc: 93.833% (18076/19264)
Loss: 0.267 | Acc: 93.836% (24082/25664)
Loss: 0.269 | Acc: 93.784% (30071/32064)
Loss: 0.272 | Acc: 93.737% (36055/38464)
Loss: 0.270 | Acc: 93.808% (42086/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6870, Accuracy: 8325/10000 (83.25%)

Epoch: 138
Loss: 0.270 | Acc: 95.312% (61/64)
Loss: 0.251 | Acc: 94.214% (6090/6464)
Loss: 0.254 | Acc: 94.123% (12108/12864)
Loss: 0.246 | Acc: 94.368% (18179/19264)
Loss: 0.247 | Acc: 94.366% (24218/25664)
Loss: 0.246 | Acc: 94.299% (30236/32064)
Loss: 0.243 | Acc: 94.356% (36293/38464)
Loss: 0.247 | Acc: 94.274% (42295/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5563, Accuracy: 8781/10000 (87.81%)

Epoch: 139
Loss: 0.367 | Acc: 90.625% (58/64)
Loss: 0.222 | Acc: 94.957% (6138/6464)
Loss: 0.223 | Acc: 94.792% (12194/12864)
Loss: 0.220 | Acc: 94.944% (18290/19264)
Loss: 0.222 | Acc: 94.931% (24363/25664)
Loss: 0.222 | Acc: 94.929% (30438/32064)
Loss: 0.221 | Acc: 94.946% (36520/38464)
Loss: 0.221 | Acc: 94.967% (42606/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6184, Accuracy: 8686/10000 (86.86%)

Epoch: 140
Loss: 0.301 | Acc: 90.625% (58/64)
Loss: 0.197 | Acc: 95.204% (6154/6464)
Loss: 0.195 | Acc: 95.414% (12274/12864)
Loss: 0.197 | Acc: 95.281% (18355/19264)
Loss: 0.199 | Acc: 95.203% (24433/25664)
Loss: 0.198 | Acc: 95.225% (30533/32064)
Loss: 0.199 | Acc: 95.279% (36648/38464)
Loss: 0.200 | Acc: 95.261% (42738/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5990, Accuracy: 8769/10000 (87.69%)

Epoch: 141
Loss: 0.250 | Acc: 93.750% (60/64)
Loss: 0.174 | Acc: 96.086% (6211/6464)
Loss: 0.182 | Acc: 95.748% (12317/12864)
Loss: 0.181 | Acc: 95.764% (18448/19264)
Loss: 0.183 | Acc: 95.722% (24566/25664)
Loss: 0.178 | Acc: 95.852% (30734/32064)
Loss: 0.177 | Acc: 95.817% (36855/38464)
Loss: 0.179 | Acc: 95.789% (42975/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6324, Accuracy: 8685/10000 (86.85%)

Epoch: 142
Loss: 0.066 | Acc: 98.438% (63/64)
Loss: 0.155 | Acc: 96.101% (6212/6464)
Loss: 0.155 | Acc: 96.308% (12389/12864)
Loss: 0.157 | Acc: 96.190% (18530/19264)
Loss: 0.156 | Acc: 96.267% (24706/25664)
Loss: 0.153 | Acc: 96.323% (30885/32064)
Loss: 0.153 | Acc: 96.350% (37060/38464)
Loss: 0.154 | Acc: 96.322% (43214/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5940, Accuracy: 8819/10000 (88.19%)

Epoch: 143
Loss: 0.082 | Acc: 98.438% (63/64)
Loss: 0.143 | Acc: 96.442% (6234/6464)
Loss: 0.141 | Acc: 96.494% (12413/12864)
Loss: 0.142 | Acc: 96.569% (18603/19264)
Loss: 0.145 | Acc: 96.513% (24769/25664)
Loss: 0.143 | Acc: 96.554% (30959/32064)
Loss: 0.138 | Acc: 96.659% (37179/38464)
Loss: 0.139 | Acc: 96.670% (43370/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5856, Accuracy: 8883/10000 (88.83%)

Epoch: 144
Loss: 0.080 | Acc: 98.438% (63/64)
Loss: 0.115 | Acc: 97.138% (6279/6464)
Loss: 0.112 | Acc: 97.233% (12508/12864)
Loss: 0.116 | Acc: 97.166% (18718/19264)
Loss: 0.117 | Acc: 97.109% (24922/25664)
Loss: 0.117 | Acc: 97.134% (31145/32064)
Loss: 0.118 | Acc: 97.112% (37353/38464)
Loss: 0.119 | Acc: 97.069% (43549/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5998, Accuracy: 8895/10000 (88.95%)

Epoch: 145
Loss: 0.021 | Acc: 100.000% (64/64)
Loss: 0.107 | Acc: 97.324% (6291/6464)
Loss: 0.107 | Acc: 97.341% (12522/12864)
Loss: 0.105 | Acc: 97.311% (18746/19264)
Loss: 0.105 | Acc: 97.370% (24989/25664)
Loss: 0.105 | Acc: 97.399% (31230/32064)
Loss: 0.106 | Acc: 97.333% (37438/38464)
Loss: 0.106 | Acc: 97.321% (43662/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5954, Accuracy: 8868/10000 (88.68%)

Epoch: 146
Loss: 0.198 | Acc: 93.750% (60/64)
Loss: 0.104 | Acc: 97.463% (6300/6464)
Loss: 0.100 | Acc: 97.559% (12550/12864)
Loss: 0.106 | Acc: 97.327% (18749/19264)
Loss: 0.104 | Acc: 97.378% (24991/25664)
Loss: 0.105 | Acc: 97.358% (31217/32064)
Loss: 0.105 | Acc: 97.330% (37437/38464)
Loss: 0.105 | Acc: 97.377% (43687/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5890, Accuracy: 8875/10000 (88.75%)

Epoch: 147
Loss: 0.059 | Acc: 98.438% (63/64)
Loss: 0.095 | Acc: 97.633% (6311/6464)
Loss: 0.098 | Acc: 97.567% (12551/12864)
Loss: 0.098 | Acc: 97.545% (18791/19264)
Loss: 0.097 | Acc: 97.615% (25052/25664)
Loss: 0.097 | Acc: 97.555% (31280/32064)
Loss: 0.099 | Acc: 97.509% (37506/38464)
Loss: 0.099 | Acc: 97.515% (43749/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5870, Accuracy: 8874/10000 (88.74%)
torch.Size([100, 10])
Test set: Average loss: 0.5870, Accuracy: 8874/10000 (88.74%)

Epoch: 148
Loss: 0.046 | Acc: 98.438% (63/64)
Loss: 0.091 | Acc: 97.679% (6314/6464)
Loss: 0.097 | Acc: 97.466% (12538/12864)
Loss: 0.097 | Acc: 97.430% (18769/19264)
Loss: 0.096 | Acc: 97.491% (25020/25664)
Loss: 0.095 | Acc: 97.527% (31271/32064)
Loss: 0.094 | Acc: 97.561% (37526/38464)
Loss: 0.094 | Acc: 97.568% (43773/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5875, Accuracy: 8868/10000 (88.68%)
torch.Size([100, 10])
Test set: Average loss: 0.5875, Accuracy: 8868/10000 (88.68%)

Epoch: 149
Loss: 0.243 | Acc: 93.750% (60/64)
Loss: 0.097 | Acc: 97.571% (6307/6464)
Loss: 0.095 | Acc: 97.660% (12563/12864)
Loss: 0.096 | Acc: 97.638% (18809/19264)
Loss: 0.093 | Acc: 97.682% (25069/25664)
Loss: 0.094 | Acc: 97.639% (31307/32064)
Loss: 0.095 | Acc: 97.580% (37533/38464)
Loss: 0.094 | Acc: 97.597% (43786/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5891, Accuracy: 8878/10000 (88.78%)
torch.Size([100, 10])
Test set: Average loss: 0.5891, Accuracy: 8878/10000 (88.78%)

Epoch: 150
Loss: 0.079 | Acc: 98.438% (63/64)
Loss: 1.317 | Acc: 57.024% (3686/6464)
Loss: 1.072 | Acc: 66.177% (8513/12864)
Loss: 0.978 | Acc: 69.892% (13464/19264)
Loss: 0.912 | Acc: 72.284% (18551/25664)
Loss: 0.865 | Acc: 73.968% (23717/32064)
Loss: 0.833 | Acc: 75.156% (28908/38464)
Loss: 0.811 | Acc: 75.943% (34071/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3403, Accuracy: 6025/10000 (60.25%)

Epoch: 151
Loss: 0.520 | Acc: 79.688% (51/64)
Loss: 0.633 | Acc: 82.116% (5308/6464)
Loss: 0.621 | Acc: 82.556% (10620/12864)
Loss: 0.631 | Acc: 82.532% (15899/19264)
Loss: 0.627 | Acc: 82.653% (21212/25664)
Loss: 0.625 | Acc: 82.750% (26533/32064)
Loss: 0.624 | Acc: 82.779% (31840/38464)
Loss: 0.621 | Acc: 82.873% (37180/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0250, Accuracy: 4578/10000 (45.78%)

Epoch: 152
Loss: 1.071 | Acc: 60.938% (39/64)
Loss: 0.605 | Acc: 83.555% (5401/6464)
Loss: 0.581 | Acc: 84.282% (10842/12864)
Loss: 0.590 | Acc: 84.110% (16203/19264)
Loss: 0.596 | Acc: 83.857% (21521/25664)
Loss: 0.598 | Acc: 83.864% (26890/32064)
Loss: 0.602 | Acc: 83.767% (32220/38464)
Loss: 0.601 | Acc: 83.758% (37577/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4528, Accuracy: 5593/10000 (55.93%)

Epoch: 153
Loss: 0.657 | Acc: 79.688% (51/64)
Loss: 0.589 | Acc: 84.298% (5449/6464)
Loss: 0.576 | Acc: 84.461% (10865/12864)
Loss: 0.579 | Acc: 84.427% (16264/19264)
Loss: 0.578 | Acc: 84.546% (21698/25664)
Loss: 0.582 | Acc: 84.372% (27053/32064)
Loss: 0.585 | Acc: 84.219% (32394/38464)
Loss: 0.586 | Acc: 84.206% (37778/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9688, Accuracy: 7189/10000 (71.89%)

Epoch: 154
Loss: 0.728 | Acc: 81.250% (52/64)
Loss: 0.582 | Acc: 84.035% (5432/6464)
Loss: 0.587 | Acc: 84.173% (10828/12864)
Loss: 0.587 | Acc: 84.079% (16197/19264)
Loss: 0.581 | Acc: 84.371% (21653/25664)
Loss: 0.580 | Acc: 84.428% (27071/32064)
Loss: 0.582 | Acc: 84.383% (32457/38464)
Loss: 0.579 | Acc: 84.424% (37876/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8093, Accuracy: 4953/10000 (49.53%)

Epoch: 155
Loss: 1.047 | Acc: 70.312% (45/64)
Loss: 0.605 | Acc: 84.097% (5436/6464)
Loss: 0.595 | Acc: 84.196% (10831/12864)
Loss: 0.581 | Acc: 84.541% (16286/19264)
Loss: 0.577 | Acc: 84.507% (21688/25664)
Loss: 0.572 | Acc: 84.609% (27129/32064)
Loss: 0.574 | Acc: 84.536% (32516/38464)
Loss: 0.579 | Acc: 84.489% (37905/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3342, Accuracy: 6160/10000 (61.60%)

Epoch: 156
Loss: 0.550 | Acc: 87.500% (56/64)
Loss: 0.555 | Acc: 84.793% (5481/6464)
Loss: 0.556 | Acc: 85.005% (10935/12864)
Loss: 0.558 | Acc: 85.117% (16397/19264)
Loss: 0.561 | Acc: 85.034% (21823/25664)
Loss: 0.562 | Acc: 84.939% (27235/32064)
Loss: 0.568 | Acc: 84.744% (32596/38464)
Loss: 0.569 | Acc: 84.732% (38014/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3425, Accuracy: 6182/10000 (61.82%)

Epoch: 157
Loss: 0.613 | Acc: 82.812% (53/64)
Loss: 0.556 | Acc: 84.947% (5491/6464)
Loss: 0.549 | Acc: 85.230% (10964/12864)
Loss: 0.564 | Acc: 84.956% (16366/19264)
Loss: 0.570 | Acc: 84.788% (21760/25664)
Loss: 0.570 | Acc: 84.790% (27187/32064)
Loss: 0.568 | Acc: 84.861% (32641/38464)
Loss: 0.570 | Acc: 84.741% (38018/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1888, Accuracy: 6772/10000 (67.72%)

Epoch: 158
Loss: 0.765 | Acc: 76.562% (49/64)
Loss: 0.565 | Acc: 85.102% (5501/6464)
Loss: 0.551 | Acc: 85.432% (10990/12864)
Loss: 0.556 | Acc: 85.138% (16401/19264)
Loss: 0.559 | Acc: 85.096% (21839/25664)
Loss: 0.567 | Acc: 84.874% (27214/32064)
Loss: 0.566 | Acc: 84.895% (32654/38464)
Loss: 0.568 | Acc: 84.856% (38070/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8645, Accuracy: 7497/10000 (74.97%)

Epoch: 159
Loss: 0.529 | Acc: 85.938% (55/64)
Loss: 0.546 | Acc: 85.458% (5524/6464)
Loss: 0.548 | Acc: 85.510% (11000/12864)
Loss: 0.548 | Acc: 85.522% (16475/19264)
Loss: 0.554 | Acc: 85.353% (21905/25664)
Loss: 0.553 | Acc: 85.379% (27376/32064)
Loss: 0.556 | Acc: 85.254% (32792/38464)
Loss: 0.559 | Acc: 85.144% (38199/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1412, Accuracy: 4387/10000 (43.87%)

Epoch: 160
Loss: 0.659 | Acc: 84.375% (54/64)
Loss: 0.565 | Acc: 85.597% (5533/6464)
Loss: 0.576 | Acc: 85.113% (10949/12864)
Loss: 0.562 | Acc: 85.226% (16418/19264)
Loss: 0.563 | Acc: 85.088% (21837/25664)
Loss: 0.557 | Acc: 85.226% (27327/32064)
Loss: 0.560 | Acc: 85.155% (32754/38464)
Loss: 0.559 | Acc: 85.180% (38215/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9512, Accuracy: 7304/10000 (73.04%)

Epoch: 161
Loss: 0.917 | Acc: 75.000% (48/64)
Loss: 0.531 | Acc: 85.876% (5551/6464)
Loss: 0.531 | Acc: 86.085% (11074/12864)
Loss: 0.541 | Acc: 85.813% (16531/19264)
Loss: 0.546 | Acc: 85.735% (22003/25664)
Loss: 0.554 | Acc: 85.573% (27438/32064)
Loss: 0.556 | Acc: 85.514% (32892/38464)
Loss: 0.557 | Acc: 85.452% (38337/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2268, Accuracy: 4554/10000 (45.54%)

Epoch: 162
Loss: 0.765 | Acc: 81.250% (52/64)
Loss: 0.546 | Acc: 85.241% (5510/6464)
Loss: 0.538 | Acc: 85.751% (11031/12864)
Loss: 0.543 | Acc: 85.662% (16502/19264)
Loss: 0.545 | Acc: 85.595% (21967/25664)
Loss: 0.550 | Acc: 85.470% (27405/32064)
Loss: 0.551 | Acc: 85.428% (32859/38464)
Loss: 0.553 | Acc: 85.356% (38294/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7756, Accuracy: 7919/10000 (79.19%)

Epoch: 163
Loss: 0.598 | Acc: 84.375% (54/64)
Loss: 0.526 | Acc: 86.402% (5585/6464)
Loss: 0.531 | Acc: 86.163% (11084/12864)
Loss: 0.535 | Acc: 85.995% (16566/19264)
Loss: 0.544 | Acc: 85.665% (21985/25664)
Loss: 0.548 | Acc: 85.488% (27411/32064)
Loss: 0.545 | Acc: 85.574% (32915/38464)
Loss: 0.548 | Acc: 85.474% (38347/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0046, Accuracy: 7159/10000 (71.59%)

Epoch: 164
Loss: 0.718 | Acc: 81.250% (52/64)
Loss: 0.537 | Acc: 85.675% (5538/6464)
Loss: 0.520 | Acc: 86.101% (11076/12864)
Loss: 0.526 | Acc: 86.026% (16572/19264)
Loss: 0.538 | Acc: 85.669% (21986/25664)
Loss: 0.535 | Acc: 85.750% (27495/32064)
Loss: 0.538 | Acc: 85.680% (32956/38464)
Loss: 0.540 | Acc: 85.632% (38418/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9107, Accuracy: 7384/10000 (73.84%)

Epoch: 165
Loss: 0.549 | Acc: 87.500% (56/64)
Loss: 0.538 | Acc: 85.999% (5559/6464)
Loss: 0.539 | Acc: 86.101% (11076/12864)
Loss: 0.535 | Acc: 86.259% (16617/19264)
Loss: 0.535 | Acc: 86.195% (22121/25664)
Loss: 0.529 | Acc: 86.340% (27684/32064)
Loss: 0.528 | Acc: 86.348% (33213/38464)
Loss: 0.530 | Acc: 86.227% (38685/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6411, Accuracy: 5663/10000 (56.63%)

Epoch: 166
Loss: 0.919 | Acc: 73.438% (47/64)
Loss: 0.511 | Acc: 86.463% (5589/6464)
Loss: 0.512 | Acc: 86.660% (11148/12864)
Loss: 0.515 | Acc: 86.519% (16667/19264)
Loss: 0.517 | Acc: 86.413% (22177/25664)
Loss: 0.520 | Acc: 86.312% (27675/32064)
Loss: 0.523 | Acc: 86.268% (33182/38464)
Loss: 0.523 | Acc: 86.339% (38735/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9162, Accuracy: 7457/10000 (74.57%)

Epoch: 167
Loss: 0.381 | Acc: 87.500% (56/64)
Loss: 0.497 | Acc: 86.804% (5611/6464)
Loss: 0.497 | Acc: 86.956% (11186/12864)
Loss: 0.508 | Acc: 86.763% (16714/19264)
Loss: 0.506 | Acc: 86.865% (22293/25664)
Loss: 0.512 | Acc: 86.680% (27793/32064)
Loss: 0.518 | Acc: 86.551% (33291/38464)
Loss: 0.519 | Acc: 86.526% (38819/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3340, Accuracy: 6623/10000 (66.23%)

Epoch: 168
Loss: 0.458 | Acc: 82.812% (53/64)
Loss: 0.486 | Acc: 87.098% (5630/6464)
Loss: 0.504 | Acc: 86.684% (11151/12864)
Loss: 0.507 | Acc: 86.654% (16693/19264)
Loss: 0.510 | Acc: 86.674% (22244/25664)
Loss: 0.511 | Acc: 86.683% (27794/32064)
Loss: 0.513 | Acc: 86.712% (33353/38464)
Loss: 0.514 | Acc: 86.727% (38909/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1734, Accuracy: 6799/10000 (67.99%)

Epoch: 169
Loss: 0.730 | Acc: 75.000% (48/64)
Loss: 0.500 | Acc: 86.912% (5618/6464)
Loss: 0.495 | Acc: 87.205% (11218/12864)
Loss: 0.504 | Acc: 86.882% (16737/19264)
Loss: 0.501 | Acc: 86.974% (22321/25664)
Loss: 0.506 | Acc: 86.848% (27847/32064)
Loss: 0.510 | Acc: 86.788% (33382/38464)
Loss: 0.507 | Acc: 86.798% (38941/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9578, Accuracy: 7386/10000 (73.86%)

Epoch: 170
Loss: 0.961 | Acc: 78.125% (50/64)
Loss: 0.492 | Acc: 87.717% (5670/6464)
Loss: 0.497 | Acc: 87.477% (11253/12864)
Loss: 0.499 | Acc: 87.438% (16844/19264)
Loss: 0.501 | Acc: 87.243% (22390/25664)
Loss: 0.501 | Acc: 87.120% (27934/32064)
Loss: 0.499 | Acc: 87.196% (33539/38464)
Loss: 0.501 | Acc: 87.163% (39105/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5684, Accuracy: 5847/10000 (58.47%)

Epoch: 171
Loss: 0.853 | Acc: 76.562% (49/64)
Loss: 0.479 | Acc: 87.670% (5667/6464)
Loss: 0.474 | Acc: 87.749% (11288/12864)
Loss: 0.484 | Acc: 87.505% (16857/19264)
Loss: 0.484 | Acc: 87.543% (22467/25664)
Loss: 0.483 | Acc: 87.553% (28073/32064)
Loss: 0.486 | Acc: 87.508% (33659/38464)
Loss: 0.489 | Acc: 87.455% (39236/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7778, Accuracy: 7824/10000 (78.24%)

Epoch: 172
Loss: 0.981 | Acc: 76.562% (49/64)
Loss: 0.489 | Acc: 87.330% (5645/6464)
Loss: 0.477 | Acc: 87.648% (11275/12864)
Loss: 0.476 | Acc: 87.827% (16919/19264)
Loss: 0.477 | Acc: 87.769% (22525/25664)
Loss: 0.474 | Acc: 87.952% (28201/32064)
Loss: 0.475 | Acc: 87.838% (33786/38464)
Loss: 0.477 | Acc: 87.857% (39416/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0926, Accuracy: 7028/10000 (70.28%)

Epoch: 173
Loss: 0.381 | Acc: 92.188% (59/64)
Loss: 0.455 | Acc: 88.660% (5731/6464)
Loss: 0.459 | Acc: 88.565% (11393/12864)
Loss: 0.465 | Acc: 88.414% (17032/19264)
Loss: 0.464 | Acc: 88.330% (22669/25664)
Loss: 0.464 | Acc: 88.342% (28326/32064)
Loss: 0.468 | Acc: 88.249% (33944/38464)
Loss: 0.468 | Acc: 88.215% (39577/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7836, Accuracy: 5139/10000 (51.39%)

Epoch: 174
Loss: 0.604 | Acc: 84.375% (54/64)
Loss: 0.470 | Acc: 88.041% (5691/6464)
Loss: 0.464 | Acc: 88.347% (11365/12864)
Loss: 0.460 | Acc: 88.398% (17029/19264)
Loss: 0.467 | Acc: 88.233% (22644/25664)
Loss: 0.465 | Acc: 88.242% (28294/32064)
Loss: 0.466 | Acc: 88.202% (33926/38464)
Loss: 0.466 | Acc: 88.189% (39565/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8054, Accuracy: 7735/10000 (77.35%)

Epoch: 175
Loss: 0.354 | Acc: 90.625% (58/64)
Loss: 0.438 | Acc: 89.295% (5772/6464)
Loss: 0.430 | Acc: 89.350% (11494/12864)
Loss: 0.438 | Acc: 89.260% (17195/19264)
Loss: 0.443 | Acc: 89.027% (22848/25664)
Loss: 0.440 | Acc: 89.044% (28551/32064)
Loss: 0.444 | Acc: 89.024% (34242/38464)
Loss: 0.445 | Acc: 89.011% (39934/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7302, Accuracy: 8028/10000 (80.28%)

Epoch: 176
Loss: 0.561 | Acc: 89.062% (57/64)
Loss: 0.431 | Acc: 89.279% (5771/6464)
Loss: 0.436 | Acc: 89.241% (11480/12864)
Loss: 0.436 | Acc: 89.208% (17185/19264)
Loss: 0.442 | Acc: 89.094% (22865/25664)
Loss: 0.440 | Acc: 89.147% (28584/32064)
Loss: 0.437 | Acc: 89.151% (34291/38464)
Loss: 0.439 | Acc: 89.091% (39970/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7768, Accuracy: 7898/10000 (78.98%)

Epoch: 177
Loss: 0.543 | Acc: 84.375% (54/64)
Loss: 0.440 | Acc: 89.016% (5754/6464)
Loss: 0.434 | Acc: 89.373% (11497/12864)
Loss: 0.420 | Acc: 89.768% (17293/19264)
Loss: 0.426 | Acc: 89.577% (22989/25664)
Loss: 0.426 | Acc: 89.596% (28728/32064)
Loss: 0.429 | Acc: 89.512% (34430/38464)
Loss: 0.427 | Acc: 89.573% (40186/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8193, Accuracy: 7691/10000 (76.91%)

Epoch: 178
Loss: 0.308 | Acc: 92.188% (59/64)
Loss: 0.373 | Acc: 90.671% (5861/6464)
Loss: 0.386 | Acc: 90.563% (11650/12864)
Loss: 0.397 | Acc: 90.179% (17372/19264)
Loss: 0.403 | Acc: 89.963% (23088/25664)
Loss: 0.410 | Acc: 89.799% (28793/32064)
Loss: 0.408 | Acc: 89.887% (34574/38464)
Loss: 0.410 | Acc: 89.847% (40309/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7770, Accuracy: 7886/10000 (78.86%)

Epoch: 179
Loss: 0.464 | Acc: 87.500% (56/64)
Loss: 0.414 | Acc: 89.851% (5808/6464)
Loss: 0.404 | Acc: 90.104% (11591/12864)
Loss: 0.397 | Acc: 90.339% (17403/19264)
Loss: 0.400 | Acc: 90.189% (23146/25664)
Loss: 0.401 | Acc: 90.238% (28934/32064)
Loss: 0.402 | Acc: 90.196% (34693/38464)
Loss: 0.400 | Acc: 90.251% (40490/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6268, Accuracy: 8386/10000 (83.86%)

Epoch: 180
Loss: 0.302 | Acc: 89.062% (57/64)
Loss: 0.380 | Acc: 91.275% (5900/6464)
Loss: 0.382 | Acc: 91.060% (11714/12864)
Loss: 0.379 | Acc: 91.108% (17551/19264)
Loss: 0.375 | Acc: 91.135% (23389/25664)
Loss: 0.379 | Acc: 90.965% (29167/32064)
Loss: 0.382 | Acc: 90.791% (34922/38464)
Loss: 0.383 | Acc: 90.768% (40722/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5888, Accuracy: 8533/10000 (85.33%)

Epoch: 181
Loss: 0.408 | Acc: 87.500% (56/64)
Loss: 0.366 | Acc: 90.842% (5872/6464)
Loss: 0.362 | Acc: 91.224% (11735/12864)
Loss: 0.367 | Acc: 91.108% (17551/19264)
Loss: 0.367 | Acc: 91.143% (23391/25664)
Loss: 0.364 | Acc: 91.168% (29232/32064)
Loss: 0.368 | Acc: 91.155% (35062/38464)
Loss: 0.370 | Acc: 91.131% (40885/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6827, Accuracy: 8240/10000 (82.40%)

Epoch: 182
Loss: 0.390 | Acc: 89.062% (57/64)
Loss: 0.368 | Acc: 91.460% (5912/6464)
Loss: 0.350 | Acc: 91.884% (11820/12864)
Loss: 0.353 | Acc: 91.757% (17676/19264)
Loss: 0.352 | Acc: 91.739% (23544/25664)
Loss: 0.355 | Acc: 91.620% (29377/32064)
Loss: 0.355 | Acc: 91.509% (35198/38464)
Loss: 0.355 | Acc: 91.552% (41074/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5630, Accuracy: 8627/10000 (86.27%)

Epoch: 183
Loss: 0.386 | Acc: 92.188% (59/64)
Loss: 0.321 | Acc: 92.698% (5992/6464)
Loss: 0.323 | Acc: 92.537% (11904/12864)
Loss: 0.331 | Acc: 92.369% (17794/19264)
Loss: 0.336 | Acc: 92.160% (23652/25664)
Loss: 0.337 | Acc: 92.078% (29524/32064)
Loss: 0.341 | Acc: 91.925% (35358/38464)
Loss: 0.341 | Acc: 91.931% (41244/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5416, Accuracy: 8729/10000 (87.29%)

Epoch: 184
Loss: 0.384 | Acc: 92.188% (59/64)
Loss: 0.324 | Acc: 92.311% (5967/6464)
Loss: 0.323 | Acc: 92.374% (11883/12864)
Loss: 0.327 | Acc: 92.364% (17793/19264)
Loss: 0.325 | Acc: 92.488% (23736/25664)
Loss: 0.320 | Acc: 92.546% (29674/32064)
Loss: 0.324 | Acc: 92.471% (35568/38464)
Loss: 0.326 | Acc: 92.439% (41472/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5567, Accuracy: 8659/10000 (86.59%)

Epoch: 185
Loss: 0.268 | Acc: 92.188% (59/64)
Loss: 0.281 | Acc: 93.533% (6046/6464)
Loss: 0.288 | Acc: 93.315% (12004/12864)
Loss: 0.286 | Acc: 93.319% (17977/19264)
Loss: 0.299 | Acc: 93.045% (23879/25664)
Loss: 0.301 | Acc: 93.014% (29824/32064)
Loss: 0.304 | Acc: 92.944% (35750/38464)
Loss: 0.304 | Acc: 92.968% (41709/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6634, Accuracy: 8377/10000 (83.77%)

Epoch: 186
Loss: 0.184 | Acc: 95.312% (61/64)
Loss: 0.271 | Acc: 93.796% (6063/6464)
Loss: 0.271 | Acc: 93.750% (12060/12864)
Loss: 0.270 | Acc: 93.719% (18054/19264)
Loss: 0.279 | Acc: 93.610% (24024/25664)
Loss: 0.284 | Acc: 93.541% (29993/32064)
Loss: 0.286 | Acc: 93.487% (35959/38464)
Loss: 0.285 | Acc: 93.516% (41955/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5789, Accuracy: 8660/10000 (86.60%)

Epoch: 187
Loss: 0.195 | Acc: 96.875% (62/64)
Loss: 0.256 | Acc: 94.121% (6084/6464)
Loss: 0.253 | Acc: 94.146% (12111/12864)
Loss: 0.261 | Acc: 93.895% (18088/19264)
Loss: 0.262 | Acc: 93.894% (24097/25664)
Loss: 0.265 | Acc: 93.853% (30093/32064)
Loss: 0.262 | Acc: 93.966% (36143/38464)
Loss: 0.262 | Acc: 93.971% (42159/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5689, Accuracy: 8762/10000 (87.62%)

Epoch: 188
Loss: 0.405 | Acc: 92.188% (59/64)
Loss: 0.249 | Acc: 94.276% (6094/6464)
Loss: 0.247 | Acc: 94.364% (12139/12864)
Loss: 0.244 | Acc: 94.534% (18211/19264)
Loss: 0.244 | Acc: 94.541% (24263/25664)
Loss: 0.245 | Acc: 94.470% (30291/32064)
Loss: 0.243 | Acc: 94.514% (36354/38464)
Loss: 0.242 | Acc: 94.486% (42390/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5531, Accuracy: 8788/10000 (87.88%)

Epoch: 189
Loss: 0.192 | Acc: 96.875% (62/64)
Loss: 0.210 | Acc: 95.142% (6150/6464)
Loss: 0.210 | Acc: 95.211% (12248/12864)
Loss: 0.215 | Acc: 95.074% (18315/19264)
Loss: 0.218 | Acc: 95.005% (24382/25664)
Loss: 0.217 | Acc: 95.010% (30464/32064)
Loss: 0.220 | Acc: 94.936% (36516/38464)
Loss: 0.220 | Acc: 94.896% (42574/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5556, Accuracy: 8842/10000 (88.42%)

Epoch: 190
Loss: 0.276 | Acc: 93.750% (60/64)
Loss: 0.181 | Acc: 95.653% (6183/6464)
Loss: 0.184 | Acc: 95.631% (12302/12864)
Loss: 0.190 | Acc: 95.515% (18400/19264)
Loss: 0.191 | Acc: 95.507% (24511/25664)
Loss: 0.189 | Acc: 95.571% (30644/32064)
Loss: 0.192 | Acc: 95.515% (36739/38464)
Loss: 0.192 | Acc: 95.506% (42848/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6132, Accuracy: 8716/10000 (87.16%)

Epoch: 191
Loss: 0.289 | Acc: 93.750% (60/64)
Loss: 0.167 | Acc: 96.148% (6215/6464)
Loss: 0.169 | Acc: 96.082% (12360/12864)
Loss: 0.167 | Acc: 96.117% (18516/19264)
Loss: 0.170 | Acc: 95.983% (24633/25664)
Loss: 0.171 | Acc: 95.983% (30776/32064)
Loss: 0.172 | Acc: 95.973% (36915/38464)
Loss: 0.173 | Acc: 95.948% (43046/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5831, Accuracy: 8800/10000 (88.00%)

Epoch: 192
Loss: 0.066 | Acc: 98.438% (63/64)
Loss: 0.154 | Acc: 96.241% (6221/6464)
Loss: 0.144 | Acc: 96.541% (12419/12864)
Loss: 0.145 | Acc: 96.543% (18598/19264)
Loss: 0.147 | Acc: 96.474% (24759/25664)
Loss: 0.149 | Acc: 96.413% (30914/32064)
Loss: 0.149 | Acc: 96.386% (37074/38464)
Loss: 0.151 | Acc: 96.331% (43218/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5841, Accuracy: 8875/10000 (88.75%)

Epoch: 193
Loss: 0.097 | Acc: 96.875% (62/64)
Loss: 0.141 | Acc: 96.504% (6238/6464)
Loss: 0.143 | Acc: 96.502% (12414/12864)
Loss: 0.142 | Acc: 96.496% (18589/19264)
Loss: 0.141 | Acc: 96.501% (24766/25664)
Loss: 0.139 | Acc: 96.591% (30971/32064)
Loss: 0.137 | Acc: 96.672% (37184/38464)
Loss: 0.136 | Acc: 96.701% (43384/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5944, Accuracy: 8859/10000 (88.59%)

Epoch: 194
Loss: 0.099 | Acc: 96.875% (62/64)
Loss: 0.109 | Acc: 97.293% (6289/6464)
Loss: 0.113 | Acc: 97.186% (12502/12864)
Loss: 0.112 | Acc: 97.207% (18726/19264)
Loss: 0.115 | Acc: 97.156% (24934/25664)
Loss: 0.114 | Acc: 97.187% (31162/32064)
Loss: 0.114 | Acc: 97.184% (37381/38464)
Loss: 0.112 | Acc: 97.209% (43612/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5972, Accuracy: 8884/10000 (88.84%)

Epoch: 195
Loss: 0.181 | Acc: 96.875% (62/64)
Loss: 0.105 | Acc: 97.432% (6298/6464)
Loss: 0.104 | Acc: 97.450% (12536/12864)
Loss: 0.107 | Acc: 97.327% (18749/19264)
Loss: 0.106 | Acc: 97.374% (24990/25664)
Loss: 0.104 | Acc: 97.452% (31247/32064)
Loss: 0.105 | Acc: 97.426% (37474/38464)
Loss: 0.106 | Acc: 97.390% (43693/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5974, Accuracy: 8889/10000 (88.89%)

Epoch: 196
Loss: 0.134 | Acc: 95.312% (61/64)
Loss: 0.096 | Acc: 97.571% (6307/6464)
Loss: 0.096 | Acc: 97.590% (12554/12864)
Loss: 0.098 | Acc: 97.493% (18781/19264)
Loss: 0.099 | Acc: 97.487% (25019/25664)
Loss: 0.098 | Acc: 97.514% (31267/32064)
Loss: 0.099 | Acc: 97.489% (37498/38464)
Loss: 0.098 | Acc: 97.515% (43749/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5956, Accuracy: 8865/10000 (88.65%)

Epoch: 197
Loss: 0.030 | Acc: 100.000% (64/64)
Loss: 0.091 | Acc: 97.664% (6313/6464)
Loss: 0.093 | Acc: 97.637% (12560/12864)
Loss: 0.093 | Acc: 97.628% (18807/19264)
Loss: 0.092 | Acc: 97.689% (25071/25664)
Loss: 0.093 | Acc: 97.701% (31327/32064)
Loss: 0.093 | Acc: 97.694% (37577/38464)
Loss: 0.093 | Acc: 97.677% (43822/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5978, Accuracy: 8879/10000 (88.79%)
torch.Size([100, 10])
Test set: Average loss: 0.5978, Accuracy: 8879/10000 (88.79%)

Epoch: 198
Loss: 0.029 | Acc: 100.000% (64/64)
Loss: 0.104 | Acc: 97.478% (6301/6464)
Loss: 0.099 | Acc: 97.520% (12545/12864)
Loss: 0.093 | Acc: 97.664% (18814/19264)
Loss: 0.093 | Acc: 97.604% (25049/25664)
Loss: 0.094 | Acc: 97.617% (31300/32064)
Loss: 0.095 | Acc: 97.564% (37527/38464)
Loss: 0.094 | Acc: 97.604% (43789/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5936, Accuracy: 8876/10000 (88.76%)
torch.Size([100, 10])
Test set: Average loss: 0.5936, Accuracy: 8876/10000 (88.76%)

Epoch: 199
Loss: 0.024 | Acc: 100.000% (64/64)
Loss: 0.097 | Acc: 97.556% (6306/6464)
Loss: 0.095 | Acc: 97.613% (12557/12864)
Loss: 0.096 | Acc: 97.550% (18792/19264)
Loss: 0.092 | Acc: 97.689% (25071/25664)
Loss: 0.093 | Acc: 97.655% (31312/32064)
Loss: 0.092 | Acc: 97.689% (37575/38464)
Loss: 0.092 | Acc: 97.697% (43831/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5972, Accuracy: 8871/10000 (88.71%)
torch.Size([100, 10])
Test set: Average loss: 0.5972, Accuracy: 8871/10000 (88.71%)
9021
10000
-0.48690834641456604
