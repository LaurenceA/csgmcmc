==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.403 | Acc: 12.500% (8/64)
Loss: 2.854 | Acc: 15.114% (977/6464)
Loss: 2.506 | Acc: 17.102% (2200/12864)
Loss: 2.375 | Acc: 18.719% (3606/19264)
Loss: 2.295 | Acc: 20.266% (5201/25664)
Loss: 2.239 | Acc: 21.629% (6935/32064)
Loss: 2.201 | Acc: 22.697% (8730/38464)
Loss: 2.165 | Acc: 23.894% (10720/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0746, Accuracy: 2941/10000 (29.41%)

Epoch: 1
Loss: 2.252 | Acc: 20.312% (13/64)
Loss: 1.898 | Acc: 33.246% (2149/6464)
Loss: 1.897 | Acc: 33.217% (4273/12864)
Loss: 1.887 | Acc: 33.918% (6534/19264)
Loss: 1.880 | Acc: 34.476% (8848/25664)
Loss: 1.873 | Acc: 34.886% (11186/32064)
Loss: 1.863 | Acc: 35.342% (13594/38464)
Loss: 1.856 | Acc: 35.873% (16094/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0668, Accuracy: 3187/10000 (31.87%)

Epoch: 2
Loss: 1.690 | Acc: 50.000% (32/64)
Loss: 1.776 | Acc: 40.702% (2631/6464)
Loss: 1.768 | Acc: 40.765% (5244/12864)
Loss: 1.754 | Acc: 41.398% (7975/19264)
Loss: 1.747 | Acc: 41.603% (10677/25664)
Loss: 1.737 | Acc: 42.081% (13493/32064)
Loss: 1.733 | Acc: 42.390% (16305/38464)
Loss: 1.728 | Acc: 42.569% (19098/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7650, Accuracy: 4243/10000 (42.43%)

Epoch: 3
Loss: 2.004 | Acc: 35.938% (23/64)
Loss: 1.654 | Acc: 45.575% (2946/6464)
Loss: 1.670 | Acc: 45.717% (5881/12864)
Loss: 1.654 | Acc: 46.361% (8931/19264)
Loss: 1.648 | Acc: 46.965% (12053/25664)
Loss: 1.643 | Acc: 47.268% (15156/32064)
Loss: 1.634 | Acc: 47.780% (18378/38464)
Loss: 1.625 | Acc: 48.206% (21627/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9066, Accuracy: 3829/10000 (38.29%)

Epoch: 4
Loss: 1.812 | Acc: 42.188% (27/64)
Loss: 1.557 | Acc: 51.655% (3339/6464)
Loss: 1.555 | Acc: 51.609% (6639/12864)
Loss: 1.552 | Acc: 51.915% (10001/19264)
Loss: 1.544 | Acc: 52.159% (13386/25664)
Loss: 1.542 | Acc: 52.230% (16747/32064)
Loss: 1.536 | Acc: 52.431% (20167/38464)
Loss: 1.531 | Acc: 52.670% (23630/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6009, Accuracy: 5123/10000 (51.23%)

Epoch: 5
Loss: 1.787 | Acc: 50.000% (32/64)
Loss: 1.478 | Acc: 54.873% (3547/6464)
Loss: 1.490 | Acc: 54.221% (6975/12864)
Loss: 1.478 | Acc: 55.186% (10631/19264)
Loss: 1.475 | Acc: 55.288% (14189/25664)
Loss: 1.465 | Acc: 55.748% (17875/32064)
Loss: 1.465 | Acc: 55.748% (21443/38464)
Loss: 1.459 | Acc: 56.052% (25147/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7770, Accuracy: 4544/10000 (45.44%)

Epoch: 6
Loss: 1.405 | Acc: 57.812% (37/64)
Loss: 1.423 | Acc: 57.952% (3746/6464)
Loss: 1.419 | Acc: 57.999% (7461/12864)
Loss: 1.414 | Acc: 58.264% (11224/19264)
Loss: 1.404 | Acc: 58.596% (15038/25664)
Loss: 1.398 | Acc: 58.795% (18852/32064)
Loss: 1.396 | Acc: 58.959% (22678/38464)
Loss: 1.394 | Acc: 59.083% (26507/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0048, Accuracy: 3603/10000 (36.03%)

Epoch: 7
Loss: 1.645 | Acc: 42.188% (27/64)
Loss: 1.379 | Acc: 60.535% (3913/6464)
Loss: 1.363 | Acc: 60.759% (7816/12864)
Loss: 1.361 | Acc: 60.896% (11731/19264)
Loss: 1.355 | Acc: 61.206% (15708/25664)
Loss: 1.352 | Acc: 61.243% (19637/32064)
Loss: 1.352 | Acc: 61.216% (23546/38464)
Loss: 1.346 | Acc: 61.403% (27548/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5022, Accuracy: 5661/10000 (56.61%)

Epoch: 8
Loss: 1.282 | Acc: 64.062% (41/64)
Loss: 1.336 | Acc: 61.866% (3999/6464)
Loss: 1.325 | Acc: 62.251% (8008/12864)
Loss: 1.321 | Acc: 62.552% (12050/19264)
Loss: 1.321 | Acc: 62.504% (16041/25664)
Loss: 1.315 | Acc: 62.612% (20076/32064)
Loss: 1.314 | Acc: 62.713% (24122/38464)
Loss: 1.312 | Acc: 62.825% (28186/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4980, Accuracy: 5667/10000 (56.67%)

Epoch: 9
Loss: 1.426 | Acc: 54.688% (35/64)
Loss: 1.271 | Acc: 64.573% (4174/6464)
Loss: 1.286 | Acc: 64.101% (8246/12864)
Loss: 1.295 | Acc: 63.642% (12260/19264)
Loss: 1.293 | Acc: 63.716% (16352/25664)
Loss: 1.293 | Acc: 63.794% (20455/32064)
Loss: 1.292 | Acc: 63.787% (24535/38464)
Loss: 1.287 | Acc: 63.967% (28698/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5443, Accuracy: 5295/10000 (52.95%)

Epoch: 10
Loss: 1.045 | Acc: 73.438% (47/64)
Loss: 1.257 | Acc: 65.022% (4203/6464)
Loss: 1.261 | Acc: 65.229% (8391/12864)
Loss: 1.262 | Acc: 64.981% (12518/19264)
Loss: 1.259 | Acc: 65.064% (16698/25664)
Loss: 1.264 | Acc: 64.973% (20833/32064)
Loss: 1.266 | Acc: 64.902% (24964/38464)
Loss: 1.265 | Acc: 64.885% (29110/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6853, Accuracy: 5052/10000 (50.52%)

Epoch: 11
Loss: 1.366 | Acc: 57.812% (37/64)
Loss: 1.250 | Acc: 64.991% (4201/6464)
Loss: 1.255 | Acc: 65.096% (8374/12864)
Loss: 1.251 | Acc: 65.464% (12611/19264)
Loss: 1.258 | Acc: 65.278% (16753/25664)
Loss: 1.257 | Acc: 65.248% (20921/32064)
Loss: 1.252 | Acc: 65.357% (25139/38464)
Loss: 1.251 | Acc: 65.369% (29327/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4236, Accuracy: 5986/10000 (59.86%)

Epoch: 12
Loss: 1.340 | Acc: 59.375% (38/64)
Loss: 1.228 | Acc: 65.996% (4266/6464)
Loss: 1.234 | Acc: 66.076% (8500/12864)
Loss: 1.230 | Acc: 66.326% (12777/19264)
Loss: 1.232 | Acc: 66.276% (17009/25664)
Loss: 1.235 | Acc: 66.214% (21231/32064)
Loss: 1.233 | Acc: 66.343% (25518/38464)
Loss: 1.235 | Acc: 66.191% (29696/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5603, Accuracy: 5335/10000 (53.35%)

Epoch: 13
Loss: 1.414 | Acc: 65.625% (42/64)
Loss: 1.214 | Acc: 67.327% (4352/6464)
Loss: 1.219 | Acc: 66.900% (8606/12864)
Loss: 1.213 | Acc: 67.089% (12924/19264)
Loss: 1.219 | Acc: 66.965% (17186/25664)
Loss: 1.217 | Acc: 67.050% (21499/32064)
Loss: 1.219 | Acc: 66.964% (25757/38464)
Loss: 1.220 | Acc: 66.949% (30036/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5688, Accuracy: 5536/10000 (55.36%)

Epoch: 14
Loss: 1.271 | Acc: 67.188% (43/64)
Loss: 1.230 | Acc: 66.259% (4283/6464)
Loss: 1.212 | Acc: 66.877% (8603/12864)
Loss: 1.214 | Acc: 66.736% (12856/19264)
Loss: 1.214 | Acc: 66.950% (17182/25664)
Loss: 1.210 | Acc: 67.110% (21518/32064)
Loss: 1.208 | Acc: 67.214% (25853/38464)
Loss: 1.209 | Acc: 67.228% (30161/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6784, Accuracy: 5113/10000 (51.13%)

Epoch: 15
Loss: 1.456 | Acc: 57.812% (37/64)
Loss: 1.200 | Acc: 67.512% (4364/6464)
Loss: 1.198 | Acc: 68.004% (8748/12864)
Loss: 1.199 | Acc: 68.086% (13116/19264)
Loss: 1.197 | Acc: 68.049% (17464/25664)
Loss: 1.192 | Acc: 68.126% (21844/32064)
Loss: 1.195 | Acc: 67.923% (26126/38464)
Loss: 1.195 | Acc: 67.852% (30441/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5230, Accuracy: 5527/10000 (55.27%)

Epoch: 16
Loss: 1.370 | Acc: 64.062% (41/64)
Loss: 1.173 | Acc: 68.858% (4451/6464)
Loss: 1.169 | Acc: 68.734% (8842/12864)
Loss: 1.175 | Acc: 68.568% (13209/19264)
Loss: 1.185 | Acc: 68.294% (17527/25664)
Loss: 1.181 | Acc: 68.429% (21941/32064)
Loss: 1.185 | Acc: 68.357% (26293/38464)
Loss: 1.179 | Acc: 68.467% (30717/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6491, Accuracy: 5325/10000 (53.25%)

Epoch: 17
Loss: 1.282 | Acc: 64.062% (41/64)
Loss: 1.159 | Acc: 69.477% (4491/6464)
Loss: 1.170 | Acc: 68.843% (8856/12864)
Loss: 1.172 | Acc: 68.734% (13241/19264)
Loss: 1.167 | Acc: 68.879% (17677/25664)
Loss: 1.168 | Acc: 68.878% (22085/32064)
Loss: 1.168 | Acc: 68.916% (26508/38464)
Loss: 1.168 | Acc: 68.875% (30900/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4169, Accuracy: 6076/10000 (60.76%)

Epoch: 18
Loss: 1.179 | Acc: 67.188% (43/64)
Loss: 1.113 | Acc: 70.823% (4578/6464)
Loss: 1.126 | Acc: 70.390% (9055/12864)
Loss: 1.143 | Acc: 69.944% (13474/19264)
Loss: 1.148 | Acc: 69.833% (17922/25664)
Loss: 1.148 | Acc: 69.845% (22395/32064)
Loss: 1.155 | Acc: 69.611% (26775/38464)
Loss: 1.154 | Acc: 69.572% (31213/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7270, Accuracy: 5145/10000 (51.45%)

Epoch: 19
Loss: 1.687 | Acc: 54.688% (35/64)
Loss: 1.139 | Acc: 69.756% (4509/6464)
Loss: 1.143 | Acc: 69.862% (8987/12864)
Loss: 1.137 | Acc: 70.079% (13500/19264)
Loss: 1.135 | Acc: 70.196% (18015/25664)
Loss: 1.139 | Acc: 70.128% (22486/32064)
Loss: 1.142 | Acc: 70.024% (26934/38464)
Loss: 1.143 | Acc: 69.980% (31396/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4288, Accuracy: 5925/10000 (59.25%)

Epoch: 20
Loss: 1.106 | Acc: 70.312% (45/64)
Loss: 1.117 | Acc: 70.916% (4584/6464)
Loss: 1.125 | Acc: 70.623% (9085/12864)
Loss: 1.125 | Acc: 70.681% (13616/19264)
Loss: 1.125 | Acc: 70.620% (18124/25664)
Loss: 1.130 | Acc: 70.472% (22596/32064)
Loss: 1.131 | Acc: 70.549% (27136/38464)
Loss: 1.131 | Acc: 70.535% (31645/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1067, Accuracy: 4002/10000 (40.02%)

Epoch: 21
Loss: 1.107 | Acc: 68.750% (44/64)
Loss: 1.112 | Acc: 71.086% (4595/6464)
Loss: 1.113 | Acc: 71.067% (9142/12864)
Loss: 1.110 | Acc: 71.169% (13710/19264)
Loss: 1.120 | Acc: 70.757% (18159/25664)
Loss: 1.119 | Acc: 70.805% (22703/32064)
Loss: 1.121 | Acc: 70.814% (27238/38464)
Loss: 1.121 | Acc: 70.896% (31807/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3477, Accuracy: 6236/10000 (62.36%)

Epoch: 22
Loss: 0.913 | Acc: 79.688% (51/64)
Loss: 1.100 | Acc: 71.798% (4641/6464)
Loss: 1.116 | Acc: 71.144% (9152/12864)
Loss: 1.112 | Acc: 71.117% (13700/19264)
Loss: 1.115 | Acc: 71.103% (18248/25664)
Loss: 1.107 | Acc: 71.326% (22870/32064)
Loss: 1.108 | Acc: 71.246% (27404/38464)
Loss: 1.105 | Acc: 71.376% (32022/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6476, Accuracy: 5191/10000 (51.91%)

Epoch: 23
Loss: 1.109 | Acc: 71.875% (46/64)
Loss: 1.082 | Acc: 72.324% (4675/6464)
Loss: 1.094 | Acc: 71.914% (9251/12864)
Loss: 1.098 | Acc: 71.839% (13839/19264)
Loss: 1.102 | Acc: 71.692% (18399/25664)
Loss: 1.101 | Acc: 71.638% (22970/32064)
Loss: 1.099 | Acc: 71.683% (27572/38464)
Loss: 1.098 | Acc: 71.735% (32183/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3445, Accuracy: 6247/10000 (62.47%)

Epoch: 24
Loss: 1.150 | Acc: 70.312% (45/64)
Loss: 1.091 | Acc: 71.875% (4646/6464)
Loss: 1.097 | Acc: 71.836% (9241/12864)
Loss: 1.090 | Acc: 72.114% (13892/19264)
Loss: 1.095 | Acc: 72.039% (18488/25664)
Loss: 1.090 | Acc: 72.062% (23106/32064)
Loss: 1.089 | Acc: 72.039% (27709/38464)
Loss: 1.090 | Acc: 72.031% (32316/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2738, Accuracy: 6628/10000 (66.28%)

Epoch: 25
Loss: 1.174 | Acc: 65.625% (42/64)
Loss: 1.066 | Acc: 73.283% (4737/6464)
Loss: 1.076 | Acc: 72.652% (9346/12864)
Loss: 1.075 | Acc: 72.742% (14013/19264)
Loss: 1.074 | Acc: 72.744% (18669/25664)
Loss: 1.077 | Acc: 72.708% (23313/32064)
Loss: 1.080 | Acc: 72.554% (27907/38464)
Loss: 1.081 | Acc: 72.484% (32519/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4170, Accuracy: 5965/10000 (59.65%)

Epoch: 26
Loss: 1.047 | Acc: 68.750% (44/64)
Loss: 1.081 | Acc: 72.246% (4670/6464)
Loss: 1.073 | Acc: 72.411% (9315/12864)
Loss: 1.066 | Acc: 72.716% (14008/19264)
Loss: 1.073 | Acc: 72.565% (18623/25664)
Loss: 1.076 | Acc: 72.608% (23281/32064)
Loss: 1.067 | Acc: 72.788% (27997/38464)
Loss: 1.064 | Acc: 72.967% (32736/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3332, Accuracy: 6387/10000 (63.87%)

Epoch: 27
Loss: 1.279 | Acc: 65.625% (42/64)
Loss: 1.083 | Acc: 72.494% (4686/6464)
Loss: 1.049 | Acc: 73.710% (9482/12864)
Loss: 1.053 | Acc: 73.396% (14139/19264)
Loss: 1.051 | Acc: 73.410% (18840/25664)
Loss: 1.049 | Acc: 73.503% (23568/32064)
Loss: 1.046 | Acc: 73.596% (28308/38464)
Loss: 1.049 | Acc: 73.513% (32981/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7643, Accuracy: 5181/10000 (51.81%)

Epoch: 28
Loss: 1.347 | Acc: 65.625% (42/64)
Loss: 1.051 | Acc: 73.345% (4741/6464)
Loss: 1.062 | Acc: 73.080% (9401/12864)
Loss: 1.043 | Acc: 73.697% (14197/19264)
Loss: 1.046 | Acc: 73.609% (18891/25664)
Loss: 1.041 | Acc: 73.724% (23639/32064)
Loss: 1.045 | Acc: 73.651% (28329/38464)
Loss: 1.046 | Acc: 73.678% (33055/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3651, Accuracy: 6200/10000 (62.00%)

Epoch: 29
Loss: 0.980 | Acc: 76.562% (49/64)
Loss: 1.007 | Acc: 75.309% (4868/6464)
Loss: 1.021 | Acc: 74.588% (9595/12864)
Loss: 1.013 | Acc: 74.761% (14402/19264)
Loss: 1.019 | Acc: 74.540% (19130/25664)
Loss: 1.023 | Acc: 74.342% (23837/32064)
Loss: 1.024 | Acc: 74.386% (28612/38464)
Loss: 1.020 | Acc: 74.539% (33441/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2697, Accuracy: 6600/10000 (66.00%)

Epoch: 30
Loss: 1.482 | Acc: 62.500% (40/64)
Loss: 0.994 | Acc: 75.557% (4884/6464)
Loss: 1.006 | Acc: 75.202% (9674/12864)
Loss: 1.003 | Acc: 75.192% (14485/19264)
Loss: 1.003 | Acc: 75.086% (19270/25664)
Loss: 1.010 | Acc: 74.959% (24035/32064)
Loss: 1.014 | Acc: 74.860% (28794/38464)
Loss: 1.013 | Acc: 74.889% (33598/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1808, Accuracy: 6954/10000 (69.54%)

Epoch: 31
Loss: 0.632 | Acc: 85.938% (55/64)
Loss: 0.973 | Acc: 76.253% (4929/6464)
Loss: 0.992 | Acc: 75.295% (9686/12864)
Loss: 0.993 | Acc: 75.369% (14519/19264)
Loss: 0.994 | Acc: 75.370% (19343/25664)
Loss: 0.996 | Acc: 75.324% (24152/32064)
Loss: 0.993 | Acc: 75.497% (29039/38464)
Loss: 0.996 | Acc: 75.383% (33820/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1744, Accuracy: 7005/10000 (70.05%)

Epoch: 32
Loss: 0.958 | Acc: 70.312% (45/64)
Loss: 0.975 | Acc: 75.990% (4912/6464)
Loss: 0.982 | Acc: 75.622% (9728/12864)
Loss: 0.985 | Acc: 75.748% (14592/19264)
Loss: 0.982 | Acc: 75.799% (19453/25664)
Loss: 0.981 | Acc: 75.820% (24311/32064)
Loss: 0.982 | Acc: 75.770% (29144/38464)
Loss: 0.981 | Acc: 75.865% (34036/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2623, Accuracy: 6660/10000 (66.60%)

Epoch: 33
Loss: 1.034 | Acc: 73.438% (47/64)
Loss: 0.929 | Acc: 76.779% (4963/6464)
Loss: 0.945 | Acc: 76.570% (9850/12864)
Loss: 0.941 | Acc: 76.770% (14789/19264)
Loss: 0.950 | Acc: 76.485% (19629/25664)
Loss: 0.948 | Acc: 76.550% (24545/32064)
Loss: 0.956 | Acc: 76.440% (29402/38464)
Loss: 0.958 | Acc: 76.444% (34296/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3902, Accuracy: 6217/10000 (62.17%)

Epoch: 34
Loss: 1.051 | Acc: 73.438% (47/64)
Loss: 0.924 | Acc: 77.150% (4987/6464)
Loss: 0.923 | Acc: 77.262% (9939/12864)
Loss: 0.924 | Acc: 77.352% (14901/19264)
Loss: 0.930 | Acc: 77.205% (19814/25664)
Loss: 0.932 | Acc: 77.221% (24760/32064)
Loss: 0.936 | Acc: 77.202% (29695/38464)
Loss: 0.940 | Acc: 77.146% (34611/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1949, Accuracy: 7007/10000 (70.07%)

Epoch: 35
Loss: 0.869 | Acc: 79.688% (51/64)
Loss: 0.878 | Acc: 78.605% (5081/6464)
Loss: 0.903 | Acc: 77.970% (10030/12864)
Loss: 0.904 | Acc: 77.954% (15017/19264)
Loss: 0.904 | Acc: 77.942% (20003/25664)
Loss: 0.908 | Acc: 77.826% (24954/32064)
Loss: 0.914 | Acc: 77.647% (29866/38464)
Loss: 0.919 | Acc: 77.528% (34782/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1897, Accuracy: 7030/10000 (70.30%)

Epoch: 36
Loss: 1.059 | Acc: 70.312% (45/64)
Loss: 0.895 | Acc: 78.357% (5065/6464)
Loss: 0.894 | Acc: 78.187% (10058/12864)
Loss: 0.892 | Acc: 78.307% (15085/19264)
Loss: 0.895 | Acc: 78.137% (20053/25664)
Loss: 0.898 | Acc: 78.122% (25049/32064)
Loss: 0.898 | Acc: 78.164% (30065/38464)
Loss: 0.900 | Acc: 78.152% (35062/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1972, Accuracy: 7096/10000 (70.96%)

Epoch: 37
Loss: 0.856 | Acc: 76.562% (49/64)
Loss: 0.859 | Acc: 79.486% (5138/6464)
Loss: 0.858 | Acc: 79.415% (10216/12864)
Loss: 0.857 | Acc: 79.381% (15292/19264)
Loss: 0.853 | Acc: 79.368% (20369/25664)
Loss: 0.861 | Acc: 79.017% (25336/32064)
Loss: 0.870 | Acc: 78.869% (30336/38464)
Loss: 0.874 | Acc: 78.734% (35323/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2023, Accuracy: 7033/10000 (70.33%)

Epoch: 38
Loss: 0.851 | Acc: 78.125% (50/64)
Loss: 0.829 | Acc: 79.626% (5147/6464)
Loss: 0.827 | Acc: 79.618% (10242/12864)
Loss: 0.830 | Acc: 79.641% (15342/19264)
Loss: 0.840 | Acc: 79.372% (20370/25664)
Loss: 0.844 | Acc: 79.310% (25430/32064)
Loss: 0.843 | Acc: 79.360% (30525/38464)
Loss: 0.845 | Acc: 79.344% (35597/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2006, Accuracy: 7050/10000 (70.50%)

Epoch: 39
Loss: 0.913 | Acc: 75.000% (48/64)
Loss: 0.788 | Acc: 80.647% (5213/6464)
Loss: 0.786 | Acc: 81.032% (10424/12864)
Loss: 0.796 | Acc: 80.778% (15561/19264)
Loss: 0.800 | Acc: 80.681% (20706/25664)
Loss: 0.806 | Acc: 80.458% (25798/32064)
Loss: 0.808 | Acc: 80.358% (30909/38464)
Loss: 0.816 | Acc: 80.167% (35966/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1880, Accuracy: 7103/10000 (71.03%)

Epoch: 40
Loss: 0.629 | Acc: 82.812% (53/64)
Loss: 0.767 | Acc: 81.049% (5239/6464)
Loss: 0.770 | Acc: 81.001% (10420/12864)
Loss: 0.777 | Acc: 80.861% (15577/19264)
Loss: 0.781 | Acc: 80.701% (20711/25664)
Loss: 0.783 | Acc: 80.729% (25885/32064)
Loss: 0.785 | Acc: 80.665% (31027/38464)
Loss: 0.783 | Acc: 80.735% (36221/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2066, Accuracy: 7180/10000 (71.80%)

Epoch: 41
Loss: 0.915 | Acc: 76.562% (49/64)
Loss: 0.739 | Acc: 81.730% (5283/6464)
Loss: 0.741 | Acc: 81.592% (10496/12864)
Loss: 0.737 | Acc: 81.795% (15757/19264)
Loss: 0.743 | Acc: 81.644% (20953/25664)
Loss: 0.742 | Acc: 81.634% (26175/32064)
Loss: 0.745 | Acc: 81.549% (31367/38464)
Loss: 0.747 | Acc: 81.475% (36553/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2463, Accuracy: 7121/10000 (71.21%)

Epoch: 42
Loss: 0.693 | Acc: 85.938% (55/64)
Loss: 0.706 | Acc: 82.580% (5338/6464)
Loss: 0.707 | Acc: 82.393% (10599/12864)
Loss: 0.707 | Acc: 82.345% (15863/19264)
Loss: 0.708 | Acc: 82.310% (21124/25664)
Loss: 0.707 | Acc: 82.317% (26394/32064)
Loss: 0.708 | Acc: 82.368% (31682/38464)
Loss: 0.704 | Acc: 82.523% (37023/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2587, Accuracy: 7211/10000 (72.11%)

Epoch: 43
Loss: 0.517 | Acc: 87.500% (56/64)
Loss: 0.650 | Acc: 83.679% (5409/6464)
Loss: 0.652 | Acc: 83.528% (10745/12864)
Loss: 0.656 | Acc: 83.409% (16068/19264)
Loss: 0.651 | Acc: 83.510% (21432/25664)
Loss: 0.650 | Acc: 83.549% (26789/32064)
Loss: 0.656 | Acc: 83.434% (32092/38464)
Loss: 0.657 | Acc: 83.452% (37440/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2942, Accuracy: 7092/10000 (70.92%)

Epoch: 44
Loss: 0.582 | Acc: 85.938% (55/64)
Loss: 0.616 | Acc: 83.880% (5422/6464)
Loss: 0.613 | Acc: 84.204% (10832/12864)
Loss: 0.608 | Acc: 84.442% (16267/19264)
Loss: 0.610 | Acc: 84.336% (21644/25664)
Loss: 0.615 | Acc: 84.125% (26974/32064)
Loss: 0.610 | Acc: 84.227% (32397/38464)
Loss: 0.610 | Acc: 84.255% (37800/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3043, Accuracy: 7138/10000 (71.38%)

Epoch: 45
Loss: 0.391 | Acc: 89.062% (57/64)
Loss: 0.557 | Acc: 85.458% (5524/6464)
Loss: 0.555 | Acc: 85.386% (10984/12864)
Loss: 0.563 | Acc: 85.221% (16417/19264)
Loss: 0.564 | Acc: 85.143% (21851/25664)
Loss: 0.565 | Acc: 85.155% (27304/32064)
Loss: 0.561 | Acc: 85.293% (32807/38464)
Loss: 0.558 | Acc: 85.382% (38306/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3448, Accuracy: 7047/10000 (70.47%)

Epoch: 46
Loss: 0.384 | Acc: 85.938% (55/64)
Loss: 0.517 | Acc: 85.752% (5543/6464)
Loss: 0.516 | Acc: 86.256% (11096/12864)
Loss: 0.513 | Acc: 86.394% (16643/19264)
Loss: 0.514 | Acc: 86.389% (22171/25664)
Loss: 0.515 | Acc: 86.449% (27719/32064)
Loss: 0.515 | Acc: 86.385% (33227/38464)
Loss: 0.514 | Acc: 86.426% (38774/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3538, Accuracy: 7076/10000 (70.76%)

Epoch: 47
Loss: 0.202 | Acc: 98.438% (63/64)
Loss: 0.498 | Acc: 86.742% (5607/6464)
Loss: 0.490 | Acc: 87.111% (11206/12864)
Loss: 0.492 | Acc: 87.022% (16764/19264)
Loss: 0.487 | Acc: 87.130% (22361/25664)
Loss: 0.488 | Acc: 87.054% (27913/32064)
Loss: 0.485 | Acc: 87.159% (33525/38464)
Loss: 0.484 | Acc: 87.175% (39110/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3730, Accuracy: 7115/10000 (71.15%)
torch.Size([100, 10])
Test set: Average loss: 1.3730, Accuracy: 7115/10000 (71.15%)

Epoch: 48
Loss: 0.544 | Acc: 85.938% (55/64)
Loss: 0.450 | Acc: 87.980% (5687/6464)
Loss: 0.460 | Acc: 87.562% (11264/12864)
Loss: 0.464 | Acc: 87.370% (16831/19264)
Loss: 0.463 | Acc: 87.461% (22446/25664)
Loss: 0.458 | Acc: 87.656% (28106/32064)
Loss: 0.459 | Acc: 87.640% (33710/38464)
Loss: 0.459 | Acc: 87.656% (39326/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3730, Accuracy: 7113/10000 (71.13%)
torch.Size([100, 10])
Test set: Average loss: 1.3730, Accuracy: 7113/10000 (71.13%)

Epoch: 49
Loss: 0.459 | Acc: 85.938% (55/64)
Loss: 0.460 | Acc: 87.206% (5637/6464)
Loss: 0.464 | Acc: 87.220% (11220/12864)
Loss: 0.463 | Acc: 87.360% (16829/19264)
Loss: 0.455 | Acc: 87.516% (22460/25664)
Loss: 0.455 | Acc: 87.556% (28074/32064)
Loss: 0.454 | Acc: 87.586% (33689/38464)
Loss: 0.453 | Acc: 87.629% (39314/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3843, Accuracy: 7104/10000 (71.04%)
torch.Size([100, 10])
Test set: Average loss: 1.3843, Accuracy: 7104/10000 (71.04%)

Epoch: 50
Loss: 0.402 | Acc: 90.625% (58/64)
Loss: 1.815 | Acc: 38.861% (2512/6464)
Loss: 1.581 | Acc: 50.109% (6446/12864)
Loss: 1.482 | Acc: 54.604% (10519/19264)
Loss: 1.432 | Acc: 57.096% (14653/25664)
Loss: 1.396 | Acc: 58.945% (18900/32064)
Loss: 1.367 | Acc: 60.223% (23164/38464)
Loss: 1.349 | Acc: 61.129% (27425/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0266, Accuracy: 4201/10000 (42.01%)

Epoch: 51
Loss: 1.245 | Acc: 67.188% (43/64)
Loss: 1.201 | Acc: 67.265% (4348/6464)
Loss: 1.198 | Acc: 67.561% (8691/12864)
Loss: 1.201 | Acc: 67.577% (13018/19264)
Loss: 1.198 | Acc: 67.647% (17361/25664)
Loss: 1.195 | Acc: 67.827% (21748/32064)
Loss: 1.190 | Acc: 67.999% (26155/38464)
Loss: 1.188 | Acc: 68.135% (30568/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4965, Accuracy: 5811/10000 (58.11%)

Epoch: 52
Loss: 1.217 | Acc: 68.750% (44/64)
Loss: 1.164 | Acc: 69.508% (4493/6464)
Loss: 1.160 | Acc: 69.488% (8939/12864)
Loss: 1.158 | Acc: 69.461% (13381/19264)
Loss: 1.159 | Acc: 69.440% (17821/25664)
Loss: 1.159 | Acc: 69.474% (22276/32064)
Loss: 1.158 | Acc: 69.429% (26705/38464)
Loss: 1.160 | Acc: 69.450% (31158/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4391, Accuracy: 6051/10000 (60.51%)

Epoch: 53
Loss: 1.309 | Acc: 62.500% (40/64)
Loss: 1.138 | Acc: 70.050% (4528/6464)
Loss: 1.146 | Acc: 69.729% (8970/12864)
Loss: 1.150 | Acc: 69.570% (13402/19264)
Loss: 1.154 | Acc: 69.354% (17799/25664)
Loss: 1.156 | Acc: 69.321% (22227/32064)
Loss: 1.151 | Acc: 69.556% (26754/38464)
Loss: 1.153 | Acc: 69.508% (31184/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7942, Accuracy: 5051/10000 (50.51%)

Epoch: 54
Loss: 1.137 | Acc: 67.188% (43/64)
Loss: 1.142 | Acc: 69.879% (4517/6464)
Loss: 1.149 | Acc: 69.768% (8975/12864)
Loss: 1.144 | Acc: 69.996% (13484/19264)
Loss: 1.141 | Acc: 70.044% (17976/25664)
Loss: 1.145 | Acc: 69.954% (22430/32064)
Loss: 1.147 | Acc: 69.886% (26881/38464)
Loss: 1.147 | Acc: 69.885% (31353/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5536, Accuracy: 5360/10000 (53.60%)

Epoch: 55
Loss: 1.301 | Acc: 67.188% (43/64)
Loss: 1.133 | Acc: 70.266% (4542/6464)
Loss: 1.138 | Acc: 70.390% (9055/12864)
Loss: 1.141 | Acc: 70.255% (13534/19264)
Loss: 1.144 | Acc: 70.161% (18006/25664)
Loss: 1.141 | Acc: 70.172% (22500/32064)
Loss: 1.141 | Acc: 70.196% (27000/38464)
Loss: 1.143 | Acc: 70.159% (31476/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2534, Accuracy: 6659/10000 (66.59%)

Epoch: 56
Loss: 1.284 | Acc: 65.625% (42/64)
Loss: 1.134 | Acc: 70.514% (4558/6464)
Loss: 1.133 | Acc: 70.289% (9042/12864)
Loss: 1.132 | Acc: 70.385% (13559/19264)
Loss: 1.135 | Acc: 70.262% (18032/25664)
Loss: 1.138 | Acc: 70.172% (22500/32064)
Loss: 1.138 | Acc: 70.175% (26992/38464)
Loss: 1.137 | Acc: 70.101% (31450/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4323, Accuracy: 6093/10000 (60.93%)

Epoch: 57
Loss: 1.321 | Acc: 68.750% (44/64)
Loss: 1.129 | Acc: 70.297% (4544/6464)
Loss: 1.135 | Acc: 70.141% (9023/12864)
Loss: 1.138 | Acc: 69.996% (13484/19264)
Loss: 1.138 | Acc: 70.048% (17977/25664)
Loss: 1.134 | Acc: 70.197% (22508/32064)
Loss: 1.139 | Acc: 70.102% (26964/38464)
Loss: 1.135 | Acc: 70.237% (31511/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5214, Accuracy: 5624/10000 (56.24%)

Epoch: 58
Loss: 1.211 | Acc: 64.062% (41/64)
Loss: 1.131 | Acc: 70.498% (4557/6464)
Loss: 1.139 | Acc: 70.227% (9034/12864)
Loss: 1.128 | Acc: 70.624% (13605/19264)
Loss: 1.131 | Acc: 70.507% (18095/25664)
Loss: 1.134 | Acc: 70.447% (22588/32064)
Loss: 1.133 | Acc: 70.474% (27107/38464)
Loss: 1.130 | Acc: 70.580% (31665/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4400, Accuracy: 5952/10000 (59.52%)

Epoch: 59
Loss: 0.959 | Acc: 75.000% (48/64)
Loss: 1.137 | Acc: 70.421% (4552/6464)
Loss: 1.132 | Acc: 70.693% (9094/12864)
Loss: 1.131 | Acc: 70.712% (13622/19264)
Loss: 1.125 | Acc: 70.928% (18203/25664)
Loss: 1.128 | Acc: 70.808% (22704/32064)
Loss: 1.130 | Acc: 70.721% (27202/38464)
Loss: 1.134 | Acc: 70.638% (31691/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3366, Accuracy: 6359/10000 (63.59%)

Epoch: 60
Loss: 1.094 | Acc: 68.750% (44/64)
Loss: 1.118 | Acc: 70.947% (4586/6464)
Loss: 1.115 | Acc: 71.028% (9137/12864)
Loss: 1.129 | Acc: 70.660% (13612/19264)
Loss: 1.129 | Acc: 70.585% (18115/25664)
Loss: 1.126 | Acc: 70.818% (22707/32064)
Loss: 1.124 | Acc: 70.887% (27266/38464)
Loss: 1.125 | Acc: 70.839% (31781/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5643, Accuracy: 5684/10000 (56.84%)

Epoch: 61
Loss: 1.246 | Acc: 65.625% (42/64)
Loss: 1.108 | Acc: 71.395% (4615/6464)
Loss: 1.104 | Acc: 71.572% (9207/12864)
Loss: 1.113 | Acc: 71.143% (13705/19264)
Loss: 1.120 | Acc: 70.979% (18216/25664)
Loss: 1.119 | Acc: 71.036% (22777/32064)
Loss: 1.120 | Acc: 71.061% (27333/38464)
Loss: 1.118 | Acc: 71.099% (31898/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4978, Accuracy: 5765/10000 (57.65%)

Epoch: 62
Loss: 1.270 | Acc: 65.625% (42/64)
Loss: 1.108 | Acc: 71.767% (4639/6464)
Loss: 1.107 | Acc: 71.688% (9222/12864)
Loss: 1.118 | Acc: 71.418% (13758/19264)
Loss: 1.112 | Acc: 71.563% (18366/25664)
Loss: 1.116 | Acc: 71.311% (22865/32064)
Loss: 1.117 | Acc: 71.300% (27425/38464)
Loss: 1.119 | Acc: 71.217% (31951/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7111, Accuracy: 5242/10000 (52.42%)

Epoch: 63
Loss: 0.838 | Acc: 81.250% (52/64)
Loss: 1.106 | Acc: 71.627% (4630/6464)
Loss: 1.111 | Acc: 71.385% (9183/12864)
Loss: 1.103 | Acc: 71.699% (13812/19264)
Loss: 1.108 | Acc: 71.372% (18317/25664)
Loss: 1.109 | Acc: 71.410% (22897/32064)
Loss: 1.113 | Acc: 71.326% (27435/38464)
Loss: 1.114 | Acc: 71.304% (31990/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4263, Accuracy: 6057/10000 (60.57%)

Epoch: 64
Loss: 1.079 | Acc: 73.438% (47/64)
Loss: 1.114 | Acc: 71.473% (4620/6464)
Loss: 1.109 | Acc: 71.657% (9218/12864)
Loss: 1.100 | Acc: 71.802% (13832/19264)
Loss: 1.102 | Acc: 71.715% (18405/25664)
Loss: 1.103 | Acc: 71.750% (23006/32064)
Loss: 1.102 | Acc: 71.732% (27591/38464)
Loss: 1.105 | Acc: 71.581% (32114/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5866, Accuracy: 5378/10000 (53.78%)

Epoch: 65
Loss: 0.989 | Acc: 76.562% (49/64)
Loss: 1.083 | Acc: 72.494% (4686/6464)
Loss: 1.087 | Acc: 72.295% (9300/12864)
Loss: 1.102 | Acc: 71.756% (13823/19264)
Loss: 1.100 | Acc: 71.778% (18421/25664)
Loss: 1.103 | Acc: 71.597% (22957/32064)
Loss: 1.103 | Acc: 71.636% (27554/38464)
Loss: 1.100 | Acc: 71.712% (32173/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3067, Accuracy: 6444/10000 (64.44%)

Epoch: 66
Loss: 1.041 | Acc: 78.125% (50/64)
Loss: 1.048 | Acc: 73.623% (4759/6464)
Loss: 1.074 | Acc: 72.808% (9366/12864)
Loss: 1.084 | Acc: 72.488% (13964/19264)
Loss: 1.089 | Acc: 72.269% (18547/25664)
Loss: 1.091 | Acc: 72.202% (23151/32064)
Loss: 1.091 | Acc: 72.195% (27769/38464)
Loss: 1.090 | Acc: 72.187% (32386/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5919, Accuracy: 5436/10000 (54.36%)

Epoch: 67
Loss: 1.475 | Acc: 57.812% (37/64)
Loss: 1.095 | Acc: 72.030% (4656/6464)
Loss: 1.082 | Acc: 72.303% (9301/12864)
Loss: 1.083 | Acc: 72.285% (13925/19264)
Loss: 1.089 | Acc: 72.249% (18542/25664)
Loss: 1.088 | Acc: 72.330% (23192/32064)
Loss: 1.087 | Acc: 72.359% (27832/38464)
Loss: 1.087 | Acc: 72.290% (32432/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3812, Accuracy: 6173/10000 (61.73%)

Epoch: 68
Loss: 0.969 | Acc: 75.000% (48/64)
Loss: 1.088 | Acc: 72.339% (4676/6464)
Loss: 1.067 | Acc: 72.800% (9365/12864)
Loss: 1.076 | Acc: 72.534% (13973/19264)
Loss: 1.077 | Acc: 72.514% (18610/25664)
Loss: 1.081 | Acc: 72.533% (23257/32064)
Loss: 1.083 | Acc: 72.548% (27905/38464)
Loss: 1.078 | Acc: 72.675% (32605/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3971, Accuracy: 6131/10000 (61.31%)

Epoch: 69
Loss: 1.245 | Acc: 60.938% (39/64)
Loss: 1.046 | Acc: 73.484% (4750/6464)
Loss: 1.055 | Acc: 73.212% (9418/12864)
Loss: 1.065 | Acc: 72.918% (14047/19264)
Loss: 1.070 | Acc: 72.775% (18677/25664)
Loss: 1.070 | Acc: 72.726% (23319/32064)
Loss: 1.068 | Acc: 72.855% (28023/38464)
Loss: 1.070 | Acc: 72.856% (32686/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3491, Accuracy: 6326/10000 (63.26%)

Epoch: 70
Loss: 1.031 | Acc: 78.125% (50/64)
Loss: 1.030 | Acc: 74.041% (4786/6464)
Loss: 1.034 | Acc: 73.951% (9513/12864)
Loss: 1.042 | Acc: 73.806% (14218/19264)
Loss: 1.044 | Acc: 73.702% (18915/25664)
Loss: 1.054 | Acc: 73.384% (23530/32064)
Loss: 1.060 | Acc: 73.185% (28150/38464)
Loss: 1.065 | Acc: 73.005% (32753/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3737, Accuracy: 6261/10000 (62.61%)

Epoch: 71
Loss: 1.098 | Acc: 70.312% (45/64)
Loss: 1.027 | Acc: 73.979% (4782/6464)
Loss: 1.034 | Acc: 73.974% (9516/12864)
Loss: 1.043 | Acc: 73.723% (14202/19264)
Loss: 1.045 | Acc: 73.663% (18905/25664)
Loss: 1.047 | Acc: 73.678% (23624/32064)
Loss: 1.052 | Acc: 73.487% (28266/38464)
Loss: 1.052 | Acc: 73.411% (32935/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2600, Accuracy: 6634/10000 (66.34%)

Epoch: 72
Loss: 0.994 | Acc: 71.875% (46/64)
Loss: 1.025 | Acc: 74.010% (4784/6464)
Loss: 1.038 | Acc: 73.842% (9499/12864)
Loss: 1.047 | Acc: 73.526% (14164/19264)
Loss: 1.046 | Acc: 73.609% (18891/25664)
Loss: 1.045 | Acc: 73.693% (23629/32064)
Loss: 1.045 | Acc: 73.648% (28328/38464)
Loss: 1.048 | Acc: 73.607% (33023/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2823, Accuracy: 6677/10000 (66.77%)

Epoch: 73
Loss: 1.101 | Acc: 75.000% (48/64)
Loss: 1.030 | Acc: 74.118% (4791/6464)
Loss: 1.035 | Acc: 74.052% (9526/12864)
Loss: 1.041 | Acc: 73.879% (14232/19264)
Loss: 1.044 | Acc: 73.757% (18929/25664)
Loss: 1.043 | Acc: 73.771% (23654/32064)
Loss: 1.040 | Acc: 73.905% (28427/38464)
Loss: 1.040 | Acc: 73.941% (33173/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2304, Accuracy: 6814/10000 (68.14%)

Epoch: 74
Loss: 1.147 | Acc: 65.625% (42/64)
Loss: 1.022 | Acc: 74.072% (4788/6464)
Loss: 1.018 | Acc: 74.448% (9577/12864)
Loss: 1.024 | Acc: 74.398% (14332/19264)
Loss: 1.027 | Acc: 74.314% (19072/25664)
Loss: 1.024 | Acc: 74.485% (23883/32064)
Loss: 1.031 | Acc: 74.290% (28575/38464)
Loss: 1.030 | Acc: 74.340% (33352/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2997, Accuracy: 6520/10000 (65.20%)

Epoch: 75
Loss: 0.847 | Acc: 82.812% (53/64)
Loss: 1.008 | Acc: 75.325% (4869/6464)
Loss: 1.016 | Acc: 74.961% (9643/12864)
Loss: 1.018 | Acc: 74.803% (14410/19264)
Loss: 1.018 | Acc: 74.696% (19170/25664)
Loss: 1.016 | Acc: 74.719% (23958/32064)
Loss: 1.020 | Acc: 74.581% (28687/38464)
Loss: 1.021 | Acc: 74.585% (33462/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1814, Accuracy: 6989/10000 (69.89%)

Epoch: 76
Loss: 0.875 | Acc: 79.688% (51/64)
Loss: 0.979 | Acc: 75.727% (4895/6464)
Loss: 0.982 | Acc: 75.723% (9741/12864)
Loss: 0.994 | Acc: 75.529% (14550/19264)
Loss: 1.000 | Acc: 75.327% (19332/25664)
Loss: 1.007 | Acc: 75.134% (24091/32064)
Loss: 1.007 | Acc: 75.091% (28883/38464)
Loss: 1.005 | Acc: 75.158% (33719/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2225, Accuracy: 6782/10000 (67.82%)

Epoch: 77
Loss: 0.963 | Acc: 78.125% (50/64)
Loss: 0.980 | Acc: 75.511% (4881/6464)
Loss: 0.989 | Acc: 75.428% (9703/12864)
Loss: 0.990 | Acc: 75.446% (14534/19264)
Loss: 0.994 | Acc: 75.390% (19348/25664)
Loss: 0.994 | Acc: 75.393% (24174/32064)
Loss: 0.992 | Acc: 75.517% (29047/38464)
Loss: 0.993 | Acc: 75.484% (33865/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2137, Accuracy: 6889/10000 (68.89%)

Epoch: 78
Loss: 0.900 | Acc: 76.562% (49/64)
Loss: 0.972 | Acc: 76.485% (4944/6464)
Loss: 0.978 | Acc: 76.220% (9805/12864)
Loss: 0.989 | Acc: 75.929% (14627/19264)
Loss: 0.989 | Acc: 75.994% (19503/25664)
Loss: 0.987 | Acc: 75.970% (24359/32064)
Loss: 0.982 | Acc: 76.082% (29264/38464)
Loss: 0.984 | Acc: 76.039% (34114/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5409, Accuracy: 5678/10000 (56.78%)

Epoch: 79
Loss: 1.111 | Acc: 70.312% (45/64)
Loss: 0.946 | Acc: 77.058% (4981/6464)
Loss: 0.954 | Acc: 76.664% (9862/12864)
Loss: 0.959 | Acc: 76.511% (14739/19264)
Loss: 0.966 | Acc: 76.325% (19588/25664)
Loss: 0.969 | Acc: 76.276% (24457/32064)
Loss: 0.967 | Acc: 76.365% (29373/38464)
Loss: 0.965 | Acc: 76.438% (34293/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3252, Accuracy: 6361/10000 (63.61%)

Epoch: 80
Loss: 1.335 | Acc: 62.500% (40/64)
Loss: 0.987 | Acc: 75.495% (4880/6464)
Loss: 0.967 | Acc: 76.182% (9800/12864)
Loss: 0.963 | Acc: 76.334% (14705/19264)
Loss: 0.959 | Acc: 76.543% (19644/25664)
Loss: 0.956 | Acc: 76.634% (24572/32064)
Loss: 0.958 | Acc: 76.604% (29465/38464)
Loss: 0.958 | Acc: 76.634% (34381/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2060, Accuracy: 6974/10000 (69.74%)

Epoch: 81
Loss: 0.843 | Acc: 79.688% (51/64)
Loss: 0.929 | Acc: 77.150% (4987/6464)
Loss: 0.936 | Acc: 77.013% (9907/12864)
Loss: 0.938 | Acc: 77.009% (14835/19264)
Loss: 0.944 | Acc: 76.855% (19724/25664)
Loss: 0.941 | Acc: 77.052% (24706/32064)
Loss: 0.940 | Acc: 77.036% (29631/38464)
Loss: 0.944 | Acc: 76.941% (34519/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2211, Accuracy: 6996/10000 (69.96%)

Epoch: 82
Loss: 0.846 | Acc: 78.125% (50/64)
Loss: 0.933 | Acc: 77.537% (5012/6464)
Loss: 0.933 | Acc: 77.355% (9951/12864)
Loss: 0.923 | Acc: 77.528% (14935/19264)
Loss: 0.921 | Acc: 77.560% (19905/25664)
Loss: 0.923 | Acc: 77.492% (24847/32064)
Loss: 0.925 | Acc: 77.467% (29797/38464)
Loss: 0.925 | Acc: 77.492% (34766/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1644, Accuracy: 7125/10000 (71.25%)

Epoch: 83
Loss: 1.107 | Acc: 68.750% (44/64)
Loss: 0.875 | Acc: 78.388% (5067/6464)
Loss: 0.894 | Acc: 77.853% (10015/12864)
Loss: 0.889 | Acc: 78.213% (15067/19264)
Loss: 0.901 | Acc: 77.965% (20009/25664)
Loss: 0.900 | Acc: 78.000% (25010/32064)
Loss: 0.903 | Acc: 77.990% (29998/38464)
Loss: 0.904 | Acc: 78.034% (35009/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3679, Accuracy: 6387/10000 (63.87%)

Epoch: 84
Loss: 0.757 | Acc: 84.375% (54/64)
Loss: 0.883 | Acc: 78.512% (5075/6464)
Loss: 0.889 | Acc: 78.669% (10120/12864)
Loss: 0.890 | Acc: 78.545% (15131/19264)
Loss: 0.893 | Acc: 78.569% (20164/25664)
Loss: 0.884 | Acc: 78.761% (25254/32064)
Loss: 0.885 | Acc: 78.715% (30277/38464)
Loss: 0.888 | Acc: 78.589% (35258/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1681, Accuracy: 7205/10000 (72.05%)

Epoch: 85
Loss: 0.887 | Acc: 79.688% (51/64)
Loss: 0.856 | Acc: 79.301% (5126/6464)
Loss: 0.850 | Acc: 79.454% (10221/12864)
Loss: 0.852 | Acc: 79.418% (15299/19264)
Loss: 0.851 | Acc: 79.395% (20376/25664)
Loss: 0.851 | Acc: 79.460% (25478/32064)
Loss: 0.857 | Acc: 79.326% (30512/38464)
Loss: 0.862 | Acc: 79.184% (35525/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2937, Accuracy: 6773/10000 (67.73%)

Epoch: 86
Loss: 0.828 | Acc: 76.562% (49/64)
Loss: 0.818 | Acc: 80.074% (5176/6464)
Loss: 0.815 | Acc: 80.185% (10315/12864)
Loss: 0.811 | Acc: 80.342% (15477/19264)
Loss: 0.823 | Acc: 80.097% (20556/25664)
Loss: 0.829 | Acc: 79.909% (25622/32064)
Loss: 0.835 | Acc: 79.734% (30669/38464)
Loss: 0.839 | Acc: 79.596% (35710/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2358, Accuracy: 6955/10000 (69.55%)

Epoch: 87
Loss: 0.666 | Acc: 84.375% (54/64)
Loss: 0.805 | Acc: 80.631% (5212/6464)
Loss: 0.787 | Acc: 80.970% (10416/12864)
Loss: 0.800 | Acc: 80.586% (15524/19264)
Loss: 0.808 | Acc: 80.354% (20622/25664)
Loss: 0.809 | Acc: 80.321% (25754/32064)
Loss: 0.808 | Acc: 80.353% (30907/38464)
Loss: 0.804 | Acc: 80.459% (36097/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2113, Accuracy: 7151/10000 (71.51%)

Epoch: 88
Loss: 0.563 | Acc: 85.938% (55/64)
Loss: 0.773 | Acc: 81.126% (5244/6464)
Loss: 0.774 | Acc: 81.149% (10439/12864)
Loss: 0.772 | Acc: 81.110% (15625/19264)
Loss: 0.777 | Acc: 80.934% (20771/25664)
Loss: 0.778 | Acc: 80.873% (25931/32064)
Loss: 0.777 | Acc: 80.935% (31131/38464)
Loss: 0.780 | Acc: 80.882% (36287/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2233, Accuracy: 7155/10000 (71.55%)

Epoch: 89
Loss: 0.650 | Acc: 82.812% (53/64)
Loss: 0.730 | Acc: 82.116% (5308/6464)
Loss: 0.740 | Acc: 81.802% (10523/12864)
Loss: 0.741 | Acc: 81.831% (15764/19264)
Loss: 0.741 | Acc: 81.792% (20991/25664)
Loss: 0.744 | Acc: 81.621% (26171/32064)
Loss: 0.744 | Acc: 81.637% (31401/38464)
Loss: 0.745 | Acc: 81.613% (36615/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2451, Accuracy: 7173/10000 (71.73%)

Epoch: 90
Loss: 0.751 | Acc: 78.125% (50/64)
Loss: 0.682 | Acc: 83.106% (5372/6464)
Loss: 0.699 | Acc: 82.579% (10623/12864)
Loss: 0.699 | Acc: 82.636% (15919/19264)
Loss: 0.698 | Acc: 82.622% (21204/25664)
Loss: 0.702 | Acc: 82.516% (26458/32064)
Loss: 0.706 | Acc: 82.412% (31699/38464)
Loss: 0.705 | Acc: 82.478% (37003/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2437, Accuracy: 7207/10000 (72.07%)

Epoch: 91
Loss: 0.420 | Acc: 89.062% (57/64)
Loss: 0.656 | Acc: 82.983% (5364/6464)
Loss: 0.654 | Acc: 83.248% (10709/12864)
Loss: 0.666 | Acc: 82.901% (15970/19264)
Loss: 0.664 | Acc: 83.000% (21301/25664)
Loss: 0.664 | Acc: 82.984% (26608/32064)
Loss: 0.664 | Acc: 83.039% (31940/38464)
Loss: 0.663 | Acc: 83.122% (37292/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2818, Accuracy: 7194/10000 (71.94%)

Epoch: 92
Loss: 0.888 | Acc: 81.250% (52/64)
Loss: 0.612 | Acc: 83.895% (5423/6464)
Loss: 0.602 | Acc: 84.266% (10840/12864)
Loss: 0.603 | Acc: 84.401% (16259/19264)
Loss: 0.609 | Acc: 84.258% (21624/25664)
Loss: 0.619 | Acc: 84.001% (26934/32064)
Loss: 0.619 | Acc: 83.951% (32291/38464)
Loss: 0.619 | Acc: 83.940% (37659/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3280, Accuracy: 7137/10000 (71.37%)

Epoch: 93
Loss: 0.470 | Acc: 84.375% (54/64)
Loss: 0.558 | Acc: 85.056% (5498/6464)
Loss: 0.550 | Acc: 85.518% (11001/12864)
Loss: 0.552 | Acc: 85.486% (16468/19264)
Loss: 0.559 | Acc: 85.310% (21894/25664)
Loss: 0.558 | Acc: 85.401% (27383/32064)
Loss: 0.564 | Acc: 85.251% (32791/38464)
Loss: 0.564 | Acc: 85.242% (38243/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3663, Accuracy: 7148/10000 (71.48%)

Epoch: 94
Loss: 0.405 | Acc: 89.062% (57/64)
Loss: 0.502 | Acc: 86.463% (5589/6464)
Loss: 0.510 | Acc: 86.350% (11108/12864)
Loss: 0.512 | Acc: 86.316% (16628/19264)
Loss: 0.511 | Acc: 86.308% (22150/25664)
Loss: 0.512 | Acc: 86.324% (27679/32064)
Loss: 0.511 | Acc: 86.424% (33242/38464)
Loss: 0.507 | Acc: 86.550% (38830/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4252, Accuracy: 7105/10000 (71.05%)

Epoch: 95
Loss: 0.323 | Acc: 90.625% (58/64)
Loss: 0.444 | Acc: 87.763% (5673/6464)
Loss: 0.457 | Acc: 87.500% (11256/12864)
Loss: 0.461 | Acc: 87.490% (16854/19264)
Loss: 0.460 | Acc: 87.555% (22470/25664)
Loss: 0.465 | Acc: 87.475% (28048/32064)
Loss: 0.466 | Acc: 87.464% (33642/38464)
Loss: 0.463 | Acc: 87.531% (39270/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4625, Accuracy: 7018/10000 (70.18%)

Epoch: 96
Loss: 0.365 | Acc: 90.625% (58/64)
Loss: 0.433 | Acc: 87.809% (5676/6464)
Loss: 0.429 | Acc: 87.951% (11314/12864)
Loss: 0.432 | Acc: 87.967% (16946/19264)
Loss: 0.429 | Acc: 88.046% (22596/25664)
Loss: 0.425 | Acc: 88.233% (28291/32064)
Loss: 0.424 | Acc: 88.257% (33947/38464)
Loss: 0.422 | Acc: 88.311% (39620/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4927, Accuracy: 6997/10000 (69.97%)

Epoch: 97
Loss: 0.502 | Acc: 81.250% (52/64)
Loss: 0.394 | Acc: 88.784% (5739/6464)
Loss: 0.397 | Acc: 88.954% (11443/12864)
Loss: 0.399 | Acc: 88.793% (17105/19264)
Loss: 0.392 | Acc: 88.965% (22832/25664)
Loss: 0.390 | Acc: 89.059% (28556/32064)
Loss: 0.388 | Acc: 89.130% (34283/38464)
Loss: 0.389 | Acc: 89.076% (39963/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4940, Accuracy: 7044/10000 (70.44%)
torch.Size([100, 10])
Test set: Average loss: 1.4940, Accuracy: 7044/10000 (70.44%)

Epoch: 98
Loss: 0.320 | Acc: 92.188% (59/64)
Loss: 0.380 | Acc: 89.511% (5786/6464)
Loss: 0.383 | Acc: 89.280% (11485/12864)
Loss: 0.379 | Acc: 89.457% (17233/19264)
Loss: 0.379 | Acc: 89.487% (22966/25664)
Loss: 0.377 | Acc: 89.521% (28704/32064)
Loss: 0.376 | Acc: 89.546% (34443/38464)
Loss: 0.374 | Acc: 89.577% (40188/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4958, Accuracy: 7022/10000 (70.22%)
torch.Size([100, 10])
Test set: Average loss: 1.4958, Accuracy: 7022/10000 (70.22%)

Epoch: 99
Loss: 0.218 | Acc: 95.312% (61/64)
Loss: 0.356 | Acc: 90.084% (5823/6464)
Loss: 0.367 | Acc: 89.824% (11555/12864)
Loss: 0.364 | Acc: 89.862% (17311/19264)
Loss: 0.363 | Acc: 89.959% (23087/25664)
Loss: 0.365 | Acc: 89.873% (28817/32064)
Loss: 0.364 | Acc: 89.840% (34556/38464)
Loss: 0.364 | Acc: 89.836% (40304/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5091, Accuracy: 7027/10000 (70.27%)
torch.Size([100, 10])
Test set: Average loss: 1.5091, Accuracy: 7027/10000 (70.27%)

Epoch: 100
Loss: 0.383 | Acc: 89.062% (57/64)
Loss: 1.726 | Acc: 44.322% (2865/6464)
Loss: 1.529 | Acc: 53.242% (6849/12864)
Loss: 1.429 | Acc: 57.610% (11098/19264)
Loss: 1.376 | Acc: 59.991% (15396/25664)
Loss: 1.341 | Acc: 61.486% (19715/32064)
Loss: 1.315 | Acc: 62.539% (24055/38464)
Loss: 1.300 | Acc: 63.236% (28370/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4174, Accuracy: 6089/10000 (60.89%)

Epoch: 101
Loss: 1.367 | Acc: 64.062% (41/64)
Loss: 1.146 | Acc: 69.864% (4516/6464)
Loss: 1.154 | Acc: 69.496% (8940/12864)
Loss: 1.149 | Acc: 69.643% (13416/19264)
Loss: 1.148 | Acc: 69.783% (17909/25664)
Loss: 1.147 | Acc: 69.792% (22378/32064)
Loss: 1.145 | Acc: 69.806% (26850/38464)
Loss: 1.147 | Acc: 69.853% (31339/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3783, Accuracy: 6136/10000 (61.36%)

Epoch: 102
Loss: 0.987 | Acc: 70.312% (45/64)
Loss: 1.133 | Acc: 70.312% (4545/6464)
Loss: 1.123 | Acc: 70.779% (9105/12864)
Loss: 1.125 | Acc: 70.660% (13612/19264)
Loss: 1.127 | Acc: 70.519% (18098/25664)
Loss: 1.126 | Acc: 70.550% (22621/32064)
Loss: 1.130 | Acc: 70.419% (27086/38464)
Loss: 1.128 | Acc: 70.553% (31653/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5726, Accuracy: 5393/10000 (53.93%)

Epoch: 103
Loss: 0.979 | Acc: 75.000% (48/64)
Loss: 1.130 | Acc: 70.792% (4576/6464)
Loss: 1.131 | Acc: 70.927% (9124/12864)
Loss: 1.128 | Acc: 70.894% (13657/19264)
Loss: 1.120 | Acc: 71.084% (18243/25664)
Loss: 1.123 | Acc: 71.070% (22788/32064)
Loss: 1.127 | Acc: 70.999% (27309/38464)
Loss: 1.126 | Acc: 70.923% (31819/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8593, Accuracy: 4544/10000 (45.44%)

Epoch: 104
Loss: 1.243 | Acc: 62.500% (40/64)
Loss: 1.087 | Acc: 72.014% (4655/6464)
Loss: 1.106 | Acc: 71.525% (9201/12864)
Loss: 1.106 | Acc: 71.429% (13760/19264)
Loss: 1.114 | Acc: 71.154% (18261/25664)
Loss: 1.117 | Acc: 71.092% (22795/32064)
Loss: 1.121 | Acc: 70.970% (27298/38464)
Loss: 1.123 | Acc: 70.883% (31801/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3695, Accuracy: 6287/10000 (62.87%)

Epoch: 105
Loss: 1.506 | Acc: 56.250% (36/64)
Loss: 1.129 | Acc: 70.838% (4579/6464)
Loss: 1.111 | Acc: 71.416% (9187/12864)
Loss: 1.113 | Acc: 71.299% (13735/19264)
Loss: 1.106 | Acc: 71.372% (18317/25664)
Loss: 1.109 | Acc: 71.264% (22850/32064)
Loss: 1.115 | Acc: 71.126% (27358/38464)
Loss: 1.117 | Acc: 71.039% (31871/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4983, Accuracy: 5694/10000 (56.94%)

Epoch: 106
Loss: 1.208 | Acc: 65.625% (42/64)
Loss: 1.115 | Acc: 71.442% (4618/6464)
Loss: 1.124 | Acc: 71.300% (9172/12864)
Loss: 1.117 | Acc: 71.429% (13760/19264)
Loss: 1.117 | Acc: 71.466% (18341/25664)
Loss: 1.116 | Acc: 71.426% (22902/32064)
Loss: 1.120 | Acc: 71.267% (27412/38464)
Loss: 1.121 | Acc: 71.182% (31935/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7279, Accuracy: 5123/10000 (51.23%)

Epoch: 107
Loss: 1.099 | Acc: 71.875% (46/64)
Loss: 1.070 | Acc: 72.370% (4678/6464)
Loss: 1.092 | Acc: 71.595% (9210/12864)
Loss: 1.102 | Acc: 71.377% (13750/19264)
Loss: 1.111 | Acc: 71.131% (18255/25664)
Loss: 1.111 | Acc: 71.064% (22786/32064)
Loss: 1.115 | Acc: 70.882% (27264/38464)
Loss: 1.116 | Acc: 70.988% (31848/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6987, Accuracy: 5128/10000 (51.28%)

Epoch: 108
Loss: 1.461 | Acc: 60.938% (39/64)
Loss: 1.105 | Acc: 71.906% (4648/6464)
Loss: 1.104 | Acc: 71.758% (9231/12864)
Loss: 1.110 | Acc: 71.543% (13782/19264)
Loss: 1.109 | Acc: 71.626% (18382/25664)
Loss: 1.108 | Acc: 71.672% (22981/32064)
Loss: 1.112 | Acc: 71.490% (27498/38464)
Loss: 1.112 | Acc: 71.563% (32106/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9238, Accuracy: 5009/10000 (50.09%)

Epoch: 109
Loss: 1.255 | Acc: 65.625% (42/64)
Loss: 1.126 | Acc: 70.823% (4578/6464)
Loss: 1.111 | Acc: 71.494% (9197/12864)
Loss: 1.111 | Acc: 71.480% (13770/19264)
Loss: 1.110 | Acc: 71.481% (18345/25664)
Loss: 1.111 | Acc: 71.448% (22909/32064)
Loss: 1.112 | Acc: 71.386% (27458/38464)
Loss: 1.113 | Acc: 71.360% (32015/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5664, Accuracy: 5412/10000 (54.12%)

Epoch: 110
Loss: 1.307 | Acc: 67.188% (43/64)
Loss: 1.100 | Acc: 71.736% (4637/6464)
Loss: 1.088 | Acc: 72.170% (9284/12864)
Loss: 1.087 | Acc: 72.186% (13906/19264)
Loss: 1.092 | Acc: 72.070% (18496/25664)
Loss: 1.098 | Acc: 71.965% (23075/32064)
Loss: 1.100 | Acc: 71.943% (27672/38464)
Loss: 1.100 | Acc: 71.853% (32236/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3364, Accuracy: 6370/10000 (63.70%)

Epoch: 111
Loss: 1.016 | Acc: 71.875% (46/64)
Loss: 1.105 | Acc: 71.318% (4610/6464)
Loss: 1.103 | Acc: 71.634% (9215/12864)
Loss: 1.099 | Acc: 71.828% (13837/19264)
Loss: 1.095 | Acc: 71.840% (18437/25664)
Loss: 1.102 | Acc: 71.644% (22972/32064)
Loss: 1.102 | Acc: 71.664% (27565/38464)
Loss: 1.104 | Acc: 71.663% (32151/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5200, Accuracy: 5567/10000 (55.67%)

Epoch: 112
Loss: 1.235 | Acc: 64.062% (41/64)
Loss: 1.097 | Acc: 71.844% (4644/6464)
Loss: 1.078 | Acc: 72.264% (9296/12864)
Loss: 1.086 | Acc: 72.145% (13898/19264)
Loss: 1.088 | Acc: 72.097% (18503/25664)
Loss: 1.089 | Acc: 72.118% (23124/32064)
Loss: 1.095 | Acc: 71.979% (27686/38464)
Loss: 1.099 | Acc: 71.799% (32212/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5053, Accuracy: 5659/10000 (56.59%)

Epoch: 113
Loss: 1.144 | Acc: 70.312% (45/64)
Loss: 1.067 | Acc: 73.082% (4724/6464)
Loss: 1.081 | Acc: 72.388% (9312/12864)
Loss: 1.082 | Acc: 72.394% (13946/19264)
Loss: 1.082 | Acc: 72.346% (18567/25664)
Loss: 1.080 | Acc: 72.374% (23206/32064)
Loss: 1.086 | Acc: 72.174% (27761/38464)
Loss: 1.090 | Acc: 72.078% (32337/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4081, Accuracy: 6084/10000 (60.84%)

Epoch: 114
Loss: 1.104 | Acc: 70.312% (45/64)
Loss: 1.070 | Acc: 72.927% (4714/6464)
Loss: 1.075 | Acc: 72.520% (9329/12864)
Loss: 1.078 | Acc: 72.498% (13966/19264)
Loss: 1.079 | Acc: 72.510% (18609/25664)
Loss: 1.083 | Acc: 72.411% (23218/32064)
Loss: 1.089 | Acc: 72.190% (27767/38464)
Loss: 1.091 | Acc: 72.203% (32393/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6302, Accuracy: 5534/10000 (55.34%)

Epoch: 115
Loss: 1.052 | Acc: 76.562% (49/64)
Loss: 1.048 | Acc: 73.391% (4744/6464)
Loss: 1.064 | Acc: 72.940% (9383/12864)
Loss: 1.076 | Acc: 72.623% (13990/19264)
Loss: 1.083 | Acc: 72.514% (18610/25664)
Loss: 1.082 | Acc: 72.499% (23246/32064)
Loss: 1.079 | Acc: 72.585% (27919/38464)
Loss: 1.078 | Acc: 72.559% (32553/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3655, Accuracy: 6392/10000 (63.92%)

Epoch: 116
Loss: 1.008 | Acc: 73.438% (47/64)
Loss: 1.057 | Acc: 73.298% (4738/6464)
Loss: 1.062 | Acc: 73.189% (9415/12864)
Loss: 1.066 | Acc: 73.059% (14074/19264)
Loss: 1.073 | Acc: 72.861% (18699/25664)
Loss: 1.076 | Acc: 72.889% (23371/32064)
Loss: 1.076 | Acc: 72.873% (28030/38464)
Loss: 1.076 | Acc: 72.827% (32673/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4844, Accuracy: 5637/10000 (56.37%)

Epoch: 117
Loss: 0.939 | Acc: 75.000% (48/64)
Loss: 1.089 | Acc: 71.844% (4644/6464)
Loss: 1.092 | Acc: 72.062% (9270/12864)
Loss: 1.079 | Acc: 72.337% (13935/19264)
Loss: 1.077 | Acc: 72.600% (18632/25664)
Loss: 1.083 | Acc: 72.383% (23209/32064)
Loss: 1.077 | Acc: 72.590% (27921/38464)
Loss: 1.073 | Acc: 72.729% (32629/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2810, Accuracy: 6564/10000 (65.64%)

Epoch: 118
Loss: 1.336 | Acc: 68.750% (44/64)
Loss: 1.033 | Acc: 74.118% (4791/6464)
Loss: 1.045 | Acc: 73.927% (9510/12864)
Loss: 1.053 | Acc: 73.702% (14198/19264)
Loss: 1.055 | Acc: 73.570% (18881/25664)
Loss: 1.061 | Acc: 73.300% (23503/32064)
Loss: 1.062 | Acc: 73.243% (28172/38464)
Loss: 1.063 | Acc: 73.226% (32852/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6422, Accuracy: 5274/10000 (52.74%)

Epoch: 119
Loss: 1.058 | Acc: 70.312% (45/64)
Loss: 1.049 | Acc: 73.592% (4757/6464)
Loss: 1.053 | Acc: 73.329% (9433/12864)
Loss: 1.050 | Acc: 73.432% (14146/19264)
Loss: 1.057 | Acc: 73.223% (18792/25664)
Loss: 1.060 | Acc: 73.185% (23466/32064)
Loss: 1.059 | Acc: 73.201% (28156/38464)
Loss: 1.058 | Acc: 73.266% (32870/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4710, Accuracy: 5853/10000 (58.53%)

Epoch: 120
Loss: 0.971 | Acc: 75.000% (48/64)
Loss: 1.059 | Acc: 73.561% (4755/6464)
Loss: 1.051 | Acc: 73.562% (9463/12864)
Loss: 1.044 | Acc: 73.874% (14231/19264)
Loss: 1.045 | Acc: 73.753% (18928/25664)
Loss: 1.042 | Acc: 73.756% (23649/32064)
Loss: 1.044 | Acc: 73.770% (28375/38464)
Loss: 1.047 | Acc: 73.763% (33093/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5077, Accuracy: 5849/10000 (58.49%)

Epoch: 121
Loss: 1.489 | Acc: 62.500% (40/64)
Loss: 1.001 | Acc: 75.124% (4856/6464)
Loss: 1.028 | Acc: 74.331% (9562/12864)
Loss: 1.039 | Acc: 74.014% (14258/19264)
Loss: 1.044 | Acc: 73.796% (18939/25664)
Loss: 1.037 | Acc: 74.014% (23732/32064)
Loss: 1.040 | Acc: 73.887% (28420/38464)
Loss: 1.044 | Acc: 73.763% (33093/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2735, Accuracy: 6618/10000 (66.18%)

Epoch: 122
Loss: 1.046 | Acc: 71.875% (46/64)
Loss: 1.021 | Acc: 74.675% (4827/6464)
Loss: 1.020 | Acc: 74.689% (9608/12864)
Loss: 1.021 | Acc: 74.605% (14372/19264)
Loss: 1.020 | Acc: 74.606% (19147/25664)
Loss: 1.024 | Acc: 74.476% (23880/32064)
Loss: 1.026 | Acc: 74.428% (28628/38464)
Loss: 1.029 | Acc: 74.387% (33373/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4040, Accuracy: 6126/10000 (61.26%)

Epoch: 123
Loss: 0.918 | Acc: 75.000% (48/64)
Loss: 0.995 | Acc: 75.046% (4851/6464)
Loss: 1.010 | Acc: 74.860% (9630/12864)
Loss: 1.012 | Acc: 74.849% (14419/19264)
Loss: 1.011 | Acc: 74.875% (19216/25664)
Loss: 1.016 | Acc: 74.719% (23958/32064)
Loss: 1.019 | Acc: 74.602% (28695/38464)
Loss: 1.021 | Acc: 74.588% (33463/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1671, Accuracy: 7094/10000 (70.94%)

Epoch: 124
Loss: 0.867 | Acc: 79.688% (51/64)
Loss: 1.006 | Acc: 75.511% (4881/6464)
Loss: 0.995 | Acc: 75.715% (9740/12864)
Loss: 1.005 | Acc: 75.420% (14529/19264)
Loss: 1.004 | Acc: 75.370% (19343/25664)
Loss: 1.007 | Acc: 75.206% (24114/32064)
Loss: 1.006 | Acc: 75.286% (28958/38464)
Loss: 1.013 | Acc: 75.094% (33690/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3180, Accuracy: 6518/10000 (65.18%)

Epoch: 125
Loss: 1.113 | Acc: 71.875% (46/64)
Loss: 0.985 | Acc: 75.696% (4893/6464)
Loss: 0.987 | Acc: 75.630% (9729/12864)
Loss: 1.004 | Acc: 75.088% (14465/19264)
Loss: 1.003 | Acc: 75.171% (19292/25664)
Loss: 1.006 | Acc: 75.228% (24121/32064)
Loss: 1.005 | Acc: 75.260% (28948/38464)
Loss: 1.007 | Acc: 75.160% (33720/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3655, Accuracy: 6242/10000 (62.42%)

Epoch: 126
Loss: 0.910 | Acc: 70.312% (45/64)
Loss: 0.966 | Acc: 76.098% (4919/6464)
Loss: 0.967 | Acc: 76.213% (9804/12864)
Loss: 0.979 | Acc: 75.846% (14611/19264)
Loss: 0.985 | Acc: 75.694% (19426/25664)
Loss: 0.988 | Acc: 75.608% (24243/32064)
Loss: 0.988 | Acc: 75.619% (29086/38464)
Loss: 0.990 | Acc: 75.542% (33891/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1651, Accuracy: 7129/10000 (71.29%)

Epoch: 127
Loss: 0.852 | Acc: 81.250% (52/64)
Loss: 0.950 | Acc: 76.330% (4934/6464)
Loss: 0.970 | Acc: 75.878% (9761/12864)
Loss: 0.980 | Acc: 75.628% (14569/19264)
Loss: 0.982 | Acc: 75.697% (19427/25664)
Loss: 0.988 | Acc: 75.527% (24217/32064)
Loss: 0.982 | Acc: 75.712% (29122/38464)
Loss: 0.979 | Acc: 75.854% (34031/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5299, Accuracy: 5701/10000 (57.01%)

Epoch: 128
Loss: 1.293 | Acc: 68.750% (44/64)
Loss: 0.939 | Acc: 76.903% (4971/6464)
Loss: 0.957 | Acc: 76.376% (9825/12864)
Loss: 0.959 | Acc: 76.319% (14702/19264)
Loss: 0.961 | Acc: 76.352% (19595/25664)
Loss: 0.966 | Acc: 76.338% (24477/32064)
Loss: 0.968 | Acc: 76.238% (29324/38464)
Loss: 0.970 | Acc: 76.161% (34169/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2463, Accuracy: 6830/10000 (68.30%)

Epoch: 129
Loss: 0.925 | Acc: 78.125% (50/64)
Loss: 0.928 | Acc: 77.351% (5000/6464)
Loss: 0.943 | Acc: 76.975% (9902/12864)
Loss: 0.934 | Acc: 77.123% (14857/19264)
Loss: 0.940 | Acc: 76.905% (19737/25664)
Loss: 0.953 | Acc: 76.506% (24531/32064)
Loss: 0.958 | Acc: 76.446% (29404/38464)
Loss: 0.959 | Acc: 76.493% (34318/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2378, Accuracy: 6881/10000 (68.81%)

Epoch: 130
Loss: 1.024 | Acc: 75.000% (48/64)
Loss: 0.941 | Acc: 76.671% (4956/6464)
Loss: 0.959 | Acc: 76.438% (9833/12864)
Loss: 0.951 | Acc: 76.760% (14787/19264)
Loss: 0.949 | Acc: 76.792% (19708/25664)
Loss: 0.945 | Acc: 76.893% (24655/32064)
Loss: 0.944 | Acc: 76.942% (29595/38464)
Loss: 0.944 | Acc: 76.904% (34502/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3091, Accuracy: 6516/10000 (65.16%)

Epoch: 131
Loss: 0.943 | Acc: 75.000% (48/64)
Loss: 0.906 | Acc: 78.202% (5055/6464)
Loss: 0.904 | Acc: 78.257% (10067/12864)
Loss: 0.909 | Acc: 78.203% (15065/19264)
Loss: 0.912 | Acc: 77.973% (20011/25664)
Loss: 0.919 | Acc: 77.816% (24951/32064)
Loss: 0.920 | Acc: 77.696% (29885/38464)
Loss: 0.924 | Acc: 77.574% (34803/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1842, Accuracy: 7044/10000 (70.44%)

Epoch: 132
Loss: 1.044 | Acc: 75.000% (48/64)
Loss: 0.895 | Acc: 78.388% (5067/6464)
Loss: 0.905 | Acc: 77.923% (10024/12864)
Loss: 0.902 | Acc: 77.912% (15009/19264)
Loss: 0.907 | Acc: 77.813% (19970/25664)
Loss: 0.910 | Acc: 77.757% (24932/32064)
Loss: 0.908 | Acc: 77.862% (29949/38464)
Loss: 0.909 | Acc: 77.895% (34947/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2401, Accuracy: 6897/10000 (68.97%)

Epoch: 133
Loss: 0.860 | Acc: 79.688% (51/64)
Loss: 0.861 | Acc: 79.378% (5131/6464)
Loss: 0.880 | Acc: 78.762% (10132/12864)
Loss: 0.892 | Acc: 78.338% (15091/19264)
Loss: 0.894 | Acc: 78.328% (20102/25664)
Loss: 0.898 | Acc: 78.209% (25077/32064)
Loss: 0.897 | Acc: 78.182% (30072/38464)
Loss: 0.895 | Acc: 78.314% (35135/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2671, Accuracy: 6853/10000 (68.53%)

Epoch: 134
Loss: 1.003 | Acc: 75.000% (48/64)
Loss: 0.859 | Acc: 79.595% (5145/6464)
Loss: 0.855 | Acc: 79.680% (10250/12864)
Loss: 0.858 | Acc: 79.469% (15309/19264)
Loss: 0.861 | Acc: 79.387% (20374/25664)
Loss: 0.867 | Acc: 79.126% (25371/32064)
Loss: 0.867 | Acc: 79.155% (30446/38464)
Loss: 0.867 | Acc: 79.132% (35502/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1759, Accuracy: 7124/10000 (71.24%)

Epoch: 135
Loss: 1.010 | Acc: 75.000% (48/64)
Loss: 0.810 | Acc: 80.244% (5187/6464)
Loss: 0.820 | Acc: 80.107% (10305/12864)
Loss: 0.830 | Acc: 79.838% (15380/19264)
Loss: 0.835 | Acc: 79.695% (20453/25664)
Loss: 0.837 | Acc: 79.560% (25510/32064)
Loss: 0.845 | Acc: 79.370% (30529/38464)
Loss: 0.843 | Acc: 79.478% (35657/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1802, Accuracy: 7186/10000 (71.86%)

Epoch: 136
Loss: 1.249 | Acc: 67.188% (43/64)
Loss: 0.807 | Acc: 80.043% (5174/6464)
Loss: 0.807 | Acc: 80.100% (10304/12864)
Loss: 0.805 | Acc: 80.290% (15467/19264)
Loss: 0.812 | Acc: 80.194% (20581/25664)
Loss: 0.814 | Acc: 80.143% (25697/32064)
Loss: 0.820 | Acc: 80.010% (30775/38464)
Loss: 0.820 | Acc: 80.055% (35916/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3129, Accuracy: 6775/10000 (67.75%)

Epoch: 137
Loss: 0.733 | Acc: 82.812% (53/64)
Loss: 0.774 | Acc: 80.894% (5229/6464)
Loss: 0.775 | Acc: 81.133% (10437/12864)
Loss: 0.781 | Acc: 81.016% (15607/19264)
Loss: 0.779 | Acc: 80.993% (20786/25664)
Loss: 0.786 | Acc: 80.823% (25915/32064)
Loss: 0.791 | Acc: 80.691% (31037/38464)
Loss: 0.791 | Acc: 80.740% (36223/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3112, Accuracy: 6767/10000 (67.67%)

Epoch: 138
Loss: 0.855 | Acc: 79.688% (51/64)
Loss: 0.745 | Acc: 81.931% (5296/6464)
Loss: 0.751 | Acc: 81.545% (10490/12864)
Loss: 0.749 | Acc: 81.608% (15721/19264)
Loss: 0.749 | Acc: 81.581% (20937/25664)
Loss: 0.757 | Acc: 81.378% (26093/32064)
Loss: 0.752 | Acc: 81.489% (31344/38464)
Loss: 0.755 | Acc: 81.415% (36526/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2386, Accuracy: 7156/10000 (71.56%)

Epoch: 139
Loss: 0.555 | Acc: 87.500% (56/64)
Loss: 0.700 | Acc: 82.596% (5339/6464)
Loss: 0.705 | Acc: 82.509% (10614/12864)
Loss: 0.709 | Acc: 82.413% (15876/19264)
Loss: 0.718 | Acc: 82.099% (21070/25664)
Loss: 0.721 | Acc: 82.061% (26312/32064)
Loss: 0.721 | Acc: 82.038% (31555/38464)
Loss: 0.723 | Acc: 82.006% (36791/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2389, Accuracy: 7170/10000 (71.70%)

Epoch: 140
Loss: 0.517 | Acc: 87.500% (56/64)
Loss: 0.658 | Acc: 83.524% (5399/6464)
Loss: 0.673 | Acc: 82.960% (10672/12864)
Loss: 0.679 | Acc: 82.973% (15984/19264)
Loss: 0.682 | Acc: 82.867% (21267/25664)
Loss: 0.679 | Acc: 82.984% (26608/32064)
Loss: 0.682 | Acc: 82.901% (31887/38464)
Loss: 0.683 | Acc: 82.897% (37191/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2673, Accuracy: 7202/10000 (72.02%)

Epoch: 141
Loss: 0.562 | Acc: 87.500% (56/64)
Loss: 0.603 | Acc: 85.025% (5496/6464)
Loss: 0.619 | Acc: 84.484% (10868/12864)
Loss: 0.631 | Acc: 83.991% (16180/19264)
Loss: 0.638 | Acc: 83.740% (21491/25664)
Loss: 0.635 | Acc: 83.795% (26868/32064)
Loss: 0.633 | Acc: 83.855% (32254/38464)
Loss: 0.638 | Acc: 83.671% (37538/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3022, Accuracy: 7171/10000 (71.71%)

Epoch: 142
Loss: 0.585 | Acc: 85.938% (55/64)
Loss: 0.598 | Acc: 84.158% (5440/6464)
Loss: 0.586 | Acc: 84.841% (10914/12864)
Loss: 0.595 | Acc: 84.593% (16296/19264)
Loss: 0.589 | Acc: 84.846% (21775/25664)
Loss: 0.588 | Acc: 84.849% (27206/32064)
Loss: 0.591 | Acc: 84.820% (32625/38464)
Loss: 0.592 | Acc: 84.801% (38045/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3621, Accuracy: 7137/10000 (71.37%)

Epoch: 143
Loss: 0.498 | Acc: 89.062% (57/64)
Loss: 0.538 | Acc: 85.845% (5549/6464)
Loss: 0.541 | Acc: 85.743% (11030/12864)
Loss: 0.539 | Acc: 85.927% (16553/19264)
Loss: 0.544 | Acc: 85.727% (22001/25664)
Loss: 0.544 | Acc: 85.735% (27490/32064)
Loss: 0.543 | Acc: 85.782% (32995/38464)
Loss: 0.545 | Acc: 85.741% (38467/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3806, Accuracy: 7094/10000 (70.94%)

Epoch: 144
Loss: 0.558 | Acc: 85.938% (55/64)
Loss: 0.491 | Acc: 87.098% (5630/6464)
Loss: 0.497 | Acc: 86.754% (11160/12864)
Loss: 0.497 | Acc: 86.820% (16725/19264)
Loss: 0.497 | Acc: 86.736% (22260/25664)
Loss: 0.493 | Acc: 86.829% (27841/32064)
Loss: 0.493 | Acc: 86.798% (33386/38464)
Loss: 0.493 | Acc: 86.816% (38949/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4232, Accuracy: 7117/10000 (71.17%)

Epoch: 145
Loss: 0.427 | Acc: 90.625% (58/64)
Loss: 0.442 | Acc: 87.748% (5672/6464)
Loss: 0.439 | Acc: 88.021% (11323/12864)
Loss: 0.440 | Acc: 87.998% (16952/19264)
Loss: 0.443 | Acc: 87.890% (22556/25664)
Loss: 0.441 | Acc: 87.983% (28211/32064)
Loss: 0.443 | Acc: 87.932% (33822/38464)
Loss: 0.441 | Acc: 88.008% (39484/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4807, Accuracy: 7060/10000 (70.60%)

Epoch: 146
Loss: 0.531 | Acc: 82.812% (53/64)
Loss: 0.385 | Acc: 89.356% (5776/6464)
Loss: 0.397 | Acc: 88.930% (11440/12864)
Loss: 0.406 | Acc: 88.684% (17084/19264)
Loss: 0.404 | Acc: 88.685% (22760/25664)
Loss: 0.404 | Acc: 88.694% (28439/32064)
Loss: 0.407 | Acc: 88.654% (34100/38464)
Loss: 0.406 | Acc: 88.715% (39801/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4924, Accuracy: 7107/10000 (71.07%)

Epoch: 147
Loss: 0.263 | Acc: 93.750% (60/64)
Loss: 0.360 | Acc: 89.743% (5801/6464)
Loss: 0.361 | Acc: 89.785% (11550/12864)
Loss: 0.370 | Acc: 89.452% (17232/19264)
Loss: 0.365 | Acc: 89.709% (23023/25664)
Loss: 0.367 | Acc: 89.596% (28728/32064)
Loss: 0.370 | Acc: 89.520% (34433/38464)
Loss: 0.372 | Acc: 89.482% (40145/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4897, Accuracy: 7071/10000 (70.71%)
torch.Size([100, 10])
Test set: Average loss: 1.4897, Accuracy: 7071/10000 (70.71%)

Epoch: 148
Loss: 0.215 | Acc: 93.750% (60/64)
Loss: 0.349 | Acc: 90.207% (5831/6464)
Loss: 0.350 | Acc: 90.120% (11593/12864)
Loss: 0.351 | Acc: 90.137% (17364/19264)
Loss: 0.350 | Acc: 90.239% (23159/25664)
Loss: 0.350 | Acc: 90.282% (28948/32064)
Loss: 0.352 | Acc: 90.173% (34684/38464)
Loss: 0.353 | Acc: 90.097% (40421/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5058, Accuracy: 7078/10000 (70.78%)
torch.Size([100, 10])
Test set: Average loss: 1.5058, Accuracy: 7078/10000 (70.78%)

Epoch: 149
Loss: 0.399 | Acc: 87.500% (56/64)
Loss: 0.360 | Acc: 89.496% (5785/6464)
Loss: 0.350 | Acc: 89.887% (11563/12864)
Loss: 0.348 | Acc: 90.096% (17356/19264)
Loss: 0.346 | Acc: 90.177% (23143/25664)
Loss: 0.345 | Acc: 90.148% (28905/32064)
Loss: 0.349 | Acc: 90.011% (34622/38464)
Loss: 0.348 | Acc: 90.079% (40413/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5108, Accuracy: 7080/10000 (70.80%)
torch.Size([100, 10])
Test set: Average loss: 1.5108, Accuracy: 7080/10000 (70.80%)

Epoch: 150
Loss: 0.278 | Acc: 92.188% (59/64)
Loss: 1.631 | Acc: 48.979% (3166/6464)
Loss: 1.460 | Acc: 56.266% (7238/12864)
Loss: 1.389 | Acc: 59.417% (11446/19264)
Loss: 1.346 | Acc: 61.339% (15742/25664)
Loss: 1.311 | Acc: 62.930% (20178/32064)
Loss: 1.285 | Acc: 63.943% (24595/38464)
Loss: 1.268 | Acc: 64.671% (29014/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6382, Accuracy: 5245/10000 (52.45%)

Epoch: 151
Loss: 0.905 | Acc: 78.125% (50/64)
Loss: 1.136 | Acc: 69.972% (4523/6464)
Loss: 1.137 | Acc: 70.017% (9007/12864)
Loss: 1.144 | Acc: 69.866% (13459/19264)
Loss: 1.143 | Acc: 69.751% (17901/25664)
Loss: 1.140 | Acc: 69.963% (22433/32064)
Loss: 1.137 | Acc: 70.102% (26964/38464)
Loss: 1.137 | Acc: 70.085% (31443/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8320, Accuracy: 4805/10000 (48.05%)

Epoch: 152
Loss: 1.178 | Acc: 68.750% (44/64)
Loss: 1.101 | Acc: 71.844% (4644/6464)
Loss: 1.087 | Acc: 72.054% (9269/12864)
Loss: 1.109 | Acc: 71.496% (13773/19264)
Loss: 1.118 | Acc: 71.010% (18224/25664)
Loss: 1.123 | Acc: 70.846% (22716/32064)
Loss: 1.123 | Acc: 70.890% (27267/38464)
Loss: 1.119 | Acc: 71.070% (31885/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4646, Accuracy: 5787/10000 (57.87%)

Epoch: 153
Loss: 1.016 | Acc: 68.750% (44/64)
Loss: 1.115 | Acc: 70.637% (4566/6464)
Loss: 1.094 | Acc: 71.642% (9216/12864)
Loss: 1.108 | Acc: 71.397% (13754/19264)
Loss: 1.105 | Acc: 71.657% (18390/25664)
Loss: 1.107 | Acc: 71.488% (22922/32064)
Loss: 1.111 | Acc: 71.384% (27457/38464)
Loss: 1.112 | Acc: 71.411% (32038/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2715, Accuracy: 6602/10000 (66.02%)

Epoch: 154
Loss: 1.258 | Acc: 70.312% (45/64)
Loss: 1.083 | Acc: 71.705% (4635/6464)
Loss: 1.096 | Acc: 71.323% (9175/12864)
Loss: 1.100 | Acc: 71.371% (13749/19264)
Loss: 1.105 | Acc: 71.357% (18313/25664)
Loss: 1.109 | Acc: 71.329% (22871/32064)
Loss: 1.110 | Acc: 71.246% (27404/38464)
Loss: 1.111 | Acc: 71.249% (31965/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3997, Accuracy: 6057/10000 (60.57%)

Epoch: 155
Loss: 1.238 | Acc: 67.188% (43/64)
Loss: 1.108 | Acc: 71.272% (4607/6464)
Loss: 1.112 | Acc: 71.160% (9154/12864)
Loss: 1.095 | Acc: 71.782% (13828/19264)
Loss: 1.100 | Acc: 71.672% (18394/25664)
Loss: 1.100 | Acc: 71.579% (22951/32064)
Loss: 1.103 | Acc: 71.498% (27501/38464)
Loss: 1.105 | Acc: 71.451% (32056/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5077, Accuracy: 5826/10000 (58.26%)

Epoch: 156
Loss: 0.861 | Acc: 79.688% (51/64)
Loss: 1.109 | Acc: 71.736% (4637/6464)
Loss: 1.090 | Acc: 72.100% (9275/12864)
Loss: 1.083 | Acc: 72.244% (13917/19264)
Loss: 1.088 | Acc: 72.070% (18496/25664)
Loss: 1.095 | Acc: 71.844% (23036/32064)
Loss: 1.100 | Acc: 71.706% (27581/38464)
Loss: 1.103 | Acc: 71.654% (32147/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2719, Accuracy: 3788/10000 (37.88%)

Epoch: 157
Loss: 0.946 | Acc: 78.125% (50/64)
Loss: 1.096 | Acc: 71.689% (4634/6464)
Loss: 1.091 | Acc: 71.906% (9250/12864)
Loss: 1.102 | Acc: 71.631% (13799/19264)
Loss: 1.107 | Acc: 71.567% (18367/25664)
Loss: 1.108 | Acc: 71.597% (22957/32064)
Loss: 1.107 | Acc: 71.636% (27554/38464)
Loss: 1.105 | Acc: 71.625% (32134/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4271, Accuracy: 6018/10000 (60.18%)

Epoch: 158
Loss: 1.365 | Acc: 64.062% (41/64)
Loss: 1.095 | Acc: 71.813% (4642/6464)
Loss: 1.090 | Acc: 71.961% (9257/12864)
Loss: 1.089 | Acc: 72.103% (13890/19264)
Loss: 1.090 | Acc: 72.136% (18513/25664)
Loss: 1.092 | Acc: 72.059% (23105/32064)
Loss: 1.095 | Acc: 71.984% (27688/38464)
Loss: 1.099 | Acc: 71.873% (32245/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3640, Accuracy: 6302/10000 (63.02%)

Epoch: 159
Loss: 0.970 | Acc: 79.688% (51/64)
Loss: 1.082 | Acc: 72.633% (4695/6464)
Loss: 1.082 | Acc: 72.660% (9347/12864)
Loss: 1.081 | Acc: 72.617% (13989/19264)
Loss: 1.087 | Acc: 72.409% (18583/25664)
Loss: 1.086 | Acc: 72.358% (23201/32064)
Loss: 1.092 | Acc: 72.132% (27745/38464)
Loss: 1.096 | Acc: 71.964% (32286/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4391, Accuracy: 5997/10000 (59.97%)

Epoch: 160
Loss: 1.105 | Acc: 68.750% (44/64)
Loss: 1.090 | Acc: 72.277% (4672/6464)
Loss: 1.088 | Acc: 72.295% (9300/12864)
Loss: 1.082 | Acc: 72.488% (13964/19264)
Loss: 1.085 | Acc: 72.269% (18547/25664)
Loss: 1.083 | Acc: 72.337% (23194/32064)
Loss: 1.088 | Acc: 72.187% (27766/38464)
Loss: 1.092 | Acc: 72.067% (32332/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3561, Accuracy: 6211/10000 (62.11%)

Epoch: 161
Loss: 1.560 | Acc: 57.812% (37/64)
Loss: 1.099 | Acc: 71.968% (4652/6464)
Loss: 1.089 | Acc: 72.442% (9319/12864)
Loss: 1.097 | Acc: 72.223% (13913/19264)
Loss: 1.099 | Acc: 72.101% (18504/25664)
Loss: 1.096 | Acc: 72.196% (23149/32064)
Loss: 1.098 | Acc: 72.140% (27748/38464)
Loss: 1.097 | Acc: 72.171% (32379/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2982, Accuracy: 6502/10000 (65.02%)

Epoch: 162
Loss: 1.134 | Acc: 71.875% (46/64)
Loss: 1.066 | Acc: 72.540% (4689/6464)
Loss: 1.068 | Acc: 72.971% (9387/12864)
Loss: 1.069 | Acc: 72.960% (14055/19264)
Loss: 1.077 | Acc: 72.744% (18669/25664)
Loss: 1.083 | Acc: 72.555% (23264/32064)
Loss: 1.084 | Acc: 72.434% (27861/38464)
Loss: 1.088 | Acc: 72.379% (32472/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2708, Accuracy: 6646/10000 (66.46%)

Epoch: 163
Loss: 0.934 | Acc: 79.688% (51/64)
Loss: 1.048 | Acc: 73.066% (4723/6464)
Loss: 1.064 | Acc: 72.722% (9355/12864)
Loss: 1.069 | Acc: 72.654% (13996/19264)
Loss: 1.076 | Acc: 72.401% (18581/25664)
Loss: 1.080 | Acc: 72.399% (23214/32064)
Loss: 1.084 | Acc: 72.281% (27802/38464)
Loss: 1.087 | Acc: 72.247% (32413/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6235, Accuracy: 5587/10000 (55.87%)

Epoch: 164
Loss: 1.157 | Acc: 73.438% (47/64)
Loss: 1.074 | Acc: 72.772% (4704/6464)
Loss: 1.052 | Acc: 73.368% (9438/12864)
Loss: 1.070 | Acc: 72.882% (14040/19264)
Loss: 1.075 | Acc: 72.643% (18643/25664)
Loss: 1.075 | Acc: 72.670% (23301/32064)
Loss: 1.078 | Acc: 72.702% (27964/38464)
Loss: 1.081 | Acc: 72.541% (32545/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4283, Accuracy: 5996/10000 (59.96%)

Epoch: 165
Loss: 1.245 | Acc: 70.312% (45/64)
Loss: 1.094 | Acc: 71.921% (4649/6464)
Loss: 1.081 | Acc: 72.310% (9302/12864)
Loss: 1.076 | Acc: 72.597% (13985/19264)
Loss: 1.074 | Acc: 72.596% (18631/25664)
Loss: 1.076 | Acc: 72.692% (23308/32064)
Loss: 1.074 | Acc: 72.723% (27972/38464)
Loss: 1.075 | Acc: 72.680% (32607/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2067, Accuracy: 6923/10000 (69.23%)

Epoch: 166
Loss: 1.408 | Acc: 56.250% (36/64)
Loss: 1.046 | Acc: 73.546% (4754/6464)
Loss: 1.054 | Acc: 73.360% (9437/12864)
Loss: 1.048 | Acc: 73.650% (14188/19264)
Loss: 1.058 | Acc: 73.270% (18804/25664)
Loss: 1.064 | Acc: 73.104% (23440/32064)
Loss: 1.068 | Acc: 72.998% (28078/38464)
Loss: 1.070 | Acc: 72.965% (32735/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4178, Accuracy: 6007/10000 (60.07%)

Epoch: 167
Loss: 0.902 | Acc: 78.125% (50/64)
Loss: 1.058 | Acc: 72.741% (4702/6464)
Loss: 1.064 | Acc: 72.909% (9379/12864)
Loss: 1.062 | Acc: 73.303% (14121/19264)
Loss: 1.059 | Acc: 73.344% (18823/25664)
Loss: 1.059 | Acc: 73.397% (23534/32064)
Loss: 1.058 | Acc: 73.448% (28251/38464)
Loss: 1.060 | Acc: 73.368% (32916/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6200, Accuracy: 5609/10000 (56.09%)

Epoch: 168
Loss: 0.725 | Acc: 79.688% (51/64)
Loss: 1.035 | Acc: 73.731% (4766/6464)
Loss: 1.053 | Acc: 73.189% (9415/12864)
Loss: 1.053 | Acc: 73.230% (14107/19264)
Loss: 1.055 | Acc: 73.278% (18806/25664)
Loss: 1.057 | Acc: 73.347% (23518/32064)
Loss: 1.057 | Acc: 73.336% (28208/38464)
Loss: 1.057 | Acc: 73.299% (32885/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3334, Accuracy: 6319/10000 (63.19%)

Epoch: 169
Loss: 1.010 | Acc: 71.875% (46/64)
Loss: 1.045 | Acc: 73.809% (4771/6464)
Loss: 1.051 | Acc: 73.422% (9445/12864)
Loss: 1.062 | Acc: 73.219% (14105/19264)
Loss: 1.052 | Acc: 73.558% (18878/25664)
Loss: 1.056 | Acc: 73.472% (23558/32064)
Loss: 1.054 | Acc: 73.528% (28282/38464)
Loss: 1.056 | Acc: 73.442% (32949/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5406, Accuracy: 5605/10000 (56.05%)

Epoch: 170
Loss: 1.608 | Acc: 57.812% (37/64)
Loss: 1.030 | Acc: 74.459% (4813/6464)
Loss: 1.033 | Acc: 74.308% (9559/12864)
Loss: 1.042 | Acc: 74.009% (14257/19264)
Loss: 1.043 | Acc: 73.893% (18964/25664)
Loss: 1.043 | Acc: 73.899% (23695/32064)
Loss: 1.038 | Acc: 74.108% (28505/38464)
Loss: 1.042 | Acc: 73.986% (33193/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3880, Accuracy: 6236/10000 (62.36%)

Epoch: 171
Loss: 1.142 | Acc: 65.625% (42/64)
Loss: 1.013 | Acc: 74.412% (4810/6464)
Loss: 1.022 | Acc: 74.370% (9567/12864)
Loss: 1.020 | Acc: 74.429% (14338/19264)
Loss: 1.029 | Acc: 74.225% (19049/25664)
Loss: 1.031 | Acc: 74.136% (23771/32064)
Loss: 1.034 | Acc: 74.150% (28521/38464)
Loss: 1.036 | Acc: 74.146% (33265/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2319, Accuracy: 6771/10000 (67.71%)

Epoch: 172
Loss: 1.233 | Acc: 68.750% (44/64)
Loss: 1.023 | Acc: 74.304% (4803/6464)
Loss: 1.018 | Acc: 74.674% (9606/12864)
Loss: 1.019 | Acc: 74.590% (14369/19264)
Loss: 1.022 | Acc: 74.544% (19131/25664)
Loss: 1.022 | Acc: 74.601% (23920/32064)
Loss: 1.024 | Acc: 74.480% (28648/38464)
Loss: 1.026 | Acc: 74.374% (33367/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5497, Accuracy: 5656/10000 (56.56%)

Epoch: 173
Loss: 0.894 | Acc: 76.562% (49/64)
Loss: 1.029 | Acc: 74.273% (4801/6464)
Loss: 1.018 | Acc: 74.767% (9618/12864)
Loss: 1.020 | Acc: 74.678% (14386/19264)
Loss: 1.022 | Acc: 74.599% (19145/25664)
Loss: 1.022 | Acc: 74.726% (23960/32064)
Loss: 1.021 | Acc: 74.743% (28749/38464)
Loss: 1.020 | Acc: 74.779% (33549/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3210, Accuracy: 6506/10000 (65.06%)

Epoch: 174
Loss: 1.161 | Acc: 68.750% (44/64)
Loss: 1.001 | Acc: 75.155% (4858/6464)
Loss: 1.004 | Acc: 75.109% (9662/12864)
Loss: 0.993 | Acc: 75.410% (14527/19264)
Loss: 1.001 | Acc: 75.222% (19305/25664)
Loss: 1.005 | Acc: 75.087% (24076/32064)
Loss: 1.003 | Acc: 75.208% (28928/38464)
Loss: 1.005 | Acc: 75.138% (33710/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2218, Accuracy: 6889/10000 (68.89%)

Epoch: 175
Loss: 1.274 | Acc: 68.750% (44/64)
Loss: 0.980 | Acc: 76.269% (4930/6464)
Loss: 0.975 | Acc: 75.987% (9775/12864)
Loss: 0.983 | Acc: 75.706% (14584/19264)
Loss: 0.989 | Acc: 75.565% (19393/25664)
Loss: 0.982 | Acc: 75.727% (24281/32064)
Loss: 0.985 | Acc: 75.668% (29105/38464)
Loss: 0.991 | Acc: 75.535% (33888/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5893, Accuracy: 5463/10000 (54.63%)

Epoch: 176
Loss: 1.223 | Acc: 71.875% (46/64)
Loss: 0.989 | Acc: 75.882% (4905/6464)
Loss: 0.992 | Acc: 75.676% (9735/12864)
Loss: 0.989 | Acc: 75.675% (14578/19264)
Loss: 0.988 | Acc: 75.744% (19439/25664)
Loss: 0.987 | Acc: 75.720% (24279/32064)
Loss: 0.985 | Acc: 75.850% (29175/38464)
Loss: 0.983 | Acc: 75.883% (34044/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2605, Accuracy: 6737/10000 (67.37%)

Epoch: 177
Loss: 0.911 | Acc: 76.562% (49/64)
Loss: 0.984 | Acc: 75.959% (4910/6464)
Loss: 0.966 | Acc: 76.539% (9846/12864)
Loss: 0.971 | Acc: 76.339% (14706/19264)
Loss: 0.972 | Acc: 76.235% (19565/25664)
Loss: 0.977 | Acc: 76.060% (24388/32064)
Loss: 0.981 | Acc: 75.907% (29197/38464)
Loss: 0.978 | Acc: 76.048% (34118/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3779, Accuracy: 6376/10000 (63.76%)

Epoch: 178
Loss: 0.803 | Acc: 78.125% (50/64)
Loss: 0.916 | Acc: 77.599% (5016/6464)
Loss: 0.942 | Acc: 76.998% (9905/12864)
Loss: 0.951 | Acc: 76.682% (14772/19264)
Loss: 0.956 | Acc: 76.582% (19654/25664)
Loss: 0.959 | Acc: 76.531% (24539/32064)
Loss: 0.959 | Acc: 76.555% (29446/38464)
Loss: 0.963 | Acc: 76.411% (34281/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3682, Accuracy: 6297/10000 (62.97%)

Epoch: 179
Loss: 1.003 | Acc: 73.438% (47/64)
Loss: 0.963 | Acc: 76.593% (4951/6464)
Loss: 0.952 | Acc: 77.006% (9906/12864)
Loss: 0.944 | Acc: 77.144% (14861/19264)
Loss: 0.944 | Acc: 77.170% (19805/25664)
Loss: 0.942 | Acc: 77.249% (24769/32064)
Loss: 0.940 | Acc: 77.205% (29696/38464)
Loss: 0.943 | Acc: 77.160% (34617/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1865, Accuracy: 7009/10000 (70.09%)

Epoch: 180
Loss: 0.629 | Acc: 82.812% (53/64)
Loss: 0.929 | Acc: 77.197% (4990/6464)
Loss: 0.930 | Acc: 77.169% (9927/12864)
Loss: 0.917 | Acc: 77.684% (14965/19264)
Loss: 0.919 | Acc: 77.731% (19949/25664)
Loss: 0.923 | Acc: 77.601% (24882/32064)
Loss: 0.928 | Acc: 77.543% (29826/38464)
Loss: 0.931 | Acc: 77.416% (34732/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2743, Accuracy: 6685/10000 (66.85%)

Epoch: 181
Loss: 1.039 | Acc: 71.875% (46/64)
Loss: 0.889 | Acc: 78.697% (5087/6464)
Loss: 0.887 | Acc: 78.514% (10100/12864)
Loss: 0.893 | Acc: 78.317% (15087/19264)
Loss: 0.906 | Acc: 78.004% (20019/25664)
Loss: 0.905 | Acc: 78.038% (25022/32064)
Loss: 0.911 | Acc: 77.883% (29957/38464)
Loss: 0.916 | Acc: 77.762% (34887/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2029, Accuracy: 6980/10000 (69.80%)

Epoch: 182
Loss: 1.156 | Acc: 65.625% (42/64)
Loss: 0.892 | Acc: 78.218% (5056/6464)
Loss: 0.870 | Acc: 79.073% (10172/12864)
Loss: 0.881 | Acc: 78.753% (15171/19264)
Loss: 0.889 | Acc: 78.538% (20156/25664)
Loss: 0.894 | Acc: 78.318% (25112/32064)
Loss: 0.897 | Acc: 78.239% (30094/38464)
Loss: 0.898 | Acc: 78.263% (35112/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1904, Accuracy: 7096/10000 (70.96%)

Epoch: 183
Loss: 0.812 | Acc: 81.250% (52/64)
Loss: 0.865 | Acc: 79.053% (5110/6464)
Loss: 0.868 | Acc: 79.027% (10166/12864)
Loss: 0.880 | Acc: 78.644% (15150/19264)
Loss: 0.881 | Acc: 78.671% (20190/25664)
Loss: 0.883 | Acc: 78.555% (25188/32064)
Loss: 0.884 | Acc: 78.523% (30203/38464)
Loss: 0.885 | Acc: 78.537% (35235/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1797, Accuracy: 7105/10000 (71.05%)

Epoch: 184
Loss: 0.817 | Acc: 81.250% (52/64)
Loss: 0.839 | Acc: 79.842% (5161/6464)
Loss: 0.851 | Acc: 79.462% (10222/12864)
Loss: 0.857 | Acc: 79.397% (15295/19264)
Loss: 0.855 | Acc: 79.555% (20417/25664)
Loss: 0.854 | Acc: 79.544% (25505/32064)
Loss: 0.854 | Acc: 79.537% (30593/38464)
Loss: 0.855 | Acc: 79.507% (35670/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1450, Accuracy: 7267/10000 (72.67%)

Epoch: 185
Loss: 0.918 | Acc: 81.250% (52/64)
Loss: 0.798 | Acc: 80.693% (5216/6464)
Loss: 0.808 | Acc: 80.356% (10337/12864)
Loss: 0.814 | Acc: 80.207% (15451/19264)
Loss: 0.827 | Acc: 79.937% (20515/25664)
Loss: 0.831 | Acc: 79.828% (25596/32064)
Loss: 0.830 | Acc: 79.854% (30715/38464)
Loss: 0.836 | Acc: 79.716% (35764/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1904, Accuracy: 7139/10000 (71.39%)

Epoch: 186
Loss: 0.389 | Acc: 92.188% (59/64)
Loss: 0.777 | Acc: 81.327% (5257/6464)
Loss: 0.785 | Acc: 81.032% (10424/12864)
Loss: 0.801 | Acc: 80.601% (15527/19264)
Loss: 0.808 | Acc: 80.447% (20646/25664)
Loss: 0.812 | Acc: 80.333% (25758/32064)
Loss: 0.810 | Acc: 80.369% (30913/38464)
Loss: 0.811 | Acc: 80.361% (36053/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1879, Accuracy: 7210/10000 (72.10%)

Epoch: 187
Loss: 0.619 | Acc: 87.500% (56/64)
Loss: 0.783 | Acc: 80.724% (5218/6464)
Loss: 0.775 | Acc: 81.032% (10424/12864)
Loss: 0.773 | Acc: 81.053% (15614/19264)
Loss: 0.779 | Acc: 80.888% (20759/25664)
Loss: 0.778 | Acc: 80.954% (25957/32064)
Loss: 0.781 | Acc: 80.951% (31137/38464)
Loss: 0.785 | Acc: 80.862% (36278/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2389, Accuracy: 7108/10000 (71.08%)

Epoch: 188
Loss: 0.694 | Acc: 87.500% (56/64)
Loss: 0.754 | Acc: 81.358% (5259/6464)
Loss: 0.753 | Acc: 81.538% (10489/12864)
Loss: 0.756 | Acc: 81.478% (15696/19264)
Loss: 0.755 | Acc: 81.464% (20907/25664)
Loss: 0.756 | Acc: 81.443% (26114/32064)
Loss: 0.753 | Acc: 81.492% (31345/38464)
Loss: 0.757 | Acc: 81.375% (36508/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2192, Accuracy: 7202/10000 (72.02%)

Epoch: 189
Loss: 0.585 | Acc: 87.500% (56/64)
Loss: 0.686 | Acc: 82.874% (5357/6464)
Loss: 0.696 | Acc: 82.696% (10638/12864)
Loss: 0.702 | Acc: 82.703% (15932/19264)
Loss: 0.706 | Acc: 82.680% (21219/25664)
Loss: 0.707 | Acc: 82.594% (26483/32064)
Loss: 0.713 | Acc: 82.360% (31679/38464)
Loss: 0.718 | Acc: 82.182% (36870/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2304, Accuracy: 7274/10000 (72.74%)

Epoch: 190
Loss: 0.609 | Acc: 84.375% (54/64)
Loss: 0.650 | Acc: 83.617% (5405/6464)
Loss: 0.651 | Acc: 83.497% (10741/12864)
Loss: 0.662 | Acc: 83.249% (16037/19264)
Loss: 0.668 | Acc: 83.148% (21339/25664)
Loss: 0.666 | Acc: 83.262% (26697/32064)
Loss: 0.669 | Acc: 83.153% (31984/38464)
Loss: 0.670 | Acc: 83.200% (37327/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3179, Accuracy: 6986/10000 (69.86%)

Epoch: 191
Loss: 0.780 | Acc: 78.125% (50/64)
Loss: 0.621 | Acc: 83.895% (5423/6464)
Loss: 0.609 | Acc: 84.453% (10864/12864)
Loss: 0.615 | Acc: 84.344% (16248/19264)
Loss: 0.618 | Acc: 84.219% (21614/25664)
Loss: 0.621 | Acc: 84.194% (26996/32064)
Loss: 0.627 | Acc: 84.003% (32311/38464)
Loss: 0.627 | Acc: 83.987% (37680/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2903, Accuracy: 7186/10000 (71.86%)

Epoch: 192
Loss: 0.721 | Acc: 78.125% (50/64)
Loss: 0.586 | Acc: 84.762% (5479/6464)
Loss: 0.574 | Acc: 85.005% (10935/12864)
Loss: 0.575 | Acc: 84.967% (16368/19264)
Loss: 0.576 | Acc: 84.936% (21798/25664)
Loss: 0.582 | Acc: 84.818% (27196/32064)
Loss: 0.581 | Acc: 84.859% (32640/38464)
Loss: 0.583 | Acc: 84.805% (38047/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3648, Accuracy: 7201/10000 (72.01%)

Epoch: 193
Loss: 0.459 | Acc: 87.500% (56/64)
Loss: 0.523 | Acc: 86.139% (5568/6464)
Loss: 0.537 | Acc: 85.502% (10999/12864)
Loss: 0.538 | Acc: 85.636% (16497/19264)
Loss: 0.542 | Acc: 85.626% (21975/25664)
Loss: 0.538 | Acc: 85.707% (27481/32064)
Loss: 0.534 | Acc: 85.844% (33019/38464)
Loss: 0.534 | Acc: 85.866% (38523/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4061, Accuracy: 7083/10000 (70.83%)

Epoch: 194
Loss: 0.471 | Acc: 85.938% (55/64)
Loss: 0.482 | Acc: 87.144% (5633/6464)
Loss: 0.477 | Acc: 87.243% (11223/12864)
Loss: 0.474 | Acc: 87.386% (16834/19264)
Loss: 0.479 | Acc: 87.204% (22380/25664)
Loss: 0.477 | Acc: 87.272% (27983/32064)
Loss: 0.480 | Acc: 87.126% (33512/38464)
Loss: 0.481 | Acc: 87.143% (39096/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4410, Accuracy: 7135/10000 (71.35%)

Epoch: 195
Loss: 0.421 | Acc: 89.062% (57/64)
Loss: 0.422 | Acc: 88.335% (5710/6464)
Loss: 0.427 | Acc: 88.448% (11378/12864)
Loss: 0.433 | Acc: 88.227% (16996/19264)
Loss: 0.436 | Acc: 88.120% (22615/25664)
Loss: 0.439 | Acc: 88.043% (28230/32064)
Loss: 0.437 | Acc: 88.059% (33871/38464)
Loss: 0.437 | Acc: 88.082% (39517/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4718, Accuracy: 7093/10000 (70.93%)

Epoch: 196
Loss: 0.575 | Acc: 81.250% (52/64)
Loss: 0.381 | Acc: 89.558% (5789/6464)
Loss: 0.387 | Acc: 89.366% (11496/12864)
Loss: 0.397 | Acc: 88.953% (17136/19264)
Loss: 0.399 | Acc: 88.977% (22835/25664)
Loss: 0.396 | Acc: 89.038% (28549/32064)
Loss: 0.397 | Acc: 88.972% (34222/38464)
Loss: 0.395 | Acc: 89.011% (39934/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4992, Accuracy: 7051/10000 (70.51%)

Epoch: 197
Loss: 0.353 | Acc: 92.188% (59/64)
Loss: 0.365 | Acc: 89.712% (5799/6464)
Loss: 0.364 | Acc: 89.840% (11557/12864)
Loss: 0.361 | Acc: 89.955% (17329/19264)
Loss: 0.365 | Acc: 89.737% (23030/25664)
Loss: 0.368 | Acc: 89.696% (28760/32064)
Loss: 0.367 | Acc: 89.668% (34490/38464)
Loss: 0.366 | Acc: 89.725% (40254/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5128, Accuracy: 7080/10000 (70.80%)
torch.Size([100, 10])
Test set: Average loss: 1.5128, Accuracy: 7080/10000 (70.80%)

Epoch: 198
Loss: 0.389 | Acc: 89.062% (57/64)
Loss: 0.354 | Acc: 89.944% (5814/6464)
Loss: 0.346 | Acc: 90.213% (11605/12864)
Loss: 0.348 | Acc: 90.246% (17385/19264)
Loss: 0.351 | Acc: 90.083% (23119/25664)
Loss: 0.350 | Acc: 90.082% (28884/32064)
Loss: 0.351 | Acc: 90.014% (34623/38464)
Loss: 0.350 | Acc: 90.066% (40407/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5072, Accuracy: 7066/10000 (70.66%)
torch.Size([100, 10])
Test set: Average loss: 1.5072, Accuracy: 7066/10000 (70.66%)

Epoch: 199
Loss: 0.197 | Acc: 93.750% (60/64)
Loss: 0.355 | Acc: 89.836% (5807/6464)
Loss: 0.347 | Acc: 90.159% (11598/12864)
Loss: 0.345 | Acc: 90.184% (17373/19264)
Loss: 0.343 | Acc: 90.259% (23164/25664)
Loss: 0.346 | Acc: 90.201% (28922/32064)
Loss: 0.341 | Acc: 90.375% (34762/38464)
Loss: 0.341 | Acc: 90.389% (40552/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5267, Accuracy: 7066/10000 (70.66%)
torch.Size([100, 10])
Test set: Average loss: 1.5267, Accuracy: 7066/10000 (70.66%)
7450
10000
-1.238145112991333
