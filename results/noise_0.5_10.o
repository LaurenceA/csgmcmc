==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.418 | Acc: 12.500% (8/64)
Loss: 2.917 | Acc: 11.757% (760/6464)
Loss: 2.595 | Acc: 13.293% (1710/12864)
Loss: 2.484 | Acc: 14.094% (2715/19264)
Loss: 2.422 | Acc: 15.017% (3854/25664)
Loss: 2.385 | Acc: 15.606% (5004/32064)
Loss: 2.359 | Acc: 16.127% (6203/38464)
Loss: 2.338 | Acc: 16.550% (7425/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3192, Accuracy: 1769/10000 (17.69%)

Epoch: 1
Loss: 2.420 | Acc: 7.812% (5/64)
Loss: 2.210 | Acc: 19.709% (1274/6464)
Loss: 2.202 | Acc: 20.468% (2633/12864)
Loss: 2.197 | Acc: 20.640% (3976/19264)
Loss: 2.194 | Acc: 21.006% (5391/25664)
Loss: 2.193 | Acc: 21.183% (6792/32064)
Loss: 2.188 | Acc: 21.415% (8237/38464)
Loss: 2.187 | Acc: 21.643% (9710/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2419, Accuracy: 2084/10000 (20.84%)

Epoch: 2
Loss: 2.043 | Acc: 26.562% (17/64)
Loss: 2.150 | Acc: 24.644% (1593/6464)
Loss: 2.152 | Acc: 24.176% (3110/12864)
Loss: 2.152 | Acc: 24.434% (4707/19264)
Loss: 2.151 | Acc: 24.579% (6308/25664)
Loss: 2.151 | Acc: 24.551% (7872/32064)
Loss: 2.149 | Acc: 24.743% (9517/38464)
Loss: 2.147 | Acc: 24.915% (11178/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1547, Accuracy: 2426/10000 (24.26%)

Epoch: 3
Loss: 2.430 | Acc: 14.062% (9/64)
Loss: 2.135 | Acc: 25.541% (1651/6464)
Loss: 2.136 | Acc: 25.793% (3318/12864)
Loss: 2.128 | Acc: 26.111% (5030/19264)
Loss: 2.127 | Acc: 26.344% (6761/25664)
Loss: 2.126 | Acc: 26.397% (8464/32064)
Loss: 2.124 | Acc: 26.516% (10199/38464)
Loss: 2.121 | Acc: 26.696% (11977/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1696, Accuracy: 2388/10000 (23.88%)

Epoch: 4
Loss: 2.011 | Acc: 32.812% (21/64)
Loss: 2.099 | Acc: 28.342% (1832/6464)
Loss: 2.091 | Acc: 28.630% (3683/12864)
Loss: 2.095 | Acc: 28.494% (5489/19264)
Loss: 2.095 | Acc: 28.441% (7299/25664)
Loss: 2.097 | Acc: 28.356% (9092/32064)
Loss: 2.095 | Acc: 28.486% (10957/38464)
Loss: 2.094 | Acc: 28.660% (12858/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1478, Accuracy: 2598/10000 (25.98%)

Epoch: 5
Loss: 2.024 | Acc: 34.375% (22/64)
Loss: 2.065 | Acc: 30.074% (1944/6464)
Loss: 2.077 | Acc: 29.719% (3823/12864)
Loss: 2.073 | Acc: 29.916% (5763/19264)
Loss: 2.071 | Acc: 30.085% (7721/25664)
Loss: 2.069 | Acc: 30.377% (9740/32064)
Loss: 2.069 | Acc: 30.439% (11708/38464)
Loss: 2.067 | Acc: 30.670% (13760/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1763, Accuracy: 2627/10000 (26.27%)

Epoch: 6
Loss: 1.927 | Acc: 32.812% (21/64)
Loss: 2.027 | Acc: 33.540% (2168/6464)
Loss: 2.034 | Acc: 33.131% (4262/12864)
Loss: 2.039 | Acc: 32.932% (6344/19264)
Loss: 2.037 | Acc: 32.984% (8465/25664)
Loss: 2.032 | Acc: 33.196% (10644/32064)
Loss: 2.035 | Acc: 33.179% (12762/38464)
Loss: 2.033 | Acc: 33.321% (14949/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0769, Accuracy: 3132/10000 (31.32%)

Epoch: 7
Loss: 1.960 | Acc: 37.500% (24/64)
Loss: 2.014 | Acc: 34.808% (2250/6464)
Loss: 2.009 | Acc: 34.740% (4469/12864)
Loss: 2.012 | Acc: 34.718% (6688/19264)
Loss: 2.010 | Acc: 34.823% (8937/25664)
Loss: 2.010 | Acc: 34.886% (11186/32064)
Loss: 2.010 | Acc: 34.994% (13460/38464)
Loss: 2.009 | Acc: 35.055% (15727/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1079, Accuracy: 2993/10000 (29.93%)

Epoch: 8
Loss: 2.136 | Acc: 29.688% (19/64)
Loss: 1.993 | Acc: 35.396% (2288/6464)
Loss: 1.988 | Acc: 35.751% (4599/12864)
Loss: 1.985 | Acc: 36.031% (6941/19264)
Loss: 1.989 | Acc: 35.902% (9214/25664)
Loss: 1.985 | Acc: 36.190% (11604/32064)
Loss: 1.987 | Acc: 36.151% (13905/38464)
Loss: 1.986 | Acc: 36.234% (16256/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1575, Accuracy: 3028/10000 (30.28%)

Epoch: 9
Loss: 2.059 | Acc: 32.812% (21/64)
Loss: 1.960 | Acc: 37.407% (2418/6464)
Loss: 1.970 | Acc: 36.878% (4744/12864)
Loss: 1.972 | Acc: 36.955% (7119/19264)
Loss: 1.971 | Acc: 37.067% (9513/25664)
Loss: 1.972 | Acc: 37.191% (11925/32064)
Loss: 1.973 | Acc: 37.250% (14328/38464)
Loss: 1.973 | Acc: 37.311% (16739/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1762, Accuracy: 2805/10000 (28.05%)

Epoch: 10
Loss: 1.901 | Acc: 42.188% (27/64)
Loss: 1.965 | Acc: 37.949% (2453/6464)
Loss: 1.966 | Acc: 37.811% (4864/12864)
Loss: 1.962 | Acc: 37.900% (7301/19264)
Loss: 1.960 | Acc: 38.046% (9764/25664)
Loss: 1.956 | Acc: 38.429% (12322/32064)
Loss: 1.955 | Acc: 38.511% (14813/38464)
Loss: 1.955 | Acc: 38.541% (17291/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0626, Accuracy: 3257/10000 (32.57%)

Epoch: 11
Loss: 1.907 | Acc: 35.938% (23/64)
Loss: 1.931 | Acc: 40.130% (2594/6464)
Loss: 1.938 | Acc: 39.529% (5085/12864)
Loss: 1.939 | Acc: 39.743% (7656/19264)
Loss: 1.940 | Acc: 39.705% (10190/25664)
Loss: 1.941 | Acc: 39.596% (12696/32064)
Loss: 1.941 | Acc: 39.499% (15193/38464)
Loss: 1.938 | Acc: 39.658% (17792/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0791, Accuracy: 3210/10000 (32.10%)

Epoch: 12
Loss: 1.956 | Acc: 32.812% (21/64)
Loss: 1.938 | Acc: 39.681% (2565/6464)
Loss: 1.932 | Acc: 40.003% (5146/12864)
Loss: 1.927 | Acc: 40.205% (7745/19264)
Loss: 1.928 | Acc: 40.274% (10336/25664)
Loss: 1.928 | Acc: 40.366% (12943/32064)
Loss: 1.924 | Acc: 40.503% (15579/38464)
Loss: 1.926 | Acc: 40.447% (18146/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0412, Accuracy: 3346/10000 (33.46%)

Epoch: 13
Loss: 2.118 | Acc: 25.000% (16/64)
Loss: 1.909 | Acc: 41.677% (2694/6464)
Loss: 1.912 | Acc: 41.278% (5310/12864)
Loss: 1.912 | Acc: 41.367% (7969/19264)
Loss: 1.912 | Acc: 41.295% (10598/25664)
Loss: 1.914 | Acc: 41.152% (13195/32064)
Loss: 1.915 | Acc: 41.150% (15828/38464)
Loss: 1.915 | Acc: 41.147% (18460/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0060, Accuracy: 3681/10000 (36.81%)

Epoch: 14
Loss: 1.947 | Acc: 43.750% (28/64)
Loss: 1.905 | Acc: 41.600% (2689/6464)
Loss: 1.902 | Acc: 41.939% (5395/12864)
Loss: 1.903 | Acc: 41.850% (8062/19264)
Loss: 1.903 | Acc: 41.965% (10770/25664)
Loss: 1.903 | Acc: 41.941% (13448/32064)
Loss: 1.905 | Acc: 41.896% (16115/38464)
Loss: 1.903 | Acc: 41.924% (18809/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0689, Accuracy: 3255/10000 (32.55%)

Epoch: 15
Loss: 1.929 | Acc: 42.188% (27/64)
Loss: 1.906 | Acc: 41.785% (2701/6464)
Loss: 1.904 | Acc: 42.040% (5408/12864)
Loss: 1.905 | Acc: 41.923% (8076/19264)
Loss: 1.903 | Acc: 41.985% (10775/25664)
Loss: 1.899 | Acc: 42.138% (13511/32064)
Loss: 1.897 | Acc: 42.226% (16242/38464)
Loss: 1.899 | Acc: 42.101% (18888/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1125, Accuracy: 3072/10000 (30.72%)

Epoch: 16
Loss: 2.151 | Acc: 31.250% (20/64)
Loss: 1.879 | Acc: 43.162% (2790/6464)
Loss: 1.888 | Acc: 42.631% (5484/12864)
Loss: 1.892 | Acc: 42.592% (8205/19264)
Loss: 1.897 | Acc: 42.176% (10824/25664)
Loss: 1.895 | Acc: 42.468% (13617/32064)
Loss: 1.893 | Acc: 42.554% (16368/38464)
Loss: 1.888 | Acc: 42.687% (19151/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1878, Accuracy: 2922/10000 (29.22%)

Epoch: 17
Loss: 1.846 | Acc: 42.188% (27/64)
Loss: 1.879 | Acc: 43.719% (2826/6464)
Loss: 1.888 | Acc: 42.965% (5527/12864)
Loss: 1.890 | Acc: 42.759% (8237/19264)
Loss: 1.886 | Acc: 42.994% (11034/25664)
Loss: 1.888 | Acc: 42.827% (13732/32064)
Loss: 1.887 | Acc: 42.889% (16497/38464)
Loss: 1.885 | Acc: 42.912% (19252/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0302, Accuracy: 3634/10000 (36.34%)

Epoch: 18
Loss: 1.985 | Acc: 40.625% (26/64)
Loss: 1.859 | Acc: 43.827% (2833/6464)
Loss: 1.874 | Acc: 43.431% (5587/12864)
Loss: 1.875 | Acc: 43.485% (8377/19264)
Loss: 1.875 | Acc: 43.458% (11153/25664)
Loss: 1.874 | Acc: 43.610% (13983/32064)
Loss: 1.873 | Acc: 43.526% (16742/38464)
Loss: 1.873 | Acc: 43.543% (19535/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9690, Accuracy: 3879/10000 (38.79%)

Epoch: 19
Loss: 2.124 | Acc: 35.938% (23/64)
Loss: 1.858 | Acc: 43.936% (2840/6464)
Loss: 1.858 | Acc: 44.061% (5668/12864)
Loss: 1.854 | Acc: 44.321% (8538/19264)
Loss: 1.858 | Acc: 44.299% (11369/25664)
Loss: 1.862 | Acc: 44.155% (14158/32064)
Loss: 1.866 | Acc: 44.065% (16949/38464)
Loss: 1.866 | Acc: 44.006% (19743/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0855, Accuracy: 3237/10000 (32.37%)

Epoch: 20
Loss: 1.806 | Acc: 48.438% (31/64)
Loss: 1.859 | Acc: 44.508% (2877/6464)
Loss: 1.852 | Acc: 44.776% (5760/12864)
Loss: 1.854 | Acc: 44.513% (8575/19264)
Loss: 1.858 | Acc: 44.323% (11375/25664)
Loss: 1.858 | Acc: 44.336% (14216/32064)
Loss: 1.861 | Acc: 44.257% (17023/38464)
Loss: 1.861 | Acc: 44.227% (19842/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9339, Accuracy: 4068/10000 (40.68%)

Epoch: 21
Loss: 1.874 | Acc: 43.750% (28/64)
Loss: 1.850 | Acc: 44.539% (2879/6464)
Loss: 1.853 | Acc: 44.224% (5689/12864)
Loss: 1.850 | Acc: 44.409% (8555/19264)
Loss: 1.854 | Acc: 44.327% (11376/25664)
Loss: 1.854 | Acc: 44.411% (14240/32064)
Loss: 1.856 | Acc: 44.291% (17036/38464)
Loss: 1.853 | Acc: 44.494% (19962/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9440, Accuracy: 4067/10000 (40.67%)

Epoch: 22
Loss: 1.736 | Acc: 51.562% (33/64)
Loss: 1.832 | Acc: 45.282% (2927/6464)
Loss: 1.846 | Acc: 44.761% (5758/12864)
Loss: 1.845 | Acc: 44.799% (8630/19264)
Loss: 1.849 | Acc: 44.627% (11453/25664)
Loss: 1.847 | Acc: 44.726% (14341/32064)
Loss: 1.847 | Acc: 44.787% (17227/38464)
Loss: 1.845 | Acc: 44.856% (20124/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9167, Accuracy: 4189/10000 (41.89%)

Epoch: 23
Loss: 1.792 | Acc: 48.438% (31/64)
Loss: 1.830 | Acc: 45.653% (2951/6464)
Loss: 1.838 | Acc: 45.266% (5823/12864)
Loss: 1.842 | Acc: 45.126% (8693/19264)
Loss: 1.844 | Acc: 44.938% (11533/25664)
Loss: 1.843 | Acc: 45.066% (14450/32064)
Loss: 1.846 | Acc: 44.982% (17302/38464)
Loss: 1.843 | Acc: 45.181% (20270/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1023, Accuracy: 3282/10000 (32.82%)

Epoch: 24
Loss: 1.724 | Acc: 50.000% (32/64)
Loss: 1.848 | Acc: 44.601% (2883/6464)
Loss: 1.837 | Acc: 44.908% (5777/12864)
Loss: 1.835 | Acc: 45.271% (8721/19264)
Loss: 1.840 | Acc: 45.133% (11583/25664)
Loss: 1.833 | Acc: 45.372% (14548/32064)
Loss: 1.833 | Acc: 45.440% (17478/38464)
Loss: 1.836 | Acc: 45.308% (20327/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9584, Accuracy: 3957/10000 (39.57%)

Epoch: 25
Loss: 1.881 | Acc: 42.188% (27/64)
Loss: 1.813 | Acc: 46.395% (2999/6464)
Loss: 1.824 | Acc: 45.802% (5892/12864)
Loss: 1.825 | Acc: 45.775% (8818/19264)
Loss: 1.824 | Acc: 45.850% (11767/25664)
Loss: 1.826 | Acc: 45.880% (14711/32064)
Loss: 1.828 | Acc: 45.778% (17608/38464)
Loss: 1.828 | Acc: 45.801% (20548/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9591, Accuracy: 3858/10000 (38.58%)

Epoch: 26
Loss: 2.007 | Acc: 37.500% (24/64)
Loss: 1.838 | Acc: 45.282% (2927/6464)
Loss: 1.836 | Acc: 45.484% (5851/12864)
Loss: 1.826 | Acc: 45.961% (8854/19264)
Loss: 1.826 | Acc: 45.885% (11776/25664)
Loss: 1.828 | Acc: 45.840% (14698/32064)
Loss: 1.824 | Acc: 45.900% (17655/38464)
Loss: 1.822 | Acc: 46.073% (20670/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8700, Accuracy: 4417/10000 (44.17%)

Epoch: 27
Loss: 1.857 | Acc: 42.188% (27/64)
Loss: 1.837 | Acc: 45.158% (2919/6464)
Loss: 1.818 | Acc: 46.222% (5946/12864)
Loss: 1.811 | Acc: 46.413% (8941/19264)
Loss: 1.816 | Acc: 46.193% (11855/25664)
Loss: 1.814 | Acc: 46.373% (14869/32064)
Loss: 1.810 | Acc: 46.529% (17897/38464)
Loss: 1.809 | Acc: 46.543% (20881/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9351, Accuracy: 4037/10000 (40.37%)

Epoch: 28
Loss: 1.845 | Acc: 45.312% (29/64)
Loss: 1.808 | Acc: 46.767% (3023/6464)
Loss: 1.812 | Acc: 46.657% (6002/12864)
Loss: 1.805 | Acc: 47.031% (9060/19264)
Loss: 1.807 | Acc: 46.891% (12034/25664)
Loss: 1.806 | Acc: 46.978% (15063/32064)
Loss: 1.805 | Acc: 46.979% (18070/38464)
Loss: 1.803 | Acc: 47.156% (21156/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9450, Accuracy: 3982/10000 (39.82%)

Epoch: 29
Loss: 1.864 | Acc: 42.188% (27/64)
Loss: 1.791 | Acc: 47.633% (3079/6464)
Loss: 1.785 | Acc: 47.823% (6152/12864)
Loss: 1.787 | Acc: 47.846% (9217/19264)
Loss: 1.790 | Acc: 47.639% (12226/25664)
Loss: 1.789 | Acc: 47.614% (15267/32064)
Loss: 1.793 | Acc: 47.559% (18293/38464)
Loss: 1.792 | Acc: 47.624% (21366/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8684, Accuracy: 4407/10000 (44.07%)

Epoch: 30
Loss: 2.057 | Acc: 35.938% (23/64)
Loss: 1.757 | Acc: 48.994% (3167/6464)
Loss: 1.764 | Acc: 48.912% (6292/12864)
Loss: 1.771 | Acc: 48.521% (9347/19264)
Loss: 1.775 | Acc: 48.344% (12407/25664)
Loss: 1.779 | Acc: 48.216% (15460/32064)
Loss: 1.783 | Acc: 48.094% (18499/38464)
Loss: 1.784 | Acc: 48.112% (21585/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8817, Accuracy: 4366/10000 (43.66%)

Epoch: 31
Loss: 1.717 | Acc: 46.875% (30/64)
Loss: 1.762 | Acc: 48.871% (3159/6464)
Loss: 1.769 | Acc: 48.531% (6243/12864)
Loss: 1.773 | Acc: 48.531% (9349/19264)
Loss: 1.775 | Acc: 48.430% (12429/25664)
Loss: 1.774 | Acc: 48.416% (15524/32064)
Loss: 1.773 | Acc: 48.451% (18636/38464)
Loss: 1.776 | Acc: 48.333% (21684/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9496, Accuracy: 4004/10000 (40.04%)

Epoch: 32
Loss: 1.645 | Acc: 50.000% (32/64)
Loss: 1.761 | Acc: 48.809% (3155/6464)
Loss: 1.765 | Acc: 48.577% (6249/12864)
Loss: 1.770 | Acc: 48.463% (9336/19264)
Loss: 1.768 | Acc: 48.508% (12449/25664)
Loss: 1.766 | Acc: 48.646% (15598/32064)
Loss: 1.766 | Acc: 48.617% (18700/38464)
Loss: 1.767 | Acc: 48.636% (21820/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8858, Accuracy: 4425/10000 (44.25%)

Epoch: 33
Loss: 1.781 | Acc: 46.875% (30/64)
Loss: 1.731 | Acc: 49.892% (3225/6464)
Loss: 1.737 | Acc: 49.666% (6389/12864)
Loss: 1.737 | Acc: 49.756% (9585/19264)
Loss: 1.747 | Acc: 49.349% (12665/25664)
Loss: 1.747 | Acc: 49.339% (15820/32064)
Loss: 1.751 | Acc: 49.199% (18924/38464)
Loss: 1.755 | Acc: 49.086% (22022/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8816, Accuracy: 4397/10000 (43.97%)

Epoch: 34
Loss: 1.743 | Acc: 50.000% (32/64)
Loss: 1.729 | Acc: 50.031% (3234/6464)
Loss: 1.730 | Acc: 50.008% (6433/12864)
Loss: 1.732 | Acc: 49.875% (9608/19264)
Loss: 1.738 | Acc: 49.556% (12718/25664)
Loss: 1.740 | Acc: 49.551% (15888/32064)
Loss: 1.742 | Acc: 49.522% (19048/38464)
Loss: 1.743 | Acc: 49.570% (22239/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8782, Accuracy: 4474/10000 (44.74%)

Epoch: 35
Loss: 1.517 | Acc: 62.500% (40/64)
Loss: 1.680 | Acc: 52.228% (3376/6464)
Loss: 1.700 | Acc: 51.236% (6591/12864)
Loss: 1.714 | Acc: 50.607% (9749/19264)
Loss: 1.714 | Acc: 50.748% (13024/25664)
Loss: 1.718 | Acc: 50.599% (16224/32064)
Loss: 1.720 | Acc: 50.520% (19432/38464)
Loss: 1.727 | Acc: 50.187% (22516/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8904, Accuracy: 4345/10000 (43.45%)

Epoch: 36
Loss: 1.724 | Acc: 48.438% (31/64)
Loss: 1.727 | Acc: 49.737% (3215/6464)
Loss: 1.713 | Acc: 50.490% (6495/12864)
Loss: 1.713 | Acc: 50.628% (9753/19264)
Loss: 1.713 | Acc: 50.623% (12992/25664)
Loss: 1.711 | Acc: 50.642% (16238/32064)
Loss: 1.712 | Acc: 50.606% (19465/38464)
Loss: 1.713 | Acc: 50.635% (22717/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8874, Accuracy: 4406/10000 (44.06%)

Epoch: 37
Loss: 1.693 | Acc: 51.562% (33/64)
Loss: 1.687 | Acc: 51.825% (3350/6464)
Loss: 1.690 | Acc: 51.609% (6639/12864)
Loss: 1.690 | Acc: 51.490% (9919/19264)
Loss: 1.693 | Acc: 51.414% (13195/25664)
Loss: 1.700 | Acc: 51.129% (16394/32064)
Loss: 1.702 | Acc: 51.009% (19620/38464)
Loss: 1.700 | Acc: 51.081% (22917/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8744, Accuracy: 4518/10000 (45.18%)

Epoch: 38
Loss: 1.767 | Acc: 50.000% (32/64)
Loss: 1.669 | Acc: 51.934% (3357/6464)
Loss: 1.676 | Acc: 51.679% (6648/12864)
Loss: 1.681 | Acc: 51.635% (9947/19264)
Loss: 1.686 | Acc: 51.407% (13193/25664)
Loss: 1.683 | Acc: 51.481% (16507/32064)
Loss: 1.678 | Acc: 51.687% (19881/38464)
Loss: 1.681 | Acc: 51.620% (23159/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8989, Accuracy: 4398/10000 (43.98%)

Epoch: 39
Loss: 1.867 | Acc: 42.188% (27/64)
Loss: 1.640 | Acc: 53.125% (3434/6464)
Loss: 1.642 | Acc: 53.226% (6847/12864)
Loss: 1.658 | Acc: 52.419% (10098/19264)
Loss: 1.652 | Acc: 52.595% (13498/25664)
Loss: 1.652 | Acc: 52.623% (16873/32064)
Loss: 1.654 | Acc: 52.592% (20229/38464)
Loss: 1.661 | Acc: 52.347% (23485/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8909, Accuracy: 4526/10000 (45.26%)

Epoch: 40
Loss: 1.612 | Acc: 56.250% (36/64)
Loss: 1.628 | Acc: 52.893% (3419/6464)
Loss: 1.627 | Acc: 53.343% (6862/12864)
Loss: 1.631 | Acc: 53.265% (10261/19264)
Loss: 1.630 | Acc: 53.324% (13685/25664)
Loss: 1.631 | Acc: 53.272% (17081/32064)
Loss: 1.635 | Acc: 53.068% (20412/38464)
Loss: 1.635 | Acc: 53.031% (23792/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9021, Accuracy: 4467/10000 (44.67%)

Epoch: 41
Loss: 1.655 | Acc: 46.875% (30/64)
Loss: 1.600 | Acc: 53.775% (3476/6464)
Loss: 1.604 | Acc: 53.630% (6899/12864)
Loss: 1.597 | Acc: 53.862% (10376/19264)
Loss: 1.602 | Acc: 53.659% (13771/25664)
Loss: 1.605 | Acc: 53.580% (17180/32064)
Loss: 1.608 | Acc: 53.520% (20586/38464)
Loss: 1.608 | Acc: 53.564% (24031/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9467, Accuracy: 4392/10000 (43.92%)

Epoch: 42
Loss: 1.546 | Acc: 60.938% (39/64)
Loss: 1.595 | Acc: 54.115% (3498/6464)
Loss: 1.588 | Acc: 54.058% (6954/12864)
Loss: 1.583 | Acc: 54.179% (10437/19264)
Loss: 1.581 | Acc: 54.228% (13917/25664)
Loss: 1.579 | Acc: 54.335% (17422/32064)
Loss: 1.577 | Acc: 54.467% (20950/38464)
Loss: 1.577 | Acc: 54.476% (24440/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9225, Accuracy: 4543/10000 (45.43%)

Epoch: 43
Loss: 1.477 | Acc: 54.688% (35/64)
Loss: 1.498 | Acc: 56.652% (3662/6464)
Loss: 1.518 | Acc: 56.118% (7219/12864)
Loss: 1.525 | Acc: 55.902% (10769/19264)
Loss: 1.529 | Acc: 55.821% (14326/25664)
Loss: 1.530 | Acc: 55.785% (17887/32064)
Loss: 1.532 | Acc: 55.725% (21434/38464)
Loss: 1.533 | Acc: 55.664% (24973/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9538, Accuracy: 4455/10000 (44.55%)

Epoch: 44
Loss: 1.345 | Acc: 64.062% (41/64)
Loss: 1.474 | Acc: 57.580% (3722/6464)
Loss: 1.483 | Acc: 57.276% (7368/12864)
Loss: 1.481 | Acc: 57.309% (11040/19264)
Loss: 1.484 | Acc: 57.099% (14654/25664)
Loss: 1.489 | Acc: 56.768% (18202/32064)
Loss: 1.490 | Acc: 56.773% (21837/38464)
Loss: 1.491 | Acc: 56.734% (25453/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9944, Accuracy: 4424/10000 (44.24%)

Epoch: 45
Loss: 1.459 | Acc: 57.812% (37/64)
Loss: 1.444 | Acc: 57.797% (3736/6464)
Loss: 1.438 | Acc: 58.085% (7472/12864)
Loss: 1.455 | Acc: 57.569% (11090/19264)
Loss: 1.465 | Acc: 57.298% (14705/25664)
Loss: 1.466 | Acc: 57.379% (18398/32064)
Loss: 1.463 | Acc: 57.493% (22114/38464)
Loss: 1.462 | Acc: 57.581% (25833/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9776, Accuracy: 4452/10000 (44.52%)

Epoch: 46
Loss: 1.347 | Acc: 60.938% (39/64)
Loss: 1.447 | Acc: 57.874% (3741/6464)
Loss: 1.441 | Acc: 58.139% (7479/12864)
Loss: 1.446 | Acc: 58.197% (11211/19264)
Loss: 1.450 | Acc: 58.136% (14920/25664)
Loss: 1.451 | Acc: 58.152% (18646/32064)
Loss: 1.454 | Acc: 58.031% (22321/38464)
Loss: 1.454 | Acc: 57.986% (26015/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9718, Accuracy: 4413/10000 (44.13%)

Epoch: 47
Loss: 1.273 | Acc: 68.750% (44/64)
Loss: 1.434 | Acc: 58.447% (3778/6464)
Loss: 1.436 | Acc: 58.256% (7494/12864)
Loss: 1.432 | Acc: 58.524% (11274/19264)
Loss: 1.430 | Acc: 58.584% (15035/25664)
Loss: 1.439 | Acc: 58.237% (18673/32064)
Loss: 1.442 | Acc: 58.117% (22354/38464)
Loss: 1.444 | Acc: 58.093% (26063/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9668, Accuracy: 4449/10000 (44.49%)
torch.Size([100, 10])
Test set: Average loss: 1.9668, Accuracy: 4449/10000 (44.49%)

Epoch: 48
Loss: 1.413 | Acc: 57.812% (37/64)
Loss: 1.415 | Acc: 58.524% (3783/6464)
Loss: 1.424 | Acc: 58.287% (7498/12864)
Loss: 1.432 | Acc: 58.031% (11179/19264)
Loss: 1.438 | Acc: 57.805% (14835/25664)
Loss: 1.430 | Acc: 58.268% (18683/32064)
Loss: 1.428 | Acc: 58.405% (22465/38464)
Loss: 1.428 | Acc: 58.441% (26219/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9758, Accuracy: 4426/10000 (44.26%)
torch.Size([100, 10])
Test set: Average loss: 1.9758, Accuracy: 4426/10000 (44.26%)

Epoch: 49
Loss: 1.422 | Acc: 56.250% (36/64)
Loss: 1.432 | Acc: 57.828% (3738/6464)
Loss: 1.431 | Acc: 58.170% (7483/12864)
Loss: 1.426 | Acc: 58.191% (11210/19264)
Loss: 1.420 | Acc: 58.502% (15014/25664)
Loss: 1.418 | Acc: 58.545% (18772/32064)
Loss: 1.420 | Acc: 58.564% (22526/38464)
Loss: 1.417 | Acc: 58.704% (26337/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9815, Accuracy: 4423/10000 (44.23%)
torch.Size([100, 10])
Test set: Average loss: 1.9815, Accuracy: 4423/10000 (44.23%)

Epoch: 50
Loss: 1.316 | Acc: 65.625% (42/64)
Loss: 2.144 | Acc: 26.191% (1693/6464)
Loss: 2.058 | Acc: 31.973% (4113/12864)
Loss: 2.015 | Acc: 34.785% (6701/19264)
Loss: 1.993 | Acc: 36.292% (9314/25664)
Loss: 1.977 | Acc: 37.381% (11986/32064)
Loss: 1.964 | Acc: 38.168% (14681/38464)
Loss: 1.955 | Acc: 38.813% (17413/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2573, Accuracy: 2589/10000 (25.89%)

Epoch: 51
Loss: 2.022 | Acc: 37.500% (24/64)
Loss: 1.889 | Acc: 42.806% (2767/6464)
Loss: 1.895 | Acc: 42.351% (5448/12864)
Loss: 1.891 | Acc: 42.509% (8189/19264)
Loss: 1.887 | Acc: 42.639% (10943/25664)
Loss: 1.884 | Acc: 42.849% (13739/32064)
Loss: 1.883 | Acc: 42.978% (16531/38464)
Loss: 1.881 | Acc: 43.063% (19320/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0478, Accuracy: 3486/10000 (34.86%)

Epoch: 52
Loss: 1.654 | Acc: 46.875% (30/64)
Loss: 1.861 | Acc: 44.230% (2859/6464)
Loss: 1.864 | Acc: 44.216% (5688/12864)
Loss: 1.862 | Acc: 44.305% (8535/19264)
Loss: 1.868 | Acc: 43.999% (11292/25664)
Loss: 1.867 | Acc: 43.987% (14104/32064)
Loss: 1.866 | Acc: 44.072% (16952/38464)
Loss: 1.868 | Acc: 44.002% (19741/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0831, Accuracy: 3273/10000 (32.73%)

Epoch: 53
Loss: 1.778 | Acc: 42.188% (27/64)
Loss: 1.853 | Acc: 44.663% (2887/6464)
Loss: 1.855 | Acc: 44.473% (5721/12864)
Loss: 1.864 | Acc: 44.124% (8500/19264)
Loss: 1.867 | Acc: 43.964% (11283/25664)
Loss: 1.870 | Acc: 43.828% (14053/32064)
Loss: 1.870 | Acc: 43.773% (16837/38464)
Loss: 1.871 | Acc: 43.808% (19654/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4525, Accuracy: 2582/10000 (25.82%)

Epoch: 54
Loss: 1.835 | Acc: 42.188% (27/64)
Loss: 1.864 | Acc: 43.951% (2841/6464)
Loss: 1.867 | Acc: 43.983% (5658/12864)
Loss: 1.866 | Acc: 44.082% (8492/19264)
Loss: 1.861 | Acc: 44.319% (11374/25664)
Loss: 1.863 | Acc: 44.137% (14152/32064)
Loss: 1.863 | Acc: 44.223% (17010/38464)
Loss: 1.863 | Acc: 44.216% (19837/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0345, Accuracy: 3473/10000 (34.73%)

Epoch: 55
Loss: 1.780 | Acc: 43.750% (28/64)
Loss: 1.859 | Acc: 44.137% (2853/6464)
Loss: 1.859 | Acc: 44.496% (5724/12864)
Loss: 1.856 | Acc: 44.710% (8613/19264)
Loss: 1.858 | Acc: 44.397% (11394/25664)
Loss: 1.858 | Acc: 44.470% (14259/32064)
Loss: 1.856 | Acc: 44.592% (17152/38464)
Loss: 1.859 | Acc: 44.463% (19948/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0018, Accuracy: 3884/10000 (38.84%)

Epoch: 56
Loss: 2.018 | Acc: 37.500% (24/64)
Loss: 1.864 | Acc: 44.214% (2858/6464)
Loss: 1.857 | Acc: 44.434% (5716/12864)
Loss: 1.856 | Acc: 44.679% (8607/19264)
Loss: 1.865 | Acc: 44.264% (11360/25664)
Loss: 1.862 | Acc: 44.386% (14232/32064)
Loss: 1.859 | Acc: 44.512% (17121/38464)
Loss: 1.859 | Acc: 44.481% (19956/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0328, Accuracy: 3745/10000 (37.45%)

Epoch: 57
Loss: 1.995 | Acc: 40.625% (26/64)
Loss: 1.834 | Acc: 46.086% (2979/6464)
Loss: 1.842 | Acc: 45.639% (5871/12864)
Loss: 1.853 | Acc: 45.037% (8676/19264)
Loss: 1.852 | Acc: 44.989% (11546/25664)
Loss: 1.852 | Acc: 45.004% (14430/32064)
Loss: 1.855 | Acc: 44.863% (17256/38464)
Loss: 1.853 | Acc: 44.934% (20159/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0450, Accuracy: 3352/10000 (33.52%)

Epoch: 58
Loss: 1.761 | Acc: 46.875% (30/64)
Loss: 1.845 | Acc: 44.787% (2895/6464)
Loss: 1.853 | Acc: 44.574% (5734/12864)
Loss: 1.853 | Acc: 44.461% (8565/19264)
Loss: 1.851 | Acc: 44.638% (11456/25664)
Loss: 1.852 | Acc: 44.679% (14326/32064)
Loss: 1.854 | Acc: 44.657% (17177/38464)
Loss: 1.852 | Acc: 44.720% (20063/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0220, Accuracy: 3543/10000 (35.43%)

Epoch: 59
Loss: 1.800 | Acc: 48.438% (31/64)
Loss: 1.856 | Acc: 44.895% (2902/6464)
Loss: 1.843 | Acc: 45.375% (5837/12864)
Loss: 1.847 | Acc: 45.105% (8689/19264)
Loss: 1.845 | Acc: 45.141% (11585/25664)
Loss: 1.848 | Acc: 45.082% (14455/32064)
Loss: 1.849 | Acc: 45.029% (17320/38464)
Loss: 1.851 | Acc: 44.864% (20128/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9914, Accuracy: 3733/10000 (37.33%)

Epoch: 60
Loss: 2.014 | Acc: 34.375% (22/64)
Loss: 1.850 | Acc: 45.019% (2910/6464)
Loss: 1.856 | Acc: 44.761% (5758/12864)
Loss: 1.856 | Acc: 44.617% (8595/19264)
Loss: 1.851 | Acc: 44.946% (11535/25664)
Loss: 1.850 | Acc: 44.923% (14404/32064)
Loss: 1.851 | Acc: 44.897% (17269/38464)
Loss: 1.852 | Acc: 44.771% (20086/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9651, Accuracy: 3972/10000 (39.72%)

Epoch: 61
Loss: 1.837 | Acc: 45.312% (29/64)
Loss: 1.831 | Acc: 45.699% (2954/6464)
Loss: 1.832 | Acc: 45.794% (5891/12864)
Loss: 1.838 | Acc: 45.437% (8753/19264)
Loss: 1.845 | Acc: 45.098% (11574/25664)
Loss: 1.845 | Acc: 45.138% (14473/32064)
Loss: 1.845 | Acc: 45.190% (17382/38464)
Loss: 1.845 | Acc: 45.188% (20273/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0366, Accuracy: 3626/10000 (36.26%)

Epoch: 62
Loss: 1.750 | Acc: 48.438% (31/64)
Loss: 1.834 | Acc: 45.885% (2966/6464)
Loss: 1.837 | Acc: 45.826% (5895/12864)
Loss: 1.836 | Acc: 45.707% (8805/19264)
Loss: 1.835 | Acc: 45.593% (11701/25664)
Loss: 1.842 | Acc: 45.247% (14508/32064)
Loss: 1.843 | Acc: 45.227% (17396/38464)
Loss: 1.844 | Acc: 45.190% (20274/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0495, Accuracy: 3529/10000 (35.29%)

Epoch: 63
Loss: 1.710 | Acc: 50.000% (32/64)
Loss: 1.833 | Acc: 45.374% (2933/6464)
Loss: 1.830 | Acc: 45.662% (5874/12864)
Loss: 1.825 | Acc: 45.961% (8854/19264)
Loss: 1.831 | Acc: 45.729% (11736/25664)
Loss: 1.837 | Acc: 45.462% (14577/32064)
Loss: 1.841 | Acc: 45.245% (17403/38464)
Loss: 1.843 | Acc: 45.228% (20291/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9891, Accuracy: 3803/10000 (38.03%)

Epoch: 64
Loss: 1.915 | Acc: 48.438% (31/64)
Loss: 1.833 | Acc: 45.823% (2962/6464)
Loss: 1.833 | Acc: 45.748% (5885/12864)
Loss: 1.828 | Acc: 45.998% (8861/19264)
Loss: 1.834 | Acc: 45.690% (11726/25664)
Loss: 1.835 | Acc: 45.718% (14659/32064)
Loss: 1.836 | Acc: 45.559% (17524/38464)
Loss: 1.839 | Acc: 45.404% (20370/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9633, Accuracy: 3889/10000 (38.89%)

Epoch: 65
Loss: 1.667 | Acc: 51.562% (33/64)
Loss: 1.822 | Acc: 46.303% (2993/6464)
Loss: 1.820 | Acc: 46.300% (5956/12864)
Loss: 1.834 | Acc: 45.572% (8779/19264)
Loss: 1.838 | Acc: 45.351% (11639/25664)
Loss: 1.840 | Acc: 45.328% (14534/32064)
Loss: 1.841 | Acc: 45.344% (17441/38464)
Loss: 1.838 | Acc: 45.473% (20401/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0072, Accuracy: 3659/10000 (36.59%)

Epoch: 66
Loss: 1.873 | Acc: 45.312% (29/64)
Loss: 1.830 | Acc: 45.947% (2970/6464)
Loss: 1.837 | Acc: 45.553% (5860/12864)
Loss: 1.839 | Acc: 45.385% (8743/19264)
Loss: 1.836 | Acc: 45.406% (11653/25664)
Loss: 1.835 | Acc: 45.437% (14569/32064)
Loss: 1.833 | Acc: 45.614% (17545/38464)
Loss: 1.829 | Acc: 45.772% (20535/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2519, Accuracy: 2632/10000 (26.32%)

Epoch: 67
Loss: 1.691 | Acc: 50.000% (32/64)
Loss: 1.835 | Acc: 45.823% (2962/6464)
Loss: 1.836 | Acc: 45.896% (5904/12864)
Loss: 1.831 | Acc: 46.164% (8893/19264)
Loss: 1.831 | Acc: 46.092% (11829/25664)
Loss: 1.828 | Acc: 46.167% (14803/32064)
Loss: 1.829 | Acc: 46.118% (17739/38464)
Loss: 1.827 | Acc: 46.175% (20716/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9920, Accuracy: 4003/10000 (40.03%)

Epoch: 68
Loss: 1.892 | Acc: 45.312% (29/64)
Loss: 1.833 | Acc: 45.606% (2948/6464)
Loss: 1.818 | Acc: 46.183% (5941/12864)
Loss: 1.824 | Acc: 45.977% (8857/19264)
Loss: 1.816 | Acc: 46.431% (11916/25664)
Loss: 1.816 | Acc: 46.435% (14889/32064)
Loss: 1.821 | Acc: 46.212% (17775/38464)
Loss: 1.821 | Acc: 46.164% (20711/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9071, Accuracy: 4294/10000 (42.94%)

Epoch: 69
Loss: 1.871 | Acc: 45.312% (29/64)
Loss: 1.787 | Acc: 47.989% (3102/6464)
Loss: 1.794 | Acc: 47.979% (6172/12864)
Loss: 1.808 | Acc: 47.176% (9088/19264)
Loss: 1.814 | Acc: 46.875% (12030/25664)
Loss: 1.815 | Acc: 46.844% (15020/32064)
Loss: 1.816 | Acc: 46.784% (17995/38464)
Loss: 1.816 | Acc: 46.681% (20943/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9771, Accuracy: 3857/10000 (38.57%)

Epoch: 70
Loss: 1.918 | Acc: 42.188% (27/64)
Loss: 1.792 | Acc: 47.803% (3090/6464)
Loss: 1.797 | Acc: 47.598% (6123/12864)
Loss: 1.808 | Acc: 47.020% (9058/19264)
Loss: 1.807 | Acc: 47.054% (12076/25664)
Loss: 1.811 | Acc: 46.887% (15034/32064)
Loss: 1.813 | Acc: 46.875% (18030/38464)
Loss: 1.813 | Acc: 46.801% (20997/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9432, Accuracy: 4128/10000 (41.28%)

Epoch: 71
Loss: 1.826 | Acc: 43.750% (28/64)
Loss: 1.778 | Acc: 48.283% (3121/6464)
Loss: 1.790 | Acc: 47.613% (6125/12864)
Loss: 1.798 | Acc: 47.379% (9127/19264)
Loss: 1.801 | Acc: 47.276% (12133/25664)
Loss: 1.803 | Acc: 47.227% (15143/32064)
Loss: 1.804 | Acc: 47.080% (18109/38464)
Loss: 1.805 | Acc: 46.955% (21066/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9920, Accuracy: 3737/10000 (37.37%)

Epoch: 72
Loss: 1.933 | Acc: 39.062% (25/64)
Loss: 1.791 | Acc: 47.463% (3068/6464)
Loss: 1.802 | Acc: 47.007% (6047/12864)
Loss: 1.809 | Acc: 46.771% (9010/19264)
Loss: 1.806 | Acc: 46.980% (12057/25664)
Loss: 1.806 | Acc: 46.947% (15053/32064)
Loss: 1.801 | Acc: 47.216% (18161/38464)
Loss: 1.803 | Acc: 47.183% (21168/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9353, Accuracy: 4175/10000 (41.75%)

Epoch: 73
Loss: 1.616 | Acc: 57.812% (37/64)
Loss: 1.802 | Acc: 47.014% (3039/6464)
Loss: 1.794 | Acc: 47.683% (6134/12864)
Loss: 1.800 | Acc: 47.347% (9121/19264)
Loss: 1.802 | Acc: 47.202% (12114/25664)
Loss: 1.801 | Acc: 47.231% (15144/32064)
Loss: 1.799 | Acc: 47.317% (18200/38464)
Loss: 1.797 | Acc: 47.472% (21298/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9363, Accuracy: 4028/10000 (40.28%)

Epoch: 74
Loss: 1.753 | Acc: 50.000% (32/64)
Loss: 1.791 | Acc: 47.695% (3083/6464)
Loss: 1.789 | Acc: 47.567% (6119/12864)
Loss: 1.789 | Acc: 47.716% (9192/19264)
Loss: 1.792 | Acc: 47.650% (12229/25664)
Loss: 1.787 | Acc: 47.867% (15348/32064)
Loss: 1.791 | Acc: 47.671% (18336/38464)
Loss: 1.792 | Acc: 47.702% (21401/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9091, Accuracy: 4169/10000 (41.69%)

Epoch: 75
Loss: 1.612 | Acc: 51.562% (33/64)
Loss: 1.757 | Acc: 48.948% (3164/6464)
Loss: 1.761 | Acc: 48.780% (6275/12864)
Loss: 1.772 | Acc: 48.365% (9317/19264)
Loss: 1.776 | Acc: 48.130% (12352/25664)
Loss: 1.778 | Acc: 48.129% (15432/32064)
Loss: 1.779 | Acc: 48.107% (18504/38464)
Loss: 1.781 | Acc: 48.052% (21558/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9471, Accuracy: 4120/10000 (41.20%)

Epoch: 76
Loss: 1.762 | Acc: 51.562% (33/64)
Loss: 1.763 | Acc: 48.577% (3140/6464)
Loss: 1.761 | Acc: 48.733% (6269/12864)
Loss: 1.773 | Acc: 48.370% (9318/19264)
Loss: 1.777 | Acc: 48.212% (12373/25664)
Loss: 1.777 | Acc: 48.191% (15452/32064)
Loss: 1.778 | Acc: 48.185% (18534/38464)
Loss: 1.776 | Acc: 48.324% (21680/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8877, Accuracy: 4328/10000 (43.28%)

Epoch: 77
Loss: 1.764 | Acc: 46.875% (30/64)
Loss: 1.775 | Acc: 48.175% (3114/6464)
Loss: 1.765 | Acc: 48.826% (6281/12864)
Loss: 1.769 | Acc: 48.645% (9371/19264)
Loss: 1.775 | Acc: 48.325% (12402/25664)
Loss: 1.772 | Acc: 48.506% (15553/32064)
Loss: 1.770 | Acc: 48.575% (18684/38464)
Loss: 1.769 | Acc: 48.620% (21813/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9806, Accuracy: 3765/10000 (37.65%)

Epoch: 78
Loss: 1.860 | Acc: 45.312% (29/64)
Loss: 1.765 | Acc: 48.376% (3127/6464)
Loss: 1.767 | Acc: 48.570% (6248/12864)
Loss: 1.764 | Acc: 48.640% (9370/19264)
Loss: 1.764 | Acc: 48.625% (12479/25664)
Loss: 1.761 | Acc: 48.762% (15635/32064)
Loss: 1.760 | Acc: 48.825% (18780/38464)
Loss: 1.763 | Acc: 48.779% (21884/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8910, Accuracy: 4334/10000 (43.34%)

Epoch: 79
Loss: 1.673 | Acc: 54.688% (35/64)
Loss: 1.742 | Acc: 49.722% (3214/6464)
Loss: 1.752 | Acc: 49.409% (6356/12864)
Loss: 1.749 | Acc: 49.439% (9524/19264)
Loss: 1.748 | Acc: 49.567% (12721/25664)
Loss: 1.750 | Acc: 49.526% (15880/32064)
Loss: 1.750 | Acc: 49.444% (19018/38464)
Loss: 1.749 | Acc: 49.474% (22196/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8897, Accuracy: 4353/10000 (43.53%)

Epoch: 80
Loss: 1.853 | Acc: 46.875% (30/64)
Loss: 1.763 | Acc: 48.592% (3141/6464)
Loss: 1.745 | Acc: 49.627% (6384/12864)
Loss: 1.740 | Acc: 49.772% (9588/19264)
Loss: 1.738 | Acc: 49.770% (12773/25664)
Loss: 1.742 | Acc: 49.588% (15900/32064)
Loss: 1.743 | Acc: 49.540% (19055/38464)
Loss: 1.746 | Acc: 49.452% (22186/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8934, Accuracy: 4395/10000 (43.95%)

Epoch: 81
Loss: 1.851 | Acc: 45.312% (29/64)
Loss: 1.722 | Acc: 50.402% (3258/6464)
Loss: 1.730 | Acc: 50.093% (6444/12864)
Loss: 1.733 | Acc: 50.119% (9655/19264)
Loss: 1.735 | Acc: 50.023% (12838/25664)
Loss: 1.735 | Acc: 50.019% (16038/32064)
Loss: 1.731 | Acc: 50.200% (19309/38464)
Loss: 1.733 | Acc: 50.049% (22454/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8951, Accuracy: 4371/10000 (43.71%)

Epoch: 82
Loss: 1.652 | Acc: 53.125% (34/64)
Loss: 1.733 | Acc: 49.613% (3207/6464)
Loss: 1.726 | Acc: 49.852% (6413/12864)
Loss: 1.718 | Acc: 50.426% (9714/19264)
Loss: 1.718 | Acc: 50.448% (12947/25664)
Loss: 1.721 | Acc: 50.356% (16146/32064)
Loss: 1.725 | Acc: 50.203% (19310/38464)
Loss: 1.724 | Acc: 50.221% (22531/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8802, Accuracy: 4489/10000 (44.89%)

Epoch: 83
Loss: 1.840 | Acc: 42.188% (27/64)
Loss: 1.682 | Acc: 51.671% (3340/6464)
Loss: 1.685 | Acc: 51.469% (6621/12864)
Loss: 1.692 | Acc: 51.267% (9876/19264)
Loss: 1.702 | Acc: 50.904% (13064/25664)
Loss: 1.703 | Acc: 50.964% (16341/32064)
Loss: 1.705 | Acc: 50.959% (19601/38464)
Loss: 1.704 | Acc: 51.016% (22888/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8614, Accuracy: 4602/10000 (46.02%)

Epoch: 84
Loss: 1.825 | Acc: 46.875% (30/64)
Loss: 1.695 | Acc: 51.269% (3314/6464)
Loss: 1.686 | Acc: 51.578% (6635/12864)
Loss: 1.696 | Acc: 51.355% (9893/19264)
Loss: 1.702 | Acc: 51.079% (13109/25664)
Loss: 1.700 | Acc: 51.160% (16404/32064)
Loss: 1.699 | Acc: 51.178% (19685/38464)
Loss: 1.696 | Acc: 51.286% (23009/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8960, Accuracy: 4410/10000 (44.10%)

Epoch: 85
Loss: 1.576 | Acc: 56.250% (36/64)
Loss: 1.688 | Acc: 51.037% (3299/6464)
Loss: 1.680 | Acc: 51.570% (6634/12864)
Loss: 1.672 | Acc: 51.957% (10009/19264)
Loss: 1.668 | Acc: 52.205% (13398/25664)
Loss: 1.669 | Acc: 52.062% (16693/32064)
Loss: 1.675 | Acc: 51.911% (19967/38464)
Loss: 1.680 | Acc: 51.707% (23198/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9717, Accuracy: 3985/10000 (39.85%)

Epoch: 86
Loss: 1.559 | Acc: 54.688% (35/64)
Loss: 1.647 | Acc: 52.769% (3411/6464)
Loss: 1.648 | Acc: 52.635% (6771/12864)
Loss: 1.644 | Acc: 52.839% (10179/19264)
Loss: 1.650 | Acc: 52.591% (13497/25664)
Loss: 1.658 | Acc: 52.355% (16787/32064)
Loss: 1.662 | Acc: 52.257% (20100/38464)
Loss: 1.660 | Acc: 52.285% (23457/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8980, Accuracy: 4510/10000 (45.10%)

Epoch: 87
Loss: 1.316 | Acc: 64.062% (41/64)
Loss: 1.621 | Acc: 53.218% (3440/6464)
Loss: 1.628 | Acc: 53.172% (6840/12864)
Loss: 1.638 | Acc: 52.865% (10184/19264)
Loss: 1.640 | Acc: 52.770% (13543/25664)
Loss: 1.637 | Acc: 52.982% (16988/32064)
Loss: 1.638 | Acc: 52.959% (20370/38464)
Loss: 1.636 | Acc: 53.056% (23803/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9065, Accuracy: 4503/10000 (45.03%)

Epoch: 88
Loss: 1.739 | Acc: 48.438% (31/64)
Loss: 1.616 | Acc: 53.171% (3437/6464)
Loss: 1.611 | Acc: 53.568% (6891/12864)
Loss: 1.612 | Acc: 53.654% (10336/19264)
Loss: 1.613 | Acc: 53.784% (13803/25664)
Loss: 1.614 | Acc: 53.686% (17214/32064)
Loss: 1.608 | Acc: 53.957% (20754/38464)
Loss: 1.609 | Acc: 53.916% (24189/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9056, Accuracy: 4537/10000 (45.37%)

Epoch: 89
Loss: 1.476 | Acc: 59.375% (38/64)
Loss: 1.585 | Acc: 54.425% (3518/6464)
Loss: 1.560 | Acc: 55.356% (7121/12864)
Loss: 1.569 | Acc: 55.020% (10599/19264)
Loss: 1.575 | Acc: 54.750% (14051/25664)
Loss: 1.574 | Acc: 54.716% (17544/32064)
Loss: 1.578 | Acc: 54.573% (20991/38464)
Loss: 1.581 | Acc: 54.449% (24428/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9147, Accuracy: 4595/10000 (45.95%)

Epoch: 90
Loss: 1.679 | Acc: 53.125% (34/64)
Loss: 1.528 | Acc: 55.894% (3613/6464)
Loss: 1.541 | Acc: 55.465% (7135/12864)
Loss: 1.549 | Acc: 55.316% (10656/19264)
Loss: 1.549 | Acc: 55.198% (14166/25664)
Loss: 1.550 | Acc: 55.187% (17695/32064)
Loss: 1.552 | Acc: 55.137% (21208/38464)
Loss: 1.553 | Acc: 55.200% (24765/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9383, Accuracy: 4479/10000 (44.79%)

Epoch: 91
Loss: 1.491 | Acc: 57.812% (37/64)
Loss: 1.509 | Acc: 56.250% (3636/6464)
Loss: 1.512 | Acc: 56.273% (7239/12864)
Loss: 1.511 | Acc: 56.323% (10850/19264)
Loss: 1.507 | Acc: 56.445% (14486/25664)
Loss: 1.511 | Acc: 56.250% (18036/32064)
Loss: 1.512 | Acc: 56.349% (21674/38464)
Loss: 1.513 | Acc: 56.297% (25257/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9809, Accuracy: 4396/10000 (43.96%)

Epoch: 92
Loss: 1.484 | Acc: 62.500% (40/64)
Loss: 1.467 | Acc: 57.271% (3702/6464)
Loss: 1.450 | Acc: 58.092% (7473/12864)
Loss: 1.455 | Acc: 57.880% (11150/19264)
Loss: 1.457 | Acc: 57.840% (14844/25664)
Loss: 1.465 | Acc: 57.426% (18413/32064)
Loss: 1.465 | Acc: 57.433% (22091/38464)
Loss: 1.466 | Acc: 57.378% (25742/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9974, Accuracy: 4411/10000 (44.11%)

Epoch: 93
Loss: 1.420 | Acc: 62.500% (40/64)
Loss: 1.404 | Acc: 59.143% (3823/6464)
Loss: 1.393 | Acc: 59.593% (7666/12864)
Loss: 1.395 | Acc: 59.567% (11475/19264)
Loss: 1.401 | Acc: 59.422% (15250/25664)
Loss: 1.398 | Acc: 59.437% (19058/32064)
Loss: 1.405 | Acc: 59.214% (22776/38464)
Loss: 1.408 | Acc: 59.123% (26525/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0132, Accuracy: 4392/10000 (43.92%)

Epoch: 94
Loss: 1.317 | Acc: 59.375% (38/64)
Loss: 1.323 | Acc: 61.340% (3965/6464)
Loss: 1.326 | Acc: 61.350% (7892/12864)
Loss: 1.334 | Acc: 61.036% (11758/19264)
Loss: 1.339 | Acc: 60.895% (15628/25664)
Loss: 1.343 | Acc: 60.679% (19456/32064)
Loss: 1.345 | Acc: 60.639% (23324/38464)
Loss: 1.344 | Acc: 60.688% (27227/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0771, Accuracy: 4269/10000 (42.69%)

Epoch: 95
Loss: 1.183 | Acc: 65.625% (42/64)
Loss: 1.265 | Acc: 62.701% (4053/6464)
Loss: 1.279 | Acc: 62.135% (7993/12864)
Loss: 1.294 | Acc: 61.773% (11900/19264)
Loss: 1.301 | Acc: 61.740% (15845/25664)
Loss: 1.311 | Acc: 61.430% (19697/32064)
Loss: 1.317 | Acc: 61.270% (23567/38464)
Loss: 1.318 | Acc: 61.314% (27508/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0877, Accuracy: 4320/10000 (43.20%)

Epoch: 96
Loss: 1.191 | Acc: 68.750% (44/64)
Loss: 1.318 | Acc: 61.525% (3977/6464)
Loss: 1.306 | Acc: 61.777% (7947/12864)
Loss: 1.312 | Acc: 61.483% (11844/19264)
Loss: 1.317 | Acc: 61.195% (15705/25664)
Loss: 1.310 | Acc: 61.518% (19725/32064)
Loss: 1.313 | Acc: 61.535% (23669/38464)
Loss: 1.314 | Acc: 61.446% (27567/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0941, Accuracy: 4308/10000 (43.08%)

Epoch: 97
Loss: 1.365 | Acc: 56.250% (36/64)
Loss: 1.273 | Acc: 62.655% (4050/6464)
Loss: 1.278 | Acc: 62.290% (8013/12864)
Loss: 1.287 | Acc: 61.971% (11938/19264)
Loss: 1.284 | Acc: 61.993% (15910/25664)
Loss: 1.285 | Acc: 62.023% (19887/32064)
Loss: 1.284 | Acc: 62.126% (23896/38464)
Loss: 1.286 | Acc: 62.041% (27834/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0985, Accuracy: 4297/10000 (42.97%)
torch.Size([100, 10])
Test set: Average loss: 2.0985, Accuracy: 4297/10000 (42.97%)

Epoch: 98
Loss: 1.142 | Acc: 68.750% (44/64)
Loss: 1.274 | Acc: 62.206% (4021/6464)
Loss: 1.282 | Acc: 62.002% (7976/12864)
Loss: 1.277 | Acc: 62.163% (11975/19264)
Loss: 1.275 | Acc: 62.290% (15986/25664)
Loss: 1.276 | Acc: 62.394% (20006/32064)
Loss: 1.272 | Acc: 62.568% (24066/38464)
Loss: 1.273 | Acc: 62.502% (28041/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0985, Accuracy: 4313/10000 (43.13%)
torch.Size([100, 10])
Test set: Average loss: 2.0985, Accuracy: 4313/10000 (43.13%)

Epoch: 99
Loss: 1.288 | Acc: 62.500% (40/64)
Loss: 1.244 | Acc: 63.397% (4098/6464)
Loss: 1.255 | Acc: 62.951% (8098/12864)
Loss: 1.250 | Acc: 63.263% (12187/19264)
Loss: 1.252 | Acc: 63.147% (16206/25664)
Loss: 1.254 | Acc: 63.018% (20206/32064)
Loss: 1.254 | Acc: 63.067% (24258/38464)
Loss: 1.255 | Acc: 63.106% (28312/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1029, Accuracy: 4293/10000 (42.93%)
torch.Size([100, 10])
Test set: Average loss: 2.1029, Accuracy: 4293/10000 (42.93%)

Epoch: 100
Loss: 1.438 | Acc: 54.688% (35/64)
Loss: 2.259 | Acc: 16.723% (1081/6464)
Loss: 2.197 | Acc: 21.284% (2738/12864)
Loss: 2.134 | Acc: 26.189% (5045/19264)
Loss: 2.080 | Acc: 29.867% (7665/25664)
Loss: 2.048 | Acc: 32.083% (10287/32064)
Loss: 2.020 | Acc: 33.936% (13053/38464)
Loss: 2.001 | Acc: 35.213% (15798/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2547, Accuracy: 2646/10000 (26.46%)

Epoch: 101
Loss: 2.086 | Acc: 32.812% (21/64)
Loss: 1.862 | Acc: 43.812% (2832/6464)
Loss: 1.859 | Acc: 44.045% (5666/12864)
Loss: 1.852 | Acc: 44.440% (8561/19264)
Loss: 1.858 | Acc: 44.370% (11387/25664)
Loss: 1.857 | Acc: 44.349% (14220/32064)
Loss: 1.856 | Acc: 44.421% (17086/38464)
Loss: 1.859 | Acc: 44.323% (19885/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0794, Accuracy: 3317/10000 (33.17%)

Epoch: 102
Loss: 1.840 | Acc: 43.750% (28/64)
Loss: 1.845 | Acc: 45.390% (2934/6464)
Loss: 1.849 | Acc: 45.064% (5797/12864)
Loss: 1.851 | Acc: 44.970% (8663/19264)
Loss: 1.848 | Acc: 44.935% (11532/25664)
Loss: 1.848 | Acc: 44.910% (14400/32064)
Loss: 1.851 | Acc: 44.730% (17205/38464)
Loss: 1.854 | Acc: 44.677% (20044/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1501, Accuracy: 3395/10000 (33.95%)

Epoch: 103
Loss: 1.976 | Acc: 40.625% (26/64)
Loss: 1.854 | Acc: 44.709% (2890/6464)
Loss: 1.853 | Acc: 44.807% (5764/12864)
Loss: 1.851 | Acc: 44.793% (8629/19264)
Loss: 1.849 | Acc: 44.927% (11530/25664)
Loss: 1.847 | Acc: 45.094% (14459/32064)
Loss: 1.847 | Acc: 45.146% (17365/38464)
Loss: 1.849 | Acc: 45.063% (20217/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0401, Accuracy: 3586/10000 (35.86%)

Epoch: 104
Loss: 1.819 | Acc: 46.875% (30/64)
Loss: 1.826 | Acc: 46.117% (2981/6464)
Loss: 1.835 | Acc: 45.647% (5872/12864)
Loss: 1.834 | Acc: 45.665% (8797/19264)
Loss: 1.838 | Acc: 45.558% (11692/25664)
Loss: 1.841 | Acc: 45.384% (14552/32064)
Loss: 1.846 | Acc: 45.146% (17365/38464)
Loss: 1.846 | Acc: 45.163% (20262/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9785, Accuracy: 3875/10000 (38.75%)

Epoch: 105
Loss: 2.150 | Acc: 31.250% (20/64)
Loss: 1.850 | Acc: 45.096% (2915/6464)
Loss: 1.833 | Acc: 45.585% (5864/12864)
Loss: 1.840 | Acc: 45.370% (8740/19264)
Loss: 1.837 | Acc: 45.394% (11650/25664)
Loss: 1.838 | Acc: 45.278% (14518/32064)
Loss: 1.841 | Acc: 45.136% (17361/38464)
Loss: 1.841 | Acc: 45.152% (20257/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3722, Accuracy: 2282/10000 (22.82%)

Epoch: 106
Loss: 2.129 | Acc: 29.688% (19/64)
Loss: 1.845 | Acc: 45.003% (2909/6464)
Loss: 1.856 | Acc: 44.683% (5748/12864)
Loss: 1.853 | Acc: 44.985% (8666/19264)
Loss: 1.852 | Acc: 44.942% (11534/25664)
Loss: 1.851 | Acc: 45.125% (14469/32064)
Loss: 1.851 | Acc: 45.167% (17373/38464)
Loss: 1.847 | Acc: 45.290% (20319/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0465, Accuracy: 3430/10000 (34.30%)

Epoch: 107
Loss: 2.012 | Acc: 37.500% (24/64)
Loss: 1.819 | Acc: 46.071% (2978/6464)
Loss: 1.832 | Acc: 45.452% (5847/12864)
Loss: 1.829 | Acc: 45.764% (8816/19264)
Loss: 1.835 | Acc: 45.457% (11666/25664)
Loss: 1.834 | Acc: 45.509% (14592/32064)
Loss: 1.837 | Acc: 45.328% (17435/38464)
Loss: 1.840 | Acc: 45.237% (20295/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2312, Accuracy: 3177/10000 (31.77%)

Epoch: 108
Loss: 1.990 | Acc: 35.938% (23/64)
Loss: 1.833 | Acc: 45.359% (2932/6464)
Loss: 1.825 | Acc: 45.841% (5897/12864)
Loss: 1.827 | Acc: 45.842% (8831/19264)
Loss: 1.830 | Acc: 45.710% (11731/25664)
Loss: 1.832 | Acc: 45.540% (14602/32064)
Loss: 1.836 | Acc: 45.409% (17466/38464)
Loss: 1.837 | Acc: 45.384% (20361/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2907, Accuracy: 2615/10000 (26.15%)

Epoch: 109
Loss: 1.887 | Acc: 42.188% (27/64)
Loss: 1.846 | Acc: 45.560% (2945/6464)
Loss: 1.829 | Acc: 45.911% (5906/12864)
Loss: 1.833 | Acc: 45.780% (8819/19264)
Loss: 1.832 | Acc: 45.788% (11751/25664)
Loss: 1.837 | Acc: 45.550% (14605/32064)
Loss: 1.838 | Acc: 45.474% (17491/38464)
Loss: 1.839 | Acc: 45.431% (20382/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0120, Accuracy: 3748/10000 (37.48%)

Epoch: 110
Loss: 1.870 | Acc: 42.188% (27/64)
Loss: 1.845 | Acc: 45.142% (2918/6464)
Loss: 1.834 | Acc: 45.810% (5893/12864)
Loss: 1.832 | Acc: 45.904% (8843/19264)
Loss: 1.832 | Acc: 45.870% (11772/25664)
Loss: 1.833 | Acc: 45.802% (14686/32064)
Loss: 1.834 | Acc: 45.804% (17618/38464)
Loss: 1.832 | Acc: 45.888% (20587/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0528, Accuracy: 3378/10000 (33.78%)

Epoch: 111
Loss: 1.809 | Acc: 43.750% (28/64)
Loss: 1.820 | Acc: 46.071% (2978/6464)
Loss: 1.821 | Acc: 46.222% (5946/12864)
Loss: 1.826 | Acc: 45.946% (8851/19264)
Loss: 1.828 | Acc: 45.870% (11772/25664)
Loss: 1.832 | Acc: 45.771% (14676/32064)
Loss: 1.834 | Acc: 45.741% (17594/38464)
Loss: 1.835 | Acc: 45.841% (20566/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0381, Accuracy: 3650/10000 (36.50%)

Epoch: 112
Loss: 1.973 | Acc: 42.188% (27/64)
Loss: 1.818 | Acc: 46.194% (2986/6464)
Loss: 1.822 | Acc: 46.113% (5932/12864)
Loss: 1.825 | Acc: 46.024% (8866/19264)
Loss: 1.829 | Acc: 45.905% (11781/25664)
Loss: 1.829 | Acc: 45.955% (14735/32064)
Loss: 1.833 | Acc: 45.778% (17608/38464)
Loss: 1.831 | Acc: 45.832% (20562/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9211, Accuracy: 4154/10000 (41.54%)

Epoch: 113
Loss: 1.676 | Acc: 53.125% (34/64)
Loss: 1.803 | Acc: 47.649% (3080/6464)
Loss: 1.816 | Acc: 46.556% (5989/12864)
Loss: 1.820 | Acc: 46.356% (8930/19264)
Loss: 1.822 | Acc: 46.294% (11881/25664)
Loss: 1.825 | Acc: 46.201% (14814/32064)
Loss: 1.830 | Acc: 45.973% (17683/38464)
Loss: 1.829 | Acc: 46.097% (20681/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0088, Accuracy: 3706/10000 (37.06%)

Epoch: 114
Loss: 1.692 | Acc: 53.125% (34/64)
Loss: 1.818 | Acc: 46.225% (2988/6464)
Loss: 1.819 | Acc: 46.074% (5927/12864)
Loss: 1.820 | Acc: 46.143% (8889/19264)
Loss: 1.817 | Acc: 46.404% (11909/25664)
Loss: 1.820 | Acc: 46.342% (14859/32064)
Loss: 1.822 | Acc: 46.241% (17786/38464)
Loss: 1.824 | Acc: 46.086% (20676/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0110, Accuracy: 3673/10000 (36.73%)

Epoch: 115
Loss: 1.755 | Acc: 48.438% (31/64)
Loss: 1.791 | Acc: 47.618% (3078/6464)
Loss: 1.817 | Acc: 46.471% (5978/12864)
Loss: 1.816 | Acc: 46.558% (8969/19264)
Loss: 1.820 | Acc: 46.435% (11917/25664)
Loss: 1.823 | Acc: 46.223% (14821/32064)
Loss: 1.820 | Acc: 46.347% (17827/38464)
Loss: 1.821 | Acc: 46.309% (20776/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9646, Accuracy: 3920/10000 (39.20%)

Epoch: 116
Loss: 1.630 | Acc: 57.812% (37/64)
Loss: 1.799 | Acc: 47.772% (3088/6464)
Loss: 1.803 | Acc: 47.295% (6084/12864)
Loss: 1.812 | Acc: 46.937% (9042/19264)
Loss: 1.815 | Acc: 46.793% (12009/25664)
Loss: 1.813 | Acc: 46.891% (15035/32064)
Loss: 1.814 | Acc: 46.805% (18003/38464)
Loss: 1.817 | Acc: 46.621% (20916/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0152, Accuracy: 3634/10000 (36.34%)

Epoch: 117
Loss: 1.590 | Acc: 50.000% (32/64)
Loss: 1.804 | Acc: 46.921% (3033/6464)
Loss: 1.811 | Acc: 46.720% (6010/12864)
Loss: 1.814 | Acc: 46.673% (8991/19264)
Loss: 1.818 | Acc: 46.571% (11952/25664)
Loss: 1.819 | Acc: 46.569% (14932/32064)
Loss: 1.819 | Acc: 46.602% (17925/38464)
Loss: 1.816 | Acc: 46.697% (20950/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9631, Accuracy: 4011/10000 (40.11%)

Epoch: 118
Loss: 1.964 | Acc: 42.188% (27/64)
Loss: 1.796 | Acc: 47.618% (3078/6464)
Loss: 1.800 | Acc: 47.466% (6106/12864)
Loss: 1.805 | Acc: 47.301% (9112/19264)
Loss: 1.805 | Acc: 47.288% (12136/25664)
Loss: 1.806 | Acc: 47.162% (15122/32064)
Loss: 1.806 | Acc: 47.083% (18110/38464)
Loss: 1.807 | Acc: 47.044% (21106/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0383, Accuracy: 3515/10000 (35.15%)

Epoch: 119
Loss: 1.647 | Acc: 51.562% (33/64)
Loss: 1.818 | Acc: 46.720% (3020/6464)
Loss: 1.810 | Acc: 46.922% (6036/12864)
Loss: 1.798 | Acc: 47.171% (9087/19264)
Loss: 1.801 | Acc: 47.089% (12085/25664)
Loss: 1.804 | Acc: 47.078% (15095/32064)
Loss: 1.805 | Acc: 47.125% (18126/38464)
Loss: 1.807 | Acc: 47.018% (21094/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0682, Accuracy: 3439/10000 (34.39%)

Epoch: 120
Loss: 1.601 | Acc: 54.688% (35/64)
Loss: 1.814 | Acc: 46.488% (3005/6464)
Loss: 1.810 | Acc: 46.844% (6026/12864)
Loss: 1.802 | Acc: 47.192% (9091/19264)
Loss: 1.800 | Acc: 47.276% (12133/25664)
Loss: 1.800 | Acc: 47.262% (15154/32064)
Loss: 1.800 | Acc: 47.348% (18212/38464)
Loss: 1.804 | Acc: 47.171% (21163/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9727, Accuracy: 3892/10000 (38.92%)

Epoch: 121
Loss: 1.704 | Acc: 57.812% (37/64)
Loss: 1.790 | Acc: 48.113% (3110/6464)
Loss: 1.793 | Acc: 47.668% (6132/12864)
Loss: 1.791 | Acc: 47.597% (9169/19264)
Loss: 1.794 | Acc: 47.537% (12200/25664)
Loss: 1.792 | Acc: 47.577% (15255/32064)
Loss: 1.795 | Acc: 47.509% (18274/38464)
Loss: 1.797 | Acc: 47.455% (21290/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9198, Accuracy: 4277/10000 (42.77%)

Epoch: 122
Loss: 1.941 | Acc: 37.500% (24/64)
Loss: 1.787 | Acc: 47.447% (3067/6464)
Loss: 1.793 | Acc: 47.676% (6133/12864)
Loss: 1.790 | Acc: 47.695% (9188/19264)
Loss: 1.788 | Acc: 47.888% (12290/25664)
Loss: 1.790 | Acc: 47.811% (15330/32064)
Loss: 1.790 | Acc: 47.845% (18403/38464)
Loss: 1.792 | Acc: 47.724% (21411/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9044, Accuracy: 4314/10000 (43.14%)

Epoch: 123
Loss: 1.894 | Acc: 43.750% (28/64)
Loss: 1.777 | Acc: 48.345% (3125/6464)
Loss: 1.783 | Acc: 48.298% (6213/12864)
Loss: 1.782 | Acc: 48.271% (9299/19264)
Loss: 1.777 | Acc: 48.426% (12428/25664)
Loss: 1.777 | Acc: 48.366% (15508/32064)
Loss: 1.779 | Acc: 48.318% (18585/38464)
Loss: 1.782 | Acc: 48.186% (21618/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9879, Accuracy: 3830/10000 (38.30%)

Epoch: 124
Loss: 1.679 | Acc: 56.250% (36/64)
Loss: 1.770 | Acc: 48.468% (3133/6464)
Loss: 1.763 | Acc: 48.577% (6249/12864)
Loss: 1.767 | Acc: 48.733% (9388/19264)
Loss: 1.766 | Acc: 48.773% (12517/25664)
Loss: 1.771 | Acc: 48.603% (15584/32064)
Loss: 1.775 | Acc: 48.406% (18619/38464)
Loss: 1.778 | Acc: 48.295% (21667/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9347, Accuracy: 4111/10000 (41.11%)

Epoch: 125
Loss: 1.737 | Acc: 50.000% (32/64)
Loss: 1.778 | Acc: 48.004% (3103/6464)
Loss: 1.766 | Acc: 48.616% (6254/12864)
Loss: 1.768 | Acc: 48.489% (9341/19264)
Loss: 1.762 | Acc: 48.858% (12539/25664)
Loss: 1.769 | Acc: 48.612% (15587/32064)
Loss: 1.770 | Acc: 48.554% (18676/38464)
Loss: 1.771 | Acc: 48.544% (21779/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9294, Accuracy: 4077/10000 (40.77%)

Epoch: 126
Loss: 1.730 | Acc: 48.438% (31/64)
Loss: 1.737 | Acc: 49.814% (3220/6464)
Loss: 1.756 | Acc: 49.230% (6333/12864)
Loss: 1.761 | Acc: 48.910% (9422/19264)
Loss: 1.766 | Acc: 48.660% (12488/25664)
Loss: 1.770 | Acc: 48.491% (15548/32064)
Loss: 1.762 | Acc: 48.944% (18826/38464)
Loss: 1.764 | Acc: 48.841% (21912/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9083, Accuracy: 4239/10000 (42.39%)

Epoch: 127
Loss: 1.673 | Acc: 57.812% (37/64)
Loss: 1.760 | Acc: 48.902% (3161/6464)
Loss: 1.756 | Acc: 49.052% (6310/12864)
Loss: 1.761 | Acc: 48.868% (9414/19264)
Loss: 1.758 | Acc: 49.010% (12578/25664)
Loss: 1.761 | Acc: 48.880% (15673/32064)
Loss: 1.758 | Acc: 48.952% (18829/38464)
Loss: 1.756 | Acc: 49.097% (22027/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9139, Accuracy: 4162/10000 (41.62%)

Epoch: 128
Loss: 2.144 | Acc: 34.375% (22/64)
Loss: 1.726 | Acc: 50.418% (3259/6464)
Loss: 1.738 | Acc: 49.658% (6388/12864)
Loss: 1.738 | Acc: 49.792% (9592/19264)
Loss: 1.743 | Acc: 49.657% (12744/25664)
Loss: 1.744 | Acc: 49.623% (15911/32064)
Loss: 1.743 | Acc: 49.610% (19082/38464)
Loss: 1.746 | Acc: 49.481% (22199/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9081, Accuracy: 4317/10000 (43.17%)

Epoch: 129
Loss: 1.765 | Acc: 46.875% (30/64)
Loss: 1.722 | Acc: 50.480% (3263/6464)
Loss: 1.719 | Acc: 50.560% (6504/12864)
Loss: 1.722 | Acc: 50.420% (9713/19264)
Loss: 1.725 | Acc: 50.191% (12881/25664)
Loss: 1.734 | Acc: 49.928% (16009/32064)
Loss: 1.737 | Acc: 49.870% (19182/38464)
Loss: 1.738 | Acc: 49.844% (22362/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9117, Accuracy: 4274/10000 (42.74%)

Epoch: 130
Loss: 1.855 | Acc: 45.312% (29/64)
Loss: 1.722 | Acc: 50.696% (3277/6464)
Loss: 1.730 | Acc: 50.396% (6483/12864)
Loss: 1.732 | Acc: 50.234% (9677/19264)
Loss: 1.731 | Acc: 50.222% (12889/25664)
Loss: 1.730 | Acc: 50.234% (16107/32064)
Loss: 1.731 | Acc: 50.156% (19292/38464)
Loss: 1.729 | Acc: 50.234% (22537/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9269, Accuracy: 4193/10000 (41.93%)

Epoch: 131
Loss: 1.929 | Acc: 40.625% (26/64)
Loss: 1.698 | Acc: 51.238% (3312/6464)
Loss: 1.708 | Acc: 50.801% (6535/12864)
Loss: 1.707 | Acc: 50.857% (9797/19264)
Loss: 1.708 | Acc: 50.846% (13049/25664)
Loss: 1.711 | Acc: 50.720% (16263/32064)
Loss: 1.714 | Acc: 50.650% (19482/38464)
Loss: 1.718 | Acc: 50.493% (22653/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8836, Accuracy: 4468/10000 (44.68%)

Epoch: 132
Loss: 2.194 | Acc: 31.250% (20/64)
Loss: 1.689 | Acc: 51.872% (3353/6464)
Loss: 1.694 | Acc: 51.485% (6623/12864)
Loss: 1.701 | Acc: 51.147% (9853/19264)
Loss: 1.701 | Acc: 51.204% (13141/25664)
Loss: 1.702 | Acc: 51.117% (16390/32064)
Loss: 1.706 | Acc: 51.001% (19617/38464)
Loss: 1.706 | Acc: 51.023% (22891/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9160, Accuracy: 4294/10000 (42.94%)

Epoch: 133
Loss: 1.682 | Acc: 53.125% (34/64)
Loss: 1.645 | Acc: 53.125% (3434/6464)
Loss: 1.679 | Acc: 51.726% (6654/12864)
Loss: 1.695 | Acc: 51.095% (9843/19264)
Loss: 1.694 | Acc: 51.153% (13128/25664)
Loss: 1.695 | Acc: 51.088% (16381/32064)
Loss: 1.691 | Acc: 51.297% (19731/38464)
Loss: 1.690 | Acc: 51.351% (23038/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8950, Accuracy: 4466/10000 (44.66%)

Epoch: 134
Loss: 1.571 | Acc: 60.938% (39/64)
Loss: 1.662 | Acc: 52.584% (3399/6464)
Loss: 1.668 | Acc: 52.317% (6730/12864)
Loss: 1.673 | Acc: 52.134% (10043/19264)
Loss: 1.673 | Acc: 52.046% (13357/25664)
Loss: 1.675 | Acc: 51.962% (16661/32064)
Loss: 1.672 | Acc: 52.085% (20034/38464)
Loss: 1.672 | Acc: 52.039% (23347/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8887, Accuracy: 4506/10000 (45.06%)

Epoch: 135
Loss: 1.882 | Acc: 43.750% (28/64)
Loss: 1.655 | Acc: 52.553% (3397/6464)
Loss: 1.642 | Acc: 52.806% (6793/12864)
Loss: 1.647 | Acc: 52.632% (10139/19264)
Loss: 1.654 | Acc: 52.381% (13443/25664)
Loss: 1.654 | Acc: 52.420% (16808/32064)
Loss: 1.658 | Acc: 52.306% (20119/38464)
Loss: 1.659 | Acc: 52.345% (23484/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9158, Accuracy: 4427/10000 (44.27%)

Epoch: 136
Loss: 1.976 | Acc: 40.625% (26/64)
Loss: 1.633 | Acc: 53.311% (3446/6464)
Loss: 1.627 | Acc: 53.405% (6870/12864)
Loss: 1.627 | Acc: 53.411% (10289/19264)
Loss: 1.636 | Acc: 53.000% (13602/25664)
Loss: 1.639 | Acc: 52.788% (16926/32064)
Loss: 1.640 | Acc: 52.771% (20298/38464)
Loss: 1.637 | Acc: 52.942% (23752/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9502, Accuracy: 4257/10000 (42.57%)

Epoch: 137
Loss: 1.597 | Acc: 48.438% (31/64)
Loss: 1.596 | Acc: 54.394% (3516/6464)
Loss: 1.602 | Acc: 53.825% (6924/12864)
Loss: 1.610 | Acc: 53.717% (10348/19264)
Loss: 1.605 | Acc: 54.017% (13863/25664)
Loss: 1.605 | Acc: 53.989% (17311/32064)
Loss: 1.609 | Acc: 53.798% (20693/38464)
Loss: 1.611 | Acc: 53.711% (24097/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9355, Accuracy: 4359/10000 (43.59%)

Epoch: 138
Loss: 1.739 | Acc: 46.875% (30/64)
Loss: 1.573 | Acc: 54.904% (3549/6464)
Loss: 1.575 | Acc: 54.625% (7027/12864)
Loss: 1.576 | Acc: 54.765% (10550/19264)
Loss: 1.583 | Acc: 54.543% (13998/25664)
Loss: 1.583 | Acc: 54.519% (17481/32064)
Loss: 1.581 | Acc: 54.651% (21021/38464)
Loss: 1.580 | Acc: 54.714% (24547/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9349, Accuracy: 4428/10000 (44.28%)

Epoch: 139
Loss: 1.437 | Acc: 62.500% (40/64)
Loss: 1.519 | Acc: 56.838% (3674/6464)
Loss: 1.525 | Acc: 56.312% (7244/12864)
Loss: 1.530 | Acc: 56.131% (10813/19264)
Loss: 1.537 | Acc: 55.946% (14358/25664)
Loss: 1.542 | Acc: 55.845% (17906/32064)
Loss: 1.546 | Acc: 55.712% (21429/38464)
Loss: 1.549 | Acc: 55.604% (24946/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9496, Accuracy: 4432/10000 (44.32%)

Epoch: 140
Loss: 1.752 | Acc: 51.562% (33/64)
Loss: 1.493 | Acc: 57.611% (3724/6464)
Loss: 1.504 | Acc: 56.887% (7318/12864)
Loss: 1.506 | Acc: 56.769% (10936/19264)
Loss: 1.508 | Acc: 56.531% (14508/25664)
Loss: 1.509 | Acc: 56.543% (18130/32064)
Loss: 1.513 | Acc: 56.380% (21686/38464)
Loss: 1.515 | Acc: 56.319% (25267/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9561, Accuracy: 4475/10000 (44.75%)

Epoch: 141
Loss: 1.439 | Acc: 56.250% (36/64)
Loss: 1.430 | Acc: 58.601% (3788/6464)
Loss: 1.441 | Acc: 58.178% (7484/12864)
Loss: 1.446 | Acc: 58.041% (11181/19264)
Loss: 1.458 | Acc: 57.583% (14778/25664)
Loss: 1.461 | Acc: 57.494% (18435/32064)
Loss: 1.462 | Acc: 57.550% (22136/38464)
Loss: 1.468 | Acc: 57.440% (25770/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0164, Accuracy: 4346/10000 (43.46%)

Epoch: 142
Loss: 1.177 | Acc: 67.188% (43/64)
Loss: 1.419 | Acc: 58.400% (3775/6464)
Loss: 1.413 | Acc: 58.699% (7551/12864)
Loss: 1.420 | Acc: 58.461% (11262/19264)
Loss: 1.416 | Acc: 58.635% (15048/25664)
Loss: 1.419 | Acc: 58.614% (18794/32064)
Loss: 1.418 | Acc: 58.699% (22578/38464)
Loss: 1.419 | Acc: 58.691% (26331/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0832, Accuracy: 4353/10000 (43.53%)

Epoch: 143
Loss: 1.238 | Acc: 64.062% (41/64)
Loss: 1.354 | Acc: 60.504% (3911/6464)
Loss: 1.358 | Acc: 60.121% (7734/12864)
Loss: 1.353 | Acc: 60.418% (11639/19264)
Loss: 1.360 | Acc: 60.271% (15468/25664)
Loss: 1.359 | Acc: 60.336% (19346/32064)
Loss: 1.362 | Acc: 60.223% (23164/38464)
Loss: 1.363 | Acc: 60.204% (27010/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1186, Accuracy: 4279/10000 (42.79%)

Epoch: 144
Loss: 1.469 | Acc: 57.812% (37/64)
Loss: 1.278 | Acc: 62.314% (4028/6464)
Loss: 1.292 | Acc: 61.684% (7935/12864)
Loss: 1.293 | Acc: 61.856% (11916/19264)
Loss: 1.294 | Acc: 61.970% (15904/25664)
Loss: 1.293 | Acc: 61.985% (19875/32064)
Loss: 1.294 | Acc: 61.910% (23813/38464)
Loss: 1.300 | Acc: 61.740% (27699/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1500, Accuracy: 4302/10000 (43.02%)

Epoch: 145
Loss: 1.239 | Acc: 62.500% (40/64)
Loss: 1.241 | Acc: 63.567% (4109/6464)
Loss: 1.242 | Acc: 63.596% (8181/12864)
Loss: 1.237 | Acc: 63.580% (12248/19264)
Loss: 1.245 | Acc: 63.385% (16267/25664)
Loss: 1.249 | Acc: 63.311% (20300/32064)
Loss: 1.255 | Acc: 63.119% (24278/38464)
Loss: 1.261 | Acc: 62.977% (28254/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1532, Accuracy: 4236/10000 (42.36%)

Epoch: 146
Loss: 1.366 | Acc: 56.250% (36/64)
Loss: 1.225 | Acc: 63.598% (4111/6464)
Loss: 1.227 | Acc: 63.720% (8197/12864)
Loss: 1.240 | Acc: 63.351% (12204/19264)
Loss: 1.238 | Acc: 63.490% (16294/25664)
Loss: 1.241 | Acc: 63.389% (20325/32064)
Loss: 1.247 | Acc: 63.121% (24279/38464)
Loss: 1.250 | Acc: 63.002% (28265/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1381, Accuracy: 4242/10000 (42.42%)

Epoch: 147
Loss: 1.265 | Acc: 62.500% (40/64)
Loss: 1.194 | Acc: 64.650% (4179/6464)
Loss: 1.208 | Acc: 64.358% (8279/12864)
Loss: 1.215 | Acc: 64.037% (12336/19264)
Loss: 1.216 | Acc: 64.121% (16456/25664)
Loss: 1.219 | Acc: 64.034% (20532/32064)
Loss: 1.224 | Acc: 63.888% (24574/38464)
Loss: 1.223 | Acc: 63.967% (28698/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1398, Accuracy: 4213/10000 (42.13%)
torch.Size([100, 10])
Test set: Average loss: 2.1398, Accuracy: 4213/10000 (42.13%)

Epoch: 148
Loss: 1.177 | Acc: 62.500% (40/64)
Loss: 1.197 | Acc: 64.790% (4188/6464)
Loss: 1.210 | Acc: 64.342% (8277/12864)
Loss: 1.201 | Acc: 64.644% (12453/19264)
Loss: 1.200 | Acc: 64.608% (16581/25664)
Loss: 1.202 | Acc: 64.577% (20706/32064)
Loss: 1.207 | Acc: 64.393% (24768/38464)
Loss: 1.206 | Acc: 64.430% (28906/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1558, Accuracy: 4215/10000 (42.15%)
torch.Size([100, 10])
Test set: Average loss: 2.1558, Accuracy: 4215/10000 (42.15%)

Epoch: 149
Loss: 1.227 | Acc: 65.625% (42/64)
Loss: 1.192 | Acc: 64.991% (4201/6464)
Loss: 1.195 | Acc: 64.723% (8326/12864)
Loss: 1.194 | Acc: 64.810% (12485/19264)
Loss: 1.194 | Acc: 64.694% (16603/25664)
Loss: 1.193 | Acc: 64.699% (20745/32064)
Loss: 1.195 | Acc: 64.684% (24880/38464)
Loss: 1.193 | Acc: 64.838% (29089/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1723, Accuracy: 4225/10000 (42.25%)
torch.Size([100, 10])
Test set: Average loss: 2.1723, Accuracy: 4225/10000 (42.25%)

Epoch: 150
Loss: 1.177 | Acc: 62.500% (40/64)
Loss: 2.182 | Acc: 23.778% (1537/6464)
Loss: 2.074 | Acc: 30.908% (3976/12864)
Loss: 2.025 | Acc: 34.126% (6574/19264)
Loss: 1.990 | Acc: 36.347% (9328/25664)
Loss: 1.963 | Acc: 38.018% (12190/32064)
Loss: 1.948 | Acc: 38.953% (14983/38464)
Loss: 1.934 | Acc: 39.823% (17866/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3452, Accuracy: 2323/10000 (23.23%)

Epoch: 151
Loss: 1.976 | Acc: 40.625% (26/64)
Loss: 1.841 | Acc: 45.220% (2923/6464)
Loss: 1.838 | Acc: 45.188% (5813/12864)
Loss: 1.843 | Acc: 45.100% (8688/19264)
Loss: 1.844 | Acc: 45.067% (11566/25664)
Loss: 1.847 | Acc: 45.004% (14430/32064)
Loss: 1.848 | Acc: 45.011% (17313/38464)
Loss: 1.848 | Acc: 44.922% (20154/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0689, Accuracy: 3525/10000 (35.25%)

Epoch: 152
Loss: 1.657 | Acc: 51.562% (33/64)
Loss: 1.820 | Acc: 46.132% (2982/6464)
Loss: 1.832 | Acc: 45.709% (5880/12864)
Loss: 1.836 | Acc: 45.468% (8759/19264)
Loss: 1.840 | Acc: 45.262% (11616/25664)
Loss: 1.841 | Acc: 45.241% (14506/32064)
Loss: 1.841 | Acc: 45.261% (17409/38464)
Loss: 1.841 | Acc: 45.335% (20339/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0537, Accuracy: 3433/10000 (34.33%)

Epoch: 153
Loss: 1.802 | Acc: 40.625% (26/64)
Loss: 1.844 | Acc: 44.756% (2893/6464)
Loss: 1.833 | Acc: 45.390% (5839/12864)
Loss: 1.841 | Acc: 45.105% (8689/19264)
Loss: 1.833 | Acc: 45.585% (11699/25664)
Loss: 1.835 | Acc: 45.506% (14591/32064)
Loss: 1.838 | Acc: 45.359% (17447/38464)
Loss: 1.838 | Acc: 45.448% (20390/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0181, Accuracy: 3634/10000 (36.34%)

Epoch: 154
Loss: 2.104 | Acc: 34.375% (22/64)
Loss: 1.825 | Acc: 45.390% (2934/6464)
Loss: 1.828 | Acc: 45.810% (5893/12864)
Loss: 1.832 | Acc: 45.603% (8785/19264)
Loss: 1.834 | Acc: 45.581% (11698/25664)
Loss: 1.833 | Acc: 45.627% (14630/32064)
Loss: 1.833 | Acc: 45.653% (17560/38464)
Loss: 1.833 | Acc: 45.720% (20512/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1057, Accuracy: 3137/10000 (31.37%)

Epoch: 155
Loss: 1.840 | Acc: 42.188% (27/64)
Loss: 1.842 | Acc: 45.715% (2955/6464)
Loss: 1.845 | Acc: 45.351% (5834/12864)
Loss: 1.835 | Acc: 45.868% (8836/19264)
Loss: 1.834 | Acc: 45.729% (11736/25664)
Loss: 1.832 | Acc: 45.852% (14702/32064)
Loss: 1.833 | Acc: 45.879% (17647/38464)
Loss: 1.833 | Acc: 45.847% (20569/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0226, Accuracy: 3610/10000 (36.10%)

Epoch: 156
Loss: 1.656 | Acc: 51.562% (33/64)
Loss: 1.831 | Acc: 45.622% (2949/6464)
Loss: 1.834 | Acc: 45.763% (5887/12864)
Loss: 1.826 | Acc: 46.102% (8881/19264)
Loss: 1.825 | Acc: 46.068% (11823/25664)
Loss: 1.830 | Acc: 45.874% (14709/32064)
Loss: 1.831 | Acc: 45.825% (17626/38464)
Loss: 1.831 | Acc: 45.774% (20536/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9867, Accuracy: 3772/10000 (37.72%)

Epoch: 157
Loss: 1.977 | Acc: 37.500% (24/64)
Loss: 1.834 | Acc: 45.560% (2945/6464)
Loss: 1.828 | Acc: 46.020% (5920/12864)
Loss: 1.834 | Acc: 45.800% (8823/19264)
Loss: 1.834 | Acc: 45.792% (11752/25664)
Loss: 1.834 | Acc: 45.783% (14680/32064)
Loss: 1.835 | Acc: 45.788% (17612/38464)
Loss: 1.835 | Acc: 45.707% (20506/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9743, Accuracy: 3964/10000 (39.64%)

Epoch: 158
Loss: 1.962 | Acc: 42.188% (27/64)
Loss: 1.825 | Acc: 46.364% (2997/6464)
Loss: 1.827 | Acc: 46.191% (5942/12864)
Loss: 1.830 | Acc: 46.018% (8865/19264)
Loss: 1.830 | Acc: 45.901% (11780/25664)
Loss: 1.830 | Acc: 45.893% (14715/32064)
Loss: 1.829 | Acc: 45.923% (17664/38464)
Loss: 1.830 | Acc: 45.943% (20612/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9938, Accuracy: 3916/10000 (39.16%)

Epoch: 159
Loss: 1.689 | Acc: 48.438% (31/64)
Loss: 1.816 | Acc: 46.566% (3010/6464)
Loss: 1.819 | Acc: 46.276% (5953/12864)
Loss: 1.822 | Acc: 46.169% (8894/19264)
Loss: 1.824 | Acc: 46.139% (11841/25664)
Loss: 1.824 | Acc: 46.211% (14817/32064)
Loss: 1.828 | Acc: 46.092% (17729/38464)
Loss: 1.828 | Acc: 46.162% (20710/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1350, Accuracy: 3522/10000 (35.22%)

Epoch: 160
Loss: 1.946 | Acc: 35.938% (23/64)
Loss: 1.820 | Acc: 46.519% (3007/6464)
Loss: 1.819 | Acc: 46.673% (6004/12864)
Loss: 1.818 | Acc: 46.569% (8971/19264)
Loss: 1.825 | Acc: 46.294% (11881/25664)
Loss: 1.824 | Acc: 46.254% (14831/32064)
Loss: 1.826 | Acc: 46.183% (17764/38464)
Loss: 1.828 | Acc: 46.110% (20687/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0354, Accuracy: 3634/10000 (36.34%)

Epoch: 161
Loss: 2.047 | Acc: 37.500% (24/64)
Loss: 1.829 | Acc: 46.009% (2974/6464)
Loss: 1.819 | Acc: 46.331% (5960/12864)
Loss: 1.828 | Acc: 45.935% (8849/19264)
Loss: 1.831 | Acc: 45.815% (11758/25664)
Loss: 1.830 | Acc: 45.880% (14711/32064)
Loss: 1.829 | Acc: 45.991% (17690/38464)
Loss: 1.828 | Acc: 46.061% (20665/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0166, Accuracy: 3588/10000 (35.88%)

Epoch: 162
Loss: 1.704 | Acc: 53.125% (34/64)
Loss: 1.820 | Acc: 46.024% (2975/6464)
Loss: 1.818 | Acc: 46.253% (5950/12864)
Loss: 1.817 | Acc: 46.408% (8940/19264)
Loss: 1.820 | Acc: 46.314% (11886/25664)
Loss: 1.825 | Acc: 46.055% (14767/32064)
Loss: 1.821 | Acc: 46.251% (17790/38464)
Loss: 1.821 | Acc: 46.222% (20737/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1685, Accuracy: 3102/10000 (31.02%)

Epoch: 163
Loss: 1.926 | Acc: 40.625% (26/64)
Loss: 1.799 | Acc: 47.293% (3057/6464)
Loss: 1.804 | Acc: 47.038% (6051/12864)
Loss: 1.813 | Acc: 46.631% (8983/19264)
Loss: 1.818 | Acc: 46.427% (11915/25664)
Loss: 1.819 | Acc: 46.435% (14889/32064)
Loss: 1.820 | Acc: 46.420% (17855/38464)
Loss: 1.822 | Acc: 46.365% (20801/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9602, Accuracy: 4088/10000 (40.88%)

Epoch: 164
Loss: 1.994 | Acc: 43.750% (28/64)
Loss: 1.820 | Acc: 46.442% (3002/6464)
Loss: 1.811 | Acc: 46.751% (6014/12864)
Loss: 1.813 | Acc: 46.699% (8996/19264)
Loss: 1.818 | Acc: 46.376% (11902/25664)
Loss: 1.818 | Acc: 46.307% (14848/32064)
Loss: 1.820 | Acc: 46.254% (17791/38464)
Loss: 1.822 | Acc: 46.273% (20760/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9755, Accuracy: 3932/10000 (39.32%)

Epoch: 165
Loss: 2.011 | Acc: 40.625% (26/64)
Loss: 1.826 | Acc: 46.504% (3006/6464)
Loss: 1.822 | Acc: 46.525% (5985/12864)
Loss: 1.818 | Acc: 46.626% (8982/19264)
Loss: 1.816 | Acc: 46.622% (11965/25664)
Loss: 1.813 | Acc: 46.803% (15007/32064)
Loss: 1.812 | Acc: 46.870% (18028/38464)
Loss: 1.812 | Acc: 46.835% (21012/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9425, Accuracy: 4013/10000 (40.13%)

Epoch: 166
Loss: 1.950 | Acc: 39.062% (25/64)
Loss: 1.796 | Acc: 47.803% (3090/6464)
Loss: 1.799 | Acc: 47.598% (6123/12864)
Loss: 1.799 | Acc: 47.456% (9142/19264)
Loss: 1.807 | Acc: 46.945% (12048/25664)
Loss: 1.811 | Acc: 46.806% (15008/32064)
Loss: 1.811 | Acc: 46.807% (18004/38464)
Loss: 1.812 | Acc: 46.793% (20993/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9242, Accuracy: 4185/10000 (41.85%)

Epoch: 167
Loss: 1.977 | Acc: 42.188% (27/64)
Loss: 1.802 | Acc: 47.138% (3047/6464)
Loss: 1.801 | Acc: 47.186% (6070/12864)
Loss: 1.806 | Acc: 47.010% (9056/19264)
Loss: 1.801 | Acc: 47.237% (12123/25664)
Loss: 1.803 | Acc: 47.140% (15115/32064)
Loss: 1.805 | Acc: 47.099% (18116/38464)
Loss: 1.807 | Acc: 47.042% (21105/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1200, Accuracy: 3236/10000 (32.36%)

Epoch: 168
Loss: 1.744 | Acc: 48.438% (31/64)
Loss: 1.803 | Acc: 47.153% (3048/6464)
Loss: 1.805 | Acc: 47.062% (6054/12864)
Loss: 1.804 | Acc: 47.026% (9059/19264)
Loss: 1.800 | Acc: 47.198% (12113/25664)
Loss: 1.801 | Acc: 47.231% (15144/32064)
Loss: 1.800 | Acc: 47.203% (18156/38464)
Loss: 1.804 | Acc: 47.004% (21088/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9717, Accuracy: 3850/10000 (38.50%)

Epoch: 169
Loss: 1.988 | Acc: 40.625% (26/64)
Loss: 1.804 | Acc: 46.643% (3015/6464)
Loss: 1.804 | Acc: 46.704% (6008/12864)
Loss: 1.804 | Acc: 46.813% (9018/19264)
Loss: 1.805 | Acc: 46.871% (12029/25664)
Loss: 1.805 | Acc: 46.934% (15049/32064)
Loss: 1.804 | Acc: 47.049% (18097/38464)
Loss: 1.804 | Acc: 47.089% (21126/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0319, Accuracy: 3470/10000 (34.70%)

Epoch: 170
Loss: 1.858 | Acc: 48.438% (31/64)
Loss: 1.788 | Acc: 47.741% (3086/6464)
Loss: 1.792 | Acc: 47.404% (6098/12864)
Loss: 1.796 | Acc: 47.311% (9114/19264)
Loss: 1.798 | Acc: 47.253% (12127/25664)
Loss: 1.798 | Acc: 47.255% (15152/32064)
Loss: 1.797 | Acc: 47.387% (18227/38464)
Loss: 1.799 | Acc: 47.370% (21252/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0072, Accuracy: 3730/10000 (37.30%)

Epoch: 171
Loss: 1.781 | Acc: 50.000% (32/64)
Loss: 1.773 | Acc: 48.530% (3137/6464)
Loss: 1.779 | Acc: 48.266% (6209/12864)
Loss: 1.781 | Acc: 48.017% (9250/19264)
Loss: 1.784 | Acc: 47.861% (12283/25664)
Loss: 1.784 | Acc: 47.817% (15332/32064)
Loss: 1.787 | Acc: 47.730% (18359/38464)
Loss: 1.792 | Acc: 47.568% (21341/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1096, Accuracy: 3278/10000 (32.78%)

Epoch: 172
Loss: 1.810 | Acc: 48.438% (31/64)
Loss: 1.784 | Acc: 47.942% (3099/6464)
Loss: 1.775 | Acc: 48.577% (6249/12864)
Loss: 1.774 | Acc: 48.588% (9360/19264)
Loss: 1.776 | Acc: 48.367% (12413/25664)
Loss: 1.781 | Acc: 48.269% (15477/32064)
Loss: 1.783 | Acc: 48.162% (18525/38464)
Loss: 1.783 | Acc: 48.137% (21596/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0301, Accuracy: 3649/10000 (36.49%)

Epoch: 173
Loss: 1.887 | Acc: 46.875% (30/64)
Loss: 1.808 | Acc: 46.952% (3035/6464)
Loss: 1.789 | Acc: 47.816% (6151/12864)
Loss: 1.784 | Acc: 48.121% (9270/19264)
Loss: 1.781 | Acc: 48.274% (12389/25664)
Loss: 1.778 | Acc: 48.388% (15515/32064)
Loss: 1.780 | Acc: 48.263% (18564/38464)
Loss: 1.778 | Acc: 48.297% (21668/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8887, Accuracy: 4298/10000 (42.98%)

Epoch: 174
Loss: 1.735 | Acc: 53.125% (34/64)
Loss: 1.756 | Acc: 49.165% (3178/6464)
Loss: 1.766 | Acc: 48.795% (6277/12864)
Loss: 1.757 | Acc: 49.263% (9490/19264)
Loss: 1.763 | Acc: 48.921% (12555/25664)
Loss: 1.768 | Acc: 48.650% (15599/32064)
Loss: 1.770 | Acc: 48.580% (18686/38464)
Loss: 1.771 | Acc: 48.516% (21766/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9430, Accuracy: 4174/10000 (41.74%)

Epoch: 175
Loss: 1.677 | Acc: 48.438% (31/64)
Loss: 1.755 | Acc: 48.948% (3164/6464)
Loss: 1.759 | Acc: 48.787% (6276/12864)
Loss: 1.756 | Acc: 48.983% (9436/19264)
Loss: 1.757 | Acc: 48.960% (12565/25664)
Loss: 1.753 | Acc: 49.230% (15785/32064)
Loss: 1.756 | Acc: 49.085% (18880/38464)
Loss: 1.760 | Acc: 48.957% (21964/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9309, Accuracy: 4142/10000 (41.42%)

Epoch: 176
Loss: 1.828 | Acc: 45.312% (29/64)
Loss: 1.762 | Acc: 49.196% (3180/6464)
Loss: 1.763 | Acc: 48.881% (6288/12864)
Loss: 1.762 | Acc: 48.941% (9428/19264)
Loss: 1.766 | Acc: 48.749% (12511/25664)
Loss: 1.765 | Acc: 48.721% (15622/32064)
Loss: 1.760 | Acc: 48.957% (18831/38464)
Loss: 1.756 | Acc: 49.095% (22026/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9127, Accuracy: 4267/10000 (42.67%)

Epoch: 177
Loss: 1.738 | Acc: 48.438% (31/64)
Loss: 1.771 | Acc: 48.484% (3134/6464)
Loss: 1.748 | Acc: 49.409% (6356/12864)
Loss: 1.751 | Acc: 49.278% (9493/19264)
Loss: 1.753 | Acc: 49.190% (12624/25664)
Loss: 1.754 | Acc: 49.170% (15766/32064)
Loss: 1.752 | Acc: 49.160% (18909/38464)
Loss: 1.751 | Acc: 49.307% (22121/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8500, Accuracy: 4628/10000 (46.28%)

Epoch: 178
Loss: 1.739 | Acc: 46.875% (30/64)
Loss: 1.709 | Acc: 50.851% (3287/6464)
Loss: 1.740 | Acc: 49.681% (6391/12864)
Loss: 1.732 | Acc: 50.083% (9648/19264)
Loss: 1.738 | Acc: 49.852% (12794/25664)
Loss: 1.736 | Acc: 50.053% (16049/32064)
Loss: 1.735 | Acc: 50.133% (19283/38464)
Loss: 1.738 | Acc: 50.000% (22432/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0567, Accuracy: 3502/10000 (35.02%)

Epoch: 179
Loss: 1.685 | Acc: 54.688% (35/64)
Loss: 1.729 | Acc: 49.722% (3214/6464)
Loss: 1.717 | Acc: 50.319% (6473/12864)
Loss: 1.718 | Acc: 50.348% (9699/19264)
Loss: 1.721 | Acc: 50.288% (12906/25664)
Loss: 1.719 | Acc: 50.474% (16184/32064)
Loss: 1.720 | Acc: 50.398% (19385/38464)
Loss: 1.725 | Acc: 50.216% (22529/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8899, Accuracy: 4381/10000 (43.81%)

Epoch: 180
Loss: 1.772 | Acc: 50.000% (32/64)
Loss: 1.698 | Acc: 50.944% (3293/6464)
Loss: 1.707 | Acc: 50.956% (6555/12864)
Loss: 1.706 | Acc: 50.924% (9810/19264)
Loss: 1.706 | Acc: 50.982% (13084/25664)
Loss: 1.715 | Acc: 50.667% (16246/32064)
Loss: 1.717 | Acc: 50.538% (19439/38464)
Loss: 1.718 | Acc: 50.546% (22677/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9226, Accuracy: 4301/10000 (43.01%)

Epoch: 181
Loss: 1.619 | Acc: 53.125% (34/64)
Loss: 1.685 | Acc: 51.562% (3333/6464)
Loss: 1.692 | Acc: 51.298% (6599/12864)
Loss: 1.687 | Acc: 51.583% (9937/19264)
Loss: 1.693 | Acc: 51.418% (13196/25664)
Loss: 1.696 | Acc: 51.357% (16467/32064)
Loss: 1.703 | Acc: 51.058% (19639/38464)
Loss: 1.706 | Acc: 50.905% (22838/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9210, Accuracy: 4254/10000 (42.54%)

Epoch: 182
Loss: 1.895 | Acc: 40.625% (26/64)
Loss: 1.699 | Acc: 51.021% (3298/6464)
Loss: 1.681 | Acc: 51.780% (6661/12864)
Loss: 1.678 | Acc: 52.030% (10023/19264)
Loss: 1.680 | Acc: 51.843% (13305/25664)
Loss: 1.687 | Acc: 51.609% (16548/32064)
Loss: 1.688 | Acc: 51.604% (19849/38464)
Loss: 1.691 | Acc: 51.507% (23108/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8775, Accuracy: 4514/10000 (45.14%)

Epoch: 183
Loss: 1.620 | Acc: 60.938% (39/64)
Loss: 1.666 | Acc: 52.599% (3400/6464)
Loss: 1.675 | Acc: 52.083% (6700/12864)
Loss: 1.675 | Acc: 52.128% (10042/19264)
Loss: 1.680 | Acc: 51.894% (13318/25664)
Loss: 1.683 | Acc: 51.712% (16581/32064)
Loss: 1.682 | Acc: 51.692% (19883/38464)
Loss: 1.683 | Acc: 51.681% (23186/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9293, Accuracy: 4377/10000 (43.77%)

Epoch: 184
Loss: 1.453 | Acc: 59.375% (38/64)
Loss: 1.649 | Acc: 52.584% (3399/6464)
Loss: 1.652 | Acc: 52.472% (6750/12864)
Loss: 1.655 | Acc: 52.492% (10112/19264)
Loss: 1.653 | Acc: 52.544% (13485/25664)
Loss: 1.653 | Acc: 52.570% (16856/32064)
Loss: 1.657 | Acc: 52.441% (20171/38464)
Loss: 1.662 | Acc: 52.311% (23469/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9543, Accuracy: 4230/10000 (42.30%)

Epoch: 185
Loss: 1.703 | Acc: 48.438% (31/64)
Loss: 1.622 | Acc: 53.373% (3450/6464)
Loss: 1.634 | Acc: 53.008% (6819/12864)
Loss: 1.635 | Acc: 53.073% (10224/19264)
Loss: 1.641 | Acc: 52.907% (13578/25664)
Loss: 1.644 | Acc: 52.829% (16939/32064)
Loss: 1.640 | Acc: 52.930% (20359/38464)
Loss: 1.644 | Acc: 52.833% (23703/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9051, Accuracy: 4404/10000 (44.04%)

Epoch: 186
Loss: 1.539 | Acc: 57.812% (37/64)
Loss: 1.604 | Acc: 54.316% (3511/6464)
Loss: 1.605 | Acc: 54.050% (6953/12864)
Loss: 1.615 | Acc: 53.639% (10333/19264)
Loss: 1.620 | Acc: 53.546% (13742/25664)
Loss: 1.619 | Acc: 53.630% (17196/32064)
Loss: 1.623 | Acc: 53.440% (20555/38464)
Loss: 1.623 | Acc: 53.484% (23995/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9111, Accuracy: 4452/10000 (44.52%)

Epoch: 187
Loss: 1.465 | Acc: 59.375% (38/64)
Loss: 1.603 | Acc: 53.697% (3471/6464)
Loss: 1.593 | Acc: 53.887% (6932/12864)
Loss: 1.590 | Acc: 54.231% (10447/19264)
Loss: 1.598 | Acc: 53.982% (13854/25664)
Loss: 1.599 | Acc: 53.936% (17294/32064)
Loss: 1.599 | Acc: 53.970% (20759/38464)
Loss: 1.598 | Acc: 54.059% (24253/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9460, Accuracy: 4316/10000 (43.16%)

Epoch: 188
Loss: 1.420 | Acc: 60.938% (39/64)
Loss: 1.560 | Acc: 55.430% (3583/6464)
Loss: 1.566 | Acc: 55.123% (7091/12864)
Loss: 1.566 | Acc: 55.175% (10629/19264)
Loss: 1.565 | Acc: 55.143% (14152/25664)
Loss: 1.568 | Acc: 55.074% (17659/32064)
Loss: 1.565 | Acc: 55.181% (21225/38464)
Loss: 1.569 | Acc: 55.002% (24676/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9390, Accuracy: 4468/10000 (44.68%)

Epoch: 189
Loss: 1.591 | Acc: 48.438% (31/64)
Loss: 1.507 | Acc: 56.652% (3662/6464)
Loss: 1.523 | Acc: 56.289% (7241/12864)
Loss: 1.522 | Acc: 56.281% (10842/19264)
Loss: 1.527 | Acc: 56.102% (14398/25664)
Loss: 1.532 | Acc: 55.947% (17939/32064)
Loss: 1.535 | Acc: 55.847% (21481/38464)
Loss: 1.538 | Acc: 55.666% (24974/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9495, Accuracy: 4528/10000 (45.28%)

Epoch: 190
Loss: 1.543 | Acc: 54.688% (35/64)
Loss: 1.479 | Acc: 57.178% (3696/6464)
Loss: 1.488 | Acc: 56.794% (7306/12864)
Loss: 1.489 | Acc: 56.790% (10940/19264)
Loss: 1.489 | Acc: 56.932% (14611/25664)
Loss: 1.490 | Acc: 56.983% (18271/32064)
Loss: 1.492 | Acc: 56.892% (21883/38464)
Loss: 1.491 | Acc: 56.934% (25543/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9878, Accuracy: 4429/10000 (44.29%)

Epoch: 191
Loss: 1.635 | Acc: 51.562% (33/64)
Loss: 1.428 | Acc: 58.338% (3771/6464)
Loss: 1.423 | Acc: 58.644% (7544/12864)
Loss: 1.436 | Acc: 58.363% (11243/19264)
Loss: 1.442 | Acc: 58.179% (14931/25664)
Loss: 1.442 | Acc: 58.168% (18651/32064)
Loss: 1.446 | Acc: 58.124% (22357/38464)
Loss: 1.449 | Acc: 57.975% (26010/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0231, Accuracy: 4336/10000 (43.36%)

Epoch: 192
Loss: 1.488 | Acc: 51.562% (33/64)
Loss: 1.410 | Acc: 58.493% (3781/6464)
Loss: 1.401 | Acc: 59.041% (7595/12864)
Loss: 1.388 | Acc: 59.541% (11470/19264)
Loss: 1.395 | Acc: 59.453% (15258/25664)
Loss: 1.401 | Acc: 59.235% (18993/32064)
Loss: 1.400 | Acc: 59.245% (22788/38464)
Loss: 1.398 | Acc: 59.382% (26641/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1070, Accuracy: 4287/10000 (42.87%)

Epoch: 193
Loss: 1.240 | Acc: 62.500% (40/64)
Loss: 1.316 | Acc: 61.247% (3959/6464)
Loss: 1.326 | Acc: 61.233% (7877/12864)
Loss: 1.326 | Acc: 61.270% (11803/19264)
Loss: 1.336 | Acc: 60.840% (15614/25664)
Loss: 1.334 | Acc: 60.938% (19539/32064)
Loss: 1.336 | Acc: 60.854% (23407/38464)
Loss: 1.338 | Acc: 60.779% (27268/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1222, Accuracy: 4225/10000 (42.25%)

Epoch: 194
Loss: 1.026 | Acc: 71.875% (46/64)
Loss: 1.277 | Acc: 62.407% (4034/6464)
Loss: 1.262 | Acc: 62.982% (8102/12864)
Loss: 1.260 | Acc: 63.024% (12141/19264)
Loss: 1.266 | Acc: 62.784% (16113/25664)
Loss: 1.271 | Acc: 62.569% (20062/32064)
Loss: 1.273 | Acc: 62.531% (24052/38464)
Loss: 1.272 | Acc: 62.498% (28039/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1622, Accuracy: 4256/10000 (42.56%)

Epoch: 195
Loss: 1.132 | Acc: 68.750% (44/64)
Loss: 1.202 | Acc: 64.202% (4150/6464)
Loss: 1.218 | Acc: 64.008% (8234/12864)
Loss: 1.223 | Acc: 64.016% (12332/19264)
Loss: 1.223 | Acc: 63.926% (16406/25664)
Loss: 1.228 | Acc: 63.785% (20452/32064)
Loss: 1.234 | Acc: 63.545% (24442/38464)
Loss: 1.237 | Acc: 63.403% (28445/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1505, Accuracy: 4214/10000 (42.14%)

Epoch: 196
Loss: 1.219 | Acc: 64.062% (41/64)
Loss: 1.203 | Acc: 64.109% (4144/6464)
Loss: 1.195 | Acc: 64.490% (8296/12864)
Loss: 1.213 | Acc: 63.922% (12314/19264)
Loss: 1.211 | Acc: 64.168% (16468/25664)
Loss: 1.211 | Acc: 64.209% (20588/32064)
Loss: 1.216 | Acc: 64.031% (24629/38464)
Loss: 1.218 | Acc: 63.913% (28674/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1733, Accuracy: 4208/10000 (42.08%)

Epoch: 197
Loss: 1.216 | Acc: 62.500% (40/64)
Loss: 1.182 | Acc: 65.099% (4208/6464)
Loss: 1.184 | Acc: 64.972% (8358/12864)
Loss: 1.182 | Acc: 65.090% (12539/19264)
Loss: 1.186 | Acc: 65.005% (16683/25664)
Loss: 1.188 | Acc: 64.827% (20786/32064)
Loss: 1.189 | Acc: 64.811% (24929/38464)
Loss: 1.192 | Acc: 64.684% (29020/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2001, Accuracy: 4157/10000 (41.57%)
torch.Size([100, 10])
Test set: Average loss: 2.2001, Accuracy: 4157/10000 (41.57%)

Epoch: 198
Loss: 1.083 | Acc: 67.188% (43/64)
Loss: 1.149 | Acc: 66.182% (4278/6464)
Loss: 1.156 | Acc: 66.154% (8510/12864)
Loss: 1.162 | Acc: 65.921% (12699/19264)
Loss: 1.166 | Acc: 65.613% (16839/25664)
Loss: 1.172 | Acc: 65.388% (20966/32064)
Loss: 1.172 | Acc: 65.394% (25153/38464)
Loss: 1.173 | Acc: 65.375% (29330/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1875, Accuracy: 4158/10000 (41.58%)
torch.Size([100, 10])
Test set: Average loss: 2.1875, Accuracy: 4158/10000 (41.58%)

Epoch: 199
Loss: 1.204 | Acc: 65.625% (42/64)
Loss: 1.175 | Acc: 64.929% (4197/6464)
Loss: 1.160 | Acc: 65.547% (8432/12864)
Loss: 1.159 | Acc: 65.651% (12647/19264)
Loss: 1.157 | Acc: 65.742% (16872/25664)
Loss: 1.159 | Acc: 65.606% (21036/32064)
Loss: 1.157 | Acc: 65.695% (25269/38464)
Loss: 1.160 | Acc: 65.612% (29436/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1990, Accuracy: 4142/10000 (41.42%)
torch.Size([100, 10])
Test set: Average loss: 2.1990, Accuracy: 4142/10000 (41.42%)
4654
10000
-1.9244966506958008
