==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.355 | Acc: 15.625% (10/64)
Loss: 2.942 | Acc: 15.610% (1009/6464)
Loss: 2.508 | Acc: 18.812% (2420/12864)
Loss: 2.334 | Acc: 20.608% (3970/19264)
Loss: 2.232 | Acc: 22.483% (5770/25664)
Loss: 2.161 | Acc: 24.061% (7715/32064)
Loss: 2.107 | Acc: 25.413% (9775/38464)
Loss: 2.059 | Acc: 26.895% (12066/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1607, Accuracy: 2834/10000 (28.34%)

Epoch: 1
Loss: 2.102 | Acc: 29.688% (19/64)
Loss: 1.701 | Acc: 38.304% (2476/6464)
Loss: 1.676 | Acc: 39.754% (5114/12864)
Loss: 1.655 | Acc: 40.454% (7793/19264)
Loss: 1.640 | Acc: 41.155% (10562/25664)
Loss: 1.620 | Acc: 41.988% (13463/32064)
Loss: 1.602 | Acc: 42.671% (16413/38464)
Loss: 1.586 | Acc: 43.474% (19504/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5359, Accuracy: 4692/10000 (46.92%)

Epoch: 2
Loss: 1.252 | Acc: 54.688% (35/64)
Loss: 1.416 | Acc: 50.278% (3250/6464)
Loss: 1.413 | Acc: 50.676% (6519/12864)
Loss: 1.397 | Acc: 51.453% (9912/19264)
Loss: 1.378 | Acc: 52.182% (13392/25664)
Loss: 1.364 | Acc: 52.894% (16960/32064)
Loss: 1.354 | Acc: 53.497% (20577/38464)
Loss: 1.343 | Acc: 53.905% (24184/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5091, Accuracy: 5039/10000 (50.39%)

Epoch: 3
Loss: 1.025 | Acc: 67.188% (43/64)
Loss: 1.234 | Acc: 58.617% (3789/6464)
Loss: 1.227 | Acc: 58.963% (7585/12864)
Loss: 1.206 | Acc: 59.723% (11505/19264)
Loss: 1.191 | Acc: 60.291% (15473/25664)
Loss: 1.182 | Acc: 60.682% (19457/32064)
Loss: 1.171 | Acc: 61.143% (23518/38464)
Loss: 1.163 | Acc: 61.577% (27626/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7478, Accuracy: 4730/10000 (47.30%)

Epoch: 4
Loss: 1.339 | Acc: 59.375% (38/64)
Loss: 1.074 | Acc: 65.842% (4256/6464)
Loss: 1.065 | Acc: 65.734% (8456/12864)
Loss: 1.058 | Acc: 66.149% (12743/19264)
Loss: 1.051 | Acc: 66.428% (17048/25664)
Loss: 1.042 | Acc: 66.795% (21417/32064)
Loss: 1.031 | Acc: 67.239% (25863/38464)
Loss: 1.025 | Acc: 67.535% (30299/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2586, Accuracy: 6051/10000 (60.51%)

Epoch: 5
Loss: 1.344 | Acc: 65.625% (42/64)
Loss: 0.936 | Acc: 70.900% (4583/6464)
Loss: 0.946 | Acc: 70.670% (9091/12864)
Loss: 0.941 | Acc: 70.977% (13673/19264)
Loss: 0.940 | Acc: 71.014% (18225/25664)
Loss: 0.933 | Acc: 71.186% (22825/32064)
Loss: 0.930 | Acc: 71.316% (27431/38464)
Loss: 0.928 | Acc: 71.398% (32032/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2410, Accuracy: 6130/10000 (61.30%)

Epoch: 6
Loss: 0.894 | Acc: 73.438% (47/64)
Loss: 0.877 | Acc: 73.623% (4759/6464)
Loss: 0.877 | Acc: 73.492% (9454/12864)
Loss: 0.873 | Acc: 73.630% (14184/19264)
Loss: 0.873 | Acc: 73.558% (18878/25664)
Loss: 0.868 | Acc: 73.671% (23622/32064)
Loss: 0.867 | Acc: 73.705% (28350/38464)
Loss: 0.866 | Acc: 73.761% (33092/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6310, Accuracy: 4991/10000 (49.91%)

Epoch: 7
Loss: 1.098 | Acc: 65.625% (42/64)
Loss: 0.836 | Acc: 75.046% (4851/6464)
Loss: 0.838 | Acc: 74.969% (9644/12864)
Loss: 0.839 | Acc: 75.021% (14452/19264)
Loss: 0.837 | Acc: 75.199% (19299/25664)
Loss: 0.832 | Acc: 75.340% (24157/32064)
Loss: 0.831 | Acc: 75.333% (28976/38464)
Loss: 0.826 | Acc: 75.430% (33841/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0804, Accuracy: 6793/10000 (67.93%)

Epoch: 8
Loss: 1.123 | Acc: 67.188% (43/64)
Loss: 0.813 | Acc: 75.727% (4895/6464)
Loss: 0.799 | Acc: 76.119% (9792/12864)
Loss: 0.789 | Acc: 76.630% (14762/19264)
Loss: 0.791 | Acc: 76.617% (19663/25664)
Loss: 0.789 | Acc: 76.697% (24592/32064)
Loss: 0.793 | Acc: 76.485% (29419/38464)
Loss: 0.789 | Acc: 76.616% (34373/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9320, Accuracy: 4643/10000 (46.43%)

Epoch: 9
Loss: 1.066 | Acc: 70.312% (45/64)
Loss: 0.770 | Acc: 77.692% (5022/6464)
Loss: 0.778 | Acc: 77.285% (9942/12864)
Loss: 0.781 | Acc: 77.024% (14838/19264)
Loss: 0.775 | Acc: 77.182% (19808/25664)
Loss: 0.776 | Acc: 77.292% (24783/32064)
Loss: 0.773 | Acc: 77.381% (29764/38464)
Loss: 0.767 | Acc: 77.597% (34813/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1809, Accuracy: 6391/10000 (63.91%)

Epoch: 10
Loss: 0.863 | Acc: 78.125% (50/64)
Loss: 0.751 | Acc: 78.171% (5053/6464)
Loss: 0.735 | Acc: 78.599% (10111/12864)
Loss: 0.745 | Acc: 78.161% (15057/19264)
Loss: 0.741 | Acc: 78.191% (20067/25664)
Loss: 0.743 | Acc: 78.206% (25076/32064)
Loss: 0.744 | Acc: 78.117% (30047/38464)
Loss: 0.745 | Acc: 78.134% (35054/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8094, Accuracy: 7646/10000 (76.46%)

Epoch: 11
Loss: 0.942 | Acc: 75.000% (48/64)
Loss: 0.720 | Acc: 79.007% (5107/6464)
Loss: 0.732 | Acc: 78.801% (10137/12864)
Loss: 0.725 | Acc: 79.106% (15239/19264)
Loss: 0.728 | Acc: 79.060% (20290/25664)
Loss: 0.727 | Acc: 79.023% (25338/32064)
Loss: 0.726 | Acc: 79.022% (30395/38464)
Loss: 0.728 | Acc: 79.039% (35460/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0751, Accuracy: 6806/10000 (68.06%)

Epoch: 12
Loss: 0.827 | Acc: 76.562% (49/64)
Loss: 0.699 | Acc: 79.718% (5153/6464)
Loss: 0.702 | Acc: 79.944% (10284/12864)
Loss: 0.700 | Acc: 79.973% (15406/19264)
Loss: 0.701 | Acc: 79.921% (20511/25664)
Loss: 0.703 | Acc: 79.818% (25593/32064)
Loss: 0.703 | Acc: 79.851% (30714/38464)
Loss: 0.707 | Acc: 79.757% (35782/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0757, Accuracy: 3886/10000 (38.86%)

Epoch: 13
Loss: 0.936 | Acc: 67.188% (43/64)
Loss: 0.696 | Acc: 80.476% (5202/6464)
Loss: 0.692 | Acc: 80.480% (10353/12864)
Loss: 0.690 | Acc: 80.487% (15505/19264)
Loss: 0.693 | Acc: 80.299% (20608/25664)
Loss: 0.689 | Acc: 80.414% (25784/32064)
Loss: 0.691 | Acc: 80.361% (30910/38464)
Loss: 0.690 | Acc: 80.401% (36071/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1892, Accuracy: 6361/10000 (63.61%)

Epoch: 14
Loss: 0.986 | Acc: 67.188% (43/64)
Loss: 0.704 | Acc: 80.028% (5173/6464)
Loss: 0.698 | Acc: 79.975% (10288/12864)
Loss: 0.685 | Acc: 80.388% (15486/19264)
Loss: 0.679 | Acc: 80.650% (20698/25664)
Loss: 0.675 | Acc: 80.795% (25906/32064)
Loss: 0.672 | Acc: 80.847% (31097/38464)
Loss: 0.675 | Acc: 80.815% (36257/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3530, Accuracy: 5741/10000 (57.41%)

Epoch: 15
Loss: 0.838 | Acc: 75.000% (48/64)
Loss: 0.665 | Acc: 81.312% (5256/6464)
Loss: 0.657 | Acc: 81.685% (10508/12864)
Loss: 0.667 | Acc: 81.520% (15704/19264)
Loss: 0.662 | Acc: 81.585% (20938/25664)
Loss: 0.662 | Acc: 81.637% (26176/32064)
Loss: 0.663 | Acc: 81.507% (31351/38464)
Loss: 0.662 | Acc: 81.509% (36568/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0091, Accuracy: 7053/10000 (70.53%)

Epoch: 16
Loss: 0.807 | Acc: 79.688% (51/64)
Loss: 0.632 | Acc: 81.993% (5300/6464)
Loss: 0.629 | Acc: 81.911% (10537/12864)
Loss: 0.636 | Acc: 81.857% (15769/19264)
Loss: 0.641 | Acc: 81.854% (21007/25664)
Loss: 0.639 | Acc: 82.011% (26296/32064)
Loss: 0.642 | Acc: 82.007% (31543/38464)
Loss: 0.643 | Acc: 81.983% (36781/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2560, Accuracy: 6489/10000 (64.89%)

Epoch: 17
Loss: 0.629 | Acc: 75.000% (48/64)
Loss: 0.611 | Acc: 82.983% (5364/6464)
Loss: 0.633 | Acc: 82.299% (10587/12864)
Loss: 0.637 | Acc: 82.174% (15830/19264)
Loss: 0.634 | Acc: 82.314% (21125/25664)
Loss: 0.633 | Acc: 82.441% (26434/32064)
Loss: 0.633 | Acc: 82.417% (31701/38464)
Loss: 0.633 | Acc: 82.416% (36975/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8098, Accuracy: 7741/10000 (77.41%)

Epoch: 18
Loss: 0.584 | Acc: 79.688% (51/64)
Loss: 0.588 | Acc: 83.895% (5423/6464)
Loss: 0.597 | Acc: 83.504% (10742/12864)
Loss: 0.607 | Acc: 83.150% (16018/19264)
Loss: 0.611 | Acc: 83.077% (21321/25664)
Loss: 0.615 | Acc: 82.965% (26602/32064)
Loss: 0.617 | Acc: 82.903% (31888/38464)
Loss: 0.617 | Acc: 82.855% (37172/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9457, Accuracy: 7329/10000 (73.29%)

Epoch: 19
Loss: 0.778 | Acc: 76.562% (49/64)
Loss: 0.598 | Acc: 83.617% (5405/6464)
Loss: 0.591 | Acc: 83.831% (10784/12864)
Loss: 0.584 | Acc: 83.991% (16180/19264)
Loss: 0.589 | Acc: 83.884% (21528/25664)
Loss: 0.597 | Acc: 83.714% (26842/32064)
Loss: 0.602 | Acc: 83.566% (32143/38464)
Loss: 0.603 | Acc: 83.584% (37499/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0830, Accuracy: 6759/10000 (67.59%)

Epoch: 20
Loss: 0.572 | Acc: 82.812% (53/64)
Loss: 0.570 | Acc: 84.298% (5449/6464)
Loss: 0.579 | Acc: 84.204% (10832/12864)
Loss: 0.580 | Acc: 84.152% (16211/19264)
Loss: 0.579 | Acc: 84.180% (21604/25664)
Loss: 0.578 | Acc: 84.197% (26997/32064)
Loss: 0.581 | Acc: 84.172% (32376/38464)
Loss: 0.583 | Acc: 84.152% (37754/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6746, Accuracy: 5208/10000 (52.08%)

Epoch: 21
Loss: 0.524 | Acc: 87.500% (56/64)
Loss: 0.598 | Acc: 83.261% (5382/6464)
Loss: 0.584 | Acc: 83.761% (10775/12864)
Loss: 0.576 | Acc: 84.188% (16218/19264)
Loss: 0.578 | Acc: 84.204% (21610/25664)
Loss: 0.578 | Acc: 84.256% (27016/32064)
Loss: 0.577 | Acc: 84.378% (32455/38464)
Loss: 0.575 | Acc: 84.424% (37876/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9502, Accuracy: 7328/10000 (73.28%)

Epoch: 22
Loss: 0.554 | Acc: 84.375% (54/64)
Loss: 0.537 | Acc: 85.783% (5545/6464)
Loss: 0.559 | Acc: 85.261% (10968/12864)
Loss: 0.557 | Acc: 85.112% (16396/19264)
Loss: 0.561 | Acc: 85.002% (21815/25664)
Loss: 0.558 | Acc: 85.145% (27301/32064)
Loss: 0.559 | Acc: 85.145% (32750/38464)
Loss: 0.557 | Acc: 85.144% (38199/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8360, Accuracy: 7625/10000 (76.25%)

Epoch: 23
Loss: 0.609 | Acc: 84.375% (54/64)
Loss: 0.515 | Acc: 86.386% (5584/6464)
Loss: 0.531 | Acc: 85.945% (11056/12864)
Loss: 0.537 | Acc: 85.896% (16547/19264)
Loss: 0.542 | Acc: 85.587% (21965/25664)
Loss: 0.548 | Acc: 85.398% (27382/32064)
Loss: 0.545 | Acc: 85.480% (32879/38464)
Loss: 0.546 | Acc: 85.461% (38341/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2791, Accuracy: 6309/10000 (63.09%)

Epoch: 24
Loss: 0.973 | Acc: 71.875% (46/64)
Loss: 0.536 | Acc: 85.659% (5537/6464)
Loss: 0.544 | Acc: 85.339% (10978/12864)
Loss: 0.543 | Acc: 85.605% (16491/19264)
Loss: 0.546 | Acc: 85.579% (21963/25664)
Loss: 0.543 | Acc: 85.651% (27463/32064)
Loss: 0.542 | Acc: 85.737% (32978/38464)
Loss: 0.544 | Acc: 85.646% (38424/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1292, Accuracy: 6987/10000 (69.87%)

Epoch: 25
Loss: 0.729 | Acc: 81.250% (52/64)
Loss: 0.512 | Acc: 86.618% (5599/6464)
Loss: 0.525 | Acc: 86.311% (11103/12864)
Loss: 0.522 | Acc: 86.436% (16651/19264)
Loss: 0.523 | Acc: 86.323% (22154/25664)
Loss: 0.519 | Acc: 86.433% (27714/32064)
Loss: 0.522 | Acc: 86.320% (33202/38464)
Loss: 0.524 | Acc: 86.236% (38689/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7255, Accuracy: 8019/10000 (80.19%)

Epoch: 26
Loss: 0.329 | Acc: 92.188% (59/64)
Loss: 0.508 | Acc: 86.603% (5598/6464)
Loss: 0.511 | Acc: 86.676% (11150/12864)
Loss: 0.503 | Acc: 87.017% (16763/19264)
Loss: 0.507 | Acc: 87.029% (22335/25664)
Loss: 0.507 | Acc: 86.920% (27870/32064)
Loss: 0.506 | Acc: 86.988% (33459/38464)
Loss: 0.504 | Acc: 86.990% (39027/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2138, Accuracy: 6613/10000 (66.13%)

Epoch: 27
Loss: 0.566 | Acc: 82.812% (53/64)
Loss: 0.507 | Acc: 86.866% (5615/6464)
Loss: 0.489 | Acc: 87.446% (11249/12864)
Loss: 0.491 | Acc: 87.318% (16821/19264)
Loss: 0.492 | Acc: 87.266% (22396/25664)
Loss: 0.491 | Acc: 87.300% (27992/32064)
Loss: 0.493 | Acc: 87.237% (33555/38464)
Loss: 0.495 | Acc: 87.224% (39132/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0414, Accuracy: 6935/10000 (69.35%)

Epoch: 28
Loss: 0.646 | Acc: 79.688% (51/64)
Loss: 0.459 | Acc: 88.397% (5714/6464)
Loss: 0.475 | Acc: 87.982% (11318/12864)
Loss: 0.473 | Acc: 88.035% (16959/19264)
Loss: 0.477 | Acc: 87.925% (22565/25664)
Loss: 0.480 | Acc: 87.827% (28161/32064)
Loss: 0.482 | Acc: 87.789% (33767/38464)
Loss: 0.481 | Acc: 87.861% (39418/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8519, Accuracy: 7656/10000 (76.56%)

Epoch: 29
Loss: 0.330 | Acc: 92.188% (59/64)
Loss: 0.457 | Acc: 88.150% (5698/6464)
Loss: 0.461 | Acc: 88.223% (11349/12864)
Loss: 0.453 | Acc: 88.497% (17048/19264)
Loss: 0.458 | Acc: 88.377% (22681/25664)
Loss: 0.459 | Acc: 88.358% (28331/32064)
Loss: 0.461 | Acc: 88.285% (33958/38464)
Loss: 0.462 | Acc: 88.262% (39598/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7306, Accuracy: 7980/10000 (79.80%)

Epoch: 30
Loss: 0.440 | Acc: 87.500% (56/64)
Loss: 0.438 | Acc: 89.062% (5757/6464)
Loss: 0.439 | Acc: 89.039% (11454/12864)
Loss: 0.440 | Acc: 88.933% (17132/19264)
Loss: 0.443 | Acc: 88.708% (22766/25664)
Loss: 0.451 | Acc: 88.623% (28416/32064)
Loss: 0.452 | Acc: 88.595% (34077/38464)
Loss: 0.452 | Acc: 88.594% (39747/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8878, Accuracy: 7654/10000 (76.54%)

Epoch: 31
Loss: 0.378 | Acc: 84.375% (54/64)
Loss: 0.423 | Acc: 89.264% (5770/6464)
Loss: 0.427 | Acc: 89.171% (11471/12864)
Loss: 0.430 | Acc: 89.239% (17191/19264)
Loss: 0.430 | Acc: 89.179% (22887/25664)
Loss: 0.433 | Acc: 89.150% (28585/32064)
Loss: 0.430 | Acc: 89.231% (34322/38464)
Loss: 0.433 | Acc: 89.047% (39950/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5661, Accuracy: 8586/10000 (85.86%)

Epoch: 32
Loss: 0.577 | Acc: 89.062% (57/64)
Loss: 0.406 | Acc: 90.254% (5834/6464)
Loss: 0.415 | Acc: 89.863% (11560/12864)
Loss: 0.413 | Acc: 89.961% (17330/19264)
Loss: 0.409 | Acc: 90.072% (23116/25664)
Loss: 0.408 | Acc: 90.079% (28883/32064)
Loss: 0.412 | Acc: 89.978% (34609/38464)
Loss: 0.412 | Acc: 90.010% (40382/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8074, Accuracy: 7846/10000 (78.46%)

Epoch: 33
Loss: 0.381 | Acc: 92.188% (59/64)
Loss: 0.372 | Acc: 90.965% (5880/6464)
Loss: 0.405 | Acc: 90.143% (11596/12864)
Loss: 0.408 | Acc: 90.070% (17351/19264)
Loss: 0.408 | Acc: 90.115% (23127/25664)
Loss: 0.399 | Acc: 90.391% (28983/32064)
Loss: 0.401 | Acc: 90.261% (34718/38464)
Loss: 0.398 | Acc: 90.304% (40514/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7373, Accuracy: 8017/10000 (80.17%)

Epoch: 34
Loss: 0.548 | Acc: 85.938% (55/64)
Loss: 0.382 | Acc: 90.733% (5865/6464)
Loss: 0.374 | Acc: 91.014% (11708/12864)
Loss: 0.374 | Acc: 90.952% (17521/19264)
Loss: 0.373 | Acc: 91.019% (23359/25664)
Loss: 0.376 | Acc: 90.912% (29150/32064)
Loss: 0.378 | Acc: 90.888% (34959/38464)
Loss: 0.380 | Acc: 90.821% (40746/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5369, Accuracy: 8686/10000 (86.86%)

Epoch: 35
Loss: 0.268 | Acc: 93.750% (60/64)
Loss: 0.338 | Acc: 91.445% (5911/6464)
Loss: 0.353 | Acc: 91.379% (11755/12864)
Loss: 0.354 | Acc: 91.435% (17614/19264)
Loss: 0.353 | Acc: 91.564% (23499/25664)
Loss: 0.352 | Acc: 91.604% (29372/32064)
Loss: 0.357 | Acc: 91.467% (35182/38464)
Loss: 0.360 | Acc: 91.387% (41000/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5649, Accuracy: 8660/10000 (86.60%)

Epoch: 36
Loss: 0.296 | Acc: 93.750% (60/64)
Loss: 0.330 | Acc: 92.141% (5956/6464)
Loss: 0.333 | Acc: 92.141% (11853/12864)
Loss: 0.333 | Acc: 92.141% (17750/19264)
Loss: 0.337 | Acc: 91.985% (23607/25664)
Loss: 0.340 | Acc: 91.910% (29470/32064)
Loss: 0.338 | Acc: 91.928% (35359/38464)
Loss: 0.339 | Acc: 91.904% (41232/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5450, Accuracy: 8695/10000 (86.95%)

Epoch: 37
Loss: 0.287 | Acc: 92.188% (59/64)
Loss: 0.308 | Acc: 92.698% (5992/6464)
Loss: 0.306 | Acc: 92.794% (11937/12864)
Loss: 0.306 | Acc: 92.831% (17883/19264)
Loss: 0.300 | Acc: 92.955% (23856/25664)
Loss: 0.308 | Acc: 92.764% (29744/32064)
Loss: 0.315 | Acc: 92.590% (35614/38464)
Loss: 0.319 | Acc: 92.522% (41509/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6381, Accuracy: 8479/10000 (84.79%)

Epoch: 38
Loss: 0.572 | Acc: 87.500% (56/64)
Loss: 0.288 | Acc: 93.054% (6015/6464)
Loss: 0.284 | Acc: 93.229% (11993/12864)
Loss: 0.286 | Acc: 93.288% (17971/19264)
Loss: 0.285 | Acc: 93.317% (23949/25664)
Loss: 0.290 | Acc: 93.182% (29878/32064)
Loss: 0.292 | Acc: 93.105% (35812/38464)
Loss: 0.292 | Acc: 93.157% (41794/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5728, Accuracy: 8641/10000 (86.41%)

Epoch: 39
Loss: 0.193 | Acc: 95.312% (61/64)
Loss: 0.266 | Acc: 93.858% (6067/6464)
Loss: 0.264 | Acc: 93.867% (12075/12864)
Loss: 0.264 | Acc: 93.833% (18076/19264)
Loss: 0.266 | Acc: 93.773% (24066/25664)
Loss: 0.268 | Acc: 93.722% (30051/32064)
Loss: 0.268 | Acc: 93.729% (36052/38464)
Loss: 0.270 | Acc: 93.683% (42030/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5745, Accuracy: 8663/10000 (86.63%)

Epoch: 40
Loss: 0.074 | Acc: 100.000% (64/64)
Loss: 0.245 | Acc: 94.168% (6087/6464)
Loss: 0.239 | Acc: 94.302% (12131/12864)
Loss: 0.246 | Acc: 94.176% (18142/19264)
Loss: 0.249 | Acc: 94.167% (24167/25664)
Loss: 0.246 | Acc: 94.249% (30220/32064)
Loss: 0.246 | Acc: 94.228% (36244/38464)
Loss: 0.247 | Acc: 94.245% (42282/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6294, Accuracy: 8548/10000 (85.48%)

Epoch: 41
Loss: 0.301 | Acc: 93.750% (60/64)
Loss: 0.216 | Acc: 94.787% (6127/6464)
Loss: 0.221 | Acc: 94.846% (12201/12864)
Loss: 0.221 | Acc: 94.809% (18264/19264)
Loss: 0.222 | Acc: 94.775% (24323/25664)
Loss: 0.222 | Acc: 94.826% (30405/32064)
Loss: 0.223 | Acc: 94.793% (36461/38464)
Loss: 0.222 | Acc: 94.807% (42534/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6455, Accuracy: 8543/10000 (85.43%)

Epoch: 42
Loss: 0.170 | Acc: 96.875% (62/64)
Loss: 0.196 | Acc: 95.220% (6155/6464)
Loss: 0.200 | Acc: 95.110% (12235/12864)
Loss: 0.205 | Acc: 94.970% (18295/19264)
Loss: 0.205 | Acc: 95.020% (24386/25664)
Loss: 0.203 | Acc: 95.088% (30489/32064)
Loss: 0.203 | Acc: 95.081% (36572/38464)
Loss: 0.202 | Acc: 95.125% (42677/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5816, Accuracy: 8782/10000 (87.82%)

Epoch: 43
Loss: 0.182 | Acc: 95.312% (61/64)
Loss: 0.172 | Acc: 95.838% (6195/6464)
Loss: 0.172 | Acc: 95.810% (12325/12864)
Loss: 0.174 | Acc: 95.759% (18447/19264)
Loss: 0.176 | Acc: 95.706% (24562/25664)
Loss: 0.174 | Acc: 95.802% (30718/32064)
Loss: 0.177 | Acc: 95.721% (36818/38464)
Loss: 0.174 | Acc: 95.805% (42982/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6069, Accuracy: 8757/10000 (87.57%)

Epoch: 44
Loss: 0.100 | Acc: 98.438% (63/64)
Loss: 0.150 | Acc: 96.241% (6221/6464)
Loss: 0.155 | Acc: 96.105% (12363/12864)
Loss: 0.148 | Acc: 96.361% (18563/19264)
Loss: 0.150 | Acc: 96.318% (24719/25664)
Loss: 0.153 | Acc: 96.229% (30855/32064)
Loss: 0.153 | Acc: 96.241% (37018/38464)
Loss: 0.151 | Acc: 96.278% (43194/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5850, Accuracy: 8825/10000 (88.25%)

Epoch: 45
Loss: 0.087 | Acc: 98.438% (63/64)
Loss: 0.121 | Acc: 97.045% (6273/6464)
Loss: 0.131 | Acc: 96.720% (12442/12864)
Loss: 0.128 | Acc: 96.844% (18656/19264)
Loss: 0.131 | Acc: 96.711% (24820/25664)
Loss: 0.130 | Acc: 96.741% (31019/32064)
Loss: 0.130 | Acc: 96.740% (37210/38464)
Loss: 0.131 | Acc: 96.768% (43414/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5947, Accuracy: 8814/10000 (88.14%)

Epoch: 46
Loss: 0.106 | Acc: 96.875% (62/64)
Loss: 0.122 | Acc: 96.952% (6267/6464)
Loss: 0.125 | Acc: 96.914% (12467/12864)
Loss: 0.123 | Acc: 97.026% (18691/19264)
Loss: 0.122 | Acc: 96.988% (24891/25664)
Loss: 0.121 | Acc: 97.015% (31107/32064)
Loss: 0.120 | Acc: 97.023% (37319/38464)
Loss: 0.120 | Acc: 97.027% (43530/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6001, Accuracy: 8815/10000 (88.15%)

Epoch: 47
Loss: 0.029 | Acc: 100.000% (64/64)
Loss: 0.112 | Acc: 97.030% (6272/6464)
Loss: 0.113 | Acc: 97.147% (12497/12864)
Loss: 0.115 | Acc: 97.129% (18711/19264)
Loss: 0.113 | Acc: 97.156% (24934/25664)
Loss: 0.114 | Acc: 97.153% (31151/32064)
Loss: 0.113 | Acc: 97.161% (37372/38464)
Loss: 0.112 | Acc: 97.194% (43605/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6031, Accuracy: 8831/10000 (88.31%)
torch.Size([100, 10])
Test set: Average loss: 0.6031, Accuracy: 8831/10000 (88.31%)

Epoch: 48
Loss: 0.038 | Acc: 100.000% (64/64)
Loss: 0.107 | Acc: 97.277% (6288/6464)
Loss: 0.102 | Acc: 97.458% (12537/12864)
Loss: 0.105 | Acc: 97.358% (18755/19264)
Loss: 0.105 | Acc: 97.323% (24977/25664)
Loss: 0.106 | Acc: 97.324% (31206/32064)
Loss: 0.106 | Acc: 97.330% (37437/38464)
Loss: 0.105 | Acc: 97.339% (43670/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6008, Accuracy: 8856/10000 (88.56%)
torch.Size([100, 10])
Test set: Average loss: 0.6008, Accuracy: 8856/10000 (88.56%)

Epoch: 49
Loss: 0.140 | Acc: 95.312% (61/64)
Loss: 0.105 | Acc: 97.293% (6289/6464)
Loss: 0.105 | Acc: 97.349% (12523/12864)
Loss: 0.103 | Acc: 97.415% (18766/19264)
Loss: 0.102 | Acc: 97.424% (25003/25664)
Loss: 0.102 | Acc: 97.433% (31241/32064)
Loss: 0.103 | Acc: 97.387% (37459/38464)
Loss: 0.104 | Acc: 97.374% (43686/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5987, Accuracy: 8853/10000 (88.53%)
torch.Size([100, 10])
Test set: Average loss: 0.5987, Accuracy: 8853/10000 (88.53%)

Epoch: 50
Loss: 0.040 | Acc: 100.000% (64/64)
Loss: 1.575 | Acc: 44.972% (2907/6464)
Loss: 1.239 | Acc: 58.823% (7567/12864)
Loss: 1.096 | Acc: 64.535% (12432/19264)
Loss: 1.021 | Acc: 67.565% (17340/25664)
Loss: 0.967 | Acc: 69.748% (22364/32064)
Loss: 0.929 | Acc: 71.215% (27392/38464)
Loss: 0.900 | Acc: 72.294% (32434/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3575, Accuracy: 5997/10000 (59.97%)

Epoch: 51
Loss: 0.552 | Acc: 89.062% (57/64)
Loss: 0.685 | Acc: 80.229% (5186/6464)
Loss: 0.679 | Acc: 80.589% (10367/12864)
Loss: 0.684 | Acc: 80.544% (15516/19264)
Loss: 0.685 | Acc: 80.478% (20654/25664)
Loss: 0.680 | Acc: 80.732% (25886/32064)
Loss: 0.671 | Acc: 80.998% (31155/38464)
Loss: 0.669 | Acc: 81.188% (36424/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8407, Accuracy: 7578/10000 (75.78%)

Epoch: 52
Loss: 0.817 | Acc: 71.875% (46/64)
Loss: 0.635 | Acc: 81.993% (5300/6464)
Loss: 0.636 | Acc: 81.864% (10531/12864)
Loss: 0.631 | Acc: 82.148% (15825/19264)
Loss: 0.635 | Acc: 82.068% (21062/25664)
Loss: 0.636 | Acc: 82.170% (26347/32064)
Loss: 0.634 | Acc: 82.222% (31626/38464)
Loss: 0.637 | Acc: 82.186% (36872/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1011, Accuracy: 6796/10000 (67.96%)

Epoch: 53
Loss: 0.731 | Acc: 78.125% (50/64)
Loss: 0.592 | Acc: 83.864% (5421/6464)
Loss: 0.605 | Acc: 83.621% (10757/12864)
Loss: 0.614 | Acc: 83.394% (16065/19264)
Loss: 0.616 | Acc: 83.323% (21384/25664)
Loss: 0.622 | Acc: 83.112% (26649/32064)
Loss: 0.623 | Acc: 83.080% (31956/38464)
Loss: 0.621 | Acc: 83.058% (37263/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2406, Accuracy: 6544/10000 (65.44%)

Epoch: 54
Loss: 0.725 | Acc: 76.562% (49/64)
Loss: 0.606 | Acc: 82.766% (5350/6464)
Loss: 0.606 | Acc: 83.085% (10688/12864)
Loss: 0.601 | Acc: 83.259% (16039/19264)
Loss: 0.607 | Acc: 83.171% (21345/25664)
Loss: 0.613 | Acc: 82.928% (26590/32064)
Loss: 0.617 | Acc: 82.836% (31862/38464)
Loss: 0.620 | Acc: 82.870% (37179/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2905, Accuracy: 6442/10000 (64.42%)

Epoch: 55
Loss: 0.797 | Acc: 76.562% (49/64)
Loss: 0.613 | Acc: 82.874% (5357/6464)
Loss: 0.608 | Acc: 83.326% (10719/12864)
Loss: 0.605 | Acc: 83.467% (16079/19264)
Loss: 0.609 | Acc: 83.323% (21384/25664)
Loss: 0.605 | Acc: 83.496% (26772/32064)
Loss: 0.607 | Acc: 83.444% (32096/38464)
Loss: 0.608 | Acc: 83.441% (37435/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7996, Accuracy: 5525/10000 (55.25%)

Epoch: 56
Loss: 0.618 | Acc: 82.812% (53/64)
Loss: 0.604 | Acc: 83.756% (5414/6464)
Loss: 0.611 | Acc: 83.551% (10748/12864)
Loss: 0.604 | Acc: 83.742% (16132/19264)
Loss: 0.600 | Acc: 83.732% (21489/25664)
Loss: 0.604 | Acc: 83.630% (26815/32064)
Loss: 0.604 | Acc: 83.683% (32188/38464)
Loss: 0.607 | Acc: 83.564% (37490/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8583, Accuracy: 7519/10000 (75.19%)

Epoch: 57
Loss: 0.609 | Acc: 85.938% (55/64)
Loss: 0.596 | Acc: 83.106% (5372/6464)
Loss: 0.595 | Acc: 83.349% (10722/12864)
Loss: 0.597 | Acc: 83.446% (16075/19264)
Loss: 0.599 | Acc: 83.494% (21428/25664)
Loss: 0.597 | Acc: 83.471% (26764/32064)
Loss: 0.602 | Acc: 83.403% (32080/38464)
Loss: 0.600 | Acc: 83.472% (37449/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9835, Accuracy: 7167/10000 (71.67%)

Epoch: 58
Loss: 0.941 | Acc: 76.562% (49/64)
Loss: 0.587 | Acc: 83.926% (5425/6464)
Loss: 0.598 | Acc: 84.002% (10806/12864)
Loss: 0.596 | Acc: 84.162% (16213/19264)
Loss: 0.596 | Acc: 84.020% (21563/25664)
Loss: 0.595 | Acc: 83.938% (26914/32064)
Loss: 0.596 | Acc: 83.871% (32260/38464)
Loss: 0.599 | Acc: 83.764% (37580/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9068, Accuracy: 7496/10000 (74.96%)

Epoch: 59
Loss: 0.289 | Acc: 93.750% (60/64)
Loss: 0.592 | Acc: 84.205% (5443/6464)
Loss: 0.581 | Acc: 84.422% (10860/12864)
Loss: 0.583 | Acc: 84.282% (16236/19264)
Loss: 0.585 | Acc: 84.200% (21609/25664)
Loss: 0.585 | Acc: 84.207% (27000/32064)
Loss: 0.587 | Acc: 84.115% (32354/38464)
Loss: 0.590 | Acc: 84.103% (37732/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0114, Accuracy: 7189/10000 (71.89%)

Epoch: 60
Loss: 0.684 | Acc: 82.812% (53/64)
Loss: 0.583 | Acc: 84.545% (5465/6464)
Loss: 0.581 | Acc: 84.383% (10855/12864)
Loss: 0.591 | Acc: 84.126% (16206/19264)
Loss: 0.591 | Acc: 84.094% (21582/25664)
Loss: 0.587 | Acc: 84.228% (27007/32064)
Loss: 0.588 | Acc: 84.141% (32364/38464)
Loss: 0.589 | Acc: 84.143% (37750/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1877, Accuracy: 6758/10000 (67.58%)

Epoch: 61
Loss: 0.829 | Acc: 81.250% (52/64)
Loss: 0.564 | Acc: 84.607% (5469/6464)
Loss: 0.573 | Acc: 84.593% (10882/12864)
Loss: 0.582 | Acc: 84.365% (16252/19264)
Loss: 0.585 | Acc: 84.422% (21666/25664)
Loss: 0.584 | Acc: 84.428% (27071/32064)
Loss: 0.584 | Acc: 84.450% (32483/38464)
Loss: 0.582 | Acc: 84.460% (37892/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0423, Accuracy: 7061/10000 (70.61%)

Epoch: 62
Loss: 0.599 | Acc: 87.500% (56/64)
Loss: 0.549 | Acc: 85.071% (5499/6464)
Loss: 0.558 | Acc: 85.059% (10942/12864)
Loss: 0.568 | Acc: 84.821% (16340/19264)
Loss: 0.571 | Acc: 84.671% (21730/25664)
Loss: 0.575 | Acc: 84.537% (27106/32064)
Loss: 0.573 | Acc: 84.471% (32491/38464)
Loss: 0.574 | Acc: 84.466% (37895/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7936, Accuracy: 7784/10000 (77.84%)

Epoch: 63
Loss: 0.309 | Acc: 87.500% (56/64)
Loss: 0.558 | Acc: 84.824% (5483/6464)
Loss: 0.564 | Acc: 84.880% (10919/12864)
Loss: 0.563 | Acc: 84.873% (16350/19264)
Loss: 0.562 | Acc: 84.718% (21742/25664)
Loss: 0.563 | Acc: 84.865% (27211/32064)
Loss: 0.566 | Acc: 84.762% (32603/38464)
Loss: 0.565 | Acc: 84.888% (38084/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1435, Accuracy: 6777/10000 (67.77%)

Epoch: 64
Loss: 0.713 | Acc: 82.812% (53/64)
Loss: 0.559 | Acc: 85.272% (5512/6464)
Loss: 0.544 | Acc: 85.650% (11018/12864)
Loss: 0.542 | Acc: 85.688% (16507/19264)
Loss: 0.548 | Acc: 85.404% (21918/25664)
Loss: 0.550 | Acc: 85.301% (27351/32064)
Loss: 0.553 | Acc: 85.236% (32785/38464)
Loss: 0.558 | Acc: 85.099% (38179/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9144, Accuracy: 7336/10000 (73.36%)

Epoch: 65
Loss: 0.412 | Acc: 90.625% (58/64)
Loss: 0.539 | Acc: 85.613% (5534/6464)
Loss: 0.541 | Acc: 85.665% (11020/12864)
Loss: 0.549 | Acc: 85.460% (16463/19264)
Loss: 0.553 | Acc: 85.263% (21882/25664)
Loss: 0.557 | Acc: 85.267% (27340/32064)
Loss: 0.553 | Acc: 85.282% (32803/38464)
Loss: 0.556 | Acc: 85.226% (38236/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7347, Accuracy: 5095/10000 (50.95%)

Epoch: 66
Loss: 0.713 | Acc: 82.812% (53/64)
Loss: 0.528 | Acc: 86.092% (5565/6464)
Loss: 0.540 | Acc: 85.549% (11005/12864)
Loss: 0.545 | Acc: 85.465% (16464/19264)
Loss: 0.552 | Acc: 85.291% (21889/25664)
Loss: 0.546 | Acc: 85.401% (27383/32064)
Loss: 0.547 | Acc: 85.368% (32836/38464)
Loss: 0.546 | Acc: 85.356% (38294/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0841, Accuracy: 6780/10000 (67.80%)

Epoch: 67
Loss: 0.610 | Acc: 84.375% (54/64)
Loss: 0.543 | Acc: 86.108% (5566/6464)
Loss: 0.534 | Acc: 86.248% (11095/12864)
Loss: 0.533 | Acc: 86.244% (16614/19264)
Loss: 0.535 | Acc: 86.292% (22146/25664)
Loss: 0.536 | Acc: 86.146% (27622/32064)
Loss: 0.536 | Acc: 86.093% (33115/38464)
Loss: 0.541 | Acc: 85.920% (38547/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5372, Accuracy: 6055/10000 (60.55%)

Epoch: 68
Loss: 0.613 | Acc: 82.812% (53/64)
Loss: 0.547 | Acc: 85.303% (5514/6464)
Loss: 0.534 | Acc: 86.023% (11066/12864)
Loss: 0.538 | Acc: 85.792% (16527/19264)
Loss: 0.535 | Acc: 85.887% (22042/25664)
Loss: 0.535 | Acc: 85.966% (27564/32064)
Loss: 0.537 | Acc: 85.914% (33046/38464)
Loss: 0.535 | Acc: 85.929% (38551/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8763, Accuracy: 7543/10000 (75.43%)

Epoch: 69
Loss: 0.739 | Acc: 78.125% (50/64)
Loss: 0.514 | Acc: 86.525% (5593/6464)
Loss: 0.516 | Acc: 86.653% (11147/12864)
Loss: 0.526 | Acc: 86.306% (16626/19264)
Loss: 0.525 | Acc: 86.319% (22153/25664)
Loss: 0.527 | Acc: 86.259% (27658/32064)
Loss: 0.523 | Acc: 86.374% (33223/38464)
Loss: 0.523 | Acc: 86.363% (38746/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0082, Accuracy: 7261/10000 (72.61%)

Epoch: 70
Loss: 0.526 | Acc: 87.500% (56/64)
Loss: 0.505 | Acc: 87.098% (5630/6464)
Loss: 0.500 | Acc: 87.166% (11213/12864)
Loss: 0.500 | Acc: 86.976% (16755/19264)
Loss: 0.501 | Acc: 87.075% (22347/25664)
Loss: 0.504 | Acc: 87.088% (27924/32064)
Loss: 0.509 | Acc: 86.912% (33430/38464)
Loss: 0.515 | Acc: 86.642% (38871/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7457, Accuracy: 7911/10000 (79.11%)

Epoch: 71
Loss: 0.792 | Acc: 79.688% (51/64)
Loss: 0.495 | Acc: 87.129% (5632/6464)
Loss: 0.499 | Acc: 87.041% (11197/12864)
Loss: 0.500 | Acc: 87.085% (16776/19264)
Loss: 0.500 | Acc: 87.005% (22329/25664)
Loss: 0.507 | Acc: 86.920% (27870/32064)
Loss: 0.505 | Acc: 86.866% (33412/38464)
Loss: 0.504 | Acc: 86.863% (38970/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0520, Accuracy: 6906/10000 (69.06%)

Epoch: 72
Loss: 0.443 | Acc: 82.812% (53/64)
Loss: 0.492 | Acc: 86.912% (5618/6464)
Loss: 0.501 | Acc: 87.142% (11210/12864)
Loss: 0.501 | Acc: 87.157% (16790/19264)
Loss: 0.498 | Acc: 87.165% (22370/25664)
Loss: 0.499 | Acc: 87.154% (27945/32064)
Loss: 0.496 | Acc: 87.219% (33548/38464)
Loss: 0.498 | Acc: 87.195% (39119/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6886, Accuracy: 8161/10000 (81.61%)

Epoch: 73
Loss: 0.329 | Acc: 92.188% (59/64)
Loss: 0.471 | Acc: 87.670% (5667/6464)
Loss: 0.484 | Acc: 87.298% (11230/12864)
Loss: 0.488 | Acc: 87.246% (16807/19264)
Loss: 0.493 | Acc: 87.157% (22368/25664)
Loss: 0.493 | Acc: 87.144% (27942/32064)
Loss: 0.489 | Acc: 87.292% (33576/38464)
Loss: 0.492 | Acc: 87.299% (39166/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8407, Accuracy: 7684/10000 (76.84%)

Epoch: 74
Loss: 0.455 | Acc: 82.812% (53/64)
Loss: 0.462 | Acc: 87.964% (5686/6464)
Loss: 0.463 | Acc: 88.169% (11342/12864)
Loss: 0.470 | Acc: 88.009% (16954/19264)
Loss: 0.470 | Acc: 87.983% (22580/25664)
Loss: 0.472 | Acc: 87.987% (28212/32064)
Loss: 0.479 | Acc: 87.820% (33779/38464)
Loss: 0.477 | Acc: 87.843% (39410/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7715, Accuracy: 7853/10000 (78.53%)

Epoch: 75
Loss: 0.509 | Acc: 85.938% (55/64)
Loss: 0.435 | Acc: 88.846% (5743/6464)
Loss: 0.447 | Acc: 88.689% (11409/12864)
Loss: 0.452 | Acc: 88.460% (17041/19264)
Loss: 0.455 | Acc: 88.396% (22686/25664)
Loss: 0.462 | Acc: 88.236% (28292/32064)
Loss: 0.466 | Acc: 88.192% (33922/38464)
Loss: 0.464 | Acc: 88.238% (39587/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5707, Accuracy: 8529/10000 (85.29%)

Epoch: 76
Loss: 0.539 | Acc: 89.062% (57/64)
Loss: 0.447 | Acc: 88.552% (5724/6464)
Loss: 0.443 | Acc: 88.829% (11427/12864)
Loss: 0.452 | Acc: 88.621% (17072/19264)
Loss: 0.454 | Acc: 88.513% (22716/25664)
Loss: 0.456 | Acc: 88.401% (28345/32064)
Loss: 0.457 | Acc: 88.361% (33987/38464)
Loss: 0.454 | Acc: 88.505% (39707/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6758, Accuracy: 8214/10000 (82.14%)

Epoch: 77
Loss: 0.769 | Acc: 82.812% (53/64)
Loss: 0.438 | Acc: 89.016% (5754/6464)
Loss: 0.440 | Acc: 89.195% (11474/12864)
Loss: 0.437 | Acc: 89.192% (17182/19264)
Loss: 0.438 | Acc: 89.191% (22890/25664)
Loss: 0.438 | Acc: 89.231% (28611/32064)
Loss: 0.437 | Acc: 89.221% (34318/38464)
Loss: 0.434 | Acc: 89.261% (40046/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6716, Accuracy: 8243/10000 (82.43%)

Epoch: 78
Loss: 0.506 | Acc: 87.500% (56/64)
Loss: 0.412 | Acc: 89.851% (5808/6464)
Loss: 0.403 | Acc: 90.081% (11588/12864)
Loss: 0.420 | Acc: 89.639% (17268/19264)
Loss: 0.426 | Acc: 89.542% (22980/25664)
Loss: 0.430 | Acc: 89.480% (28691/32064)
Loss: 0.429 | Acc: 89.476% (34416/38464)
Loss: 0.427 | Acc: 89.493% (40150/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6402, Accuracy: 8351/10000 (83.51%)

Epoch: 79
Loss: 0.424 | Acc: 92.188% (59/64)
Loss: 0.410 | Acc: 90.114% (5825/6464)
Loss: 0.396 | Acc: 90.322% (11619/12864)
Loss: 0.402 | Acc: 90.179% (17372/19264)
Loss: 0.411 | Acc: 89.963% (23088/25664)
Loss: 0.413 | Acc: 89.933% (28836/32064)
Loss: 0.413 | Acc: 89.920% (34587/38464)
Loss: 0.414 | Acc: 89.856% (40313/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1374, Accuracy: 6820/10000 (68.20%)

Epoch: 80
Loss: 0.525 | Acc: 87.500% (56/64)
Loss: 0.415 | Acc: 89.619% (5793/6464)
Loss: 0.403 | Acc: 89.918% (11567/12864)
Loss: 0.404 | Acc: 90.101% (17357/19264)
Loss: 0.402 | Acc: 90.130% (23131/25664)
Loss: 0.403 | Acc: 90.129% (28899/32064)
Loss: 0.402 | Acc: 90.227% (34705/38464)
Loss: 0.402 | Acc: 90.193% (40464/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7493, Accuracy: 8007/10000 (80.07%)

Epoch: 81
Loss: 0.288 | Acc: 90.625% (58/64)
Loss: 0.371 | Acc: 90.888% (5875/6464)
Loss: 0.389 | Acc: 90.609% (11656/12864)
Loss: 0.392 | Acc: 90.583% (17450/19264)
Loss: 0.390 | Acc: 90.621% (23257/25664)
Loss: 0.387 | Acc: 90.681% (29076/32064)
Loss: 0.391 | Acc: 90.570% (34837/38464)
Loss: 0.390 | Acc: 90.531% (40616/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5674, Accuracy: 8618/10000 (86.18%)

Epoch: 82
Loss: 0.443 | Acc: 87.500% (56/64)
Loss: 0.388 | Acc: 90.594% (5856/6464)
Loss: 0.372 | Acc: 91.247% (11738/12864)
Loss: 0.356 | Acc: 91.596% (17645/19264)
Loss: 0.362 | Acc: 91.420% (23462/25664)
Loss: 0.365 | Acc: 91.283% (29269/32064)
Loss: 0.366 | Acc: 91.288% (35113/38464)
Loss: 0.369 | Acc: 91.258% (40942/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6189, Accuracy: 8485/10000 (84.85%)

Epoch: 83
Loss: 0.349 | Acc: 92.188% (59/64)
Loss: 0.326 | Acc: 92.435% (5975/6464)
Loss: 0.343 | Acc: 91.791% (11808/12864)
Loss: 0.338 | Acc: 91.860% (17696/19264)
Loss: 0.345 | Acc: 91.724% (23540/25664)
Loss: 0.345 | Acc: 91.685% (29398/32064)
Loss: 0.353 | Acc: 91.545% (35212/38464)
Loss: 0.354 | Acc: 91.539% (41068/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8264, Accuracy: 7872/10000 (78.72%)

Epoch: 84
Loss: 0.240 | Acc: 95.312% (61/64)
Loss: 0.331 | Acc: 92.574% (5984/6464)
Loss: 0.334 | Acc: 92.164% (11856/12864)
Loss: 0.348 | Acc: 91.783% (17681/19264)
Loss: 0.344 | Acc: 91.884% (23581/25664)
Loss: 0.339 | Acc: 92.085% (29526/32064)
Loss: 0.338 | Acc: 92.099% (35425/38464)
Loss: 0.336 | Acc: 92.138% (41337/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6205, Accuracy: 8474/10000 (84.74%)

Epoch: 85
Loss: 0.427 | Acc: 87.500% (56/64)
Loss: 0.307 | Acc: 92.915% (6006/6464)
Loss: 0.312 | Acc: 92.623% (11915/12864)
Loss: 0.312 | Acc: 92.675% (17853/19264)
Loss: 0.312 | Acc: 92.651% (23778/25664)
Loss: 0.311 | Acc: 92.643% (29705/32064)
Loss: 0.314 | Acc: 92.575% (35608/38464)
Loss: 0.317 | Acc: 92.482% (41491/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5820, Accuracy: 8612/10000 (86.12%)

Epoch: 86
Loss: 0.171 | Acc: 95.312% (61/64)
Loss: 0.271 | Acc: 94.152% (6086/6464)
Loss: 0.270 | Acc: 93.983% (12090/12864)
Loss: 0.285 | Acc: 93.553% (18022/19264)
Loss: 0.292 | Acc: 93.275% (23938/25664)
Loss: 0.291 | Acc: 93.251% (29900/32064)
Loss: 0.293 | Acc: 93.220% (35856/38464)
Loss: 0.296 | Acc: 93.144% (41788/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6334, Accuracy: 8477/10000 (84.77%)

Epoch: 87
Loss: 0.338 | Acc: 93.750% (60/64)
Loss: 0.310 | Acc: 92.837% (6001/6464)
Loss: 0.283 | Acc: 93.385% (12013/12864)
Loss: 0.284 | Acc: 93.418% (17996/19264)
Loss: 0.281 | Acc: 93.454% (23984/25664)
Loss: 0.282 | Acc: 93.466% (29969/32064)
Loss: 0.283 | Acc: 93.430% (35937/38464)
Loss: 0.280 | Acc: 93.507% (41951/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5572, Accuracy: 8765/10000 (87.65%)

Epoch: 88
Loss: 0.168 | Acc: 96.875% (62/64)
Loss: 0.241 | Acc: 94.446% (6105/6464)
Loss: 0.247 | Acc: 94.333% (12135/12864)
Loss: 0.247 | Acc: 94.363% (18178/19264)
Loss: 0.248 | Acc: 94.334% (24210/25664)
Loss: 0.248 | Acc: 94.290% (30233/32064)
Loss: 0.248 | Acc: 94.262% (36257/38464)
Loss: 0.251 | Acc: 94.234% (42277/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5547, Accuracy: 8819/10000 (88.19%)

Epoch: 89
Loss: 0.213 | Acc: 95.312% (61/64)
Loss: 0.229 | Acc: 94.694% (6121/6464)
Loss: 0.229 | Acc: 94.691% (12181/12864)
Loss: 0.231 | Acc: 94.669% (18237/19264)
Loss: 0.230 | Acc: 94.638% (24288/25664)
Loss: 0.232 | Acc: 94.589% (30329/32064)
Loss: 0.230 | Acc: 94.665% (36412/38464)
Loss: 0.229 | Acc: 94.726% (42498/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5691, Accuracy: 8756/10000 (87.56%)

Epoch: 90
Loss: 0.043 | Acc: 100.000% (64/64)
Loss: 0.196 | Acc: 95.405% (6167/6464)
Loss: 0.198 | Acc: 95.328% (12263/12864)
Loss: 0.201 | Acc: 95.261% (18351/19264)
Loss: 0.199 | Acc: 95.328% (24465/25664)
Loss: 0.203 | Acc: 95.222% (30532/32064)
Loss: 0.204 | Acc: 95.162% (36603/38464)
Loss: 0.205 | Acc: 95.110% (42670/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5780, Accuracy: 8768/10000 (87.68%)

Epoch: 91
Loss: 0.256 | Acc: 93.750% (60/64)
Loss: 0.187 | Acc: 95.838% (6195/6464)
Loss: 0.184 | Acc: 95.818% (12326/12864)
Loss: 0.179 | Acc: 95.847% (18464/19264)
Loss: 0.176 | Acc: 95.811% (24589/25664)
Loss: 0.179 | Acc: 95.755% (30703/32064)
Loss: 0.182 | Acc: 95.687% (36805/38464)
Loss: 0.181 | Acc: 95.723% (42945/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5811, Accuracy: 8858/10000 (88.58%)

Epoch: 92
Loss: 0.313 | Acc: 92.188% (59/64)
Loss: 0.136 | Acc: 96.689% (6250/6464)
Loss: 0.137 | Acc: 96.665% (12435/12864)
Loss: 0.144 | Acc: 96.455% (18581/19264)
Loss: 0.151 | Acc: 96.236% (24698/25664)
Loss: 0.155 | Acc: 96.176% (30838/32064)
Loss: 0.155 | Acc: 96.150% (36983/38464)
Loss: 0.155 | Acc: 96.157% (43140/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5942, Accuracy: 8819/10000 (88.19%)

Epoch: 93
Loss: 0.163 | Acc: 95.312% (61/64)
Loss: 0.133 | Acc: 96.566% (6242/6464)
Loss: 0.136 | Acc: 96.556% (12421/12864)
Loss: 0.134 | Acc: 96.621% (18613/19264)
Loss: 0.135 | Acc: 96.591% (24789/25664)
Loss: 0.134 | Acc: 96.638% (30986/32064)
Loss: 0.132 | Acc: 96.698% (37194/38464)
Loss: 0.134 | Acc: 96.650% (43361/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5981, Accuracy: 8825/10000 (88.25%)

Epoch: 94
Loss: 0.053 | Acc: 98.438% (63/64)
Loss: 0.121 | Acc: 96.860% (6261/6464)
Loss: 0.123 | Acc: 96.891% (12464/12864)
Loss: 0.120 | Acc: 96.963% (18679/19264)
Loss: 0.121 | Acc: 96.906% (24870/25664)
Loss: 0.119 | Acc: 96.953% (31087/32064)
Loss: 0.120 | Acc: 96.979% (37302/38464)
Loss: 0.118 | Acc: 97.033% (43533/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6000, Accuracy: 8864/10000 (88.64%)

Epoch: 95
Loss: 0.034 | Acc: 100.000% (64/64)
Loss: 0.092 | Acc: 97.478% (6301/6464)
Loss: 0.095 | Acc: 97.396% (12529/12864)
Loss: 0.095 | Acc: 97.441% (18771/19264)
Loss: 0.098 | Acc: 97.370% (24989/25664)
Loss: 0.097 | Acc: 97.399% (31230/32064)
Loss: 0.099 | Acc: 97.385% (37458/38464)
Loss: 0.099 | Acc: 97.432% (43712/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6177, Accuracy: 8844/10000 (88.44%)

Epoch: 96
Loss: 0.117 | Acc: 98.438% (63/64)
Loss: 0.086 | Acc: 97.741% (6318/6464)
Loss: 0.090 | Acc: 97.575% (12552/12864)
Loss: 0.095 | Acc: 97.410% (18765/19264)
Loss: 0.094 | Acc: 97.409% (24999/25664)
Loss: 0.092 | Acc: 97.514% (31267/32064)
Loss: 0.091 | Acc: 97.551% (37522/38464)
Loss: 0.091 | Acc: 97.566% (43772/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6097, Accuracy: 8865/10000 (88.65%)

Epoch: 97
Loss: 0.072 | Acc: 98.438% (63/64)
Loss: 0.085 | Acc: 97.649% (6312/6464)
Loss: 0.085 | Acc: 97.699% (12568/12864)
Loss: 0.083 | Acc: 97.804% (18841/19264)
Loss: 0.082 | Acc: 97.834% (25108/25664)
Loss: 0.081 | Acc: 97.857% (31377/32064)
Loss: 0.082 | Acc: 97.853% (37638/38464)
Loss: 0.082 | Acc: 97.833% (43892/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6128, Accuracy: 8861/10000 (88.61%)
torch.Size([100, 10])
Test set: Average loss: 0.6128, Accuracy: 8861/10000 (88.61%)

Epoch: 98
Loss: 0.074 | Acc: 98.438% (63/64)
Loss: 0.078 | Acc: 97.803% (6322/6464)
Loss: 0.076 | Acc: 97.932% (12598/12864)
Loss: 0.077 | Acc: 97.929% (18865/19264)
Loss: 0.076 | Acc: 97.974% (25144/25664)
Loss: 0.078 | Acc: 97.917% (31396/32064)
Loss: 0.079 | Acc: 97.873% (37646/38464)
Loss: 0.080 | Acc: 97.885% (43915/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6102, Accuracy: 8867/10000 (88.67%)
torch.Size([100, 10])
Test set: Average loss: 0.6102, Accuracy: 8867/10000 (88.67%)

Epoch: 99
Loss: 0.025 | Acc: 100.000% (64/64)
Loss: 0.080 | Acc: 97.896% (6328/6464)
Loss: 0.073 | Acc: 98.134% (12624/12864)
Loss: 0.075 | Acc: 98.048% (18888/19264)
Loss: 0.076 | Acc: 98.032% (25159/25664)
Loss: 0.076 | Acc: 98.041% (31436/32064)
Loss: 0.075 | Acc: 98.037% (37709/38464)
Loss: 0.076 | Acc: 98.012% (43972/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6142, Accuracy: 8869/10000 (88.69%)
torch.Size([100, 10])
Test set: Average loss: 0.6142, Accuracy: 8869/10000 (88.69%)

Epoch: 100
Loss: 0.094 | Acc: 96.875% (62/64)
Loss: 1.832 | Acc: 33.431% (2161/6464)
Loss: 1.411 | Acc: 51.399% (6612/12864)
Loss: 1.214 | Acc: 59.474% (11457/19264)
Loss: 1.098 | Acc: 64.105% (16452/25664)
Loss: 1.022 | Acc: 67.138% (21527/32064)
Loss: 0.970 | Acc: 69.247% (26635/38464)
Loss: 0.928 | Acc: 70.874% (31797/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2956, Accuracy: 6427/10000 (64.27%)

Epoch: 101
Loss: 0.756 | Acc: 78.125% (50/64)
Loss: 0.626 | Acc: 82.194% (5313/6464)
Loss: 0.646 | Acc: 81.654% (10504/12864)
Loss: 0.648 | Acc: 81.774% (15753/19264)
Loss: 0.643 | Acc: 81.975% (21038/25664)
Loss: 0.641 | Acc: 82.023% (26300/32064)
Loss: 0.640 | Acc: 82.134% (31592/38464)
Loss: 0.643 | Acc: 82.171% (36865/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8425, Accuracy: 7550/10000 (75.50%)

Epoch: 102
Loss: 0.437 | Acc: 89.062% (57/64)
Loss: 0.587 | Acc: 84.174% (5441/6464)
Loss: 0.596 | Acc: 83.652% (10761/12864)
Loss: 0.602 | Acc: 83.435% (16073/19264)
Loss: 0.603 | Acc: 83.413% (21407/25664)
Loss: 0.606 | Acc: 83.380% (26735/32064)
Loss: 0.609 | Acc: 83.390% (32075/38464)
Loss: 0.610 | Acc: 83.403% (37418/44864)
torch.Size([100, 10])
Test set: Average loss: 3.9184, Accuracy: 2684/10000 (26.84%)

Epoch: 103
Loss: 0.853 | Acc: 75.000% (48/64)
Loss: 0.596 | Acc: 83.493% (5397/6464)
Loss: 0.598 | Acc: 83.528% (10745/12864)
Loss: 0.595 | Acc: 83.700% (16124/19264)
Loss: 0.597 | Acc: 83.763% (21497/25664)
Loss: 0.598 | Acc: 83.751% (26854/32064)
Loss: 0.598 | Acc: 83.741% (32210/38464)
Loss: 0.595 | Acc: 83.735% (37567/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9109, Accuracy: 5043/10000 (50.43%)

Epoch: 104
Loss: 0.826 | Acc: 78.125% (50/64)
Loss: 0.607 | Acc: 83.323% (5386/6464)
Loss: 0.605 | Acc: 83.660% (10762/12864)
Loss: 0.596 | Acc: 84.012% (16184/19264)
Loss: 0.595 | Acc: 83.958% (21547/25664)
Loss: 0.593 | Acc: 84.063% (26954/32064)
Loss: 0.592 | Acc: 84.021% (32318/38464)
Loss: 0.592 | Acc: 83.985% (37679/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2215, Accuracy: 6426/10000 (64.26%)

Epoch: 105
Loss: 0.803 | Acc: 78.125% (50/64)
Loss: 0.580 | Acc: 84.004% (5430/6464)
Loss: 0.580 | Acc: 84.352% (10851/12864)
Loss: 0.584 | Acc: 84.261% (16232/19264)
Loss: 0.578 | Acc: 84.414% (21664/25664)
Loss: 0.583 | Acc: 84.325% (27038/32064)
Loss: 0.586 | Acc: 84.214% (32392/38464)
Loss: 0.586 | Acc: 84.212% (37781/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5645, Accuracy: 5441/10000 (54.41%)

Epoch: 106
Loss: 0.560 | Acc: 85.938% (55/64)
Loss: 0.582 | Acc: 84.499% (5462/6464)
Loss: 0.574 | Acc: 84.507% (10871/12864)
Loss: 0.572 | Acc: 84.666% (16310/19264)
Loss: 0.577 | Acc: 84.414% (21664/25664)
Loss: 0.584 | Acc: 84.222% (27005/32064)
Loss: 0.583 | Acc: 84.305% (32427/38464)
Loss: 0.584 | Acc: 84.246% (37796/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0670, Accuracy: 7121/10000 (71.21%)

Epoch: 107
Loss: 0.456 | Acc: 89.062% (57/64)
Loss: 0.559 | Acc: 85.009% (5495/6464)
Loss: 0.570 | Acc: 84.437% (10862/12864)
Loss: 0.577 | Acc: 84.489% (16276/19264)
Loss: 0.580 | Acc: 84.500% (21686/25664)
Loss: 0.581 | Acc: 84.350% (27046/32064)
Loss: 0.579 | Acc: 84.396% (32462/38464)
Loss: 0.575 | Acc: 84.556% (37935/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1102, Accuracy: 6690/10000 (66.90%)

Epoch: 108
Loss: 0.749 | Acc: 76.562% (49/64)
Loss: 0.572 | Acc: 84.746% (5478/6464)
Loss: 0.564 | Acc: 85.082% (10945/12864)
Loss: 0.569 | Acc: 84.889% (16353/19264)
Loss: 0.570 | Acc: 84.897% (21788/25664)
Loss: 0.569 | Acc: 84.759% (27177/32064)
Loss: 0.574 | Acc: 84.697% (32578/38464)
Loss: 0.576 | Acc: 84.585% (37948/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4290, Accuracy: 3946/10000 (39.46%)

Epoch: 109
Loss: 0.865 | Acc: 75.000% (48/64)
Loss: 0.565 | Acc: 84.731% (5477/6464)
Loss: 0.576 | Acc: 84.406% (10858/12864)
Loss: 0.573 | Acc: 84.536% (16285/19264)
Loss: 0.567 | Acc: 84.620% (21717/25664)
Loss: 0.568 | Acc: 84.653% (27143/32064)
Loss: 0.572 | Acc: 84.539% (32517/38464)
Loss: 0.573 | Acc: 84.535% (37926/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3004, Accuracy: 4291/10000 (42.91%)

Epoch: 110
Loss: 0.964 | Acc: 68.750% (44/64)
Loss: 0.594 | Acc: 84.019% (5431/6464)
Loss: 0.571 | Acc: 84.577% (10880/12864)
Loss: 0.568 | Acc: 84.723% (16321/19264)
Loss: 0.567 | Acc: 84.757% (21752/25664)
Loss: 0.570 | Acc: 84.665% (27147/32064)
Loss: 0.568 | Acc: 84.801% (32618/38464)
Loss: 0.569 | Acc: 84.805% (38047/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0079, Accuracy: 7191/10000 (71.91%)

Epoch: 111
Loss: 0.798 | Acc: 73.438% (47/64)
Loss: 0.563 | Acc: 85.040% (5497/6464)
Loss: 0.570 | Acc: 84.756% (10903/12864)
Loss: 0.566 | Acc: 84.936% (16362/19264)
Loss: 0.560 | Acc: 85.072% (21833/25664)
Loss: 0.560 | Acc: 85.095% (27285/32064)
Loss: 0.564 | Acc: 84.916% (32662/38464)
Loss: 0.565 | Acc: 84.877% (38079/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3351, Accuracy: 6419/10000 (64.19%)

Epoch: 112
Loss: 1.020 | Acc: 70.312% (45/64)
Loss: 0.538 | Acc: 86.077% (5564/6464)
Loss: 0.540 | Acc: 85.860% (11045/12864)
Loss: 0.549 | Acc: 85.574% (16485/19264)
Loss: 0.550 | Acc: 85.556% (21957/25664)
Loss: 0.554 | Acc: 85.432% (27393/32064)
Loss: 0.559 | Acc: 85.269% (32798/38464)
Loss: 0.559 | Acc: 85.298% (38268/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5057, Accuracy: 5456/10000 (54.56%)

Epoch: 113
Loss: 0.695 | Acc: 82.812% (53/64)
Loss: 0.550 | Acc: 85.628% (5535/6464)
Loss: 0.556 | Acc: 85.191% (10959/12864)
Loss: 0.547 | Acc: 85.387% (16449/19264)
Loss: 0.546 | Acc: 85.373% (21910/25664)
Loss: 0.546 | Acc: 85.410% (27386/32064)
Loss: 0.548 | Acc: 85.397% (32847/38464)
Loss: 0.551 | Acc: 85.345% (38289/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1594, Accuracy: 6740/10000 (67.40%)

Epoch: 114
Loss: 0.714 | Acc: 82.812% (53/64)
Loss: 0.543 | Acc: 85.829% (5548/6464)
Loss: 0.536 | Acc: 85.712% (11026/12864)
Loss: 0.544 | Acc: 85.403% (16452/19264)
Loss: 0.544 | Acc: 85.447% (21929/25664)
Loss: 0.544 | Acc: 85.473% (27406/32064)
Loss: 0.547 | Acc: 85.438% (32863/38464)
Loss: 0.548 | Acc: 85.443% (38333/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0288, Accuracy: 6980/10000 (69.80%)

Epoch: 115
Loss: 0.716 | Acc: 84.375% (54/64)
Loss: 0.509 | Acc: 86.757% (5608/6464)
Loss: 0.511 | Acc: 86.863% (11174/12864)
Loss: 0.528 | Acc: 86.239% (16613/19264)
Loss: 0.531 | Acc: 86.047% (22083/25664)
Loss: 0.535 | Acc: 85.916% (27548/32064)
Loss: 0.537 | Acc: 85.810% (33006/38464)
Loss: 0.539 | Acc: 85.726% (38460/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8514, Accuracy: 7738/10000 (77.38%)

Epoch: 116
Loss: 0.509 | Acc: 87.500% (56/64)
Loss: 0.508 | Acc: 86.881% (5616/6464)
Loss: 0.518 | Acc: 86.559% (11135/12864)
Loss: 0.528 | Acc: 86.181% (16602/19264)
Loss: 0.526 | Acc: 86.230% (22130/25664)
Loss: 0.532 | Acc: 86.103% (27608/32064)
Loss: 0.529 | Acc: 86.234% (33169/38464)
Loss: 0.532 | Acc: 86.118% (38636/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8713, Accuracy: 7615/10000 (76.15%)

Epoch: 117
Loss: 0.491 | Acc: 84.375% (54/64)
Loss: 0.529 | Acc: 85.953% (5556/6464)
Loss: 0.519 | Acc: 86.217% (11091/12864)
Loss: 0.514 | Acc: 86.399% (16644/19264)
Loss: 0.516 | Acc: 86.471% (22192/25664)
Loss: 0.523 | Acc: 86.330% (27681/32064)
Loss: 0.524 | Acc: 86.273% (33184/38464)
Loss: 0.525 | Acc: 86.279% (38708/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9784, Accuracy: 7169/10000 (71.69%)

Epoch: 118
Loss: 0.672 | Acc: 84.375% (54/64)
Loss: 0.517 | Acc: 86.170% (5570/6464)
Loss: 0.516 | Acc: 86.342% (11107/12864)
Loss: 0.512 | Acc: 86.374% (16639/19264)
Loss: 0.515 | Acc: 86.378% (22168/25664)
Loss: 0.519 | Acc: 86.199% (27639/32064)
Loss: 0.519 | Acc: 86.210% (33160/38464)
Loss: 0.521 | Acc: 86.201% (38673/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1042, Accuracy: 6874/10000 (68.74%)

Epoch: 119
Loss: 0.407 | Acc: 90.625% (58/64)
Loss: 0.524 | Acc: 85.999% (5559/6464)
Loss: 0.512 | Acc: 86.598% (11140/12864)
Loss: 0.508 | Acc: 86.758% (16713/19264)
Loss: 0.509 | Acc: 86.721% (22256/25664)
Loss: 0.512 | Acc: 86.602% (27768/32064)
Loss: 0.509 | Acc: 86.684% (33342/38464)
Loss: 0.511 | Acc: 86.689% (38892/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7214, Accuracy: 8014/10000 (80.14%)

Epoch: 120
Loss: 0.456 | Acc: 84.375% (54/64)
Loss: 0.513 | Acc: 86.479% (5590/6464)
Loss: 0.511 | Acc: 86.707% (11154/12864)
Loss: 0.510 | Acc: 86.758% (16713/19264)
Loss: 0.509 | Acc: 86.861% (22292/25664)
Loss: 0.506 | Acc: 86.964% (27884/32064)
Loss: 0.508 | Acc: 86.983% (33457/38464)
Loss: 0.506 | Acc: 87.007% (39035/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1496, Accuracy: 6813/10000 (68.13%)

Epoch: 121
Loss: 0.531 | Acc: 85.938% (55/64)
Loss: 0.476 | Acc: 87.314% (5644/6464)
Loss: 0.480 | Acc: 87.298% (11230/12864)
Loss: 0.491 | Acc: 87.137% (16786/19264)
Loss: 0.496 | Acc: 87.087% (22350/25664)
Loss: 0.492 | Acc: 87.226% (27968/32064)
Loss: 0.495 | Acc: 87.102% (33503/38464)
Loss: 0.496 | Acc: 87.159% (39103/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2381, Accuracy: 6549/10000 (65.49%)

Epoch: 122
Loss: 0.793 | Acc: 81.250% (52/64)
Loss: 0.465 | Acc: 88.134% (5697/6464)
Loss: 0.463 | Acc: 88.246% (11352/12864)
Loss: 0.469 | Acc: 87.962% (16945/19264)
Loss: 0.475 | Acc: 87.866% (22550/25664)
Loss: 0.481 | Acc: 87.718% (28126/32064)
Loss: 0.479 | Acc: 87.698% (33732/38464)
Loss: 0.483 | Acc: 87.556% (39281/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7996, Accuracy: 7762/10000 (77.62%)

Epoch: 123
Loss: 0.470 | Acc: 82.812% (53/64)
Loss: 0.468 | Acc: 88.258% (5705/6464)
Loss: 0.474 | Acc: 88.114% (11335/12864)
Loss: 0.474 | Acc: 87.983% (16949/19264)
Loss: 0.471 | Acc: 88.096% (22609/25664)
Loss: 0.471 | Acc: 88.130% (28258/32064)
Loss: 0.473 | Acc: 88.075% (33877/38464)
Loss: 0.472 | Acc: 88.106% (39528/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7267, Accuracy: 8040/10000 (80.40%)

Epoch: 124
Loss: 0.544 | Acc: 89.062% (57/64)
Loss: 0.456 | Acc: 88.598% (5727/6464)
Loss: 0.450 | Acc: 88.775% (11420/12864)
Loss: 0.453 | Acc: 88.808% (17108/19264)
Loss: 0.456 | Acc: 88.614% (22742/25664)
Loss: 0.463 | Acc: 88.395% (28343/32064)
Loss: 0.463 | Acc: 88.444% (34019/38464)
Loss: 0.466 | Acc: 88.358% (39641/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9259, Accuracy: 7569/10000 (75.69%)

Epoch: 125
Loss: 0.401 | Acc: 90.625% (58/64)
Loss: 0.415 | Acc: 89.851% (5808/6464)
Loss: 0.432 | Acc: 89.319% (11490/12864)
Loss: 0.444 | Acc: 88.974% (17140/19264)
Loss: 0.442 | Acc: 89.016% (22845/25664)
Loss: 0.448 | Acc: 88.832% (28483/32064)
Loss: 0.449 | Acc: 88.756% (34139/38464)
Loss: 0.453 | Acc: 88.681% (39786/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9359, Accuracy: 7378/10000 (73.78%)

Epoch: 126
Loss: 0.631 | Acc: 76.562% (49/64)
Loss: 0.420 | Acc: 89.619% (5793/6464)
Loss: 0.420 | Acc: 89.669% (11535/12864)
Loss: 0.434 | Acc: 89.208% (17185/19264)
Loss: 0.438 | Acc: 89.078% (22861/25664)
Loss: 0.437 | Acc: 89.116% (28574/32064)
Loss: 0.438 | Acc: 89.029% (34244/38464)
Loss: 0.440 | Acc: 88.927% (39896/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6514, Accuracy: 8348/10000 (83.48%)

Epoch: 127
Loss: 0.525 | Acc: 87.500% (56/64)
Loss: 0.427 | Acc: 89.233% (5768/6464)
Loss: 0.435 | Acc: 89.164% (11470/12864)
Loss: 0.438 | Acc: 89.187% (17181/19264)
Loss: 0.436 | Acc: 89.183% (22888/25664)
Loss: 0.436 | Acc: 89.178% (28594/32064)
Loss: 0.433 | Acc: 89.229% (34321/38464)
Loss: 0.432 | Acc: 89.265% (40048/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0336, Accuracy: 7272/10000 (72.72%)

Epoch: 128
Loss: 0.510 | Acc: 89.062% (57/64)
Loss: 0.395 | Acc: 90.424% (5845/6464)
Loss: 0.411 | Acc: 89.809% (11553/12864)
Loss: 0.415 | Acc: 89.665% (17273/19264)
Loss: 0.418 | Acc: 89.639% (23005/25664)
Loss: 0.420 | Acc: 89.577% (28722/32064)
Loss: 0.421 | Acc: 89.525% (34435/38464)
Loss: 0.421 | Acc: 89.513% (40159/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6380, Accuracy: 8377/10000 (83.77%)

Epoch: 129
Loss: 0.433 | Acc: 90.625% (58/64)
Loss: 0.389 | Acc: 90.207% (5831/6464)
Loss: 0.396 | Acc: 90.291% (11615/12864)
Loss: 0.391 | Acc: 90.355% (17406/19264)
Loss: 0.394 | Acc: 90.348% (23187/25664)
Loss: 0.399 | Acc: 90.220% (28928/32064)
Loss: 0.406 | Acc: 90.037% (34632/38464)
Loss: 0.409 | Acc: 89.941% (40351/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0959, Accuracy: 7152/10000 (71.52%)

Epoch: 130
Loss: 0.384 | Acc: 87.500% (56/64)
Loss: 0.399 | Acc: 90.161% (5828/6464)
Loss: 0.404 | Acc: 90.127% (11594/12864)
Loss: 0.390 | Acc: 90.552% (17444/19264)
Loss: 0.390 | Acc: 90.539% (23236/25664)
Loss: 0.387 | Acc: 90.606% (29052/32064)
Loss: 0.389 | Acc: 90.547% (34828/38464)
Loss: 0.391 | Acc: 90.451% (40580/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6536, Accuracy: 8257/10000 (82.57%)

Epoch: 131
Loss: 0.644 | Acc: 82.812% (53/64)
Loss: 0.353 | Acc: 91.306% (5902/6464)
Loss: 0.370 | Acc: 91.006% (11707/12864)
Loss: 0.364 | Acc: 91.170% (17563/19264)
Loss: 0.365 | Acc: 91.182% (23401/25664)
Loss: 0.370 | Acc: 91.083% (29205/32064)
Loss: 0.371 | Acc: 91.077% (35032/38464)
Loss: 0.374 | Acc: 90.995% (40824/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7235, Accuracy: 8149/10000 (81.49%)

Epoch: 132
Loss: 0.410 | Acc: 90.625% (58/64)
Loss: 0.318 | Acc: 92.404% (5973/6464)
Loss: 0.345 | Acc: 91.799% (11809/12864)
Loss: 0.348 | Acc: 91.720% (17669/19264)
Loss: 0.357 | Acc: 91.545% (23494/25664)
Loss: 0.361 | Acc: 91.420% (29313/32064)
Loss: 0.361 | Acc: 91.376% (35147/38464)
Loss: 0.363 | Acc: 91.320% (40970/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5851, Accuracy: 8548/10000 (85.48%)

Epoch: 133
Loss: 0.365 | Acc: 93.750% (60/64)
Loss: 0.305 | Acc: 92.899% (6005/6464)
Loss: 0.322 | Acc: 92.467% (11895/12864)
Loss: 0.332 | Acc: 92.281% (17777/19264)
Loss: 0.335 | Acc: 92.164% (23653/25664)
Loss: 0.339 | Acc: 92.028% (29508/32064)
Loss: 0.341 | Acc: 91.954% (35369/38464)
Loss: 0.343 | Acc: 91.878% (41220/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5816, Accuracy: 8656/10000 (86.56%)

Epoch: 134
Loss: 0.184 | Acc: 96.875% (62/64)
Loss: 0.315 | Acc: 92.837% (6001/6464)
Loss: 0.315 | Acc: 92.724% (11928/12864)
Loss: 0.316 | Acc: 92.634% (17845/19264)
Loss: 0.321 | Acc: 92.554% (23753/25664)
Loss: 0.324 | Acc: 92.493% (29657/32064)
Loss: 0.325 | Acc: 92.447% (35559/38464)
Loss: 0.321 | Acc: 92.515% (41506/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5673, Accuracy: 8670/10000 (86.70%)

Epoch: 135
Loss: 0.232 | Acc: 93.750% (60/64)
Loss: 0.277 | Acc: 93.595% (6050/6464)
Loss: 0.288 | Acc: 93.151% (11983/12864)
Loss: 0.295 | Acc: 92.977% (17911/19264)
Loss: 0.305 | Acc: 92.764% (23807/25664)
Loss: 0.304 | Acc: 92.867% (29777/32064)
Loss: 0.308 | Acc: 92.798% (35694/38464)
Loss: 0.307 | Acc: 92.807% (41637/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6318, Accuracy: 8499/10000 (84.99%)

Epoch: 136
Loss: 0.220 | Acc: 95.312% (61/64)
Loss: 0.285 | Acc: 93.069% (6016/6464)
Loss: 0.283 | Acc: 93.252% (11996/12864)
Loss: 0.277 | Acc: 93.496% (18011/19264)
Loss: 0.281 | Acc: 93.415% (23974/25664)
Loss: 0.285 | Acc: 93.363% (29936/32064)
Loss: 0.287 | Acc: 93.282% (35880/38464)
Loss: 0.287 | Acc: 93.320% (41867/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5829, Accuracy: 8701/10000 (87.01%)

Epoch: 137
Loss: 0.241 | Acc: 93.750% (60/64)
Loss: 0.263 | Acc: 93.626% (6052/6464)
Loss: 0.260 | Acc: 93.890% (12078/12864)
Loss: 0.256 | Acc: 94.036% (18115/19264)
Loss: 0.259 | Acc: 93.941% (24109/25664)
Loss: 0.261 | Acc: 93.915% (30113/32064)
Loss: 0.262 | Acc: 93.872% (36107/38464)
Loss: 0.261 | Acc: 93.944% (42147/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6119, Accuracy: 8634/10000 (86.34%)

Epoch: 138
Loss: 0.302 | Acc: 95.312% (61/64)
Loss: 0.255 | Acc: 93.982% (6075/6464)
Loss: 0.250 | Acc: 94.014% (12094/12864)
Loss: 0.243 | Acc: 94.238% (18154/19264)
Loss: 0.243 | Acc: 94.276% (24195/25664)
Loss: 0.243 | Acc: 94.271% (30227/32064)
Loss: 0.240 | Acc: 94.353% (36292/38464)
Loss: 0.243 | Acc: 94.298% (42306/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6071, Accuracy: 8652/10000 (86.52%)

Epoch: 139
Loss: 0.366 | Acc: 92.188% (59/64)
Loss: 0.221 | Acc: 95.065% (6145/6464)
Loss: 0.218 | Acc: 95.095% (12233/12864)
Loss: 0.221 | Acc: 94.913% (18284/19264)
Loss: 0.222 | Acc: 94.899% (24355/25664)
Loss: 0.222 | Acc: 94.888% (30425/32064)
Loss: 0.222 | Acc: 94.889% (36498/38464)
Loss: 0.220 | Acc: 94.934% (42591/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5862, Accuracy: 8773/10000 (87.73%)

Epoch: 140
Loss: 0.289 | Acc: 89.062% (57/64)
Loss: 0.192 | Acc: 95.668% (6184/6464)
Loss: 0.192 | Acc: 95.569% (12294/12864)
Loss: 0.194 | Acc: 95.489% (18395/19264)
Loss: 0.196 | Acc: 95.449% (24496/25664)
Loss: 0.195 | Acc: 95.409% (30592/32064)
Loss: 0.196 | Acc: 95.416% (36701/38464)
Loss: 0.197 | Acc: 95.377% (42790/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8269, Accuracy: 8076/10000 (80.76%)

Epoch: 141
Loss: 0.219 | Acc: 93.750% (60/64)
Loss: 0.171 | Acc: 95.916% (6200/6464)
Loss: 0.176 | Acc: 95.810% (12325/12864)
Loss: 0.172 | Acc: 95.925% (18479/19264)
Loss: 0.174 | Acc: 95.850% (24599/25664)
Loss: 0.171 | Acc: 95.914% (30754/32064)
Loss: 0.170 | Acc: 95.910% (36891/38464)
Loss: 0.172 | Acc: 95.892% (43021/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5981, Accuracy: 8796/10000 (87.96%)

Epoch: 142
Loss: 0.080 | Acc: 98.438% (63/64)
Loss: 0.147 | Acc: 96.225% (6220/6464)
Loss: 0.147 | Acc: 96.401% (12401/12864)
Loss: 0.149 | Acc: 96.325% (18556/19264)
Loss: 0.148 | Acc: 96.384% (24736/25664)
Loss: 0.147 | Acc: 96.413% (30914/32064)
Loss: 0.147 | Acc: 96.391% (37076/38464)
Loss: 0.149 | Acc: 96.318% (43212/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5938, Accuracy: 8816/10000 (88.16%)

Epoch: 143
Loss: 0.099 | Acc: 98.438% (63/64)
Loss: 0.137 | Acc: 96.535% (6240/6464)
Loss: 0.132 | Acc: 96.634% (12431/12864)
Loss: 0.134 | Acc: 96.667% (18622/19264)
Loss: 0.136 | Acc: 96.626% (24798/25664)
Loss: 0.134 | Acc: 96.716% (31011/32064)
Loss: 0.132 | Acc: 96.748% (37213/38464)
Loss: 0.132 | Acc: 96.750% (43406/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5977, Accuracy: 8857/10000 (88.57%)

Epoch: 144
Loss: 0.093 | Acc: 98.438% (63/64)
Loss: 0.114 | Acc: 97.061% (6274/6464)
Loss: 0.110 | Acc: 97.116% (12493/12864)
Loss: 0.114 | Acc: 97.109% (18707/19264)
Loss: 0.114 | Acc: 97.093% (24918/25664)
Loss: 0.114 | Acc: 97.062% (31122/32064)
Loss: 0.115 | Acc: 97.047% (37328/38464)
Loss: 0.115 | Acc: 97.038% (43535/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6115, Accuracy: 8846/10000 (88.46%)

Epoch: 145
Loss: 0.028 | Acc: 100.000% (64/64)
Loss: 0.099 | Acc: 97.401% (6296/6464)
Loss: 0.098 | Acc: 97.474% (12539/12864)
Loss: 0.096 | Acc: 97.545% (18791/19264)
Loss: 0.096 | Acc: 97.545% (25034/25664)
Loss: 0.095 | Acc: 97.580% (31288/32064)
Loss: 0.096 | Acc: 97.551% (37522/38464)
Loss: 0.096 | Acc: 97.541% (43761/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6094, Accuracy: 8853/10000 (88.53%)

Epoch: 146
Loss: 0.185 | Acc: 93.750% (60/64)
Loss: 0.086 | Acc: 97.726% (6317/6464)
Loss: 0.085 | Acc: 97.707% (12569/12864)
Loss: 0.091 | Acc: 97.648% (18811/19264)
Loss: 0.088 | Acc: 97.748% (25086/25664)
Loss: 0.089 | Acc: 97.742% (31340/32064)
Loss: 0.089 | Acc: 97.738% (37594/38464)
Loss: 0.088 | Acc: 97.769% (43863/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6163, Accuracy: 8862/10000 (88.62%)

Epoch: 147
Loss: 0.069 | Acc: 98.438% (63/64)
Loss: 0.080 | Acc: 97.881% (6327/6464)
Loss: 0.083 | Acc: 97.746% (12574/12864)
Loss: 0.083 | Acc: 97.752% (18831/19264)
Loss: 0.081 | Acc: 97.841% (25110/25664)
Loss: 0.080 | Acc: 97.882% (31385/32064)
Loss: 0.080 | Acc: 97.879% (37648/38464)
Loss: 0.081 | Acc: 97.876% (43911/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6144, Accuracy: 8853/10000 (88.53%)
torch.Size([100, 10])
Test set: Average loss: 0.6144, Accuracy: 8853/10000 (88.53%)

Epoch: 148
Loss: 0.032 | Acc: 98.438% (63/64)
Loss: 0.070 | Acc: 98.221% (6349/6464)
Loss: 0.076 | Acc: 98.033% (12611/12864)
Loss: 0.078 | Acc: 97.976% (18874/19264)
Loss: 0.077 | Acc: 98.001% (25151/25664)
Loss: 0.076 | Acc: 98.007% (31425/32064)
Loss: 0.076 | Acc: 98.011% (37699/38464)
Loss: 0.076 | Acc: 98.010% (43971/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6123, Accuracy: 8857/10000 (88.57%)
torch.Size([100, 10])
Test set: Average loss: 0.6123, Accuracy: 8857/10000 (88.57%)

Epoch: 149
Loss: 0.195 | Acc: 95.312% (61/64)
Loss: 0.074 | Acc: 98.159% (6345/6464)
Loss: 0.072 | Acc: 98.119% (12622/12864)
Loss: 0.075 | Acc: 98.043% (18887/19264)
Loss: 0.073 | Acc: 98.063% (25167/25664)
Loss: 0.074 | Acc: 98.020% (31429/32064)
Loss: 0.075 | Acc: 98.001% (37695/38464)
Loss: 0.075 | Acc: 98.036% (43983/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6155, Accuracy: 8854/10000 (88.54%)
torch.Size([100, 10])
Test set: Average loss: 0.6155, Accuracy: 8854/10000 (88.54%)

Epoch: 150
Loss: 0.097 | Acc: 96.875% (62/64)
Loss: 1.486 | Acc: 50.897% (3290/6464)
Loss: 1.171 | Acc: 62.648% (8059/12864)
Loss: 1.052 | Acc: 67.177% (12941/19264)
Loss: 0.968 | Acc: 70.351% (18055/25664)
Loss: 0.912 | Acc: 72.377% (23207/32064)
Loss: 0.872 | Acc: 73.775% (28377/38464)
Loss: 0.843 | Acc: 74.811% (33563/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8745, Accuracy: 4815/10000 (48.15%)

Epoch: 151
Loss: 0.587 | Acc: 82.812% (53/64)
Loss: 0.637 | Acc: 81.544% (5271/6464)
Loss: 0.629 | Acc: 82.167% (10570/12864)
Loss: 0.635 | Acc: 82.143% (15824/19264)
Loss: 0.631 | Acc: 82.248% (21108/25664)
Loss: 0.629 | Acc: 82.367% (26410/32064)
Loss: 0.629 | Acc: 82.410% (31698/38464)
Loss: 0.627 | Acc: 82.492% (37009/44864)
torch.Size([100, 10])
Test set: Average loss: 3.7052, Accuracy: 3081/10000 (30.81%)

Epoch: 152
Loss: 1.137 | Acc: 64.062% (41/64)
Loss: 0.594 | Acc: 83.973% (5428/6464)
Loss: 0.578 | Acc: 84.196% (10831/12864)
Loss: 0.583 | Acc: 84.199% (16220/19264)
Loss: 0.588 | Acc: 83.958% (21547/25664)
Loss: 0.594 | Acc: 83.904% (26903/32064)
Loss: 0.599 | Acc: 83.764% (32219/38464)
Loss: 0.598 | Acc: 83.838% (37613/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9791, Accuracy: 7118/10000 (71.18%)

Epoch: 153
Loss: 0.653 | Acc: 75.000% (48/64)
Loss: 0.587 | Acc: 83.524% (5399/6464)
Loss: 0.575 | Acc: 84.196% (10831/12864)
Loss: 0.576 | Acc: 84.422% (16263/19264)
Loss: 0.575 | Acc: 84.469% (21678/25664)
Loss: 0.579 | Acc: 84.347% (27045/32064)
Loss: 0.586 | Acc: 84.136% (32362/38464)
Loss: 0.585 | Acc: 84.177% (37765/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9472, Accuracy: 7327/10000 (73.27%)

Epoch: 154
Loss: 0.635 | Acc: 79.688% (51/64)
Loss: 0.585 | Acc: 83.834% (5419/6464)
Loss: 0.588 | Acc: 84.017% (10808/12864)
Loss: 0.585 | Acc: 84.287% (16237/19264)
Loss: 0.583 | Acc: 84.391% (21658/25664)
Loss: 0.582 | Acc: 84.459% (27081/32064)
Loss: 0.584 | Acc: 84.372% (32453/38464)
Loss: 0.582 | Acc: 84.442% (37884/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5488, Accuracy: 5642/10000 (56.42%)

Epoch: 155
Loss: 0.897 | Acc: 76.562% (49/64)
Loss: 0.585 | Acc: 84.793% (5481/6464)
Loss: 0.582 | Acc: 84.538% (10875/12864)
Loss: 0.575 | Acc: 84.614% (16300/19264)
Loss: 0.574 | Acc: 84.543% (21697/25664)
Loss: 0.570 | Acc: 84.618% (27132/32064)
Loss: 0.574 | Acc: 84.497% (32501/38464)
Loss: 0.578 | Acc: 84.415% (37872/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0232, Accuracy: 4834/10000 (48.34%)

Epoch: 156
Loss: 0.672 | Acc: 78.125% (50/64)
Loss: 0.562 | Acc: 84.916% (5489/6464)
Loss: 0.559 | Acc: 84.989% (10933/12864)
Loss: 0.564 | Acc: 84.868% (16349/19264)
Loss: 0.563 | Acc: 84.909% (21791/25664)
Loss: 0.565 | Acc: 84.805% (27192/32064)
Loss: 0.570 | Acc: 84.739% (32594/38464)
Loss: 0.569 | Acc: 84.723% (38010/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1633, Accuracy: 6660/10000 (66.60%)

Epoch: 157
Loss: 0.635 | Acc: 78.125% (50/64)
Loss: 0.566 | Acc: 84.576% (5467/6464)
Loss: 0.560 | Acc: 84.639% (10888/12864)
Loss: 0.571 | Acc: 84.432% (16265/19264)
Loss: 0.572 | Acc: 84.585% (21708/25664)
Loss: 0.570 | Acc: 84.681% (27152/32064)
Loss: 0.570 | Acc: 84.729% (32590/38464)
Loss: 0.571 | Acc: 84.678% (37990/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9162, Accuracy: 7274/10000 (72.74%)

Epoch: 158
Loss: 0.756 | Acc: 78.125% (50/64)
Loss: 0.554 | Acc: 85.535% (5529/6464)
Loss: 0.550 | Acc: 85.176% (10957/12864)
Loss: 0.559 | Acc: 84.993% (16373/19264)
Loss: 0.557 | Acc: 85.209% (21868/25664)
Loss: 0.566 | Acc: 84.955% (27240/32064)
Loss: 0.565 | Acc: 84.965% (32681/38464)
Loss: 0.566 | Acc: 84.943% (38109/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0797, Accuracy: 6907/10000 (69.07%)

Epoch: 159
Loss: 0.531 | Acc: 82.812% (53/64)
Loss: 0.554 | Acc: 84.994% (5494/6464)
Loss: 0.549 | Acc: 85.176% (10957/12864)
Loss: 0.551 | Acc: 85.366% (16445/19264)
Loss: 0.555 | Acc: 85.092% (21838/25664)
Loss: 0.553 | Acc: 85.205% (27320/32064)
Loss: 0.558 | Acc: 85.093% (32730/38464)
Loss: 0.563 | Acc: 84.972% (38122/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5492, Accuracy: 5928/10000 (59.28%)

Epoch: 160
Loss: 0.668 | Acc: 81.250% (52/64)
Loss: 0.560 | Acc: 85.056% (5498/6464)
Loss: 0.568 | Acc: 84.958% (10929/12864)
Loss: 0.557 | Acc: 85.309% (16434/19264)
Loss: 0.558 | Acc: 85.143% (21851/25664)
Loss: 0.550 | Acc: 85.379% (27376/32064)
Loss: 0.555 | Acc: 85.238% (32786/38464)
Loss: 0.554 | Acc: 85.282% (38261/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0781, Accuracy: 6924/10000 (69.24%)

Epoch: 161
Loss: 0.915 | Acc: 78.125% (50/64)
Loss: 0.530 | Acc: 86.030% (5561/6464)
Loss: 0.535 | Acc: 85.899% (11050/12864)
Loss: 0.549 | Acc: 85.346% (16441/19264)
Loss: 0.553 | Acc: 85.197% (21865/25664)
Loss: 0.560 | Acc: 85.148% (27302/32064)
Loss: 0.560 | Acc: 85.217% (32778/38464)
Loss: 0.560 | Acc: 85.193% (38221/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3922, Accuracy: 6115/10000 (61.15%)

Epoch: 162
Loss: 0.796 | Acc: 76.562% (49/64)
Loss: 0.552 | Acc: 85.025% (5496/6464)
Loss: 0.541 | Acc: 85.774% (11034/12864)
Loss: 0.543 | Acc: 85.704% (16510/19264)
Loss: 0.545 | Acc: 85.739% (22004/25664)
Loss: 0.546 | Acc: 85.651% (27463/32064)
Loss: 0.549 | Acc: 85.581% (32918/38464)
Loss: 0.551 | Acc: 85.483% (38351/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6187, Accuracy: 8356/10000 (83.56%)

Epoch: 163
Loss: 0.397 | Acc: 93.750% (60/64)
Loss: 0.520 | Acc: 86.494% (5591/6464)
Loss: 0.531 | Acc: 86.163% (11084/12864)
Loss: 0.539 | Acc: 85.891% (16546/19264)
Loss: 0.545 | Acc: 85.766% (22011/25664)
Loss: 0.548 | Acc: 85.604% (27448/32064)
Loss: 0.545 | Acc: 85.665% (32950/38464)
Loss: 0.549 | Acc: 85.536% (38375/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8340, Accuracy: 7643/10000 (76.43%)

Epoch: 164
Loss: 0.623 | Acc: 81.250% (52/64)
Loss: 0.530 | Acc: 86.340% (5581/6464)
Loss: 0.514 | Acc: 86.746% (11159/12864)
Loss: 0.525 | Acc: 86.322% (16629/19264)
Loss: 0.539 | Acc: 85.883% (22041/25664)
Loss: 0.536 | Acc: 85.878% (27536/32064)
Loss: 0.536 | Acc: 85.852% (33022/38464)
Loss: 0.538 | Acc: 85.804% (38495/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8616, Accuracy: 7600/10000 (76.00%)

Epoch: 165
Loss: 0.439 | Acc: 89.062% (57/64)
Loss: 0.530 | Acc: 86.216% (5573/6464)
Loss: 0.536 | Acc: 86.062% (11071/12864)
Loss: 0.537 | Acc: 85.906% (16549/19264)
Loss: 0.534 | Acc: 86.050% (22084/25664)
Loss: 0.531 | Acc: 86.209% (27642/32064)
Loss: 0.529 | Acc: 86.283% (33188/38464)
Loss: 0.529 | Acc: 86.232% (38687/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3860, Accuracy: 6258/10000 (62.58%)

Epoch: 166
Loss: 0.714 | Acc: 79.688% (51/64)
Loss: 0.512 | Acc: 86.355% (5582/6464)
Loss: 0.515 | Acc: 86.334% (11106/12864)
Loss: 0.518 | Acc: 86.233% (16612/19264)
Loss: 0.520 | Acc: 86.241% (22133/25664)
Loss: 0.521 | Acc: 86.137% (27619/32064)
Loss: 0.525 | Acc: 86.013% (33084/38464)
Loss: 0.526 | Acc: 86.047% (38604/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8580, Accuracy: 7575/10000 (75.75%)

Epoch: 167
Loss: 0.553 | Acc: 82.812% (53/64)
Loss: 0.497 | Acc: 86.618% (5599/6464)
Loss: 0.500 | Acc: 86.824% (11169/12864)
Loss: 0.509 | Acc: 86.778% (16717/19264)
Loss: 0.504 | Acc: 86.861% (22292/25664)
Loss: 0.513 | Acc: 86.611% (27771/32064)
Loss: 0.517 | Acc: 86.489% (33267/38464)
Loss: 0.518 | Acc: 86.517% (38815/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4687, Accuracy: 6163/10000 (61.63%)

Epoch: 168
Loss: 0.584 | Acc: 82.812% (53/64)
Loss: 0.478 | Acc: 87.794% (5675/6464)
Loss: 0.495 | Acc: 87.267% (11226/12864)
Loss: 0.498 | Acc: 87.194% (16797/19264)
Loss: 0.504 | Acc: 87.001% (22328/25664)
Loss: 0.506 | Acc: 86.911% (27867/32064)
Loss: 0.510 | Acc: 86.834% (33400/38464)
Loss: 0.511 | Acc: 86.847% (38963/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7896, Accuracy: 7794/10000 (77.94%)

Epoch: 169
Loss: 0.663 | Acc: 76.562% (49/64)
Loss: 0.485 | Acc: 87.191% (5636/6464)
Loss: 0.491 | Acc: 87.228% (11221/12864)
Loss: 0.499 | Acc: 87.048% (16769/19264)
Loss: 0.501 | Acc: 86.978% (22322/25664)
Loss: 0.504 | Acc: 86.976% (27888/32064)
Loss: 0.507 | Acc: 86.918% (33432/38464)
Loss: 0.507 | Acc: 86.854% (38966/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7975, Accuracy: 5139/10000 (51.39%)

Epoch: 170
Loss: 0.848 | Acc: 81.250% (52/64)
Loss: 0.511 | Acc: 87.051% (5627/6464)
Loss: 0.506 | Acc: 87.018% (11194/12864)
Loss: 0.510 | Acc: 86.846% (16730/19264)
Loss: 0.507 | Acc: 86.958% (22317/25664)
Loss: 0.509 | Acc: 86.851% (27848/32064)
Loss: 0.505 | Acc: 86.975% (33454/38464)
Loss: 0.507 | Acc: 86.956% (39012/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0074, Accuracy: 7281/10000 (72.81%)

Epoch: 171
Loss: 0.613 | Acc: 79.688% (51/64)
Loss: 0.469 | Acc: 88.320% (5709/6464)
Loss: 0.469 | Acc: 88.099% (11333/12864)
Loss: 0.479 | Acc: 87.910% (16935/19264)
Loss: 0.478 | Acc: 87.913% (22562/25664)
Loss: 0.478 | Acc: 87.918% (28190/32064)
Loss: 0.479 | Acc: 87.913% (33815/38464)
Loss: 0.482 | Acc: 87.812% (39396/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7795, Accuracy: 7803/10000 (78.03%)

Epoch: 172
Loss: 0.892 | Acc: 81.250% (52/64)
Loss: 0.480 | Acc: 87.732% (5671/6464)
Loss: 0.474 | Acc: 87.951% (11314/12864)
Loss: 0.475 | Acc: 87.848% (16923/19264)
Loss: 0.477 | Acc: 87.761% (22523/25664)
Loss: 0.476 | Acc: 87.843% (28166/32064)
Loss: 0.477 | Acc: 87.791% (33768/38464)
Loss: 0.479 | Acc: 87.774% (39379/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2575, Accuracy: 6529/10000 (65.29%)

Epoch: 173
Loss: 0.554 | Acc: 85.938% (55/64)
Loss: 0.449 | Acc: 88.598% (5727/6464)
Loss: 0.455 | Acc: 88.371% (11368/12864)
Loss: 0.464 | Acc: 88.227% (16996/19264)
Loss: 0.463 | Acc: 88.194% (22634/25664)
Loss: 0.463 | Acc: 88.333% (28323/32064)
Loss: 0.465 | Acc: 88.251% (33945/38464)
Loss: 0.466 | Acc: 88.224% (39581/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4770, Accuracy: 5925/10000 (59.25%)

Epoch: 174
Loss: 0.738 | Acc: 76.562% (49/64)
Loss: 0.458 | Acc: 88.212% (5702/6464)
Loss: 0.459 | Acc: 88.215% (11348/12864)
Loss: 0.453 | Acc: 88.388% (17027/19264)
Loss: 0.461 | Acc: 88.291% (22659/25664)
Loss: 0.461 | Acc: 88.245% (28295/32064)
Loss: 0.460 | Acc: 88.233% (33938/38464)
Loss: 0.463 | Acc: 88.158% (39551/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8224, Accuracy: 7667/10000 (76.67%)

Epoch: 175
Loss: 0.400 | Acc: 90.625% (58/64)
Loss: 0.434 | Acc: 89.032% (5755/6464)
Loss: 0.434 | Acc: 88.993% (11448/12864)
Loss: 0.443 | Acc: 88.902% (17126/19264)
Loss: 0.449 | Acc: 88.712% (22767/25664)
Loss: 0.444 | Acc: 88.766% (28462/32064)
Loss: 0.449 | Acc: 88.683% (34111/38464)
Loss: 0.449 | Acc: 88.679% (39785/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8404, Accuracy: 7678/10000 (76.78%)

Epoch: 176
Loss: 0.565 | Acc: 85.938% (55/64)
Loss: 0.427 | Acc: 89.217% (5767/6464)
Loss: 0.439 | Acc: 88.938% (11441/12864)
Loss: 0.434 | Acc: 89.125% (17169/19264)
Loss: 0.440 | Acc: 88.969% (22833/25664)
Loss: 0.439 | Acc: 88.900% (28505/32064)
Loss: 0.435 | Acc: 89.005% (34235/38464)
Loss: 0.438 | Acc: 88.971% (39916/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6513, Accuracy: 8272/10000 (82.72%)

Epoch: 177
Loss: 0.327 | Acc: 92.188% (59/64)
Loss: 0.423 | Acc: 89.588% (5791/6464)
Loss: 0.423 | Acc: 89.490% (11512/12864)
Loss: 0.415 | Acc: 89.836% (17306/19264)
Loss: 0.420 | Acc: 89.705% (23022/25664)
Loss: 0.423 | Acc: 89.562% (28717/32064)
Loss: 0.427 | Acc: 89.468% (34413/38464)
Loss: 0.426 | Acc: 89.513% (40159/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8889, Accuracy: 7620/10000 (76.20%)

Epoch: 178
Loss: 0.359 | Acc: 89.062% (57/64)
Loss: 0.378 | Acc: 90.702% (5863/6464)
Loss: 0.385 | Acc: 90.446% (11635/12864)
Loss: 0.394 | Acc: 90.272% (17390/19264)
Loss: 0.401 | Acc: 90.118% (23128/25664)
Loss: 0.410 | Acc: 89.873% (28817/32064)
Loss: 0.410 | Acc: 89.894% (34577/38464)
Loss: 0.411 | Acc: 89.918% (40341/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8345, Accuracy: 7648/10000 (76.48%)

Epoch: 179
Loss: 0.549 | Acc: 81.250% (52/64)
Loss: 0.411 | Acc: 90.084% (5823/6464)
Loss: 0.404 | Acc: 90.236% (11608/12864)
Loss: 0.398 | Acc: 90.303% (17396/19264)
Loss: 0.398 | Acc: 90.165% (23140/25664)
Loss: 0.397 | Acc: 90.238% (28934/32064)
Loss: 0.398 | Acc: 90.188% (34690/38464)
Loss: 0.398 | Acc: 90.217% (40475/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6412, Accuracy: 8330/10000 (83.30%)

Epoch: 180
Loss: 0.274 | Acc: 92.188% (59/64)
Loss: 0.390 | Acc: 90.362% (5841/6464)
Loss: 0.390 | Acc: 90.508% (11643/12864)
Loss: 0.388 | Acc: 90.604% (17454/19264)
Loss: 0.382 | Acc: 90.699% (23277/25664)
Loss: 0.384 | Acc: 90.659% (29069/32064)
Loss: 0.385 | Acc: 90.617% (34855/38464)
Loss: 0.386 | Acc: 90.589% (40642/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7682, Accuracy: 8016/10000 (80.16%)

Epoch: 181
Loss: 0.477 | Acc: 85.938% (55/64)
Loss: 0.371 | Acc: 90.424% (5845/6464)
Loss: 0.365 | Acc: 91.021% (11709/12864)
Loss: 0.369 | Acc: 90.999% (17530/19264)
Loss: 0.370 | Acc: 91.003% (23355/25664)
Loss: 0.368 | Acc: 90.984% (29173/32064)
Loss: 0.371 | Acc: 91.015% (35008/38464)
Loss: 0.372 | Acc: 91.020% (40835/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6216, Accuracy: 8434/10000 (84.34%)

Epoch: 182
Loss: 0.365 | Acc: 85.938% (55/64)
Loss: 0.360 | Acc: 91.182% (5894/6464)
Loss: 0.348 | Acc: 91.775% (11806/12864)
Loss: 0.350 | Acc: 91.783% (17681/19264)
Loss: 0.351 | Acc: 91.786% (23556/25664)
Loss: 0.354 | Acc: 91.723% (29410/32064)
Loss: 0.351 | Acc: 91.798% (35309/38464)
Loss: 0.352 | Acc: 91.719% (41149/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5616, Accuracy: 8654/10000 (86.54%)

Epoch: 183
Loss: 0.294 | Acc: 92.188% (59/64)
Loss: 0.319 | Acc: 92.713% (5993/6464)
Loss: 0.333 | Acc: 92.242% (11866/12864)
Loss: 0.337 | Acc: 92.094% (17741/19264)
Loss: 0.339 | Acc: 92.039% (23621/25664)
Loss: 0.340 | Acc: 91.985% (29494/32064)
Loss: 0.341 | Acc: 91.930% (35360/38464)
Loss: 0.340 | Acc: 91.974% (41263/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6102, Accuracy: 8545/10000 (85.45%)

Epoch: 184
Loss: 0.350 | Acc: 90.625% (58/64)
Loss: 0.322 | Acc: 92.311% (5967/6464)
Loss: 0.317 | Acc: 92.545% (11905/12864)
Loss: 0.320 | Acc: 92.509% (17821/19264)
Loss: 0.318 | Acc: 92.636% (23774/25664)
Loss: 0.315 | Acc: 92.674% (29715/32064)
Loss: 0.321 | Acc: 92.479% (35571/38464)
Loss: 0.322 | Acc: 92.517% (41507/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5911, Accuracy: 8595/10000 (85.95%)

Epoch: 185
Loss: 0.250 | Acc: 95.312% (61/64)
Loss: 0.287 | Acc: 93.038% (6014/6464)
Loss: 0.293 | Acc: 93.058% (11971/12864)
Loss: 0.288 | Acc: 93.252% (17964/19264)
Loss: 0.299 | Acc: 93.017% (23872/25664)
Loss: 0.299 | Acc: 93.073% (29843/32064)
Loss: 0.300 | Acc: 93.009% (35775/38464)
Loss: 0.301 | Acc: 92.981% (41715/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7127, Accuracy: 8256/10000 (82.56%)

Epoch: 186
Loss: 0.158 | Acc: 96.875% (62/64)
Loss: 0.283 | Acc: 92.992% (6011/6464)
Loss: 0.276 | Acc: 93.455% (12022/12864)
Loss: 0.273 | Acc: 93.537% (18019/19264)
Loss: 0.280 | Acc: 93.434% (23979/25664)
Loss: 0.283 | Acc: 93.363% (29936/32064)
Loss: 0.284 | Acc: 93.326% (35897/38464)
Loss: 0.282 | Acc: 93.342% (41877/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5757, Accuracy: 8651/10000 (86.51%)

Epoch: 187
Loss: 0.212 | Acc: 96.875% (62/64)
Loss: 0.246 | Acc: 93.967% (6074/6464)
Loss: 0.249 | Acc: 93.952% (12086/12864)
Loss: 0.259 | Acc: 93.776% (18065/19264)
Loss: 0.261 | Acc: 93.910% (24101/25664)
Loss: 0.263 | Acc: 93.887% (30104/32064)
Loss: 0.261 | Acc: 93.961% (36141/38464)
Loss: 0.261 | Acc: 93.951% (42150/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6490, Accuracy: 8528/10000 (85.28%)

Epoch: 188
Loss: 0.377 | Acc: 92.188% (59/64)
Loss: 0.247 | Acc: 94.261% (6093/6464)
Loss: 0.242 | Acc: 94.504% (12157/12864)
Loss: 0.239 | Acc: 94.581% (18220/19264)
Loss: 0.240 | Acc: 94.502% (24253/25664)
Loss: 0.238 | Acc: 94.533% (30311/32064)
Loss: 0.236 | Acc: 94.608% (36390/38464)
Loss: 0.236 | Acc: 94.619% (42450/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5757, Accuracy: 8758/10000 (87.58%)

Epoch: 189
Loss: 0.157 | Acc: 96.875% (62/64)
Loss: 0.199 | Acc: 95.436% (6169/6464)
Loss: 0.207 | Acc: 95.188% (12245/12864)
Loss: 0.215 | Acc: 95.001% (18301/19264)
Loss: 0.217 | Acc: 94.946% (24367/25664)
Loss: 0.218 | Acc: 94.966% (30450/32064)
Loss: 0.221 | Acc: 94.889% (36498/38464)
Loss: 0.220 | Acc: 94.911% (42581/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6207, Accuracy: 8673/10000 (86.73%)

Epoch: 190
Loss: 0.275 | Acc: 90.625% (58/64)
Loss: 0.190 | Acc: 95.328% (6162/6464)
Loss: 0.188 | Acc: 95.577% (12295/12864)
Loss: 0.190 | Acc: 95.494% (18396/19264)
Loss: 0.191 | Acc: 95.488% (24506/25664)
Loss: 0.189 | Acc: 95.574% (30645/32064)
Loss: 0.192 | Acc: 95.513% (36738/38464)
Loss: 0.191 | Acc: 95.520% (42854/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5797, Accuracy: 8808/10000 (88.08%)

Epoch: 191
Loss: 0.236 | Acc: 90.625% (58/64)
Loss: 0.166 | Acc: 96.071% (6210/6464)
Loss: 0.164 | Acc: 96.160% (12370/12864)
Loss: 0.161 | Acc: 96.252% (18542/19264)
Loss: 0.161 | Acc: 96.283% (24710/25664)
Loss: 0.160 | Acc: 96.304% (30879/32064)
Loss: 0.163 | Acc: 96.189% (36998/38464)
Loss: 0.165 | Acc: 96.151% (43137/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5972, Accuracy: 8795/10000 (87.95%)

Epoch: 192
Loss: 0.051 | Acc: 98.438% (63/64)
Loss: 0.145 | Acc: 96.519% (6239/6464)
Loss: 0.138 | Acc: 96.665% (12435/12864)
Loss: 0.139 | Acc: 96.657% (18620/19264)
Loss: 0.141 | Acc: 96.630% (24799/25664)
Loss: 0.142 | Acc: 96.572% (30965/32064)
Loss: 0.143 | Acc: 96.566% (37143/38464)
Loss: 0.145 | Acc: 96.507% (43297/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6071, Accuracy: 8827/10000 (88.27%)

Epoch: 193
Loss: 0.086 | Acc: 98.438% (63/64)
Loss: 0.134 | Acc: 96.674% (6249/6464)
Loss: 0.138 | Acc: 96.564% (12422/12864)
Loss: 0.137 | Acc: 96.584% (18606/19264)
Loss: 0.136 | Acc: 96.649% (24804/25664)
Loss: 0.133 | Acc: 96.744% (31020/32064)
Loss: 0.131 | Acc: 96.823% (37242/38464)
Loss: 0.130 | Acc: 96.819% (43437/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6026, Accuracy: 8834/10000 (88.34%)

Epoch: 194
Loss: 0.122 | Acc: 96.875% (62/64)
Loss: 0.108 | Acc: 97.262% (6287/6464)
Loss: 0.110 | Acc: 97.155% (12498/12864)
Loss: 0.109 | Acc: 97.207% (18726/19264)
Loss: 0.111 | Acc: 97.113% (24923/25664)
Loss: 0.109 | Acc: 97.224% (31174/32064)
Loss: 0.108 | Acc: 97.260% (37410/38464)
Loss: 0.108 | Acc: 97.256% (43633/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6197, Accuracy: 8819/10000 (88.19%)

Epoch: 195
Loss: 0.151 | Acc: 96.875% (62/64)
Loss: 0.088 | Acc: 97.633% (6311/6464)
Loss: 0.096 | Acc: 97.489% (12541/12864)
Loss: 0.099 | Acc: 97.368% (18757/19264)
Loss: 0.096 | Acc: 97.487% (25019/25664)
Loss: 0.094 | Acc: 97.577% (31287/32064)
Loss: 0.096 | Acc: 97.541% (37518/38464)
Loss: 0.096 | Acc: 97.526% (43754/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6271, Accuracy: 8828/10000 (88.28%)

Epoch: 196
Loss: 0.117 | Acc: 96.875% (62/64)
Loss: 0.081 | Acc: 97.958% (6332/6464)
Loss: 0.082 | Acc: 97.839% (12586/12864)
Loss: 0.086 | Acc: 97.737% (18828/19264)
Loss: 0.086 | Acc: 97.740% (25084/25664)
Loss: 0.084 | Acc: 97.801% (31359/32064)
Loss: 0.086 | Acc: 97.798% (37617/38464)
Loss: 0.084 | Acc: 97.813% (43883/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6299, Accuracy: 8829/10000 (88.29%)

Epoch: 197
Loss: 0.026 | Acc: 100.000% (64/64)
Loss: 0.079 | Acc: 97.958% (6332/6464)
Loss: 0.082 | Acc: 97.870% (12590/12864)
Loss: 0.081 | Acc: 97.960% (18871/19264)
Loss: 0.079 | Acc: 97.997% (25150/25664)
Loss: 0.080 | Acc: 97.967% (31412/32064)
Loss: 0.079 | Acc: 97.972% (37684/38464)
Loss: 0.078 | Acc: 97.972% (43954/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6284, Accuracy: 8826/10000 (88.26%)
torch.Size([100, 10])
Test set: Average loss: 0.6284, Accuracy: 8826/10000 (88.26%)

Epoch: 198
Loss: 0.013 | Acc: 100.000% (64/64)
Loss: 0.080 | Acc: 97.958% (6332/6464)
Loss: 0.079 | Acc: 97.917% (12596/12864)
Loss: 0.074 | Acc: 98.069% (18892/19264)
Loss: 0.074 | Acc: 98.036% (25160/25664)
Loss: 0.074 | Acc: 98.026% (31431/32064)
Loss: 0.075 | Acc: 98.006% (37697/38464)
Loss: 0.074 | Acc: 98.041% (43985/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6322, Accuracy: 8825/10000 (88.25%)
torch.Size([100, 10])
Test set: Average loss: 0.6322, Accuracy: 8825/10000 (88.25%)

Epoch: 199
Loss: 0.023 | Acc: 100.000% (64/64)
Loss: 0.077 | Acc: 97.973% (6333/6464)
Loss: 0.076 | Acc: 97.994% (12606/12864)
Loss: 0.076 | Acc: 97.970% (18873/19264)
Loss: 0.073 | Acc: 98.083% (25172/25664)
Loss: 0.075 | Acc: 98.038% (31435/32064)
Loss: 0.073 | Acc: 98.097% (37732/38464)
Loss: 0.074 | Acc: 98.088% (44006/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6363, Accuracy: 8831/10000 (88.31%)
torch.Size([100, 10])
Test set: Average loss: 0.6363, Accuracy: 8831/10000 (88.31%)
9043
10000
-0.4991067945957184
