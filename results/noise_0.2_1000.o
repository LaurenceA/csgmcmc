==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.403 | Acc: 12.500% (8/64)
Loss: 2.860 | Acc: 13.908% (899/6464)
Loss: 2.520 | Acc: 16.216% (2086/12864)
Loss: 2.392 | Acc: 17.629% (3396/19264)
Loss: 2.313 | Acc: 19.093% (4900/25664)
Loss: 2.263 | Acc: 20.188% (6473/32064)
Loss: 2.227 | Acc: 21.150% (8135/38464)
Loss: 2.193 | Acc: 22.203% (9961/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2427, Accuracy: 2341/10000 (23.41%)

Epoch: 1
Loss: 2.303 | Acc: 21.875% (14/64)
Loss: 1.936 | Acc: 31.018% (2005/6464)
Loss: 1.937 | Acc: 31.444% (4045/12864)
Loss: 1.928 | Acc: 31.992% (6163/19264)
Loss: 1.919 | Acc: 32.649% (8379/25664)
Loss: 1.911 | Acc: 33.196% (10644/32064)
Loss: 1.901 | Acc: 33.696% (12961/38464)
Loss: 1.892 | Acc: 34.257% (15369/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0514, Accuracy: 3059/10000 (30.59%)

Epoch: 2
Loss: 1.678 | Acc: 46.875% (30/64)
Loss: 1.820 | Acc: 37.980% (2455/6464)
Loss: 1.812 | Acc: 38.106% (4902/12864)
Loss: 1.800 | Acc: 38.907% (7495/19264)
Loss: 1.792 | Acc: 39.250% (10073/25664)
Loss: 1.783 | Acc: 39.705% (12731/32064)
Loss: 1.781 | Acc: 40.087% (15419/38464)
Loss: 1.778 | Acc: 40.195% (18033/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7570, Accuracy: 4154/10000 (41.54%)

Epoch: 3
Loss: 2.098 | Acc: 25.000% (16/64)
Loss: 1.721 | Acc: 42.528% (2749/6464)
Loss: 1.736 | Acc: 42.413% (5456/12864)
Loss: 1.717 | Acc: 43.210% (8324/19264)
Loss: 1.711 | Acc: 43.695% (11214/25664)
Loss: 1.706 | Acc: 44.024% (14116/32064)
Loss: 1.696 | Acc: 44.501% (17117/38464)
Loss: 1.687 | Acc: 44.893% (20141/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8902, Accuracy: 3806/10000 (38.06%)

Epoch: 4
Loss: 1.763 | Acc: 45.312% (29/64)
Loss: 1.615 | Acc: 48.577% (3140/6464)
Loss: 1.611 | Acc: 48.640% (6257/12864)
Loss: 1.606 | Acc: 48.816% (9404/19264)
Loss: 1.598 | Acc: 49.069% (12593/25664)
Loss: 1.596 | Acc: 49.286% (15803/32064)
Loss: 1.588 | Acc: 49.683% (19110/38464)
Loss: 1.582 | Acc: 50.018% (22440/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6544, Accuracy: 4854/10000 (48.54%)

Epoch: 5
Loss: 1.839 | Acc: 46.875% (30/64)
Loss: 1.518 | Acc: 52.754% (3410/6464)
Loss: 1.533 | Acc: 52.161% (6710/12864)
Loss: 1.525 | Acc: 52.860% (10183/19264)
Loss: 1.521 | Acc: 53.078% (13622/25664)
Loss: 1.511 | Acc: 53.530% (17164/32064)
Loss: 1.512 | Acc: 53.458% (20562/38464)
Loss: 1.508 | Acc: 53.582% (24039/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0565, Accuracy: 3580/10000 (35.80%)

Epoch: 6
Loss: 1.471 | Acc: 60.938% (39/64)
Loss: 1.478 | Acc: 55.244% (3571/6464)
Loss: 1.477 | Acc: 55.162% (7096/12864)
Loss: 1.472 | Acc: 55.471% (10686/19264)
Loss: 1.462 | Acc: 55.755% (14309/25664)
Loss: 1.458 | Acc: 55.935% (17935/32064)
Loss: 1.456 | Acc: 56.089% (21574/38464)
Loss: 1.454 | Acc: 56.221% (25223/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8942, Accuracy: 3915/10000 (39.15%)

Epoch: 7
Loss: 1.624 | Acc: 46.875% (30/64)
Loss: 1.434 | Acc: 57.488% (3716/6464)
Loss: 1.421 | Acc: 57.680% (7420/12864)
Loss: 1.420 | Acc: 57.724% (11120/19264)
Loss: 1.415 | Acc: 58.097% (14910/25664)
Loss: 1.410 | Acc: 58.452% (18742/32064)
Loss: 1.409 | Acc: 58.546% (22519/38464)
Loss: 1.402 | Acc: 58.758% (26361/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4893, Accuracy: 5607/10000 (56.07%)

Epoch: 8
Loss: 1.394 | Acc: 53.125% (34/64)
Loss: 1.384 | Acc: 59.050% (3817/6464)
Loss: 1.372 | Acc: 59.810% (7694/12864)
Loss: 1.366 | Acc: 60.128% (11583/19264)
Loss: 1.367 | Acc: 60.185% (15446/25664)
Loss: 1.360 | Acc: 60.410% (19370/32064)
Loss: 1.360 | Acc: 60.454% (23253/38464)
Loss: 1.355 | Acc: 60.657% (27213/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6347, Accuracy: 5202/10000 (52.02%)

Epoch: 9
Loss: 1.579 | Acc: 48.438% (31/64)
Loss: 1.309 | Acc: 62.701% (4053/6464)
Loss: 1.325 | Acc: 62.306% (8015/12864)
Loss: 1.334 | Acc: 61.867% (11918/19264)
Loss: 1.331 | Acc: 61.826% (15867/25664)
Loss: 1.329 | Acc: 61.951% (19864/32064)
Loss: 1.328 | Acc: 62.071% (23875/38464)
Loss: 1.323 | Acc: 62.344% (27970/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5349, Accuracy: 5314/10000 (53.14%)

Epoch: 10
Loss: 1.042 | Acc: 71.875% (46/64)
Loss: 1.288 | Acc: 63.614% (4112/6464)
Loss: 1.293 | Acc: 63.378% (8153/12864)
Loss: 1.295 | Acc: 63.377% (12209/19264)
Loss: 1.289 | Acc: 63.443% (16282/25664)
Loss: 1.292 | Acc: 63.535% (20372/32064)
Loss: 1.296 | Acc: 63.392% (24383/38464)
Loss: 1.294 | Acc: 63.458% (28470/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7090, Accuracy: 4891/10000 (48.91%)

Epoch: 11
Loss: 1.282 | Acc: 64.062% (41/64)
Loss: 1.275 | Acc: 63.892% (4130/6464)
Loss: 1.284 | Acc: 63.930% (8224/12864)
Loss: 1.276 | Acc: 64.270% (12381/19264)
Loss: 1.283 | Acc: 64.039% (16435/25664)
Loss: 1.281 | Acc: 64.128% (20562/32064)
Loss: 1.275 | Acc: 64.320% (24740/38464)
Loss: 1.275 | Acc: 64.250% (28825/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4957, Accuracy: 5614/10000 (56.14%)

Epoch: 12
Loss: 1.368 | Acc: 56.250% (36/64)
Loss: 1.250 | Acc: 65.300% (4221/6464)
Loss: 1.255 | Acc: 65.299% (8400/12864)
Loss: 1.258 | Acc: 65.262% (12572/19264)
Loss: 1.258 | Acc: 65.196% (16732/25664)
Loss: 1.261 | Acc: 65.070% (20864/32064)
Loss: 1.258 | Acc: 65.245% (25096/38464)
Loss: 1.259 | Acc: 65.284% (29289/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5393, Accuracy: 5412/10000 (54.12%)

Epoch: 13
Loss: 1.447 | Acc: 59.375% (38/64)
Loss: 1.224 | Acc: 66.491% (4298/6464)
Loss: 1.233 | Acc: 65.967% (8486/12864)
Loss: 1.231 | Acc: 66.113% (12736/19264)
Loss: 1.237 | Acc: 66.135% (16973/25664)
Loss: 1.234 | Acc: 66.286% (21254/32064)
Loss: 1.236 | Acc: 66.231% (25475/38464)
Loss: 1.237 | Acc: 66.176% (29689/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4789, Accuracy: 5799/10000 (57.99%)

Epoch: 14
Loss: 1.288 | Acc: 59.375% (38/64)
Loss: 1.238 | Acc: 65.486% (4233/6464)
Loss: 1.226 | Acc: 65.913% (8479/12864)
Loss: 1.228 | Acc: 65.957% (12706/19264)
Loss: 1.228 | Acc: 66.202% (16990/25664)
Loss: 1.224 | Acc: 66.451% (21307/32064)
Loss: 1.222 | Acc: 66.535% (25592/38464)
Loss: 1.225 | Acc: 66.470% (29821/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0093, Accuracy: 4057/10000 (40.57%)

Epoch: 15
Loss: 1.464 | Acc: 56.250% (36/64)
Loss: 1.210 | Acc: 66.816% (4319/6464)
Loss: 1.208 | Acc: 67.156% (8639/12864)
Loss: 1.210 | Acc: 67.099% (12926/19264)
Loss: 1.209 | Acc: 67.223% (17252/25664)
Loss: 1.203 | Acc: 67.434% (21622/32064)
Loss: 1.208 | Acc: 67.258% (25870/38464)
Loss: 1.207 | Acc: 67.223% (30159/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4654, Accuracy: 5777/10000 (57.77%)

Epoch: 16
Loss: 1.384 | Acc: 60.938% (39/64)
Loss: 1.180 | Acc: 68.425% (4423/6464)
Loss: 1.176 | Acc: 68.354% (8793/12864)
Loss: 1.185 | Acc: 68.163% (13131/19264)
Loss: 1.195 | Acc: 67.799% (17400/25664)
Loss: 1.192 | Acc: 67.948% (21787/32064)
Loss: 1.196 | Acc: 67.949% (26136/38464)
Loss: 1.189 | Acc: 68.057% (30533/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4389, Accuracy: 5847/10000 (58.47%)

Epoch: 17
Loss: 1.128 | Acc: 67.188% (43/64)
Loss: 1.172 | Acc: 69.291% (4479/6464)
Loss: 1.187 | Acc: 68.486% (8810/12864)
Loss: 1.187 | Acc: 68.423% (13181/19264)
Loss: 1.182 | Acc: 68.528% (17587/25664)
Loss: 1.182 | Acc: 68.591% (21993/32064)
Loss: 1.181 | Acc: 68.537% (26362/38464)
Loss: 1.181 | Acc: 68.456% (30712/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3985, Accuracy: 6046/10000 (60.46%)

Epoch: 18
Loss: 1.124 | Acc: 70.312% (45/64)
Loss: 1.126 | Acc: 70.019% (4526/6464)
Loss: 1.141 | Acc: 69.597% (8953/12864)
Loss: 1.158 | Acc: 69.233% (13337/19264)
Loss: 1.163 | Acc: 69.112% (17737/25664)
Loss: 1.162 | Acc: 69.121% (22163/32064)
Loss: 1.167 | Acc: 68.937% (26516/38464)
Loss: 1.167 | Acc: 68.937% (30928/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4810, Accuracy: 5848/10000 (58.48%)

Epoch: 19
Loss: 1.746 | Acc: 53.125% (34/64)
Loss: 1.153 | Acc: 69.353% (4483/6464)
Loss: 1.157 | Acc: 69.356% (8922/12864)
Loss: 1.147 | Acc: 69.643% (13416/19264)
Loss: 1.143 | Acc: 69.763% (17904/25664)
Loss: 1.150 | Acc: 69.523% (22292/32064)
Loss: 1.152 | Acc: 69.514% (26738/38464)
Loss: 1.152 | Acc: 69.479% (31171/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3737, Accuracy: 6130/10000 (61.30%)

Epoch: 20
Loss: 1.086 | Acc: 73.438% (47/64)
Loss: 1.127 | Acc: 70.900% (4583/6464)
Loss: 1.135 | Acc: 70.390% (9055/12864)
Loss: 1.136 | Acc: 70.229% (13529/19264)
Loss: 1.137 | Acc: 70.200% (18016/25664)
Loss: 1.142 | Acc: 70.100% (22477/32064)
Loss: 1.143 | Acc: 70.097% (26962/38464)
Loss: 1.142 | Acc: 70.090% (31445/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6665, Accuracy: 5100/10000 (51.00%)

Epoch: 21
Loss: 0.929 | Acc: 76.562% (49/64)
Loss: 1.126 | Acc: 70.158% (4535/6464)
Loss: 1.124 | Acc: 70.367% (9052/12864)
Loss: 1.122 | Acc: 70.416% (13565/19264)
Loss: 1.130 | Acc: 70.227% (18023/25664)
Loss: 1.128 | Acc: 70.319% (22547/32064)
Loss: 1.132 | Acc: 70.198% (27001/38464)
Loss: 1.131 | Acc: 70.281% (31531/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4579, Accuracy: 5797/10000 (57.97%)

Epoch: 22
Loss: 1.042 | Acc: 78.125% (50/64)
Loss: 1.113 | Acc: 71.442% (4618/6464)
Loss: 1.125 | Acc: 70.779% (9105/12864)
Loss: 1.120 | Acc: 70.925% (13663/19264)
Loss: 1.124 | Acc: 70.722% (18150/25664)
Loss: 1.117 | Acc: 70.936% (22745/32064)
Loss: 1.118 | Acc: 70.869% (27259/38464)
Loss: 1.116 | Acc: 70.921% (31818/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6400, Accuracy: 5116/10000 (51.16%)

Epoch: 23
Loss: 1.138 | Acc: 67.188% (43/64)
Loss: 1.086 | Acc: 71.627% (4630/6464)
Loss: 1.098 | Acc: 71.541% (9203/12864)
Loss: 1.105 | Acc: 71.434% (13761/19264)
Loss: 1.108 | Acc: 71.287% (18295/25664)
Loss: 1.108 | Acc: 71.282% (22856/32064)
Loss: 1.104 | Acc: 71.368% (27451/38464)
Loss: 1.104 | Acc: 71.362% (32016/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4295, Accuracy: 5950/10000 (59.50%)

Epoch: 24
Loss: 1.196 | Acc: 71.875% (46/64)
Loss: 1.103 | Acc: 71.581% (4627/6464)
Loss: 1.112 | Acc: 71.253% (9166/12864)
Loss: 1.101 | Acc: 71.719% (13816/19264)
Loss: 1.108 | Acc: 71.571% (18368/25664)
Loss: 1.103 | Acc: 71.597% (22957/32064)
Loss: 1.101 | Acc: 71.675% (27569/38464)
Loss: 1.100 | Acc: 71.665% (32152/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3729, Accuracy: 6256/10000 (62.56%)

Epoch: 25
Loss: 1.248 | Acc: 65.625% (42/64)
Loss: 1.070 | Acc: 72.478% (4685/6464)
Loss: 1.079 | Acc: 72.326% (9304/12864)
Loss: 1.079 | Acc: 72.337% (13935/19264)
Loss: 1.076 | Acc: 72.549% (18619/25664)
Loss: 1.082 | Acc: 72.368% (23204/32064)
Loss: 1.087 | Acc: 72.192% (27768/38464)
Loss: 1.086 | Acc: 72.180% (32383/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4127, Accuracy: 6001/10000 (60.01%)

Epoch: 26
Loss: 1.031 | Acc: 75.000% (48/64)
Loss: 1.085 | Acc: 71.674% (4633/6464)
Loss: 1.082 | Acc: 72.023% (9265/12864)
Loss: 1.075 | Acc: 72.399% (13947/19264)
Loss: 1.081 | Acc: 72.269% (18547/25664)
Loss: 1.082 | Acc: 72.237% (23162/32064)
Loss: 1.075 | Acc: 72.395% (27846/38464)
Loss: 1.071 | Acc: 72.546% (32547/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4669, Accuracy: 5822/10000 (58.22%)

Epoch: 27
Loss: 1.360 | Acc: 64.062% (41/64)
Loss: 1.091 | Acc: 71.875% (4646/6464)
Loss: 1.060 | Acc: 73.057% (9398/12864)
Loss: 1.064 | Acc: 72.763% (14017/19264)
Loss: 1.062 | Acc: 72.904% (18710/25664)
Loss: 1.060 | Acc: 73.013% (23411/32064)
Loss: 1.055 | Acc: 73.131% (28129/38464)
Loss: 1.057 | Acc: 73.061% (32778/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7379, Accuracy: 5333/10000 (53.33%)

Epoch: 28
Loss: 1.272 | Acc: 64.062% (41/64)
Loss: 1.047 | Acc: 73.128% (4727/6464)
Loss: 1.057 | Acc: 73.142% (9409/12864)
Loss: 1.042 | Acc: 73.728% (14203/19264)
Loss: 1.046 | Acc: 73.519% (18868/25664)
Loss: 1.042 | Acc: 73.668% (23621/32064)
Loss: 1.046 | Acc: 73.573% (28299/38464)
Loss: 1.047 | Acc: 73.516% (32982/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6348, Accuracy: 5213/10000 (52.13%)

Epoch: 29
Loss: 1.040 | Acc: 71.875% (46/64)
Loss: 1.016 | Acc: 74.196% (4796/6464)
Loss: 1.027 | Acc: 74.059% (9527/12864)
Loss: 1.018 | Acc: 74.336% (14320/19264)
Loss: 1.025 | Acc: 74.217% (19047/25664)
Loss: 1.027 | Acc: 74.195% (23790/32064)
Loss: 1.029 | Acc: 74.181% (28533/38464)
Loss: 1.025 | Acc: 74.229% (33302/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3957, Accuracy: 6158/10000 (61.58%)

Epoch: 30
Loss: 1.451 | Acc: 59.375% (38/64)
Loss: 0.995 | Acc: 75.340% (4870/6464)
Loss: 1.007 | Acc: 74.907% (9636/12864)
Loss: 1.005 | Acc: 74.824% (14414/19264)
Loss: 1.003 | Acc: 74.895% (19221/25664)
Loss: 1.013 | Acc: 74.660% (23939/32064)
Loss: 1.015 | Acc: 74.670% (28721/38464)
Loss: 1.016 | Acc: 74.663% (33497/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2088, Accuracy: 6861/10000 (68.61%)

Epoch: 31
Loss: 0.614 | Acc: 85.938% (55/64)
Loss: 0.981 | Acc: 75.727% (4895/6464)
Loss: 0.998 | Acc: 75.140% (9666/12864)
Loss: 0.997 | Acc: 75.244% (14495/19264)
Loss: 0.996 | Acc: 75.226% (19306/25664)
Loss: 1.000 | Acc: 75.181% (24106/32064)
Loss: 0.997 | Acc: 75.234% (28938/38464)
Loss: 1.001 | Acc: 75.109% (33697/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1926, Accuracy: 6972/10000 (69.72%)

Epoch: 32
Loss: 0.943 | Acc: 71.875% (46/64)
Loss: 0.980 | Acc: 75.155% (4858/6464)
Loss: 0.983 | Acc: 75.303% (9687/12864)
Loss: 0.986 | Acc: 75.327% (14511/19264)
Loss: 0.983 | Acc: 75.499% (19376/25664)
Loss: 0.983 | Acc: 75.558% (24227/32064)
Loss: 0.984 | Acc: 75.543% (29057/38464)
Loss: 0.982 | Acc: 75.640% (33935/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3292, Accuracy: 6480/10000 (64.80%)

Epoch: 33
Loss: 1.082 | Acc: 76.562% (49/64)
Loss: 0.931 | Acc: 76.671% (4956/6464)
Loss: 0.947 | Acc: 76.508% (9842/12864)
Loss: 0.942 | Acc: 76.640% (14764/19264)
Loss: 0.951 | Acc: 76.372% (19600/25664)
Loss: 0.952 | Acc: 76.382% (24491/32064)
Loss: 0.958 | Acc: 76.206% (29312/38464)
Loss: 0.962 | Acc: 76.155% (34166/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3897, Accuracy: 6213/10000 (62.13%)

Epoch: 34
Loss: 1.053 | Acc: 71.875% (46/64)
Loss: 0.922 | Acc: 77.429% (5005/6464)
Loss: 0.922 | Acc: 77.550% (9976/12864)
Loss: 0.925 | Acc: 77.243% (14880/19264)
Loss: 0.931 | Acc: 76.956% (19750/25664)
Loss: 0.935 | Acc: 76.877% (24650/32064)
Loss: 0.939 | Acc: 76.796% (29539/38464)
Loss: 0.943 | Acc: 76.745% (34431/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1959, Accuracy: 6973/10000 (69.73%)

Epoch: 35
Loss: 0.919 | Acc: 79.688% (51/64)
Loss: 0.872 | Acc: 78.357% (5065/6464)
Loss: 0.897 | Acc: 77.900% (10021/12864)
Loss: 0.901 | Acc: 77.741% (14976/19264)
Loss: 0.905 | Acc: 77.525% (19896/25664)
Loss: 0.909 | Acc: 77.542% (24863/32064)
Loss: 0.913 | Acc: 77.519% (29817/38464)
Loss: 0.916 | Acc: 77.432% (34739/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2119, Accuracy: 6993/10000 (69.93%)

Epoch: 36
Loss: 1.003 | Acc: 70.312% (45/64)
Loss: 0.891 | Acc: 78.032% (5044/6464)
Loss: 0.894 | Acc: 77.938% (10026/12864)
Loss: 0.892 | Acc: 78.120% (15049/19264)
Loss: 0.894 | Acc: 77.985% (20014/25664)
Loss: 0.899 | Acc: 77.738% (24926/32064)
Loss: 0.898 | Acc: 77.834% (29938/38464)
Loss: 0.899 | Acc: 77.824% (34915/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1960, Accuracy: 7066/10000 (70.66%)

Epoch: 37
Loss: 0.774 | Acc: 78.125% (50/64)
Loss: 0.865 | Acc: 78.759% (5091/6464)
Loss: 0.863 | Acc: 78.809% (10138/12864)
Loss: 0.859 | Acc: 78.924% (15204/19264)
Loss: 0.855 | Acc: 79.025% (20281/25664)
Loss: 0.859 | Acc: 78.920% (25305/32064)
Loss: 0.864 | Acc: 78.770% (30298/38464)
Loss: 0.868 | Acc: 78.673% (35296/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2545, Accuracy: 6860/10000 (68.60%)

Epoch: 38
Loss: 0.955 | Acc: 76.562% (49/64)
Loss: 0.833 | Acc: 78.929% (5102/6464)
Loss: 0.823 | Acc: 79.462% (10222/12864)
Loss: 0.827 | Acc: 79.319% (15280/19264)
Loss: 0.838 | Acc: 79.103% (20301/25664)
Loss: 0.841 | Acc: 79.089% (25359/32064)
Loss: 0.840 | Acc: 79.134% (30438/38464)
Loss: 0.840 | Acc: 79.124% (35498/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2517, Accuracy: 6928/10000 (69.28%)

Epoch: 39
Loss: 0.926 | Acc: 76.562% (49/64)
Loss: 0.781 | Acc: 80.817% (5224/6464)
Loss: 0.785 | Acc: 80.768% (10390/12864)
Loss: 0.791 | Acc: 80.580% (15523/19264)
Loss: 0.794 | Acc: 80.478% (20654/25664)
Loss: 0.801 | Acc: 80.305% (25749/32064)
Loss: 0.802 | Acc: 80.213% (30853/38464)
Loss: 0.811 | Acc: 80.004% (35893/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2176, Accuracy: 7057/10000 (70.57%)

Epoch: 40
Loss: 0.529 | Acc: 90.625% (58/64)
Loss: 0.762 | Acc: 80.662% (5214/6464)
Loss: 0.756 | Acc: 81.048% (10426/12864)
Loss: 0.765 | Acc: 80.913% (15587/19264)
Loss: 0.770 | Acc: 80.814% (20740/25664)
Loss: 0.772 | Acc: 80.801% (25908/32064)
Loss: 0.773 | Acc: 80.759% (31063/38464)
Loss: 0.772 | Acc: 80.789% (36245/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2237, Accuracy: 7157/10000 (71.57%)

Epoch: 41
Loss: 0.873 | Acc: 76.562% (49/64)
Loss: 0.723 | Acc: 81.962% (5298/6464)
Loss: 0.728 | Acc: 81.670% (10506/12864)
Loss: 0.722 | Acc: 81.707% (15740/19264)
Loss: 0.729 | Acc: 81.550% (20929/25664)
Loss: 0.730 | Acc: 81.459% (26119/32064)
Loss: 0.733 | Acc: 81.351% (31291/38464)
Loss: 0.736 | Acc: 81.297% (36473/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2655, Accuracy: 7108/10000 (71.08%)

Epoch: 42
Loss: 0.595 | Acc: 85.938% (55/64)
Loss: 0.682 | Acc: 82.534% (5335/6464)
Loss: 0.680 | Acc: 82.572% (10622/12864)
Loss: 0.685 | Acc: 82.574% (15907/19264)
Loss: 0.687 | Acc: 82.462% (21163/25664)
Loss: 0.688 | Acc: 82.342% (26402/32064)
Loss: 0.687 | Acc: 82.326% (31666/38464)
Loss: 0.683 | Acc: 82.514% (37019/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2955, Accuracy: 7076/10000 (70.76%)

Epoch: 43
Loss: 0.568 | Acc: 82.812% (53/64)
Loss: 0.624 | Acc: 83.942% (5426/6464)
Loss: 0.631 | Acc: 83.668% (10763/12864)
Loss: 0.635 | Acc: 83.565% (16098/19264)
Loss: 0.632 | Acc: 83.685% (21477/25664)
Loss: 0.630 | Acc: 83.701% (26838/32064)
Loss: 0.632 | Acc: 83.624% (32165/38464)
Loss: 0.634 | Acc: 83.688% (37546/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3302, Accuracy: 7062/10000 (70.62%)

Epoch: 44
Loss: 0.426 | Acc: 85.938% (55/64)
Loss: 0.587 | Acc: 84.390% (5455/6464)
Loss: 0.591 | Acc: 84.383% (10855/12864)
Loss: 0.584 | Acc: 84.536% (16285/19264)
Loss: 0.584 | Acc: 84.585% (21708/25664)
Loss: 0.587 | Acc: 84.384% (27057/32064)
Loss: 0.585 | Acc: 84.489% (32498/38464)
Loss: 0.585 | Acc: 84.480% (37901/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3716, Accuracy: 7059/10000 (70.59%)

Epoch: 45
Loss: 0.430 | Acc: 87.500% (56/64)
Loss: 0.532 | Acc: 85.520% (5528/6464)
Loss: 0.536 | Acc: 85.619% (11014/12864)
Loss: 0.536 | Acc: 85.610% (16492/19264)
Loss: 0.540 | Acc: 85.482% (21938/25664)
Loss: 0.538 | Acc: 85.560% (27434/32064)
Loss: 0.535 | Acc: 85.641% (32941/38464)
Loss: 0.531 | Acc: 85.781% (38485/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3904, Accuracy: 7012/10000 (70.12%)

Epoch: 46
Loss: 0.298 | Acc: 87.500% (56/64)
Loss: 0.476 | Acc: 86.959% (5621/6464)
Loss: 0.476 | Acc: 87.228% (11221/12864)
Loss: 0.477 | Acc: 87.105% (16780/19264)
Loss: 0.477 | Acc: 87.064% (22344/25664)
Loss: 0.477 | Acc: 87.123% (27935/32064)
Loss: 0.478 | Acc: 87.068% (33490/38464)
Loss: 0.478 | Acc: 87.045% (39052/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4210, Accuracy: 6992/10000 (69.92%)

Epoch: 47
Loss: 0.219 | Acc: 96.875% (62/64)
Loss: 0.467 | Acc: 87.268% (5641/6464)
Loss: 0.458 | Acc: 87.469% (11252/12864)
Loss: 0.458 | Acc: 87.417% (16840/19264)
Loss: 0.452 | Acc: 87.636% (22491/25664)
Loss: 0.451 | Acc: 87.612% (28092/32064)
Loss: 0.449 | Acc: 87.705% (33735/38464)
Loss: 0.449 | Acc: 87.723% (39356/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4364, Accuracy: 7014/10000 (70.14%)
torch.Size([100, 10])
Test set: Average loss: 1.4364, Accuracy: 7014/10000 (70.14%)

Epoch: 48
Loss: 0.555 | Acc: 87.500% (56/64)
Loss: 0.413 | Acc: 88.784% (5739/6464)
Loss: 0.414 | Acc: 88.588% (11396/12864)
Loss: 0.424 | Acc: 88.279% (17006/19264)
Loss: 0.424 | Acc: 88.334% (22670/25664)
Loss: 0.423 | Acc: 88.408% (28347/32064)
Loss: 0.424 | Acc: 88.384% (33996/38464)
Loss: 0.424 | Acc: 88.374% (39648/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4446, Accuracy: 7013/10000 (70.13%)
torch.Size([100, 10])
Test set: Average loss: 1.4446, Accuracy: 7013/10000 (70.13%)

Epoch: 49
Loss: 0.414 | Acc: 87.500% (56/64)
Loss: 0.417 | Acc: 88.459% (5718/6464)
Loss: 0.424 | Acc: 88.238% (11351/12864)
Loss: 0.422 | Acc: 88.336% (17017/19264)
Loss: 0.417 | Acc: 88.420% (22692/25664)
Loss: 0.416 | Acc: 88.436% (28356/32064)
Loss: 0.413 | Acc: 88.582% (34072/38464)
Loss: 0.413 | Acc: 88.586% (39743/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4532, Accuracy: 7018/10000 (70.18%)
torch.Size([100, 10])
Test set: Average loss: 1.4532, Accuracy: 7018/10000 (70.18%)

Epoch: 50
Loss: 0.315 | Acc: 93.750% (60/64)
Loss: 1.529 | Acc: 53.806% (3478/6464)
Loss: 1.415 | Acc: 58.800% (7564/12864)
Loss: 1.363 | Acc: 60.906% (11733/19264)
Loss: 1.337 | Acc: 62.169% (15955/25664)
Loss: 1.316 | Acc: 63.015% (20205/32064)
Loss: 1.300 | Acc: 63.634% (24476/38464)
Loss: 1.290 | Acc: 64.027% (28725/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5257, Accuracy: 5739/10000 (57.39%)

Epoch: 51
Loss: 1.177 | Acc: 71.875% (46/64)
Loss: 1.193 | Acc: 67.373% (4355/6464)
Loss: 1.186 | Acc: 68.012% (8749/12864)
Loss: 1.193 | Acc: 67.701% (13042/19264)
Loss: 1.191 | Acc: 67.885% (17422/25664)
Loss: 1.189 | Acc: 67.942% (21785/32064)
Loss: 1.186 | Acc: 68.105% (26196/38464)
Loss: 1.185 | Acc: 68.184% (30590/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4941, Accuracy: 5877/10000 (58.77%)

Epoch: 52
Loss: 1.153 | Acc: 68.750% (44/64)
Loss: 1.155 | Acc: 69.771% (4510/6464)
Loss: 1.159 | Acc: 69.450% (8934/12864)
Loss: 1.153 | Acc: 69.570% (13402/19264)
Loss: 1.157 | Acc: 69.311% (17788/25664)
Loss: 1.160 | Acc: 69.184% (22183/32064)
Loss: 1.159 | Acc: 69.163% (26603/38464)
Loss: 1.163 | Acc: 69.156% (31026/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4547, Accuracy: 6055/10000 (60.55%)

Epoch: 53
Loss: 1.361 | Acc: 62.500% (40/64)
Loss: 1.141 | Acc: 70.251% (4541/6464)
Loss: 1.144 | Acc: 70.211% (9032/12864)
Loss: 1.147 | Acc: 70.006% (13486/19264)
Loss: 1.152 | Acc: 69.732% (17896/25664)
Loss: 1.154 | Acc: 69.751% (22365/32064)
Loss: 1.149 | Acc: 69.829% (26859/38464)
Loss: 1.152 | Acc: 69.753% (31294/44864)
torch.Size([100, 10])
Test set: Average loss: 3.5805, Accuracy: 2120/10000 (21.20%)

Epoch: 54
Loss: 1.315 | Acc: 54.688% (35/64)
Loss: 1.155 | Acc: 68.920% (4455/6464)
Loss: 1.157 | Acc: 69.209% (8903/12864)
Loss: 1.153 | Acc: 69.466% (13382/19264)
Loss: 1.147 | Acc: 69.736% (17897/25664)
Loss: 1.150 | Acc: 69.611% (22320/32064)
Loss: 1.151 | Acc: 69.561% (26756/38464)
Loss: 1.151 | Acc: 69.575% (31214/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5111, Accuracy: 5567/10000 (55.67%)

Epoch: 55
Loss: 1.415 | Acc: 59.375% (38/64)
Loss: 1.139 | Acc: 69.864% (4516/6464)
Loss: 1.145 | Acc: 70.079% (9015/12864)
Loss: 1.148 | Acc: 69.996% (13484/19264)
Loss: 1.149 | Acc: 69.888% (17936/25664)
Loss: 1.147 | Acc: 69.944% (22427/32064)
Loss: 1.145 | Acc: 69.998% (26924/38464)
Loss: 1.146 | Acc: 69.960% (31387/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3922, Accuracy: 6088/10000 (60.88%)

Epoch: 56
Loss: 1.342 | Acc: 65.625% (42/64)
Loss: 1.141 | Acc: 70.189% (4537/6464)
Loss: 1.142 | Acc: 70.266% (9039/12864)
Loss: 1.137 | Acc: 70.318% (13546/19264)
Loss: 1.137 | Acc: 70.375% (18061/25664)
Loss: 1.143 | Acc: 70.175% (22501/32064)
Loss: 1.143 | Acc: 70.092% (26960/38464)
Loss: 1.142 | Acc: 70.112% (31455/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4115, Accuracy: 6033/10000 (60.33%)

Epoch: 57
Loss: 1.474 | Acc: 62.500% (40/64)
Loss: 1.132 | Acc: 70.096% (4531/6464)
Loss: 1.136 | Acc: 70.064% (9013/12864)
Loss: 1.136 | Acc: 70.427% (13567/19264)
Loss: 1.137 | Acc: 70.367% (18059/25664)
Loss: 1.133 | Acc: 70.425% (22581/32064)
Loss: 1.139 | Acc: 70.354% (27061/38464)
Loss: 1.135 | Acc: 70.431% (31598/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3108, Accuracy: 3303/10000 (33.03%)

Epoch: 58
Loss: 1.439 | Acc: 56.250% (36/64)
Loss: 1.142 | Acc: 69.848% (4515/6464)
Loss: 1.149 | Acc: 70.095% (9017/12864)
Loss: 1.132 | Acc: 70.603% (13601/19264)
Loss: 1.132 | Acc: 70.616% (18123/25664)
Loss: 1.138 | Acc: 70.403% (22574/32064)
Loss: 1.137 | Acc: 70.385% (27073/38464)
Loss: 1.135 | Acc: 70.435% (31600/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3871, Accuracy: 6220/10000 (62.20%)

Epoch: 59
Loss: 0.876 | Acc: 79.688% (51/64)
Loss: 1.135 | Acc: 70.591% (4563/6464)
Loss: 1.134 | Acc: 70.553% (9076/12864)
Loss: 1.132 | Acc: 70.494% (13580/19264)
Loss: 1.125 | Acc: 70.757% (18159/25664)
Loss: 1.129 | Acc: 70.624% (22645/32064)
Loss: 1.130 | Acc: 70.578% (27147/38464)
Loss: 1.134 | Acc: 70.544% (31649/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4627, Accuracy: 5899/10000 (58.99%)

Epoch: 60
Loss: 1.126 | Acc: 70.312% (45/64)
Loss: 1.127 | Acc: 70.560% (4561/6464)
Loss: 1.124 | Acc: 70.647% (9088/12864)
Loss: 1.134 | Acc: 70.479% (13577/19264)
Loss: 1.135 | Acc: 70.546% (18105/25664)
Loss: 1.132 | Acc: 70.640% (22650/32064)
Loss: 1.130 | Acc: 70.741% (27210/38464)
Loss: 1.130 | Acc: 70.703% (31720/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3751, Accuracy: 6325/10000 (63.25%)

Epoch: 61
Loss: 1.182 | Acc: 68.750% (44/64)
Loss: 1.113 | Acc: 71.055% (4593/6464)
Loss: 1.109 | Acc: 71.121% (9149/12864)
Loss: 1.117 | Acc: 70.904% (13659/19264)
Loss: 1.123 | Acc: 70.690% (18142/25664)
Loss: 1.124 | Acc: 70.665% (22658/32064)
Loss: 1.125 | Acc: 70.744% (27211/38464)
Loss: 1.122 | Acc: 70.847% (31785/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3127, Accuracy: 6435/10000 (64.35%)

Epoch: 62
Loss: 1.216 | Acc: 71.875% (46/64)
Loss: 1.104 | Acc: 71.627% (4630/6464)
Loss: 1.105 | Acc: 71.463% (9193/12864)
Loss: 1.118 | Acc: 71.262% (13728/19264)
Loss: 1.114 | Acc: 71.326% (18305/25664)
Loss: 1.119 | Acc: 71.189% (22826/32064)
Loss: 1.119 | Acc: 71.199% (27386/38464)
Loss: 1.119 | Acc: 71.177% (31933/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6856, Accuracy: 5281/10000 (52.81%)

Epoch: 63
Loss: 0.987 | Acc: 76.562% (49/64)
Loss: 1.097 | Acc: 71.937% (4650/6464)
Loss: 1.104 | Acc: 71.533% (9202/12864)
Loss: 1.096 | Acc: 71.750% (13822/19264)
Loss: 1.103 | Acc: 71.458% (18339/25664)
Loss: 1.104 | Acc: 71.476% (22918/32064)
Loss: 1.109 | Acc: 71.363% (27449/38464)
Loss: 1.112 | Acc: 71.342% (32007/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4587, Accuracy: 6077/10000 (60.77%)

Epoch: 64
Loss: 1.071 | Acc: 73.438% (47/64)
Loss: 1.120 | Acc: 71.303% (4609/6464)
Loss: 1.110 | Acc: 71.720% (9226/12864)
Loss: 1.099 | Acc: 71.994% (13869/19264)
Loss: 1.101 | Acc: 71.840% (18437/25664)
Loss: 1.104 | Acc: 71.791% (23019/32064)
Loss: 1.103 | Acc: 71.768% (27605/38464)
Loss: 1.105 | Acc: 71.639% (32140/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2992, Accuracy: 6476/10000 (64.76%)

Epoch: 65
Loss: 0.950 | Acc: 71.875% (46/64)
Loss: 1.086 | Acc: 71.875% (4646/6464)
Loss: 1.085 | Acc: 71.999% (9262/12864)
Loss: 1.101 | Acc: 71.595% (13792/19264)
Loss: 1.097 | Acc: 71.700% (18401/25664)
Loss: 1.102 | Acc: 71.488% (22922/32064)
Loss: 1.103 | Acc: 71.451% (27483/38464)
Loss: 1.100 | Acc: 71.538% (32095/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5449, Accuracy: 5476/10000 (54.76%)

Epoch: 66
Loss: 1.041 | Acc: 70.312% (45/64)
Loss: 1.052 | Acc: 72.679% (4698/6464)
Loss: 1.076 | Acc: 72.100% (9275/12864)
Loss: 1.084 | Acc: 71.917% (13854/19264)
Loss: 1.089 | Acc: 71.805% (18428/25664)
Loss: 1.092 | Acc: 71.735% (23001/32064)
Loss: 1.092 | Acc: 71.766% (27604/38464)
Loss: 1.092 | Acc: 71.775% (32201/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8474, Accuracy: 4508/10000 (45.08%)

Epoch: 67
Loss: 1.366 | Acc: 64.062% (41/64)
Loss: 1.094 | Acc: 72.432% (4682/6464)
Loss: 1.083 | Acc: 72.536% (9331/12864)
Loss: 1.086 | Acc: 72.462% (13959/19264)
Loss: 1.091 | Acc: 72.276% (18549/25664)
Loss: 1.089 | Acc: 72.284% (23177/32064)
Loss: 1.090 | Acc: 72.195% (27769/38464)
Loss: 1.090 | Acc: 72.189% (32387/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5246, Accuracy: 5582/10000 (55.82%)

Epoch: 68
Loss: 0.978 | Acc: 78.125% (50/64)
Loss: 1.091 | Acc: 71.643% (4631/6464)
Loss: 1.067 | Acc: 72.800% (9365/12864)
Loss: 1.074 | Acc: 72.591% (13984/19264)
Loss: 1.075 | Acc: 72.631% (18640/25664)
Loss: 1.079 | Acc: 72.648% (23294/32064)
Loss: 1.082 | Acc: 72.515% (27892/38464)
Loss: 1.077 | Acc: 72.633% (32586/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4937, Accuracy: 5942/10000 (59.42%)

Epoch: 69
Loss: 1.141 | Acc: 73.438% (47/64)
Loss: 1.052 | Acc: 73.252% (4735/6464)
Loss: 1.060 | Acc: 73.088% (9402/12864)
Loss: 1.070 | Acc: 72.830% (14030/19264)
Loss: 1.074 | Acc: 72.721% (18663/25664)
Loss: 1.073 | Acc: 72.739% (23323/32064)
Loss: 1.071 | Acc: 72.827% (28012/38464)
Loss: 1.071 | Acc: 72.869% (32692/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3620, Accuracy: 6280/10000 (62.80%)

Epoch: 70
Loss: 1.086 | Acc: 71.875% (46/64)
Loss: 1.022 | Acc: 74.149% (4793/6464)
Loss: 1.030 | Acc: 74.098% (9532/12864)
Loss: 1.042 | Acc: 73.811% (14219/19264)
Loss: 1.044 | Acc: 73.706% (18916/25664)
Loss: 1.054 | Acc: 73.353% (23520/32064)
Loss: 1.058 | Acc: 73.243% (28172/38464)
Loss: 1.062 | Acc: 73.099% (32795/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3301, Accuracy: 6298/10000 (62.98%)

Epoch: 71
Loss: 1.086 | Acc: 73.438% (47/64)
Loss: 1.022 | Acc: 74.428% (4811/6464)
Loss: 1.025 | Acc: 74.223% (9548/12864)
Loss: 1.038 | Acc: 73.874% (14231/19264)
Loss: 1.042 | Acc: 73.714% (18918/25664)
Loss: 1.045 | Acc: 73.650% (23615/32064)
Loss: 1.050 | Acc: 73.451% (28252/38464)
Loss: 1.050 | Acc: 73.424% (32941/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5662, Accuracy: 5458/10000 (54.58%)

Epoch: 72
Loss: 1.164 | Acc: 65.625% (42/64)
Loss: 1.026 | Acc: 74.242% (4799/6464)
Loss: 1.042 | Acc: 73.725% (9484/12864)
Loss: 1.053 | Acc: 73.282% (14117/19264)
Loss: 1.050 | Acc: 73.422% (18843/25664)
Loss: 1.049 | Acc: 73.572% (23590/32064)
Loss: 1.047 | Acc: 73.591% (28306/38464)
Loss: 1.049 | Acc: 73.556% (33000/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3771, Accuracy: 6277/10000 (62.77%)

Epoch: 73
Loss: 1.125 | Acc: 68.750% (44/64)
Loss: 1.031 | Acc: 74.196% (4796/6464)
Loss: 1.034 | Acc: 74.090% (9531/12864)
Loss: 1.038 | Acc: 73.931% (14242/19264)
Loss: 1.038 | Acc: 73.983% (18987/25664)
Loss: 1.037 | Acc: 73.971% (23718/32064)
Loss: 1.036 | Acc: 74.012% (28468/38464)
Loss: 1.037 | Acc: 73.961% (33182/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2218, Accuracy: 6808/10000 (68.08%)

Epoch: 74
Loss: 1.129 | Acc: 67.188% (43/64)
Loss: 1.010 | Acc: 74.876% (4840/6464)
Loss: 1.014 | Acc: 74.611% (9598/12864)
Loss: 1.020 | Acc: 74.590% (14369/19264)
Loss: 1.025 | Acc: 74.369% (19086/25664)
Loss: 1.021 | Acc: 74.495% (23886/32064)
Loss: 1.028 | Acc: 74.277% (28570/38464)
Loss: 1.029 | Acc: 74.215% (33296/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3052, Accuracy: 6521/10000 (65.21%)

Epoch: 75
Loss: 0.917 | Acc: 78.125% (50/64)
Loss: 1.009 | Acc: 74.923% (4843/6464)
Loss: 1.013 | Acc: 74.790% (9621/12864)
Loss: 1.015 | Acc: 74.834% (14416/19264)
Loss: 1.017 | Acc: 74.692% (19169/25664)
Loss: 1.015 | Acc: 74.697% (23951/32064)
Loss: 1.017 | Acc: 74.633% (28707/38464)
Loss: 1.018 | Acc: 74.590% (33464/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2914, Accuracy: 6628/10000 (66.28%)

Epoch: 76
Loss: 0.885 | Acc: 79.688% (51/64)
Loss: 0.981 | Acc: 75.712% (4894/6464)
Loss: 0.981 | Acc: 75.754% (9745/12864)
Loss: 0.993 | Acc: 75.478% (14540/19264)
Loss: 0.999 | Acc: 75.214% (19303/25664)
Loss: 1.005 | Acc: 74.991% (24045/32064)
Loss: 1.006 | Acc: 74.938% (28824/38464)
Loss: 1.004 | Acc: 75.029% (33661/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3411, Accuracy: 6332/10000 (63.32%)

Epoch: 77
Loss: 0.988 | Acc: 76.562% (49/64)
Loss: 0.986 | Acc: 75.217% (4862/6464)
Loss: 0.995 | Acc: 75.233% (9678/12864)
Loss: 0.989 | Acc: 75.337% (14513/19264)
Loss: 0.995 | Acc: 75.203% (19300/25664)
Loss: 0.996 | Acc: 75.187% (24108/32064)
Loss: 0.994 | Acc: 75.302% (28964/38464)
Loss: 0.995 | Acc: 75.261% (33765/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2688, Accuracy: 6676/10000 (66.76%)

Epoch: 78
Loss: 0.885 | Acc: 79.688% (51/64)
Loss: 0.959 | Acc: 76.733% (4960/6464)
Loss: 0.973 | Acc: 76.143% (9795/12864)
Loss: 0.984 | Acc: 75.711% (14585/19264)
Loss: 0.983 | Acc: 75.830% (19461/25664)
Loss: 0.983 | Acc: 75.839% (24317/32064)
Loss: 0.977 | Acc: 75.936% (29208/38464)
Loss: 0.979 | Acc: 75.860% (34034/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3150, Accuracy: 6448/10000 (64.48%)

Epoch: 79
Loss: 1.001 | Acc: 78.125% (50/64)
Loss: 0.939 | Acc: 77.305% (4997/6464)
Loss: 0.947 | Acc: 76.858% (9887/12864)
Loss: 0.949 | Acc: 76.843% (14803/19264)
Loss: 0.958 | Acc: 76.633% (19667/25664)
Loss: 0.962 | Acc: 76.450% (24513/32064)
Loss: 0.961 | Acc: 76.524% (29434/38464)
Loss: 0.959 | Acc: 76.598% (34365/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3188, Accuracy: 6441/10000 (64.41%)

Epoch: 80
Loss: 1.256 | Acc: 64.062% (41/64)
Loss: 0.977 | Acc: 75.541% (4883/6464)
Loss: 0.959 | Acc: 76.213% (9804/12864)
Loss: 0.956 | Acc: 76.500% (14737/19264)
Loss: 0.949 | Acc: 76.746% (19696/25664)
Loss: 0.947 | Acc: 76.756% (24611/32064)
Loss: 0.950 | Acc: 76.664% (29488/38464)
Loss: 0.952 | Acc: 76.596% (34364/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1962, Accuracy: 7066/10000 (70.66%)

Epoch: 81
Loss: 0.897 | Acc: 76.562% (49/64)
Loss: 0.931 | Acc: 77.274% (4995/6464)
Loss: 0.937 | Acc: 77.044% (9911/12864)
Loss: 0.934 | Acc: 77.097% (14852/19264)
Loss: 0.940 | Acc: 76.929% (19743/25664)
Loss: 0.936 | Acc: 77.068% (24711/32064)
Loss: 0.935 | Acc: 77.093% (29653/38464)
Loss: 0.938 | Acc: 77.048% (34567/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2747, Accuracy: 6785/10000 (67.85%)

Epoch: 82
Loss: 0.768 | Acc: 82.812% (53/64)
Loss: 0.923 | Acc: 77.119% (4985/6464)
Loss: 0.921 | Acc: 77.270% (9940/12864)
Loss: 0.911 | Acc: 77.590% (14947/19264)
Loss: 0.911 | Acc: 77.646% (19927/25664)
Loss: 0.915 | Acc: 77.495% (24848/32064)
Loss: 0.918 | Acc: 77.459% (29794/38464)
Loss: 0.920 | Acc: 77.398% (34724/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1706, Accuracy: 7156/10000 (71.56%)

Epoch: 83
Loss: 1.130 | Acc: 75.000% (48/64)
Loss: 0.865 | Acc: 78.945% (5103/6464)
Loss: 0.886 | Acc: 78.265% (10068/12864)
Loss: 0.885 | Acc: 78.369% (15097/19264)
Loss: 0.895 | Acc: 78.125% (20050/25664)
Loss: 0.894 | Acc: 78.109% (25045/32064)
Loss: 0.898 | Acc: 77.998% (30001/38464)
Loss: 0.900 | Acc: 77.947% (34970/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2636, Accuracy: 6769/10000 (67.69%)

Epoch: 84
Loss: 0.701 | Acc: 81.250% (52/64)
Loss: 0.868 | Acc: 78.837% (5096/6464)
Loss: 0.875 | Acc: 78.739% (10129/12864)
Loss: 0.881 | Acc: 78.514% (15125/19264)
Loss: 0.882 | Acc: 78.433% (20129/25664)
Loss: 0.875 | Acc: 78.549% (25186/32064)
Loss: 0.876 | Acc: 78.559% (30217/38464)
Loss: 0.879 | Acc: 78.464% (35202/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2149, Accuracy: 7035/10000 (70.35%)

Epoch: 85
Loss: 0.968 | Acc: 78.125% (50/64)
Loss: 0.835 | Acc: 79.811% (5159/6464)
Loss: 0.842 | Acc: 79.439% (10219/12864)
Loss: 0.843 | Acc: 79.412% (15298/19264)
Loss: 0.842 | Acc: 79.462% (20393/25664)
Loss: 0.841 | Acc: 79.557% (25509/32064)
Loss: 0.846 | Acc: 79.389% (30536/38464)
Loss: 0.852 | Acc: 79.228% (35545/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2341, Accuracy: 6918/10000 (69.18%)

Epoch: 86
Loss: 0.869 | Acc: 79.688% (51/64)
Loss: 0.799 | Acc: 80.507% (5204/6464)
Loss: 0.801 | Acc: 80.605% (10369/12864)
Loss: 0.799 | Acc: 80.622% (15531/19264)
Loss: 0.812 | Acc: 80.190% (20580/25664)
Loss: 0.821 | Acc: 79.887% (25615/32064)
Loss: 0.826 | Acc: 79.747% (30674/38464)
Loss: 0.829 | Acc: 79.670% (35743/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2180, Accuracy: 7100/10000 (71.00%)

Epoch: 87
Loss: 0.620 | Acc: 85.938% (55/64)
Loss: 0.805 | Acc: 79.950% (5168/6464)
Loss: 0.785 | Acc: 80.597% (10368/12864)
Loss: 0.799 | Acc: 80.118% (15434/19264)
Loss: 0.801 | Acc: 80.034% (20540/25664)
Loss: 0.801 | Acc: 80.077% (25676/32064)
Loss: 0.800 | Acc: 80.150% (30829/38464)
Loss: 0.796 | Acc: 80.309% (36030/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3057, Accuracy: 6886/10000 (68.86%)

Epoch: 88
Loss: 0.529 | Acc: 87.500% (56/64)
Loss: 0.757 | Acc: 81.327% (5257/6464)
Loss: 0.758 | Acc: 81.149% (10439/12864)
Loss: 0.759 | Acc: 81.079% (15619/19264)
Loss: 0.759 | Acc: 81.121% (20819/25664)
Loss: 0.762 | Acc: 81.075% (25996/32064)
Loss: 0.762 | Acc: 81.107% (31197/38464)
Loss: 0.765 | Acc: 81.069% (36371/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2575, Accuracy: 7060/10000 (70.60%)

Epoch: 89
Loss: 0.514 | Acc: 87.500% (56/64)
Loss: 0.703 | Acc: 82.596% (5339/6464)
Loss: 0.721 | Acc: 82.261% (10582/12864)
Loss: 0.722 | Acc: 82.023% (15801/19264)
Loss: 0.723 | Acc: 81.870% (21011/25664)
Loss: 0.725 | Acc: 81.818% (26234/32064)
Loss: 0.724 | Acc: 81.804% (31465/38464)
Loss: 0.727 | Acc: 81.823% (36709/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2718, Accuracy: 7092/10000 (70.92%)

Epoch: 90
Loss: 0.889 | Acc: 76.562% (49/64)
Loss: 0.663 | Acc: 83.246% (5381/6464)
Loss: 0.678 | Acc: 82.805% (10652/12864)
Loss: 0.680 | Acc: 82.797% (15950/19264)
Loss: 0.678 | Acc: 82.781% (21245/25664)
Loss: 0.683 | Acc: 82.666% (26506/32064)
Loss: 0.688 | Acc: 82.480% (31725/38464)
Loss: 0.686 | Acc: 82.545% (37033/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3056, Accuracy: 7109/10000 (71.09%)

Epoch: 91
Loss: 0.460 | Acc: 89.062% (57/64)
Loss: 0.625 | Acc: 83.957% (5427/6464)
Loss: 0.633 | Acc: 83.776% (10777/12864)
Loss: 0.641 | Acc: 83.446% (16075/19264)
Loss: 0.637 | Acc: 83.580% (21450/25664)
Loss: 0.641 | Acc: 83.436% (26753/32064)
Loss: 0.641 | Acc: 83.514% (32123/38464)
Loss: 0.640 | Acc: 83.570% (37493/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3081, Accuracy: 7154/10000 (71.54%)

Epoch: 92
Loss: 0.668 | Acc: 82.812% (53/64)
Loss: 0.568 | Acc: 84.978% (5493/6464)
Loss: 0.569 | Acc: 85.145% (10953/12864)
Loss: 0.575 | Acc: 85.029% (16380/19264)
Loss: 0.582 | Acc: 84.878% (21783/25664)
Loss: 0.591 | Acc: 84.600% (27126/32064)
Loss: 0.589 | Acc: 84.596% (32539/38464)
Loss: 0.588 | Acc: 84.571% (37942/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3738, Accuracy: 7032/10000 (70.32%)

Epoch: 93
Loss: 0.413 | Acc: 87.500% (56/64)
Loss: 0.518 | Acc: 85.876% (5551/6464)
Loss: 0.515 | Acc: 86.217% (11091/12864)
Loss: 0.514 | Acc: 86.223% (16610/19264)
Loss: 0.520 | Acc: 86.078% (22091/25664)
Loss: 0.520 | Acc: 86.050% (27591/32064)
Loss: 0.526 | Acc: 85.878% (33032/38464)
Loss: 0.529 | Acc: 85.804% (38495/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4101, Accuracy: 7021/10000 (70.21%)

Epoch: 94
Loss: 0.444 | Acc: 92.188% (59/64)
Loss: 0.469 | Acc: 87.237% (5639/6464)
Loss: 0.479 | Acc: 86.847% (11172/12864)
Loss: 0.478 | Acc: 86.893% (16739/19264)
Loss: 0.479 | Acc: 86.853% (22290/25664)
Loss: 0.484 | Acc: 86.789% (27828/32064)
Loss: 0.480 | Acc: 86.951% (33445/38464)
Loss: 0.478 | Acc: 87.005% (39034/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4816, Accuracy: 7035/10000 (70.35%)

Epoch: 95
Loss: 0.387 | Acc: 84.375% (54/64)
Loss: 0.425 | Acc: 88.196% (5701/6464)
Loss: 0.427 | Acc: 88.075% (11330/12864)
Loss: 0.428 | Acc: 88.035% (16959/19264)
Loss: 0.427 | Acc: 88.159% (22625/25664)
Loss: 0.431 | Acc: 88.018% (28222/32064)
Loss: 0.433 | Acc: 88.002% (33849/38464)
Loss: 0.430 | Acc: 88.059% (39507/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5110, Accuracy: 6998/10000 (69.98%)

Epoch: 96
Loss: 0.439 | Acc: 90.625% (58/64)
Loss: 0.410 | Acc: 88.459% (5718/6464)
Loss: 0.401 | Acc: 88.736% (11415/12864)
Loss: 0.401 | Acc: 88.606% (17069/19264)
Loss: 0.397 | Acc: 88.790% (22787/25664)
Loss: 0.391 | Acc: 88.972% (28528/32064)
Loss: 0.391 | Acc: 88.987% (34228/38464)
Loss: 0.389 | Acc: 89.007% (39932/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5253, Accuracy: 6996/10000 (69.96%)

Epoch: 97
Loss: 0.451 | Acc: 85.938% (55/64)
Loss: 0.351 | Acc: 89.960% (5815/6464)
Loss: 0.359 | Acc: 89.653% (11533/12864)
Loss: 0.360 | Acc: 89.784% (17296/19264)
Loss: 0.356 | Acc: 89.931% (23080/25664)
Loss: 0.356 | Acc: 89.923% (28833/32064)
Loss: 0.354 | Acc: 90.011% (34622/38464)
Loss: 0.354 | Acc: 89.979% (40368/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5331, Accuracy: 6994/10000 (69.94%)
torch.Size([100, 10])
Test set: Average loss: 1.5331, Accuracy: 6994/10000 (69.94%)

Epoch: 98
Loss: 0.211 | Acc: 93.750% (60/64)
Loss: 0.340 | Acc: 90.347% (5840/6464)
Loss: 0.341 | Acc: 90.384% (11627/12864)
Loss: 0.339 | Acc: 90.474% (17429/19264)
Loss: 0.341 | Acc: 90.372% (23193/25664)
Loss: 0.339 | Acc: 90.488% (29014/32064)
Loss: 0.339 | Acc: 90.440% (34787/38464)
Loss: 0.339 | Acc: 90.456% (40582/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5256, Accuracy: 6998/10000 (69.98%)
torch.Size([100, 10])
Test set: Average loss: 1.5256, Accuracy: 6998/10000 (69.98%)

Epoch: 99
Loss: 0.240 | Acc: 93.750% (60/64)
Loss: 0.318 | Acc: 90.996% (5882/6464)
Loss: 0.325 | Acc: 90.571% (11651/12864)
Loss: 0.323 | Acc: 90.755% (17483/19264)
Loss: 0.324 | Acc: 90.707% (23279/25664)
Loss: 0.327 | Acc: 90.622% (29057/32064)
Loss: 0.328 | Acc: 90.609% (34852/38464)
Loss: 0.327 | Acc: 90.647% (40668/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5452, Accuracy: 6994/10000 (69.94%)
torch.Size([100, 10])
Test set: Average loss: 1.5452, Accuracy: 6994/10000 (69.94%)

Epoch: 100
Loss: 0.256 | Acc: 92.188% (59/64)
Loss: 2.064 | Acc: 26.129% (1689/6464)
Loss: 1.820 | Acc: 38.277% (4924/12864)
Loss: 1.644 | Acc: 46.776% (9011/19264)
Loss: 1.546 | Acc: 51.329% (13173/25664)
Loss: 1.480 | Acc: 54.510% (17478/32064)
Loss: 1.434 | Acc: 56.718% (21816/38464)
Loss: 1.401 | Acc: 58.274% (26144/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8015, Accuracy: 4579/10000 (45.79%)

Epoch: 101
Loss: 1.400 | Acc: 59.375% (38/64)
Loss: 1.167 | Acc: 68.889% (4453/6464)
Loss: 1.173 | Acc: 68.571% (8821/12864)
Loss: 1.169 | Acc: 68.724% (13239/19264)
Loss: 1.164 | Acc: 69.019% (17713/25664)
Loss: 1.163 | Acc: 69.084% (22151/32064)
Loss: 1.159 | Acc: 69.213% (26622/38464)
Loss: 1.161 | Acc: 69.287% (31085/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2775, Accuracy: 6577/10000 (65.77%)

Epoch: 102
Loss: 0.914 | Acc: 73.438% (47/64)
Loss: 1.133 | Acc: 70.343% (4547/6464)
Loss: 1.132 | Acc: 70.344% (9049/12864)
Loss: 1.135 | Acc: 70.333% (13549/19264)
Loss: 1.132 | Acc: 70.453% (18081/25664)
Loss: 1.131 | Acc: 70.472% (22596/32064)
Loss: 1.135 | Acc: 70.294% (27038/38464)
Loss: 1.133 | Acc: 70.386% (31578/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7768, Accuracy: 4901/10000 (49.01%)

Epoch: 103
Loss: 1.350 | Acc: 60.938% (39/64)
Loss: 1.145 | Acc: 70.343% (4547/6464)
Loss: 1.137 | Acc: 70.476% (9066/12864)
Loss: 1.132 | Acc: 70.660% (13612/19264)
Loss: 1.126 | Acc: 70.916% (18200/25664)
Loss: 1.128 | Acc: 70.918% (22739/32064)
Loss: 1.130 | Acc: 70.838% (27247/38464)
Loss: 1.130 | Acc: 70.794% (31761/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8965, Accuracy: 4729/10000 (47.29%)

Epoch: 104
Loss: 1.306 | Acc: 60.938% (39/64)
Loss: 1.099 | Acc: 71.024% (4591/6464)
Loss: 1.119 | Acc: 70.810% (9109/12864)
Loss: 1.118 | Acc: 71.107% (13698/19264)
Loss: 1.122 | Acc: 70.971% (18214/25664)
Loss: 1.123 | Acc: 70.964% (22754/32064)
Loss: 1.128 | Acc: 70.819% (27240/38464)
Loss: 1.127 | Acc: 70.830% (31777/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5690, Accuracy: 5466/10000 (54.66%)

Epoch: 105
Loss: 1.666 | Acc: 54.688% (35/64)
Loss: 1.129 | Acc: 70.498% (4557/6464)
Loss: 1.114 | Acc: 70.934% (9125/12864)
Loss: 1.118 | Acc: 70.702% (13620/19264)
Loss: 1.108 | Acc: 70.940% (18206/25664)
Loss: 1.112 | Acc: 70.877% (22726/32064)
Loss: 1.117 | Acc: 70.838% (27247/38464)
Loss: 1.118 | Acc: 70.892% (31805/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7666, Accuracy: 4732/10000 (47.32%)

Epoch: 106
Loss: 1.237 | Acc: 67.188% (43/64)
Loss: 1.110 | Acc: 71.860% (4645/6464)
Loss: 1.125 | Acc: 71.175% (9156/12864)
Loss: 1.115 | Acc: 71.465% (13767/19264)
Loss: 1.117 | Acc: 71.376% (18318/25664)
Loss: 1.117 | Acc: 71.370% (22884/32064)
Loss: 1.120 | Acc: 71.217% (27393/38464)
Loss: 1.121 | Acc: 71.099% (31898/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7500, Accuracy: 4958/10000 (49.58%)

Epoch: 107
Loss: 1.215 | Acc: 62.500% (40/64)
Loss: 1.068 | Acc: 72.571% (4691/6464)
Loss: 1.089 | Acc: 71.891% (9248/12864)
Loss: 1.101 | Acc: 71.641% (13801/19264)
Loss: 1.110 | Acc: 71.341% (18309/25664)
Loss: 1.110 | Acc: 71.348% (22877/32064)
Loss: 1.113 | Acc: 71.215% (27392/38464)
Loss: 1.116 | Acc: 71.193% (31940/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7460, Accuracy: 5000/10000 (50.00%)

Epoch: 108
Loss: 1.321 | Acc: 65.625% (42/64)
Loss: 1.101 | Acc: 71.627% (4630/6464)
Loss: 1.100 | Acc: 71.766% (9232/12864)
Loss: 1.108 | Acc: 71.574% (13788/19264)
Loss: 1.109 | Acc: 71.555% (18364/25664)
Loss: 1.108 | Acc: 71.516% (22931/32064)
Loss: 1.113 | Acc: 71.415% (27469/38464)
Loss: 1.113 | Acc: 71.371% (32020/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4075, Accuracy: 3535/10000 (35.35%)

Epoch: 109
Loss: 1.262 | Acc: 68.750% (44/64)
Loss: 1.126 | Acc: 70.947% (4586/6464)
Loss: 1.110 | Acc: 71.479% (9195/12864)
Loss: 1.106 | Acc: 71.579% (13789/19264)
Loss: 1.105 | Acc: 71.544% (18361/25664)
Loss: 1.107 | Acc: 71.476% (22918/32064)
Loss: 1.110 | Acc: 71.337% (27439/38464)
Loss: 1.110 | Acc: 71.382% (32025/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4176, Accuracy: 5964/10000 (59.64%)

Epoch: 110
Loss: 1.496 | Acc: 60.938% (39/64)
Loss: 1.099 | Acc: 71.921% (4649/6464)
Loss: 1.091 | Acc: 71.945% (9255/12864)
Loss: 1.091 | Acc: 72.176% (13904/19264)
Loss: 1.095 | Acc: 71.898% (18452/25664)
Loss: 1.099 | Acc: 71.788% (23018/32064)
Loss: 1.101 | Acc: 71.753% (27599/38464)
Loss: 1.099 | Acc: 71.830% (32226/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5318, Accuracy: 5607/10000 (56.07%)

Epoch: 111
Loss: 1.063 | Acc: 65.625% (42/64)
Loss: 1.093 | Acc: 72.123% (4662/6464)
Loss: 1.102 | Acc: 71.797% (9236/12864)
Loss: 1.100 | Acc: 71.870% (13845/19264)
Loss: 1.093 | Acc: 72.039% (18488/25664)
Loss: 1.102 | Acc: 71.816% (23027/32064)
Loss: 1.103 | Acc: 71.823% (27626/38464)
Loss: 1.103 | Acc: 71.761% (32195/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6490, Accuracy: 5011/10000 (50.11%)

Epoch: 112
Loss: 1.480 | Acc: 56.250% (36/64)
Loss: 1.099 | Acc: 71.999% (4654/6464)
Loss: 1.079 | Acc: 72.458% (9321/12864)
Loss: 1.086 | Acc: 72.223% (13913/19264)
Loss: 1.089 | Acc: 72.124% (18510/25664)
Loss: 1.089 | Acc: 72.065% (23107/32064)
Loss: 1.095 | Acc: 71.982% (27687/38464)
Loss: 1.097 | Acc: 71.937% (32274/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9494, Accuracy: 4127/10000 (41.27%)

Epoch: 113
Loss: 1.189 | Acc: 67.188% (43/64)
Loss: 1.075 | Acc: 72.618% (4694/6464)
Loss: 1.081 | Acc: 72.217% (9290/12864)
Loss: 1.080 | Acc: 72.436% (13954/19264)
Loss: 1.081 | Acc: 72.463% (18597/25664)
Loss: 1.080 | Acc: 72.449% (23230/32064)
Loss: 1.085 | Acc: 72.351% (27829/38464)
Loss: 1.089 | Acc: 72.261% (32419/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3345, Accuracy: 3371/10000 (33.71%)

Epoch: 114
Loss: 1.084 | Acc: 71.875% (46/64)
Loss: 1.070 | Acc: 72.850% (4709/6464)
Loss: 1.076 | Acc: 72.466% (9322/12864)
Loss: 1.078 | Acc: 72.524% (13971/19264)
Loss: 1.082 | Acc: 72.428% (18588/25664)
Loss: 1.084 | Acc: 72.418% (23220/32064)
Loss: 1.090 | Acc: 72.242% (27787/38464)
Loss: 1.091 | Acc: 72.158% (32373/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3994, Accuracy: 6046/10000 (60.46%)

Epoch: 115
Loss: 0.804 | Acc: 79.688% (51/64)
Loss: 1.048 | Acc: 73.515% (4752/6464)
Loss: 1.066 | Acc: 73.025% (9394/12864)
Loss: 1.078 | Acc: 72.669% (13999/19264)
Loss: 1.084 | Acc: 72.654% (18646/25664)
Loss: 1.083 | Acc: 72.561% (23266/32064)
Loss: 1.081 | Acc: 72.517% (27893/38464)
Loss: 1.080 | Acc: 72.477% (32516/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3430, Accuracy: 6389/10000 (63.89%)

Epoch: 116
Loss: 0.955 | Acc: 76.562% (49/64)
Loss: 1.062 | Acc: 73.128% (4727/6464)
Loss: 1.069 | Acc: 72.839% (9370/12864)
Loss: 1.070 | Acc: 72.908% (14045/19264)
Loss: 1.076 | Acc: 72.728% (18665/25664)
Loss: 1.078 | Acc: 72.745% (23325/32064)
Loss: 1.076 | Acc: 72.772% (27991/38464)
Loss: 1.077 | Acc: 72.693% (32613/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4297, Accuracy: 5985/10000 (59.85%)

Epoch: 117
Loss: 0.803 | Acc: 79.688% (51/64)
Loss: 1.077 | Acc: 72.525% (4688/6464)
Loss: 1.083 | Acc: 72.435% (9318/12864)
Loss: 1.074 | Acc: 72.669% (13999/19264)
Loss: 1.074 | Acc: 72.830% (18691/25664)
Loss: 1.080 | Acc: 72.611% (23282/32064)
Loss: 1.073 | Acc: 72.819% (28009/38464)
Loss: 1.069 | Acc: 72.929% (32719/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3052, Accuracy: 6496/10000 (64.96%)

Epoch: 118
Loss: 1.299 | Acc: 71.875% (46/64)
Loss: 1.036 | Acc: 73.871% (4775/6464)
Loss: 1.049 | Acc: 73.678% (9478/12864)
Loss: 1.058 | Acc: 73.547% (14168/19264)
Loss: 1.056 | Acc: 73.578% (18883/25664)
Loss: 1.062 | Acc: 73.400% (23535/32064)
Loss: 1.062 | Acc: 73.373% (28222/38464)
Loss: 1.063 | Acc: 73.348% (32907/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4421, Accuracy: 5850/10000 (58.50%)

Epoch: 119
Loss: 0.949 | Acc: 76.562% (49/64)
Loss: 1.050 | Acc: 72.896% (4712/6464)
Loss: 1.048 | Acc: 73.220% (9419/12864)
Loss: 1.048 | Acc: 73.417% (14143/19264)
Loss: 1.054 | Acc: 73.266% (18803/25664)
Loss: 1.057 | Acc: 73.188% (23467/32064)
Loss: 1.055 | Acc: 73.245% (28173/38464)
Loss: 1.054 | Acc: 73.353% (32909/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5767, Accuracy: 5507/10000 (55.07%)

Epoch: 120
Loss: 1.033 | Acc: 68.750% (44/64)
Loss: 1.059 | Acc: 73.407% (4745/6464)
Loss: 1.054 | Acc: 73.655% (9475/12864)
Loss: 1.044 | Acc: 73.837% (14224/19264)
Loss: 1.043 | Acc: 73.862% (18956/25664)
Loss: 1.043 | Acc: 73.849% (23679/32064)
Loss: 1.045 | Acc: 73.788% (28382/38464)
Loss: 1.047 | Acc: 73.743% (33084/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2874, Accuracy: 6658/10000 (66.58%)

Epoch: 121
Loss: 1.229 | Acc: 65.625% (42/64)
Loss: 1.003 | Acc: 74.845% (4838/6464)
Loss: 1.024 | Acc: 74.277% (9555/12864)
Loss: 1.035 | Acc: 74.040% (14263/19264)
Loss: 1.042 | Acc: 73.831% (18948/25664)
Loss: 1.035 | Acc: 74.061% (23747/32064)
Loss: 1.039 | Acc: 73.918% (28432/38464)
Loss: 1.043 | Acc: 73.879% (33145/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2927, Accuracy: 6548/10000 (65.48%)

Epoch: 122
Loss: 1.179 | Acc: 70.312% (45/64)
Loss: 1.019 | Acc: 74.505% (4816/6464)
Loss: 1.016 | Acc: 74.635% (9601/12864)
Loss: 1.018 | Acc: 74.668% (14384/19264)
Loss: 1.015 | Acc: 74.770% (19189/25664)
Loss: 1.020 | Acc: 74.654% (23937/32064)
Loss: 1.021 | Acc: 74.561% (28679/38464)
Loss: 1.026 | Acc: 74.456% (33404/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2608, Accuracy: 6704/10000 (67.04%)

Epoch: 123
Loss: 0.934 | Acc: 71.875% (46/64)
Loss: 0.994 | Acc: 74.814% (4836/6464)
Loss: 1.009 | Acc: 74.658% (9604/12864)
Loss: 1.009 | Acc: 74.694% (14389/19264)
Loss: 1.009 | Acc: 74.856% (19211/25664)
Loss: 1.013 | Acc: 74.588% (23916/32064)
Loss: 1.018 | Acc: 74.446% (28635/38464)
Loss: 1.020 | Acc: 74.443% (33398/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2038, Accuracy: 6985/10000 (69.85%)

Epoch: 124
Loss: 0.838 | Acc: 81.250% (52/64)
Loss: 0.993 | Acc: 75.959% (4910/6464)
Loss: 0.991 | Acc: 75.544% (9718/12864)
Loss: 1.000 | Acc: 75.254% (14497/19264)
Loss: 1.001 | Acc: 75.245% (19311/25664)
Loss: 1.004 | Acc: 75.190% (24109/32064)
Loss: 1.004 | Acc: 75.213% (28930/38464)
Loss: 1.011 | Acc: 74.904% (33605/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1657, Accuracy: 7068/10000 (70.68%)

Epoch: 125
Loss: 1.020 | Acc: 71.875% (46/64)
Loss: 0.979 | Acc: 75.928% (4908/6464)
Loss: 0.977 | Acc: 75.808% (9752/12864)
Loss: 0.996 | Acc: 75.234% (14493/19264)
Loss: 0.996 | Acc: 75.370% (19343/25664)
Loss: 1.000 | Acc: 75.306% (24146/32064)
Loss: 0.999 | Acc: 75.302% (28964/38464)
Loss: 1.002 | Acc: 75.176% (33727/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3972, Accuracy: 6103/10000 (61.03%)

Epoch: 126
Loss: 0.987 | Acc: 65.625% (42/64)
Loss: 0.954 | Acc: 76.067% (4917/6464)
Loss: 0.961 | Acc: 76.283% (9813/12864)
Loss: 0.976 | Acc: 75.893% (14620/19264)
Loss: 0.983 | Acc: 75.639% (19412/25664)
Loss: 0.986 | Acc: 75.605% (24242/32064)
Loss: 0.986 | Acc: 75.619% (29086/38464)
Loss: 0.989 | Acc: 75.566% (33902/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1763, Accuracy: 7062/10000 (70.62%)

Epoch: 127
Loss: 0.834 | Acc: 82.812% (53/64)
Loss: 0.946 | Acc: 76.903% (4971/6464)
Loss: 0.967 | Acc: 76.314% (9817/12864)
Loss: 0.975 | Acc: 75.924% (14626/19264)
Loss: 0.980 | Acc: 75.818% (19458/25664)
Loss: 0.984 | Acc: 75.702% (24273/32064)
Loss: 0.980 | Acc: 75.840% (29171/38464)
Loss: 0.977 | Acc: 76.005% (34099/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4590, Accuracy: 5931/10000 (59.31%)

Epoch: 128
Loss: 1.238 | Acc: 71.875% (46/64)
Loss: 0.940 | Acc: 77.027% (4979/6464)
Loss: 0.953 | Acc: 76.632% (9858/12864)
Loss: 0.954 | Acc: 76.428% (14723/19264)
Loss: 0.957 | Acc: 76.313% (19585/25664)
Loss: 0.960 | Acc: 76.341% (24478/32064)
Loss: 0.962 | Acc: 76.310% (29352/38464)
Loss: 0.964 | Acc: 76.248% (34208/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3583, Accuracy: 6311/10000 (63.11%)

Epoch: 129
Loss: 0.970 | Acc: 75.000% (48/64)
Loss: 0.927 | Acc: 77.460% (5007/6464)
Loss: 0.936 | Acc: 77.254% (9938/12864)
Loss: 0.928 | Acc: 77.575% (14944/19264)
Loss: 0.935 | Acc: 77.369% (19856/25664)
Loss: 0.948 | Acc: 76.999% (24689/32064)
Loss: 0.952 | Acc: 76.848% (29559/38464)
Loss: 0.954 | Acc: 76.821% (34465/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2467, Accuracy: 6847/10000 (68.47%)

Epoch: 130
Loss: 1.006 | Acc: 76.562% (49/64)
Loss: 0.927 | Acc: 77.259% (4994/6464)
Loss: 0.946 | Acc: 77.060% (9913/12864)
Loss: 0.942 | Acc: 77.076% (14848/19264)
Loss: 0.940 | Acc: 77.112% (19790/25664)
Loss: 0.936 | Acc: 77.224% (24761/32064)
Loss: 0.935 | Acc: 77.176% (29685/38464)
Loss: 0.935 | Acc: 77.207% (34638/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2713, Accuracy: 6721/10000 (67.21%)

Epoch: 131
Loss: 0.890 | Acc: 79.688% (51/64)
Loss: 0.894 | Acc: 78.465% (5072/6464)
Loss: 0.899 | Acc: 78.350% (10079/12864)
Loss: 0.906 | Acc: 78.063% (15038/19264)
Loss: 0.908 | Acc: 78.016% (20022/25664)
Loss: 0.915 | Acc: 77.810% (24949/32064)
Loss: 0.917 | Acc: 77.805% (29927/38464)
Loss: 0.920 | Acc: 77.673% (34847/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2419, Accuracy: 6831/10000 (68.31%)

Epoch: 132
Loss: 1.193 | Acc: 68.750% (44/64)
Loss: 0.884 | Acc: 78.806% (5094/6464)
Loss: 0.898 | Acc: 78.288% (10071/12864)
Loss: 0.895 | Acc: 78.182% (15061/19264)
Loss: 0.899 | Acc: 78.133% (20052/25664)
Loss: 0.902 | Acc: 78.010% (25013/32064)
Loss: 0.902 | Acc: 78.003% (30003/38464)
Loss: 0.904 | Acc: 77.933% (34964/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1680, Accuracy: 7131/10000 (71.31%)

Epoch: 133
Loss: 0.902 | Acc: 76.562% (49/64)
Loss: 0.840 | Acc: 79.718% (5153/6464)
Loss: 0.861 | Acc: 79.097% (10175/12864)
Loss: 0.876 | Acc: 78.603% (15142/19264)
Loss: 0.882 | Acc: 78.448% (20133/25664)
Loss: 0.888 | Acc: 78.334% (25117/32064)
Loss: 0.888 | Acc: 78.323% (30126/38464)
Loss: 0.886 | Acc: 78.426% (35185/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3416, Accuracy: 6523/10000 (65.23%)

Epoch: 134
Loss: 0.900 | Acc: 73.438% (47/64)
Loss: 0.846 | Acc: 79.208% (5120/6464)
Loss: 0.849 | Acc: 78.996% (10162/12864)
Loss: 0.851 | Acc: 79.007% (15220/19264)
Loss: 0.852 | Acc: 79.006% (20276/25664)
Loss: 0.859 | Acc: 78.855% (25284/32064)
Loss: 0.859 | Acc: 78.897% (30347/38464)
Loss: 0.859 | Acc: 78.921% (35407/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1793, Accuracy: 7171/10000 (71.71%)

Epoch: 135
Loss: 0.808 | Acc: 79.688% (51/64)
Loss: 0.794 | Acc: 80.476% (5202/6464)
Loss: 0.805 | Acc: 80.092% (10303/12864)
Loss: 0.817 | Acc: 79.807% (15374/19264)
Loss: 0.826 | Acc: 79.586% (20425/25664)
Loss: 0.830 | Acc: 79.494% (25489/32064)
Loss: 0.837 | Acc: 79.326% (30512/38464)
Loss: 0.836 | Acc: 79.373% (35610/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2818, Accuracy: 6809/10000 (68.09%)

Epoch: 136
Loss: 1.294 | Acc: 65.625% (42/64)
Loss: 0.793 | Acc: 80.306% (5191/6464)
Loss: 0.800 | Acc: 80.232% (10321/12864)
Loss: 0.796 | Acc: 80.445% (15497/19264)
Loss: 0.806 | Acc: 80.245% (20594/25664)
Loss: 0.808 | Acc: 80.112% (25687/32064)
Loss: 0.815 | Acc: 79.864% (30719/38464)
Loss: 0.813 | Acc: 79.977% (35881/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3438, Accuracy: 6883/10000 (68.83%)

Epoch: 137
Loss: 0.741 | Acc: 81.250% (52/64)
Loss: 0.757 | Acc: 81.265% (5253/6464)
Loss: 0.760 | Acc: 81.227% (10449/12864)
Loss: 0.768 | Acc: 81.058% (15615/19264)
Loss: 0.768 | Acc: 81.094% (20812/25664)
Loss: 0.773 | Acc: 80.910% (25943/32064)
Loss: 0.778 | Acc: 80.779% (31071/38464)
Loss: 0.778 | Acc: 80.782% (36242/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3285, Accuracy: 6704/10000 (67.04%)

Epoch: 138
Loss: 0.907 | Acc: 70.312% (45/64)
Loss: 0.734 | Acc: 81.683% (5280/6464)
Loss: 0.741 | Acc: 81.460% (10479/12864)
Loss: 0.742 | Acc: 81.536% (15707/19264)
Loss: 0.736 | Acc: 81.729% (20975/25664)
Loss: 0.741 | Acc: 81.503% (26133/32064)
Loss: 0.739 | Acc: 81.591% (31383/38464)
Loss: 0.740 | Acc: 81.569% (36595/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2584, Accuracy: 7089/10000 (70.89%)

Epoch: 139
Loss: 0.638 | Acc: 85.938% (55/64)
Loss: 0.692 | Acc: 82.550% (5336/6464)
Loss: 0.691 | Acc: 82.424% (10603/12864)
Loss: 0.692 | Acc: 82.501% (15893/19264)
Loss: 0.702 | Acc: 82.162% (21086/25664)
Loss: 0.706 | Acc: 82.080% (26318/32064)
Loss: 0.706 | Acc: 82.085% (31573/38464)
Loss: 0.708 | Acc: 82.124% (36844/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2423, Accuracy: 7216/10000 (72.16%)

Epoch: 140
Loss: 0.463 | Acc: 87.500% (56/64)
Loss: 0.623 | Acc: 84.081% (5435/6464)
Loss: 0.649 | Acc: 83.403% (10729/12864)
Loss: 0.654 | Acc: 83.373% (16061/19264)
Loss: 0.658 | Acc: 83.307% (21380/25664)
Loss: 0.654 | Acc: 83.383% (26736/32064)
Loss: 0.658 | Acc: 83.252% (32022/38464)
Loss: 0.661 | Acc: 83.129% (37295/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3154, Accuracy: 7113/10000 (71.13%)

Epoch: 141
Loss: 0.466 | Acc: 87.500% (56/64)
Loss: 0.585 | Acc: 85.149% (5504/6464)
Loss: 0.596 | Acc: 84.600% (10883/12864)
Loss: 0.610 | Acc: 84.276% (16235/19264)
Loss: 0.613 | Acc: 84.087% (21580/25664)
Loss: 0.611 | Acc: 84.116% (26971/32064)
Loss: 0.608 | Acc: 84.190% (32383/38464)
Loss: 0.615 | Acc: 83.998% (37685/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3417, Accuracy: 7073/10000 (70.73%)

Epoch: 142
Loss: 0.544 | Acc: 85.938% (55/64)
Loss: 0.565 | Acc: 85.009% (5495/6464)
Loss: 0.567 | Acc: 84.927% (10925/12864)
Loss: 0.569 | Acc: 84.847% (16345/19264)
Loss: 0.561 | Acc: 85.092% (21838/25664)
Loss: 0.560 | Acc: 85.158% (27305/32064)
Loss: 0.562 | Acc: 85.145% (32750/38464)
Loss: 0.562 | Acc: 85.153% (38203/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4229, Accuracy: 7021/10000 (70.21%)

Epoch: 143
Loss: 0.546 | Acc: 89.062% (57/64)
Loss: 0.497 | Acc: 86.340% (5581/6464)
Loss: 0.501 | Acc: 86.155% (11083/12864)
Loss: 0.501 | Acc: 86.270% (16619/19264)
Loss: 0.508 | Acc: 86.093% (22095/25664)
Loss: 0.508 | Acc: 86.168% (27629/32064)
Loss: 0.508 | Acc: 86.177% (33147/38464)
Loss: 0.510 | Acc: 86.120% (38637/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4024, Accuracy: 7035/10000 (70.35%)

Epoch: 144
Loss: 0.496 | Acc: 89.062% (57/64)
Loss: 0.457 | Acc: 87.686% (5668/6464)
Loss: 0.461 | Acc: 87.267% (11226/12864)
Loss: 0.464 | Acc: 87.225% (16803/19264)
Loss: 0.464 | Acc: 87.309% (22407/25664)
Loss: 0.461 | Acc: 87.422% (28031/32064)
Loss: 0.459 | Acc: 87.378% (33609/38464)
Loss: 0.459 | Acc: 87.397% (39210/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4820, Accuracy: 7056/10000 (70.56%)

Epoch: 145
Loss: 0.419 | Acc: 85.938% (55/64)
Loss: 0.406 | Acc: 88.552% (5724/6464)
Loss: 0.408 | Acc: 88.705% (11411/12864)
Loss: 0.407 | Acc: 88.761% (17099/19264)
Loss: 0.407 | Acc: 88.782% (22785/25664)
Loss: 0.407 | Acc: 88.716% (28446/32064)
Loss: 0.410 | Acc: 88.631% (34091/38464)
Loss: 0.409 | Acc: 88.652% (39773/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5043, Accuracy: 7034/10000 (70.34%)

Epoch: 146
Loss: 0.567 | Acc: 82.812% (53/64)
Loss: 0.366 | Acc: 89.851% (5808/6464)
Loss: 0.369 | Acc: 89.607% (11527/12864)
Loss: 0.374 | Acc: 89.353% (17213/19264)
Loss: 0.370 | Acc: 89.479% (22964/25664)
Loss: 0.370 | Acc: 89.546% (28712/32064)
Loss: 0.370 | Acc: 89.536% (34439/38464)
Loss: 0.367 | Acc: 89.620% (40207/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5407, Accuracy: 7021/10000 (70.21%)

Epoch: 147
Loss: 0.324 | Acc: 92.188% (59/64)
Loss: 0.323 | Acc: 90.671% (5861/6464)
Loss: 0.323 | Acc: 90.796% (11680/12864)
Loss: 0.332 | Acc: 90.459% (17426/19264)
Loss: 0.329 | Acc: 90.613% (23255/25664)
Loss: 0.331 | Acc: 90.594% (29048/32064)
Loss: 0.335 | Acc: 90.539% (34825/38464)
Loss: 0.335 | Acc: 90.502% (40603/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5435, Accuracy: 7006/10000 (70.06%)
torch.Size([100, 10])
Test set: Average loss: 1.5435, Accuracy: 7006/10000 (70.06%)

Epoch: 148
Loss: 0.236 | Acc: 92.188% (59/64)
Loss: 0.311 | Acc: 91.043% (5885/6464)
Loss: 0.314 | Acc: 91.192% (11731/12864)
Loss: 0.316 | Acc: 91.071% (17544/19264)
Loss: 0.315 | Acc: 91.046% (23366/25664)
Loss: 0.315 | Acc: 90.987% (29174/32064)
Loss: 0.318 | Acc: 90.919% (34971/38464)
Loss: 0.319 | Acc: 90.861% (40764/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5576, Accuracy: 7011/10000 (70.11%)
torch.Size([100, 10])
Test set: Average loss: 1.5576, Accuracy: 7011/10000 (70.11%)

Epoch: 149
Loss: 0.388 | Acc: 89.062% (57/64)
Loss: 0.327 | Acc: 90.393% (5843/6464)
Loss: 0.316 | Acc: 90.975% (11703/12864)
Loss: 0.314 | Acc: 91.071% (17544/19264)
Loss: 0.309 | Acc: 91.202% (23406/25664)
Loss: 0.309 | Acc: 91.230% (29252/32064)
Loss: 0.312 | Acc: 91.090% (35037/38464)
Loss: 0.310 | Acc: 91.142% (40890/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5694, Accuracy: 7015/10000 (70.15%)
torch.Size([100, 10])
Test set: Average loss: 1.5694, Accuracy: 7015/10000 (70.15%)

Epoch: 150
Loss: 0.209 | Acc: 93.750% (60/64)
Loss: 1.626 | Acc: 49.350% (3190/6464)
Loss: 1.457 | Acc: 56.475% (7265/12864)
Loss: 1.388 | Acc: 59.432% (11449/19264)
Loss: 1.345 | Acc: 61.460% (15773/25664)
Loss: 1.309 | Acc: 63.033% (20211/32064)
Loss: 1.284 | Acc: 64.081% (24648/38464)
Loss: 1.266 | Acc: 64.803% (29073/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8620, Accuracy: 4463/10000 (44.63%)

Epoch: 151
Loss: 0.905 | Acc: 78.125% (50/64)
Loss: 1.133 | Acc: 70.065% (4529/6464)
Loss: 1.135 | Acc: 70.072% (9014/12864)
Loss: 1.146 | Acc: 69.612% (13410/19264)
Loss: 1.143 | Acc: 69.818% (17918/25664)
Loss: 1.141 | Acc: 70.032% (22455/32064)
Loss: 1.137 | Acc: 70.185% (26996/38464)
Loss: 1.136 | Acc: 70.201% (31495/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3506, Accuracy: 3623/10000 (36.23%)

Epoch: 152
Loss: 1.208 | Acc: 57.812% (37/64)
Loss: 1.096 | Acc: 71.550% (4625/6464)
Loss: 1.090 | Acc: 71.898% (9249/12864)
Loss: 1.110 | Acc: 71.382% (13751/19264)
Loss: 1.117 | Acc: 71.002% (18222/25664)
Loss: 1.122 | Acc: 70.868% (22723/32064)
Loss: 1.124 | Acc: 70.903% (27272/38464)
Loss: 1.118 | Acc: 71.104% (31900/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1651, Accuracy: 3149/10000 (31.49%)

Epoch: 153
Loss: 1.164 | Acc: 60.938% (39/64)
Loss: 1.124 | Acc: 70.529% (4559/6464)
Loss: 1.095 | Acc: 71.587% (9209/12864)
Loss: 1.111 | Acc: 71.283% (13732/19264)
Loss: 1.107 | Acc: 71.524% (18356/25664)
Loss: 1.110 | Acc: 71.404% (22895/32064)
Loss: 1.113 | Acc: 71.321% (27433/38464)
Loss: 1.114 | Acc: 71.311% (31993/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3965, Accuracy: 6034/10000 (60.34%)

Epoch: 154
Loss: 1.195 | Acc: 71.875% (46/64)
Loss: 1.085 | Acc: 71.581% (4627/6464)
Loss: 1.098 | Acc: 71.098% (9146/12864)
Loss: 1.104 | Acc: 71.159% (13708/19264)
Loss: 1.106 | Acc: 71.201% (18273/25664)
Loss: 1.112 | Acc: 71.102% (22798/32064)
Loss: 1.112 | Acc: 71.082% (27341/38464)
Loss: 1.112 | Acc: 71.139% (31916/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5295, Accuracy: 5531/10000 (55.31%)

Epoch: 155
Loss: 1.106 | Acc: 68.750% (44/64)
Loss: 1.109 | Acc: 71.318% (4610/6464)
Loss: 1.112 | Acc: 71.261% (9167/12864)
Loss: 1.098 | Acc: 71.600% (13793/19264)
Loss: 1.104 | Acc: 71.478% (18344/25664)
Loss: 1.104 | Acc: 71.585% (22953/32064)
Loss: 1.108 | Acc: 71.514% (27507/38464)
Loss: 1.109 | Acc: 71.431% (32047/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6159, Accuracy: 5324/10000 (53.24%)

Epoch: 156
Loss: 0.804 | Acc: 84.375% (54/64)
Loss: 1.106 | Acc: 71.658% (4632/6464)
Loss: 1.087 | Acc: 72.233% (9292/12864)
Loss: 1.080 | Acc: 72.446% (13956/19264)
Loss: 1.085 | Acc: 72.198% (18529/25664)
Loss: 1.091 | Acc: 71.975% (23078/32064)
Loss: 1.098 | Acc: 71.787% (27612/38464)
Loss: 1.102 | Acc: 71.645% (32143/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3144, Accuracy: 6406/10000 (64.06%)

Epoch: 157
Loss: 0.943 | Acc: 76.562% (49/64)
Loss: 1.092 | Acc: 71.782% (4640/6464)
Loss: 1.089 | Acc: 72.069% (9271/12864)
Loss: 1.098 | Acc: 71.766% (13825/19264)
Loss: 1.103 | Acc: 71.587% (18372/25664)
Loss: 1.105 | Acc: 71.582% (22952/32064)
Loss: 1.103 | Acc: 71.649% (27559/38464)
Loss: 1.102 | Acc: 71.677% (32157/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3918, Accuracy: 6141/10000 (61.41%)

Epoch: 158
Loss: 1.445 | Acc: 60.938% (39/64)
Loss: 1.095 | Acc: 71.813% (4642/6464)
Loss: 1.098 | Acc: 71.517% (9200/12864)
Loss: 1.096 | Acc: 71.709% (13814/19264)
Loss: 1.094 | Acc: 71.723% (18407/25664)
Loss: 1.095 | Acc: 71.797% (23021/32064)
Loss: 1.096 | Acc: 71.794% (27615/38464)
Loss: 1.100 | Acc: 71.735% (32183/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5301, Accuracy: 5656/10000 (56.56%)

Epoch: 159
Loss: 1.085 | Acc: 75.000% (48/64)
Loss: 1.084 | Acc: 72.184% (4666/6464)
Loss: 1.086 | Acc: 72.178% (9285/12864)
Loss: 1.083 | Acc: 72.316% (13931/19264)
Loss: 1.092 | Acc: 72.097% (18503/25664)
Loss: 1.089 | Acc: 72.190% (23147/32064)
Loss: 1.095 | Acc: 72.047% (27712/38464)
Loss: 1.098 | Acc: 71.884% (32250/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5645, Accuracy: 5518/10000 (55.18%)

Epoch: 160
Loss: 1.241 | Acc: 65.625% (42/64)
Loss: 1.097 | Acc: 72.107% (4661/6464)
Loss: 1.095 | Acc: 71.968% (9258/12864)
Loss: 1.086 | Acc: 72.150% (13899/19264)
Loss: 1.088 | Acc: 71.937% (18462/25664)
Loss: 1.086 | Acc: 72.043% (23100/32064)
Loss: 1.090 | Acc: 71.969% (27682/38464)
Loss: 1.094 | Acc: 71.848% (32234/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5954, Accuracy: 5349/10000 (53.49%)

Epoch: 161
Loss: 1.584 | Acc: 56.250% (36/64)
Loss: 1.093 | Acc: 72.293% (4673/6464)
Loss: 1.089 | Acc: 72.427% (9317/12864)
Loss: 1.098 | Acc: 72.155% (13900/19264)
Loss: 1.098 | Acc: 72.136% (18513/25664)
Loss: 1.097 | Acc: 72.081% (23112/32064)
Loss: 1.100 | Acc: 71.958% (27678/38464)
Loss: 1.098 | Acc: 71.980% (32293/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4732, Accuracy: 5667/10000 (56.67%)

Epoch: 162
Loss: 1.172 | Acc: 67.188% (43/64)
Loss: 1.062 | Acc: 73.082% (4724/6464)
Loss: 1.068 | Acc: 72.940% (9383/12864)
Loss: 1.066 | Acc: 73.007% (14064/19264)
Loss: 1.076 | Acc: 72.724% (18664/25664)
Loss: 1.084 | Acc: 72.436% (23226/32064)
Loss: 1.085 | Acc: 72.312% (27814/38464)
Loss: 1.089 | Acc: 72.238% (32409/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4035, Accuracy: 6234/10000 (62.34%)

Epoch: 163
Loss: 0.938 | Acc: 75.000% (48/64)
Loss: 1.044 | Acc: 73.298% (4738/6464)
Loss: 1.055 | Acc: 73.243% (9422/12864)
Loss: 1.066 | Acc: 72.950% (14053/19264)
Loss: 1.075 | Acc: 72.592% (18630/25664)
Loss: 1.077 | Acc: 72.636% (23290/32064)
Loss: 1.082 | Acc: 72.517% (27893/38464)
Loss: 1.086 | Acc: 72.410% (32486/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4783, Accuracy: 5839/10000 (58.39%)

Epoch: 164
Loss: 1.134 | Acc: 68.750% (44/64)
Loss: 1.071 | Acc: 72.757% (4703/6464)
Loss: 1.049 | Acc: 73.469% (9451/12864)
Loss: 1.067 | Acc: 72.955% (14054/19264)
Loss: 1.073 | Acc: 72.623% (18638/25664)
Loss: 1.073 | Acc: 72.624% (23286/32064)
Loss: 1.078 | Acc: 72.533% (27899/38464)
Loss: 1.080 | Acc: 72.481% (32518/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3541, Accuracy: 6290/10000 (62.90%)

Epoch: 165
Loss: 1.365 | Acc: 67.188% (43/64)
Loss: 1.083 | Acc: 72.649% (4696/6464)
Loss: 1.075 | Acc: 72.683% (9350/12864)
Loss: 1.070 | Acc: 72.929% (14049/19264)
Loss: 1.071 | Acc: 72.845% (18695/25664)
Loss: 1.075 | Acc: 72.730% (23320/32064)
Loss: 1.072 | Acc: 72.769% (27990/38464)
Loss: 1.073 | Acc: 72.718% (32624/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3107, Accuracy: 6448/10000 (64.48%)

Epoch: 166
Loss: 1.292 | Acc: 60.938% (39/64)
Loss: 1.042 | Acc: 73.623% (4759/6464)
Loss: 1.048 | Acc: 73.500% (9455/12864)
Loss: 1.045 | Acc: 73.697% (14197/19264)
Loss: 1.054 | Acc: 73.543% (18874/25664)
Loss: 1.058 | Acc: 73.422% (23542/32064)
Loss: 1.064 | Acc: 73.209% (28159/38464)
Loss: 1.067 | Acc: 73.088% (32790/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6807, Accuracy: 5060/10000 (50.60%)

Epoch: 167
Loss: 0.994 | Acc: 70.312% (45/64)
Loss: 1.060 | Acc: 72.772% (4704/6464)
Loss: 1.065 | Acc: 72.746% (9358/12864)
Loss: 1.065 | Acc: 73.085% (14079/19264)
Loss: 1.061 | Acc: 73.188% (18783/25664)
Loss: 1.061 | Acc: 73.179% (23464/32064)
Loss: 1.061 | Acc: 73.235% (28169/38464)
Loss: 1.065 | Acc: 73.141% (32814/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3973, Accuracy: 6232/10000 (62.32%)

Epoch: 168
Loss: 0.789 | Acc: 84.375% (54/64)
Loss: 1.044 | Acc: 73.979% (4782/6464)
Loss: 1.057 | Acc: 73.274% (9426/12864)
Loss: 1.054 | Acc: 73.365% (14133/19264)
Loss: 1.054 | Acc: 73.371% (18830/25664)
Loss: 1.057 | Acc: 73.322% (23510/32064)
Loss: 1.060 | Acc: 73.219% (28163/38464)
Loss: 1.059 | Acc: 73.328% (32898/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2088, Accuracy: 6847/10000 (68.47%)

Epoch: 169
Loss: 1.030 | Acc: 68.750% (44/64)
Loss: 1.027 | Acc: 74.428% (4811/6464)
Loss: 1.044 | Acc: 73.710% (9482/12864)
Loss: 1.056 | Acc: 73.328% (14126/19264)
Loss: 1.050 | Acc: 73.453% (18851/25664)
Loss: 1.055 | Acc: 73.391% (23532/32064)
Loss: 1.051 | Acc: 73.580% (28302/38464)
Loss: 1.054 | Acc: 73.478% (32965/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3819, Accuracy: 6267/10000 (62.67%)

Epoch: 170
Loss: 1.478 | Acc: 60.938% (39/64)
Loss: 1.033 | Acc: 74.335% (4805/6464)
Loss: 1.035 | Acc: 74.160% (9540/12864)
Loss: 1.043 | Acc: 73.993% (14254/19264)
Loss: 1.044 | Acc: 73.831% (18948/25664)
Loss: 1.045 | Acc: 73.724% (23639/32064)
Loss: 1.041 | Acc: 73.895% (28423/38464)
Loss: 1.045 | Acc: 73.745% (33085/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5098, Accuracy: 5881/10000 (58.81%)

Epoch: 171
Loss: 1.165 | Acc: 68.750% (44/64)
Loss: 1.001 | Acc: 75.062% (4852/6464)
Loss: 1.017 | Acc: 74.751% (9616/12864)
Loss: 1.020 | Acc: 74.564% (14364/19264)
Loss: 1.028 | Acc: 74.318% (19073/25664)
Loss: 1.033 | Acc: 74.158% (23778/32064)
Loss: 1.035 | Acc: 74.168% (28528/38464)
Loss: 1.036 | Acc: 74.173% (33277/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2940, Accuracy: 6562/10000 (65.62%)

Epoch: 172
Loss: 1.253 | Acc: 67.188% (43/64)
Loss: 1.022 | Acc: 74.397% (4809/6464)
Loss: 1.017 | Acc: 74.526% (9587/12864)
Loss: 1.016 | Acc: 74.574% (14366/19264)
Loss: 1.018 | Acc: 74.622% (19151/25664)
Loss: 1.019 | Acc: 74.663% (23940/32064)
Loss: 1.021 | Acc: 74.566% (28681/38464)
Loss: 1.025 | Acc: 74.416% (33386/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5354, Accuracy: 5736/10000 (57.36%)

Epoch: 173
Loss: 0.823 | Acc: 82.812% (53/64)
Loss: 1.015 | Acc: 74.551% (4819/6464)
Loss: 1.012 | Acc: 74.697% (9609/12864)
Loss: 1.014 | Acc: 74.772% (14404/19264)
Loss: 1.017 | Acc: 74.731% (19179/25664)
Loss: 1.018 | Acc: 74.701% (23952/32064)
Loss: 1.019 | Acc: 74.665% (28719/38464)
Loss: 1.018 | Acc: 74.719% (33522/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6658, Accuracy: 5249/10000 (52.49%)

Epoch: 174
Loss: 1.187 | Acc: 70.312% (45/64)
Loss: 1.008 | Acc: 74.969% (4846/6464)
Loss: 1.004 | Acc: 75.039% (9653/12864)
Loss: 0.995 | Acc: 75.166% (14480/19264)
Loss: 1.003 | Acc: 74.969% (19240/25664)
Loss: 1.004 | Acc: 75.000% (24048/32064)
Loss: 1.002 | Acc: 75.096% (28885/38464)
Loss: 1.004 | Acc: 74.998% (33647/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3142, Accuracy: 6473/10000 (64.73%)

Epoch: 175
Loss: 1.194 | Acc: 71.875% (46/64)
Loss: 0.977 | Acc: 75.619% (4888/6464)
Loss: 0.969 | Acc: 75.902% (9764/12864)
Loss: 0.980 | Acc: 75.680% (14579/19264)
Loss: 0.987 | Acc: 75.475% (19370/25664)
Loss: 0.982 | Acc: 75.627% (24249/32064)
Loss: 0.984 | Acc: 75.601% (29079/38464)
Loss: 0.989 | Acc: 75.530% (33886/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2305, Accuracy: 6781/10000 (67.81%)

Epoch: 176
Loss: 1.058 | Acc: 73.438% (47/64)
Loss: 0.984 | Acc: 76.191% (4925/6464)
Loss: 0.990 | Acc: 75.536% (9717/12864)
Loss: 0.984 | Acc: 75.737% (14590/19264)
Loss: 0.985 | Acc: 75.709% (19430/25664)
Loss: 0.987 | Acc: 75.671% (24263/32064)
Loss: 0.983 | Acc: 75.855% (29177/38464)
Loss: 0.983 | Acc: 75.827% (34019/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2732, Accuracy: 6694/10000 (66.94%)

Epoch: 177
Loss: 1.018 | Acc: 76.562% (49/64)
Loss: 0.995 | Acc: 75.139% (4857/6464)
Loss: 0.966 | Acc: 76.135% (9794/12864)
Loss: 0.969 | Acc: 76.121% (14664/19264)
Loss: 0.969 | Acc: 76.153% (19544/25664)
Loss: 0.971 | Acc: 76.191% (24430/32064)
Loss: 0.976 | Acc: 75.983% (29226/38464)
Loss: 0.974 | Acc: 76.126% (34153/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3324, Accuracy: 6378/10000 (63.78%)

Epoch: 178
Loss: 0.763 | Acc: 82.812% (53/64)
Loss: 0.915 | Acc: 77.274% (4995/6464)
Loss: 0.940 | Acc: 76.726% (9870/12864)
Loss: 0.948 | Acc: 76.552% (14747/19264)
Loss: 0.953 | Acc: 76.418% (19612/25664)
Loss: 0.954 | Acc: 76.503% (24530/32064)
Loss: 0.954 | Acc: 76.513% (29430/38464)
Loss: 0.958 | Acc: 76.433% (34291/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3600, Accuracy: 6348/10000 (63.48%)

Epoch: 179
Loss: 0.932 | Acc: 76.562% (49/64)
Loss: 0.949 | Acc: 76.918% (4972/6464)
Loss: 0.941 | Acc: 76.975% (9902/12864)
Loss: 0.935 | Acc: 77.175% (14867/19264)
Loss: 0.937 | Acc: 77.120% (19792/25664)
Loss: 0.935 | Acc: 77.174% (24745/32064)
Loss: 0.933 | Acc: 77.176% (29685/38464)
Loss: 0.936 | Acc: 77.126% (34602/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1965, Accuracy: 6954/10000 (69.54%)

Epoch: 180
Loss: 0.721 | Acc: 79.688% (51/64)
Loss: 0.908 | Acc: 77.553% (5013/6464)
Loss: 0.917 | Acc: 77.309% (9945/12864)
Loss: 0.911 | Acc: 77.476% (14925/19264)
Loss: 0.912 | Acc: 77.591% (19913/25664)
Loss: 0.919 | Acc: 77.492% (24847/32064)
Loss: 0.924 | Acc: 77.431% (29783/38464)
Loss: 0.926 | Acc: 77.374% (34713/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2449, Accuracy: 6845/10000 (68.45%)

Epoch: 181
Loss: 0.991 | Acc: 70.312% (45/64)
Loss: 0.882 | Acc: 78.419% (5069/6464)
Loss: 0.879 | Acc: 78.249% (10066/12864)
Loss: 0.887 | Acc: 78.058% (15037/19264)
Loss: 0.897 | Acc: 77.887% (19989/25664)
Loss: 0.898 | Acc: 77.947% (24993/32064)
Loss: 0.906 | Acc: 77.816% (29931/38464)
Loss: 0.911 | Acc: 77.661% (34842/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3638, Accuracy: 6436/10000 (64.36%)

Epoch: 182
Loss: 1.164 | Acc: 67.188% (43/64)
Loss: 0.882 | Acc: 78.264% (5059/6464)
Loss: 0.861 | Acc: 78.879% (10147/12864)
Loss: 0.871 | Acc: 78.675% (15156/19264)
Loss: 0.880 | Acc: 78.456% (20135/25664)
Loss: 0.885 | Acc: 78.378% (25131/32064)
Loss: 0.888 | Acc: 78.310% (30121/38464)
Loss: 0.891 | Acc: 78.259% (35110/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2703, Accuracy: 6872/10000 (68.72%)

Epoch: 183
Loss: 0.882 | Acc: 79.688% (51/64)
Loss: 0.867 | Acc: 78.806% (5094/6464)
Loss: 0.864 | Acc: 78.809% (10138/12864)
Loss: 0.871 | Acc: 78.701% (15161/19264)
Loss: 0.872 | Acc: 78.709% (20200/25664)
Loss: 0.875 | Acc: 78.621% (25209/32064)
Loss: 0.876 | Acc: 78.518% (30201/38464)
Loss: 0.878 | Acc: 78.497% (35217/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1571, Accuracy: 7200/10000 (72.00%)

Epoch: 184
Loss: 0.773 | Acc: 82.812% (53/64)
Loss: 0.825 | Acc: 79.718% (5153/6464)
Loss: 0.838 | Acc: 79.244% (10194/12864)
Loss: 0.846 | Acc: 79.200% (15257/19264)
Loss: 0.844 | Acc: 79.278% (20346/25664)
Loss: 0.847 | Acc: 79.170% (25385/32064)
Loss: 0.847 | Acc: 79.139% (30440/38464)
Loss: 0.848 | Acc: 79.193% (35529/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2093, Accuracy: 7100/10000 (71.00%)

Epoch: 185
Loss: 0.888 | Acc: 81.250% (52/64)
Loss: 0.786 | Acc: 80.863% (5227/6464)
Loss: 0.794 | Acc: 80.574% (10365/12864)
Loss: 0.794 | Acc: 80.596% (15526/19264)
Loss: 0.809 | Acc: 80.202% (20583/25664)
Loss: 0.814 | Acc: 80.043% (25665/32064)
Loss: 0.817 | Acc: 79.976% (30762/38464)
Loss: 0.822 | Acc: 79.864% (35830/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1980, Accuracy: 7059/10000 (70.59%)

Epoch: 186
Loss: 0.409 | Acc: 93.750% (60/64)
Loss: 0.769 | Acc: 80.863% (5227/6464)
Loss: 0.780 | Acc: 80.675% (10378/12864)
Loss: 0.791 | Acc: 80.612% (15529/19264)
Loss: 0.796 | Acc: 80.482% (20655/25664)
Loss: 0.798 | Acc: 80.424% (25787/32064)
Loss: 0.797 | Acc: 80.421% (30933/38464)
Loss: 0.798 | Acc: 80.425% (36082/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2102, Accuracy: 7181/10000 (71.81%)

Epoch: 187
Loss: 0.625 | Acc: 87.500% (56/64)
Loss: 0.770 | Acc: 80.817% (5224/6464)
Loss: 0.758 | Acc: 81.343% (10464/12864)
Loss: 0.755 | Acc: 81.411% (15683/19264)
Loss: 0.761 | Acc: 81.316% (20869/25664)
Loss: 0.764 | Acc: 81.206% (26038/32064)
Loss: 0.767 | Acc: 81.146% (31212/38464)
Loss: 0.769 | Acc: 81.067% (36370/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2770, Accuracy: 6939/10000 (69.39%)

Epoch: 188
Loss: 0.707 | Acc: 84.375% (54/64)
Loss: 0.739 | Acc: 81.420% (5263/6464)
Loss: 0.731 | Acc: 81.678% (10507/12864)
Loss: 0.736 | Acc: 81.582% (15716/19264)
Loss: 0.733 | Acc: 81.706% (20969/25664)
Loss: 0.734 | Acc: 81.684% (26191/32064)
Loss: 0.734 | Acc: 81.723% (31434/38464)
Loss: 0.737 | Acc: 81.649% (36631/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2489, Accuracy: 7195/10000 (71.95%)

Epoch: 189
Loss: 0.664 | Acc: 81.250% (52/64)
Loss: 0.659 | Acc: 83.338% (5387/6464)
Loss: 0.669 | Acc: 83.061% (10685/12864)
Loss: 0.678 | Acc: 82.927% (15975/19264)
Loss: 0.683 | Acc: 82.797% (21249/25664)
Loss: 0.688 | Acc: 82.675% (26509/32064)
Loss: 0.693 | Acc: 82.540% (31748/38464)
Loss: 0.698 | Acc: 82.344% (36943/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2779, Accuracy: 7253/10000 (72.53%)

Epoch: 190
Loss: 0.603 | Acc: 81.250% (52/64)
Loss: 0.627 | Acc: 83.973% (5428/6464)
Loss: 0.638 | Acc: 83.551% (10748/12864)
Loss: 0.647 | Acc: 83.300% (16047/19264)
Loss: 0.647 | Acc: 83.268% (21370/25664)
Loss: 0.644 | Acc: 83.402% (26742/32064)
Loss: 0.645 | Acc: 83.418% (32086/38464)
Loss: 0.646 | Acc: 83.403% (37418/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3402, Accuracy: 7032/10000 (70.32%)

Epoch: 191
Loss: 0.693 | Acc: 81.250% (52/64)
Loss: 0.595 | Acc: 84.390% (5455/6464)
Loss: 0.585 | Acc: 84.733% (10900/12864)
Loss: 0.589 | Acc: 84.603% (16298/19264)
Loss: 0.594 | Acc: 84.578% (21706/25664)
Loss: 0.596 | Acc: 84.550% (27110/32064)
Loss: 0.606 | Acc: 84.313% (32430/38464)
Loss: 0.606 | Acc: 84.259% (37802/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3760, Accuracy: 7018/10000 (70.18%)

Epoch: 192
Loss: 0.664 | Acc: 81.250% (52/64)
Loss: 0.547 | Acc: 85.319% (5515/6464)
Loss: 0.539 | Acc: 85.502% (10999/12864)
Loss: 0.539 | Acc: 85.569% (16484/19264)
Loss: 0.545 | Acc: 85.404% (21918/25664)
Loss: 0.553 | Acc: 85.276% (27343/32064)
Loss: 0.551 | Acc: 85.381% (32841/38464)
Loss: 0.553 | Acc: 85.349% (38291/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3987, Accuracy: 7098/10000 (70.98%)

Epoch: 193
Loss: 0.422 | Acc: 85.938% (55/64)
Loss: 0.498 | Acc: 86.417% (5586/6464)
Loss: 0.510 | Acc: 86.124% (11079/12864)
Loss: 0.505 | Acc: 86.368% (16638/19264)
Loss: 0.504 | Acc: 86.436% (22183/25664)
Loss: 0.501 | Acc: 86.483% (27730/32064)
Loss: 0.500 | Acc: 86.478% (33263/38464)
Loss: 0.500 | Acc: 86.488% (38802/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4544, Accuracy: 7051/10000 (70.51%)

Epoch: 194
Loss: 0.424 | Acc: 85.938% (55/64)
Loss: 0.436 | Acc: 87.608% (5663/6464)
Loss: 0.435 | Acc: 87.772% (11291/12864)
Loss: 0.433 | Acc: 88.014% (16955/19264)
Loss: 0.443 | Acc: 87.726% (22514/25664)
Loss: 0.440 | Acc: 87.768% (28142/32064)
Loss: 0.443 | Acc: 87.708% (33736/38464)
Loss: 0.444 | Acc: 87.736% (39362/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4947, Accuracy: 7078/10000 (70.78%)

Epoch: 195
Loss: 0.370 | Acc: 89.062% (57/64)
Loss: 0.387 | Acc: 88.923% (5748/6464)
Loss: 0.391 | Acc: 88.954% (11443/12864)
Loss: 0.396 | Acc: 88.756% (17098/19264)
Loss: 0.396 | Acc: 88.805% (22791/25664)
Loss: 0.399 | Acc: 88.748% (28456/32064)
Loss: 0.399 | Acc: 88.790% (34152/38464)
Loss: 0.399 | Acc: 88.835% (39855/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5216, Accuracy: 7061/10000 (70.61%)

Epoch: 196
Loss: 0.437 | Acc: 84.375% (54/64)
Loss: 0.340 | Acc: 89.882% (5810/6464)
Loss: 0.346 | Acc: 90.058% (11585/12864)
Loss: 0.360 | Acc: 89.753% (17290/19264)
Loss: 0.361 | Acc: 89.748% (23033/25664)
Loss: 0.357 | Acc: 89.842% (28807/32064)
Loss: 0.356 | Acc: 89.874% (34569/38464)
Loss: 0.355 | Acc: 89.932% (40347/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5406, Accuracy: 6989/10000 (69.89%)

Epoch: 197
Loss: 0.236 | Acc: 93.750% (60/64)
Loss: 0.314 | Acc: 91.105% (5889/6464)
Loss: 0.315 | Acc: 91.053% (11713/12864)
Loss: 0.319 | Acc: 91.009% (17532/19264)
Loss: 0.325 | Acc: 90.726% (23284/25664)
Loss: 0.326 | Acc: 90.747% (29097/32064)
Loss: 0.326 | Acc: 90.719% (34894/38464)
Loss: 0.326 | Acc: 90.745% (40712/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5619, Accuracy: 6991/10000 (69.91%)
torch.Size([100, 10])
Test set: Average loss: 1.5619, Accuracy: 6991/10000 (69.91%)

Epoch: 198
Loss: 0.313 | Acc: 89.062% (57/64)
Loss: 0.317 | Acc: 90.687% (5862/6464)
Loss: 0.312 | Acc: 91.091% (11718/12864)
Loss: 0.310 | Acc: 91.139% (17557/19264)
Loss: 0.313 | Acc: 90.937% (23338/25664)
Loss: 0.312 | Acc: 90.987% (29174/32064)
Loss: 0.313 | Acc: 90.955% (34985/38464)
Loss: 0.312 | Acc: 90.937% (40798/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5637, Accuracy: 6979/10000 (69.79%)
torch.Size([100, 10])
Test set: Average loss: 1.5637, Accuracy: 6979/10000 (69.79%)

Epoch: 199
Loss: 0.231 | Acc: 95.312% (61/64)
Loss: 0.318 | Acc: 90.594% (5856/6464)
Loss: 0.310 | Acc: 91.006% (11707/12864)
Loss: 0.308 | Acc: 91.175% (17564/19264)
Loss: 0.304 | Acc: 91.389% (23454/25664)
Loss: 0.304 | Acc: 91.302% (29275/32064)
Loss: 0.302 | Acc: 91.426% (35166/38464)
Loss: 0.303 | Acc: 91.421% (41015/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5736, Accuracy: 6999/10000 (69.99%)
torch.Size([100, 10])
Test set: Average loss: 1.5736, Accuracy: 6999/10000 (69.99%)
7393
10000
-1.2678014039993286
