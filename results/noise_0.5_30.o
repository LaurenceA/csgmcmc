==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.418 | Acc: 12.500% (8/64)
Loss: 2.915 | Acc: 12.051% (779/6464)
Loss: 2.591 | Acc: 13.612% (1751/12864)
Loss: 2.481 | Acc: 14.229% (2741/19264)
Loss: 2.419 | Acc: 15.243% (3912/25664)
Loss: 2.382 | Acc: 15.921% (5105/32064)
Loss: 2.356 | Acc: 16.382% (6301/38464)
Loss: 2.334 | Acc: 16.853% (7561/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2291, Accuracy: 1972/10000 (19.72%)

Epoch: 1
Loss: 2.344 | Acc: 7.812% (5/64)
Loss: 2.202 | Acc: 21.055% (1361/6464)
Loss: 2.194 | Acc: 21.440% (2758/12864)
Loss: 2.190 | Acc: 21.688% (4178/19264)
Loss: 2.189 | Acc: 21.778% (5589/25664)
Loss: 2.187 | Acc: 21.838% (7002/32064)
Loss: 2.183 | Acc: 22.145% (8518/38464)
Loss: 2.182 | Acc: 22.412% (10055/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2227, Accuracy: 2105/10000 (21.05%)

Epoch: 2
Loss: 2.080 | Acc: 26.562% (17/64)
Loss: 2.148 | Acc: 24.118% (1559/6464)
Loss: 2.154 | Acc: 24.137% (3105/12864)
Loss: 2.151 | Acc: 24.450% (4710/19264)
Loss: 2.148 | Acc: 24.567% (6305/25664)
Loss: 2.149 | Acc: 24.623% (7895/32064)
Loss: 2.147 | Acc: 24.800% (9539/38464)
Loss: 2.145 | Acc: 25.013% (11222/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1521, Accuracy: 2446/10000 (24.46%)

Epoch: 3
Loss: 2.376 | Acc: 10.938% (7/64)
Loss: 2.132 | Acc: 25.897% (1674/6464)
Loss: 2.134 | Acc: 25.871% (3328/12864)
Loss: 2.129 | Acc: 26.023% (5013/19264)
Loss: 2.126 | Acc: 26.301% (6750/25664)
Loss: 2.126 | Acc: 26.435% (8476/32064)
Loss: 2.124 | Acc: 26.537% (10207/38464)
Loss: 2.121 | Acc: 26.739% (11996/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1490, Accuracy: 2509/10000 (25.09%)

Epoch: 4
Loss: 2.004 | Acc: 34.375% (22/64)
Loss: 2.098 | Acc: 28.589% (1848/6464)
Loss: 2.091 | Acc: 28.801% (3705/12864)
Loss: 2.096 | Acc: 28.649% (5519/19264)
Loss: 2.097 | Acc: 28.472% (7307/25664)
Loss: 2.099 | Acc: 28.371% (9097/32064)
Loss: 2.097 | Acc: 28.437% (10938/38464)
Loss: 2.096 | Acc: 28.618% (12839/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1249, Accuracy: 2687/10000 (26.87%)

Epoch: 5
Loss: 2.041 | Acc: 29.688% (19/64)
Loss: 2.068 | Acc: 30.028% (1941/6464)
Loss: 2.081 | Acc: 29.540% (3800/12864)
Loss: 2.079 | Acc: 29.589% (5700/19264)
Loss: 2.077 | Acc: 29.633% (7605/25664)
Loss: 2.075 | Acc: 29.868% (9577/32064)
Loss: 2.074 | Acc: 30.051% (11559/38464)
Loss: 2.072 | Acc: 30.271% (13581/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2119, Accuracy: 2428/10000 (24.28%)

Epoch: 6
Loss: 1.948 | Acc: 35.938% (23/64)
Loss: 2.036 | Acc: 32.611% (2108/6464)
Loss: 2.043 | Acc: 32.478% (4178/12864)
Loss: 2.049 | Acc: 32.325% (6227/19264)
Loss: 2.047 | Acc: 32.489% (8338/25664)
Loss: 2.042 | Acc: 32.647% (10468/32064)
Loss: 2.043 | Acc: 32.628% (12550/38464)
Loss: 2.041 | Acc: 32.761% (14698/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0918, Accuracy: 3009/10000 (30.09%)

Epoch: 7
Loss: 2.026 | Acc: 35.938% (23/64)
Loss: 2.019 | Acc: 33.895% (2191/6464)
Loss: 2.015 | Acc: 34.087% (4385/12864)
Loss: 2.017 | Acc: 34.276% (6603/19264)
Loss: 2.016 | Acc: 34.270% (8795/25664)
Loss: 2.016 | Acc: 34.484% (11057/32064)
Loss: 2.016 | Acc: 34.391% (13228/38464)
Loss: 2.015 | Acc: 34.509% (15482/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0719, Accuracy: 3104/10000 (31.04%)

Epoch: 8
Loss: 2.137 | Acc: 26.562% (17/64)
Loss: 1.998 | Acc: 35.458% (2292/6464)
Loss: 1.993 | Acc: 35.541% (4572/12864)
Loss: 1.989 | Acc: 35.657% (6869/19264)
Loss: 1.994 | Acc: 35.536% (9120/25664)
Loss: 1.991 | Acc: 35.791% (11476/32064)
Loss: 1.993 | Acc: 35.761% (13755/38464)
Loss: 1.992 | Acc: 35.822% (16071/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0940, Accuracy: 3225/10000 (32.25%)

Epoch: 9
Loss: 2.101 | Acc: 28.125% (18/64)
Loss: 1.973 | Acc: 37.160% (2402/6464)
Loss: 1.978 | Acc: 36.800% (4734/12864)
Loss: 1.980 | Acc: 36.612% (7053/19264)
Loss: 1.981 | Acc: 36.553% (9381/25664)
Loss: 1.981 | Acc: 36.602% (11736/32064)
Loss: 1.983 | Acc: 36.621% (14086/38464)
Loss: 1.983 | Acc: 36.675% (16454/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2117, Accuracy: 2801/10000 (28.01%)

Epoch: 10
Loss: 1.949 | Acc: 40.625% (26/64)
Loss: 1.978 | Acc: 37.546% (2427/6464)
Loss: 1.976 | Acc: 37.298% (4798/12864)
Loss: 1.971 | Acc: 37.386% (7202/19264)
Loss: 1.971 | Acc: 37.364% (9589/25664)
Loss: 1.968 | Acc: 37.559% (12043/32064)
Loss: 1.968 | Acc: 37.570% (14451/38464)
Loss: 1.968 | Acc: 37.585% (16862/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1903, Accuracy: 2680/10000 (26.80%)

Epoch: 11
Loss: 1.908 | Acc: 46.875% (30/64)
Loss: 1.947 | Acc: 38.830% (2510/6464)
Loss: 1.956 | Acc: 38.394% (4939/12864)
Loss: 1.956 | Acc: 38.517% (7420/19264)
Loss: 1.957 | Acc: 38.548% (9893/25664)
Loss: 1.959 | Acc: 38.507% (12347/32064)
Loss: 1.958 | Acc: 38.514% (14814/38464)
Loss: 1.955 | Acc: 38.559% (17299/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0748, Accuracy: 3249/10000 (32.49%)

Epoch: 12
Loss: 1.931 | Acc: 37.500% (24/64)
Loss: 1.954 | Acc: 38.846% (2511/6464)
Loss: 1.945 | Acc: 39.319% (5058/12864)
Loss: 1.941 | Acc: 39.405% (7591/19264)
Loss: 1.942 | Acc: 39.386% (10108/25664)
Loss: 1.941 | Acc: 39.465% (12654/32064)
Loss: 1.939 | Acc: 39.608% (15235/38464)
Loss: 1.940 | Acc: 39.486% (17715/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0459, Accuracy: 3280/10000 (32.80%)

Epoch: 13
Loss: 2.087 | Acc: 32.812% (21/64)
Loss: 1.923 | Acc: 40.455% (2615/6464)
Loss: 1.925 | Acc: 40.392% (5196/12864)
Loss: 1.927 | Acc: 40.402% (7783/19264)
Loss: 1.927 | Acc: 40.376% (10362/25664)
Loss: 1.927 | Acc: 40.391% (12951/32064)
Loss: 1.928 | Acc: 40.394% (15537/38464)
Loss: 1.928 | Acc: 40.453% (18149/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0700, Accuracy: 3510/10000 (35.10%)

Epoch: 14
Loss: 1.944 | Acc: 40.625% (26/64)
Loss: 1.916 | Acc: 40.548% (2621/6464)
Loss: 1.915 | Acc: 40.617% (5225/12864)
Loss: 1.915 | Acc: 40.833% (7866/19264)
Loss: 1.914 | Acc: 40.968% (10514/25664)
Loss: 1.914 | Acc: 40.984% (13141/32064)
Loss: 1.914 | Acc: 41.098% (15808/38464)
Loss: 1.913 | Acc: 41.213% (18490/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0295, Accuracy: 3369/10000 (33.69%)

Epoch: 15
Loss: 1.925 | Acc: 37.500% (24/64)
Loss: 1.919 | Acc: 40.780% (2636/6464)
Loss: 1.915 | Acc: 41.294% (5312/12864)
Loss: 1.914 | Acc: 41.456% (7986/19264)
Loss: 1.912 | Acc: 41.494% (10649/25664)
Loss: 1.908 | Acc: 41.611% (13342/32064)
Loss: 1.906 | Acc: 41.717% (16046/38464)
Loss: 1.909 | Acc: 41.583% (18656/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0517, Accuracy: 3589/10000 (35.89%)

Epoch: 16
Loss: 2.204 | Acc: 25.000% (16/64)
Loss: 1.888 | Acc: 42.033% (2717/6464)
Loss: 1.899 | Acc: 41.535% (5343/12864)
Loss: 1.903 | Acc: 41.424% (7980/19264)
Loss: 1.905 | Acc: 41.412% (10628/25664)
Loss: 1.904 | Acc: 41.592% (13336/32064)
Loss: 1.902 | Acc: 41.756% (16061/38464)
Loss: 1.897 | Acc: 41.878% (18788/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0690, Accuracy: 3339/10000 (33.39%)

Epoch: 17
Loss: 1.909 | Acc: 39.062% (25/64)
Loss: 1.891 | Acc: 42.621% (2755/6464)
Loss: 1.898 | Acc: 42.180% (5426/12864)
Loss: 1.898 | Acc: 42.390% (8166/19264)
Loss: 1.894 | Acc: 42.495% (10906/25664)
Loss: 1.896 | Acc: 42.356% (13581/32064)
Loss: 1.894 | Acc: 42.403% (16310/38464)
Loss: 1.892 | Acc: 42.453% (19046/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0186, Accuracy: 3683/10000 (36.83%)

Epoch: 18
Loss: 1.994 | Acc: 42.188% (27/64)
Loss: 1.865 | Acc: 43.781% (2830/6464)
Loss: 1.880 | Acc: 43.144% (5550/12864)
Loss: 1.882 | Acc: 43.028% (8289/19264)
Loss: 1.882 | Acc: 42.873% (11003/25664)
Loss: 1.881 | Acc: 42.883% (13750/32064)
Loss: 1.881 | Acc: 42.882% (16494/38464)
Loss: 1.880 | Acc: 42.999% (19291/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9943, Accuracy: 3819/10000 (38.19%)

Epoch: 19
Loss: 2.162 | Acc: 31.250% (20/64)
Loss: 1.867 | Acc: 43.255% (2796/6464)
Loss: 1.866 | Acc: 43.245% (5563/12864)
Loss: 1.860 | Acc: 43.714% (8421/19264)
Loss: 1.863 | Acc: 43.742% (11226/25664)
Loss: 1.868 | Acc: 43.613% (13984/32064)
Loss: 1.872 | Acc: 43.472% (16721/38464)
Loss: 1.872 | Acc: 43.532% (19530/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0947, Accuracy: 3156/10000 (31.56%)

Epoch: 20
Loss: 1.820 | Acc: 43.750% (28/64)
Loss: 1.865 | Acc: 44.028% (2846/6464)
Loss: 1.857 | Acc: 44.325% (5702/12864)
Loss: 1.858 | Acc: 44.279% (8530/19264)
Loss: 1.862 | Acc: 44.144% (11329/25664)
Loss: 1.863 | Acc: 44.130% (14150/32064)
Loss: 1.864 | Acc: 44.101% (16963/38464)
Loss: 1.865 | Acc: 44.031% (19754/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0246, Accuracy: 3507/10000 (35.07%)

Epoch: 21
Loss: 1.898 | Acc: 43.750% (28/64)
Loss: 1.854 | Acc: 44.462% (2874/6464)
Loss: 1.857 | Acc: 44.131% (5677/12864)
Loss: 1.852 | Acc: 44.607% (8593/19264)
Loss: 1.857 | Acc: 44.323% (11375/25664)
Loss: 1.857 | Acc: 44.324% (14212/32064)
Loss: 1.859 | Acc: 44.239% (17016/38464)
Loss: 1.856 | Acc: 44.383% (19912/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9169, Accuracy: 4189/10000 (41.89%)

Epoch: 22
Loss: 1.700 | Acc: 53.125% (34/64)
Loss: 1.841 | Acc: 44.570% (2881/6464)
Loss: 1.852 | Acc: 44.387% (5710/12864)
Loss: 1.850 | Acc: 44.586% (8589/19264)
Loss: 1.853 | Acc: 44.420% (11400/25664)
Loss: 1.851 | Acc: 44.517% (14274/32064)
Loss: 1.850 | Acc: 44.631% (17167/38464)
Loss: 1.849 | Acc: 44.731% (20068/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9652, Accuracy: 3868/10000 (38.68%)

Epoch: 23
Loss: 1.811 | Acc: 45.312% (29/64)
Loss: 1.830 | Acc: 45.699% (2954/6464)
Loss: 1.841 | Acc: 45.227% (5818/12864)
Loss: 1.845 | Acc: 45.074% (8683/19264)
Loss: 1.848 | Acc: 44.915% (11527/25664)
Loss: 1.848 | Acc: 44.944% (14411/32064)
Loss: 1.849 | Acc: 44.808% (17235/38464)
Loss: 1.846 | Acc: 44.911% (20149/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9850, Accuracy: 3799/10000 (37.99%)

Epoch: 24
Loss: 1.731 | Acc: 53.125% (34/64)
Loss: 1.844 | Acc: 45.111% (2916/6464)
Loss: 1.837 | Acc: 45.320% (5830/12864)
Loss: 1.836 | Acc: 45.567% (8778/19264)
Loss: 1.841 | Acc: 45.414% (11655/25664)
Loss: 1.835 | Acc: 45.556% (14607/32064)
Loss: 1.835 | Acc: 45.559% (17524/38464)
Loss: 1.837 | Acc: 45.460% (20395/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9886, Accuracy: 3868/10000 (38.68%)

Epoch: 25
Loss: 1.840 | Acc: 48.438% (31/64)
Loss: 1.812 | Acc: 46.334% (2995/6464)
Loss: 1.822 | Acc: 45.880% (5902/12864)
Loss: 1.825 | Acc: 45.904% (8843/19264)
Loss: 1.824 | Acc: 46.018% (11810/25664)
Loss: 1.827 | Acc: 45.921% (14724/32064)
Loss: 1.829 | Acc: 45.812% (17621/38464)
Loss: 1.829 | Acc: 45.772% (20535/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9355, Accuracy: 3966/10000 (39.66%)

Epoch: 26
Loss: 1.966 | Acc: 42.188% (27/64)
Loss: 1.838 | Acc: 45.405% (2935/6464)
Loss: 1.840 | Acc: 45.414% (5842/12864)
Loss: 1.829 | Acc: 45.858% (8834/19264)
Loss: 1.828 | Acc: 45.913% (11783/25664)
Loss: 1.829 | Acc: 45.852% (14702/32064)
Loss: 1.826 | Acc: 45.994% (17691/38464)
Loss: 1.823 | Acc: 46.157% (20708/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8957, Accuracy: 4241/10000 (42.41%)

Epoch: 27
Loss: 1.850 | Acc: 39.062% (25/64)
Loss: 1.839 | Acc: 45.560% (2945/6464)
Loss: 1.817 | Acc: 46.479% (5979/12864)
Loss: 1.810 | Acc: 46.647% (8986/19264)
Loss: 1.815 | Acc: 46.384% (11904/25664)
Loss: 1.814 | Acc: 46.479% (14903/32064)
Loss: 1.810 | Acc: 46.683% (17956/38464)
Loss: 1.809 | Acc: 46.694% (20949/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9233, Accuracy: 4160/10000 (41.60%)

Epoch: 28
Loss: 1.818 | Acc: 42.188% (27/64)
Loss: 1.805 | Acc: 47.030% (3040/6464)
Loss: 1.811 | Acc: 46.751% (6014/12864)
Loss: 1.804 | Acc: 47.135% (9080/19264)
Loss: 1.809 | Acc: 46.875% (12030/25664)
Loss: 1.807 | Acc: 46.959% (15057/32064)
Loss: 1.806 | Acc: 46.963% (18064/38464)
Loss: 1.804 | Acc: 47.040% (21104/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9144, Accuracy: 4140/10000 (41.40%)

Epoch: 29
Loss: 1.857 | Acc: 42.188% (27/64)
Loss: 1.791 | Acc: 47.602% (3077/6464)
Loss: 1.783 | Acc: 47.956% (6169/12864)
Loss: 1.785 | Acc: 47.939% (9235/19264)
Loss: 1.789 | Acc: 47.685% (12238/25664)
Loss: 1.788 | Acc: 47.751% (15311/32064)
Loss: 1.794 | Acc: 47.554% (18291/38464)
Loss: 1.792 | Acc: 47.606% (21358/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8642, Accuracy: 4422/10000 (44.22%)

Epoch: 30
Loss: 2.052 | Acc: 39.062% (25/64)
Loss: 1.762 | Acc: 48.871% (3159/6464)
Loss: 1.766 | Acc: 48.655% (6259/12864)
Loss: 1.773 | Acc: 48.396% (9323/19264)
Loss: 1.776 | Acc: 48.336% (12405/25664)
Loss: 1.779 | Acc: 48.160% (15442/32064)
Loss: 1.783 | Acc: 47.957% (18446/38464)
Loss: 1.785 | Acc: 47.911% (21495/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8962, Accuracy: 4268/10000 (42.68%)

Epoch: 31
Loss: 1.646 | Acc: 54.688% (35/64)
Loss: 1.760 | Acc: 49.350% (3190/6464)
Loss: 1.766 | Acc: 48.919% (6293/12864)
Loss: 1.772 | Acc: 48.728% (9387/19264)
Loss: 1.773 | Acc: 48.625% (12479/25664)
Loss: 1.772 | Acc: 48.575% (15575/32064)
Loss: 1.771 | Acc: 48.606% (18696/38464)
Loss: 1.775 | Acc: 48.411% (21719/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8800, Accuracy: 4422/10000 (44.22%)

Epoch: 32
Loss: 1.650 | Acc: 56.250% (36/64)
Loss: 1.761 | Acc: 49.226% (3182/6464)
Loss: 1.764 | Acc: 48.803% (6278/12864)
Loss: 1.769 | Acc: 48.681% (9378/19264)
Loss: 1.766 | Acc: 48.847% (12536/25664)
Loss: 1.764 | Acc: 48.940% (15692/32064)
Loss: 1.766 | Acc: 48.846% (18788/38464)
Loss: 1.767 | Acc: 48.834% (21909/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8756, Accuracy: 4477/10000 (44.77%)

Epoch: 33
Loss: 1.792 | Acc: 46.875% (30/64)
Loss: 1.730 | Acc: 50.124% (3240/6464)
Loss: 1.738 | Acc: 49.782% (6404/12864)
Loss: 1.737 | Acc: 49.824% (9598/19264)
Loss: 1.747 | Acc: 49.373% (12671/25664)
Loss: 1.747 | Acc: 49.426% (15848/32064)
Loss: 1.751 | Acc: 49.308% (18966/38464)
Loss: 1.754 | Acc: 49.189% (22068/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9047, Accuracy: 4265/10000 (42.65%)

Epoch: 34
Loss: 1.735 | Acc: 53.125% (34/64)
Loss: 1.729 | Acc: 50.820% (3285/6464)
Loss: 1.730 | Acc: 50.358% (6478/12864)
Loss: 1.733 | Acc: 50.109% (9653/19264)
Loss: 1.738 | Acc: 49.778% (12775/25664)
Loss: 1.741 | Acc: 49.588% (15900/32064)
Loss: 1.742 | Acc: 49.613% (19083/38464)
Loss: 1.743 | Acc: 49.603% (22254/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8742, Accuracy: 4483/10000 (44.83%)

Epoch: 35
Loss: 1.517 | Acc: 60.938% (39/64)
Loss: 1.677 | Acc: 52.367% (3385/6464)
Loss: 1.698 | Acc: 51.477% (6622/12864)
Loss: 1.714 | Acc: 50.638% (9755/19264)
Loss: 1.715 | Acc: 50.662% (13002/25664)
Loss: 1.719 | Acc: 50.558% (16211/32064)
Loss: 1.719 | Acc: 50.536% (19438/38464)
Loss: 1.726 | Acc: 50.265% (22551/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8784, Accuracy: 4422/10000 (44.22%)

Epoch: 36
Loss: 1.715 | Acc: 51.562% (33/64)
Loss: 1.723 | Acc: 50.000% (3232/6464)
Loss: 1.711 | Acc: 50.567% (6505/12864)
Loss: 1.711 | Acc: 50.727% (9772/19264)
Loss: 1.711 | Acc: 50.678% (13006/25664)
Loss: 1.711 | Acc: 50.708% (16259/32064)
Loss: 1.712 | Acc: 50.614% (19468/38464)
Loss: 1.712 | Acc: 50.604% (22703/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8798, Accuracy: 4459/10000 (44.59%)

Epoch: 37
Loss: 1.721 | Acc: 50.000% (32/64)
Loss: 1.688 | Acc: 51.145% (3306/6464)
Loss: 1.688 | Acc: 51.228% (6590/12864)
Loss: 1.690 | Acc: 51.126% (9849/19264)
Loss: 1.693 | Acc: 51.103% (13115/25664)
Loss: 1.701 | Acc: 50.798% (16288/32064)
Loss: 1.703 | Acc: 50.749% (19520/38464)
Loss: 1.701 | Acc: 50.856% (22816/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8850, Accuracy: 4494/10000 (44.94%)

Epoch: 38
Loss: 1.749 | Acc: 46.875% (30/64)
Loss: 1.669 | Acc: 52.027% (3363/6464)
Loss: 1.672 | Acc: 51.936% (6681/12864)
Loss: 1.676 | Acc: 51.921% (10002/19264)
Loss: 1.683 | Acc: 51.633% (13251/25664)
Loss: 1.683 | Acc: 51.584% (16540/32064)
Loss: 1.678 | Acc: 51.822% (19933/38464)
Loss: 1.680 | Acc: 51.683% (23187/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8752, Accuracy: 4516/10000 (45.16%)

Epoch: 39
Loss: 1.741 | Acc: 46.875% (30/64)
Loss: 1.641 | Acc: 53.156% (3436/6464)
Loss: 1.640 | Acc: 53.109% (6832/12864)
Loss: 1.658 | Acc: 52.549% (10123/19264)
Loss: 1.651 | Acc: 52.743% (13536/25664)
Loss: 1.653 | Acc: 52.654% (16883/32064)
Loss: 1.653 | Acc: 52.602% (20233/38464)
Loss: 1.660 | Acc: 52.365% (23493/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8738, Accuracy: 4603/10000 (46.03%)

Epoch: 40
Loss: 1.606 | Acc: 53.125% (34/64)
Loss: 1.631 | Acc: 53.264% (3443/6464)
Loss: 1.633 | Acc: 53.280% (6854/12864)
Loss: 1.634 | Acc: 53.198% (10248/19264)
Loss: 1.636 | Acc: 53.160% (13643/25664)
Loss: 1.633 | Acc: 53.209% (17061/32064)
Loss: 1.637 | Acc: 52.959% (20370/38464)
Loss: 1.638 | Acc: 52.976% (23767/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8684, Accuracy: 4629/10000 (46.29%)

Epoch: 41
Loss: 1.664 | Acc: 48.438% (31/64)
Loss: 1.594 | Acc: 54.347% (3513/6464)
Loss: 1.604 | Acc: 53.724% (6911/12864)
Loss: 1.602 | Acc: 53.706% (10346/19264)
Loss: 1.604 | Acc: 53.717% (13786/25664)
Loss: 1.605 | Acc: 53.792% (17248/32064)
Loss: 1.608 | Acc: 53.632% (20629/38464)
Loss: 1.607 | Acc: 53.664% (24076/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9253, Accuracy: 4468/10000 (44.68%)

Epoch: 42
Loss: 1.460 | Acc: 60.938% (39/64)
Loss: 1.590 | Acc: 53.976% (3489/6464)
Loss: 1.590 | Acc: 54.011% (6948/12864)
Loss: 1.582 | Acc: 54.293% (10459/19264)
Loss: 1.581 | Acc: 54.107% (13886/25664)
Loss: 1.578 | Acc: 54.344% (17425/32064)
Loss: 1.577 | Acc: 54.500% (20963/38464)
Loss: 1.574 | Acc: 54.641% (24514/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9121, Accuracy: 4555/10000 (45.55%)

Epoch: 43
Loss: 1.534 | Acc: 59.375% (38/64)
Loss: 1.497 | Acc: 57.348% (3707/6464)
Loss: 1.514 | Acc: 56.390% (7254/12864)
Loss: 1.522 | Acc: 56.125% (10812/19264)
Loss: 1.526 | Acc: 56.090% (14395/25664)
Loss: 1.527 | Acc: 55.988% (17952/32064)
Loss: 1.532 | Acc: 55.889% (21497/38464)
Loss: 1.534 | Acc: 55.731% (25003/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9581, Accuracy: 4384/10000 (43.84%)

Epoch: 44
Loss: 1.347 | Acc: 59.375% (38/64)
Loss: 1.464 | Acc: 57.704% (3730/6464)
Loss: 1.477 | Acc: 57.152% (7352/12864)
Loss: 1.475 | Acc: 57.366% (11051/19264)
Loss: 1.482 | Acc: 57.119% (14659/25664)
Loss: 1.489 | Acc: 56.830% (18222/32064)
Loss: 1.491 | Acc: 56.819% (21855/38464)
Loss: 1.491 | Acc: 56.874% (25516/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9845, Accuracy: 4413/10000 (44.13%)

Epoch: 45
Loss: 1.426 | Acc: 57.812% (37/64)
Loss: 1.446 | Acc: 57.751% (3733/6464)
Loss: 1.432 | Acc: 58.310% (7501/12864)
Loss: 1.444 | Acc: 57.984% (11170/19264)
Loss: 1.450 | Acc: 57.828% (14841/25664)
Loss: 1.446 | Acc: 58.053% (18614/32064)
Loss: 1.442 | Acc: 58.137% (22362/38464)
Loss: 1.440 | Acc: 58.209% (26115/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9915, Accuracy: 4448/10000 (44.48%)

Epoch: 46
Loss: 1.355 | Acc: 60.938% (39/64)
Loss: 1.409 | Acc: 58.895% (3807/6464)
Loss: 1.399 | Acc: 59.499% (7654/12864)
Loss: 1.399 | Acc: 59.463% (11455/19264)
Loss: 1.399 | Acc: 59.492% (15268/25664)
Loss: 1.398 | Acc: 59.578% (19103/32064)
Loss: 1.400 | Acc: 59.469% (22874/38464)
Loss: 1.399 | Acc: 59.455% (26674/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0066, Accuracy: 4351/10000 (43.51%)

Epoch: 47
Loss: 1.293 | Acc: 67.188% (43/64)
Loss: 1.368 | Acc: 59.870% (3870/6464)
Loss: 1.368 | Acc: 59.966% (7714/12864)
Loss: 1.364 | Acc: 60.039% (11566/19264)
Loss: 1.359 | Acc: 60.365% (15492/25664)
Loss: 1.366 | Acc: 60.105% (19272/32064)
Loss: 1.365 | Acc: 60.095% (23115/38464)
Loss: 1.367 | Acc: 60.048% (26940/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0192, Accuracy: 4355/10000 (43.55%)
torch.Size([100, 10])
Test set: Average loss: 2.0192, Accuracy: 4355/10000 (43.55%)

Epoch: 48
Loss: 1.404 | Acc: 57.812% (37/64)
Loss: 1.320 | Acc: 61.185% (3955/6464)
Loss: 1.331 | Acc: 60.891% (7833/12864)
Loss: 1.339 | Acc: 60.678% (11689/19264)
Loss: 1.344 | Acc: 60.536% (15536/25664)
Loss: 1.339 | Acc: 60.766% (19484/32064)
Loss: 1.338 | Acc: 60.797% (23385/38464)
Loss: 1.337 | Acc: 60.764% (27261/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0327, Accuracy: 4339/10000 (43.39%)
torch.Size([100, 10])
Test set: Average loss: 2.0327, Accuracy: 4339/10000 (43.39%)

Epoch: 49
Loss: 1.307 | Acc: 64.062% (41/64)
Loss: 1.335 | Acc: 60.535% (3913/6464)
Loss: 1.336 | Acc: 60.782% (7819/12864)
Loss: 1.330 | Acc: 60.948% (11741/19264)
Loss: 1.322 | Acc: 61.238% (15716/25664)
Loss: 1.320 | Acc: 61.228% (19632/32064)
Loss: 1.321 | Acc: 61.255% (23561/38464)
Loss: 1.318 | Acc: 61.397% (27545/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0385, Accuracy: 4317/10000 (43.17%)
torch.Size([100, 10])
Test set: Average loss: 2.0385, Accuracy: 4317/10000 (43.17%)

Epoch: 50
Loss: 1.210 | Acc: 67.188% (43/64)
Loss: 2.124 | Acc: 27.723% (1792/6464)
Loss: 2.047 | Acc: 32.743% (4212/12864)
Loss: 2.009 | Acc: 35.268% (6794/19264)
Loss: 1.989 | Acc: 36.534% (9376/25664)
Loss: 1.974 | Acc: 37.534% (12035/32064)
Loss: 1.962 | Acc: 38.277% (14723/38464)
Loss: 1.954 | Acc: 38.875% (17441/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0694, Accuracy: 3390/10000 (33.90%)

Epoch: 51
Loss: 1.965 | Acc: 39.062% (25/64)
Loss: 1.883 | Acc: 43.441% (2808/6464)
Loss: 1.892 | Acc: 42.903% (5519/12864)
Loss: 1.889 | Acc: 42.893% (8263/19264)
Loss: 1.886 | Acc: 43.072% (11054/25664)
Loss: 1.883 | Acc: 43.282% (13878/32064)
Loss: 1.881 | Acc: 43.404% (16695/38464)
Loss: 1.879 | Acc: 43.523% (19526/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9661, Accuracy: 3938/10000 (39.38%)

Epoch: 52
Loss: 1.656 | Acc: 45.312% (29/64)
Loss: 1.860 | Acc: 43.673% (2823/6464)
Loss: 1.862 | Acc: 43.975% (5657/12864)
Loss: 1.863 | Acc: 44.134% (8502/19264)
Loss: 1.867 | Acc: 44.011% (11295/25664)
Loss: 1.866 | Acc: 44.024% (14116/32064)
Loss: 1.864 | Acc: 44.187% (16996/38464)
Loss: 1.866 | Acc: 44.060% (19767/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0459, Accuracy: 3413/10000 (34.13%)

Epoch: 53
Loss: 1.742 | Acc: 45.312% (29/64)
Loss: 1.849 | Acc: 44.307% (2864/6464)
Loss: 1.852 | Acc: 44.582% (5735/12864)
Loss: 1.860 | Acc: 44.352% (8544/19264)
Loss: 1.864 | Acc: 44.171% (11336/25664)
Loss: 1.867 | Acc: 44.043% (14122/32064)
Loss: 1.867 | Acc: 44.057% (16946/38464)
Loss: 1.867 | Acc: 44.051% (19763/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3973, Accuracy: 2681/10000 (26.81%)

Epoch: 54
Loss: 1.722 | Acc: 51.562% (33/64)
Loss: 1.860 | Acc: 44.230% (2859/6464)
Loss: 1.862 | Acc: 44.426% (5715/12864)
Loss: 1.863 | Acc: 44.435% (8560/19264)
Loss: 1.858 | Acc: 44.572% (11439/25664)
Loss: 1.860 | Acc: 44.405% (14238/32064)
Loss: 1.860 | Acc: 44.382% (17071/38464)
Loss: 1.861 | Acc: 44.341% (19893/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0571, Accuracy: 3290/10000 (32.90%)

Epoch: 55
Loss: 1.691 | Acc: 50.000% (32/64)
Loss: 1.850 | Acc: 44.632% (2885/6464)
Loss: 1.855 | Acc: 44.473% (5721/12864)
Loss: 1.852 | Acc: 44.679% (8607/19264)
Loss: 1.855 | Acc: 44.510% (11423/25664)
Loss: 1.855 | Acc: 44.661% (14320/32064)
Loss: 1.854 | Acc: 44.699% (17193/38464)
Loss: 1.857 | Acc: 44.593% (20006/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0288, Accuracy: 3759/10000 (37.59%)

Epoch: 56
Loss: 2.113 | Acc: 31.250% (20/64)
Loss: 1.861 | Acc: 44.493% (2876/6464)
Loss: 1.855 | Acc: 44.815% (5765/12864)
Loss: 1.856 | Acc: 44.783% (8627/19264)
Loss: 1.865 | Acc: 44.292% (11367/25664)
Loss: 1.861 | Acc: 44.520% (14275/32064)
Loss: 1.858 | Acc: 44.605% (17157/38464)
Loss: 1.858 | Acc: 44.559% (19991/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0904, Accuracy: 3633/10000 (36.33%)

Epoch: 57
Loss: 2.058 | Acc: 34.375% (22/64)
Loss: 1.836 | Acc: 45.220% (2923/6464)
Loss: 1.842 | Acc: 45.103% (5802/12864)
Loss: 1.852 | Acc: 44.669% (8605/19264)
Loss: 1.851 | Acc: 44.837% (11507/25664)
Loss: 1.852 | Acc: 44.810% (14368/32064)
Loss: 1.854 | Acc: 44.790% (17228/38464)
Loss: 1.852 | Acc: 44.842% (20118/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0997, Accuracy: 3040/10000 (30.40%)

Epoch: 58
Loss: 1.717 | Acc: 46.875% (30/64)
Loss: 1.843 | Acc: 45.080% (2914/6464)
Loss: 1.850 | Acc: 44.737% (5755/12864)
Loss: 1.851 | Acc: 44.710% (8613/19264)
Loss: 1.850 | Acc: 44.810% (11500/25664)
Loss: 1.852 | Acc: 44.801% (14365/32064)
Loss: 1.852 | Acc: 44.798% (17231/38464)
Loss: 1.851 | Acc: 44.920% (20153/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0452, Accuracy: 3517/10000 (35.17%)

Epoch: 59
Loss: 1.863 | Acc: 46.875% (30/64)
Loss: 1.858 | Acc: 44.585% (2882/6464)
Loss: 1.842 | Acc: 45.328% (5831/12864)
Loss: 1.848 | Acc: 44.980% (8665/19264)
Loss: 1.845 | Acc: 45.012% (11552/25664)
Loss: 1.847 | Acc: 44.904% (14398/32064)
Loss: 1.849 | Acc: 44.852% (17252/38464)
Loss: 1.850 | Acc: 44.820% (20108/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9751, Accuracy: 3743/10000 (37.43%)

Epoch: 60
Loss: 1.977 | Acc: 39.062% (25/64)
Loss: 1.851 | Acc: 44.400% (2870/6464)
Loss: 1.856 | Acc: 44.473% (5721/12864)
Loss: 1.856 | Acc: 44.591% (8590/19264)
Loss: 1.849 | Acc: 45.028% (11556/25664)
Loss: 1.849 | Acc: 45.075% (14453/32064)
Loss: 1.849 | Acc: 45.050% (17328/38464)
Loss: 1.850 | Acc: 44.976% (20178/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1587, Accuracy: 3226/10000 (32.26%)

Epoch: 61
Loss: 1.888 | Acc: 40.625% (26/64)
Loss: 1.832 | Acc: 45.003% (2909/6464)
Loss: 1.833 | Acc: 45.344% (5833/12864)
Loss: 1.839 | Acc: 45.183% (8704/19264)
Loss: 1.846 | Acc: 44.899% (11523/25664)
Loss: 1.845 | Acc: 45.001% (14429/32064)
Loss: 1.845 | Acc: 45.092% (17344/38464)
Loss: 1.844 | Acc: 45.123% (20244/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9815, Accuracy: 3869/10000 (38.69%)

Epoch: 62
Loss: 1.731 | Acc: 45.312% (29/64)
Loss: 1.832 | Acc: 45.545% (2944/6464)
Loss: 1.834 | Acc: 45.577% (5863/12864)
Loss: 1.833 | Acc: 45.671% (8798/19264)
Loss: 1.834 | Acc: 45.554% (11691/25664)
Loss: 1.841 | Acc: 45.325% (14533/32064)
Loss: 1.842 | Acc: 45.198% (17385/38464)
Loss: 1.842 | Acc: 45.210% (20283/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0004, Accuracy: 3769/10000 (37.69%)

Epoch: 63
Loss: 1.613 | Acc: 56.250% (36/64)
Loss: 1.826 | Acc: 45.916% (2968/6464)
Loss: 1.825 | Acc: 46.137% (5935/12864)
Loss: 1.820 | Acc: 46.434% (8945/19264)
Loss: 1.827 | Acc: 46.049% (11818/25664)
Loss: 1.833 | Acc: 45.746% (14668/32064)
Loss: 1.837 | Acc: 45.494% (17499/38464)
Loss: 1.838 | Acc: 45.533% (20428/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9564, Accuracy: 3972/10000 (39.72%)

Epoch: 64
Loss: 2.011 | Acc: 40.625% (26/64)
Loss: 1.829 | Acc: 45.668% (2952/6464)
Loss: 1.832 | Acc: 45.911% (5906/12864)
Loss: 1.827 | Acc: 46.091% (8879/19264)
Loss: 1.832 | Acc: 45.877% (11774/25664)
Loss: 1.833 | Acc: 45.865% (14706/32064)
Loss: 1.833 | Acc: 45.853% (17637/38464)
Loss: 1.836 | Acc: 45.680% (20494/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9608, Accuracy: 3877/10000 (38.77%)

Epoch: 65
Loss: 1.624 | Acc: 57.812% (37/64)
Loss: 1.817 | Acc: 46.720% (3020/6464)
Loss: 1.817 | Acc: 46.533% (5986/12864)
Loss: 1.830 | Acc: 45.754% (8814/19264)
Loss: 1.835 | Acc: 45.550% (11690/25664)
Loss: 1.837 | Acc: 45.550% (14605/32064)
Loss: 1.838 | Acc: 45.557% (17523/38464)
Loss: 1.835 | Acc: 45.703% (20504/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9710, Accuracy: 3932/10000 (39.32%)

Epoch: 66
Loss: 1.924 | Acc: 45.312% (29/64)
Loss: 1.826 | Acc: 46.334% (2995/6464)
Loss: 1.833 | Acc: 45.802% (5892/12864)
Loss: 1.835 | Acc: 45.717% (8807/19264)
Loss: 1.833 | Acc: 45.772% (11747/25664)
Loss: 1.833 | Acc: 45.740% (14666/32064)
Loss: 1.832 | Acc: 45.760% (17601/38464)
Loss: 1.829 | Acc: 45.863% (20576/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3573, Accuracy: 2550/10000 (25.50%)

Epoch: 67
Loss: 1.661 | Acc: 56.250% (36/64)
Loss: 1.830 | Acc: 45.885% (2966/6464)
Loss: 1.832 | Acc: 45.763% (5887/12864)
Loss: 1.827 | Acc: 46.138% (8888/19264)
Loss: 1.826 | Acc: 46.115% (11835/25664)
Loss: 1.824 | Acc: 46.189% (14810/32064)
Loss: 1.825 | Acc: 46.126% (17742/38464)
Loss: 1.823 | Acc: 46.213% (20733/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0182, Accuracy: 3839/10000 (38.39%)

Epoch: 68
Loss: 1.883 | Acc: 40.625% (26/64)
Loss: 1.830 | Acc: 45.699% (2954/6464)
Loss: 1.816 | Acc: 46.346% (5962/12864)
Loss: 1.824 | Acc: 45.967% (8855/19264)
Loss: 1.815 | Acc: 46.489% (11931/25664)
Loss: 1.814 | Acc: 46.607% (14944/32064)
Loss: 1.819 | Acc: 46.345% (17826/38464)
Loss: 1.819 | Acc: 46.362% (20800/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9129, Accuracy: 4282/10000 (42.82%)

Epoch: 69
Loss: 1.942 | Acc: 45.312% (29/64)
Loss: 1.784 | Acc: 48.004% (3103/6464)
Loss: 1.794 | Acc: 47.512% (6112/12864)
Loss: 1.808 | Acc: 46.906% (9036/19264)
Loss: 1.814 | Acc: 46.715% (11989/25664)
Loss: 1.814 | Acc: 46.647% (14957/32064)
Loss: 1.814 | Acc: 46.701% (17963/38464)
Loss: 1.816 | Acc: 46.561% (20889/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9906, Accuracy: 3852/10000 (38.52%)

Epoch: 70
Loss: 1.820 | Acc: 48.438% (31/64)
Loss: 1.787 | Acc: 47.587% (3076/6464)
Loss: 1.791 | Acc: 47.466% (6106/12864)
Loss: 1.804 | Acc: 46.927% (9040/19264)
Loss: 1.806 | Acc: 46.937% (12046/25664)
Loss: 1.811 | Acc: 46.794% (15004/32064)
Loss: 1.811 | Acc: 46.794% (17999/38464)
Loss: 1.811 | Acc: 46.793% (20993/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9189, Accuracy: 4234/10000 (42.34%)

Epoch: 71
Loss: 1.803 | Acc: 45.312% (29/64)
Loss: 1.774 | Acc: 48.144% (3112/6464)
Loss: 1.786 | Acc: 47.862% (6157/12864)
Loss: 1.790 | Acc: 47.773% (9203/19264)
Loss: 1.795 | Acc: 47.650% (12229/25664)
Loss: 1.799 | Acc: 47.483% (15225/32064)
Loss: 1.800 | Acc: 47.343% (18210/38464)
Loss: 1.801 | Acc: 47.227% (21188/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9558, Accuracy: 3946/10000 (39.46%)

Epoch: 72
Loss: 1.816 | Acc: 46.875% (30/64)
Loss: 1.784 | Acc: 48.082% (3108/6464)
Loss: 1.797 | Acc: 47.201% (6072/12864)
Loss: 1.805 | Acc: 46.854% (9026/19264)
Loss: 1.802 | Acc: 47.011% (12065/25664)
Loss: 1.801 | Acc: 47.075% (15094/32064)
Loss: 1.797 | Acc: 47.301% (18194/38464)
Loss: 1.799 | Acc: 47.265% (21205/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9578, Accuracy: 4067/10000 (40.67%)

Epoch: 73
Loss: 1.644 | Acc: 54.688% (35/64)
Loss: 1.801 | Acc: 47.432% (3066/6464)
Loss: 1.793 | Acc: 47.792% (6148/12864)
Loss: 1.796 | Acc: 47.737% (9196/19264)
Loss: 1.798 | Acc: 47.724% (12248/25664)
Loss: 1.796 | Acc: 47.776% (15319/32064)
Loss: 1.795 | Acc: 47.788% (18381/38464)
Loss: 1.792 | Acc: 47.851% (21468/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0185, Accuracy: 3654/10000 (36.54%)

Epoch: 74
Loss: 1.773 | Acc: 48.438% (31/64)
Loss: 1.788 | Acc: 48.144% (3112/6464)
Loss: 1.784 | Acc: 48.197% (6200/12864)
Loss: 1.784 | Acc: 48.116% (9269/19264)
Loss: 1.786 | Acc: 48.024% (12325/25664)
Loss: 1.782 | Acc: 48.216% (15460/32064)
Loss: 1.786 | Acc: 48.110% (18505/38464)
Loss: 1.787 | Acc: 48.070% (21566/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0032, Accuracy: 3850/10000 (38.50%)

Epoch: 75
Loss: 1.597 | Acc: 54.688% (35/64)
Loss: 1.755 | Acc: 49.072% (3172/6464)
Loss: 1.762 | Acc: 48.912% (6292/12864)
Loss: 1.774 | Acc: 48.354% (9315/19264)
Loss: 1.776 | Acc: 48.305% (12397/25664)
Loss: 1.776 | Acc: 48.300% (15487/32064)
Loss: 1.778 | Acc: 48.331% (18590/38464)
Loss: 1.779 | Acc: 48.319% (21678/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9821, Accuracy: 3948/10000 (39.48%)

Epoch: 76
Loss: 1.725 | Acc: 53.125% (34/64)
Loss: 1.765 | Acc: 48.979% (3166/6464)
Loss: 1.758 | Acc: 49.145% (6322/12864)
Loss: 1.769 | Acc: 48.749% (9391/19264)
Loss: 1.773 | Acc: 48.582% (12468/25664)
Loss: 1.774 | Acc: 48.484% (15546/32064)
Loss: 1.775 | Acc: 48.427% (18627/38464)
Loss: 1.772 | Acc: 48.582% (21796/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8867, Accuracy: 4380/10000 (43.80%)

Epoch: 77
Loss: 1.736 | Acc: 50.000% (32/64)
Loss: 1.775 | Acc: 48.175% (3114/6464)
Loss: 1.763 | Acc: 48.826% (6281/12864)
Loss: 1.765 | Acc: 48.816% (9404/19264)
Loss: 1.772 | Acc: 48.617% (12477/25664)
Loss: 1.769 | Acc: 48.668% (15605/32064)
Loss: 1.767 | Acc: 48.801% (18771/38464)
Loss: 1.767 | Acc: 48.828% (21906/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9602, Accuracy: 3949/10000 (39.49%)

Epoch: 78
Loss: 1.835 | Acc: 48.438% (31/64)
Loss: 1.762 | Acc: 48.762% (3152/6464)
Loss: 1.765 | Acc: 48.756% (6272/12864)
Loss: 1.763 | Acc: 48.915% (9423/19264)
Loss: 1.762 | Acc: 48.948% (12562/25664)
Loss: 1.758 | Acc: 49.074% (15735/32064)
Loss: 1.757 | Acc: 49.103% (18887/38464)
Loss: 1.760 | Acc: 48.977% (21973/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8811, Accuracy: 4389/10000 (43.89%)

Epoch: 79
Loss: 1.544 | Acc: 57.812% (37/64)
Loss: 1.740 | Acc: 49.954% (3229/6464)
Loss: 1.749 | Acc: 49.339% (6347/12864)
Loss: 1.745 | Acc: 49.496% (9535/19264)
Loss: 1.747 | Acc: 49.462% (12694/25664)
Loss: 1.747 | Acc: 49.551% (15888/32064)
Loss: 1.748 | Acc: 49.498% (19039/38464)
Loss: 1.746 | Acc: 49.614% (22259/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9125, Accuracy: 4186/10000 (41.86%)

Epoch: 80
Loss: 1.854 | Acc: 43.750% (28/64)
Loss: 1.762 | Acc: 48.716% (3149/6464)
Loss: 1.742 | Acc: 49.518% (6370/12864)
Loss: 1.737 | Acc: 49.792% (9592/19264)
Loss: 1.735 | Acc: 49.918% (12811/25664)
Loss: 1.739 | Acc: 49.754% (15953/32064)
Loss: 1.740 | Acc: 49.706% (19119/38464)
Loss: 1.742 | Acc: 49.641% (22271/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8792, Accuracy: 4463/10000 (44.63%)

Epoch: 81
Loss: 1.863 | Acc: 46.875% (30/64)
Loss: 1.722 | Acc: 50.309% (3252/6464)
Loss: 1.728 | Acc: 50.016% (6434/12864)
Loss: 1.729 | Acc: 50.151% (9661/19264)
Loss: 1.732 | Acc: 49.981% (12827/25664)
Loss: 1.730 | Acc: 50.059% (16051/32064)
Loss: 1.727 | Acc: 50.205% (19311/38464)
Loss: 1.729 | Acc: 50.174% (22510/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8778, Accuracy: 4463/10000 (44.63%)

Epoch: 82
Loss: 1.638 | Acc: 51.562% (33/64)
Loss: 1.724 | Acc: 50.077% (3237/6464)
Loss: 1.724 | Acc: 50.225% (6461/12864)
Loss: 1.718 | Acc: 50.519% (9732/19264)
Loss: 1.718 | Acc: 50.584% (12982/25664)
Loss: 1.719 | Acc: 50.465% (16181/32064)
Loss: 1.722 | Acc: 50.416% (19392/38464)
Loss: 1.721 | Acc: 50.473% (22644/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8838, Accuracy: 4404/10000 (44.04%)

Epoch: 83
Loss: 1.768 | Acc: 48.438% (31/64)
Loss: 1.684 | Acc: 51.980% (3360/6464)
Loss: 1.683 | Acc: 51.749% (6657/12864)
Loss: 1.689 | Acc: 51.578% (9936/19264)
Loss: 1.699 | Acc: 51.149% (13127/25664)
Loss: 1.700 | Acc: 51.170% (16407/32064)
Loss: 1.702 | Acc: 51.100% (19655/38464)
Loss: 1.702 | Acc: 51.166% (22955/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8678, Accuracy: 4553/10000 (45.53%)

Epoch: 84
Loss: 1.886 | Acc: 40.625% (26/64)
Loss: 1.693 | Acc: 51.207% (3310/6464)
Loss: 1.683 | Acc: 51.702% (6651/12864)
Loss: 1.693 | Acc: 51.417% (9905/19264)
Loss: 1.699 | Acc: 51.149% (13127/25664)
Loss: 1.696 | Acc: 51.254% (16434/32064)
Loss: 1.696 | Acc: 51.277% (19723/38464)
Loss: 1.694 | Acc: 51.415% (23067/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8972, Accuracy: 4379/10000 (43.79%)

Epoch: 85
Loss: 1.596 | Acc: 54.688% (35/64)
Loss: 1.681 | Acc: 51.377% (3321/6464)
Loss: 1.674 | Acc: 51.772% (6660/12864)
Loss: 1.668 | Acc: 52.108% (10038/19264)
Loss: 1.666 | Acc: 52.279% (13417/25664)
Loss: 1.664 | Acc: 52.314% (16774/32064)
Loss: 1.671 | Acc: 52.088% (20035/38464)
Loss: 1.676 | Acc: 51.868% (23270/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8993, Accuracy: 4420/10000 (44.20%)

Epoch: 86
Loss: 1.643 | Acc: 53.125% (34/64)
Loss: 1.635 | Acc: 53.434% (3454/6464)
Loss: 1.638 | Acc: 53.195% (6843/12864)
Loss: 1.638 | Acc: 53.161% (10241/19264)
Loss: 1.646 | Acc: 52.903% (13577/25664)
Loss: 1.653 | Acc: 52.610% (16869/32064)
Loss: 1.660 | Acc: 52.392% (20152/38464)
Loss: 1.658 | Acc: 52.445% (23529/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9009, Accuracy: 4467/10000 (44.67%)

Epoch: 87
Loss: 1.413 | Acc: 64.062% (41/64)
Loss: 1.623 | Acc: 53.063% (3430/6464)
Loss: 1.623 | Acc: 53.242% (6849/12864)
Loss: 1.632 | Acc: 52.891% (10189/19264)
Loss: 1.634 | Acc: 52.950% (13589/25664)
Loss: 1.632 | Acc: 53.113% (17030/32064)
Loss: 1.633 | Acc: 53.169% (20451/38464)
Loss: 1.629 | Acc: 53.361% (23940/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9159, Accuracy: 4501/10000 (45.01%)

Epoch: 88
Loss: 1.646 | Acc: 50.000% (32/64)
Loss: 1.601 | Acc: 53.821% (3479/6464)
Loss: 1.608 | Acc: 53.700% (6908/12864)
Loss: 1.612 | Acc: 53.686% (10342/19264)
Loss: 1.610 | Acc: 53.780% (13802/25664)
Loss: 1.613 | Acc: 53.636% (17198/32064)
Loss: 1.606 | Acc: 53.962% (20756/38464)
Loss: 1.607 | Acc: 54.032% (24241/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9234, Accuracy: 4405/10000 (44.05%)

Epoch: 89
Loss: 1.524 | Acc: 57.812% (37/64)
Loss: 1.586 | Acc: 54.270% (3508/6464)
Loss: 1.559 | Acc: 55.302% (7114/12864)
Loss: 1.566 | Acc: 55.103% (10615/19264)
Loss: 1.570 | Acc: 54.933% (14098/25664)
Loss: 1.569 | Acc: 55.027% (17644/32064)
Loss: 1.574 | Acc: 54.854% (21099/38464)
Loss: 1.576 | Acc: 54.810% (24590/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9324, Accuracy: 4494/10000 (44.94%)

Epoch: 90
Loss: 1.581 | Acc: 56.250% (36/64)
Loss: 1.515 | Acc: 56.467% (3650/6464)
Loss: 1.532 | Acc: 55.892% (7190/12864)
Loss: 1.544 | Acc: 55.570% (10705/19264)
Loss: 1.544 | Acc: 55.514% (14247/25664)
Loss: 1.547 | Acc: 55.480% (17789/32064)
Loss: 1.548 | Acc: 55.462% (21333/38464)
Loss: 1.547 | Acc: 55.454% (24879/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9689, Accuracy: 4388/10000 (43.88%)

Epoch: 91
Loss: 1.447 | Acc: 57.812% (37/64)
Loss: 1.505 | Acc: 56.791% (3671/6464)
Loss: 1.508 | Acc: 56.514% (7270/12864)
Loss: 1.505 | Acc: 56.499% (10884/19264)
Loss: 1.504 | Acc: 56.675% (14545/25664)
Loss: 1.506 | Acc: 56.515% (18121/32064)
Loss: 1.505 | Acc: 56.604% (21772/38464)
Loss: 1.508 | Acc: 56.531% (25362/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9741, Accuracy: 4437/10000 (44.37%)

Epoch: 92
Loss: 1.428 | Acc: 56.250% (36/64)
Loss: 1.468 | Acc: 56.993% (3684/6464)
Loss: 1.443 | Acc: 58.123% (7477/12864)
Loss: 1.449 | Acc: 57.823% (11139/19264)
Loss: 1.453 | Acc: 57.692% (14806/25664)
Loss: 1.463 | Acc: 57.292% (18370/32064)
Loss: 1.461 | Acc: 57.316% (22046/38464)
Loss: 1.461 | Acc: 57.347% (25728/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0050, Accuracy: 4379/10000 (43.79%)

Epoch: 93
Loss: 1.463 | Acc: 54.688% (35/64)
Loss: 1.394 | Acc: 59.158% (3824/6464)
Loss: 1.390 | Acc: 59.779% (7690/12864)
Loss: 1.390 | Acc: 59.775% (11515/19264)
Loss: 1.397 | Acc: 59.426% (15251/25664)
Loss: 1.397 | Acc: 59.422% (19053/32064)
Loss: 1.402 | Acc: 59.196% (22769/38464)
Loss: 1.404 | Acc: 59.045% (26490/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0329, Accuracy: 4374/10000 (43.74%)

Epoch: 94
Loss: 1.336 | Acc: 60.938% (39/64)
Loss: 1.310 | Acc: 61.835% (3997/6464)
Loss: 1.323 | Acc: 61.303% (7886/12864)
Loss: 1.332 | Acc: 61.036% (11758/19264)
Loss: 1.337 | Acc: 60.821% (15609/25664)
Loss: 1.336 | Acc: 60.856% (19513/32064)
Loss: 1.338 | Acc: 60.875% (23415/38464)
Loss: 1.338 | Acc: 60.848% (27299/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1152, Accuracy: 4208/10000 (42.08%)

Epoch: 95
Loss: 0.980 | Acc: 71.875% (46/64)
Loss: 1.255 | Acc: 63.026% (4074/6464)
Loss: 1.273 | Acc: 62.648% (8059/12864)
Loss: 1.279 | Acc: 62.484% (12037/19264)
Loss: 1.283 | Acc: 62.344% (16000/25664)
Loss: 1.290 | Acc: 62.070% (19902/32064)
Loss: 1.292 | Acc: 61.912% (23814/38464)
Loss: 1.289 | Acc: 62.050% (27838/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1284, Accuracy: 4249/10000 (42.49%)

Epoch: 96
Loss: 1.060 | Acc: 71.875% (46/64)
Loss: 1.241 | Acc: 62.887% (4065/6464)
Loss: 1.243 | Acc: 63.308% (8144/12864)
Loss: 1.249 | Acc: 63.248% (12184/19264)
Loss: 1.246 | Acc: 63.174% (16213/25664)
Loss: 1.241 | Acc: 63.245% (20279/32064)
Loss: 1.240 | Acc: 63.311% (24352/38464)
Loss: 1.242 | Acc: 63.316% (28406/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1849, Accuracy: 4163/10000 (41.63%)

Epoch: 97
Loss: 1.357 | Acc: 56.250% (36/64)
Loss: 1.194 | Acc: 64.743% (4185/6464)
Loss: 1.187 | Acc: 65.058% (8369/12864)
Loss: 1.196 | Acc: 64.478% (12421/19264)
Loss: 1.194 | Acc: 64.577% (16573/25664)
Loss: 1.196 | Acc: 64.515% (20686/32064)
Loss: 1.195 | Acc: 64.582% (24841/38464)
Loss: 1.193 | Acc: 64.684% (29020/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1825, Accuracy: 4136/10000 (41.36%)
torch.Size([100, 10])
Test set: Average loss: 2.1825, Accuracy: 4136/10000 (41.36%)

Epoch: 98
Loss: 1.007 | Acc: 73.438% (47/64)
Loss: 1.172 | Acc: 65.377% (4226/6464)
Loss: 1.173 | Acc: 64.902% (8349/12864)
Loss: 1.172 | Acc: 65.049% (12531/19264)
Loss: 1.168 | Acc: 65.259% (16748/25664)
Loss: 1.170 | Acc: 65.232% (20916/32064)
Loss: 1.165 | Acc: 65.485% (25188/38464)
Loss: 1.162 | Acc: 65.558% (29412/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2097, Accuracy: 4159/10000 (41.59%)
torch.Size([100, 10])
Test set: Average loss: 2.2097, Accuracy: 4159/10000 (41.59%)

Epoch: 99
Loss: 1.270 | Acc: 64.062% (41/64)
Loss: 1.135 | Acc: 66.569% (4303/6464)
Loss: 1.148 | Acc: 65.874% (8474/12864)
Loss: 1.142 | Acc: 66.118% (12737/19264)
Loss: 1.147 | Acc: 65.882% (16908/25664)
Loss: 1.145 | Acc: 66.049% (21178/32064)
Loss: 1.143 | Acc: 66.163% (25449/38464)
Loss: 1.144 | Acc: 66.209% (29704/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2128, Accuracy: 4147/10000 (41.47%)
torch.Size([100, 10])
Test set: Average loss: 2.2128, Accuracy: 4147/10000 (41.47%)

Epoch: 100
Loss: 1.178 | Acc: 62.500% (40/64)
Loss: 2.176 | Acc: 24.087% (1557/6464)
Loss: 2.083 | Acc: 30.442% (3916/12864)
Loss: 2.030 | Acc: 33.939% (6538/19264)
Loss: 1.995 | Acc: 36.058% (9254/25664)
Loss: 1.976 | Acc: 37.288% (11956/32064)
Loss: 1.958 | Acc: 38.363% (14756/38464)
Loss: 1.945 | Acc: 39.207% (17590/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1731, Accuracy: 2912/10000 (29.12%)

Epoch: 101
Loss: 2.079 | Acc: 32.812% (21/64)
Loss: 1.847 | Acc: 45.080% (2914/6464)
Loss: 1.849 | Acc: 45.048% (5795/12864)
Loss: 1.844 | Acc: 45.364% (8739/19264)
Loss: 1.848 | Acc: 45.223% (11606/25664)
Loss: 1.846 | Acc: 45.210% (14496/32064)
Loss: 1.845 | Acc: 45.245% (17403/38464)
Loss: 1.848 | Acc: 45.101% (20234/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9822, Accuracy: 3862/10000 (38.62%)

Epoch: 102
Loss: 1.825 | Acc: 39.062% (25/64)
Loss: 1.836 | Acc: 45.452% (2938/6464)
Loss: 1.837 | Acc: 45.281% (5825/12864)
Loss: 1.840 | Acc: 45.255% (8718/19264)
Loss: 1.837 | Acc: 45.414% (11655/25664)
Loss: 1.837 | Acc: 45.447% (14572/32064)
Loss: 1.842 | Acc: 45.242% (17402/38464)
Loss: 1.845 | Acc: 45.136% (20250/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2184, Accuracy: 3197/10000 (31.97%)

Epoch: 103
Loss: 2.019 | Acc: 37.500% (24/64)
Loss: 1.851 | Acc: 45.189% (2921/6464)
Loss: 1.846 | Acc: 45.196% (5814/12864)
Loss: 1.844 | Acc: 45.338% (8734/19264)
Loss: 1.844 | Acc: 45.387% (11648/25664)
Loss: 1.843 | Acc: 45.362% (14545/32064)
Loss: 1.842 | Acc: 45.450% (17482/38464)
Loss: 1.843 | Acc: 45.328% (20336/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0277, Accuracy: 3733/10000 (37.33%)

Epoch: 104
Loss: 1.844 | Acc: 45.312% (29/64)
Loss: 1.822 | Acc: 46.241% (2989/6464)
Loss: 1.828 | Acc: 45.981% (5915/12864)
Loss: 1.828 | Acc: 45.972% (8856/19264)
Loss: 1.832 | Acc: 45.706% (11730/25664)
Loss: 1.836 | Acc: 45.559% (14608/32064)
Loss: 1.841 | Acc: 45.401% (17463/38464)
Loss: 1.841 | Acc: 45.464% (20397/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1927, Accuracy: 2934/10000 (29.34%)

Epoch: 105
Loss: 2.106 | Acc: 29.688% (19/64)
Loss: 1.845 | Acc: 45.235% (2924/6464)
Loss: 1.829 | Acc: 45.717% (5881/12864)
Loss: 1.837 | Acc: 45.473% (8760/19264)
Loss: 1.832 | Acc: 45.706% (11730/25664)
Loss: 1.834 | Acc: 45.546% (14604/32064)
Loss: 1.836 | Acc: 45.461% (17486/38464)
Loss: 1.836 | Acc: 45.435% (20384/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1338, Accuracy: 3180/10000 (31.80%)

Epoch: 106
Loss: 2.082 | Acc: 37.500% (24/64)
Loss: 1.839 | Acc: 45.421% (2936/6464)
Loss: 1.850 | Acc: 44.869% (5772/12864)
Loss: 1.847 | Acc: 45.006% (8670/19264)
Loss: 1.847 | Acc: 45.083% (11570/25664)
Loss: 1.845 | Acc: 45.238% (14505/32064)
Loss: 1.845 | Acc: 45.240% (17401/38464)
Loss: 1.842 | Acc: 45.397% (20367/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0480, Accuracy: 3538/10000 (35.38%)

Epoch: 107
Loss: 2.028 | Acc: 39.062% (25/64)
Loss: 1.819 | Acc: 46.272% (2991/6464)
Loss: 1.829 | Acc: 45.965% (5913/12864)
Loss: 1.825 | Acc: 45.993% (8860/19264)
Loss: 1.831 | Acc: 45.714% (11732/25664)
Loss: 1.831 | Acc: 45.674% (14645/32064)
Loss: 1.834 | Acc: 45.575% (17530/38464)
Loss: 1.837 | Acc: 45.542% (20432/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1834, Accuracy: 3330/10000 (33.30%)

Epoch: 108
Loss: 2.058 | Acc: 32.812% (21/64)
Loss: 1.828 | Acc: 45.916% (2968/6464)
Loss: 1.824 | Acc: 46.090% (5929/12864)
Loss: 1.825 | Acc: 46.226% (8905/19264)
Loss: 1.829 | Acc: 45.967% (11797/25664)
Loss: 1.830 | Acc: 45.771% (14676/32064)
Loss: 1.834 | Acc: 45.700% (17578/38464)
Loss: 1.834 | Acc: 45.716% (20510/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0820, Accuracy: 3406/10000 (34.06%)

Epoch: 109
Loss: 1.699 | Acc: 54.688% (35/64)
Loss: 1.837 | Acc: 45.885% (2966/6464)
Loss: 1.823 | Acc: 46.183% (5941/12864)
Loss: 1.828 | Acc: 45.899% (8842/19264)
Loss: 1.828 | Acc: 45.897% (11779/25664)
Loss: 1.833 | Acc: 45.721% (14660/32064)
Loss: 1.833 | Acc: 45.674% (17568/38464)
Loss: 1.835 | Acc: 45.633% (20473/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9428, Accuracy: 4021/10000 (40.21%)

Epoch: 110
Loss: 1.853 | Acc: 43.750% (28/64)
Loss: 1.842 | Acc: 45.189% (2921/6464)
Loss: 1.833 | Acc: 46.004% (5918/12864)
Loss: 1.831 | Acc: 45.961% (8854/19264)
Loss: 1.830 | Acc: 45.998% (11805/25664)
Loss: 1.830 | Acc: 45.936% (14729/32064)
Loss: 1.832 | Acc: 45.827% (17627/38464)
Loss: 1.829 | Acc: 45.939% (20610/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9666, Accuracy: 3845/10000 (38.45%)

Epoch: 111
Loss: 1.781 | Acc: 45.312% (29/64)
Loss: 1.803 | Acc: 47.246% (3054/6464)
Loss: 1.813 | Acc: 46.634% (5999/12864)
Loss: 1.819 | Acc: 46.512% (8960/19264)
Loss: 1.821 | Acc: 46.524% (11940/25664)
Loss: 1.827 | Acc: 46.217% (14819/32064)
Loss: 1.830 | Acc: 46.064% (17718/38464)
Loss: 1.831 | Acc: 46.055% (20662/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0721, Accuracy: 3577/10000 (35.77%)

Epoch: 112
Loss: 1.896 | Acc: 43.750% (28/64)
Loss: 1.814 | Acc: 46.627% (3014/6464)
Loss: 1.819 | Acc: 46.510% (5983/12864)
Loss: 1.821 | Acc: 46.387% (8936/19264)
Loss: 1.826 | Acc: 46.185% (11853/25664)
Loss: 1.825 | Acc: 46.270% (14836/32064)
Loss: 1.829 | Acc: 46.043% (17710/38464)
Loss: 1.827 | Acc: 46.106% (20685/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0222, Accuracy: 3529/10000 (35.29%)

Epoch: 113
Loss: 1.634 | Acc: 59.375% (38/64)
Loss: 1.802 | Acc: 47.664% (3081/6464)
Loss: 1.812 | Acc: 47.093% (6058/12864)
Loss: 1.815 | Acc: 46.870% (9029/19264)
Loss: 1.817 | Acc: 46.707% (11987/25664)
Loss: 1.819 | Acc: 46.601% (14942/32064)
Loss: 1.826 | Acc: 46.248% (17789/38464)
Loss: 1.825 | Acc: 46.313% (20778/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0302, Accuracy: 3547/10000 (35.47%)

Epoch: 114
Loss: 1.794 | Acc: 45.312% (29/64)
Loss: 1.815 | Acc: 46.829% (3027/6464)
Loss: 1.813 | Acc: 46.813% (6022/12864)
Loss: 1.813 | Acc: 46.849% (9025/19264)
Loss: 1.810 | Acc: 47.027% (12069/25664)
Loss: 1.814 | Acc: 46.819% (15012/32064)
Loss: 1.817 | Acc: 46.659% (17947/38464)
Loss: 1.819 | Acc: 46.563% (20890/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1395, Accuracy: 3228/10000 (32.28%)

Epoch: 115
Loss: 1.784 | Acc: 50.000% (32/64)
Loss: 1.789 | Acc: 47.587% (3076/6464)
Loss: 1.814 | Acc: 46.720% (6010/12864)
Loss: 1.813 | Acc: 46.828% (9021/19264)
Loss: 1.816 | Acc: 46.719% (11990/25664)
Loss: 1.819 | Acc: 46.560% (14929/32064)
Loss: 1.816 | Acc: 46.672% (17952/38464)
Loss: 1.817 | Acc: 46.681% (20943/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8920, Accuracy: 4320/10000 (43.20%)

Epoch: 116
Loss: 1.577 | Acc: 57.812% (37/64)
Loss: 1.798 | Acc: 47.432% (3066/6464)
Loss: 1.800 | Acc: 47.544% (6116/12864)
Loss: 1.809 | Acc: 47.176% (9088/19264)
Loss: 1.810 | Acc: 47.117% (12092/25664)
Loss: 1.809 | Acc: 47.103% (15103/32064)
Loss: 1.809 | Acc: 47.065% (18103/38464)
Loss: 1.811 | Acc: 46.946% (21062/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0818, Accuracy: 3395/10000 (33.95%)

Epoch: 117
Loss: 1.739 | Acc: 37.500% (24/64)
Loss: 1.799 | Acc: 46.999% (3038/6464)
Loss: 1.804 | Acc: 46.976% (6043/12864)
Loss: 1.808 | Acc: 46.917% (9038/19264)
Loss: 1.812 | Acc: 46.754% (11999/25664)
Loss: 1.814 | Acc: 46.722% (14981/32064)
Loss: 1.814 | Acc: 46.768% (17989/38464)
Loss: 1.811 | Acc: 46.862% (21024/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0300, Accuracy: 3799/10000 (37.99%)

Epoch: 118
Loss: 2.017 | Acc: 39.062% (25/64)
Loss: 1.796 | Acc: 47.710% (3084/6464)
Loss: 1.798 | Acc: 47.582% (6121/12864)
Loss: 1.801 | Acc: 47.482% (9147/19264)
Loss: 1.803 | Acc: 47.354% (12153/25664)
Loss: 1.804 | Acc: 47.287% (15162/32064)
Loss: 1.804 | Acc: 47.291% (18190/38464)
Loss: 1.805 | Acc: 47.243% (21195/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9200, Accuracy: 4193/10000 (41.93%)

Epoch: 119
Loss: 1.688 | Acc: 50.000% (32/64)
Loss: 1.812 | Acc: 46.581% (3011/6464)
Loss: 1.804 | Acc: 46.999% (6046/12864)
Loss: 1.793 | Acc: 47.394% (9130/19264)
Loss: 1.797 | Acc: 47.417% (12169/25664)
Loss: 1.799 | Acc: 47.358% (15185/32064)
Loss: 1.801 | Acc: 47.291% (18190/38464)
Loss: 1.803 | Acc: 47.214% (21182/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1610, Accuracy: 3166/10000 (31.66%)

Epoch: 120
Loss: 1.593 | Acc: 51.562% (33/64)
Loss: 1.818 | Acc: 46.473% (3004/6464)
Loss: 1.809 | Acc: 46.883% (6031/12864)
Loss: 1.800 | Acc: 47.327% (9117/19264)
Loss: 1.798 | Acc: 47.393% (12163/25664)
Loss: 1.799 | Acc: 47.461% (15218/32064)
Loss: 1.799 | Acc: 47.416% (18238/38464)
Loss: 1.802 | Acc: 47.330% (21234/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9726, Accuracy: 4029/10000 (40.29%)

Epoch: 121
Loss: 1.777 | Acc: 48.438% (31/64)
Loss: 1.791 | Acc: 47.494% (3070/6464)
Loss: 1.788 | Acc: 47.753% (6143/12864)
Loss: 1.784 | Acc: 47.851% (9218/19264)
Loss: 1.790 | Acc: 47.705% (12243/25664)
Loss: 1.789 | Acc: 47.808% (15329/32064)
Loss: 1.791 | Acc: 47.702% (18348/38464)
Loss: 1.793 | Acc: 47.686% (21394/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9520, Accuracy: 4106/10000 (41.06%)

Epoch: 122
Loss: 1.960 | Acc: 39.062% (25/64)
Loss: 1.785 | Acc: 47.881% (3095/6464)
Loss: 1.789 | Acc: 48.134% (6192/12864)
Loss: 1.787 | Acc: 48.074% (9261/19264)
Loss: 1.785 | Acc: 48.126% (12351/25664)
Loss: 1.785 | Acc: 48.147% (15438/32064)
Loss: 1.785 | Acc: 48.074% (18491/38464)
Loss: 1.788 | Acc: 47.974% (21523/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8758, Accuracy: 4459/10000 (44.59%)

Epoch: 123
Loss: 1.861 | Acc: 43.750% (28/64)
Loss: 1.770 | Acc: 48.561% (3139/6464)
Loss: 1.779 | Acc: 48.165% (6196/12864)
Loss: 1.778 | Acc: 48.334% (9311/19264)
Loss: 1.773 | Acc: 48.570% (12465/25664)
Loss: 1.773 | Acc: 48.509% (15554/32064)
Loss: 1.776 | Acc: 48.360% (18601/38464)
Loss: 1.779 | Acc: 48.246% (21645/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9759, Accuracy: 3878/10000 (38.78%)

Epoch: 124
Loss: 1.752 | Acc: 51.562% (33/64)
Loss: 1.767 | Acc: 48.809% (3155/6464)
Loss: 1.761 | Acc: 49.013% (6305/12864)
Loss: 1.764 | Acc: 48.931% (9426/19264)
Loss: 1.764 | Acc: 48.874% (12543/25664)
Loss: 1.768 | Acc: 48.728% (15624/32064)
Loss: 1.773 | Acc: 48.567% (18681/38464)
Loss: 1.776 | Acc: 48.366% (21699/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0454, Accuracy: 3470/10000 (34.70%)

Epoch: 125
Loss: 1.825 | Acc: 45.312% (29/64)
Loss: 1.778 | Acc: 48.205% (3116/6464)
Loss: 1.763 | Acc: 48.842% (6283/12864)
Loss: 1.763 | Acc: 48.770% (9395/19264)
Loss: 1.759 | Acc: 49.002% (12576/25664)
Loss: 1.765 | Acc: 48.793% (15645/32064)
Loss: 1.766 | Acc: 48.697% (18731/38464)
Loss: 1.767 | Acc: 48.645% (21824/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9777, Accuracy: 3888/10000 (38.88%)

Epoch: 126
Loss: 1.705 | Acc: 48.438% (31/64)
Loss: 1.738 | Acc: 49.876% (3224/6464)
Loss: 1.753 | Acc: 49.308% (6343/12864)
Loss: 1.757 | Acc: 49.133% (9465/19264)
Loss: 1.763 | Acc: 48.854% (12538/25664)
Loss: 1.766 | Acc: 48.787% (15643/32064)
Loss: 1.758 | Acc: 49.212% (18929/38464)
Loss: 1.760 | Acc: 49.097% (22027/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2293, Accuracy: 2855/10000 (28.55%)

Epoch: 127
Loss: 1.760 | Acc: 50.000% (32/64)
Loss: 1.757 | Acc: 49.381% (3192/6464)
Loss: 1.754 | Acc: 49.277% (6339/12864)
Loss: 1.757 | Acc: 49.034% (9446/19264)
Loss: 1.756 | Acc: 49.139% (12611/25664)
Loss: 1.757 | Acc: 49.099% (15743/32064)
Loss: 1.754 | Acc: 49.210% (18928/38464)
Loss: 1.752 | Acc: 49.307% (22121/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0002, Accuracy: 3771/10000 (37.71%)

Epoch: 128
Loss: 2.188 | Acc: 31.250% (20/64)
Loss: 1.726 | Acc: 50.526% (3266/6464)
Loss: 1.737 | Acc: 49.790% (6405/12864)
Loss: 1.737 | Acc: 49.766% (9587/19264)
Loss: 1.742 | Acc: 49.727% (12762/25664)
Loss: 1.742 | Acc: 49.732% (15946/32064)
Loss: 1.743 | Acc: 49.672% (19106/38464)
Loss: 1.744 | Acc: 49.632% (22267/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8882, Accuracy: 4394/10000 (43.94%)

Epoch: 129
Loss: 1.707 | Acc: 50.000% (32/64)
Loss: 1.721 | Acc: 50.820% (3285/6464)
Loss: 1.720 | Acc: 50.824% (6538/12864)
Loss: 1.721 | Acc: 50.727% (9772/19264)
Loss: 1.722 | Acc: 50.549% (12973/25664)
Loss: 1.731 | Acc: 50.212% (16100/32064)
Loss: 1.735 | Acc: 50.117% (19277/38464)
Loss: 1.736 | Acc: 50.038% (22449/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9334, Accuracy: 4154/10000 (41.54%)

Epoch: 130
Loss: 1.911 | Acc: 40.625% (26/64)
Loss: 1.718 | Acc: 50.557% (3268/6464)
Loss: 1.724 | Acc: 50.171% (6454/12864)
Loss: 1.731 | Acc: 50.036% (9639/19264)
Loss: 1.729 | Acc: 50.062% (12848/25664)
Loss: 1.728 | Acc: 50.106% (16066/32064)
Loss: 1.728 | Acc: 50.133% (19283/38464)
Loss: 1.726 | Acc: 50.267% (22552/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8945, Accuracy: 4438/10000 (44.38%)

Epoch: 131
Loss: 1.858 | Acc: 42.188% (27/64)
Loss: 1.689 | Acc: 51.872% (3353/6464)
Loss: 1.704 | Acc: 51.213% (6588/12864)
Loss: 1.702 | Acc: 51.370% (9896/19264)
Loss: 1.703 | Acc: 51.340% (13176/25664)
Loss: 1.708 | Acc: 51.123% (16392/32064)
Loss: 1.711 | Acc: 51.004% (19618/38464)
Loss: 1.714 | Acc: 50.847% (22812/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8929, Accuracy: 4390/10000 (43.90%)

Epoch: 132
Loss: 2.131 | Acc: 34.375% (22/64)
Loss: 1.685 | Acc: 51.934% (3357/6464)
Loss: 1.689 | Acc: 51.508% (6626/12864)
Loss: 1.694 | Acc: 51.267% (9876/19264)
Loss: 1.695 | Acc: 51.165% (13131/25664)
Loss: 1.697 | Acc: 51.207% (16419/32064)
Loss: 1.700 | Acc: 51.102% (19656/38464)
Loss: 1.700 | Acc: 51.101% (22926/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9088, Accuracy: 4356/10000 (43.56%)

Epoch: 133
Loss: 1.689 | Acc: 53.125% (34/64)
Loss: 1.639 | Acc: 53.852% (3481/6464)
Loss: 1.675 | Acc: 52.371% (6737/12864)
Loss: 1.692 | Acc: 51.599% (9940/19264)
Loss: 1.692 | Acc: 51.582% (13238/25664)
Loss: 1.693 | Acc: 51.488% (16509/32064)
Loss: 1.689 | Acc: 51.656% (19869/38464)
Loss: 1.686 | Acc: 51.826% (23251/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8913, Accuracy: 4465/10000 (44.65%)

Epoch: 134
Loss: 1.538 | Acc: 59.375% (38/64)
Loss: 1.660 | Acc: 52.661% (3404/6464)
Loss: 1.667 | Acc: 52.456% (6748/12864)
Loss: 1.666 | Acc: 52.538% (10121/19264)
Loss: 1.667 | Acc: 52.428% (13455/25664)
Loss: 1.670 | Acc: 52.283% (16764/32064)
Loss: 1.667 | Acc: 52.400% (20155/38464)
Loss: 1.667 | Acc: 52.403% (23510/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8835, Accuracy: 4498/10000 (44.98%)

Epoch: 135
Loss: 1.905 | Acc: 43.750% (28/64)
Loss: 1.650 | Acc: 52.382% (3386/6464)
Loss: 1.642 | Acc: 52.775% (6789/12864)
Loss: 1.645 | Acc: 52.694% (10151/19264)
Loss: 1.648 | Acc: 52.673% (13518/25664)
Loss: 1.648 | Acc: 52.738% (16910/32064)
Loss: 1.652 | Acc: 52.610% (20236/38464)
Loss: 1.654 | Acc: 52.574% (23587/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9269, Accuracy: 4355/10000 (43.55%)

Epoch: 136
Loss: 2.058 | Acc: 37.500% (24/64)
Loss: 1.624 | Acc: 53.295% (3445/6464)
Loss: 1.620 | Acc: 53.623% (6898/12864)
Loss: 1.620 | Acc: 53.608% (10327/19264)
Loss: 1.630 | Acc: 53.215% (13657/25664)
Loss: 1.632 | Acc: 53.084% (17021/32064)
Loss: 1.635 | Acc: 52.961% (20371/38464)
Loss: 1.631 | Acc: 53.178% (23858/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9180, Accuracy: 4431/10000 (44.31%)

Epoch: 137
Loss: 1.579 | Acc: 54.688% (35/64)
Loss: 1.587 | Acc: 54.223% (3505/6464)
Loss: 1.592 | Acc: 54.353% (6992/12864)
Loss: 1.602 | Acc: 53.997% (10402/19264)
Loss: 1.599 | Acc: 54.197% (13909/25664)
Loss: 1.599 | Acc: 54.104% (17348/32064)
Loss: 1.603 | Acc: 53.928% (20743/38464)
Loss: 1.605 | Acc: 53.939% (24199/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9036, Accuracy: 4527/10000 (45.27%)

Epoch: 138
Loss: 1.722 | Acc: 48.438% (31/64)
Loss: 1.560 | Acc: 55.090% (3561/6464)
Loss: 1.565 | Acc: 54.952% (7069/12864)
Loss: 1.568 | Acc: 54.983% (10592/19264)
Loss: 1.575 | Acc: 54.762% (14054/25664)
Loss: 1.576 | Acc: 54.750% (17555/32064)
Loss: 1.573 | Acc: 54.784% (21072/38464)
Loss: 1.572 | Acc: 54.893% (24627/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9209, Accuracy: 4477/10000 (44.77%)

Epoch: 139
Loss: 1.533 | Acc: 59.375% (38/64)
Loss: 1.522 | Acc: 56.374% (3644/6464)
Loss: 1.520 | Acc: 56.351% (7249/12864)
Loss: 1.521 | Acc: 56.354% (10856/19264)
Loss: 1.527 | Acc: 56.118% (14402/25664)
Loss: 1.536 | Acc: 55.966% (17945/32064)
Loss: 1.539 | Acc: 55.876% (21492/38464)
Loss: 1.545 | Acc: 55.699% (24989/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9568, Accuracy: 4454/10000 (44.54%)

Epoch: 140
Loss: 1.747 | Acc: 48.438% (31/64)
Loss: 1.485 | Acc: 57.085% (3690/6464)
Loss: 1.496 | Acc: 56.662% (7289/12864)
Loss: 1.496 | Acc: 56.795% (10941/19264)
Loss: 1.498 | Acc: 56.698% (14551/25664)
Loss: 1.500 | Acc: 56.708% (18183/32064)
Loss: 1.505 | Acc: 56.492% (21729/38464)
Loss: 1.506 | Acc: 56.417% (25311/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9772, Accuracy: 4402/10000 (44.02%)

Epoch: 141
Loss: 1.350 | Acc: 57.812% (37/64)
Loss: 1.433 | Acc: 58.663% (3792/6464)
Loss: 1.439 | Acc: 58.543% (7531/12864)
Loss: 1.442 | Acc: 58.456% (11261/19264)
Loss: 1.454 | Acc: 58.070% (14903/25664)
Loss: 1.455 | Acc: 58.062% (18617/32064)
Loss: 1.457 | Acc: 58.062% (22333/38464)
Loss: 1.461 | Acc: 57.859% (25958/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0292, Accuracy: 4342/10000 (43.42%)

Epoch: 142
Loss: 1.154 | Acc: 67.188% (43/64)
Loss: 1.409 | Acc: 59.127% (3822/6464)
Loss: 1.400 | Acc: 59.422% (7644/12864)
Loss: 1.409 | Acc: 58.955% (11357/19264)
Loss: 1.409 | Acc: 58.970% (15134/25664)
Loss: 1.410 | Acc: 58.951% (18902/32064)
Loss: 1.409 | Acc: 59.019% (22701/38464)
Loss: 1.409 | Acc: 59.032% (26484/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0741, Accuracy: 4275/10000 (42.75%)

Epoch: 143
Loss: 1.208 | Acc: 64.062% (41/64)
Loss: 1.337 | Acc: 61.541% (3978/6464)
Loss: 1.346 | Acc: 60.829% (7825/12864)
Loss: 1.343 | Acc: 60.740% (11701/19264)
Loss: 1.351 | Acc: 60.396% (15500/25664)
Loss: 1.352 | Acc: 60.488% (19395/32064)
Loss: 1.355 | Acc: 60.298% (23193/38464)
Loss: 1.355 | Acc: 60.318% (27061/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0766, Accuracy: 4319/10000 (43.19%)

Epoch: 144
Loss: 1.456 | Acc: 54.688% (35/64)
Loss: 1.281 | Acc: 62.515% (4041/6464)
Loss: 1.284 | Acc: 62.228% (8005/12864)
Loss: 1.281 | Acc: 62.407% (12022/19264)
Loss: 1.287 | Acc: 62.188% (15960/25664)
Loss: 1.285 | Acc: 62.297% (19975/32064)
Loss: 1.287 | Acc: 62.287% (23958/38464)
Loss: 1.289 | Acc: 62.250% (27928/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1348, Accuracy: 4192/10000 (41.92%)

Epoch: 145
Loss: 1.209 | Acc: 62.500% (40/64)
Loss: 1.212 | Acc: 63.800% (4124/6464)
Loss: 1.215 | Acc: 64.171% (8255/12864)
Loss: 1.218 | Acc: 64.192% (12366/19264)
Loss: 1.218 | Acc: 64.113% (16454/25664)
Loss: 1.219 | Acc: 64.075% (20545/32064)
Loss: 1.225 | Acc: 63.797% (24539/38464)
Loss: 1.229 | Acc: 63.730% (28592/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1819, Accuracy: 4220/10000 (42.20%)

Epoch: 146
Loss: 1.225 | Acc: 64.062% (41/64)
Loss: 1.144 | Acc: 66.182% (4278/6464)
Loss: 1.157 | Acc: 65.866% (8473/12864)
Loss: 1.163 | Acc: 65.547% (12627/19264)
Loss: 1.162 | Acc: 65.754% (16875/25664)
Loss: 1.166 | Acc: 65.606% (21036/32064)
Loss: 1.171 | Acc: 65.378% (25147/38464)
Loss: 1.173 | Acc: 65.206% (29254/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2107, Accuracy: 4198/10000 (41.98%)

Epoch: 147
Loss: 1.113 | Acc: 67.188% (43/64)
Loss: 1.121 | Acc: 66.399% (4292/6464)
Loss: 1.118 | Acc: 66.620% (8570/12864)
Loss: 1.128 | Acc: 66.201% (12753/19264)
Loss: 1.129 | Acc: 66.268% (17007/25664)
Loss: 1.129 | Acc: 66.249% (21242/32064)
Loss: 1.133 | Acc: 66.171% (25452/38464)
Loss: 1.129 | Acc: 66.298% (29744/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2444, Accuracy: 4078/10000 (40.78%)
torch.Size([100, 10])
Test set: Average loss: 2.2444, Accuracy: 4078/10000 (40.78%)

Epoch: 148
Loss: 0.953 | Acc: 67.188% (43/64)
Loss: 1.104 | Acc: 67.373% (4355/6464)
Loss: 1.101 | Acc: 67.359% (8665/12864)
Loss: 1.096 | Acc: 67.520% (13007/19264)
Loss: 1.094 | Acc: 67.651% (17362/25664)
Loss: 1.094 | Acc: 67.612% (21679/32064)
Loss: 1.098 | Acc: 67.460% (25948/38464)
Loss: 1.096 | Acc: 67.533% (30298/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2674, Accuracy: 4086/10000 (40.86%)
torch.Size([100, 10])
Test set: Average loss: 2.2674, Accuracy: 4086/10000 (40.86%)

Epoch: 149
Loss: 1.084 | Acc: 68.750% (44/64)
Loss: 1.084 | Acc: 67.342% (4353/6464)
Loss: 1.086 | Acc: 67.506% (8684/12864)
Loss: 1.087 | Acc: 67.561% (13015/19264)
Loss: 1.088 | Acc: 67.647% (17361/25664)
Loss: 1.086 | Acc: 67.680% (21701/32064)
Loss: 1.083 | Acc: 67.741% (26056/38464)
Loss: 1.083 | Acc: 67.827% (30430/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2696, Accuracy: 4052/10000 (40.52%)
torch.Size([100, 10])
Test set: Average loss: 2.2696, Accuracy: 4052/10000 (40.52%)

Epoch: 150
Loss: 1.122 | Acc: 62.500% (40/64)
Loss: 2.245 | Acc: 18.533% (1198/6464)
Loss: 2.161 | Acc: 24.440% (3144/12864)
Loss: 2.104 | Acc: 28.577% (5505/19264)
Loss: 2.055 | Acc: 31.854% (8175/25664)
Loss: 2.019 | Acc: 34.207% (10968/32064)
Loss: 1.997 | Acc: 35.662% (13717/38464)
Loss: 1.977 | Acc: 36.965% (16584/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2706, Accuracy: 2697/10000 (26.97%)

Epoch: 151
Loss: 2.015 | Acc: 39.062% (25/64)
Loss: 1.849 | Acc: 44.663% (2887/6464)
Loss: 1.846 | Acc: 44.675% (5747/12864)
Loss: 1.850 | Acc: 44.549% (8582/19264)
Loss: 1.850 | Acc: 44.615% (11450/25664)
Loss: 1.851 | Acc: 44.692% (14330/32064)
Loss: 1.852 | Acc: 44.717% (17200/38464)
Loss: 1.853 | Acc: 44.691% (20050/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1645, Accuracy: 3407/10000 (34.07%)

Epoch: 152
Loss: 1.660 | Acc: 50.000% (32/64)
Loss: 1.822 | Acc: 45.514% (2942/6464)
Loss: 1.832 | Acc: 45.522% (5856/12864)
Loss: 1.838 | Acc: 45.390% (8744/19264)
Loss: 1.841 | Acc: 45.262% (11616/25664)
Loss: 1.843 | Acc: 45.200% (14493/32064)
Loss: 1.842 | Acc: 45.206% (17388/38464)
Loss: 1.842 | Acc: 45.284% (20316/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0378, Accuracy: 3590/10000 (35.90%)

Epoch: 153
Loss: 1.762 | Acc: 45.312% (29/64)
Loss: 1.849 | Acc: 44.941% (2905/6464)
Loss: 1.836 | Acc: 45.725% (5882/12864)
Loss: 1.842 | Acc: 45.235% (8714/19264)
Loss: 1.834 | Acc: 45.733% (11737/25664)
Loss: 1.834 | Acc: 45.696% (14652/32064)
Loss: 1.838 | Acc: 45.583% (17533/38464)
Loss: 1.837 | Acc: 45.589% (20453/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0161, Accuracy: 3655/10000 (36.55%)

Epoch: 154
Loss: 2.115 | Acc: 35.938% (23/64)
Loss: 1.828 | Acc: 45.823% (2962/6464)
Loss: 1.827 | Acc: 45.872% (5901/12864)
Loss: 1.831 | Acc: 45.707% (8805/19264)
Loss: 1.834 | Acc: 45.702% (11729/25664)
Loss: 1.831 | Acc: 45.849% (14701/32064)
Loss: 1.831 | Acc: 45.840% (17632/38464)
Loss: 1.831 | Acc: 45.928% (20605/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9844, Accuracy: 3773/10000 (37.73%)

Epoch: 155
Loss: 1.908 | Acc: 37.500% (24/64)
Loss: 1.843 | Acc: 45.575% (2946/6464)
Loss: 1.843 | Acc: 45.693% (5878/12864)
Loss: 1.833 | Acc: 45.852% (8833/19264)
Loss: 1.830 | Acc: 45.889% (11777/25664)
Loss: 1.831 | Acc: 45.840% (14698/32064)
Loss: 1.832 | Acc: 45.812% (17621/38464)
Loss: 1.832 | Acc: 45.803% (20549/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9852, Accuracy: 3791/10000 (37.91%)

Epoch: 156
Loss: 1.658 | Acc: 54.688% (35/64)
Loss: 1.833 | Acc: 45.452% (2938/6464)
Loss: 1.834 | Acc: 45.484% (5851/12864)
Loss: 1.826 | Acc: 46.008% (8863/19264)
Loss: 1.826 | Acc: 46.061% (11821/25664)
Loss: 1.830 | Acc: 45.905% (14719/32064)
Loss: 1.830 | Acc: 45.916% (17661/38464)
Loss: 1.831 | Acc: 45.876% (20582/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0089, Accuracy: 3708/10000 (37.08%)

Epoch: 157
Loss: 1.967 | Acc: 40.625% (26/64)
Loss: 1.836 | Acc: 45.452% (2938/6464)
Loss: 1.826 | Acc: 46.339% (5961/12864)
Loss: 1.830 | Acc: 46.081% (8877/19264)
Loss: 1.830 | Acc: 46.057% (11820/25664)
Loss: 1.832 | Acc: 45.949% (14733/32064)
Loss: 1.834 | Acc: 45.845% (17634/38464)
Loss: 1.832 | Acc: 45.928% (20605/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9802, Accuracy: 3876/10000 (38.76%)

Epoch: 158
Loss: 1.938 | Acc: 43.750% (28/64)
Loss: 1.829 | Acc: 46.287% (2992/6464)
Loss: 1.828 | Acc: 46.113% (5932/12864)
Loss: 1.830 | Acc: 45.894% (8841/19264)
Loss: 1.830 | Acc: 45.909% (11782/25664)
Loss: 1.830 | Acc: 45.840% (14698/32064)
Loss: 1.829 | Acc: 45.962% (17679/38464)
Loss: 1.830 | Acc: 45.968% (20623/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9781, Accuracy: 3966/10000 (39.66%)

Epoch: 159
Loss: 1.745 | Acc: 51.562% (33/64)
Loss: 1.815 | Acc: 46.488% (3005/6464)
Loss: 1.818 | Acc: 46.401% (5969/12864)
Loss: 1.820 | Acc: 46.397% (8938/19264)
Loss: 1.823 | Acc: 46.314% (11886/25664)
Loss: 1.823 | Acc: 46.398% (14877/32064)
Loss: 1.825 | Acc: 46.306% (17811/38464)
Loss: 1.826 | Acc: 46.284% (20765/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2042, Accuracy: 2982/10000 (29.82%)

Epoch: 160
Loss: 1.962 | Acc: 34.375% (22/64)
Loss: 1.812 | Acc: 47.014% (3039/6464)
Loss: 1.814 | Acc: 46.782% (6018/12864)
Loss: 1.813 | Acc: 46.942% (9043/19264)
Loss: 1.821 | Acc: 46.552% (11947/25664)
Loss: 1.819 | Acc: 46.685% (14969/32064)
Loss: 1.821 | Acc: 46.493% (17883/38464)
Loss: 1.824 | Acc: 46.436% (20833/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0130, Accuracy: 3567/10000 (35.67%)

Epoch: 161
Loss: 2.023 | Acc: 39.062% (25/64)
Loss: 1.832 | Acc: 45.978% (2972/6464)
Loss: 1.820 | Acc: 46.362% (5964/12864)
Loss: 1.827 | Acc: 46.039% (8869/19264)
Loss: 1.829 | Acc: 45.959% (11795/25664)
Loss: 1.829 | Acc: 46.027% (14758/32064)
Loss: 1.827 | Acc: 46.126% (17742/38464)
Loss: 1.826 | Acc: 46.153% (20706/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0657, Accuracy: 3391/10000 (33.91%)

Epoch: 162
Loss: 1.709 | Acc: 56.250% (36/64)
Loss: 1.815 | Acc: 47.076% (3043/6464)
Loss: 1.812 | Acc: 46.929% (6037/12864)
Loss: 1.813 | Acc: 46.865% (9028/19264)
Loss: 1.816 | Acc: 46.758% (12000/25664)
Loss: 1.820 | Acc: 46.579% (14935/32064)
Loss: 1.817 | Acc: 46.802% (18002/38464)
Loss: 1.817 | Acc: 46.750% (20974/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1693, Accuracy: 3221/10000 (32.21%)

Epoch: 163
Loss: 1.889 | Acc: 43.750% (28/64)
Loss: 1.799 | Acc: 47.231% (3053/6464)
Loss: 1.802 | Acc: 47.326% (6088/12864)
Loss: 1.810 | Acc: 46.813% (9018/19264)
Loss: 1.814 | Acc: 46.719% (11990/25664)
Loss: 1.816 | Acc: 46.535% (14921/32064)
Loss: 1.817 | Acc: 46.529% (17897/38464)
Loss: 1.819 | Acc: 46.451% (20840/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0010, Accuracy: 3826/10000 (38.26%)

Epoch: 164
Loss: 1.971 | Acc: 39.062% (25/64)
Loss: 1.816 | Acc: 46.767% (3023/6464)
Loss: 1.807 | Acc: 47.093% (6058/12864)
Loss: 1.810 | Acc: 46.880% (9031/19264)
Loss: 1.816 | Acc: 46.552% (11947/25664)
Loss: 1.814 | Acc: 46.576% (14934/32064)
Loss: 1.817 | Acc: 46.573% (17914/38464)
Loss: 1.818 | Acc: 46.552% (20885/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9830, Accuracy: 3802/10000 (38.02%)

Epoch: 165
Loss: 2.036 | Acc: 39.062% (25/64)
Loss: 1.827 | Acc: 46.334% (2995/6464)
Loss: 1.818 | Acc: 46.517% (5984/12864)
Loss: 1.815 | Acc: 46.662% (8989/19264)
Loss: 1.813 | Acc: 46.731% (11993/25664)
Loss: 1.810 | Acc: 46.856% (15024/32064)
Loss: 1.811 | Acc: 46.930% (18051/38464)
Loss: 1.811 | Acc: 46.873% (21029/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9498, Accuracy: 4049/10000 (40.49%)

Epoch: 166
Loss: 1.959 | Acc: 40.625% (26/64)
Loss: 1.791 | Acc: 47.834% (3092/6464)
Loss: 1.796 | Acc: 47.481% (6108/12864)
Loss: 1.795 | Acc: 47.342% (9120/19264)
Loss: 1.803 | Acc: 47.097% (12087/25664)
Loss: 1.806 | Acc: 46.978% (15063/32064)
Loss: 1.808 | Acc: 46.932% (18052/38464)
Loss: 1.808 | Acc: 46.915% (21048/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9062, Accuracy: 4303/10000 (43.03%)

Epoch: 167
Loss: 2.064 | Acc: 40.625% (26/64)
Loss: 1.800 | Acc: 47.045% (3041/6464)
Loss: 1.800 | Acc: 47.201% (6072/12864)
Loss: 1.801 | Acc: 47.373% (9126/19264)
Loss: 1.798 | Acc: 47.553% (12204/25664)
Loss: 1.800 | Acc: 47.368% (15188/32064)
Loss: 1.803 | Acc: 47.255% (18176/38464)
Loss: 1.804 | Acc: 47.171% (21163/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9444, Accuracy: 4174/10000 (41.74%)

Epoch: 168
Loss: 1.730 | Acc: 50.000% (32/64)
Loss: 1.799 | Acc: 47.432% (3066/6464)
Loss: 1.806 | Acc: 47.147% (6065/12864)
Loss: 1.803 | Acc: 47.249% (9102/19264)
Loss: 1.798 | Acc: 47.424% (12171/25664)
Loss: 1.800 | Acc: 47.343% (15180/32064)
Loss: 1.798 | Acc: 47.369% (18220/38464)
Loss: 1.801 | Acc: 47.223% (21186/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0090, Accuracy: 3683/10000 (36.83%)

Epoch: 169
Loss: 1.918 | Acc: 42.188% (27/64)
Loss: 1.804 | Acc: 47.308% (3058/6464)
Loss: 1.805 | Acc: 47.248% (6078/12864)
Loss: 1.801 | Acc: 47.410% (9133/19264)
Loss: 1.802 | Acc: 47.444% (12176/25664)
Loss: 1.802 | Acc: 47.496% (15229/32064)
Loss: 1.801 | Acc: 47.533% (18283/38464)
Loss: 1.801 | Acc: 47.533% (21325/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0757, Accuracy: 3396/10000 (33.96%)

Epoch: 170
Loss: 1.932 | Acc: 40.625% (26/64)
Loss: 1.777 | Acc: 48.422% (3130/6464)
Loss: 1.787 | Acc: 47.878% (6159/12864)
Loss: 1.790 | Acc: 47.711% (9191/19264)
Loss: 1.792 | Acc: 47.654% (12230/25664)
Loss: 1.792 | Acc: 47.658% (15281/32064)
Loss: 1.792 | Acc: 47.694% (18345/38464)
Loss: 1.794 | Acc: 47.633% (21370/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9757, Accuracy: 3933/10000 (39.33%)

Epoch: 171
Loss: 1.803 | Acc: 43.750% (28/64)
Loss: 1.769 | Acc: 48.561% (3139/6464)
Loss: 1.778 | Acc: 48.235% (6205/12864)
Loss: 1.780 | Acc: 48.178% (9281/19264)
Loss: 1.784 | Acc: 47.978% (12313/25664)
Loss: 1.783 | Acc: 48.029% (15400/32064)
Loss: 1.786 | Acc: 47.985% (18457/38464)
Loss: 1.790 | Acc: 47.900% (21490/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9652, Accuracy: 3950/10000 (39.50%)

Epoch: 172
Loss: 1.814 | Acc: 43.750% (28/64)
Loss: 1.782 | Acc: 48.097% (3109/6464)
Loss: 1.771 | Acc: 48.686% (6263/12864)
Loss: 1.769 | Acc: 48.811% (9403/19264)
Loss: 1.772 | Acc: 48.648% (12485/25664)
Loss: 1.777 | Acc: 48.434% (15530/32064)
Loss: 1.780 | Acc: 48.279% (18570/38464)
Loss: 1.781 | Acc: 48.241% (21643/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9747, Accuracy: 3967/10000 (39.67%)

Epoch: 173
Loss: 1.800 | Acc: 48.438% (31/64)
Loss: 1.802 | Acc: 47.416% (3065/6464)
Loss: 1.787 | Acc: 48.111% (6189/12864)
Loss: 1.782 | Acc: 48.292% (9303/19264)
Loss: 1.780 | Acc: 48.387% (12418/25664)
Loss: 1.776 | Acc: 48.606% (15585/32064)
Loss: 1.778 | Acc: 48.518% (18662/38464)
Loss: 1.776 | Acc: 48.560% (21786/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9075, Accuracy: 4244/10000 (42.44%)

Epoch: 174
Loss: 1.829 | Acc: 48.438% (31/64)
Loss: 1.757 | Acc: 49.087% (3173/6464)
Loss: 1.765 | Acc: 48.741% (6270/12864)
Loss: 1.755 | Acc: 49.351% (9507/19264)
Loss: 1.760 | Acc: 49.151% (12614/25664)
Loss: 1.765 | Acc: 48.924% (15687/32064)
Loss: 1.767 | Acc: 48.783% (18764/38464)
Loss: 1.769 | Acc: 48.674% (21837/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9295, Accuracy: 4182/10000 (41.82%)

Epoch: 175
Loss: 1.783 | Acc: 45.312% (29/64)
Loss: 1.760 | Acc: 49.072% (3172/6464)
Loss: 1.762 | Acc: 48.756% (6272/12864)
Loss: 1.758 | Acc: 48.972% (9434/19264)
Loss: 1.756 | Acc: 48.956% (12564/25664)
Loss: 1.753 | Acc: 49.227% (15784/32064)
Loss: 1.755 | Acc: 49.225% (18934/38464)
Loss: 1.759 | Acc: 49.053% (22007/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9166, Accuracy: 4204/10000 (42.04%)

Epoch: 176
Loss: 1.822 | Acc: 46.875% (30/64)
Loss: 1.765 | Acc: 48.422% (3130/6464)
Loss: 1.765 | Acc: 48.655% (6259/12864)
Loss: 1.761 | Acc: 48.894% (9419/19264)
Loss: 1.764 | Acc: 48.925% (12556/25664)
Loss: 1.762 | Acc: 49.036% (15723/32064)
Loss: 1.757 | Acc: 49.272% (18952/38464)
Loss: 1.753 | Acc: 49.436% (22179/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9015, Accuracy: 4303/10000 (43.03%)

Epoch: 177
Loss: 1.691 | Acc: 51.562% (33/64)
Loss: 1.757 | Acc: 49.242% (3183/6464)
Loss: 1.736 | Acc: 50.148% (6451/12864)
Loss: 1.740 | Acc: 49.969% (9626/19264)
Loss: 1.744 | Acc: 49.817% (12785/25664)
Loss: 1.747 | Acc: 49.688% (15932/32064)
Loss: 1.746 | Acc: 49.680% (19109/38464)
Loss: 1.746 | Acc: 49.706% (22300/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9122, Accuracy: 4237/10000 (42.37%)

Epoch: 178
Loss: 1.646 | Acc: 54.688% (35/64)
Loss: 1.711 | Acc: 50.603% (3271/6464)
Loss: 1.739 | Acc: 49.596% (6380/12864)
Loss: 1.731 | Acc: 49.891% (9611/19264)
Loss: 1.736 | Acc: 49.797% (12780/25664)
Loss: 1.735 | Acc: 49.869% (15990/32064)
Loss: 1.733 | Acc: 50.013% (19237/38464)
Loss: 1.736 | Acc: 49.958% (22413/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9204, Accuracy: 4152/10000 (41.52%)

Epoch: 179
Loss: 1.595 | Acc: 59.375% (38/64)
Loss: 1.726 | Acc: 50.186% (3244/6464)
Loss: 1.714 | Acc: 50.723% (6525/12864)
Loss: 1.717 | Acc: 50.483% (9725/19264)
Loss: 1.719 | Acc: 50.495% (12959/25664)
Loss: 1.718 | Acc: 50.639% (16237/32064)
Loss: 1.718 | Acc: 50.653% (19483/38464)
Loss: 1.723 | Acc: 50.457% (22637/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9217, Accuracy: 4155/10000 (41.55%)

Epoch: 180
Loss: 1.816 | Acc: 46.875% (30/64)
Loss: 1.703 | Acc: 51.114% (3304/6464)
Loss: 1.707 | Acc: 50.964% (6556/12864)
Loss: 1.706 | Acc: 51.028% (9830/19264)
Loss: 1.703 | Acc: 51.111% (13117/25664)
Loss: 1.712 | Acc: 50.733% (16267/32064)
Loss: 1.715 | Acc: 50.751% (19521/38464)
Loss: 1.716 | Acc: 50.707% (22749/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9036, Accuracy: 4404/10000 (44.04%)

Epoch: 181
Loss: 1.600 | Acc: 56.250% (36/64)
Loss: 1.679 | Acc: 51.717% (3343/6464)
Loss: 1.683 | Acc: 51.718% (6653/12864)
Loss: 1.680 | Acc: 51.775% (9974/19264)
Loss: 1.686 | Acc: 51.601% (13243/25664)
Loss: 1.693 | Acc: 51.378% (16474/32064)
Loss: 1.699 | Acc: 51.206% (19696/38464)
Loss: 1.703 | Acc: 51.110% (22930/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8981, Accuracy: 4331/10000 (43.31%)

Epoch: 182
Loss: 2.056 | Acc: 28.125% (18/64)
Loss: 1.696 | Acc: 50.665% (3275/6464)
Loss: 1.678 | Acc: 51.772% (6660/12864)
Loss: 1.675 | Acc: 51.973% (10012/19264)
Loss: 1.679 | Acc: 51.976% (13339/25664)
Loss: 1.685 | Acc: 51.812% (16613/32064)
Loss: 1.686 | Acc: 51.757% (19908/38464)
Loss: 1.689 | Acc: 51.625% (23161/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9141, Accuracy: 4365/10000 (43.65%)

Epoch: 183
Loss: 1.651 | Acc: 54.688% (35/64)
Loss: 1.666 | Acc: 52.259% (3378/6464)
Loss: 1.673 | Acc: 52.099% (6702/12864)
Loss: 1.674 | Acc: 52.092% (10035/19264)
Loss: 1.679 | Acc: 51.933% (13328/25664)
Loss: 1.683 | Acc: 51.775% (16601/32064)
Loss: 1.681 | Acc: 51.783% (19918/38464)
Loss: 1.681 | Acc: 51.834% (23255/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9118, Accuracy: 4455/10000 (44.55%)

Epoch: 184
Loss: 1.476 | Acc: 57.812% (37/64)
Loss: 1.652 | Acc: 52.924% (3421/6464)
Loss: 1.654 | Acc: 52.674% (6776/12864)
Loss: 1.654 | Acc: 52.715% (10155/19264)
Loss: 1.653 | Acc: 52.829% (13558/25664)
Loss: 1.654 | Acc: 52.791% (16927/32064)
Loss: 1.655 | Acc: 52.727% (20281/38464)
Loss: 1.661 | Acc: 52.496% (23552/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9516, Accuracy: 4265/10000 (42.65%)

Epoch: 185
Loss: 1.790 | Acc: 50.000% (32/64)
Loss: 1.624 | Acc: 53.311% (3446/6464)
Loss: 1.633 | Acc: 53.039% (6823/12864)
Loss: 1.633 | Acc: 53.234% (10255/19264)
Loss: 1.638 | Acc: 53.187% (13650/25664)
Loss: 1.640 | Acc: 53.150% (17042/32064)
Loss: 1.636 | Acc: 53.278% (20493/38464)
Loss: 1.640 | Acc: 53.072% (23810/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9138, Accuracy: 4386/10000 (43.86%)

Epoch: 186
Loss: 1.505 | Acc: 54.688% (35/64)
Loss: 1.607 | Acc: 53.929% (3486/6464)
Loss: 1.609 | Acc: 53.669% (6904/12864)
Loss: 1.615 | Acc: 53.670% (10339/19264)
Loss: 1.616 | Acc: 53.698% (13781/25664)
Loss: 1.616 | Acc: 53.789% (17247/32064)
Loss: 1.620 | Acc: 53.723% (20664/38464)
Loss: 1.620 | Acc: 53.711% (24097/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9088, Accuracy: 4441/10000 (44.41%)

Epoch: 187
Loss: 1.495 | Acc: 60.938% (39/64)
Loss: 1.596 | Acc: 53.899% (3484/6464)
Loss: 1.585 | Acc: 54.361% (6993/12864)
Loss: 1.587 | Acc: 54.506% (10500/19264)
Loss: 1.594 | Acc: 54.255% (13924/25664)
Loss: 1.593 | Acc: 54.379% (17436/32064)
Loss: 1.595 | Acc: 54.363% (20910/38464)
Loss: 1.595 | Acc: 54.371% (24393/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9645, Accuracy: 4309/10000 (43.09%)

Epoch: 188
Loss: 1.438 | Acc: 60.938% (39/64)
Loss: 1.554 | Acc: 55.523% (3589/6464)
Loss: 1.561 | Acc: 55.224% (7104/12864)
Loss: 1.559 | Acc: 55.264% (10646/19264)
Loss: 1.559 | Acc: 55.163% (14157/25664)
Loss: 1.559 | Acc: 55.196% (17698/32064)
Loss: 1.557 | Acc: 55.280% (21263/38464)
Loss: 1.563 | Acc: 55.075% (24709/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9404, Accuracy: 4357/10000 (43.57%)

Epoch: 189
Loss: 1.509 | Acc: 57.812% (37/64)
Loss: 1.529 | Acc: 56.126% (3628/6464)
Loss: 1.526 | Acc: 56.001% (7204/12864)
Loss: 1.523 | Acc: 56.219% (10830/19264)
Loss: 1.527 | Acc: 56.063% (14388/25664)
Loss: 1.531 | Acc: 55.944% (17938/32064)
Loss: 1.532 | Acc: 55.917% (21508/38464)
Loss: 1.534 | Acc: 55.748% (25011/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9879, Accuracy: 4302/10000 (43.02%)

Epoch: 190
Loss: 1.661 | Acc: 51.562% (33/64)
Loss: 1.479 | Acc: 57.348% (3707/6464)
Loss: 1.484 | Acc: 57.253% (7365/12864)
Loss: 1.483 | Acc: 57.158% (11011/19264)
Loss: 1.482 | Acc: 57.388% (14728/25664)
Loss: 1.485 | Acc: 57.239% (18353/32064)
Loss: 1.489 | Acc: 57.090% (21959/38464)
Loss: 1.491 | Acc: 57.122% (25627/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9944, Accuracy: 4328/10000 (43.28%)

Epoch: 191
Loss: 1.585 | Acc: 51.562% (33/64)
Loss: 1.420 | Acc: 58.787% (3800/6464)
Loss: 1.424 | Acc: 58.909% (7578/12864)
Loss: 1.434 | Acc: 58.513% (11272/19264)
Loss: 1.437 | Acc: 58.335% (14971/25664)
Loss: 1.439 | Acc: 58.365% (18714/32064)
Loss: 1.441 | Acc: 58.265% (22411/38464)
Loss: 1.444 | Acc: 58.180% (26102/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0447, Accuracy: 4311/10000 (43.11%)

Epoch: 192
Loss: 1.553 | Acc: 50.000% (32/64)
Loss: 1.409 | Acc: 58.787% (3800/6464)
Loss: 1.400 | Acc: 59.235% (7620/12864)
Loss: 1.386 | Acc: 59.666% (11494/19264)
Loss: 1.394 | Acc: 59.402% (15245/25664)
Loss: 1.401 | Acc: 59.132% (18960/32064)
Loss: 1.400 | Acc: 59.190% (22767/38464)
Loss: 1.397 | Acc: 59.290% (26600/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0788, Accuracy: 4370/10000 (43.70%)

Epoch: 193
Loss: 1.097 | Acc: 70.312% (45/64)
Loss: 1.317 | Acc: 61.355% (3966/6464)
Loss: 1.321 | Acc: 61.194% (7872/12864)
Loss: 1.322 | Acc: 61.348% (11818/19264)
Loss: 1.329 | Acc: 61.113% (15684/25664)
Loss: 1.326 | Acc: 61.240% (19636/32064)
Loss: 1.329 | Acc: 61.171% (23529/38464)
Loss: 1.332 | Acc: 61.060% (27394/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1319, Accuracy: 4274/10000 (42.74%)

Epoch: 194
Loss: 1.070 | Acc: 70.312% (45/64)
Loss: 1.255 | Acc: 62.918% (4067/6464)
Loss: 1.256 | Acc: 62.951% (8098/12864)
Loss: 1.256 | Acc: 63.004% (12137/19264)
Loss: 1.262 | Acc: 62.773% (16110/25664)
Loss: 1.265 | Acc: 62.537% (20052/32064)
Loss: 1.268 | Acc: 62.513% (24045/38464)
Loss: 1.266 | Acc: 62.634% (28100/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1781, Accuracy: 4246/10000 (42.46%)

Epoch: 195
Loss: 1.422 | Acc: 54.688% (35/64)
Loss: 1.187 | Acc: 65.408% (4228/6464)
Loss: 1.199 | Acc: 64.669% (8319/12864)
Loss: 1.206 | Acc: 64.270% (12381/19264)
Loss: 1.208 | Acc: 64.288% (16499/25664)
Loss: 1.208 | Acc: 64.306% (20619/32064)
Loss: 1.210 | Acc: 64.185% (24688/38464)
Loss: 1.212 | Acc: 64.134% (28773/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1675, Accuracy: 4272/10000 (42.72%)

Epoch: 196
Loss: 1.265 | Acc: 60.938% (39/64)
Loss: 1.150 | Acc: 65.656% (4244/6464)
Loss: 1.144 | Acc: 66.076% (8500/12864)
Loss: 1.159 | Acc: 65.355% (12590/19264)
Loss: 1.152 | Acc: 65.722% (16867/25664)
Loss: 1.152 | Acc: 65.778% (21091/32064)
Loss: 1.152 | Acc: 65.776% (25300/38464)
Loss: 1.155 | Acc: 65.783% (29513/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2325, Accuracy: 4193/10000 (41.93%)

Epoch: 197
Loss: 0.996 | Acc: 71.875% (46/64)
Loss: 1.108 | Acc: 67.249% (4347/6464)
Loss: 1.111 | Acc: 67.195% (8644/12864)
Loss: 1.104 | Acc: 67.312% (12967/19264)
Loss: 1.109 | Acc: 67.160% (17236/25664)
Loss: 1.107 | Acc: 67.138% (21527/32064)
Loss: 1.104 | Acc: 67.229% (25859/38464)
Loss: 1.109 | Acc: 67.085% (30097/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2873, Accuracy: 4097/10000 (40.97%)
torch.Size([100, 10])
Test set: Average loss: 2.2873, Accuracy: 4097/10000 (40.97%)

Epoch: 198
Loss: 0.862 | Acc: 78.125% (50/64)
Loss: 1.054 | Acc: 68.750% (4444/6464)
Loss: 1.068 | Acc: 68.385% (8797/12864)
Loss: 1.073 | Acc: 68.246% (13147/19264)
Loss: 1.074 | Acc: 68.216% (17507/25664)
Loss: 1.078 | Acc: 67.952% (21788/32064)
Loss: 1.077 | Acc: 68.006% (26158/38464)
Loss: 1.078 | Acc: 67.956% (30488/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2702, Accuracy: 4096/10000 (40.96%)
torch.Size([100, 10])
Test set: Average loss: 2.2702, Accuracy: 4096/10000 (40.96%)

Epoch: 199
Loss: 1.166 | Acc: 65.625% (42/64)
Loss: 1.077 | Acc: 67.713% (4377/6464)
Loss: 1.070 | Acc: 67.926% (8738/12864)
Loss: 1.062 | Acc: 68.267% (13151/19264)
Loss: 1.060 | Acc: 68.423% (17560/25664)
Loss: 1.059 | Acc: 68.485% (21959/32064)
Loss: 1.058 | Acc: 68.482% (26341/38464)
Loss: 1.061 | Acc: 68.425% (30698/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2780, Accuracy: 4108/10000 (41.08%)
torch.Size([100, 10])
Test set: Average loss: 2.2780, Accuracy: 4108/10000 (41.08%)
4571
10000
-1.9668532609939575
