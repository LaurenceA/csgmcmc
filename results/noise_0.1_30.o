==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.358 | Acc: 15.625% (10/64)
Loss: 3.091 | Acc: 13.165% (851/6464)
Loss: 2.617 | Acc: 16.115% (2073/12864)
Loss: 2.442 | Acc: 17.566% (3384/19264)
Loss: 2.340 | Acc: 19.221% (4933/25664)
Loss: 2.270 | Acc: 20.562% (6593/32064)
Loss: 2.219 | Acc: 21.758% (8369/38464)
Loss: 2.173 | Acc: 22.989% (10314/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4149, Accuracy: 2007/10000 (20.07%)

Epoch: 1
Loss: 2.482 | Acc: 20.312% (13/64)
Loss: 1.872 | Acc: 31.652% (2046/6464)
Loss: 1.852 | Acc: 32.859% (4227/12864)
Loss: 1.835 | Acc: 33.627% (6478/19264)
Loss: 1.823 | Acc: 34.324% (8809/25664)
Loss: 1.809 | Acc: 34.996% (11221/32064)
Loss: 1.798 | Acc: 35.483% (13648/38464)
Loss: 1.785 | Acc: 36.120% (16205/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2136, Accuracy: 3056/10000 (30.56%)

Epoch: 2
Loss: 1.488 | Acc: 50.000% (32/64)
Loss: 1.670 | Acc: 41.259% (2667/6464)
Loss: 1.665 | Acc: 41.441% (5331/12864)
Loss: 1.652 | Acc: 42.457% (8179/19264)
Loss: 1.638 | Acc: 43.017% (11040/25664)
Loss: 1.627 | Acc: 43.466% (13937/32064)
Loss: 1.620 | Acc: 43.828% (16858/38464)
Loss: 1.613 | Acc: 44.145% (19805/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8111, Accuracy: 3963/10000 (39.63%)

Epoch: 3
Loss: 1.618 | Acc: 48.438% (31/64)
Loss: 1.530 | Acc: 47.649% (3080/6464)
Loss: 1.539 | Acc: 47.839% (6154/12864)
Loss: 1.520 | Acc: 48.739% (9389/19264)
Loss: 1.505 | Acc: 49.392% (12676/25664)
Loss: 1.493 | Acc: 49.935% (16011/32064)
Loss: 1.479 | Acc: 50.385% (19380/38464)
Loss: 1.470 | Acc: 50.782% (22783/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9042, Accuracy: 3867/10000 (38.67%)

Epoch: 4
Loss: 1.578 | Acc: 45.312% (29/64)
Loss: 1.386 | Acc: 55.647% (3597/6464)
Loss: 1.368 | Acc: 55.861% (7186/12864)
Loss: 1.359 | Acc: 56.037% (10795/19264)
Loss: 1.350 | Acc: 56.457% (14489/25664)
Loss: 1.341 | Acc: 56.921% (18251/32064)
Loss: 1.331 | Acc: 57.319% (22047/38464)
Loss: 1.327 | Acc: 57.596% (25840/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5905, Accuracy: 4887/10000 (48.87%)

Epoch: 5
Loss: 1.563 | Acc: 53.125% (34/64)
Loss: 1.237 | Acc: 61.046% (3946/6464)
Loss: 1.248 | Acc: 60.704% (7809/12864)
Loss: 1.242 | Acc: 61.088% (11768/19264)
Loss: 1.239 | Acc: 61.214% (15710/25664)
Loss: 1.229 | Acc: 61.521% (19726/32064)
Loss: 1.225 | Acc: 61.795% (23769/38464)
Loss: 1.219 | Acc: 62.134% (27876/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5670, Accuracy: 4974/10000 (49.74%)

Epoch: 6
Loss: 1.260 | Acc: 67.188% (43/64)
Loss: 1.157 | Acc: 65.439% (4230/6464)
Loss: 1.152 | Acc: 65.648% (8445/12864)
Loss: 1.145 | Acc: 65.625% (12642/19264)
Loss: 1.141 | Acc: 65.695% (16860/25664)
Loss: 1.130 | Acc: 66.046% (21177/32064)
Loss: 1.130 | Acc: 66.197% (25462/38464)
Loss: 1.128 | Acc: 66.256% (29725/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7351, Accuracy: 4613/10000 (46.13%)

Epoch: 7
Loss: 1.237 | Acc: 65.625% (42/64)
Loss: 1.080 | Acc: 68.162% (4406/6464)
Loss: 1.088 | Acc: 67.771% (8718/12864)
Loss: 1.086 | Acc: 68.086% (13116/19264)
Loss: 1.081 | Acc: 68.267% (17520/25664)
Loss: 1.073 | Acc: 68.510% (21967/32064)
Loss: 1.073 | Acc: 68.547% (26366/38464)
Loss: 1.066 | Acc: 68.685% (30815/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1716, Accuracy: 6464/10000 (64.64%)

Epoch: 8
Loss: 1.137 | Acc: 67.188% (43/64)
Loss: 1.037 | Acc: 69.152% (4470/6464)
Loss: 1.033 | Acc: 69.551% (8947/12864)
Loss: 1.032 | Acc: 69.908% (13467/19264)
Loss: 1.030 | Acc: 70.153% (18004/25664)
Loss: 1.025 | Acc: 70.272% (22532/32064)
Loss: 1.026 | Acc: 70.266% (27027/38464)
Loss: 1.024 | Acc: 70.404% (31586/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3038, Accuracy: 6070/10000 (60.70%)

Epoch: 9
Loss: 1.328 | Acc: 59.375% (38/64)
Loss: 0.985 | Acc: 71.983% (4653/6464)
Loss: 1.003 | Acc: 71.440% (9190/12864)
Loss: 1.001 | Acc: 71.268% (13729/19264)
Loss: 0.996 | Acc: 71.415% (18328/25664)
Loss: 1.000 | Acc: 71.357% (22880/32064)
Loss: 0.998 | Acc: 71.337% (27439/38464)
Loss: 0.994 | Acc: 71.460% (32060/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5489, Accuracy: 5208/10000 (52.08%)

Epoch: 10
Loss: 1.007 | Acc: 73.438% (47/64)
Loss: 0.994 | Acc: 71.457% (4619/6464)
Loss: 0.978 | Acc: 72.201% (9288/12864)
Loss: 0.977 | Acc: 72.129% (13895/19264)
Loss: 0.966 | Acc: 72.506% (18608/25664)
Loss: 0.969 | Acc: 72.645% (23293/32064)
Loss: 0.969 | Acc: 72.741% (27979/38464)
Loss: 0.969 | Acc: 72.695% (32614/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0340, Accuracy: 7059/10000 (70.59%)

Epoch: 11
Loss: 1.188 | Acc: 64.062% (41/64)
Loss: 0.958 | Acc: 73.020% (4720/6464)
Loss: 0.956 | Acc: 73.165% (9412/12864)
Loss: 0.942 | Acc: 73.645% (14187/19264)
Loss: 0.944 | Acc: 73.605% (18890/25664)
Loss: 0.945 | Acc: 73.590% (23596/32064)
Loss: 0.947 | Acc: 73.575% (28300/38464)
Loss: 0.950 | Acc: 73.522% (32985/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1798, Accuracy: 6566/10000 (65.66%)

Epoch: 12
Loss: 0.955 | Acc: 76.562% (49/64)
Loss: 0.925 | Acc: 74.613% (4823/6464)
Loss: 0.927 | Acc: 74.433% (9575/12864)
Loss: 0.926 | Acc: 74.408% (14334/19264)
Loss: 0.926 | Acc: 74.287% (19065/25664)
Loss: 0.926 | Acc: 74.292% (23821/32064)
Loss: 0.926 | Acc: 74.384% (28611/38464)
Loss: 0.930 | Acc: 74.282% (33326/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6130, Accuracy: 5023/10000 (50.23%)

Epoch: 13
Loss: 1.240 | Acc: 62.500% (40/64)
Loss: 0.914 | Acc: 75.743% (4896/6464)
Loss: 0.914 | Acc: 75.295% (9686/12864)
Loss: 0.914 | Acc: 75.234% (14493/19264)
Loss: 0.915 | Acc: 75.199% (19299/25664)
Loss: 0.908 | Acc: 75.315% (24149/32064)
Loss: 0.908 | Acc: 75.330% (28975/38464)
Loss: 0.909 | Acc: 75.332% (33797/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2283, Accuracy: 6427/10000 (64.27%)

Epoch: 14
Loss: 1.159 | Acc: 68.750% (44/64)
Loss: 0.934 | Acc: 74.257% (4800/6464)
Loss: 0.914 | Acc: 74.891% (9634/12864)
Loss: 0.902 | Acc: 75.265% (14499/19264)
Loss: 0.898 | Acc: 75.464% (19367/25664)
Loss: 0.895 | Acc: 75.540% (24221/32064)
Loss: 0.893 | Acc: 75.549% (29059/38464)
Loss: 0.895 | Acc: 75.562% (33900/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5190, Accuracy: 5532/10000 (55.32%)

Epoch: 15
Loss: 1.134 | Acc: 71.875% (46/64)
Loss: 0.863 | Acc: 76.532% (4947/6464)
Loss: 0.873 | Acc: 76.547% (9847/12864)
Loss: 0.885 | Acc: 76.106% (14661/19264)
Loss: 0.878 | Acc: 76.266% (19573/25664)
Loss: 0.877 | Acc: 76.285% (24460/32064)
Loss: 0.877 | Acc: 76.292% (29345/38464)
Loss: 0.877 | Acc: 76.295% (34229/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0118, Accuracy: 7195/10000 (71.95%)

Epoch: 16
Loss: 0.945 | Acc: 73.438% (47/64)
Loss: 0.849 | Acc: 77.429% (5005/6464)
Loss: 0.850 | Acc: 77.324% (9947/12864)
Loss: 0.851 | Acc: 77.180% (14868/19264)
Loss: 0.858 | Acc: 76.777% (19704/25664)
Loss: 0.858 | Acc: 76.824% (24633/32064)
Loss: 0.861 | Acc: 76.825% (29550/38464)
Loss: 0.858 | Acc: 76.930% (34514/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6927, Accuracy: 5494/10000 (54.94%)

Epoch: 17
Loss: 1.019 | Acc: 67.188% (43/64)
Loss: 0.841 | Acc: 77.150% (4987/6464)
Loss: 0.852 | Acc: 76.866% (9888/12864)
Loss: 0.853 | Acc: 76.838% (14802/19264)
Loss: 0.850 | Acc: 77.018% (19766/25664)
Loss: 0.848 | Acc: 77.143% (24735/32064)
Loss: 0.849 | Acc: 77.103% (29657/38464)
Loss: 0.847 | Acc: 77.109% (34594/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2052, Accuracy: 6636/10000 (66.36%)

Epoch: 18
Loss: 0.776 | Acc: 76.562% (49/64)
Loss: 0.818 | Acc: 78.574% (5079/6464)
Loss: 0.822 | Acc: 78.521% (10101/12864)
Loss: 0.828 | Acc: 78.327% (15089/19264)
Loss: 0.832 | Acc: 78.219% (20074/25664)
Loss: 0.831 | Acc: 78.147% (25057/32064)
Loss: 0.833 | Acc: 78.052% (30022/38464)
Loss: 0.835 | Acc: 77.933% (34964/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0061, Accuracy: 7205/10000 (72.05%)

Epoch: 19
Loss: 1.055 | Acc: 73.438% (47/64)
Loss: 0.820 | Acc: 78.651% (5084/6464)
Loss: 0.818 | Acc: 78.537% (10103/12864)
Loss: 0.809 | Acc: 78.701% (15161/19264)
Loss: 0.810 | Acc: 78.822% (20229/25664)
Loss: 0.813 | Acc: 78.655% (25220/32064)
Loss: 0.814 | Acc: 78.588% (30228/38464)
Loss: 0.816 | Acc: 78.531% (35232/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1878, Accuracy: 6547/10000 (65.47%)

Epoch: 20
Loss: 0.714 | Acc: 81.250% (52/64)
Loss: 0.798 | Acc: 79.471% (5137/6464)
Loss: 0.802 | Acc: 79.003% (10163/12864)
Loss: 0.803 | Acc: 78.935% (15206/19264)
Loss: 0.805 | Acc: 78.826% (20230/25664)
Loss: 0.801 | Acc: 78.911% (25302/32064)
Loss: 0.805 | Acc: 78.863% (30334/38464)
Loss: 0.805 | Acc: 78.936% (35414/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9141, Accuracy: 4872/10000 (48.72%)

Epoch: 21
Loss: 0.774 | Acc: 81.250% (52/64)
Loss: 0.794 | Acc: 78.728% (5089/6464)
Loss: 0.798 | Acc: 78.731% (10128/12864)
Loss: 0.790 | Acc: 79.106% (15239/19264)
Loss: 0.799 | Acc: 78.974% (20268/25664)
Loss: 0.798 | Acc: 79.064% (25351/32064)
Loss: 0.797 | Acc: 79.116% (30431/38464)
Loss: 0.795 | Acc: 79.188% (35527/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0224, Accuracy: 7134/10000 (71.34%)

Epoch: 22
Loss: 0.641 | Acc: 85.938% (55/64)
Loss: 0.772 | Acc: 80.538% (5206/6464)
Loss: 0.790 | Acc: 79.540% (10232/12864)
Loss: 0.780 | Acc: 79.755% (15364/19264)
Loss: 0.791 | Acc: 79.458% (20392/25664)
Loss: 0.781 | Acc: 79.703% (25556/32064)
Loss: 0.779 | Acc: 79.797% (30693/38464)
Loss: 0.779 | Acc: 79.799% (35801/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1997, Accuracy: 6518/10000 (65.18%)

Epoch: 23
Loss: 0.853 | Acc: 78.125% (50/64)
Loss: 0.742 | Acc: 81.235% (5251/6464)
Loss: 0.764 | Acc: 80.473% (10352/12864)
Loss: 0.767 | Acc: 80.347% (15478/19264)
Loss: 0.765 | Acc: 80.319% (20613/25664)
Loss: 0.766 | Acc: 80.221% (25722/32064)
Loss: 0.767 | Acc: 80.205% (30850/38464)
Loss: 0.767 | Acc: 80.182% (35973/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1488, Accuracy: 6689/10000 (66.89%)

Epoch: 24
Loss: 0.812 | Acc: 81.250% (52/64)
Loss: 0.753 | Acc: 80.461% (5201/6464)
Loss: 0.762 | Acc: 80.418% (10345/12864)
Loss: 0.757 | Acc: 80.762% (15558/19264)
Loss: 0.760 | Acc: 80.724% (20717/25664)
Loss: 0.758 | Acc: 80.760% (25895/32064)
Loss: 0.757 | Acc: 80.735% (31054/38464)
Loss: 0.758 | Acc: 80.668% (36191/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2140, Accuracy: 6552/10000 (65.52%)

Epoch: 25
Loss: 0.828 | Acc: 82.812% (53/64)
Loss: 0.743 | Acc: 81.173% (5247/6464)
Loss: 0.755 | Acc: 80.892% (10406/12864)
Loss: 0.745 | Acc: 81.110% (15625/19264)
Loss: 0.745 | Acc: 81.125% (20820/25664)
Loss: 0.742 | Acc: 81.353% (26085/32064)
Loss: 0.744 | Acc: 81.195% (31231/38464)
Loss: 0.744 | Acc: 81.165% (36414/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0351, Accuracy: 4359/10000 (43.59%)

Epoch: 26
Loss: 0.684 | Acc: 81.250% (52/64)
Loss: 0.754 | Acc: 80.647% (5213/6464)
Loss: 0.743 | Acc: 81.219% (10448/12864)
Loss: 0.731 | Acc: 81.401% (15681/19264)
Loss: 0.739 | Acc: 81.250% (20852/25664)
Loss: 0.737 | Acc: 81.350% (26084/32064)
Loss: 0.731 | Acc: 81.567% (31374/38464)
Loss: 0.728 | Acc: 81.622% (36619/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8976, Accuracy: 7672/10000 (76.72%)

Epoch: 27
Loss: 0.705 | Acc: 76.562% (49/64)
Loss: 0.745 | Acc: 81.265% (5253/6464)
Loss: 0.719 | Acc: 81.880% (10533/12864)
Loss: 0.718 | Acc: 81.769% (15752/19264)
Loss: 0.719 | Acc: 81.803% (20994/25664)
Loss: 0.713 | Acc: 82.033% (26303/32064)
Loss: 0.715 | Acc: 82.030% (31552/38464)
Loss: 0.717 | Acc: 81.999% (36788/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9082, Accuracy: 7590/10000 (75.90%)

Epoch: 28
Loss: 1.010 | Acc: 67.188% (43/64)
Loss: 0.683 | Acc: 82.936% (5361/6464)
Loss: 0.700 | Acc: 82.618% (10628/12864)
Loss: 0.694 | Acc: 82.776% (15946/19264)
Loss: 0.699 | Acc: 82.610% (21201/25664)
Loss: 0.697 | Acc: 82.653% (26502/32064)
Loss: 0.704 | Acc: 82.506% (31735/38464)
Loss: 0.704 | Acc: 82.532% (37027/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1897, Accuracy: 6646/10000 (66.46%)

Epoch: 29
Loss: 0.646 | Acc: 84.375% (54/64)
Loss: 0.661 | Acc: 83.988% (5429/6464)
Loss: 0.675 | Acc: 83.621% (10757/12864)
Loss: 0.675 | Acc: 83.612% (16107/19264)
Loss: 0.685 | Acc: 83.323% (21384/25664)
Loss: 0.684 | Acc: 83.258% (26696/32064)
Loss: 0.684 | Acc: 83.252% (32022/38464)
Loss: 0.682 | Acc: 83.261% (37354/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8248, Accuracy: 7941/10000 (79.41%)

Epoch: 30
Loss: 1.102 | Acc: 71.875% (46/64)
Loss: 0.650 | Acc: 84.669% (5473/6464)
Loss: 0.664 | Acc: 84.134% (10823/12864)
Loss: 0.661 | Acc: 84.100% (16201/19264)
Loss: 0.658 | Acc: 84.063% (21574/25664)
Loss: 0.668 | Acc: 83.776% (26862/32064)
Loss: 0.669 | Acc: 83.670% (32183/38464)
Loss: 0.672 | Acc: 83.615% (37513/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8282, Accuracy: 7931/10000 (79.31%)

Epoch: 31
Loss: 0.407 | Acc: 89.062% (57/64)
Loss: 0.632 | Acc: 84.545% (5465/6464)
Loss: 0.647 | Acc: 84.204% (10832/12864)
Loss: 0.652 | Acc: 84.271% (16234/19264)
Loss: 0.652 | Acc: 84.215% (21613/25664)
Loss: 0.657 | Acc: 84.044% (26948/32064)
Loss: 0.655 | Acc: 84.092% (32345/38464)
Loss: 0.659 | Acc: 83.960% (37668/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8447, Accuracy: 7855/10000 (78.55%)

Epoch: 32
Loss: 0.842 | Acc: 78.125% (50/64)
Loss: 0.640 | Acc: 84.916% (5489/6464)
Loss: 0.643 | Acc: 84.686% (10894/12864)
Loss: 0.642 | Acc: 84.707% (16318/19264)
Loss: 0.633 | Acc: 84.897% (21788/25664)
Loss: 0.634 | Acc: 84.896% (27221/32064)
Loss: 0.638 | Acc: 84.762% (32603/38464)
Loss: 0.636 | Acc: 84.874% (38078/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9323, Accuracy: 7561/10000 (75.61%)

Epoch: 33
Loss: 0.560 | Acc: 85.938% (55/64)
Loss: 0.592 | Acc: 85.752% (5543/6464)
Loss: 0.611 | Acc: 85.362% (10981/12864)
Loss: 0.610 | Acc: 85.341% (16440/19264)
Loss: 0.616 | Acc: 85.228% (21873/25664)
Loss: 0.612 | Acc: 85.373% (27374/32064)
Loss: 0.618 | Acc: 85.158% (32755/38464)
Loss: 0.618 | Acc: 85.160% (38206/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9687, Accuracy: 7454/10000 (74.54%)

Epoch: 34
Loss: 0.756 | Acc: 78.125% (50/64)
Loss: 0.589 | Acc: 86.371% (5583/6464)
Loss: 0.585 | Acc: 86.256% (11096/12864)
Loss: 0.586 | Acc: 86.259% (16617/19264)
Loss: 0.590 | Acc: 86.086% (22093/25664)
Loss: 0.595 | Acc: 85.959% (27562/32064)
Loss: 0.596 | Acc: 85.969% (33067/38464)
Loss: 0.599 | Acc: 85.882% (38530/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7888, Accuracy: 8102/10000 (81.02%)

Epoch: 35
Loss: 0.440 | Acc: 90.625% (58/64)
Loss: 0.545 | Acc: 87.113% (5631/6464)
Loss: 0.570 | Acc: 86.513% (11129/12864)
Loss: 0.576 | Acc: 86.405% (16645/19264)
Loss: 0.573 | Acc: 86.413% (22177/25664)
Loss: 0.574 | Acc: 86.418% (27709/32064)
Loss: 0.578 | Acc: 86.307% (33197/38464)
Loss: 0.579 | Acc: 86.252% (38696/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8062, Accuracy: 8052/10000 (80.52%)

Epoch: 36
Loss: 0.574 | Acc: 85.938% (55/64)
Loss: 0.547 | Acc: 87.098% (5630/6464)
Loss: 0.557 | Acc: 86.901% (11179/12864)
Loss: 0.554 | Acc: 86.877% (16736/19264)
Loss: 0.558 | Acc: 86.654% (22239/25664)
Loss: 0.558 | Acc: 86.692% (27797/32064)
Loss: 0.559 | Acc: 86.806% (33389/38464)
Loss: 0.560 | Acc: 86.818% (38950/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8604, Accuracy: 7891/10000 (78.91%)

Epoch: 37
Loss: 0.572 | Acc: 82.812% (53/64)
Loss: 0.520 | Acc: 87.949% (5685/6464)
Loss: 0.517 | Acc: 88.060% (11328/12864)
Loss: 0.520 | Acc: 88.014% (16955/19264)
Loss: 0.517 | Acc: 88.014% (22588/25664)
Loss: 0.526 | Acc: 87.790% (28149/32064)
Loss: 0.530 | Acc: 87.643% (33711/38464)
Loss: 0.535 | Acc: 87.520% (39265/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8150, Accuracy: 8054/10000 (80.54%)

Epoch: 38
Loss: 0.647 | Acc: 84.375% (54/64)
Loss: 0.512 | Acc: 87.701% (5669/6464)
Loss: 0.504 | Acc: 88.052% (11327/12864)
Loss: 0.503 | Acc: 88.045% (16961/19264)
Loss: 0.503 | Acc: 88.061% (22600/25664)
Loss: 0.509 | Acc: 87.890% (28181/32064)
Loss: 0.511 | Acc: 87.869% (33798/38464)
Loss: 0.510 | Acc: 87.910% (39440/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8288, Accuracy: 8015/10000 (80.15%)

Epoch: 39
Loss: 0.446 | Acc: 90.625% (58/64)
Loss: 0.453 | Acc: 89.635% (5794/6464)
Loss: 0.456 | Acc: 89.467% (11509/12864)
Loss: 0.460 | Acc: 89.348% (17212/19264)
Loss: 0.463 | Acc: 89.304% (22919/25664)
Loss: 0.471 | Acc: 89.112% (28573/32064)
Loss: 0.472 | Acc: 89.055% (34254/38464)
Loss: 0.476 | Acc: 88.900% (39884/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8713, Accuracy: 7958/10000 (79.58%)

Epoch: 40
Loss: 0.323 | Acc: 93.750% (60/64)
Loss: 0.451 | Acc: 89.279% (5771/6464)
Loss: 0.434 | Acc: 89.863% (11560/12864)
Loss: 0.441 | Acc: 89.722% (17284/19264)
Loss: 0.449 | Acc: 89.479% (22964/25664)
Loss: 0.448 | Acc: 89.496% (28696/32064)
Loss: 0.447 | Acc: 89.432% (34399/38464)
Loss: 0.449 | Acc: 89.399% (40108/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8380, Accuracy: 8116/10000 (81.16%)

Epoch: 41
Loss: 0.579 | Acc: 81.250% (52/64)
Loss: 0.398 | Acc: 90.625% (5858/6464)
Loss: 0.425 | Acc: 89.933% (11569/12864)
Loss: 0.422 | Acc: 90.002% (17338/19264)
Loss: 0.423 | Acc: 89.955% (23086/25664)
Loss: 0.420 | Acc: 90.042% (28871/32064)
Loss: 0.423 | Acc: 89.996% (34616/38464)
Loss: 0.423 | Acc: 90.008% (40381/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8508, Accuracy: 8155/10000 (81.55%)

Epoch: 42
Loss: 0.387 | Acc: 93.750% (60/64)
Loss: 0.384 | Acc: 90.842% (5872/6464)
Loss: 0.387 | Acc: 90.641% (11660/12864)
Loss: 0.388 | Acc: 90.583% (17450/19264)
Loss: 0.391 | Acc: 90.528% (23233/25664)
Loss: 0.388 | Acc: 90.538% (29030/32064)
Loss: 0.389 | Acc: 90.573% (34838/38464)
Loss: 0.388 | Acc: 90.645% (40667/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8540, Accuracy: 8193/10000 (81.93%)

Epoch: 43
Loss: 0.318 | Acc: 90.625% (58/64)
Loss: 0.352 | Acc: 91.166% (5893/6464)
Loss: 0.354 | Acc: 91.177% (11729/12864)
Loss: 0.348 | Acc: 91.419% (17611/19264)
Loss: 0.345 | Acc: 91.525% (23489/25664)
Loss: 0.344 | Acc: 91.495% (29337/32064)
Loss: 0.349 | Acc: 91.413% (35161/38464)
Loss: 0.348 | Acc: 91.492% (41047/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8693, Accuracy: 8210/10000 (82.10%)

Epoch: 44
Loss: 0.199 | Acc: 96.875% (62/64)
Loss: 0.305 | Acc: 92.358% (5970/6464)
Loss: 0.323 | Acc: 91.877% (11819/12864)
Loss: 0.318 | Acc: 92.094% (17741/19264)
Loss: 0.321 | Acc: 92.075% (23630/25664)
Loss: 0.324 | Acc: 91.947% (29482/32064)
Loss: 0.321 | Acc: 92.016% (35393/38464)
Loss: 0.318 | Acc: 92.107% (41323/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8822, Accuracy: 8215/10000 (82.15%)

Epoch: 45
Loss: 0.340 | Acc: 92.188% (59/64)
Loss: 0.284 | Acc: 92.946% (6008/6464)
Loss: 0.292 | Acc: 92.732% (11929/12864)
Loss: 0.287 | Acc: 92.826% (17882/19264)
Loss: 0.290 | Acc: 92.706% (23792/25664)
Loss: 0.291 | Acc: 92.718% (29729/32064)
Loss: 0.291 | Acc: 92.715% (35662/38464)
Loss: 0.290 | Acc: 92.714% (41595/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8753, Accuracy: 8216/10000 (82.16%)

Epoch: 46
Loss: 0.311 | Acc: 87.500% (56/64)
Loss: 0.292 | Acc: 92.420% (5974/6464)
Loss: 0.290 | Acc: 92.607% (11913/12864)
Loss: 0.283 | Acc: 92.847% (17886/19264)
Loss: 0.280 | Acc: 92.920% (23847/25664)
Loss: 0.279 | Acc: 92.964% (29808/32064)
Loss: 0.278 | Acc: 92.986% (35766/38464)
Loss: 0.277 | Acc: 92.994% (41721/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8704, Accuracy: 8211/10000 (82.11%)

Epoch: 47
Loss: 0.170 | Acc: 96.875% (62/64)
Loss: 0.264 | Acc: 93.348% (6034/6464)
Loss: 0.262 | Acc: 93.400% (12015/12864)
Loss: 0.263 | Acc: 93.444% (18001/19264)
Loss: 0.260 | Acc: 93.466% (23987/25664)
Loss: 0.263 | Acc: 93.376% (29940/32064)
Loss: 0.262 | Acc: 93.425% (35935/38464)
Loss: 0.261 | Acc: 93.425% (41914/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8720, Accuracy: 8224/10000 (82.24%)
torch.Size([100, 10])
Test set: Average loss: 0.8720, Accuracy: 8224/10000 (82.24%)

Epoch: 48
Loss: 0.288 | Acc: 93.750% (60/64)
Loss: 0.252 | Acc: 93.564% (6048/6464)
Loss: 0.249 | Acc: 93.540% (12033/12864)
Loss: 0.252 | Acc: 93.433% (17999/19264)
Loss: 0.252 | Acc: 93.454% (23984/25664)
Loss: 0.252 | Acc: 93.482% (29974/32064)
Loss: 0.256 | Acc: 93.420% (35933/38464)
Loss: 0.255 | Acc: 93.454% (41927/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8748, Accuracy: 8222/10000 (82.22%)
torch.Size([100, 10])
Test set: Average loss: 0.8748, Accuracy: 8222/10000 (82.22%)

Epoch: 49
Loss: 0.214 | Acc: 95.312% (61/64)
Loss: 0.261 | Acc: 93.425% (6039/6464)
Loss: 0.258 | Acc: 93.416% (12017/12864)
Loss: 0.254 | Acc: 93.584% (18028/19264)
Loss: 0.254 | Acc: 93.532% (24004/25664)
Loss: 0.253 | Acc: 93.560% (29999/32064)
Loss: 0.253 | Acc: 93.568% (35990/38464)
Loss: 0.252 | Acc: 93.590% (41988/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8746, Accuracy: 8214/10000 (82.14%)
torch.Size([100, 10])
Test set: Average loss: 0.8746, Accuracy: 8214/10000 (82.14%)

Epoch: 50
Loss: 0.181 | Acc: 95.312% (61/64)
Loss: 1.677 | Acc: 42.512% (2748/6464)
Loss: 1.393 | Acc: 54.688% (7035/12864)
Loss: 1.258 | Acc: 60.304% (11617/19264)
Loss: 1.195 | Acc: 63.225% (16226/25664)
Loss: 1.147 | Acc: 65.360% (20957/32064)
Loss: 1.111 | Acc: 66.847% (25712/38464)
Loss: 1.086 | Acc: 67.878% (30453/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8750, Accuracy: 4920/10000 (49.20%)

Epoch: 51
Loss: 1.239 | Acc: 64.062% (41/64)
Loss: 0.893 | Acc: 75.603% (4887/6464)
Loss: 0.891 | Acc: 75.653% (9732/12864)
Loss: 0.891 | Acc: 75.805% (14603/19264)
Loss: 0.890 | Acc: 75.694% (19426/25664)
Loss: 0.887 | Acc: 75.773% (24296/32064)
Loss: 0.880 | Acc: 75.983% (29226/38464)
Loss: 0.879 | Acc: 76.081% (34133/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0337, Accuracy: 7160/10000 (71.60%)

Epoch: 52
Loss: 0.820 | Acc: 78.125% (50/64)
Loss: 0.867 | Acc: 76.624% (4953/6464)
Loss: 0.851 | Acc: 77.270% (9940/12864)
Loss: 0.844 | Acc: 77.502% (14930/19264)
Loss: 0.843 | Acc: 77.420% (19869/25664)
Loss: 0.842 | Acc: 77.486% (24845/32064)
Loss: 0.841 | Acc: 77.493% (29807/38464)
Loss: 0.845 | Acc: 77.452% (34748/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0927, Accuracy: 6841/10000 (68.41%)

Epoch: 53
Loss: 1.245 | Acc: 70.312% (45/64)
Loss: 0.808 | Acc: 78.697% (5087/6464)
Loss: 0.821 | Acc: 78.451% (10092/12864)
Loss: 0.834 | Acc: 77.990% (15024/19264)
Loss: 0.834 | Acc: 77.880% (19987/25664)
Loss: 0.837 | Acc: 77.776% (24938/32064)
Loss: 0.832 | Acc: 77.956% (29985/38464)
Loss: 0.833 | Acc: 77.962% (34977/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4150, Accuracy: 5999/10000 (59.99%)

Epoch: 54
Loss: 0.846 | Acc: 78.125% (50/64)
Loss: 0.782 | Acc: 78.666% (5085/6464)
Loss: 0.815 | Acc: 78.249% (10066/12864)
Loss: 0.810 | Acc: 78.442% (15111/19264)
Loss: 0.820 | Acc: 78.191% (20067/25664)
Loss: 0.823 | Acc: 78.097% (25041/32064)
Loss: 0.827 | Acc: 78.026% (30012/38464)
Loss: 0.830 | Acc: 77.973% (34982/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1117, Accuracy: 6836/10000 (68.36%)

Epoch: 55
Loss: 0.930 | Acc: 75.000% (48/64)
Loss: 0.814 | Acc: 78.605% (5081/6464)
Loss: 0.809 | Acc: 78.692% (10123/12864)
Loss: 0.813 | Acc: 78.769% (15174/19264)
Loss: 0.814 | Acc: 78.686% (20194/25664)
Loss: 0.813 | Acc: 78.671% (25225/32064)
Loss: 0.815 | Acc: 78.622% (30241/38464)
Loss: 0.817 | Acc: 78.655% (35288/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1338, Accuracy: 6794/10000 (67.94%)

Epoch: 56
Loss: 1.106 | Acc: 75.000% (48/64)
Loss: 0.820 | Acc: 78.682% (5086/6464)
Loss: 0.820 | Acc: 78.413% (10087/12864)
Loss: 0.810 | Acc: 78.738% (15168/19264)
Loss: 0.808 | Acc: 78.717% (20202/25664)
Loss: 0.811 | Acc: 78.702% (25235/32064)
Loss: 0.814 | Acc: 78.614% (30238/38464)
Loss: 0.815 | Acc: 78.549% (35240/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0377, Accuracy: 7085/10000 (70.85%)

Epoch: 57
Loss: 0.817 | Acc: 82.812% (53/64)
Loss: 0.804 | Acc: 78.728% (5089/6464)
Loss: 0.805 | Acc: 78.926% (10153/12864)
Loss: 0.800 | Acc: 79.298% (15276/19264)
Loss: 0.808 | Acc: 79.056% (20289/25664)
Loss: 0.810 | Acc: 79.001% (25331/32064)
Loss: 0.814 | Acc: 78.824% (30319/38464)
Loss: 0.810 | Acc: 78.812% (35358/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6808, Accuracy: 5221/10000 (52.21%)

Epoch: 58
Loss: 1.072 | Acc: 71.875% (46/64)
Loss: 0.812 | Acc: 78.759% (5091/6464)
Loss: 0.815 | Acc: 78.576% (10108/12864)
Loss: 0.807 | Acc: 78.789% (15178/19264)
Loss: 0.811 | Acc: 78.772% (20216/25664)
Loss: 0.808 | Acc: 78.880% (25292/32064)
Loss: 0.810 | Acc: 78.861% (30333/38464)
Loss: 0.808 | Acc: 78.869% (35384/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0153, Accuracy: 7295/10000 (72.95%)

Epoch: 59
Loss: 0.588 | Acc: 87.500% (56/64)
Loss: 0.804 | Acc: 79.239% (5122/6464)
Loss: 0.802 | Acc: 79.143% (10181/12864)
Loss: 0.801 | Acc: 79.127% (15243/19264)
Loss: 0.799 | Acc: 79.068% (20292/25664)
Loss: 0.801 | Acc: 79.070% (25353/32064)
Loss: 0.801 | Acc: 79.001% (30387/38464)
Loss: 0.805 | Acc: 78.939% (35415/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9744, Accuracy: 7344/10000 (73.44%)

Epoch: 60
Loss: 0.874 | Acc: 79.688% (51/64)
Loss: 0.800 | Acc: 79.703% (5152/6464)
Loss: 0.788 | Acc: 79.602% (10240/12864)
Loss: 0.803 | Acc: 79.122% (15242/19264)
Loss: 0.802 | Acc: 79.115% (20304/25664)
Loss: 0.797 | Acc: 79.301% (25427/32064)
Loss: 0.796 | Acc: 79.342% (30518/38464)
Loss: 0.795 | Acc: 79.387% (35616/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0634, Accuracy: 7172/10000 (71.72%)

Epoch: 61
Loss: 0.884 | Acc: 79.688% (51/64)
Loss: 0.777 | Acc: 80.121% (5179/6464)
Loss: 0.776 | Acc: 79.843% (10271/12864)
Loss: 0.783 | Acc: 79.677% (15349/19264)
Loss: 0.787 | Acc: 79.699% (20454/25664)
Loss: 0.792 | Acc: 79.450% (25475/32064)
Loss: 0.795 | Acc: 79.412% (30545/38464)
Loss: 0.794 | Acc: 79.424% (35633/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3223, Accuracy: 6285/10000 (62.85%)

Epoch: 62
Loss: 1.070 | Acc: 76.562% (49/64)
Loss: 0.798 | Acc: 79.455% (5136/6464)
Loss: 0.788 | Acc: 79.555% (10234/12864)
Loss: 0.790 | Acc: 79.604% (15335/19264)
Loss: 0.788 | Acc: 79.586% (20425/25664)
Loss: 0.787 | Acc: 79.610% (25526/32064)
Loss: 0.788 | Acc: 79.516% (30585/38464)
Loss: 0.791 | Acc: 79.458% (35648/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9737, Accuracy: 7374/10000 (73.74%)

Epoch: 63
Loss: 0.577 | Acc: 81.250% (52/64)
Loss: 0.778 | Acc: 79.239% (5122/6464)
Loss: 0.780 | Acc: 79.649% (10246/12864)
Loss: 0.776 | Acc: 79.874% (15387/19264)
Loss: 0.778 | Acc: 79.875% (20499/25664)
Loss: 0.777 | Acc: 79.946% (25634/32064)
Loss: 0.780 | Acc: 79.914% (30738/38464)
Loss: 0.780 | Acc: 79.968% (35877/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9604, Accuracy: 7547/10000 (75.47%)

Epoch: 64
Loss: 0.998 | Acc: 70.312% (45/64)
Loss: 0.788 | Acc: 79.950% (5168/6464)
Loss: 0.776 | Acc: 80.162% (10312/12864)
Loss: 0.768 | Acc: 80.217% (15453/19264)
Loss: 0.772 | Acc: 80.062% (20547/25664)
Loss: 0.771 | Acc: 80.121% (25690/32064)
Loss: 0.773 | Acc: 80.101% (30810/38464)
Loss: 0.776 | Acc: 79.995% (35889/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1899, Accuracy: 6632/10000 (66.32%)

Epoch: 65
Loss: 0.788 | Acc: 75.000% (48/64)
Loss: 0.756 | Acc: 80.817% (5224/6464)
Loss: 0.756 | Acc: 80.683% (10379/12864)
Loss: 0.759 | Acc: 80.762% (15558/19264)
Loss: 0.757 | Acc: 80.814% (20740/25664)
Loss: 0.764 | Acc: 80.642% (25857/32064)
Loss: 0.763 | Acc: 80.660% (31025/38464)
Loss: 0.766 | Acc: 80.606% (36163/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9766, Accuracy: 7342/10000 (73.42%)

Epoch: 66
Loss: 0.669 | Acc: 79.688% (51/64)
Loss: 0.730 | Acc: 81.513% (5269/6464)
Loss: 0.749 | Acc: 80.822% (10397/12864)
Loss: 0.752 | Acc: 80.601% (15527/19264)
Loss: 0.760 | Acc: 80.358% (20623/25664)
Loss: 0.757 | Acc: 80.445% (25794/32064)
Loss: 0.760 | Acc: 80.441% (30941/38464)
Loss: 0.758 | Acc: 80.588% (36155/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1657, Accuracy: 6597/10000 (65.97%)

Epoch: 67
Loss: 0.841 | Acc: 79.688% (51/64)
Loss: 0.748 | Acc: 81.389% (5261/6464)
Loss: 0.736 | Acc: 81.561% (10492/12864)
Loss: 0.736 | Acc: 81.525% (15705/19264)
Loss: 0.745 | Acc: 81.371% (20883/25664)
Loss: 0.748 | Acc: 81.169% (26026/32064)
Loss: 0.753 | Acc: 80.980% (31148/38464)
Loss: 0.757 | Acc: 80.802% (36251/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3612, Accuracy: 6108/10000 (61.08%)

Epoch: 68
Loss: 0.632 | Acc: 81.250% (52/64)
Loss: 0.753 | Acc: 80.476% (5202/6464)
Loss: 0.744 | Acc: 80.877% (10404/12864)
Loss: 0.747 | Acc: 81.001% (15604/19264)
Loss: 0.748 | Acc: 80.977% (20782/25664)
Loss: 0.748 | Acc: 80.954% (25957/32064)
Loss: 0.749 | Acc: 80.967% (31143/38464)
Loss: 0.745 | Acc: 81.023% (36350/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1054, Accuracy: 6919/10000 (69.19%)

Epoch: 69
Loss: 0.933 | Acc: 73.438% (47/64)
Loss: 0.696 | Acc: 82.256% (5317/6464)
Loss: 0.706 | Acc: 81.981% (10546/12864)
Loss: 0.726 | Acc: 81.702% (15739/19264)
Loss: 0.733 | Acc: 81.577% (20936/25664)
Loss: 0.737 | Acc: 81.418% (26106/32064)
Loss: 0.734 | Acc: 81.520% (31356/38464)
Loss: 0.736 | Acc: 81.506% (36567/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1822, Accuracy: 6786/10000 (67.86%)

Epoch: 70
Loss: 0.636 | Acc: 84.375% (54/64)
Loss: 0.705 | Acc: 82.271% (5318/6464)
Loss: 0.708 | Acc: 82.261% (10582/12864)
Loss: 0.710 | Acc: 82.397% (15873/19264)
Loss: 0.711 | Acc: 82.392% (21145/25664)
Loss: 0.717 | Acc: 82.204% (26358/32064)
Loss: 0.720 | Acc: 82.090% (31575/38464)
Loss: 0.727 | Acc: 81.843% (36718/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1388, Accuracy: 6773/10000 (67.73%)

Epoch: 71
Loss: 0.832 | Acc: 79.688% (51/64)
Loss: 0.698 | Acc: 82.611% (5340/6464)
Loss: 0.708 | Acc: 82.222% (10577/12864)
Loss: 0.707 | Acc: 82.413% (15876/19264)
Loss: 0.716 | Acc: 82.232% (21104/25664)
Loss: 0.720 | Acc: 82.217% (26362/32064)
Loss: 0.721 | Acc: 82.118% (31586/38464)
Loss: 0.717 | Acc: 82.197% (36877/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6427, Accuracy: 5577/10000 (55.77%)

Epoch: 72
Loss: 0.986 | Acc: 75.000% (48/64)
Loss: 0.708 | Acc: 82.611% (5340/6464)
Loss: 0.708 | Acc: 82.548% (10619/12864)
Loss: 0.715 | Acc: 82.330% (15860/19264)
Loss: 0.708 | Acc: 82.403% (21148/25664)
Loss: 0.710 | Acc: 82.413% (26425/32064)
Loss: 0.706 | Acc: 82.506% (31735/38464)
Loss: 0.708 | Acc: 82.498% (37012/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2251, Accuracy: 6684/10000 (66.84%)

Epoch: 73
Loss: 0.677 | Acc: 84.375% (54/64)
Loss: 0.668 | Acc: 83.261% (5382/6464)
Loss: 0.690 | Acc: 82.743% (10644/12864)
Loss: 0.700 | Acc: 82.563% (15905/19264)
Loss: 0.704 | Acc: 82.524% (21179/25664)
Loss: 0.704 | Acc: 82.575% (26477/32064)
Loss: 0.700 | Acc: 82.683% (31803/38464)
Loss: 0.703 | Acc: 82.599% (37057/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0048, Accuracy: 7248/10000 (72.48%)

Epoch: 74
Loss: 0.814 | Acc: 81.250% (52/64)
Loss: 0.659 | Acc: 83.648% (5407/6464)
Loss: 0.666 | Acc: 83.738% (10772/12864)
Loss: 0.680 | Acc: 83.129% (16014/19264)
Loss: 0.680 | Acc: 83.159% (21342/25664)
Loss: 0.683 | Acc: 83.112% (26649/32064)
Loss: 0.689 | Acc: 83.057% (31947/38464)
Loss: 0.689 | Acc: 83.080% (37273/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0004, Accuracy: 7217/10000 (72.17%)

Epoch: 75
Loss: 0.597 | Acc: 84.375% (54/64)
Loss: 0.650 | Acc: 84.174% (5441/6464)
Loss: 0.664 | Acc: 83.776% (10777/12864)
Loss: 0.664 | Acc: 83.840% (16151/19264)
Loss: 0.668 | Acc: 83.666% (21472/25664)
Loss: 0.671 | Acc: 83.533% (26784/32064)
Loss: 0.675 | Acc: 83.475% (32108/38464)
Loss: 0.679 | Acc: 83.392% (37413/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8531, Accuracy: 7810/10000 (78.10%)

Epoch: 76
Loss: 0.625 | Acc: 85.938% (55/64)
Loss: 0.669 | Acc: 83.663% (5408/6464)
Loss: 0.659 | Acc: 83.955% (10800/12864)
Loss: 0.667 | Acc: 83.799% (16143/19264)
Loss: 0.666 | Acc: 83.833% (21515/25664)
Loss: 0.673 | Acc: 83.639% (26818/32064)
Loss: 0.672 | Acc: 83.631% (32168/38464)
Loss: 0.670 | Acc: 83.717% (37559/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9267, Accuracy: 7564/10000 (75.64%)

Epoch: 77
Loss: 0.809 | Acc: 84.375% (54/64)
Loss: 0.646 | Acc: 84.375% (5454/6464)
Loss: 0.654 | Acc: 84.103% (10819/12864)
Loss: 0.660 | Acc: 83.820% (16147/19264)
Loss: 0.663 | Acc: 83.748% (21493/25664)
Loss: 0.662 | Acc: 83.860% (26889/32064)
Loss: 0.660 | Acc: 83.949% (32290/38464)
Loss: 0.654 | Acc: 84.121% (37740/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8624, Accuracy: 7785/10000 (77.85%)

Epoch: 78
Loss: 0.577 | Acc: 84.375% (54/64)
Loss: 0.618 | Acc: 85.473% (5525/6464)
Loss: 0.631 | Acc: 84.981% (10932/12864)
Loss: 0.637 | Acc: 84.879% (16351/19264)
Loss: 0.643 | Acc: 84.815% (21767/25664)
Loss: 0.645 | Acc: 84.646% (27141/32064)
Loss: 0.642 | Acc: 84.651% (32560/38464)
Loss: 0.643 | Acc: 84.620% (37964/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8888, Accuracy: 7714/10000 (77.14%)

Epoch: 79
Loss: 0.505 | Acc: 90.625% (58/64)
Loss: 0.605 | Acc: 85.520% (5528/6464)
Loss: 0.609 | Acc: 85.354% (10980/12864)
Loss: 0.612 | Acc: 85.174% (16408/19264)
Loss: 0.621 | Acc: 85.030% (21822/25664)
Loss: 0.624 | Acc: 84.993% (27252/32064)
Loss: 0.624 | Acc: 85.043% (32711/38464)
Loss: 0.625 | Acc: 85.021% (38144/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0620, Accuracy: 6997/10000 (69.97%)

Epoch: 80
Loss: 0.945 | Acc: 79.688% (51/64)
Loss: 0.657 | Acc: 83.895% (5423/6464)
Loss: 0.624 | Acc: 84.950% (10928/12864)
Loss: 0.617 | Acc: 85.325% (16437/19264)
Loss: 0.610 | Acc: 85.489% (21940/25664)
Loss: 0.612 | Acc: 85.448% (27398/32064)
Loss: 0.614 | Acc: 85.457% (32870/38464)
Loss: 0.615 | Acc: 85.489% (38354/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0103, Accuracy: 7211/10000 (72.11%)

Epoch: 81
Loss: 0.429 | Acc: 85.938% (55/64)
Loss: 0.592 | Acc: 85.860% (5550/6464)
Loss: 0.612 | Acc: 85.456% (10993/12864)
Loss: 0.602 | Acc: 85.771% (16523/19264)
Loss: 0.600 | Acc: 85.778% (22014/25664)
Loss: 0.596 | Acc: 85.900% (27543/32064)
Loss: 0.597 | Acc: 85.878% (33032/38464)
Loss: 0.601 | Acc: 85.773% (38481/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8133, Accuracy: 7981/10000 (79.81%)

Epoch: 82
Loss: 0.356 | Acc: 95.312% (61/64)
Loss: 0.595 | Acc: 85.721% (5541/6464)
Loss: 0.587 | Acc: 86.248% (11095/12864)
Loss: 0.578 | Acc: 86.431% (16650/19264)
Loss: 0.581 | Acc: 86.370% (22166/25664)
Loss: 0.584 | Acc: 86.259% (27658/32064)
Loss: 0.587 | Acc: 86.239% (33171/38464)
Loss: 0.587 | Acc: 86.225% (38684/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7972, Accuracy: 8075/10000 (80.75%)

Epoch: 83
Loss: 0.526 | Acc: 89.062% (57/64)
Loss: 0.541 | Acc: 87.299% (5643/6464)
Loss: 0.546 | Acc: 87.150% (11211/12864)
Loss: 0.537 | Acc: 87.433% (16843/19264)
Loss: 0.549 | Acc: 87.075% (22347/25664)
Loss: 0.552 | Acc: 87.020% (27902/32064)
Loss: 0.559 | Acc: 86.918% (33432/38464)
Loss: 0.558 | Acc: 86.947% (39008/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0070, Accuracy: 7489/10000 (74.89%)

Epoch: 84
Loss: 0.441 | Acc: 89.062% (57/64)
Loss: 0.539 | Acc: 87.376% (5648/6464)
Loss: 0.545 | Acc: 87.212% (11219/12864)
Loss: 0.554 | Acc: 86.960% (16752/19264)
Loss: 0.554 | Acc: 86.970% (22320/25664)
Loss: 0.549 | Acc: 87.076% (27920/32064)
Loss: 0.553 | Acc: 86.990% (33460/38464)
Loss: 0.552 | Acc: 87.032% (39046/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8392, Accuracy: 8010/10000 (80.10%)

Epoch: 85
Loss: 0.554 | Acc: 89.062% (57/64)
Loss: 0.518 | Acc: 87.933% (5684/6464)
Loss: 0.520 | Acc: 87.819% (11297/12864)
Loss: 0.519 | Acc: 87.775% (16909/19264)
Loss: 0.521 | Acc: 87.827% (22540/25664)
Loss: 0.519 | Acc: 87.915% (28189/32064)
Loss: 0.523 | Acc: 87.833% (33784/38464)
Loss: 0.525 | Acc: 87.738% (39363/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9011, Accuracy: 7789/10000 (77.89%)

Epoch: 86
Loss: 0.563 | Acc: 87.500% (56/64)
Loss: 0.499 | Acc: 88.212% (5702/6464)
Loss: 0.478 | Acc: 88.853% (11430/12864)
Loss: 0.488 | Acc: 88.611% (17070/19264)
Loss: 0.500 | Acc: 88.322% (22667/25664)
Loss: 0.499 | Acc: 88.333% (28323/32064)
Loss: 0.503 | Acc: 88.225% (33935/38464)
Loss: 0.503 | Acc: 88.238% (39587/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8336, Accuracy: 7995/10000 (79.95%)

Epoch: 87
Loss: 0.424 | Acc: 92.188% (59/64)
Loss: 0.493 | Acc: 88.258% (5705/6464)
Loss: 0.475 | Acc: 88.767% (11419/12864)
Loss: 0.480 | Acc: 88.720% (17091/19264)
Loss: 0.481 | Acc: 88.782% (22785/25664)
Loss: 0.481 | Acc: 88.835% (28484/32064)
Loss: 0.482 | Acc: 88.784% (34150/38464)
Loss: 0.480 | Acc: 88.884% (39877/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7962, Accuracy: 8218/10000 (82.18%)

Epoch: 88
Loss: 0.321 | Acc: 89.062% (57/64)
Loss: 0.430 | Acc: 89.929% (5813/6464)
Loss: 0.430 | Acc: 89.871% (11561/12864)
Loss: 0.439 | Acc: 89.675% (17275/19264)
Loss: 0.448 | Acc: 89.522% (22975/25664)
Loss: 0.447 | Acc: 89.493% (28695/32064)
Loss: 0.445 | Acc: 89.562% (34449/38464)
Loss: 0.447 | Acc: 89.513% (40159/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8650, Accuracy: 8021/10000 (80.21%)

Epoch: 89
Loss: 0.553 | Acc: 82.812% (53/64)
Loss: 0.407 | Acc: 90.300% (5837/6464)
Loss: 0.410 | Acc: 90.267% (11612/12864)
Loss: 0.412 | Acc: 90.236% (17383/19264)
Loss: 0.415 | Acc: 90.122% (23129/25664)
Loss: 0.421 | Acc: 89.992% (28855/32064)
Loss: 0.420 | Acc: 90.045% (34635/38464)
Loss: 0.420 | Acc: 90.068% (40408/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8235, Accuracy: 8180/10000 (81.80%)

Epoch: 90
Loss: 0.218 | Acc: 95.312% (61/64)
Loss: 0.373 | Acc: 91.151% (5892/6464)
Loss: 0.380 | Acc: 90.975% (11703/12864)
Loss: 0.384 | Acc: 90.853% (17502/19264)
Loss: 0.384 | Acc: 90.851% (23316/25664)
Loss: 0.390 | Acc: 90.712% (29086/32064)
Loss: 0.392 | Acc: 90.682% (34880/38464)
Loss: 0.391 | Acc: 90.714% (40698/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8227, Accuracy: 8230/10000 (82.30%)

Epoch: 91
Loss: 0.268 | Acc: 92.188% (59/64)
Loss: 0.352 | Acc: 91.631% (5923/6464)
Loss: 0.352 | Acc: 91.527% (11774/12864)
Loss: 0.358 | Acc: 91.383% (17604/19264)
Loss: 0.354 | Acc: 91.428% (23464/25664)
Loss: 0.354 | Acc: 91.395% (29305/32064)
Loss: 0.355 | Acc: 91.387% (35151/38464)
Loss: 0.356 | Acc: 91.383% (40998/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8535, Accuracy: 8277/10000 (82.77%)

Epoch: 92
Loss: 0.398 | Acc: 90.625% (58/64)
Loss: 0.317 | Acc: 92.033% (5949/6464)
Loss: 0.313 | Acc: 92.312% (11875/12864)
Loss: 0.318 | Acc: 92.208% (17763/19264)
Loss: 0.322 | Acc: 92.106% (23638/25664)
Loss: 0.328 | Acc: 91.897% (29466/32064)
Loss: 0.328 | Acc: 91.896% (35347/38464)
Loss: 0.326 | Acc: 91.927% (41242/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8574, Accuracy: 8278/10000 (82.78%)

Epoch: 93
Loss: 0.348 | Acc: 92.188% (59/64)
Loss: 0.270 | Acc: 93.332% (6033/6464)
Loss: 0.273 | Acc: 93.276% (11999/12864)
Loss: 0.276 | Acc: 93.065% (17928/19264)
Loss: 0.280 | Acc: 92.967% (23859/25664)
Loss: 0.281 | Acc: 92.895% (29786/32064)
Loss: 0.281 | Acc: 92.941% (35749/38464)
Loss: 0.282 | Acc: 92.919% (41687/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8834, Accuracy: 8281/10000 (82.81%)

Epoch: 94
Loss: 0.166 | Acc: 95.312% (61/64)
Loss: 0.248 | Acc: 93.580% (6049/6464)
Loss: 0.254 | Acc: 93.431% (12019/12864)
Loss: 0.259 | Acc: 93.361% (17985/19264)
Loss: 0.257 | Acc: 93.403% (23971/25664)
Loss: 0.256 | Acc: 93.485% (29975/32064)
Loss: 0.254 | Acc: 93.524% (35973/38464)
Loss: 0.252 | Acc: 93.554% (41972/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9034, Accuracy: 8276/10000 (82.76%)

Epoch: 95
Loss: 0.179 | Acc: 95.312% (61/64)
Loss: 0.213 | Acc: 94.400% (6102/6464)
Loss: 0.221 | Acc: 94.240% (12123/12864)
Loss: 0.225 | Acc: 94.160% (18139/19264)
Loss: 0.225 | Acc: 94.151% (24163/25664)
Loss: 0.227 | Acc: 94.068% (30162/32064)
Loss: 0.230 | Acc: 93.987% (36151/38464)
Loss: 0.229 | Acc: 94.002% (42173/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8979, Accuracy: 8295/10000 (82.95%)

Epoch: 96
Loss: 0.282 | Acc: 93.750% (60/64)
Loss: 0.215 | Acc: 94.415% (6103/6464)
Loss: 0.210 | Acc: 94.488% (12155/12864)
Loss: 0.220 | Acc: 94.176% (18142/19264)
Loss: 0.219 | Acc: 94.159% (24165/25664)
Loss: 0.217 | Acc: 94.268% (30226/32064)
Loss: 0.218 | Acc: 94.280% (36264/38464)
Loss: 0.219 | Acc: 94.256% (42287/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9053, Accuracy: 8282/10000 (82.82%)

Epoch: 97
Loss: 0.253 | Acc: 89.062% (57/64)
Loss: 0.206 | Acc: 94.369% (6100/6464)
Loss: 0.209 | Acc: 94.403% (12144/12864)
Loss: 0.206 | Acc: 94.513% (18207/19264)
Loss: 0.207 | Acc: 94.479% (24247/25664)
Loss: 0.206 | Acc: 94.517% (30306/32064)
Loss: 0.205 | Acc: 94.611% (36391/38464)
Loss: 0.205 | Acc: 94.575% (42430/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8973, Accuracy: 8294/10000 (82.94%)
torch.Size([100, 10])
Test set: Average loss: 0.8973, Accuracy: 8294/10000 (82.94%)

Epoch: 98
Loss: 0.097 | Acc: 98.438% (63/64)
Loss: 0.200 | Acc: 94.895% (6134/6464)
Loss: 0.197 | Acc: 94.823% (12198/12864)
Loss: 0.199 | Acc: 94.773% (18257/19264)
Loss: 0.199 | Acc: 94.779% (24324/25664)
Loss: 0.198 | Acc: 94.804% (30398/32064)
Loss: 0.198 | Acc: 94.790% (36460/38464)
Loss: 0.198 | Acc: 94.798% (42530/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9003, Accuracy: 8292/10000 (82.92%)
torch.Size([100, 10])
Test set: Average loss: 0.9003, Accuracy: 8292/10000 (82.92%)

Epoch: 99
Loss: 0.072 | Acc: 98.438% (63/64)
Loss: 0.188 | Acc: 94.926% (6136/6464)
Loss: 0.188 | Acc: 94.869% (12204/12864)
Loss: 0.189 | Acc: 94.840% (18270/19264)
Loss: 0.194 | Acc: 94.724% (24310/25664)
Loss: 0.196 | Acc: 94.704% (30366/32064)
Loss: 0.195 | Acc: 94.738% (36440/38464)
Loss: 0.194 | Acc: 94.753% (42510/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9034, Accuracy: 8293/10000 (82.93%)
torch.Size([100, 10])
Test set: Average loss: 0.9034, Accuracy: 8293/10000 (82.93%)

Epoch: 100
Loss: 0.187 | Acc: 96.875% (62/64)
Loss: 1.737 | Acc: 39.186% (2533/6464)
Loss: 1.431 | Acc: 52.861% (6800/12864)
Loss: 1.283 | Acc: 59.245% (11413/19264)
Loss: 1.201 | Acc: 62.738% (16101/25664)
Loss: 1.143 | Acc: 65.057% (20860/32064)
Loss: 1.102 | Acc: 66.891% (25729/38464)
Loss: 1.073 | Acc: 68.108% (30556/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3311, Accuracy: 5940/10000 (59.40%)

Epoch: 101
Loss: 1.039 | Acc: 67.188% (43/64)
Loss: 0.837 | Acc: 77.398% (5003/6464)
Loss: 0.841 | Acc: 77.076% (9915/12864)
Loss: 0.843 | Acc: 77.092% (14851/19264)
Loss: 0.839 | Acc: 77.334% (19847/25664)
Loss: 0.841 | Acc: 77.376% (24810/32064)
Loss: 0.838 | Acc: 77.605% (29850/38464)
Loss: 0.841 | Acc: 77.581% (34806/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1300, Accuracy: 6851/10000 (68.51%)

Epoch: 102
Loss: 0.648 | Acc: 82.812% (53/64)
Loss: 0.799 | Acc: 78.960% (5104/6464)
Loss: 0.806 | Acc: 78.825% (10140/12864)
Loss: 0.809 | Acc: 78.774% (15175/19264)
Loss: 0.810 | Acc: 78.729% (20205/25664)
Loss: 0.809 | Acc: 78.767% (25256/32064)
Loss: 0.813 | Acc: 78.622% (30241/38464)
Loss: 0.811 | Acc: 78.727% (35320/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5772, Accuracy: 5529/10000 (55.29%)

Epoch: 103
Loss: 0.681 | Acc: 79.688% (51/64)
Loss: 0.805 | Acc: 79.100% (5113/6464)
Loss: 0.811 | Acc: 79.182% (10186/12864)
Loss: 0.805 | Acc: 79.163% (15250/19264)
Loss: 0.803 | Acc: 79.220% (20331/25664)
Loss: 0.805 | Acc: 79.126% (25371/32064)
Loss: 0.806 | Acc: 79.103% (30426/38464)
Loss: 0.806 | Acc: 79.054% (35467/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7537, Accuracy: 5197/10000 (51.97%)

Epoch: 104
Loss: 0.766 | Acc: 76.562% (49/64)
Loss: 0.780 | Acc: 79.502% (5139/6464)
Loss: 0.794 | Acc: 79.509% (10228/12864)
Loss: 0.795 | Acc: 79.563% (15327/19264)
Loss: 0.799 | Acc: 79.372% (20370/25664)
Loss: 0.800 | Acc: 79.391% (25456/32064)
Loss: 0.801 | Acc: 79.339% (30517/38464)
Loss: 0.801 | Acc: 79.362% (35605/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4708, Accuracy: 6051/10000 (60.51%)

Epoch: 105
Loss: 1.145 | Acc: 60.938% (39/64)
Loss: 0.783 | Acc: 80.043% (5174/6464)
Loss: 0.781 | Acc: 80.084% (10302/12864)
Loss: 0.780 | Acc: 80.181% (15446/19264)
Loss: 0.780 | Acc: 80.023% (20537/25664)
Loss: 0.786 | Acc: 79.806% (25589/32064)
Loss: 0.787 | Acc: 79.810% (30698/38464)
Loss: 0.791 | Acc: 79.665% (35741/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2173, Accuracy: 6486/10000 (64.86%)

Epoch: 106
Loss: 0.940 | Acc: 73.438% (47/64)
Loss: 0.794 | Acc: 79.703% (5152/6464)
Loss: 0.788 | Acc: 79.812% (10267/12864)
Loss: 0.784 | Acc: 79.848% (15382/19264)
Loss: 0.786 | Acc: 79.750% (20467/25664)
Loss: 0.788 | Acc: 79.669% (25545/32064)
Loss: 0.789 | Acc: 79.597% (30616/38464)
Loss: 0.792 | Acc: 79.514% (35673/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0529, Accuracy: 7024/10000 (70.24%)

Epoch: 107
Loss: 0.778 | Acc: 82.812% (53/64)
Loss: 0.780 | Acc: 79.966% (5169/6464)
Loss: 0.776 | Acc: 80.068% (10300/12864)
Loss: 0.779 | Acc: 80.030% (15417/19264)
Loss: 0.783 | Acc: 79.941% (20516/25664)
Loss: 0.785 | Acc: 79.778% (25580/32064)
Loss: 0.785 | Acc: 79.711% (30660/38464)
Loss: 0.786 | Acc: 79.761% (35784/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0971, Accuracy: 4528/10000 (45.28%)

Epoch: 108
Loss: 1.196 | Acc: 64.062% (41/64)
Loss: 0.783 | Acc: 79.486% (5138/6464)
Loss: 0.778 | Acc: 79.897% (10278/12864)
Loss: 0.787 | Acc: 79.713% (15356/19264)
Loss: 0.788 | Acc: 79.703% (20455/25664)
Loss: 0.783 | Acc: 79.822% (25594/32064)
Loss: 0.786 | Acc: 79.739% (30671/38464)
Loss: 0.787 | Acc: 79.696% (35755/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3747, Accuracy: 3424/10000 (34.24%)

Epoch: 109
Loss: 0.917 | Acc: 75.000% (48/64)
Loss: 0.798 | Acc: 79.502% (5139/6464)
Loss: 0.790 | Acc: 79.921% (10281/12864)
Loss: 0.783 | Acc: 79.931% (15398/19264)
Loss: 0.777 | Acc: 80.124% (20563/25664)
Loss: 0.777 | Acc: 80.205% (25717/32064)
Loss: 0.781 | Acc: 80.114% (30815/38464)
Loss: 0.781 | Acc: 80.133% (35951/44864)
torch.Size([100, 10])
Test set: Average loss: 3.0150, Accuracy: 2680/10000 (26.80%)

Epoch: 110
Loss: 1.108 | Acc: 68.750% (44/64)
Loss: 0.802 | Acc: 78.914% (5101/6464)
Loss: 0.778 | Acc: 79.408% (10215/12864)
Loss: 0.773 | Acc: 79.786% (15370/19264)
Loss: 0.774 | Acc: 79.730% (20462/25664)
Loss: 0.775 | Acc: 79.790% (25584/32064)
Loss: 0.777 | Acc: 79.784% (30688/38464)
Loss: 0.777 | Acc: 79.812% (35807/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9875, Accuracy: 7265/10000 (72.65%)

Epoch: 111
Loss: 0.894 | Acc: 75.000% (48/64)
Loss: 0.771 | Acc: 80.260% (5188/6464)
Loss: 0.772 | Acc: 80.232% (10321/12864)
Loss: 0.763 | Acc: 80.523% (15512/19264)
Loss: 0.758 | Acc: 80.615% (20689/25664)
Loss: 0.765 | Acc: 80.517% (25817/32064)
Loss: 0.770 | Acc: 80.387% (30920/38464)
Loss: 0.772 | Acc: 80.356% (36051/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0492, Accuracy: 7032/10000 (70.32%)

Epoch: 112
Loss: 1.212 | Acc: 64.062% (41/64)
Loss: 0.744 | Acc: 81.157% (5246/6464)
Loss: 0.750 | Acc: 81.110% (10434/12864)
Loss: 0.759 | Acc: 80.783% (15562/19264)
Loss: 0.757 | Acc: 80.771% (20729/25664)
Loss: 0.761 | Acc: 80.579% (25837/32064)
Loss: 0.764 | Acc: 80.584% (30996/38464)
Loss: 0.768 | Acc: 80.492% (36112/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3236, Accuracy: 6134/10000 (61.34%)

Epoch: 113
Loss: 0.744 | Acc: 78.125% (50/64)
Loss: 0.755 | Acc: 80.987% (5235/6464)
Loss: 0.763 | Acc: 80.543% (10361/12864)
Loss: 0.754 | Acc: 80.788% (15563/19264)
Loss: 0.750 | Acc: 80.888% (20759/25664)
Loss: 0.747 | Acc: 80.919% (25946/32064)
Loss: 0.753 | Acc: 80.831% (31091/38464)
Loss: 0.758 | Acc: 80.715% (36212/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0200, Accuracy: 4476/10000 (44.76%)

Epoch: 114
Loss: 0.940 | Acc: 76.562% (49/64)
Loss: 0.747 | Acc: 81.281% (5254/6464)
Loss: 0.747 | Acc: 81.211% (10447/12864)
Loss: 0.751 | Acc: 80.778% (15561/19264)
Loss: 0.744 | Acc: 81.001% (20788/25664)
Loss: 0.749 | Acc: 80.898% (25939/32064)
Loss: 0.757 | Acc: 80.761% (31064/38464)
Loss: 0.759 | Acc: 80.753% (36229/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1253, Accuracy: 6814/10000 (68.14%)

Epoch: 115
Loss: 0.978 | Acc: 76.562% (49/64)
Loss: 0.712 | Acc: 81.869% (5292/6464)
Loss: 0.728 | Acc: 81.670% (10506/12864)
Loss: 0.743 | Acc: 81.141% (15631/19264)
Loss: 0.741 | Acc: 81.207% (20841/25664)
Loss: 0.742 | Acc: 81.216% (26041/32064)
Loss: 0.743 | Acc: 81.188% (31228/38464)
Loss: 0.745 | Acc: 81.105% (36387/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0615, Accuracy: 7075/10000 (70.75%)

Epoch: 116
Loss: 0.808 | Acc: 79.688% (51/64)
Loss: 0.740 | Acc: 81.853% (5291/6464)
Loss: 0.740 | Acc: 81.685% (10508/12864)
Loss: 0.741 | Acc: 81.473% (15695/19264)
Loss: 0.738 | Acc: 81.546% (20928/25664)
Loss: 0.747 | Acc: 81.234% (26047/32064)
Loss: 0.742 | Acc: 81.312% (31276/38464)
Loss: 0.743 | Acc: 81.201% (36430/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9753, Accuracy: 7422/10000 (74.22%)

Epoch: 117
Loss: 0.614 | Acc: 82.812% (53/64)
Loss: 0.754 | Acc: 81.033% (5238/6464)
Loss: 0.748 | Acc: 81.211% (10447/12864)
Loss: 0.738 | Acc: 81.546% (15709/19264)
Loss: 0.736 | Acc: 81.577% (20936/25664)
Loss: 0.745 | Acc: 81.256% (26054/32064)
Loss: 0.741 | Acc: 81.357% (31293/38464)
Loss: 0.738 | Acc: 81.390% (36515/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1187, Accuracy: 6863/10000 (68.63%)

Epoch: 118
Loss: 0.906 | Acc: 79.688% (51/64)
Loss: 0.715 | Acc: 82.085% (5306/6464)
Loss: 0.715 | Acc: 82.113% (10563/12864)
Loss: 0.710 | Acc: 82.293% (15853/19264)
Loss: 0.718 | Acc: 82.068% (21062/25664)
Loss: 0.724 | Acc: 81.905% (26262/32064)
Loss: 0.724 | Acc: 81.929% (31513/38464)
Loss: 0.728 | Acc: 81.832% (36713/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3553, Accuracy: 6347/10000 (63.47%)

Epoch: 119
Loss: 0.536 | Acc: 90.625% (58/64)
Loss: 0.733 | Acc: 81.884% (5293/6464)
Loss: 0.718 | Acc: 82.245% (10580/12864)
Loss: 0.713 | Acc: 82.262% (15847/19264)
Loss: 0.721 | Acc: 82.096% (21069/25664)
Loss: 0.722 | Acc: 82.067% (26314/32064)
Loss: 0.721 | Acc: 82.061% (31564/38464)
Loss: 0.723 | Acc: 82.019% (36797/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4950, Accuracy: 6110/10000 (61.10%)

Epoch: 120
Loss: 0.491 | Acc: 85.938% (55/64)
Loss: 0.711 | Acc: 82.596% (5339/6464)
Loss: 0.712 | Acc: 82.377% (10597/12864)
Loss: 0.713 | Acc: 82.236% (15842/19264)
Loss: 0.715 | Acc: 82.173% (21089/25664)
Loss: 0.710 | Acc: 82.329% (26398/32064)
Loss: 0.714 | Acc: 82.215% (31623/38464)
Loss: 0.714 | Acc: 82.249% (36900/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9408, Accuracy: 7576/10000 (75.76%)

Epoch: 121
Loss: 0.798 | Acc: 81.250% (52/64)
Loss: 0.662 | Acc: 83.911% (5424/6464)
Loss: 0.680 | Acc: 83.380% (10726/12864)
Loss: 0.691 | Acc: 82.947% (15979/19264)
Loss: 0.698 | Acc: 82.731% (21232/25664)
Loss: 0.699 | Acc: 82.738% (26529/32064)
Loss: 0.702 | Acc: 82.659% (31794/38464)
Loss: 0.705 | Acc: 82.581% (37049/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0052, Accuracy: 7227/10000 (72.27%)

Epoch: 122
Loss: 0.803 | Acc: 79.688% (51/64)
Loss: 0.670 | Acc: 83.230% (5380/6464)
Loss: 0.668 | Acc: 83.302% (10716/12864)
Loss: 0.673 | Acc: 83.321% (16051/19264)
Loss: 0.679 | Acc: 83.183% (21348/25664)
Loss: 0.681 | Acc: 83.196% (26676/32064)
Loss: 0.682 | Acc: 83.130% (31975/38464)
Loss: 0.686 | Acc: 83.009% (37241/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2666, Accuracy: 6635/10000 (66.35%)

Epoch: 123
Loss: 0.641 | Acc: 79.688% (51/64)
Loss: 0.684 | Acc: 83.137% (5374/6464)
Loss: 0.681 | Acc: 83.271% (10712/12864)
Loss: 0.684 | Acc: 83.212% (16030/19264)
Loss: 0.682 | Acc: 83.183% (21348/25664)
Loss: 0.684 | Acc: 83.152% (26662/32064)
Loss: 0.681 | Acc: 83.270% (32029/38464)
Loss: 0.686 | Acc: 83.167% (37312/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8740, Accuracy: 7778/10000 (77.78%)

Epoch: 124
Loss: 0.611 | Acc: 84.375% (54/64)
Loss: 0.662 | Acc: 84.035% (5432/6464)
Loss: 0.659 | Acc: 84.049% (10812/12864)
Loss: 0.667 | Acc: 83.820% (16147/19264)
Loss: 0.667 | Acc: 83.701% (21481/25664)
Loss: 0.673 | Acc: 83.642% (26819/32064)
Loss: 0.673 | Acc: 83.686% (32189/38464)
Loss: 0.676 | Acc: 83.599% (37506/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1531, Accuracy: 6792/10000 (67.92%)

Epoch: 125
Loss: 0.841 | Acc: 78.125% (50/64)
Loss: 0.651 | Acc: 84.220% (5444/6464)
Loss: 0.644 | Acc: 84.445% (10863/12864)
Loss: 0.661 | Acc: 83.944% (16171/19264)
Loss: 0.658 | Acc: 83.993% (21556/25664)
Loss: 0.662 | Acc: 83.895% (26900/32064)
Loss: 0.660 | Acc: 83.930% (32283/38464)
Loss: 0.666 | Acc: 83.845% (37616/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0031, Accuracy: 7312/10000 (73.12%)

Epoch: 126
Loss: 0.409 | Acc: 89.062% (57/64)
Loss: 0.622 | Acc: 85.009% (5495/6464)
Loss: 0.631 | Acc: 84.857% (10916/12864)
Loss: 0.647 | Acc: 84.500% (16278/19264)
Loss: 0.651 | Acc: 84.313% (21638/25664)
Loss: 0.652 | Acc: 84.338% (27042/32064)
Loss: 0.650 | Acc: 84.417% (32470/38464)
Loss: 0.651 | Acc: 84.388% (37860/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8335, Accuracy: 7937/10000 (79.37%)

Epoch: 127
Loss: 0.560 | Acc: 85.938% (55/64)
Loss: 0.627 | Acc: 85.288% (5513/6464)
Loss: 0.635 | Acc: 84.834% (10913/12864)
Loss: 0.639 | Acc: 84.795% (16335/19264)
Loss: 0.642 | Acc: 84.714% (21741/25664)
Loss: 0.644 | Acc: 84.615% (27131/32064)
Loss: 0.641 | Acc: 84.692% (32576/38464)
Loss: 0.640 | Acc: 84.683% (37992/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0090, Accuracy: 7230/10000 (72.30%)

Epoch: 128
Loss: 0.819 | Acc: 76.562% (49/64)
Loss: 0.598 | Acc: 85.412% (5521/6464)
Loss: 0.610 | Acc: 85.207% (10961/12864)
Loss: 0.618 | Acc: 84.915% (16358/19264)
Loss: 0.621 | Acc: 84.987% (21811/25664)
Loss: 0.626 | Acc: 84.899% (27222/32064)
Loss: 0.629 | Acc: 84.861% (32641/38464)
Loss: 0.629 | Acc: 84.836% (38061/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8809, Accuracy: 7821/10000 (78.21%)

Epoch: 129
Loss: 0.612 | Acc: 87.500% (56/64)
Loss: 0.600 | Acc: 85.938% (5555/6464)
Loss: 0.606 | Acc: 85.728% (11028/12864)
Loss: 0.600 | Acc: 85.849% (16538/19264)
Loss: 0.605 | Acc: 85.579% (21963/25664)
Loss: 0.612 | Acc: 85.463% (27403/32064)
Loss: 0.615 | Acc: 85.503% (32888/38464)
Loss: 0.615 | Acc: 85.552% (38382/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8679, Accuracy: 7802/10000 (78.02%)

Epoch: 130
Loss: 0.756 | Acc: 84.375% (54/64)
Loss: 0.612 | Acc: 85.102% (5501/6464)
Loss: 0.624 | Acc: 85.152% (10954/12864)
Loss: 0.607 | Acc: 85.771% (16523/19264)
Loss: 0.605 | Acc: 85.696% (21993/25664)
Loss: 0.600 | Acc: 85.847% (27526/32064)
Loss: 0.601 | Acc: 85.839% (33017/38464)
Loss: 0.599 | Acc: 85.906% (38541/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0880, Accuracy: 7030/10000 (70.30%)

Epoch: 131
Loss: 0.633 | Acc: 79.688% (51/64)
Loss: 0.565 | Acc: 87.129% (5632/6464)
Loss: 0.568 | Acc: 86.785% (11164/12864)
Loss: 0.566 | Acc: 86.820% (16725/19264)
Loss: 0.574 | Acc: 86.580% (22220/25664)
Loss: 0.580 | Acc: 86.443% (27717/32064)
Loss: 0.578 | Acc: 86.525% (33281/38464)
Loss: 0.581 | Acc: 86.497% (38806/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0272, Accuracy: 7264/10000 (72.64%)

Epoch: 132
Loss: 0.819 | Acc: 76.562% (49/64)
Loss: 0.556 | Acc: 86.866% (5615/6464)
Loss: 0.562 | Acc: 86.824% (11169/12864)
Loss: 0.562 | Acc: 86.856% (16732/19264)
Loss: 0.570 | Acc: 86.580% (22220/25664)
Loss: 0.574 | Acc: 86.499% (27735/32064)
Loss: 0.573 | Acc: 86.590% (33306/38464)
Loss: 0.574 | Acc: 86.544% (38827/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8103, Accuracy: 8050/10000 (80.50%)

Epoch: 133
Loss: 0.533 | Acc: 85.938% (55/64)
Loss: 0.497 | Acc: 88.537% (5723/6464)
Loss: 0.520 | Acc: 87.974% (11317/12864)
Loss: 0.535 | Acc: 87.645% (16884/19264)
Loss: 0.536 | Acc: 87.609% (22484/25664)
Loss: 0.546 | Acc: 87.344% (28006/32064)
Loss: 0.550 | Acc: 87.256% (33562/38464)
Loss: 0.549 | Acc: 87.335% (39182/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8172, Accuracy: 8060/10000 (80.60%)

Epoch: 134
Loss: 0.375 | Acc: 90.625% (58/64)
Loss: 0.535 | Acc: 87.639% (5665/6464)
Loss: 0.527 | Acc: 87.858% (11302/12864)
Loss: 0.527 | Acc: 87.702% (16895/19264)
Loss: 0.525 | Acc: 87.745% (22519/25664)
Loss: 0.532 | Acc: 87.619% (28094/32064)
Loss: 0.531 | Acc: 87.669% (33721/38464)
Loss: 0.527 | Acc: 87.727% (39358/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8371, Accuracy: 7996/10000 (79.96%)

Epoch: 135
Loss: 0.514 | Acc: 89.062% (57/64)
Loss: 0.477 | Acc: 88.970% (5751/6464)
Loss: 0.478 | Acc: 88.822% (11426/12864)
Loss: 0.483 | Acc: 88.710% (17089/19264)
Loss: 0.498 | Acc: 88.381% (22682/25664)
Loss: 0.502 | Acc: 88.342% (28326/32064)
Loss: 0.509 | Acc: 88.129% (33898/38464)
Loss: 0.508 | Acc: 88.149% (39547/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8342, Accuracy: 8064/10000 (80.64%)

Epoch: 136
Loss: 0.452 | Acc: 90.625% (58/64)
Loss: 0.498 | Acc: 88.258% (5705/6464)
Loss: 0.490 | Acc: 88.402% (11372/12864)
Loss: 0.479 | Acc: 88.839% (17114/19264)
Loss: 0.481 | Acc: 88.817% (22794/25664)
Loss: 0.484 | Acc: 88.735% (28452/32064)
Loss: 0.489 | Acc: 88.647% (34097/38464)
Loss: 0.487 | Acc: 88.704% (39796/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9707, Accuracy: 7670/10000 (76.70%)

Epoch: 137
Loss: 0.537 | Acc: 87.500% (56/64)
Loss: 0.457 | Acc: 89.341% (5775/6464)
Loss: 0.451 | Acc: 89.420% (11503/12864)
Loss: 0.455 | Acc: 89.405% (17223/19264)
Loss: 0.452 | Acc: 89.503% (22970/25664)
Loss: 0.458 | Acc: 89.390% (28662/32064)
Loss: 0.460 | Acc: 89.317% (34355/38464)
Loss: 0.460 | Acc: 89.314% (40070/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9999, Accuracy: 7654/10000 (76.54%)

Epoch: 138
Loss: 0.371 | Acc: 90.625% (58/64)
Loss: 0.432 | Acc: 89.805% (5805/6464)
Loss: 0.434 | Acc: 89.747% (11545/12864)
Loss: 0.425 | Acc: 90.038% (17345/19264)
Loss: 0.423 | Acc: 90.037% (23107/25664)
Loss: 0.426 | Acc: 89.951% (28842/32064)
Loss: 0.423 | Acc: 90.076% (34647/38464)
Loss: 0.428 | Acc: 89.943% (40352/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8107, Accuracy: 8237/10000 (82.37%)

Epoch: 139
Loss: 0.471 | Acc: 87.500% (56/64)
Loss: 0.381 | Acc: 91.027% (5884/6464)
Loss: 0.388 | Acc: 90.850% (11687/12864)
Loss: 0.394 | Acc: 90.661% (17465/19264)
Loss: 0.401 | Acc: 90.450% (23213/25664)
Loss: 0.403 | Acc: 90.416% (28991/32064)
Loss: 0.402 | Acc: 90.503% (34811/38464)
Loss: 0.403 | Acc: 90.500% (40602/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8998, Accuracy: 8048/10000 (80.48%)

Epoch: 140
Loss: 0.306 | Acc: 89.062% (57/64)
Loss: 0.378 | Acc: 91.043% (5885/6464)
Loss: 0.377 | Acc: 91.068% (11715/12864)
Loss: 0.368 | Acc: 91.263% (17581/19264)
Loss: 0.368 | Acc: 91.178% (23400/25664)
Loss: 0.365 | Acc: 91.277% (29267/32064)
Loss: 0.368 | Acc: 91.220% (35087/38464)
Loss: 0.370 | Acc: 91.140% (40889/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9213, Accuracy: 8005/10000 (80.05%)

Epoch: 141
Loss: 0.539 | Acc: 87.500% (56/64)
Loss: 0.331 | Acc: 91.909% (5941/6464)
Loss: 0.336 | Acc: 91.900% (11822/12864)
Loss: 0.336 | Acc: 91.923% (17708/19264)
Loss: 0.337 | Acc: 91.864% (23576/25664)
Loss: 0.332 | Acc: 91.969% (29489/32064)
Loss: 0.330 | Acc: 92.000% (35387/38464)
Loss: 0.335 | Acc: 91.880% (41221/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8943, Accuracy: 8188/10000 (81.88%)

Epoch: 142
Loss: 0.239 | Acc: 95.312% (61/64)
Loss: 0.307 | Acc: 92.017% (5948/6464)
Loss: 0.302 | Acc: 92.265% (11869/12864)
Loss: 0.301 | Acc: 92.406% (17801/19264)
Loss: 0.300 | Acc: 92.495% (23738/25664)
Loss: 0.299 | Acc: 92.506% (29661/32064)
Loss: 0.299 | Acc: 92.523% (35588/38464)
Loss: 0.300 | Acc: 92.475% (41488/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9091, Accuracy: 8224/10000 (82.24%)

Epoch: 143
Loss: 0.377 | Acc: 87.500% (56/64)
Loss: 0.273 | Acc: 93.085% (6017/6464)
Loss: 0.272 | Acc: 93.058% (11971/12864)
Loss: 0.263 | Acc: 93.387% (17990/19264)
Loss: 0.263 | Acc: 93.376% (23964/25664)
Loss: 0.264 | Acc: 93.304% (29917/32064)
Loss: 0.264 | Acc: 93.300% (35887/38464)
Loss: 0.267 | Acc: 93.224% (41824/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9218, Accuracy: 8265/10000 (82.65%)

Epoch: 144
Loss: 0.272 | Acc: 92.188% (59/64)
Loss: 0.234 | Acc: 93.874% (6068/6464)
Loss: 0.232 | Acc: 93.937% (12084/12864)
Loss: 0.234 | Acc: 93.958% (18100/19264)
Loss: 0.234 | Acc: 93.933% (24107/25664)
Loss: 0.232 | Acc: 93.987% (30136/32064)
Loss: 0.233 | Acc: 93.961% (36141/38464)
Loss: 0.236 | Acc: 93.895% (42125/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9306, Accuracy: 8257/10000 (82.57%)

Epoch: 145
Loss: 0.143 | Acc: 96.875% (62/64)
Loss: 0.195 | Acc: 95.003% (6141/6464)
Loss: 0.203 | Acc: 94.675% (12179/12864)
Loss: 0.205 | Acc: 94.643% (18232/19264)
Loss: 0.206 | Acc: 94.572% (24271/25664)
Loss: 0.205 | Acc: 94.633% (30343/32064)
Loss: 0.207 | Acc: 94.561% (36372/38464)
Loss: 0.207 | Acc: 94.584% (42434/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9363, Accuracy: 8232/10000 (82.32%)

Epoch: 146
Loss: 0.397 | Acc: 87.500% (56/64)
Loss: 0.191 | Acc: 95.019% (6142/6464)
Loss: 0.197 | Acc: 94.838% (12200/12864)
Loss: 0.201 | Acc: 94.658% (18235/19264)
Loss: 0.198 | Acc: 94.767% (24321/25664)
Loss: 0.198 | Acc: 94.767% (30386/32064)
Loss: 0.201 | Acc: 94.642% (36403/38464)
Loss: 0.201 | Acc: 94.666% (42471/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9276, Accuracy: 8239/10000 (82.39%)

Epoch: 147
Loss: 0.112 | Acc: 96.875% (62/64)
Loss: 0.188 | Acc: 94.879% (6133/6464)
Loss: 0.191 | Acc: 94.815% (12197/12864)
Loss: 0.191 | Acc: 94.866% (18275/19264)
Loss: 0.187 | Acc: 94.974% (24374/25664)
Loss: 0.187 | Acc: 94.998% (30460/32064)
Loss: 0.188 | Acc: 94.964% (36527/38464)
Loss: 0.188 | Acc: 94.980% (42612/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9242, Accuracy: 8254/10000 (82.54%)
torch.Size([100, 10])
Test set: Average loss: 0.9242, Accuracy: 8254/10000 (82.54%)

Epoch: 148
Loss: 0.072 | Acc: 98.438% (63/64)
Loss: 0.176 | Acc: 95.173% (6152/6464)
Loss: 0.178 | Acc: 95.165% (12242/12864)
Loss: 0.180 | Acc: 95.074% (18315/19264)
Loss: 0.178 | Acc: 95.223% (24438/25664)
Loss: 0.179 | Acc: 95.203% (30526/32064)
Loss: 0.181 | Acc: 95.102% (36580/38464)
Loss: 0.181 | Acc: 95.119% (42674/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9214, Accuracy: 8266/10000 (82.66%)
torch.Size([100, 10])
Test set: Average loss: 0.9214, Accuracy: 8266/10000 (82.66%)

Epoch: 149
Loss: 0.272 | Acc: 90.625% (58/64)
Loss: 0.188 | Acc: 95.019% (6142/6464)
Loss: 0.180 | Acc: 95.328% (12263/12864)
Loss: 0.178 | Acc: 95.359% (18370/19264)
Loss: 0.176 | Acc: 95.398% (24483/25664)
Loss: 0.176 | Acc: 95.394% (30587/32064)
Loss: 0.180 | Acc: 95.318% (36663/38464)
Loss: 0.179 | Acc: 95.355% (42780/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9285, Accuracy: 8266/10000 (82.66%)
torch.Size([100, 10])
Test set: Average loss: 0.9285, Accuracy: 8266/10000 (82.66%)

Epoch: 150
Loss: 0.071 | Acc: 98.438% (63/64)
Loss: 1.424 | Acc: 55.012% (3556/6464)
Loss: 1.224 | Acc: 62.788% (8077/12864)
Loss: 1.141 | Acc: 65.947% (12704/19264)
Loss: 1.088 | Acc: 68.060% (17467/25664)
Loss: 1.046 | Acc: 69.729% (22358/32064)
Loss: 1.018 | Acc: 70.812% (27237/38464)
Loss: 0.997 | Acc: 71.581% (32114/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4976, Accuracy: 5515/10000 (55.15%)

Epoch: 151
Loss: 0.781 | Acc: 78.125% (50/64)
Loss: 0.816 | Acc: 78.326% (5063/6464)
Loss: 0.826 | Acc: 78.047% (10040/12864)
Loss: 0.835 | Acc: 77.845% (14996/19264)
Loss: 0.831 | Acc: 77.883% (19988/25664)
Loss: 0.824 | Acc: 78.206% (25076/32064)
Loss: 0.825 | Acc: 78.177% (30070/38464)
Loss: 0.825 | Acc: 78.187% (35078/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7699, Accuracy: 4965/10000 (49.65%)

Epoch: 152
Loss: 0.909 | Acc: 75.000% (48/64)
Loss: 0.802 | Acc: 78.929% (5102/6464)
Loss: 0.789 | Acc: 79.377% (10211/12864)
Loss: 0.798 | Acc: 79.148% (15247/19264)
Loss: 0.800 | Acc: 78.998% (20274/25664)
Loss: 0.805 | Acc: 78.877% (25291/32064)
Loss: 0.807 | Acc: 78.856% (30331/38464)
Loss: 0.804 | Acc: 78.974% (35431/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7273, Accuracy: 5314/10000 (53.14%)

Epoch: 153
Loss: 1.020 | Acc: 67.188% (43/64)
Loss: 0.794 | Acc: 78.868% (5098/6464)
Loss: 0.776 | Acc: 79.633% (10244/12864)
Loss: 0.782 | Acc: 79.594% (15333/19264)
Loss: 0.779 | Acc: 79.851% (20493/25664)
Loss: 0.787 | Acc: 79.631% (25533/32064)
Loss: 0.790 | Acc: 79.524% (30588/38464)
Loss: 0.790 | Acc: 79.489% (35662/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0161, Accuracy: 7228/10000 (72.28%)

Epoch: 154
Loss: 0.839 | Acc: 79.688% (51/64)
Loss: 0.777 | Acc: 79.858% (5162/6464)
Loss: 0.788 | Acc: 79.563% (10235/12864)
Loss: 0.782 | Acc: 79.797% (15372/19264)
Loss: 0.783 | Acc: 79.726% (20461/25664)
Loss: 0.784 | Acc: 79.681% (25549/32064)
Loss: 0.784 | Acc: 79.771% (30683/38464)
Loss: 0.783 | Acc: 79.841% (35820/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3306, Accuracy: 6099/10000 (60.99%)

Epoch: 155
Loss: 1.004 | Acc: 75.000% (48/64)
Loss: 0.789 | Acc: 79.162% (5117/6464)
Loss: 0.790 | Acc: 79.291% (10200/12864)
Loss: 0.784 | Acc: 79.739% (15361/19264)
Loss: 0.780 | Acc: 79.765% (20471/25664)
Loss: 0.779 | Acc: 79.887% (25615/32064)
Loss: 0.782 | Acc: 79.888% (30728/38464)
Loss: 0.783 | Acc: 79.930% (35860/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9485, Accuracy: 7505/10000 (75.05%)

Epoch: 156
Loss: 0.675 | Acc: 81.250% (52/64)
Loss: 0.754 | Acc: 80.848% (5226/6464)
Loss: 0.761 | Acc: 80.504% (10356/12864)
Loss: 0.759 | Acc: 80.487% (15505/19264)
Loss: 0.763 | Acc: 80.404% (20635/25664)
Loss: 0.768 | Acc: 80.246% (25730/32064)
Loss: 0.773 | Acc: 80.163% (30834/38464)
Loss: 0.775 | Acc: 80.029% (35904/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1557, Accuracy: 6619/10000 (66.19%)

Epoch: 157
Loss: 0.985 | Acc: 73.438% (47/64)
Loss: 0.784 | Acc: 79.889% (5164/6464)
Loss: 0.769 | Acc: 80.107% (10305/12864)
Loss: 0.777 | Acc: 79.890% (15390/19264)
Loss: 0.781 | Acc: 79.878% (20500/25664)
Loss: 0.779 | Acc: 79.881% (25613/32064)
Loss: 0.773 | Acc: 80.080% (30802/38464)
Loss: 0.776 | Acc: 79.975% (35880/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3513, Accuracy: 6340/10000 (63.40%)

Epoch: 158
Loss: 0.851 | Acc: 81.250% (52/64)
Loss: 0.769 | Acc: 80.848% (5226/6464)
Loss: 0.765 | Acc: 80.356% (10337/12864)
Loss: 0.765 | Acc: 80.487% (15505/19264)
Loss: 0.768 | Acc: 80.436% (20643/25664)
Loss: 0.771 | Acc: 80.352% (25764/32064)
Loss: 0.771 | Acc: 80.361% (30910/38464)
Loss: 0.773 | Acc: 80.289% (36021/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9847, Accuracy: 7336/10000 (73.36%)

Epoch: 159
Loss: 0.858 | Acc: 71.875% (46/64)
Loss: 0.742 | Acc: 81.374% (5260/6464)
Loss: 0.747 | Acc: 81.017% (10422/12864)
Loss: 0.749 | Acc: 81.131% (15629/19264)
Loss: 0.750 | Acc: 81.036% (20797/25664)
Loss: 0.753 | Acc: 80.876% (25932/32064)
Loss: 0.757 | Acc: 80.766% (31066/38464)
Loss: 0.764 | Acc: 80.503% (36117/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2434, Accuracy: 6564/10000 (65.64%)

Epoch: 160
Loss: 0.801 | Acc: 76.562% (49/64)
Loss: 0.753 | Acc: 81.064% (5240/6464)
Loss: 0.769 | Acc: 80.675% (10378/12864)
Loss: 0.757 | Acc: 80.902% (15585/19264)
Loss: 0.759 | Acc: 80.634% (20694/25664)
Loss: 0.755 | Acc: 80.848% (25923/32064)
Loss: 0.763 | Acc: 80.636% (31016/38464)
Loss: 0.764 | Acc: 80.633% (36175/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5552, Accuracy: 5562/10000 (55.62%)

Epoch: 161
Loss: 1.243 | Acc: 67.188% (43/64)
Loss: 0.727 | Acc: 81.482% (5267/6464)
Loss: 0.741 | Acc: 81.149% (10439/12864)
Loss: 0.754 | Acc: 80.757% (15557/19264)
Loss: 0.757 | Acc: 80.580% (20680/25664)
Loss: 0.759 | Acc: 80.670% (25866/32064)
Loss: 0.762 | Acc: 80.608% (31005/38464)
Loss: 0.764 | Acc: 80.541% (36134/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3455, Accuracy: 6220/10000 (62.20%)

Epoch: 162
Loss: 0.807 | Acc: 76.562% (49/64)
Loss: 0.738 | Acc: 81.235% (5251/6464)
Loss: 0.743 | Acc: 81.413% (10473/12864)
Loss: 0.745 | Acc: 81.292% (15660/19264)
Loss: 0.747 | Acc: 81.227% (20846/25664)
Loss: 0.750 | Acc: 81.097% (26003/32064)
Loss: 0.751 | Acc: 81.099% (31194/38464)
Loss: 0.754 | Acc: 80.998% (36339/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9794, Accuracy: 7294/10000 (72.94%)

Epoch: 163
Loss: 0.418 | Acc: 89.062% (57/64)
Loss: 0.719 | Acc: 82.024% (5302/6464)
Loss: 0.733 | Acc: 81.678% (10507/12864)
Loss: 0.738 | Acc: 81.437% (15688/19264)
Loss: 0.744 | Acc: 81.250% (20852/25664)
Loss: 0.749 | Acc: 81.116% (26009/32064)
Loss: 0.750 | Acc: 81.078% (31186/38464)
Loss: 0.751 | Acc: 81.061% (36367/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0662, Accuracy: 6980/10000 (69.80%)

Epoch: 164
Loss: 0.918 | Acc: 75.000% (48/64)
Loss: 0.730 | Acc: 81.235% (5251/6464)
Loss: 0.714 | Acc: 81.887% (10534/12864)
Loss: 0.722 | Acc: 81.769% (15752/19264)
Loss: 0.736 | Acc: 81.246% (20851/25664)
Loss: 0.738 | Acc: 81.209% (26039/32064)
Loss: 0.741 | Acc: 81.201% (31233/38464)
Loss: 0.744 | Acc: 81.101% (36385/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1296, Accuracy: 6668/10000 (66.68%)

Epoch: 165
Loss: 0.743 | Acc: 82.812% (53/64)
Loss: 0.751 | Acc: 80.863% (5227/6464)
Loss: 0.741 | Acc: 80.986% (10418/12864)
Loss: 0.735 | Acc: 81.276% (15657/19264)
Loss: 0.737 | Acc: 81.308% (20867/25664)
Loss: 0.737 | Acc: 81.291% (26065/32064)
Loss: 0.732 | Acc: 81.489% (31344/38464)
Loss: 0.734 | Acc: 81.520% (36573/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9424, Accuracy: 7466/10000 (74.66%)

Epoch: 166
Loss: 0.925 | Acc: 75.000% (48/64)
Loss: 0.714 | Acc: 82.410% (5327/6464)
Loss: 0.715 | Acc: 82.276% (10584/12864)
Loss: 0.712 | Acc: 82.200% (15835/19264)
Loss: 0.723 | Acc: 81.873% (21012/25664)
Loss: 0.727 | Acc: 81.771% (26219/32064)
Loss: 0.732 | Acc: 81.640% (31402/38464)
Loss: 0.732 | Acc: 81.622% (36619/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4385, Accuracy: 4106/10000 (41.06%)

Epoch: 167
Loss: 0.826 | Acc: 78.125% (50/64)
Loss: 0.715 | Acc: 81.962% (5298/6464)
Loss: 0.720 | Acc: 81.833% (10527/12864)
Loss: 0.727 | Acc: 81.873% (15772/19264)
Loss: 0.720 | Acc: 82.135% (21079/25664)
Loss: 0.723 | Acc: 82.011% (26296/32064)
Loss: 0.724 | Acc: 81.942% (31518/38464)
Loss: 0.728 | Acc: 81.830% (36712/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5897, Accuracy: 5776/10000 (57.76%)

Epoch: 168
Loss: 0.502 | Acc: 84.375% (54/64)
Loss: 0.700 | Acc: 82.039% (5303/6464)
Loss: 0.717 | Acc: 81.724% (10513/12864)
Loss: 0.722 | Acc: 81.577% (15715/19264)
Loss: 0.720 | Acc: 81.628% (20949/25664)
Loss: 0.723 | Acc: 81.652% (26181/32064)
Loss: 0.725 | Acc: 81.661% (31410/38464)
Loss: 0.724 | Acc: 81.752% (36677/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5068, Accuracy: 5868/10000 (58.68%)

Epoch: 169
Loss: 0.747 | Acc: 76.562% (49/64)
Loss: 0.694 | Acc: 82.503% (5333/6464)
Loss: 0.705 | Acc: 82.253% (10581/12864)
Loss: 0.709 | Acc: 82.236% (15842/19264)
Loss: 0.709 | Acc: 82.353% (21135/25664)
Loss: 0.715 | Acc: 82.310% (26392/32064)
Loss: 0.715 | Acc: 82.355% (31677/38464)
Loss: 0.713 | Acc: 82.396% (36966/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0463, Accuracy: 7136/10000 (71.36%)

Epoch: 170
Loss: 1.060 | Acc: 73.438% (47/64)
Loss: 0.699 | Acc: 82.782% (5351/6464)
Loss: 0.698 | Acc: 82.657% (10633/12864)
Loss: 0.708 | Acc: 82.527% (15898/19264)
Loss: 0.706 | Acc: 82.590% (21196/25664)
Loss: 0.708 | Acc: 82.466% (26442/32064)
Loss: 0.705 | Acc: 82.584% (31765/38464)
Loss: 0.708 | Acc: 82.494% (37010/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4715, Accuracy: 6270/10000 (62.70%)

Epoch: 171
Loss: 0.769 | Acc: 81.250% (52/64)
Loss: 0.676 | Acc: 83.772% (5415/6464)
Loss: 0.688 | Acc: 83.271% (10712/12864)
Loss: 0.690 | Acc: 83.186% (16025/19264)
Loss: 0.695 | Acc: 83.027% (21308/25664)
Loss: 0.692 | Acc: 83.078% (26638/32064)
Loss: 0.695 | Acc: 82.971% (31914/38464)
Loss: 0.694 | Acc: 83.011% (37242/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2502, Accuracy: 6536/10000 (65.36%)

Epoch: 172
Loss: 0.986 | Acc: 75.000% (48/64)
Loss: 0.690 | Acc: 83.106% (5372/6464)
Loss: 0.677 | Acc: 83.535% (10746/12864)
Loss: 0.676 | Acc: 83.441% (16074/19264)
Loss: 0.676 | Acc: 83.420% (21409/25664)
Loss: 0.675 | Acc: 83.530% (26783/32064)
Loss: 0.678 | Acc: 83.403% (32080/38464)
Loss: 0.683 | Acc: 83.296% (37370/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4650, Accuracy: 5846/10000 (58.46%)

Epoch: 173
Loss: 0.644 | Acc: 85.938% (55/64)
Loss: 0.683 | Acc: 83.122% (5373/6464)
Loss: 0.667 | Acc: 83.668% (10763/12864)
Loss: 0.670 | Acc: 83.596% (16104/19264)
Loss: 0.672 | Acc: 83.529% (21437/25664)
Loss: 0.675 | Acc: 83.499% (26773/32064)
Loss: 0.676 | Acc: 83.483% (32111/38464)
Loss: 0.675 | Acc: 83.546% (37482/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0607, Accuracy: 4638/10000 (46.38%)

Epoch: 174
Loss: 0.939 | Acc: 67.188% (43/64)
Loss: 0.665 | Acc: 83.540% (5400/6464)
Loss: 0.661 | Acc: 83.745% (10773/12864)
Loss: 0.658 | Acc: 83.866% (16156/19264)
Loss: 0.667 | Acc: 83.728% (21488/25664)
Loss: 0.666 | Acc: 83.804% (26871/32064)
Loss: 0.665 | Acc: 83.821% (32241/38464)
Loss: 0.667 | Acc: 83.764% (37580/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9212, Accuracy: 7584/10000 (75.84%)

Epoch: 175
Loss: 0.620 | Acc: 82.812% (53/64)
Loss: 0.640 | Acc: 84.282% (5448/6464)
Loss: 0.637 | Acc: 84.344% (10850/12864)
Loss: 0.640 | Acc: 84.344% (16248/19264)
Loss: 0.651 | Acc: 84.184% (21605/25664)
Loss: 0.645 | Acc: 84.369% (27052/32064)
Loss: 0.650 | Acc: 84.284% (32419/38464)
Loss: 0.653 | Acc: 84.279% (37811/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9608, Accuracy: 7565/10000 (75.65%)

Epoch: 176
Loss: 0.712 | Acc: 85.938% (55/64)
Loss: 0.635 | Acc: 85.025% (5496/6464)
Loss: 0.639 | Acc: 84.888% (10920/12864)
Loss: 0.641 | Acc: 84.702% (16317/19264)
Loss: 0.647 | Acc: 84.500% (21686/25664)
Loss: 0.648 | Acc: 84.450% (27078/32064)
Loss: 0.644 | Acc: 84.580% (32533/38464)
Loss: 0.643 | Acc: 84.642% (37974/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9360, Accuracy: 7546/10000 (75.46%)

Epoch: 177
Loss: 0.505 | Acc: 85.938% (55/64)
Loss: 0.650 | Acc: 84.731% (5477/6464)
Loss: 0.632 | Acc: 85.051% (10941/12864)
Loss: 0.633 | Acc: 84.998% (16374/19264)
Loss: 0.634 | Acc: 84.979% (21809/25664)
Loss: 0.636 | Acc: 84.818% (27196/32064)
Loss: 0.640 | Acc: 84.674% (32569/38464)
Loss: 0.638 | Acc: 84.727% (38012/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8755, Accuracy: 7731/10000 (77.31%)

Epoch: 178
Loss: 0.471 | Acc: 89.062% (57/64)
Loss: 0.595 | Acc: 85.829% (5548/6464)
Loss: 0.608 | Acc: 85.790% (11036/12864)
Loss: 0.610 | Acc: 85.610% (16492/19264)
Loss: 0.613 | Acc: 85.571% (21961/25664)
Loss: 0.617 | Acc: 85.460% (27402/32064)
Loss: 0.618 | Acc: 85.438% (32863/38464)
Loss: 0.618 | Acc: 85.418% (38322/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3927, Accuracy: 6328/10000 (63.28%)

Epoch: 179
Loss: 0.605 | Acc: 84.375% (54/64)
Loss: 0.631 | Acc: 85.056% (5498/6464)
Loss: 0.614 | Acc: 85.487% (10997/12864)
Loss: 0.606 | Acc: 85.673% (16504/19264)
Loss: 0.602 | Acc: 85.844% (22031/25664)
Loss: 0.608 | Acc: 85.722% (27486/32064)
Loss: 0.603 | Acc: 85.886% (33035/38464)
Loss: 0.605 | Acc: 85.824% (38504/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8185, Accuracy: 7975/10000 (79.75%)

Epoch: 180
Loss: 0.496 | Acc: 90.625% (58/64)
Loss: 0.586 | Acc: 86.262% (5576/6464)
Loss: 0.595 | Acc: 85.922% (11053/12864)
Loss: 0.589 | Acc: 86.114% (16589/19264)
Loss: 0.584 | Acc: 86.284% (22144/25664)
Loss: 0.589 | Acc: 86.184% (27634/32064)
Loss: 0.591 | Acc: 86.143% (33134/38464)
Loss: 0.590 | Acc: 86.180% (38664/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8436, Accuracy: 7918/10000 (79.18%)

Epoch: 181
Loss: 0.650 | Acc: 82.812% (53/64)
Loss: 0.561 | Acc: 87.113% (5631/6464)
Loss: 0.549 | Acc: 87.212% (11219/12864)
Loss: 0.559 | Acc: 86.996% (16759/19264)
Loss: 0.567 | Acc: 86.799% (22276/25664)
Loss: 0.566 | Acc: 86.867% (27853/32064)
Loss: 0.571 | Acc: 86.769% (33375/38464)
Loss: 0.573 | Acc: 86.698% (38896/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9046, Accuracy: 7729/10000 (77.29%)

Epoch: 182
Loss: 0.735 | Acc: 79.688% (51/64)
Loss: 0.540 | Acc: 87.314% (5644/6464)
Loss: 0.532 | Acc: 87.492% (11255/12864)
Loss: 0.545 | Acc: 87.105% (16780/19264)
Loss: 0.549 | Acc: 87.032% (22336/25664)
Loss: 0.555 | Acc: 87.007% (27898/32064)
Loss: 0.556 | Acc: 87.027% (33474/38464)
Loss: 0.555 | Acc: 87.130% (39090/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8643, Accuracy: 7928/10000 (79.28%)

Epoch: 183
Loss: 0.545 | Acc: 89.062% (57/64)
Loss: 0.514 | Acc: 87.825% (5677/6464)
Loss: 0.531 | Acc: 87.617% (11271/12864)
Loss: 0.538 | Acc: 87.531% (16862/19264)
Loss: 0.539 | Acc: 87.473% (22449/25664)
Loss: 0.539 | Acc: 87.450% (28040/32064)
Loss: 0.540 | Acc: 87.378% (33609/38464)
Loss: 0.541 | Acc: 87.395% (39209/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7598, Accuracy: 8220/10000 (82.20%)

Epoch: 184
Loss: 0.593 | Acc: 85.938% (55/64)
Loss: 0.498 | Acc: 88.521% (5722/6464)
Loss: 0.509 | Acc: 88.036% (11325/12864)
Loss: 0.515 | Acc: 88.009% (16954/19264)
Loss: 0.513 | Acc: 88.038% (22594/25664)
Loss: 0.516 | Acc: 87.868% (28174/32064)
Loss: 0.517 | Acc: 87.812% (33776/38464)
Loss: 0.517 | Acc: 87.897% (39434/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7960, Accuracy: 8131/10000 (81.31%)

Epoch: 185
Loss: 0.540 | Acc: 85.938% (55/64)
Loss: 0.489 | Acc: 88.629% (5729/6464)
Loss: 0.478 | Acc: 88.977% (11446/12864)
Loss: 0.486 | Acc: 88.689% (17085/19264)
Loss: 0.496 | Acc: 88.490% (22710/25664)
Loss: 0.496 | Acc: 88.526% (28385/32064)
Loss: 0.496 | Acc: 88.615% (34085/38464)
Loss: 0.499 | Acc: 88.503% (39706/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8764, Accuracy: 7898/10000 (78.98%)

Epoch: 186
Loss: 0.269 | Acc: 96.875% (62/64)
Loss: 0.461 | Acc: 89.295% (5772/6464)
Loss: 0.468 | Acc: 89.109% (11463/12864)
Loss: 0.468 | Acc: 89.109% (17166/19264)
Loss: 0.474 | Acc: 88.992% (22839/25664)
Loss: 0.477 | Acc: 88.919% (28511/32064)
Loss: 0.477 | Acc: 88.888% (34190/38464)
Loss: 0.474 | Acc: 88.969% (39915/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8362, Accuracy: 8116/10000 (81.16%)

Epoch: 187
Loss: 0.229 | Acc: 95.312% (61/64)
Loss: 0.422 | Acc: 90.068% (5822/6464)
Loss: 0.429 | Acc: 89.887% (11563/12864)
Loss: 0.441 | Acc: 89.634% (17267/19264)
Loss: 0.446 | Acc: 89.503% (22970/25664)
Loss: 0.447 | Acc: 89.468% (28687/32064)
Loss: 0.450 | Acc: 89.395% (34385/38464)
Loss: 0.450 | Acc: 89.370% (40095/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8398, Accuracy: 8158/10000 (81.58%)

Epoch: 188
Loss: 0.590 | Acc: 84.375% (54/64)
Loss: 0.421 | Acc: 89.836% (5807/6464)
Loss: 0.417 | Acc: 90.096% (11590/12864)
Loss: 0.421 | Acc: 90.007% (17339/19264)
Loss: 0.423 | Acc: 89.982% (23093/25664)
Loss: 0.424 | Acc: 90.001% (28858/32064)
Loss: 0.423 | Acc: 90.037% (34632/38464)
Loss: 0.422 | Acc: 90.041% (40396/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8297, Accuracy: 8193/10000 (81.93%)

Epoch: 189
Loss: 0.181 | Acc: 95.312% (61/64)
Loss: 0.353 | Acc: 91.847% (5937/6464)
Loss: 0.373 | Acc: 91.192% (11731/12864)
Loss: 0.381 | Acc: 91.014% (17533/19264)
Loss: 0.386 | Acc: 90.898% (23328/25664)
Loss: 0.388 | Acc: 90.840% (29127/32064)
Loss: 0.391 | Acc: 90.778% (34917/38464)
Loss: 0.393 | Acc: 90.674% (40680/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8293, Accuracy: 8266/10000 (82.66%)

Epoch: 190
Loss: 0.477 | Acc: 87.500% (56/64)
Loss: 0.334 | Acc: 91.739% (5930/6464)
Loss: 0.337 | Acc: 91.822% (11812/12864)
Loss: 0.347 | Acc: 91.502% (17627/19264)
Loss: 0.350 | Acc: 91.517% (23487/25664)
Loss: 0.349 | Acc: 91.595% (29369/32064)
Loss: 0.352 | Acc: 91.548% (35213/38464)
Loss: 0.354 | Acc: 91.530% (41064/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8768, Accuracy: 8155/10000 (81.55%)

Epoch: 191
Loss: 0.321 | Acc: 92.188% (59/64)
Loss: 0.317 | Acc: 92.543% (5982/6464)
Loss: 0.314 | Acc: 92.584% (11910/12864)
Loss: 0.318 | Acc: 92.380% (17796/19264)
Loss: 0.316 | Acc: 92.413% (23717/25664)
Loss: 0.315 | Acc: 92.412% (29631/32064)
Loss: 0.320 | Acc: 92.190% (35460/38464)
Loss: 0.321 | Acc: 92.141% (41338/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9039, Accuracy: 8110/10000 (81.10%)

Epoch: 192
Loss: 0.187 | Acc: 96.875% (62/64)
Loss: 0.280 | Acc: 93.085% (6017/6464)
Loss: 0.278 | Acc: 93.027% (11967/12864)
Loss: 0.280 | Acc: 92.997% (17915/19264)
Loss: 0.284 | Acc: 92.881% (23837/25664)
Loss: 0.286 | Acc: 92.817% (29761/32064)
Loss: 0.287 | Acc: 92.791% (35691/38464)
Loss: 0.288 | Acc: 92.738% (41606/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9138, Accuracy: 8230/10000 (82.30%)

Epoch: 193
Loss: 0.141 | Acc: 93.750% (60/64)
Loss: 0.270 | Acc: 92.853% (6002/6464)
Loss: 0.264 | Acc: 92.934% (11955/12864)
Loss: 0.259 | Acc: 93.252% (17964/19264)
Loss: 0.261 | Acc: 93.243% (23930/25664)
Loss: 0.257 | Acc: 93.326% (29924/32064)
Loss: 0.255 | Acc: 93.451% (35945/38464)
Loss: 0.254 | Acc: 93.512% (41953/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9404, Accuracy: 8193/10000 (81.93%)

Epoch: 194
Loss: 0.258 | Acc: 95.312% (61/64)
Loss: 0.216 | Acc: 94.338% (6098/6464)
Loss: 0.219 | Acc: 94.255% (12125/12864)
Loss: 0.218 | Acc: 94.228% (18152/19264)
Loss: 0.220 | Acc: 94.171% (24168/25664)
Loss: 0.222 | Acc: 94.196% (30203/32064)
Loss: 0.223 | Acc: 94.208% (36236/38464)
Loss: 0.223 | Acc: 94.223% (42272/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9406, Accuracy: 8225/10000 (82.25%)

Epoch: 195
Loss: 0.262 | Acc: 92.188% (59/64)
Loss: 0.194 | Acc: 94.678% (6120/6464)
Loss: 0.193 | Acc: 94.714% (12184/12864)
Loss: 0.196 | Acc: 94.638% (18231/19264)
Loss: 0.198 | Acc: 94.627% (24285/25664)
Loss: 0.200 | Acc: 94.589% (30329/32064)
Loss: 0.200 | Acc: 94.642% (36403/38464)
Loss: 0.200 | Acc: 94.613% (42447/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9375, Accuracy: 8216/10000 (82.16%)

Epoch: 196
Loss: 0.270 | Acc: 92.188% (59/64)
Loss: 0.190 | Acc: 95.080% (6146/6464)
Loss: 0.189 | Acc: 95.040% (12226/12864)
Loss: 0.192 | Acc: 94.892% (18280/19264)
Loss: 0.190 | Acc: 94.958% (24370/25664)
Loss: 0.187 | Acc: 95.010% (30464/32064)
Loss: 0.188 | Acc: 94.967% (36528/38464)
Loss: 0.188 | Acc: 94.969% (42607/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9440, Accuracy: 8190/10000 (81.90%)

Epoch: 197
Loss: 0.092 | Acc: 98.438% (63/64)
Loss: 0.172 | Acc: 95.529% (6175/6464)
Loss: 0.178 | Acc: 95.382% (12270/12864)
Loss: 0.178 | Acc: 95.338% (18366/19264)
Loss: 0.178 | Acc: 95.231% (24440/25664)
Loss: 0.179 | Acc: 95.203% (30526/32064)
Loss: 0.179 | Acc: 95.196% (36616/38464)
Loss: 0.180 | Acc: 95.150% (42688/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9419, Accuracy: 8202/10000 (82.02%)
torch.Size([100, 10])
Test set: Average loss: 0.9419, Accuracy: 8202/10000 (82.02%)

Epoch: 198
Loss: 0.254 | Acc: 92.188% (59/64)
Loss: 0.181 | Acc: 95.220% (6155/6464)
Loss: 0.176 | Acc: 95.445% (12278/12864)
Loss: 0.175 | Acc: 95.349% (18368/19264)
Loss: 0.176 | Acc: 95.281% (24453/25664)
Loss: 0.175 | Acc: 95.303% (30558/32064)
Loss: 0.175 | Acc: 95.240% (36633/38464)
Loss: 0.174 | Acc: 95.255% (42735/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9408, Accuracy: 8219/10000 (82.19%)
torch.Size([100, 10])
Test set: Average loss: 0.9408, Accuracy: 8219/10000 (82.19%)

Epoch: 199
Loss: 0.097 | Acc: 98.438% (63/64)
Loss: 0.184 | Acc: 94.879% (6133/6464)
Loss: 0.177 | Acc: 95.095% (12233/12864)
Loss: 0.174 | Acc: 95.229% (18345/19264)
Loss: 0.172 | Acc: 95.285% (24454/25664)
Loss: 0.171 | Acc: 95.306% (30559/32064)
Loss: 0.170 | Acc: 95.388% (36690/38464)
Loss: 0.170 | Acc: 95.373% (42788/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9498, Accuracy: 8210/10000 (82.10%)
torch.Size([100, 10])
Test set: Average loss: 0.9498, Accuracy: 8210/10000 (82.10%)
8488
10000
-0.7647279500961304
