==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.358 | Acc: 15.625% (10/64)
Loss: 3.145 | Acc: 12.376% (800/6464)
Loss: 2.653 | Acc: 15.532% (1998/12864)
Loss: 2.466 | Acc: 17.525% (3376/19264)
Loss: 2.357 | Acc: 19.031% (4884/25664)
Loss: 2.283 | Acc: 20.631% (6615/32064)
Loss: 2.228 | Acc: 21.930% (8435/38464)
Loss: 2.178 | Acc: 23.235% (10424/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0117, Accuracy: 3056/10000 (30.56%)

Epoch: 1
Loss: 2.111 | Acc: 25.000% (16/64)
Loss: 1.827 | Acc: 33.230% (2148/6464)
Loss: 1.819 | Acc: 34.134% (4391/12864)
Loss: 1.805 | Acc: 34.697% (6684/19264)
Loss: 1.797 | Acc: 35.256% (9048/25664)
Loss: 1.786 | Acc: 35.760% (11466/32064)
Loss: 1.775 | Acc: 36.348% (13981/38464)
Loss: 1.763 | Acc: 36.994% (16597/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9114, Accuracy: 3617/10000 (36.17%)

Epoch: 2
Loss: 1.466 | Acc: 59.375% (38/64)
Loss: 1.641 | Acc: 42.961% (2777/6464)
Loss: 1.643 | Acc: 42.685% (5491/12864)
Loss: 1.630 | Acc: 43.464% (8373/19264)
Loss: 1.617 | Acc: 43.984% (11288/25664)
Loss: 1.605 | Acc: 44.664% (14321/32064)
Loss: 1.598 | Acc: 45.094% (17345/38464)
Loss: 1.590 | Acc: 45.451% (20391/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6416, Accuracy: 4411/10000 (44.11%)

Epoch: 3
Loss: 1.656 | Acc: 48.438% (31/64)
Loss: 1.497 | Acc: 49.845% (3222/6464)
Loss: 1.504 | Acc: 49.689% (6392/12864)
Loss: 1.483 | Acc: 50.545% (9737/19264)
Loss: 1.468 | Acc: 51.161% (13130/25664)
Loss: 1.455 | Acc: 51.740% (16590/32064)
Loss: 1.442 | Acc: 52.303% (20118/38464)
Loss: 1.432 | Acc: 52.808% (23692/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7471, Accuracy: 4436/10000 (44.36%)

Epoch: 4
Loss: 1.670 | Acc: 48.438% (31/64)
Loss: 1.352 | Acc: 57.689% (3729/6464)
Loss: 1.332 | Acc: 57.828% (7439/12864)
Loss: 1.322 | Acc: 57.911% (11156/19264)
Loss: 1.314 | Acc: 58.140% (14921/25664)
Loss: 1.308 | Acc: 58.268% (18683/32064)
Loss: 1.298 | Acc: 58.642% (22556/38464)
Loss: 1.293 | Acc: 58.969% (26456/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3919, Accuracy: 5654/10000 (56.54%)

Epoch: 5
Loss: 1.446 | Acc: 57.812% (37/64)
Loss: 1.200 | Acc: 62.330% (4029/6464)
Loss: 1.215 | Acc: 62.197% (8001/12864)
Loss: 1.208 | Acc: 62.775% (12093/19264)
Loss: 1.206 | Acc: 62.792% (16115/25664)
Loss: 1.196 | Acc: 63.227% (20273/32064)
Loss: 1.192 | Acc: 63.413% (24391/38464)
Loss: 1.186 | Acc: 63.666% (28563/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4241, Accuracy: 5596/10000 (55.96%)

Epoch: 6
Loss: 1.287 | Acc: 67.188% (43/64)
Loss: 1.121 | Acc: 66.553% (4302/6464)
Loss: 1.127 | Acc: 66.208% (8517/12864)
Loss: 1.116 | Acc: 66.601% (12830/19264)
Loss: 1.111 | Acc: 66.864% (17160/25664)
Loss: 1.103 | Acc: 67.003% (21484/32064)
Loss: 1.104 | Acc: 67.016% (25777/38464)
Loss: 1.102 | Acc: 67.154% (30128/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5383, Accuracy: 5133/10000 (51.33%)

Epoch: 7
Loss: 1.209 | Acc: 60.938% (39/64)
Loss: 1.056 | Acc: 69.152% (4470/6464)
Loss: 1.061 | Acc: 68.882% (8861/12864)
Loss: 1.066 | Acc: 68.973% (13287/19264)
Loss: 1.060 | Acc: 69.183% (17755/25664)
Loss: 1.052 | Acc: 69.470% (22275/32064)
Loss: 1.054 | Acc: 69.491% (26729/38464)
Loss: 1.047 | Acc: 69.599% (31225/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1707, Accuracy: 6477/10000 (64.77%)

Epoch: 8
Loss: 1.104 | Acc: 68.750% (44/64)
Loss: 1.019 | Acc: 70.869% (4581/6464)
Loss: 1.018 | Acc: 70.639% (9087/12864)
Loss: 1.018 | Acc: 70.749% (13629/19264)
Loss: 1.014 | Acc: 70.928% (18203/25664)
Loss: 1.010 | Acc: 71.030% (22775/32064)
Loss: 1.011 | Acc: 70.931% (27283/38464)
Loss: 1.007 | Acc: 71.053% (31877/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1433, Accuracy: 6694/10000 (66.94%)

Epoch: 9
Loss: 1.156 | Acc: 67.188% (43/64)
Loss: 0.970 | Acc: 72.184% (4666/6464)
Loss: 0.989 | Acc: 71.813% (9238/12864)
Loss: 0.988 | Acc: 71.911% (13853/19264)
Loss: 0.984 | Acc: 71.859% (18442/25664)
Loss: 0.988 | Acc: 71.800% (23022/32064)
Loss: 0.986 | Acc: 71.846% (27635/38464)
Loss: 0.982 | Acc: 72.038% (32319/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2707, Accuracy: 6027/10000 (60.27%)

Epoch: 10
Loss: 0.941 | Acc: 73.438% (47/64)
Loss: 0.971 | Acc: 72.912% (4713/6464)
Loss: 0.959 | Acc: 73.298% (9429/12864)
Loss: 0.964 | Acc: 72.732% (14011/19264)
Loss: 0.956 | Acc: 72.950% (18722/25664)
Loss: 0.961 | Acc: 72.926% (23383/32064)
Loss: 0.961 | Acc: 72.944% (28057/38464)
Loss: 0.962 | Acc: 72.940% (32724/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0101, Accuracy: 7188/10000 (71.88%)

Epoch: 11
Loss: 1.021 | Acc: 68.750% (44/64)
Loss: 0.947 | Acc: 73.267% (4736/6464)
Loss: 0.951 | Acc: 73.414% (9444/12864)
Loss: 0.937 | Acc: 74.024% (14260/19264)
Loss: 0.939 | Acc: 73.851% (18953/25664)
Loss: 0.941 | Acc: 73.740% (23644/32064)
Loss: 0.942 | Acc: 73.781% (28379/38464)
Loss: 0.945 | Acc: 73.723% (33075/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1436, Accuracy: 6714/10000 (67.14%)

Epoch: 12
Loss: 0.869 | Acc: 73.438% (47/64)
Loss: 0.920 | Acc: 74.366% (4807/6464)
Loss: 0.918 | Acc: 74.627% (9600/12864)
Loss: 0.921 | Acc: 74.528% (14357/19264)
Loss: 0.920 | Acc: 74.532% (19128/25664)
Loss: 0.921 | Acc: 74.604% (23921/32064)
Loss: 0.921 | Acc: 74.579% (28686/38464)
Loss: 0.925 | Acc: 74.472% (33411/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2666, Accuracy: 6230/10000 (62.30%)

Epoch: 13
Loss: 1.206 | Acc: 60.938% (39/64)
Loss: 0.910 | Acc: 75.696% (4893/6464)
Loss: 0.908 | Acc: 75.459% (9707/12864)
Loss: 0.912 | Acc: 75.254% (14497/19264)
Loss: 0.913 | Acc: 75.253% (19313/25664)
Loss: 0.906 | Acc: 75.458% (24195/32064)
Loss: 0.906 | Acc: 75.406% (29004/38464)
Loss: 0.907 | Acc: 75.421% (33837/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5610, Accuracy: 5531/10000 (55.31%)

Epoch: 14
Loss: 1.077 | Acc: 68.750% (44/64)
Loss: 0.931 | Acc: 74.211% (4797/6464)
Loss: 0.916 | Acc: 74.456% (9578/12864)
Loss: 0.901 | Acc: 75.083% (14464/19264)
Loss: 0.896 | Acc: 75.409% (19353/25664)
Loss: 0.895 | Acc: 75.533% (24219/32064)
Loss: 0.891 | Acc: 75.650% (29098/38464)
Loss: 0.893 | Acc: 75.642% (33936/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3703, Accuracy: 6010/10000 (60.10%)

Epoch: 15
Loss: 1.087 | Acc: 65.625% (42/64)
Loss: 0.863 | Acc: 76.037% (4915/6464)
Loss: 0.868 | Acc: 76.298% (9815/12864)
Loss: 0.882 | Acc: 75.748% (14592/19264)
Loss: 0.877 | Acc: 75.966% (19496/25664)
Loss: 0.877 | Acc: 75.982% (24363/32064)
Loss: 0.878 | Acc: 75.962% (29218/38464)
Loss: 0.876 | Acc: 76.014% (34103/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2061, Accuracy: 6560/10000 (65.60%)

Epoch: 16
Loss: 0.922 | Acc: 76.562% (49/64)
Loss: 0.848 | Acc: 77.444% (5006/6464)
Loss: 0.844 | Acc: 77.433% (9961/12864)
Loss: 0.844 | Acc: 77.471% (14924/19264)
Loss: 0.853 | Acc: 77.155% (19801/25664)
Loss: 0.854 | Acc: 77.127% (24730/32064)
Loss: 0.858 | Acc: 77.062% (29641/38464)
Loss: 0.856 | Acc: 77.042% (34564/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6056, Accuracy: 5468/10000 (54.68%)

Epoch: 17
Loss: 0.978 | Acc: 71.875% (46/64)
Loss: 0.831 | Acc: 78.202% (5055/6464)
Loss: 0.852 | Acc: 77.565% (9978/12864)
Loss: 0.854 | Acc: 77.315% (14894/19264)
Loss: 0.850 | Acc: 77.474% (19883/25664)
Loss: 0.848 | Acc: 77.539% (24862/32064)
Loss: 0.849 | Acc: 77.522% (29818/38464)
Loss: 0.845 | Acc: 77.630% (34828/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3378, Accuracy: 6352/10000 (63.52%)

Epoch: 18
Loss: 0.787 | Acc: 78.125% (50/64)
Loss: 0.812 | Acc: 78.481% (5073/6464)
Loss: 0.817 | Acc: 78.397% (10085/12864)
Loss: 0.829 | Acc: 78.078% (15041/19264)
Loss: 0.832 | Acc: 77.993% (20016/25664)
Loss: 0.831 | Acc: 78.000% (25010/32064)
Loss: 0.832 | Acc: 77.883% (29957/38464)
Loss: 0.833 | Acc: 77.811% (34909/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9793, Accuracy: 7305/10000 (73.05%)

Epoch: 19
Loss: 1.156 | Acc: 68.750% (44/64)
Loss: 0.827 | Acc: 78.187% (5054/6464)
Loss: 0.820 | Acc: 78.514% (10100/12864)
Loss: 0.811 | Acc: 78.732% (15167/19264)
Loss: 0.812 | Acc: 78.678% (20192/25664)
Loss: 0.816 | Acc: 78.509% (25173/32064)
Loss: 0.816 | Acc: 78.541% (30210/38464)
Loss: 0.817 | Acc: 78.502% (35219/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2645, Accuracy: 6303/10000 (63.03%)

Epoch: 20
Loss: 0.720 | Acc: 81.250% (52/64)
Loss: 0.799 | Acc: 78.914% (5101/6464)
Loss: 0.805 | Acc: 78.739% (10129/12864)
Loss: 0.805 | Acc: 78.613% (15144/19264)
Loss: 0.806 | Acc: 78.635% (20181/25664)
Loss: 0.802 | Acc: 78.755% (25252/32064)
Loss: 0.806 | Acc: 78.681% (30264/38464)
Loss: 0.807 | Acc: 78.725% (35319/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7638, Accuracy: 4906/10000 (49.06%)

Epoch: 21
Loss: 0.810 | Acc: 79.688% (51/64)
Loss: 0.798 | Acc: 79.007% (5107/6464)
Loss: 0.793 | Acc: 79.190% (10187/12864)
Loss: 0.787 | Acc: 79.402% (15296/19264)
Loss: 0.798 | Acc: 79.126% (20307/25664)
Loss: 0.795 | Acc: 79.323% (25434/32064)
Loss: 0.793 | Acc: 79.368% (30528/38464)
Loss: 0.793 | Acc: 79.384% (35615/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1924, Accuracy: 6624/10000 (66.24%)

Epoch: 22
Loss: 0.751 | Acc: 78.125% (50/64)
Loss: 0.779 | Acc: 80.523% (5205/6464)
Loss: 0.788 | Acc: 80.014% (10293/12864)
Loss: 0.779 | Acc: 80.056% (15422/19264)
Loss: 0.787 | Acc: 79.781% (20475/25664)
Loss: 0.778 | Acc: 79.928% (25628/32064)
Loss: 0.776 | Acc: 79.997% (30770/38464)
Loss: 0.776 | Acc: 79.997% (35890/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2089, Accuracy: 6621/10000 (66.21%)

Epoch: 23
Loss: 0.811 | Acc: 78.125% (50/64)
Loss: 0.731 | Acc: 81.281% (5254/6464)
Loss: 0.758 | Acc: 80.434% (10347/12864)
Loss: 0.763 | Acc: 80.430% (15494/19264)
Loss: 0.760 | Acc: 80.494% (20658/25664)
Loss: 0.763 | Acc: 80.361% (25767/32064)
Loss: 0.764 | Acc: 80.332% (30899/38464)
Loss: 0.762 | Acc: 80.367% (36056/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2113, Accuracy: 6515/10000 (65.15%)

Epoch: 24
Loss: 0.845 | Acc: 79.688% (51/64)
Loss: 0.748 | Acc: 80.817% (5224/6464)
Loss: 0.764 | Acc: 80.395% (10342/12864)
Loss: 0.761 | Acc: 80.502% (15508/19264)
Loss: 0.762 | Acc: 80.584% (20681/25664)
Loss: 0.757 | Acc: 80.632% (25854/32064)
Loss: 0.757 | Acc: 80.582% (30995/38464)
Loss: 0.758 | Acc: 80.586% (36154/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1045, Accuracy: 6964/10000 (69.64%)

Epoch: 25
Loss: 0.835 | Acc: 76.562% (49/64)
Loss: 0.749 | Acc: 80.910% (5230/6464)
Loss: 0.752 | Acc: 81.056% (10427/12864)
Loss: 0.741 | Acc: 81.292% (15660/19264)
Loss: 0.738 | Acc: 81.375% (20884/25664)
Loss: 0.737 | Acc: 81.609% (26167/32064)
Loss: 0.740 | Acc: 81.494% (31346/38464)
Loss: 0.741 | Acc: 81.395% (36517/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0738, Accuracy: 6980/10000 (69.80%)

Epoch: 26
Loss: 0.670 | Acc: 82.812% (53/64)
Loss: 0.745 | Acc: 81.235% (5251/6464)
Loss: 0.737 | Acc: 81.382% (10469/12864)
Loss: 0.730 | Acc: 81.432% (15687/19264)
Loss: 0.738 | Acc: 81.285% (20861/25664)
Loss: 0.737 | Acc: 81.372% (26091/32064)
Loss: 0.732 | Acc: 81.575% (31377/38464)
Loss: 0.730 | Acc: 81.598% (36608/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3764, Accuracy: 6271/10000 (62.71%)

Epoch: 27
Loss: 0.802 | Acc: 75.000% (48/64)
Loss: 0.751 | Acc: 81.064% (5240/6464)
Loss: 0.720 | Acc: 81.965% (10544/12864)
Loss: 0.717 | Acc: 82.091% (15814/19264)
Loss: 0.714 | Acc: 82.080% (21065/25664)
Loss: 0.709 | Acc: 82.270% (26379/32064)
Loss: 0.710 | Acc: 82.243% (31634/38464)
Loss: 0.713 | Acc: 82.184% (36871/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9248, Accuracy: 7557/10000 (75.57%)

Epoch: 28
Loss: 0.981 | Acc: 75.000% (48/64)
Loss: 0.682 | Acc: 83.400% (5391/6464)
Loss: 0.700 | Acc: 82.906% (10665/12864)
Loss: 0.691 | Acc: 82.989% (15987/19264)
Loss: 0.693 | Acc: 82.890% (21273/25664)
Loss: 0.693 | Acc: 82.850% (26565/32064)
Loss: 0.699 | Acc: 82.677% (31801/38464)
Loss: 0.699 | Acc: 82.694% (37100/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0929, Accuracy: 6885/10000 (68.85%)

Epoch: 29
Loss: 0.627 | Acc: 84.375% (54/64)
Loss: 0.656 | Acc: 83.555% (5401/6464)
Loss: 0.665 | Acc: 83.691% (10766/12864)
Loss: 0.667 | Acc: 83.570% (16099/19264)
Loss: 0.676 | Acc: 83.420% (21409/25664)
Loss: 0.676 | Acc: 83.374% (26733/32064)
Loss: 0.678 | Acc: 83.369% (32067/38464)
Loss: 0.678 | Acc: 83.359% (37398/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8228, Accuracy: 7884/10000 (78.84%)

Epoch: 30
Loss: 1.007 | Acc: 78.125% (50/64)
Loss: 0.644 | Acc: 84.978% (5493/6464)
Loss: 0.660 | Acc: 84.212% (10833/12864)
Loss: 0.659 | Acc: 84.126% (16206/19264)
Loss: 0.657 | Acc: 83.993% (21556/25664)
Loss: 0.667 | Acc: 83.704% (26839/32064)
Loss: 0.669 | Acc: 83.631% (32168/38464)
Loss: 0.671 | Acc: 83.588% (37501/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8794, Accuracy: 7741/10000 (77.41%)

Epoch: 31
Loss: 0.426 | Acc: 89.062% (57/64)
Loss: 0.623 | Acc: 85.040% (5497/6464)
Loss: 0.641 | Acc: 84.686% (10894/12864)
Loss: 0.647 | Acc: 84.531% (16284/19264)
Loss: 0.649 | Acc: 84.356% (21649/25664)
Loss: 0.653 | Acc: 84.260% (27017/32064)
Loss: 0.652 | Acc: 84.268% (32413/38464)
Loss: 0.656 | Acc: 84.108% (37734/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8421, Accuracy: 7874/10000 (78.74%)

Epoch: 32
Loss: 0.818 | Acc: 84.375% (54/64)
Loss: 0.632 | Acc: 85.195% (5507/6464)
Loss: 0.636 | Acc: 84.834% (10913/12864)
Loss: 0.636 | Acc: 84.723% (16321/19264)
Loss: 0.630 | Acc: 84.808% (21765/25664)
Loss: 0.629 | Acc: 84.865% (27211/32064)
Loss: 0.632 | Acc: 84.843% (32634/38464)
Loss: 0.630 | Acc: 84.946% (38110/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8457, Accuracy: 7837/10000 (78.37%)

Epoch: 33
Loss: 0.482 | Acc: 87.500% (56/64)
Loss: 0.574 | Acc: 86.340% (5581/6464)
Loss: 0.601 | Acc: 85.533% (11003/12864)
Loss: 0.602 | Acc: 85.429% (16457/19264)
Loss: 0.611 | Acc: 85.197% (21865/25664)
Loss: 0.605 | Acc: 85.354% (27368/32064)
Loss: 0.611 | Acc: 85.225% (32781/38464)
Loss: 0.611 | Acc: 85.260% (38251/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0017, Accuracy: 7284/10000 (72.84%)

Epoch: 34
Loss: 0.791 | Acc: 82.812% (53/64)
Loss: 0.578 | Acc: 86.216% (5573/6464)
Loss: 0.577 | Acc: 86.256% (11096/12864)
Loss: 0.582 | Acc: 86.140% (16594/19264)
Loss: 0.588 | Acc: 85.875% (22039/25664)
Loss: 0.593 | Acc: 85.807% (27513/32064)
Loss: 0.592 | Acc: 85.922% (33049/38464)
Loss: 0.596 | Acc: 85.777% (38483/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8410, Accuracy: 7912/10000 (79.12%)

Epoch: 35
Loss: 0.535 | Acc: 90.625% (58/64)
Loss: 0.543 | Acc: 87.160% (5634/6464)
Loss: 0.567 | Acc: 86.536% (11132/12864)
Loss: 0.570 | Acc: 86.509% (16665/19264)
Loss: 0.568 | Acc: 86.545% (22211/25664)
Loss: 0.568 | Acc: 86.608% (27770/32064)
Loss: 0.572 | Acc: 86.483% (33265/38464)
Loss: 0.574 | Acc: 86.443% (38782/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8095, Accuracy: 8054/10000 (80.54%)

Epoch: 36
Loss: 0.511 | Acc: 85.938% (55/64)
Loss: 0.538 | Acc: 86.974% (5622/6464)
Loss: 0.553 | Acc: 86.777% (11163/12864)
Loss: 0.551 | Acc: 86.825% (16726/19264)
Loss: 0.552 | Acc: 86.760% (22266/25664)
Loss: 0.553 | Acc: 86.773% (27823/32064)
Loss: 0.556 | Acc: 86.749% (33367/38464)
Loss: 0.557 | Acc: 86.760% (38924/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8801, Accuracy: 7835/10000 (78.35%)

Epoch: 37
Loss: 0.554 | Acc: 84.375% (54/64)
Loss: 0.516 | Acc: 87.871% (5680/6464)
Loss: 0.513 | Acc: 88.029% (11324/12864)
Loss: 0.513 | Acc: 87.972% (16947/19264)
Loss: 0.512 | Acc: 87.991% (22582/25664)
Loss: 0.521 | Acc: 87.693% (28118/32064)
Loss: 0.524 | Acc: 87.591% (33691/38464)
Loss: 0.529 | Acc: 87.444% (39231/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8401, Accuracy: 8005/10000 (80.05%)

Epoch: 38
Loss: 0.726 | Acc: 82.812% (53/64)
Loss: 0.502 | Acc: 87.995% (5688/6464)
Loss: 0.501 | Acc: 88.099% (11333/12864)
Loss: 0.501 | Acc: 88.138% (16979/19264)
Loss: 0.499 | Acc: 88.244% (22647/25664)
Loss: 0.503 | Acc: 88.205% (28282/32064)
Loss: 0.503 | Acc: 88.194% (33923/38464)
Loss: 0.502 | Acc: 88.244% (39590/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8396, Accuracy: 8022/10000 (80.22%)

Epoch: 39
Loss: 0.370 | Acc: 92.188% (59/64)
Loss: 0.456 | Acc: 89.341% (5775/6464)
Loss: 0.457 | Acc: 89.241% (11480/12864)
Loss: 0.461 | Acc: 89.223% (17188/19264)
Loss: 0.459 | Acc: 89.242% (22903/25664)
Loss: 0.465 | Acc: 89.087% (28565/32064)
Loss: 0.467 | Acc: 88.985% (34227/38464)
Loss: 0.472 | Acc: 88.813% (39845/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8591, Accuracy: 8013/10000 (80.13%)

Epoch: 40
Loss: 0.294 | Acc: 93.750% (60/64)
Loss: 0.438 | Acc: 89.496% (5785/6464)
Loss: 0.427 | Acc: 89.832% (11556/12864)
Loss: 0.437 | Acc: 89.592% (17259/19264)
Loss: 0.446 | Acc: 89.296% (22917/25664)
Loss: 0.444 | Acc: 89.396% (28664/32064)
Loss: 0.443 | Acc: 89.411% (34391/38464)
Loss: 0.445 | Acc: 89.348% (40085/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9758, Accuracy: 7667/10000 (76.67%)

Epoch: 41
Loss: 0.768 | Acc: 79.688% (51/64)
Loss: 0.392 | Acc: 90.656% (5860/6464)
Loss: 0.416 | Acc: 90.104% (11591/12864)
Loss: 0.411 | Acc: 90.288% (17393/19264)
Loss: 0.412 | Acc: 90.228% (23156/25664)
Loss: 0.410 | Acc: 90.245% (28936/32064)
Loss: 0.411 | Acc: 90.196% (34693/38464)
Loss: 0.412 | Acc: 90.201% (40468/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8802, Accuracy: 8096/10000 (80.96%)

Epoch: 42
Loss: 0.353 | Acc: 93.750% (60/64)
Loss: 0.362 | Acc: 91.383% (5907/6464)
Loss: 0.377 | Acc: 90.757% (11675/12864)
Loss: 0.377 | Acc: 90.833% (17498/19264)
Loss: 0.381 | Acc: 90.672% (23270/25664)
Loss: 0.381 | Acc: 90.694% (29080/32064)
Loss: 0.380 | Acc: 90.747% (34905/38464)
Loss: 0.378 | Acc: 90.826% (40748/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8977, Accuracy: 8105/10000 (81.05%)

Epoch: 43
Loss: 0.275 | Acc: 92.188% (59/64)
Loss: 0.336 | Acc: 91.337% (5904/6464)
Loss: 0.340 | Acc: 91.441% (11763/12864)
Loss: 0.337 | Acc: 91.570% (17640/19264)
Loss: 0.335 | Acc: 91.673% (23527/25664)
Loss: 0.334 | Acc: 91.695% (29401/32064)
Loss: 0.336 | Acc: 91.642% (35249/38464)
Loss: 0.336 | Acc: 91.606% (41098/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9062, Accuracy: 8123/10000 (81.23%)

Epoch: 44
Loss: 0.225 | Acc: 96.875% (62/64)
Loss: 0.297 | Acc: 92.512% (5980/6464)
Loss: 0.312 | Acc: 92.048% (11841/12864)
Loss: 0.308 | Acc: 92.151% (17752/19264)
Loss: 0.312 | Acc: 92.129% (23644/25664)
Loss: 0.314 | Acc: 92.125% (29539/32064)
Loss: 0.310 | Acc: 92.229% (35475/38464)
Loss: 0.308 | Acc: 92.301% (41410/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9039, Accuracy: 8175/10000 (81.75%)

Epoch: 45
Loss: 0.466 | Acc: 89.062% (57/64)
Loss: 0.291 | Acc: 92.636% (5988/6464)
Loss: 0.306 | Acc: 92.234% (11865/12864)
Loss: 0.313 | Acc: 92.058% (17734/19264)
Loss: 0.327 | Acc: 91.786% (23556/25664)
Loss: 0.334 | Acc: 91.745% (29417/32064)
Loss: 0.340 | Acc: 91.686% (35266/38464)
Loss: 0.348 | Acc: 91.570% (41082/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8100, Accuracy: 8164/10000 (81.64%)

Epoch: 46
Loss: 0.347 | Acc: 87.500% (56/64)
Loss: 0.428 | Acc: 89.496% (5785/6464)
Loss: 0.424 | Acc: 89.723% (11542/12864)
Loss: 0.421 | Acc: 89.805% (17300/19264)
Loss: 0.423 | Acc: 89.853% (23060/25664)
Loss: 0.422 | Acc: 89.905% (28827/32064)
Loss: 0.425 | Acc: 89.876% (34570/38464)
Loss: 0.426 | Acc: 89.910% (40337/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7909, Accuracy: 8171/10000 (81.71%)

Epoch: 47
Loss: 0.185 | Acc: 96.875% (62/64)
Loss: 0.443 | Acc: 89.790% (5804/6464)
Loss: 0.441 | Acc: 89.677% (11536/12864)
Loss: 0.446 | Acc: 89.566% (17254/19264)
Loss: 0.448 | Acc: 89.526% (22976/25664)
Loss: 0.456 | Acc: 89.328% (28642/32064)
Loss: 0.456 | Acc: 89.307% (34351/38464)
Loss: 0.456 | Acc: 89.310% (40068/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7918, Accuracy: 8147/10000 (81.47%)
torch.Size([100, 10])
Test set: Average loss: 0.7918, Accuracy: 8147/10000 (81.47%)

Epoch: 48
Loss: 0.586 | Acc: 89.062% (57/64)
Loss: 0.469 | Acc: 89.016% (5754/6464)
Loss: 0.461 | Acc: 89.179% (11472/12864)
Loss: 0.464 | Acc: 89.208% (17185/19264)
Loss: 0.466 | Acc: 89.187% (22889/25664)
Loss: 0.464 | Acc: 89.312% (28637/32064)
Loss: 0.466 | Acc: 89.237% (34324/38464)
Loss: 0.464 | Acc: 89.272% (40051/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7874, Accuracy: 8164/10000 (81.64%)
torch.Size([100, 10])
Test set: Average loss: 0.7874, Accuracy: 8164/10000 (81.64%)

Epoch: 49
Loss: 0.593 | Acc: 84.375% (54/64)
Loss: 0.463 | Acc: 89.310% (5773/6464)
Loss: 0.473 | Acc: 88.860% (11431/12864)
Loss: 0.471 | Acc: 88.912% (17128/19264)
Loss: 0.471 | Acc: 88.918% (22820/25664)
Loss: 0.471 | Acc: 88.941% (28518/32064)
Loss: 0.469 | Acc: 89.005% (34235/38464)
Loss: 0.469 | Acc: 88.960% (39911/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7904, Accuracy: 8151/10000 (81.51%)
torch.Size([100, 10])
Test set: Average loss: 0.7904, Accuracy: 8151/10000 (81.51%)

Epoch: 50
Loss: 0.442 | Acc: 93.750% (60/64)
Loss: 1.446 | Acc: 53.465% (3456/6464)
Loss: 1.254 | Acc: 61.171% (7869/12864)
Loss: 1.162 | Acc: 64.706% (12465/19264)
Loss: 1.122 | Acc: 66.572% (17085/25664)
Loss: 1.087 | Acc: 67.992% (21801/32064)
Loss: 1.062 | Acc: 69.049% (26559/38464)
Loss: 1.043 | Acc: 69.818% (31323/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1254, Accuracy: 4107/10000 (41.07%)

Epoch: 51
Loss: 0.917 | Acc: 73.438% (47/64)
Loss: 0.884 | Acc: 76.191% (4925/6464)
Loss: 0.890 | Acc: 76.018% (9779/12864)
Loss: 0.892 | Acc: 75.903% (14622/19264)
Loss: 0.890 | Acc: 75.970% (19497/25664)
Loss: 0.886 | Acc: 76.088% (24397/32064)
Loss: 0.879 | Acc: 76.313% (29353/38464)
Loss: 0.877 | Acc: 76.406% (34279/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3156, Accuracy: 6264/10000 (62.64%)

Epoch: 52
Loss: 0.803 | Acc: 78.125% (50/64)
Loss: 0.861 | Acc: 77.336% (4999/6464)
Loss: 0.847 | Acc: 77.534% (9974/12864)
Loss: 0.842 | Acc: 77.730% (14974/19264)
Loss: 0.840 | Acc: 77.708% (19943/25664)
Loss: 0.841 | Acc: 77.688% (24910/32064)
Loss: 0.840 | Acc: 77.704% (29888/38464)
Loss: 0.845 | Acc: 77.563% (34798/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1335, Accuracy: 6820/10000 (68.20%)

Epoch: 53
Loss: 1.157 | Acc: 68.750% (44/64)
Loss: 0.804 | Acc: 78.821% (5095/6464)
Loss: 0.820 | Acc: 78.444% (10091/12864)
Loss: 0.833 | Acc: 78.042% (15034/19264)
Loss: 0.833 | Acc: 77.942% (20003/25664)
Loss: 0.836 | Acc: 77.854% (24963/32064)
Loss: 0.831 | Acc: 77.977% (29993/38464)
Loss: 0.831 | Acc: 78.011% (34999/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2745, Accuracy: 6347/10000 (63.47%)

Epoch: 54
Loss: 0.611 | Acc: 84.375% (54/64)
Loss: 0.787 | Acc: 78.790% (5093/6464)
Loss: 0.815 | Acc: 78.257% (10067/12864)
Loss: 0.815 | Acc: 78.421% (15107/19264)
Loss: 0.822 | Acc: 78.289% (20092/25664)
Loss: 0.825 | Acc: 78.075% (25034/32064)
Loss: 0.827 | Acc: 78.005% (30004/38464)
Loss: 0.829 | Acc: 77.976% (34983/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5812, Accuracy: 5285/10000 (52.85%)

Epoch: 55
Loss: 0.966 | Acc: 75.000% (48/64)
Loss: 0.809 | Acc: 78.419% (5069/6464)
Loss: 0.808 | Acc: 78.817% (10139/12864)
Loss: 0.814 | Acc: 78.701% (15161/19264)
Loss: 0.817 | Acc: 78.577% (20166/25664)
Loss: 0.816 | Acc: 78.546% (25185/32064)
Loss: 0.818 | Acc: 78.523% (30203/38464)
Loss: 0.820 | Acc: 78.473% (35206/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2697, Accuracy: 6399/10000 (63.99%)

Epoch: 56
Loss: 1.163 | Acc: 71.875% (46/64)
Loss: 0.822 | Acc: 78.666% (5085/6464)
Loss: 0.818 | Acc: 78.568% (10107/12864)
Loss: 0.810 | Acc: 78.821% (15184/19264)
Loss: 0.807 | Acc: 78.865% (20240/25664)
Loss: 0.812 | Acc: 78.777% (25259/32064)
Loss: 0.815 | Acc: 78.635% (30246/38464)
Loss: 0.816 | Acc: 78.649% (35285/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0726, Accuracy: 7026/10000 (70.26%)

Epoch: 57
Loss: 0.964 | Acc: 68.750% (44/64)
Loss: 0.815 | Acc: 78.048% (5045/6464)
Loss: 0.814 | Acc: 78.343% (10078/12864)
Loss: 0.805 | Acc: 78.857% (15191/19264)
Loss: 0.815 | Acc: 78.530% (20154/25664)
Loss: 0.813 | Acc: 78.661% (25222/32064)
Loss: 0.818 | Acc: 78.525% (30204/38464)
Loss: 0.812 | Acc: 78.676% (35297/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4368, Accuracy: 5893/10000 (58.93%)

Epoch: 58
Loss: 0.994 | Acc: 68.750% (44/64)
Loss: 0.810 | Acc: 78.512% (5075/6464)
Loss: 0.813 | Acc: 78.677% (10121/12864)
Loss: 0.808 | Acc: 78.815% (15183/19264)
Loss: 0.810 | Acc: 78.893% (20247/25664)
Loss: 0.808 | Acc: 79.026% (25339/32064)
Loss: 0.810 | Acc: 78.923% (30357/38464)
Loss: 0.811 | Acc: 78.903% (35399/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1030, Accuracy: 6997/10000 (69.97%)

Epoch: 59
Loss: 0.593 | Acc: 85.938% (55/64)
Loss: 0.808 | Acc: 79.316% (5127/6464)
Loss: 0.801 | Acc: 79.314% (10203/12864)
Loss: 0.802 | Acc: 79.220% (15261/19264)
Loss: 0.801 | Acc: 79.138% (20310/25664)
Loss: 0.802 | Acc: 79.101% (25363/32064)
Loss: 0.801 | Acc: 79.040% (30402/38464)
Loss: 0.805 | Acc: 78.970% (35429/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1726, Accuracy: 6650/10000 (66.50%)

Epoch: 60
Loss: 0.848 | Acc: 78.125% (50/64)
Loss: 0.803 | Acc: 79.409% (5133/6464)
Loss: 0.792 | Acc: 79.423% (10217/12864)
Loss: 0.805 | Acc: 79.018% (15222/19264)
Loss: 0.806 | Acc: 79.099% (20300/25664)
Loss: 0.798 | Acc: 79.329% (25436/32064)
Loss: 0.798 | Acc: 79.300% (30502/38464)
Loss: 0.798 | Acc: 79.317% (35585/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4029, Accuracy: 6023/10000 (60.23%)

Epoch: 61
Loss: 0.937 | Acc: 73.438% (47/64)
Loss: 0.781 | Acc: 79.718% (5153/6464)
Loss: 0.781 | Acc: 79.656% (10247/12864)
Loss: 0.785 | Acc: 79.636% (15341/19264)
Loss: 0.792 | Acc: 79.516% (20407/25664)
Loss: 0.795 | Acc: 79.460% (25478/32064)
Loss: 0.798 | Acc: 79.428% (30551/38464)
Loss: 0.796 | Acc: 79.480% (35658/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4547, Accuracy: 5832/10000 (58.32%)

Epoch: 62
Loss: 0.973 | Acc: 78.125% (50/64)
Loss: 0.787 | Acc: 79.920% (5166/6464)
Loss: 0.780 | Acc: 79.936% (10283/12864)
Loss: 0.788 | Acc: 79.708% (15355/19264)
Loss: 0.787 | Acc: 79.758% (20469/25664)
Loss: 0.787 | Acc: 79.675% (25547/32064)
Loss: 0.787 | Acc: 79.636% (30631/38464)
Loss: 0.789 | Acc: 79.592% (35708/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9464, Accuracy: 7461/10000 (74.61%)

Epoch: 63
Loss: 0.473 | Acc: 85.938% (55/64)
Loss: 0.773 | Acc: 79.873% (5163/6464)
Loss: 0.775 | Acc: 80.022% (10294/12864)
Loss: 0.773 | Acc: 80.284% (15466/19264)
Loss: 0.773 | Acc: 80.182% (20578/25664)
Loss: 0.773 | Acc: 80.252% (25732/32064)
Loss: 0.779 | Acc: 80.054% (30792/38464)
Loss: 0.779 | Acc: 80.055% (35916/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9735, Accuracy: 7450/10000 (74.50%)

Epoch: 64
Loss: 0.888 | Acc: 76.562% (49/64)
Loss: 0.781 | Acc: 79.780% (5157/6464)
Loss: 0.775 | Acc: 80.107% (10305/12864)
Loss: 0.766 | Acc: 80.196% (15449/19264)
Loss: 0.772 | Acc: 80.015% (20535/25664)
Loss: 0.772 | Acc: 80.065% (25672/32064)
Loss: 0.773 | Acc: 80.085% (30804/38464)
Loss: 0.775 | Acc: 79.997% (35890/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0995, Accuracy: 6936/10000 (69.36%)

Epoch: 65
Loss: 0.610 | Acc: 84.375% (54/64)
Loss: 0.750 | Acc: 80.832% (5225/6464)
Loss: 0.756 | Acc: 80.784% (10392/12864)
Loss: 0.762 | Acc: 80.497% (15507/19264)
Loss: 0.762 | Acc: 80.397% (20633/25664)
Loss: 0.769 | Acc: 80.211% (25719/32064)
Loss: 0.767 | Acc: 80.306% (30889/38464)
Loss: 0.768 | Acc: 80.309% (36030/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0290, Accuracy: 7215/10000 (72.15%)

Epoch: 66
Loss: 0.760 | Acc: 84.375% (54/64)
Loss: 0.732 | Acc: 81.714% (5282/6464)
Loss: 0.757 | Acc: 80.846% (10400/12864)
Loss: 0.758 | Acc: 80.586% (15524/19264)
Loss: 0.764 | Acc: 80.397% (20633/25664)
Loss: 0.760 | Acc: 80.436% (25791/32064)
Loss: 0.763 | Acc: 80.363% (30911/38464)
Loss: 0.760 | Acc: 80.468% (36101/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0822, Accuracy: 6907/10000 (69.07%)

Epoch: 67
Loss: 0.843 | Acc: 79.688% (51/64)
Loss: 0.751 | Acc: 81.265% (5253/6464)
Loss: 0.737 | Acc: 81.740% (10515/12864)
Loss: 0.735 | Acc: 81.878% (15773/19264)
Loss: 0.742 | Acc: 81.566% (20933/25664)
Loss: 0.746 | Acc: 81.397% (26099/32064)
Loss: 0.750 | Acc: 81.214% (31238/38464)
Loss: 0.756 | Acc: 81.043% (36359/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1383, Accuracy: 6777/10000 (67.77%)

Epoch: 68
Loss: 0.536 | Acc: 84.375% (54/64)
Loss: 0.748 | Acc: 80.693% (5216/6464)
Loss: 0.738 | Acc: 81.017% (10422/12864)
Loss: 0.749 | Acc: 80.752% (15556/19264)
Loss: 0.750 | Acc: 80.802% (20737/25664)
Loss: 0.751 | Acc: 80.829% (25917/32064)
Loss: 0.752 | Acc: 80.756% (31062/38464)
Loss: 0.748 | Acc: 80.809% (36254/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0028, Accuracy: 7264/10000 (72.64%)

Epoch: 69
Loss: 1.088 | Acc: 71.875% (46/64)
Loss: 0.699 | Acc: 82.008% (5301/6464)
Loss: 0.711 | Acc: 81.825% (10526/12864)
Loss: 0.726 | Acc: 81.567% (15713/19264)
Loss: 0.732 | Acc: 81.460% (20906/25664)
Loss: 0.736 | Acc: 81.381% (26094/32064)
Loss: 0.734 | Acc: 81.427% (31320/38464)
Loss: 0.737 | Acc: 81.386% (36513/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0850, Accuracy: 7052/10000 (70.52%)

Epoch: 70
Loss: 0.710 | Acc: 81.250% (52/64)
Loss: 0.713 | Acc: 82.426% (5328/6464)
Loss: 0.709 | Acc: 82.486% (10611/12864)
Loss: 0.714 | Acc: 82.319% (15858/19264)
Loss: 0.715 | Acc: 82.279% (21116/25664)
Loss: 0.721 | Acc: 82.080% (26318/32064)
Loss: 0.726 | Acc: 81.864% (31488/38464)
Loss: 0.731 | Acc: 81.720% (36663/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9226, Accuracy: 7519/10000 (75.19%)

Epoch: 71
Loss: 0.807 | Acc: 76.562% (49/64)
Loss: 0.692 | Acc: 82.782% (5351/6464)
Loss: 0.704 | Acc: 82.408% (10601/12864)
Loss: 0.708 | Acc: 82.293% (15853/19264)
Loss: 0.718 | Acc: 82.057% (21059/25664)
Loss: 0.719 | Acc: 82.014% (26297/32064)
Loss: 0.719 | Acc: 81.962% (31526/38464)
Loss: 0.717 | Acc: 82.032% (36803/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9192, Accuracy: 4498/10000 (44.98%)

Epoch: 72
Loss: 1.061 | Acc: 68.750% (44/64)
Loss: 0.718 | Acc: 81.962% (5298/6464)
Loss: 0.712 | Acc: 82.362% (10595/12864)
Loss: 0.718 | Acc: 82.138% (15823/19264)
Loss: 0.712 | Acc: 82.286% (21118/25664)
Loss: 0.713 | Acc: 82.338% (26401/32064)
Loss: 0.709 | Acc: 82.433% (31707/38464)
Loss: 0.712 | Acc: 82.356% (36948/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9271, Accuracy: 7637/10000 (76.37%)

Epoch: 73
Loss: 0.593 | Acc: 85.938% (55/64)
Loss: 0.667 | Acc: 83.106% (5372/6464)
Loss: 0.693 | Acc: 82.595% (10625/12864)
Loss: 0.705 | Acc: 82.351% (15864/19264)
Loss: 0.707 | Acc: 82.357% (21136/25664)
Loss: 0.707 | Acc: 82.435% (26432/32064)
Loss: 0.702 | Acc: 82.599% (31771/38464)
Loss: 0.706 | Acc: 82.523% (37023/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9515, Accuracy: 7444/10000 (74.44%)

Epoch: 74
Loss: 0.796 | Acc: 75.000% (48/64)
Loss: 0.643 | Acc: 84.066% (5434/6464)
Loss: 0.663 | Acc: 83.621% (10757/12864)
Loss: 0.678 | Acc: 83.285% (16044/19264)
Loss: 0.679 | Acc: 83.257% (21367/25664)
Loss: 0.680 | Acc: 83.299% (26709/32064)
Loss: 0.688 | Acc: 83.052% (31945/38464)
Loss: 0.688 | Acc: 83.064% (37266/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8917, Accuracy: 7635/10000 (76.35%)

Epoch: 75
Loss: 0.564 | Acc: 85.938% (55/64)
Loss: 0.646 | Acc: 84.282% (5448/6464)
Loss: 0.659 | Acc: 83.776% (10777/12864)
Loss: 0.664 | Acc: 83.690% (16122/19264)
Loss: 0.666 | Acc: 83.658% (21470/25664)
Loss: 0.669 | Acc: 83.577% (26798/32064)
Loss: 0.676 | Acc: 83.392% (32076/38464)
Loss: 0.680 | Acc: 83.211% (37332/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9345, Accuracy: 7567/10000 (75.67%)

Epoch: 76
Loss: 0.553 | Acc: 85.938% (55/64)
Loss: 0.661 | Acc: 83.973% (5428/6464)
Loss: 0.650 | Acc: 84.235% (10836/12864)
Loss: 0.663 | Acc: 83.897% (16162/19264)
Loss: 0.666 | Acc: 83.911% (21535/25664)
Loss: 0.672 | Acc: 83.770% (26860/32064)
Loss: 0.672 | Acc: 83.696% (32193/38464)
Loss: 0.668 | Acc: 83.758% (37577/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9474, Accuracy: 7478/10000 (74.78%)

Epoch: 77
Loss: 0.892 | Acc: 76.562% (49/64)
Loss: 0.653 | Acc: 83.818% (5418/6464)
Loss: 0.660 | Acc: 83.730% (10771/12864)
Loss: 0.662 | Acc: 83.721% (16128/19264)
Loss: 0.662 | Acc: 83.775% (21500/25664)
Loss: 0.660 | Acc: 83.926% (26910/32064)
Loss: 0.657 | Acc: 84.032% (32322/38464)
Loss: 0.651 | Acc: 84.183% (37768/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9510, Accuracy: 7460/10000 (74.60%)

Epoch: 78
Loss: 0.652 | Acc: 79.688% (51/64)
Loss: 0.635 | Acc: 84.994% (5494/6464)
Loss: 0.635 | Acc: 84.857% (10916/12864)
Loss: 0.640 | Acc: 84.733% (16323/19264)
Loss: 0.645 | Acc: 84.624% (21718/25664)
Loss: 0.647 | Acc: 84.559% (27113/32064)
Loss: 0.643 | Acc: 84.578% (32532/38464)
Loss: 0.644 | Acc: 84.520% (37919/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9054, Accuracy: 7622/10000 (76.22%)

Epoch: 79
Loss: 0.529 | Acc: 87.500% (56/64)
Loss: 0.602 | Acc: 85.721% (5541/6464)
Loss: 0.605 | Acc: 85.580% (11009/12864)
Loss: 0.609 | Acc: 85.517% (16474/19264)
Loss: 0.618 | Acc: 85.252% (21879/25664)
Loss: 0.624 | Acc: 85.142% (27300/32064)
Loss: 0.623 | Acc: 85.186% (32766/38464)
Loss: 0.624 | Acc: 85.115% (38186/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9532, Accuracy: 7473/10000 (74.73%)

Epoch: 80
Loss: 0.955 | Acc: 76.562% (49/64)
Loss: 0.650 | Acc: 84.282% (5448/6464)
Loss: 0.618 | Acc: 85.121% (10950/12864)
Loss: 0.610 | Acc: 85.398% (16451/19264)
Loss: 0.606 | Acc: 85.431% (21925/25664)
Loss: 0.609 | Acc: 85.351% (27367/32064)
Loss: 0.611 | Acc: 85.360% (32833/38464)
Loss: 0.613 | Acc: 85.304% (38271/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8879, Accuracy: 7671/10000 (76.71%)

Epoch: 81
Loss: 0.381 | Acc: 87.500% (56/64)
Loss: 0.590 | Acc: 85.876% (5551/6464)
Loss: 0.607 | Acc: 85.409% (10987/12864)
Loss: 0.602 | Acc: 85.694% (16508/19264)
Loss: 0.601 | Acc: 85.692% (21992/25664)
Loss: 0.598 | Acc: 85.853% (27528/32064)
Loss: 0.597 | Acc: 85.873% (33030/38464)
Loss: 0.600 | Acc: 85.813% (38499/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9629, Accuracy: 7509/10000 (75.09%)

Epoch: 82
Loss: 0.444 | Acc: 89.062% (57/64)
Loss: 0.605 | Acc: 85.442% (5523/6464)
Loss: 0.584 | Acc: 86.124% (11079/12864)
Loss: 0.572 | Acc: 86.446% (16653/19264)
Loss: 0.576 | Acc: 86.374% (22167/25664)
Loss: 0.578 | Acc: 86.243% (27653/32064)
Loss: 0.581 | Acc: 86.156% (33139/38464)
Loss: 0.582 | Acc: 86.160% (38655/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8238, Accuracy: 7987/10000 (79.87%)

Epoch: 83
Loss: 0.524 | Acc: 90.625% (58/64)
Loss: 0.539 | Acc: 87.283% (5642/6464)
Loss: 0.542 | Acc: 87.127% (11208/12864)
Loss: 0.536 | Acc: 87.246% (16807/19264)
Loss: 0.551 | Acc: 86.834% (22285/25664)
Loss: 0.551 | Acc: 86.907% (27866/32064)
Loss: 0.557 | Acc: 86.801% (33387/38464)
Loss: 0.560 | Acc: 86.827% (38954/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8120, Accuracy: 8052/10000 (80.52%)

Epoch: 84
Loss: 0.463 | Acc: 89.062% (57/64)
Loss: 0.540 | Acc: 87.160% (5634/6464)
Loss: 0.541 | Acc: 87.142% (11210/12864)
Loss: 0.550 | Acc: 87.002% (16760/19264)
Loss: 0.553 | Acc: 86.935% (22311/25664)
Loss: 0.548 | Acc: 87.060% (27915/32064)
Loss: 0.551 | Acc: 87.014% (33469/38464)
Loss: 0.549 | Acc: 87.119% (39085/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7996, Accuracy: 8120/10000 (81.20%)

Epoch: 85
Loss: 0.538 | Acc: 89.062% (57/64)
Loss: 0.524 | Acc: 87.701% (5669/6464)
Loss: 0.520 | Acc: 87.764% (11290/12864)
Loss: 0.518 | Acc: 87.786% (16911/19264)
Loss: 0.520 | Acc: 87.632% (22490/25664)
Loss: 0.518 | Acc: 87.753% (28137/32064)
Loss: 0.521 | Acc: 87.731% (33745/38464)
Loss: 0.521 | Acc: 87.736% (39362/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8862, Accuracy: 7867/10000 (78.67%)

Epoch: 86
Loss: 0.649 | Acc: 82.812% (53/64)
Loss: 0.498 | Acc: 88.490% (5720/6464)
Loss: 0.476 | Acc: 89.024% (11452/12864)
Loss: 0.483 | Acc: 88.772% (17101/19264)
Loss: 0.495 | Acc: 88.451% (22700/25664)
Loss: 0.494 | Acc: 88.489% (28373/32064)
Loss: 0.499 | Acc: 88.418% (34009/38464)
Loss: 0.500 | Acc: 88.372% (39647/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8944, Accuracy: 7870/10000 (78.70%)

Epoch: 87
Loss: 0.411 | Acc: 92.188% (59/64)
Loss: 0.473 | Acc: 89.062% (5757/6464)
Loss: 0.465 | Acc: 89.039% (11454/12864)
Loss: 0.473 | Acc: 88.850% (17116/19264)
Loss: 0.474 | Acc: 88.868% (22807/25664)
Loss: 0.474 | Acc: 88.847% (28488/32064)
Loss: 0.477 | Acc: 88.719% (34125/38464)
Loss: 0.474 | Acc: 88.835% (39855/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8138, Accuracy: 8150/10000 (81.50%)

Epoch: 88
Loss: 0.378 | Acc: 92.188% (59/64)
Loss: 0.441 | Acc: 89.465% (5783/6464)
Loss: 0.439 | Acc: 89.770% (11548/12864)
Loss: 0.444 | Acc: 89.659% (17272/19264)
Loss: 0.448 | Acc: 89.635% (23004/25664)
Loss: 0.446 | Acc: 89.705% (28763/32064)
Loss: 0.442 | Acc: 89.725% (34512/38464)
Loss: 0.445 | Acc: 89.653% (40222/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8149, Accuracy: 8190/10000 (81.90%)

Epoch: 89
Loss: 0.479 | Acc: 87.500% (56/64)
Loss: 0.405 | Acc: 90.161% (5828/6464)
Loss: 0.406 | Acc: 90.306% (11617/12864)
Loss: 0.407 | Acc: 90.288% (17393/19264)
Loss: 0.408 | Acc: 90.259% (23164/25664)
Loss: 0.415 | Acc: 90.120% (28896/32064)
Loss: 0.414 | Acc: 90.157% (34678/38464)
Loss: 0.416 | Acc: 90.137% (40439/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8499, Accuracy: 8160/10000 (81.60%)

Epoch: 90
Loss: 0.248 | Acc: 95.312% (61/64)
Loss: 0.379 | Acc: 90.795% (5869/6464)
Loss: 0.377 | Acc: 90.998% (11706/12864)
Loss: 0.380 | Acc: 91.009% (17532/19264)
Loss: 0.377 | Acc: 91.007% (23356/25664)
Loss: 0.383 | Acc: 90.825% (29122/32064)
Loss: 0.385 | Acc: 90.786% (34920/38464)
Loss: 0.385 | Acc: 90.817% (40744/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8690, Accuracy: 8092/10000 (80.92%)

Epoch: 91
Loss: 0.385 | Acc: 90.625% (58/64)
Loss: 0.350 | Acc: 91.538% (5917/6464)
Loss: 0.348 | Acc: 91.433% (11762/12864)
Loss: 0.349 | Acc: 91.383% (17604/19264)
Loss: 0.346 | Acc: 91.432% (23465/25664)
Loss: 0.347 | Acc: 91.451% (29323/32064)
Loss: 0.348 | Acc: 91.436% (35170/38464)
Loss: 0.349 | Acc: 91.456% (41031/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8898, Accuracy: 8185/10000 (81.85%)

Epoch: 92
Loss: 0.383 | Acc: 90.625% (58/64)
Loss: 0.309 | Acc: 92.095% (5953/6464)
Loss: 0.302 | Acc: 92.374% (11883/12864)
Loss: 0.306 | Acc: 92.348% (17790/19264)
Loss: 0.313 | Acc: 92.184% (23658/25664)
Loss: 0.322 | Acc: 91.919% (29473/32064)
Loss: 0.322 | Acc: 91.912% (35353/38464)
Loss: 0.322 | Acc: 91.918% (41238/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9169, Accuracy: 8104/10000 (81.04%)

Epoch: 93
Loss: 0.329 | Acc: 92.188% (59/64)
Loss: 0.277 | Acc: 92.775% (5997/6464)
Loss: 0.274 | Acc: 93.043% (11969/12864)
Loss: 0.273 | Acc: 93.117% (17938/19264)
Loss: 0.278 | Acc: 92.928% (23849/25664)
Loss: 0.279 | Acc: 92.961% (29807/32064)
Loss: 0.278 | Acc: 93.058% (35794/38464)
Loss: 0.280 | Acc: 92.990% (41719/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9203, Accuracy: 8198/10000 (81.98%)

Epoch: 94
Loss: 0.206 | Acc: 93.750% (60/64)
Loss: 0.241 | Acc: 93.781% (6062/6464)
Loss: 0.247 | Acc: 93.649% (12047/12864)
Loss: 0.251 | Acc: 93.511% (18014/19264)
Loss: 0.250 | Acc: 93.598% (24021/25664)
Loss: 0.250 | Acc: 93.588% (30008/32064)
Loss: 0.248 | Acc: 93.604% (36004/38464)
Loss: 0.246 | Acc: 93.636% (42009/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9466, Accuracy: 8173/10000 (81.73%)

Epoch: 95
Loss: 0.177 | Acc: 95.312% (61/64)
Loss: 0.220 | Acc: 94.431% (6104/6464)
Loss: 0.235 | Acc: 93.960% (12087/12864)
Loss: 0.248 | Acc: 93.693% (18049/19264)
Loss: 0.259 | Acc: 93.419% (23975/25664)
Loss: 0.269 | Acc: 93.235% (29895/32064)
Loss: 0.280 | Acc: 92.978% (35763/38464)
Loss: 0.288 | Acc: 92.794% (41631/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8352, Accuracy: 8191/10000 (81.91%)

Epoch: 96
Loss: 0.297 | Acc: 93.750% (60/64)
Loss: 0.340 | Acc: 91.692% (5927/6464)
Loss: 0.342 | Acc: 91.682% (11794/12864)
Loss: 0.357 | Acc: 91.357% (17599/19264)
Loss: 0.362 | Acc: 91.338% (23441/25664)
Loss: 0.363 | Acc: 91.352% (29291/32064)
Loss: 0.366 | Acc: 91.254% (35100/38464)
Loss: 0.369 | Acc: 91.160% (40898/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8041, Accuracy: 8196/10000 (81.96%)

Epoch: 97
Loss: 0.376 | Acc: 89.062% (57/64)
Loss: 0.402 | Acc: 90.223% (5832/6464)
Loss: 0.400 | Acc: 90.291% (11615/12864)
Loss: 0.396 | Acc: 90.329% (17401/19264)
Loss: 0.399 | Acc: 90.263% (23165/25664)
Loss: 0.396 | Acc: 90.460% (29005/32064)
Loss: 0.393 | Acc: 90.547% (34828/38464)
Loss: 0.393 | Acc: 90.547% (40623/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8008, Accuracy: 8195/10000 (81.95%)
torch.Size([100, 10])
Test set: Average loss: 0.8008, Accuracy: 8195/10000 (81.95%)

Epoch: 98
Loss: 0.180 | Acc: 96.875% (62/64)
Loss: 0.403 | Acc: 90.408% (5844/6464)
Loss: 0.404 | Acc: 90.306% (11617/12864)
Loss: 0.405 | Acc: 90.371% (17409/19264)
Loss: 0.403 | Acc: 90.454% (23214/25664)
Loss: 0.401 | Acc: 90.531% (29028/32064)
Loss: 0.403 | Acc: 90.487% (34805/38464)
Loss: 0.402 | Acc: 90.482% (40594/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8006, Accuracy: 8196/10000 (81.96%)
torch.Size([100, 10])
Test set: Average loss: 0.8006, Accuracy: 8196/10000 (81.96%)

Epoch: 99
Loss: 0.249 | Acc: 93.750% (60/64)
Loss: 0.397 | Acc: 90.362% (5841/6464)
Loss: 0.392 | Acc: 90.664% (11663/12864)
Loss: 0.390 | Acc: 90.801% (17492/19264)
Loss: 0.397 | Acc: 90.633% (23260/25664)
Loss: 0.400 | Acc: 90.603% (29051/32064)
Loss: 0.400 | Acc: 90.581% (34841/38464)
Loss: 0.402 | Acc: 90.511% (40607/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8028, Accuracy: 8186/10000 (81.86%)
torch.Size([100, 10])
Test set: Average loss: 0.8028, Accuracy: 8186/10000 (81.86%)

Epoch: 100
Loss: 0.382 | Acc: 89.062% (57/64)
Loss: 1.562 | Acc: 49.118% (3175/6464)
Loss: 1.323 | Acc: 58.668% (7547/12864)
Loss: 1.211 | Acc: 63.118% (12159/19264)
Loss: 1.149 | Acc: 65.602% (16836/25664)
Loss: 1.103 | Acc: 67.421% (21618/32064)
Loss: 1.070 | Acc: 68.794% (26461/38464)
Loss: 1.047 | Acc: 69.666% (31255/44864)
torch.Size([100, 10])
Test set: Average loss: 3.5157, Accuracy: 2320/10000 (23.20%)

Epoch: 101
Loss: 1.009 | Acc: 67.188% (43/64)
Loss: 0.846 | Acc: 77.367% (5001/6464)
Loss: 0.848 | Acc: 77.146% (9924/12864)
Loss: 0.848 | Acc: 77.300% (14891/19264)
Loss: 0.846 | Acc: 77.404% (19865/25664)
Loss: 0.846 | Acc: 77.386% (24813/32064)
Loss: 0.841 | Acc: 77.613% (29853/38464)
Loss: 0.846 | Acc: 77.532% (34784/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2180, Accuracy: 6530/10000 (65.30%)

Epoch: 102
Loss: 0.787 | Acc: 79.688% (51/64)
Loss: 0.804 | Acc: 79.316% (5127/6464)
Loss: 0.820 | Acc: 78.537% (10103/12864)
Loss: 0.818 | Acc: 78.571% (15136/19264)
Loss: 0.817 | Acc: 78.596% (20171/25664)
Loss: 0.815 | Acc: 78.593% (25200/32064)
Loss: 0.819 | Acc: 78.468% (30182/38464)
Loss: 0.819 | Acc: 78.506% (35221/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4011, Accuracy: 5999/10000 (59.99%)

Epoch: 103
Loss: 0.862 | Acc: 70.312% (45/64)
Loss: 0.802 | Acc: 78.806% (5094/6464)
Loss: 0.816 | Acc: 78.584% (10109/12864)
Loss: 0.806 | Acc: 78.836% (15187/19264)
Loss: 0.803 | Acc: 79.107% (20302/25664)
Loss: 0.806 | Acc: 79.123% (25370/32064)
Loss: 0.808 | Acc: 79.084% (30419/38464)
Loss: 0.808 | Acc: 78.994% (35440/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5080, Accuracy: 5810/10000 (58.10%)

Epoch: 104
Loss: 0.796 | Acc: 75.000% (48/64)
Loss: 0.787 | Acc: 79.765% (5156/6464)
Loss: 0.802 | Acc: 79.268% (10197/12864)
Loss: 0.798 | Acc: 79.371% (15290/19264)
Loss: 0.802 | Acc: 79.169% (20318/25664)
Loss: 0.804 | Acc: 79.117% (25368/32064)
Loss: 0.804 | Acc: 79.069% (30413/38464)
Loss: 0.804 | Acc: 79.075% (35476/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1363, Accuracy: 6789/10000 (67.89%)

Epoch: 105
Loss: 0.978 | Acc: 68.750% (44/64)
Loss: 0.781 | Acc: 79.842% (5161/6464)
Loss: 0.783 | Acc: 79.897% (10278/12864)
Loss: 0.784 | Acc: 79.880% (15388/19264)
Loss: 0.785 | Acc: 79.645% (20440/25664)
Loss: 0.788 | Acc: 79.628% (25532/32064)
Loss: 0.790 | Acc: 79.638% (30632/38464)
Loss: 0.794 | Acc: 79.543% (35686/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1052, Accuracy: 3986/10000 (39.86%)

Epoch: 106
Loss: 1.066 | Acc: 68.750% (44/64)
Loss: 0.812 | Acc: 78.960% (5104/6464)
Loss: 0.797 | Acc: 79.268% (10197/12864)
Loss: 0.791 | Acc: 79.547% (15324/19264)
Loss: 0.792 | Acc: 79.586% (20425/25664)
Loss: 0.793 | Acc: 79.444% (25473/32064)
Loss: 0.794 | Acc: 79.526% (30589/38464)
Loss: 0.796 | Acc: 79.422% (35632/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1631, Accuracy: 6824/10000 (68.24%)

Epoch: 107
Loss: 0.606 | Acc: 82.812% (53/64)
Loss: 0.761 | Acc: 80.600% (5210/6464)
Loss: 0.773 | Acc: 80.107% (10305/12864)
Loss: 0.776 | Acc: 79.957% (15403/19264)
Loss: 0.781 | Acc: 79.859% (20495/25664)
Loss: 0.785 | Acc: 79.663% (25543/32064)
Loss: 0.786 | Acc: 79.623% (30626/38464)
Loss: 0.786 | Acc: 79.703% (35758/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7317, Accuracy: 5093/10000 (50.93%)

Epoch: 108
Loss: 1.146 | Acc: 68.750% (44/64)
Loss: 0.790 | Acc: 79.688% (5151/6464)
Loss: 0.781 | Acc: 80.006% (10292/12864)
Loss: 0.788 | Acc: 79.926% (15397/19264)
Loss: 0.788 | Acc: 79.945% (20517/25664)
Loss: 0.783 | Acc: 79.981% (25645/32064)
Loss: 0.787 | Acc: 79.898% (30732/38464)
Loss: 0.789 | Acc: 79.797% (35800/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3379, Accuracy: 4199/10000 (41.99%)

Epoch: 109
Loss: 1.097 | Acc: 73.438% (47/64)
Loss: 0.804 | Acc: 79.115% (5114/6464)
Loss: 0.792 | Acc: 79.610% (10241/12864)
Loss: 0.787 | Acc: 79.745% (15362/19264)
Loss: 0.783 | Acc: 79.878% (20500/25664)
Loss: 0.784 | Acc: 79.772% (25578/32064)
Loss: 0.785 | Acc: 79.750% (30675/38464)
Loss: 0.786 | Acc: 79.823% (35812/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6921, Accuracy: 5442/10000 (54.42%)

Epoch: 110
Loss: 0.954 | Acc: 70.312% (45/64)
Loss: 0.796 | Acc: 79.502% (5139/6464)
Loss: 0.770 | Acc: 80.193% (10316/12864)
Loss: 0.768 | Acc: 80.259% (15461/19264)
Loss: 0.767 | Acc: 80.280% (20603/25664)
Loss: 0.772 | Acc: 80.190% (25712/32064)
Loss: 0.775 | Acc: 80.161% (30833/38464)
Loss: 0.775 | Acc: 80.086% (35930/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9380, Accuracy: 7516/10000 (75.16%)

Epoch: 111
Loss: 0.794 | Acc: 73.438% (47/64)
Loss: 0.773 | Acc: 80.430% (5199/6464)
Loss: 0.772 | Acc: 80.138% (10309/12864)
Loss: 0.766 | Acc: 80.284% (15466/19264)
Loss: 0.761 | Acc: 80.307% (20610/25664)
Loss: 0.770 | Acc: 80.140% (25696/32064)
Loss: 0.773 | Acc: 80.057% (30793/38464)
Loss: 0.775 | Acc: 80.017% (35899/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1938, Accuracy: 6637/10000 (66.37%)

Epoch: 112
Loss: 1.226 | Acc: 64.062% (41/64)
Loss: 0.750 | Acc: 80.832% (5225/6464)
Loss: 0.753 | Acc: 80.667% (10377/12864)
Loss: 0.759 | Acc: 80.824% (15570/19264)
Loss: 0.759 | Acc: 80.720% (20716/25664)
Loss: 0.761 | Acc: 80.732% (25886/32064)
Loss: 0.765 | Acc: 80.665% (31027/38464)
Loss: 0.770 | Acc: 80.481% (36107/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0870, Accuracy: 6894/10000 (68.94%)

Epoch: 113
Loss: 0.783 | Acc: 78.125% (50/64)
Loss: 0.749 | Acc: 81.219% (5250/6464)
Loss: 0.760 | Acc: 80.651% (10375/12864)
Loss: 0.757 | Acc: 80.689% (15544/19264)
Loss: 0.755 | Acc: 80.666% (20702/25664)
Loss: 0.751 | Acc: 80.710% (25879/32064)
Loss: 0.759 | Acc: 80.538% (30978/38464)
Loss: 0.763 | Acc: 80.463% (36099/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5544, Accuracy: 5417/10000 (54.17%)

Epoch: 114
Loss: 1.004 | Acc: 73.438% (47/64)
Loss: 0.741 | Acc: 81.235% (5251/6464)
Loss: 0.743 | Acc: 81.087% (10431/12864)
Loss: 0.751 | Acc: 80.757% (15557/19264)
Loss: 0.745 | Acc: 80.880% (20757/25664)
Loss: 0.749 | Acc: 80.854% (25925/32064)
Loss: 0.756 | Acc: 80.647% (31020/38464)
Loss: 0.758 | Acc: 80.668% (36191/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2387, Accuracy: 6498/10000 (64.98%)

Epoch: 115
Loss: 0.804 | Acc: 79.688% (51/64)
Loss: 0.715 | Acc: 82.147% (5310/6464)
Loss: 0.724 | Acc: 81.950% (10542/12864)
Loss: 0.742 | Acc: 81.359% (15673/19264)
Loss: 0.742 | Acc: 81.308% (20867/25664)
Loss: 0.745 | Acc: 81.163% (26024/32064)
Loss: 0.747 | Acc: 81.084% (31188/38464)
Loss: 0.748 | Acc: 81.014% (36346/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1407, Accuracy: 6942/10000 (69.42%)

Epoch: 116
Loss: 0.770 | Acc: 82.812% (53/64)
Loss: 0.744 | Acc: 81.420% (5263/6464)
Loss: 0.744 | Acc: 81.234% (10450/12864)
Loss: 0.745 | Acc: 81.120% (15627/19264)
Loss: 0.742 | Acc: 81.211% (20842/25664)
Loss: 0.750 | Acc: 81.025% (25980/32064)
Loss: 0.745 | Acc: 81.221% (31241/38464)
Loss: 0.744 | Acc: 81.208% (36433/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2216, Accuracy: 6579/10000 (65.79%)

Epoch: 117
Loss: 0.708 | Acc: 76.562% (49/64)
Loss: 0.756 | Acc: 80.817% (5224/6464)
Loss: 0.747 | Acc: 81.087% (10431/12864)
Loss: 0.740 | Acc: 81.214% (15645/19264)
Loss: 0.735 | Acc: 81.457% (20905/25664)
Loss: 0.745 | Acc: 81.222% (26043/32064)
Loss: 0.743 | Acc: 81.336% (31285/38464)
Loss: 0.739 | Acc: 81.417% (36527/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9466, Accuracy: 7430/10000 (74.30%)

Epoch: 118
Loss: 0.884 | Acc: 78.125% (50/64)
Loss: 0.717 | Acc: 81.791% (5287/6464)
Loss: 0.724 | Acc: 81.639% (10502/12864)
Loss: 0.715 | Acc: 82.127% (15821/19264)
Loss: 0.722 | Acc: 81.979% (21039/25664)
Loss: 0.728 | Acc: 81.871% (26251/32064)
Loss: 0.726 | Acc: 81.843% (31480/38464)
Loss: 0.729 | Acc: 81.823% (36709/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9523, Accuracy: 5068/10000 (50.68%)

Epoch: 119
Loss: 0.576 | Acc: 85.938% (55/64)
Loss: 0.745 | Acc: 81.235% (5251/6464)
Loss: 0.724 | Acc: 81.934% (10540/12864)
Loss: 0.717 | Acc: 81.992% (15795/19264)
Loss: 0.723 | Acc: 81.959% (21034/25664)
Loss: 0.722 | Acc: 82.108% (26327/32064)
Loss: 0.722 | Acc: 82.131% (31591/38464)
Loss: 0.725 | Acc: 82.028% (36801/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4833, Accuracy: 6009/10000 (60.09%)

Epoch: 120
Loss: 0.662 | Acc: 78.125% (50/64)
Loss: 0.720 | Acc: 81.575% (5273/6464)
Loss: 0.716 | Acc: 82.058% (10556/12864)
Loss: 0.713 | Acc: 82.231% (15841/19264)
Loss: 0.717 | Acc: 82.103% (21071/25664)
Loss: 0.714 | Acc: 82.101% (26325/32064)
Loss: 0.717 | Acc: 82.077% (31570/38464)
Loss: 0.716 | Acc: 82.159% (36860/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9209, Accuracy: 7557/10000 (75.57%)

Epoch: 121
Loss: 0.569 | Acc: 82.812% (53/64)
Loss: 0.667 | Acc: 83.864% (5421/6464)
Loss: 0.688 | Acc: 83.069% (10686/12864)
Loss: 0.696 | Acc: 82.771% (15945/19264)
Loss: 0.701 | Acc: 82.579% (21193/25664)
Loss: 0.700 | Acc: 82.635% (26496/32064)
Loss: 0.704 | Acc: 82.545% (31750/38464)
Loss: 0.706 | Acc: 82.570% (37044/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8852, Accuracy: 7672/10000 (76.72%)

Epoch: 122
Loss: 0.804 | Acc: 81.250% (52/64)
Loss: 0.673 | Acc: 83.555% (5401/6464)
Loss: 0.666 | Acc: 83.761% (10775/12864)
Loss: 0.677 | Acc: 83.441% (16074/19264)
Loss: 0.679 | Acc: 83.385% (21400/25664)
Loss: 0.683 | Acc: 83.277% (26702/32064)
Loss: 0.685 | Acc: 83.200% (32002/38464)
Loss: 0.688 | Acc: 83.116% (37289/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8866, Accuracy: 7733/10000 (77.33%)

Epoch: 123
Loss: 0.592 | Acc: 84.375% (54/64)
Loss: 0.680 | Acc: 83.215% (5379/6464)
Loss: 0.680 | Acc: 83.396% (10728/12864)
Loss: 0.685 | Acc: 83.295% (16046/19264)
Loss: 0.681 | Acc: 83.319% (21383/25664)
Loss: 0.684 | Acc: 83.271% (26700/32064)
Loss: 0.685 | Acc: 83.197% (32001/38464)
Loss: 0.687 | Acc: 83.154% (37306/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9111, Accuracy: 7614/10000 (76.14%)

Epoch: 124
Loss: 0.712 | Acc: 82.812% (53/64)
Loss: 0.669 | Acc: 83.973% (5428/6464)
Loss: 0.663 | Acc: 84.017% (10808/12864)
Loss: 0.672 | Acc: 83.648% (16114/19264)
Loss: 0.670 | Acc: 83.580% (21450/25664)
Loss: 0.675 | Acc: 83.467% (26763/32064)
Loss: 0.675 | Acc: 83.465% (32104/38464)
Loss: 0.678 | Acc: 83.417% (37424/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0471, Accuracy: 7124/10000 (71.24%)

Epoch: 125
Loss: 0.724 | Acc: 85.938% (55/64)
Loss: 0.645 | Acc: 84.468% (5460/6464)
Loss: 0.642 | Acc: 84.406% (10858/12864)
Loss: 0.655 | Acc: 84.095% (16200/19264)
Loss: 0.655 | Acc: 84.137% (21593/25664)
Loss: 0.660 | Acc: 83.991% (26931/32064)
Loss: 0.659 | Acc: 83.995% (32308/38464)
Loss: 0.664 | Acc: 83.896% (37639/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1586, Accuracy: 6616/10000 (66.16%)

Epoch: 126
Loss: 0.422 | Acc: 87.500% (56/64)
Loss: 0.632 | Acc: 84.731% (5477/6464)
Loss: 0.629 | Acc: 84.678% (10893/12864)
Loss: 0.650 | Acc: 84.157% (16212/19264)
Loss: 0.655 | Acc: 84.032% (21566/25664)
Loss: 0.656 | Acc: 84.023% (26941/32064)
Loss: 0.653 | Acc: 84.164% (32373/38464)
Loss: 0.654 | Acc: 84.137% (37747/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8370, Accuracy: 7871/10000 (78.71%)

Epoch: 127
Loss: 0.638 | Acc: 82.812% (53/64)
Loss: 0.629 | Acc: 85.025% (5496/6464)
Loss: 0.633 | Acc: 84.873% (10918/12864)
Loss: 0.639 | Acc: 84.707% (16318/19264)
Loss: 0.642 | Acc: 84.628% (21719/25664)
Loss: 0.644 | Acc: 84.584% (27121/32064)
Loss: 0.642 | Acc: 84.580% (32533/38464)
Loss: 0.641 | Acc: 84.663% (37983/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8644, Accuracy: 7806/10000 (78.06%)

Epoch: 128
Loss: 0.796 | Acc: 81.250% (52/64)
Loss: 0.599 | Acc: 85.814% (5547/6464)
Loss: 0.608 | Acc: 85.627% (11015/12864)
Loss: 0.615 | Acc: 85.429% (16457/19264)
Loss: 0.622 | Acc: 85.232% (21874/25664)
Loss: 0.626 | Acc: 85.111% (27290/32064)
Loss: 0.630 | Acc: 85.028% (32705/38464)
Loss: 0.631 | Acc: 84.946% (38110/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9348, Accuracy: 7669/10000 (76.69%)

Epoch: 129
Loss: 0.729 | Acc: 81.250% (52/64)
Loss: 0.601 | Acc: 85.767% (5544/6464)
Loss: 0.608 | Acc: 85.603% (11012/12864)
Loss: 0.601 | Acc: 85.823% (16533/19264)
Loss: 0.605 | Acc: 85.669% (21986/25664)
Loss: 0.614 | Acc: 85.488% (27411/32064)
Loss: 0.616 | Acc: 85.438% (32863/38464)
Loss: 0.616 | Acc: 85.443% (38333/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8466, Accuracy: 7869/10000 (78.69%)

Epoch: 130
Loss: 0.801 | Acc: 81.250% (52/64)
Loss: 0.602 | Acc: 85.798% (5546/6464)
Loss: 0.620 | Acc: 85.432% (10990/12864)
Loss: 0.604 | Acc: 85.870% (16542/19264)
Loss: 0.603 | Acc: 85.875% (22039/25664)
Loss: 0.598 | Acc: 86.047% (27590/32064)
Loss: 0.600 | Acc: 85.940% (33056/38464)
Loss: 0.599 | Acc: 85.917% (38546/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8365, Accuracy: 7911/10000 (79.11%)

Epoch: 131
Loss: 0.566 | Acc: 87.500% (56/64)
Loss: 0.563 | Acc: 87.020% (5625/6464)
Loss: 0.566 | Acc: 86.839% (11171/12864)
Loss: 0.562 | Acc: 86.950% (16750/19264)
Loss: 0.572 | Acc: 86.627% (22232/25664)
Loss: 0.577 | Acc: 86.530% (27745/32064)
Loss: 0.579 | Acc: 86.486% (33266/38464)
Loss: 0.584 | Acc: 86.325% (38729/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9185, Accuracy: 7746/10000 (77.46%)

Epoch: 132
Loss: 0.766 | Acc: 79.688% (51/64)
Loss: 0.543 | Acc: 87.624% (5664/6464)
Loss: 0.556 | Acc: 87.002% (11192/12864)
Loss: 0.561 | Acc: 86.856% (16732/19264)
Loss: 0.568 | Acc: 86.627% (22232/25664)
Loss: 0.572 | Acc: 86.471% (27726/32064)
Loss: 0.573 | Acc: 86.515% (33277/38464)
Loss: 0.573 | Acc: 86.495% (38805/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8800, Accuracy: 7851/10000 (78.51%)

Epoch: 133
Loss: 0.533 | Acc: 84.375% (54/64)
Loss: 0.503 | Acc: 88.506% (5721/6464)
Loss: 0.527 | Acc: 87.842% (11300/12864)
Loss: 0.543 | Acc: 87.375% (16832/19264)
Loss: 0.543 | Acc: 87.406% (22432/25664)
Loss: 0.551 | Acc: 87.238% (27972/32064)
Loss: 0.552 | Acc: 87.144% (33519/38464)
Loss: 0.552 | Acc: 87.166% (39106/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8822, Accuracy: 7849/10000 (78.49%)

Epoch: 134
Loss: 0.494 | Acc: 89.062% (57/64)
Loss: 0.529 | Acc: 87.608% (5663/6464)
Loss: 0.527 | Acc: 87.749% (11288/12864)
Loss: 0.521 | Acc: 88.024% (16957/19264)
Loss: 0.523 | Acc: 87.940% (22569/25664)
Loss: 0.531 | Acc: 87.731% (28130/32064)
Loss: 0.530 | Acc: 87.744% (33750/38464)
Loss: 0.526 | Acc: 87.819% (39399/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8526, Accuracy: 7956/10000 (79.56%)

Epoch: 135
Loss: 0.513 | Acc: 87.500% (56/64)
Loss: 0.475 | Acc: 88.707% (5734/6464)
Loss: 0.479 | Acc: 88.837% (11428/12864)
Loss: 0.485 | Acc: 88.756% (17098/19264)
Loss: 0.498 | Acc: 88.385% (22683/25664)
Loss: 0.501 | Acc: 88.317% (28318/32064)
Loss: 0.510 | Acc: 88.134% (33900/38464)
Loss: 0.508 | Acc: 88.175% (39559/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7931, Accuracy: 8190/10000 (81.90%)

Epoch: 136
Loss: 0.418 | Acc: 90.625% (58/64)
Loss: 0.496 | Acc: 88.243% (5704/6464)
Loss: 0.486 | Acc: 88.542% (11390/12864)
Loss: 0.478 | Acc: 88.824% (17111/19264)
Loss: 0.482 | Acc: 88.700% (22764/25664)
Loss: 0.482 | Acc: 88.694% (28439/32064)
Loss: 0.487 | Acc: 88.574% (34069/38464)
Loss: 0.488 | Acc: 88.548% (39726/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8331, Accuracy: 8092/10000 (80.92%)

Epoch: 137
Loss: 0.533 | Acc: 89.062% (57/64)
Loss: 0.441 | Acc: 89.805% (5805/6464)
Loss: 0.438 | Acc: 89.933% (11569/12864)
Loss: 0.444 | Acc: 89.810% (17301/19264)
Loss: 0.446 | Acc: 89.725% (23027/25664)
Loss: 0.453 | Acc: 89.580% (28723/32064)
Loss: 0.456 | Acc: 89.481% (34418/38464)
Loss: 0.456 | Acc: 89.459% (40135/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1398, Accuracy: 7366/10000 (73.66%)

Epoch: 138
Loss: 0.488 | Acc: 84.375% (54/64)
Loss: 0.437 | Acc: 89.588% (5791/6464)
Loss: 0.440 | Acc: 89.677% (11536/12864)
Loss: 0.430 | Acc: 89.971% (17332/19264)
Loss: 0.424 | Acc: 90.150% (23136/25664)
Loss: 0.428 | Acc: 90.057% (28876/32064)
Loss: 0.423 | Acc: 90.154% (34677/38464)
Loss: 0.429 | Acc: 89.985% (40371/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8219, Accuracy: 8186/10000 (81.86%)

Epoch: 139
Loss: 0.441 | Acc: 87.500% (56/64)
Loss: 0.391 | Acc: 90.780% (5868/6464)
Loss: 0.394 | Acc: 90.672% (11664/12864)
Loss: 0.396 | Acc: 90.641% (17461/19264)
Loss: 0.403 | Acc: 90.508% (23228/25664)
Loss: 0.404 | Acc: 90.453% (29003/32064)
Loss: 0.405 | Acc: 90.394% (34769/38464)
Loss: 0.404 | Acc: 90.400% (40557/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8895, Accuracy: 8086/10000 (80.86%)

Epoch: 140
Loss: 0.338 | Acc: 92.188% (59/64)
Loss: 0.369 | Acc: 91.290% (5901/6464)
Loss: 0.375 | Acc: 91.091% (11718/12864)
Loss: 0.367 | Acc: 91.300% (17588/19264)
Loss: 0.368 | Acc: 91.198% (23405/25664)
Loss: 0.366 | Acc: 91.286% (29270/32064)
Loss: 0.367 | Acc: 91.309% (35121/38464)
Loss: 0.369 | Acc: 91.218% (40924/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8646, Accuracy: 8123/10000 (81.23%)

Epoch: 141
Loss: 0.403 | Acc: 89.062% (57/64)
Loss: 0.315 | Acc: 92.265% (5964/6464)
Loss: 0.332 | Acc: 91.877% (11819/12864)
Loss: 0.330 | Acc: 91.912% (17706/19264)
Loss: 0.333 | Acc: 91.806% (23561/25664)
Loss: 0.331 | Acc: 91.947% (29482/32064)
Loss: 0.330 | Acc: 91.985% (35381/38464)
Loss: 0.335 | Acc: 91.867% (41215/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8819, Accuracy: 8201/10000 (82.01%)

Epoch: 142
Loss: 0.248 | Acc: 95.312% (61/64)
Loss: 0.306 | Acc: 92.342% (5969/6464)
Loss: 0.298 | Acc: 92.506% (11900/12864)
Loss: 0.299 | Acc: 92.535% (17826/19264)
Loss: 0.299 | Acc: 92.601% (23765/25664)
Loss: 0.298 | Acc: 92.605% (29693/32064)
Loss: 0.299 | Acc: 92.603% (35619/38464)
Loss: 0.300 | Acc: 92.520% (41508/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9118, Accuracy: 8206/10000 (82.06%)

Epoch: 143
Loss: 0.360 | Acc: 90.625% (58/64)
Loss: 0.290 | Acc: 92.775% (5997/6464)
Loss: 0.285 | Acc: 92.701% (11925/12864)
Loss: 0.273 | Acc: 93.106% (17936/19264)
Loss: 0.273 | Acc: 93.084% (23889/25664)
Loss: 0.273 | Acc: 93.092% (29849/32064)
Loss: 0.271 | Acc: 93.118% (35817/38464)
Loss: 0.273 | Acc: 93.092% (41765/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9189, Accuracy: 8241/10000 (82.41%)

Epoch: 144
Loss: 0.267 | Acc: 95.312% (61/64)
Loss: 0.239 | Acc: 93.951% (6073/6464)
Loss: 0.239 | Acc: 93.968% (12088/12864)
Loss: 0.240 | Acc: 93.937% (18096/19264)
Loss: 0.240 | Acc: 93.844% (24084/25664)
Loss: 0.238 | Acc: 93.900% (30108/32064)
Loss: 0.238 | Acc: 93.916% (36124/38464)
Loss: 0.239 | Acc: 93.866% (42112/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9310, Accuracy: 8198/10000 (81.98%)

Epoch: 145
Loss: 0.157 | Acc: 96.875% (62/64)
Loss: 0.218 | Acc: 94.230% (6091/6464)
Loss: 0.229 | Acc: 94.084% (12103/12864)
Loss: 0.239 | Acc: 93.869% (18083/19264)
Loss: 0.246 | Acc: 93.719% (24052/25664)
Loss: 0.252 | Acc: 93.619% (30018/32064)
Loss: 0.263 | Acc: 93.337% (35901/38464)
Loss: 0.269 | Acc: 93.235% (41829/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8340, Accuracy: 8198/10000 (81.98%)

Epoch: 146
Loss: 0.540 | Acc: 85.938% (55/64)
Loss: 0.307 | Acc: 92.636% (5988/6464)
Loss: 0.322 | Acc: 92.141% (11853/12864)
Loss: 0.332 | Acc: 91.824% (17689/19264)
Loss: 0.332 | Acc: 91.755% (23548/25664)
Loss: 0.337 | Acc: 91.673% (29394/32064)
Loss: 0.343 | Acc: 91.504% (35196/38464)
Loss: 0.347 | Acc: 91.427% (41018/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8174, Accuracy: 8186/10000 (81.86%)

Epoch: 147
Loss: 0.353 | Acc: 90.625% (58/64)
Loss: 0.369 | Acc: 91.058% (5886/6464)
Loss: 0.370 | Acc: 91.045% (11712/12864)
Loss: 0.372 | Acc: 91.066% (17543/19264)
Loss: 0.367 | Acc: 91.194% (23404/25664)
Loss: 0.371 | Acc: 91.080% (29204/32064)
Loss: 0.375 | Acc: 90.971% (34991/38464)
Loss: 0.375 | Acc: 91.013% (40832/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8078, Accuracy: 8209/10000 (82.09%)
torch.Size([100, 10])
Test set: Average loss: 0.8078, Accuracy: 8209/10000 (82.09%)

Epoch: 148
Loss: 0.178 | Acc: 96.875% (62/64)
Loss: 0.371 | Acc: 90.981% (5881/6464)
Loss: 0.378 | Acc: 90.835% (11685/12864)
Loss: 0.379 | Acc: 90.885% (17508/19264)
Loss: 0.374 | Acc: 91.093% (23378/25664)
Loss: 0.377 | Acc: 91.005% (29180/32064)
Loss: 0.380 | Acc: 90.966% (34989/38464)
Loss: 0.382 | Acc: 90.895% (40779/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8104, Accuracy: 8162/10000 (81.62%)
torch.Size([100, 10])
Test set: Average loss: 0.8104, Accuracy: 8162/10000 (81.62%)

Epoch: 149
Loss: 0.494 | Acc: 85.938% (55/64)
Loss: 0.390 | Acc: 90.579% (5855/6464)
Loss: 0.378 | Acc: 91.091% (11718/12864)
Loss: 0.376 | Acc: 91.175% (17564/19264)
Loss: 0.378 | Acc: 91.112% (23383/25664)
Loss: 0.377 | Acc: 91.083% (29205/32064)
Loss: 0.383 | Acc: 90.875% (34954/38464)
Loss: 0.381 | Acc: 90.933% (40796/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8107, Accuracy: 8177/10000 (81.77%)
torch.Size([100, 10])
Test set: Average loss: 0.8107, Accuracy: 8177/10000 (81.77%)

Epoch: 150
Loss: 0.231 | Acc: 95.312% (61/64)
Loss: 1.701 | Acc: 41.708% (2696/6464)
Loss: 1.403 | Acc: 54.563% (7019/12864)
Loss: 1.277 | Acc: 59.884% (11536/19264)
Loss: 1.197 | Acc: 63.310% (16248/25664)
Loss: 1.138 | Acc: 65.768% (21088/32064)
Loss: 1.097 | Acc: 67.432% (25937/38464)
Loss: 1.067 | Acc: 68.734% (30837/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5074, Accuracy: 5555/10000 (55.55%)

Epoch: 151
Loss: 0.697 | Acc: 81.250% (52/64)
Loss: 0.838 | Acc: 77.058% (4981/6464)
Loss: 0.839 | Acc: 77.285% (9942/12864)
Loss: 0.850 | Acc: 77.097% (14852/19264)
Loss: 0.846 | Acc: 77.186% (19809/25664)
Loss: 0.839 | Acc: 77.498% (24849/32064)
Loss: 0.839 | Acc: 77.558% (29832/38464)
Loss: 0.837 | Acc: 77.695% (34857/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8377, Accuracy: 4881/10000 (48.81%)

Epoch: 152
Loss: 0.803 | Acc: 78.125% (50/64)
Loss: 0.795 | Acc: 79.270% (5124/6464)
Loss: 0.783 | Acc: 79.711% (10254/12864)
Loss: 0.797 | Acc: 79.335% (15283/19264)
Loss: 0.799 | Acc: 79.119% (20305/25664)
Loss: 0.806 | Acc: 78.948% (25314/32064)
Loss: 0.809 | Acc: 78.975% (30377/38464)
Loss: 0.808 | Acc: 78.943% (35417/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6559, Accuracy: 5405/10000 (54.05%)

Epoch: 153
Loss: 0.969 | Acc: 68.750% (44/64)
Loss: 0.789 | Acc: 79.347% (5129/6464)
Loss: 0.777 | Acc: 79.820% (10268/12864)
Loss: 0.786 | Acc: 79.604% (15335/19264)
Loss: 0.784 | Acc: 79.738% (20464/25664)
Loss: 0.789 | Acc: 79.684% (25550/32064)
Loss: 0.791 | Acc: 79.591% (30614/38464)
Loss: 0.793 | Acc: 79.514% (35673/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2401, Accuracy: 6487/10000 (64.87%)

Epoch: 154
Loss: 0.918 | Acc: 76.562% (49/64)
Loss: 0.783 | Acc: 79.827% (5160/6464)
Loss: 0.794 | Acc: 79.415% (10216/12864)
Loss: 0.787 | Acc: 79.693% (15352/19264)
Loss: 0.787 | Acc: 79.726% (20461/25664)
Loss: 0.788 | Acc: 79.753% (25572/32064)
Loss: 0.788 | Acc: 79.732% (30668/38464)
Loss: 0.786 | Acc: 79.873% (35834/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2335, Accuracy: 6476/10000 (64.76%)

Epoch: 155
Loss: 0.939 | Acc: 73.438% (47/64)
Loss: 0.791 | Acc: 79.471% (5137/6464)
Loss: 0.791 | Acc: 79.548% (10233/12864)
Loss: 0.786 | Acc: 79.776% (15368/19264)
Loss: 0.786 | Acc: 79.742% (20465/25664)
Loss: 0.783 | Acc: 79.812% (25591/32064)
Loss: 0.787 | Acc: 79.726% (30666/38464)
Loss: 0.789 | Acc: 79.641% (35730/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9455, Accuracy: 7513/10000 (75.13%)

Epoch: 156
Loss: 0.534 | Acc: 87.500% (56/64)
Loss: 0.777 | Acc: 79.904% (5165/6464)
Loss: 0.773 | Acc: 80.115% (10306/12864)
Loss: 0.771 | Acc: 80.087% (15428/19264)
Loss: 0.771 | Acc: 80.073% (20550/25664)
Loss: 0.777 | Acc: 79.862% (25607/32064)
Loss: 0.782 | Acc: 79.776% (30685/38464)
Loss: 0.781 | Acc: 79.788% (35796/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5284, Accuracy: 5643/10000 (56.43%)

Epoch: 157
Loss: 0.949 | Acc: 70.312% (45/64)
Loss: 0.788 | Acc: 79.858% (5162/6464)
Loss: 0.768 | Acc: 80.216% (10319/12864)
Loss: 0.779 | Acc: 79.957% (15403/19264)
Loss: 0.785 | Acc: 79.828% (20487/25664)
Loss: 0.783 | Acc: 80.027% (25660/32064)
Loss: 0.778 | Acc: 80.116% (30816/38464)
Loss: 0.781 | Acc: 79.979% (35882/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8575, Accuracy: 5181/10000 (51.81%)

Epoch: 158
Loss: 0.884 | Acc: 78.125% (50/64)
Loss: 0.778 | Acc: 80.384% (5196/6464)
Loss: 0.768 | Acc: 80.395% (10342/12864)
Loss: 0.774 | Acc: 80.170% (15444/19264)
Loss: 0.774 | Acc: 80.175% (20576/25664)
Loss: 0.778 | Acc: 80.112% (25687/32064)
Loss: 0.776 | Acc: 80.192% (30845/38464)
Loss: 0.779 | Acc: 80.162% (35964/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0365, Accuracy: 7214/10000 (72.14%)

Epoch: 159
Loss: 0.752 | Acc: 79.688% (51/64)
Loss: 0.753 | Acc: 81.018% (5237/6464)
Loss: 0.755 | Acc: 80.799% (10394/12864)
Loss: 0.757 | Acc: 80.679% (15542/19264)
Loss: 0.757 | Acc: 80.588% (20682/25664)
Loss: 0.759 | Acc: 80.586% (25839/32064)
Loss: 0.764 | Acc: 80.434% (30938/38464)
Loss: 0.769 | Acc: 80.285% (36019/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3117, Accuracy: 6484/10000 (64.84%)

Epoch: 160
Loss: 0.867 | Acc: 78.125% (50/64)
Loss: 0.770 | Acc: 80.600% (5210/6464)
Loss: 0.783 | Acc: 80.131% (10308/12864)
Loss: 0.766 | Acc: 80.471% (15502/19264)
Loss: 0.766 | Acc: 80.319% (20613/25664)
Loss: 0.765 | Acc: 80.461% (25799/32064)
Loss: 0.771 | Acc: 80.324% (30896/38464)
Loss: 0.771 | Acc: 80.298% (36025/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4454, Accuracy: 5820/10000 (58.20%)

Epoch: 161
Loss: 1.332 | Acc: 65.625% (42/64)
Loss: 0.745 | Acc: 80.678% (5215/6464)
Loss: 0.753 | Acc: 80.861% (10402/12864)
Loss: 0.765 | Acc: 80.627% (15532/19264)
Loss: 0.768 | Acc: 80.510% (20662/25664)
Loss: 0.769 | Acc: 80.542% (25825/32064)
Loss: 0.770 | Acc: 80.527% (30974/38464)
Loss: 0.770 | Acc: 80.492% (36112/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4037, Accuracy: 5880/10000 (58.80%)

Epoch: 162
Loss: 0.760 | Acc: 82.812% (53/64)
Loss: 0.750 | Acc: 80.770% (5221/6464)
Loss: 0.750 | Acc: 80.916% (10409/12864)
Loss: 0.753 | Acc: 80.762% (15558/19264)
Loss: 0.756 | Acc: 80.763% (20727/25664)
Loss: 0.759 | Acc: 80.629% (25853/32064)
Loss: 0.760 | Acc: 80.634% (31015/38464)
Loss: 0.762 | Acc: 80.601% (36161/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9887, Accuracy: 7356/10000 (73.56%)

Epoch: 163
Loss: 0.548 | Acc: 85.938% (55/64)
Loss: 0.734 | Acc: 81.250% (5252/6464)
Loss: 0.745 | Acc: 81.328% (10462/12864)
Loss: 0.741 | Acc: 81.556% (15711/19264)
Loss: 0.750 | Acc: 81.184% (20835/25664)
Loss: 0.753 | Acc: 81.032% (25982/32064)
Loss: 0.755 | Acc: 80.925% (31127/38464)
Loss: 0.757 | Acc: 80.853% (36274/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1957, Accuracy: 6712/10000 (67.12%)

Epoch: 164
Loss: 0.929 | Acc: 78.125% (50/64)
Loss: 0.736 | Acc: 81.235% (5251/6464)
Loss: 0.714 | Acc: 82.043% (10554/12864)
Loss: 0.725 | Acc: 81.722% (15743/19264)
Loss: 0.741 | Acc: 81.227% (20846/25664)
Loss: 0.741 | Acc: 81.175% (26028/32064)
Loss: 0.744 | Acc: 81.094% (31192/38464)
Loss: 0.748 | Acc: 80.969% (36326/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0228, Accuracy: 7124/10000 (71.24%)

Epoch: 165
Loss: 0.674 | Acc: 87.500% (56/64)
Loss: 0.751 | Acc: 81.343% (5258/6464)
Loss: 0.744 | Acc: 81.460% (10479/12864)
Loss: 0.739 | Acc: 81.639% (15727/19264)
Loss: 0.741 | Acc: 81.546% (20928/25664)
Loss: 0.741 | Acc: 81.512% (26136/32064)
Loss: 0.737 | Acc: 81.622% (31395/38464)
Loss: 0.739 | Acc: 81.555% (36589/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0803, Accuracy: 4264/10000 (42.64%)

Epoch: 166
Loss: 1.193 | Acc: 68.750% (44/64)
Loss: 0.735 | Acc: 81.900% (5294/6464)
Loss: 0.730 | Acc: 82.004% (10549/12864)
Loss: 0.723 | Acc: 81.972% (15791/19264)
Loss: 0.734 | Acc: 81.663% (20958/25664)
Loss: 0.736 | Acc: 81.553% (26149/32064)
Loss: 0.740 | Acc: 81.476% (31339/38464)
Loss: 0.738 | Acc: 81.567% (36594/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3243, Accuracy: 6181/10000 (61.81%)

Epoch: 167
Loss: 0.605 | Acc: 82.812% (53/64)
Loss: 0.709 | Acc: 82.008% (5301/6464)
Loss: 0.714 | Acc: 82.136% (10566/12864)
Loss: 0.724 | Acc: 82.034% (15803/19264)
Loss: 0.720 | Acc: 82.240% (21106/25664)
Loss: 0.724 | Acc: 82.083% (26319/32064)
Loss: 0.727 | Acc: 81.996% (31539/38464)
Loss: 0.729 | Acc: 82.003% (36790/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3296, Accuracy: 6467/10000 (64.67%)

Epoch: 168
Loss: 0.506 | Acc: 84.375% (54/64)
Loss: 0.707 | Acc: 82.147% (5310/6464)
Loss: 0.721 | Acc: 81.716% (10512/12864)
Loss: 0.727 | Acc: 81.587% (15717/19264)
Loss: 0.725 | Acc: 81.527% (20923/25664)
Loss: 0.729 | Acc: 81.562% (26152/32064)
Loss: 0.730 | Acc: 81.528% (31359/38464)
Loss: 0.728 | Acc: 81.678% (36644/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9522, Accuracy: 7423/10000 (74.23%)

Epoch: 169
Loss: 0.673 | Acc: 79.688% (51/64)
Loss: 0.696 | Acc: 82.642% (5342/6464)
Loss: 0.706 | Acc: 82.525% (10616/12864)
Loss: 0.712 | Acc: 82.366% (15867/19264)
Loss: 0.711 | Acc: 82.361% (21137/25664)
Loss: 0.717 | Acc: 82.201% (26357/32064)
Loss: 0.717 | Acc: 82.228% (31628/38464)
Loss: 0.717 | Acc: 82.269% (36909/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3883, Accuracy: 6041/10000 (60.41%)

Epoch: 170
Loss: 1.022 | Acc: 71.875% (46/64)
Loss: 0.705 | Acc: 82.673% (5344/6464)
Loss: 0.698 | Acc: 82.696% (10638/12864)
Loss: 0.711 | Acc: 82.418% (15877/19264)
Loss: 0.711 | Acc: 82.380% (21142/25664)
Loss: 0.711 | Acc: 82.342% (26402/32064)
Loss: 0.707 | Acc: 82.490% (31729/38464)
Loss: 0.712 | Acc: 82.380% (36959/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2054, Accuracy: 6826/10000 (68.26%)

Epoch: 171
Loss: 0.745 | Acc: 81.250% (52/64)
Loss: 0.681 | Acc: 83.617% (5405/6464)
Loss: 0.689 | Acc: 83.372% (10725/12864)
Loss: 0.694 | Acc: 83.072% (16003/19264)
Loss: 0.699 | Acc: 82.910% (21278/25664)
Loss: 0.696 | Acc: 82.965% (26602/32064)
Loss: 0.698 | Acc: 82.890% (31883/38464)
Loss: 0.696 | Acc: 82.946% (37213/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1781, Accuracy: 6772/10000 (67.72%)

Epoch: 172
Loss: 0.989 | Acc: 75.000% (48/64)
Loss: 0.695 | Acc: 82.905% (5359/6464)
Loss: 0.685 | Acc: 83.271% (10712/12864)
Loss: 0.679 | Acc: 83.456% (16077/19264)
Loss: 0.681 | Acc: 83.350% (21391/25664)
Loss: 0.679 | Acc: 83.430% (26751/32064)
Loss: 0.682 | Acc: 83.278% (32032/38464)
Loss: 0.686 | Acc: 83.203% (37328/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3759, Accuracy: 5918/10000 (59.18%)

Epoch: 173
Loss: 0.577 | Acc: 85.938% (55/64)
Loss: 0.688 | Acc: 82.998% (5365/6464)
Loss: 0.672 | Acc: 83.644% (10760/12864)
Loss: 0.675 | Acc: 83.711% (16126/19264)
Loss: 0.676 | Acc: 83.514% (21433/25664)
Loss: 0.678 | Acc: 83.589% (26802/32064)
Loss: 0.679 | Acc: 83.481% (32110/38464)
Loss: 0.679 | Acc: 83.459% (37443/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0027, Accuracy: 4637/10000 (46.37%)

Epoch: 174
Loss: 0.940 | Acc: 75.000% (48/64)
Loss: 0.661 | Acc: 84.189% (5442/6464)
Loss: 0.659 | Acc: 84.118% (10821/12864)
Loss: 0.663 | Acc: 83.851% (16153/19264)
Loss: 0.674 | Acc: 83.615% (21459/25664)
Loss: 0.671 | Acc: 83.708% (26840/32064)
Loss: 0.670 | Acc: 83.689% (32190/38464)
Loss: 0.673 | Acc: 83.631% (37520/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0122, Accuracy: 7357/10000 (73.57%)

Epoch: 175
Loss: 0.553 | Acc: 87.500% (56/64)
Loss: 0.649 | Acc: 84.623% (5470/6464)
Loss: 0.642 | Acc: 84.639% (10888/12864)
Loss: 0.644 | Acc: 84.609% (16299/19264)
Loss: 0.653 | Acc: 84.410% (21663/25664)
Loss: 0.646 | Acc: 84.487% (27090/32064)
Loss: 0.650 | Acc: 84.401% (32464/38464)
Loss: 0.654 | Acc: 84.272% (37808/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8750, Accuracy: 7786/10000 (77.86%)

Epoch: 176
Loss: 0.753 | Acc: 84.375% (54/64)
Loss: 0.650 | Acc: 84.499% (5462/6464)
Loss: 0.649 | Acc: 84.499% (10870/12864)
Loss: 0.646 | Acc: 84.557% (16289/19264)
Loss: 0.652 | Acc: 84.356% (21649/25664)
Loss: 0.650 | Acc: 84.469% (27084/32064)
Loss: 0.647 | Acc: 84.489% (32498/38464)
Loss: 0.646 | Acc: 84.489% (37905/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4334, Accuracy: 6129/10000 (61.29%)

Epoch: 177
Loss: 0.596 | Acc: 85.938% (55/64)
Loss: 0.655 | Acc: 84.236% (5445/6464)
Loss: 0.633 | Acc: 84.919% (10924/12864)
Loss: 0.633 | Acc: 84.915% (16358/19264)
Loss: 0.637 | Acc: 84.714% (21741/25664)
Loss: 0.641 | Acc: 84.562% (27114/32064)
Loss: 0.647 | Acc: 84.393% (32461/38464)
Loss: 0.643 | Acc: 84.533% (37925/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0020, Accuracy: 7305/10000 (73.05%)

Epoch: 178
Loss: 0.442 | Acc: 85.938% (55/64)
Loss: 0.595 | Acc: 85.922% (5554/6464)
Loss: 0.606 | Acc: 85.720% (11027/12864)
Loss: 0.614 | Acc: 85.476% (16466/19264)
Loss: 0.616 | Acc: 85.396% (21916/25664)
Loss: 0.622 | Acc: 85.270% (27341/32064)
Loss: 0.623 | Acc: 85.215% (32777/38464)
Loss: 0.622 | Acc: 85.260% (38251/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1573, Accuracy: 6890/10000 (68.90%)

Epoch: 179
Loss: 0.637 | Acc: 82.812% (53/64)
Loss: 0.618 | Acc: 85.551% (5530/6464)
Loss: 0.612 | Acc: 85.564% (11007/12864)
Loss: 0.606 | Acc: 85.642% (16498/19264)
Loss: 0.606 | Acc: 85.614% (21972/25664)
Loss: 0.610 | Acc: 85.488% (27411/32064)
Loss: 0.607 | Acc: 85.607% (32928/38464)
Loss: 0.609 | Acc: 85.599% (38403/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9171, Accuracy: 7681/10000 (76.81%)

Epoch: 180
Loss: 0.693 | Acc: 81.250% (52/64)
Loss: 0.587 | Acc: 86.572% (5596/6464)
Loss: 0.595 | Acc: 86.101% (11076/12864)
Loss: 0.591 | Acc: 86.239% (16613/19264)
Loss: 0.588 | Acc: 86.315% (22152/25664)
Loss: 0.594 | Acc: 86.125% (27615/32064)
Loss: 0.595 | Acc: 86.101% (33118/38464)
Loss: 0.593 | Acc: 86.165% (38657/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9883, Accuracy: 7450/10000 (74.50%)

Epoch: 181
Loss: 0.644 | Acc: 87.500% (56/64)
Loss: 0.573 | Acc: 86.386% (5584/6464)
Loss: 0.560 | Acc: 86.598% (11140/12864)
Loss: 0.569 | Acc: 86.498% (16663/19264)
Loss: 0.573 | Acc: 86.526% (22206/25664)
Loss: 0.572 | Acc: 86.655% (27785/32064)
Loss: 0.578 | Acc: 86.502% (33272/38464)
Loss: 0.579 | Acc: 86.414% (38769/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9729, Accuracy: 7574/10000 (75.74%)

Epoch: 182
Loss: 0.568 | Acc: 85.938% (55/64)
Loss: 0.541 | Acc: 87.252% (5640/6464)
Loss: 0.530 | Acc: 87.702% (11282/12864)
Loss: 0.544 | Acc: 87.433% (16843/19264)
Loss: 0.550 | Acc: 87.219% (22384/25664)
Loss: 0.558 | Acc: 87.035% (27907/32064)
Loss: 0.558 | Acc: 87.053% (33484/38464)
Loss: 0.559 | Acc: 87.039% (39049/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8146, Accuracy: 8079/10000 (80.79%)

Epoch: 183
Loss: 0.505 | Acc: 90.625% (58/64)
Loss: 0.506 | Acc: 88.506% (5721/6464)
Loss: 0.529 | Acc: 87.865% (11303/12864)
Loss: 0.541 | Acc: 87.578% (16871/19264)
Loss: 0.542 | Acc: 87.484% (22452/25664)
Loss: 0.542 | Acc: 87.488% (28052/32064)
Loss: 0.543 | Acc: 87.406% (33620/38464)
Loss: 0.543 | Acc: 87.442% (39230/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8536, Accuracy: 7941/10000 (79.41%)

Epoch: 184
Loss: 0.648 | Acc: 84.375% (54/64)
Loss: 0.515 | Acc: 88.212% (5702/6464)
Loss: 0.522 | Acc: 87.912% (11309/12864)
Loss: 0.529 | Acc: 87.749% (16904/19264)
Loss: 0.526 | Acc: 87.874% (22552/25664)
Loss: 0.525 | Acc: 87.880% (28178/32064)
Loss: 0.524 | Acc: 87.890% (33806/38464)
Loss: 0.525 | Acc: 87.850% (39413/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8176, Accuracy: 8061/10000 (80.61%)

Epoch: 185
Loss: 0.537 | Acc: 87.500% (56/64)
Loss: 0.491 | Acc: 88.444% (5717/6464)
Loss: 0.486 | Acc: 88.619% (11400/12864)
Loss: 0.491 | Acc: 88.543% (17057/19264)
Loss: 0.501 | Acc: 88.252% (22649/25664)
Loss: 0.501 | Acc: 88.267% (28302/32064)
Loss: 0.500 | Acc: 88.342% (33980/38464)
Loss: 0.504 | Acc: 88.265% (39599/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8267, Accuracy: 8084/10000 (80.84%)

Epoch: 186
Loss: 0.283 | Acc: 93.750% (60/64)
Loss: 0.462 | Acc: 89.310% (5773/6464)
Loss: 0.470 | Acc: 89.210% (11476/12864)
Loss: 0.471 | Acc: 89.177% (17179/19264)
Loss: 0.477 | Acc: 88.992% (22839/25664)
Loss: 0.481 | Acc: 88.872% (28496/32064)
Loss: 0.481 | Acc: 88.904% (34196/38464)
Loss: 0.480 | Acc: 88.911% (39889/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8840, Accuracy: 7973/10000 (79.73%)

Epoch: 187
Loss: 0.281 | Acc: 95.312% (61/64)
Loss: 0.439 | Acc: 89.805% (5805/6464)
Loss: 0.439 | Acc: 89.785% (11550/12864)
Loss: 0.446 | Acc: 89.639% (17268/19264)
Loss: 0.451 | Acc: 89.624% (23001/25664)
Loss: 0.451 | Acc: 89.574% (28721/32064)
Loss: 0.455 | Acc: 89.489% (34421/38464)
Loss: 0.455 | Acc: 89.504% (40155/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8397, Accuracy: 8158/10000 (81.58%)

Epoch: 188
Loss: 0.522 | Acc: 85.938% (55/64)
Loss: 0.422 | Acc: 89.898% (5811/6464)
Loss: 0.422 | Acc: 89.980% (11575/12864)
Loss: 0.427 | Acc: 90.023% (17342/19264)
Loss: 0.429 | Acc: 90.002% (23098/25664)
Loss: 0.430 | Acc: 89.998% (28857/32064)
Loss: 0.429 | Acc: 90.058% (34640/38464)
Loss: 0.429 | Acc: 90.043% (40397/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8142, Accuracy: 8226/10000 (82.26%)

Epoch: 189
Loss: 0.215 | Acc: 93.750% (60/64)
Loss: 0.371 | Acc: 91.414% (5909/6464)
Loss: 0.386 | Acc: 91.045% (11712/12864)
Loss: 0.387 | Acc: 91.051% (17540/19264)
Loss: 0.393 | Acc: 90.886% (23325/25664)
Loss: 0.395 | Acc: 90.821% (29121/32064)
Loss: 0.397 | Acc: 90.713% (34892/38464)
Loss: 0.399 | Acc: 90.658% (40673/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8054, Accuracy: 8278/10000 (82.78%)

Epoch: 190
Loss: 0.501 | Acc: 87.500% (56/64)
Loss: 0.358 | Acc: 91.399% (5908/6464)
Loss: 0.356 | Acc: 91.604% (11784/12864)
Loss: 0.364 | Acc: 91.440% (17615/19264)
Loss: 0.365 | Acc: 91.381% (23452/25664)
Loss: 0.363 | Acc: 91.423% (29314/32064)
Loss: 0.363 | Acc: 91.418% (35163/38464)
Loss: 0.365 | Acc: 91.367% (40991/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9191, Accuracy: 8025/10000 (80.25%)

Epoch: 191
Loss: 0.306 | Acc: 92.188% (59/64)
Loss: 0.327 | Acc: 92.064% (5951/6464)
Loss: 0.322 | Acc: 92.281% (11871/12864)
Loss: 0.325 | Acc: 92.156% (17753/19264)
Loss: 0.327 | Acc: 92.082% (23632/25664)
Loss: 0.329 | Acc: 92.007% (29501/32064)
Loss: 0.334 | Acc: 91.860% (35333/38464)
Loss: 0.333 | Acc: 91.875% (41219/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8825, Accuracy: 8180/10000 (81.80%)

Epoch: 192
Loss: 0.134 | Acc: 96.875% (62/64)
Loss: 0.299 | Acc: 92.543% (5982/6464)
Loss: 0.296 | Acc: 92.708% (11926/12864)
Loss: 0.296 | Acc: 92.649% (17848/19264)
Loss: 0.299 | Acc: 92.558% (23754/25664)
Loss: 0.302 | Acc: 92.518% (29665/32064)
Loss: 0.301 | Acc: 92.564% (35604/38464)
Loss: 0.303 | Acc: 92.526% (41511/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8926, Accuracy: 8266/10000 (82.66%)

Epoch: 193
Loss: 0.221 | Acc: 93.750% (60/64)
Loss: 0.272 | Acc: 93.410% (6038/6464)
Loss: 0.266 | Acc: 93.307% (12003/12864)
Loss: 0.266 | Acc: 93.304% (17974/19264)
Loss: 0.268 | Acc: 93.279% (23939/25664)
Loss: 0.265 | Acc: 93.354% (29933/32064)
Loss: 0.264 | Acc: 93.370% (35914/38464)
Loss: 0.262 | Acc: 93.418% (41911/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9381, Accuracy: 8213/10000 (82.13%)

Epoch: 194
Loss: 0.236 | Acc: 93.750% (60/64)
Loss: 0.232 | Acc: 93.936% (6072/6464)
Loss: 0.237 | Acc: 93.859% (12074/12864)
Loss: 0.233 | Acc: 93.890% (18087/19264)
Loss: 0.234 | Acc: 93.844% (24084/25664)
Loss: 0.235 | Acc: 93.834% (30087/32064)
Loss: 0.237 | Acc: 93.799% (36079/38464)
Loss: 0.236 | Acc: 93.853% (42106/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9582, Accuracy: 8241/10000 (82.41%)

Epoch: 195
Loss: 0.318 | Acc: 93.750% (60/64)
Loss: 0.213 | Acc: 94.291% (6095/6464)
Loss: 0.225 | Acc: 94.084% (12103/12864)
Loss: 0.237 | Acc: 93.734% (18057/19264)
Loss: 0.246 | Acc: 93.621% (24027/25664)
Loss: 0.255 | Acc: 93.432% (29958/32064)
Loss: 0.263 | Acc: 93.264% (35873/38464)
Loss: 0.270 | Acc: 93.128% (41781/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8361, Accuracy: 8262/10000 (82.62%)

Epoch: 196
Loss: 0.539 | Acc: 87.500% (56/64)
Loss: 0.309 | Acc: 92.543% (5982/6464)
Loss: 0.316 | Acc: 92.226% (11864/12864)
Loss: 0.327 | Acc: 91.954% (17714/19264)
Loss: 0.328 | Acc: 91.942% (23596/25664)
Loss: 0.328 | Acc: 92.013% (29503/32064)
Loss: 0.334 | Acc: 91.876% (35339/38464)
Loss: 0.338 | Acc: 91.744% (41160/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8116, Accuracy: 8239/10000 (82.39%)

Epoch: 197
Loss: 0.195 | Acc: 95.312% (61/64)
Loss: 0.348 | Acc: 91.615% (5922/6464)
Loss: 0.352 | Acc: 91.566% (11779/12864)
Loss: 0.353 | Acc: 91.461% (17619/19264)
Loss: 0.359 | Acc: 91.299% (23431/25664)
Loss: 0.363 | Acc: 91.196% (29241/32064)
Loss: 0.363 | Acc: 91.202% (35080/38464)
Loss: 0.367 | Acc: 91.113% (40877/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8056, Accuracy: 8248/10000 (82.48%)
torch.Size([100, 10])
Test set: Average loss: 0.8056, Accuracy: 8248/10000 (82.48%)

Epoch: 198
Loss: 0.474 | Acc: 85.938% (55/64)
Loss: 0.382 | Acc: 90.718% (5864/6464)
Loss: 0.374 | Acc: 90.928% (11697/12864)
Loss: 0.372 | Acc: 90.999% (17530/19264)
Loss: 0.374 | Acc: 90.886% (23325/25664)
Loss: 0.377 | Acc: 90.818% (29120/32064)
Loss: 0.377 | Acc: 90.807% (34928/38464)
Loss: 0.376 | Acc: 90.828% (40749/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8021, Accuracy: 8259/10000 (82.59%)
torch.Size([100, 10])
Test set: Average loss: 0.8021, Accuracy: 8259/10000 (82.59%)

Epoch: 199
Loss: 0.176 | Acc: 98.438% (63/64)
Loss: 0.379 | Acc: 91.027% (5884/6464)
Loss: 0.375 | Acc: 90.944% (11699/12864)
Loss: 0.375 | Acc: 90.895% (17510/19264)
Loss: 0.375 | Acc: 90.917% (23333/25664)
Loss: 0.375 | Acc: 90.959% (29165/32064)
Loss: 0.371 | Acc: 91.046% (35020/38464)
Loss: 0.372 | Acc: 90.999% (40826/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8038, Accuracy: 8255/10000 (82.55%)
torch.Size([100, 10])
Test set: Average loss: 0.8038, Accuracy: 8255/10000 (82.55%)
8469
10000
-0.7072888612747192
