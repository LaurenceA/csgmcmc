==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.358 | Acc: 15.625% (10/64)
Loss: 3.082 | Acc: 14.821% (958/6464)
Loss: 2.603 | Acc: 17.506% (2252/12864)
Loss: 2.430 | Acc: 18.610% (3585/19264)
Loss: 2.331 | Acc: 20.153% (5172/25664)
Loss: 2.265 | Acc: 21.448% (6877/32064)
Loss: 2.217 | Acc: 22.494% (8652/38464)
Loss: 2.174 | Acc: 23.571% (10575/44864)
torch.Size([100, 10])
Test set: Average loss: 7.1851, Accuracy: 1419/10000 (14.19%)

Epoch: 1
Loss: 2.237 | Acc: 21.875% (14/64)
Loss: 1.883 | Acc: 31.018% (2005/6464)
Loss: 1.864 | Acc: 32.237% (4147/12864)
Loss: 1.846 | Acc: 32.890% (6336/19264)
Loss: 1.834 | Acc: 33.529% (8605/25664)
Loss: 1.822 | Acc: 34.172% (10957/32064)
Loss: 1.811 | Acc: 34.638% (13323/38464)
Loss: 1.799 | Acc: 35.403% (15883/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9021, Accuracy: 3420/10000 (34.20%)

Epoch: 2
Loss: 1.430 | Acc: 50.000% (32/64)
Loss: 1.682 | Acc: 40.718% (2632/6464)
Loss: 1.680 | Acc: 40.711% (5237/12864)
Loss: 1.668 | Acc: 41.528% (8000/19264)
Loss: 1.654 | Acc: 42.219% (10835/25664)
Loss: 1.644 | Acc: 42.696% (13690/32064)
Loss: 1.637 | Acc: 43.170% (16605/38464)
Loss: 1.631 | Acc: 43.422% (19481/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7129, Accuracy: 4152/10000 (41.52%)

Epoch: 3
Loss: 1.632 | Acc: 35.938% (23/64)
Loss: 1.547 | Acc: 47.293% (3057/6464)
Loss: 1.555 | Acc: 47.419% (6100/12864)
Loss: 1.537 | Acc: 48.100% (9266/19264)
Loss: 1.524 | Acc: 48.609% (12475/25664)
Loss: 1.513 | Acc: 49.158% (15762/32064)
Loss: 1.500 | Acc: 49.561% (19063/38464)
Loss: 1.490 | Acc: 50.011% (22437/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3094, Accuracy: 3159/10000 (31.59%)

Epoch: 4
Loss: 1.828 | Acc: 37.500% (24/64)
Loss: 1.409 | Acc: 54.517% (3524/6464)
Loss: 1.387 | Acc: 55.084% (7086/12864)
Loss: 1.376 | Acc: 55.419% (10676/19264)
Loss: 1.366 | Acc: 55.868% (14338/25664)
Loss: 1.358 | Acc: 56.169% (18010/32064)
Loss: 1.346 | Acc: 56.674% (21799/38464)
Loss: 1.339 | Acc: 57.030% (25586/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5829, Accuracy: 4771/10000 (47.71%)

Epoch: 5
Loss: 1.630 | Acc: 53.125% (34/64)
Loss: 1.236 | Acc: 60.644% (3920/6464)
Loss: 1.254 | Acc: 60.253% (7751/12864)
Loss: 1.245 | Acc: 60.875% (11727/19264)
Loss: 1.240 | Acc: 61.109% (15683/25664)
Loss: 1.230 | Acc: 61.549% (19735/32064)
Loss: 1.226 | Acc: 61.837% (23785/38464)
Loss: 1.219 | Acc: 62.168% (27891/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7946, Accuracy: 4612/10000 (46.12%)

Epoch: 6
Loss: 1.299 | Acc: 57.812% (37/64)
Loss: 1.153 | Acc: 65.114% (4209/6464)
Loss: 1.153 | Acc: 65.283% (8398/12864)
Loss: 1.142 | Acc: 65.495% (12617/19264)
Loss: 1.137 | Acc: 65.738% (16871/25664)
Loss: 1.128 | Acc: 66.015% (21167/32064)
Loss: 1.128 | Acc: 66.103% (25426/38464)
Loss: 1.126 | Acc: 66.205% (29702/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6141, Accuracy: 5130/10000 (51.30%)

Epoch: 7
Loss: 1.293 | Acc: 57.812% (37/64)
Loss: 1.072 | Acc: 68.317% (4416/6464)
Loss: 1.081 | Acc: 67.934% (8739/12864)
Loss: 1.082 | Acc: 68.189% (13136/19264)
Loss: 1.076 | Acc: 68.508% (17582/25664)
Loss: 1.070 | Acc: 68.688% (22024/32064)
Loss: 1.069 | Acc: 68.706% (26427/38464)
Loss: 1.063 | Acc: 68.850% (30889/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1266, Accuracy: 6726/10000 (67.26%)

Epoch: 8
Loss: 1.110 | Acc: 68.750% (44/64)
Loss: 1.037 | Acc: 69.508% (4493/6464)
Loss: 1.031 | Acc: 69.776% (8976/12864)
Loss: 1.029 | Acc: 70.214% (13526/19264)
Loss: 1.023 | Acc: 70.613% (18122/25664)
Loss: 1.017 | Acc: 70.743% (22683/32064)
Loss: 1.019 | Acc: 70.689% (27190/38464)
Loss: 1.016 | Acc: 70.767% (31749/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2435, Accuracy: 6314/10000 (63.14%)

Epoch: 9
Loss: 1.242 | Acc: 60.938% (39/64)
Loss: 0.975 | Acc: 72.540% (4689/6464)
Loss: 0.995 | Acc: 71.883% (9247/12864)
Loss: 0.994 | Acc: 71.714% (13815/19264)
Loss: 0.988 | Acc: 71.789% (18424/25664)
Loss: 0.990 | Acc: 71.791% (23019/32064)
Loss: 0.988 | Acc: 71.854% (27638/38464)
Loss: 0.983 | Acc: 72.020% (32311/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3485, Accuracy: 5870/10000 (58.70%)

Epoch: 10
Loss: 0.967 | Acc: 70.312% (45/64)
Loss: 0.977 | Acc: 72.416% (4681/6464)
Loss: 0.965 | Acc: 72.878% (9375/12864)
Loss: 0.968 | Acc: 72.783% (14021/19264)
Loss: 0.959 | Acc: 72.752% (18671/25664)
Loss: 0.962 | Acc: 72.885% (23370/32064)
Loss: 0.963 | Acc: 72.871% (28029/38464)
Loss: 0.963 | Acc: 72.887% (32700/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4072, Accuracy: 5966/10000 (59.66%)

Epoch: 11
Loss: 1.035 | Acc: 68.750% (44/64)
Loss: 0.949 | Acc: 73.407% (4745/6464)
Loss: 0.948 | Acc: 73.593% (9467/12864)
Loss: 0.931 | Acc: 74.102% (14275/19264)
Loss: 0.934 | Acc: 73.995% (18990/25664)
Loss: 0.936 | Acc: 73.977% (23720/32064)
Loss: 0.937 | Acc: 73.916% (28431/38464)
Loss: 0.940 | Acc: 73.870% (33141/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1707, Accuracy: 6596/10000 (65.96%)

Epoch: 12
Loss: 0.966 | Acc: 73.438% (47/64)
Loss: 0.918 | Acc: 75.155% (4858/6464)
Loss: 0.919 | Acc: 75.210% (9675/12864)
Loss: 0.918 | Acc: 75.073% (14462/19264)
Loss: 0.919 | Acc: 74.860% (19212/25664)
Loss: 0.918 | Acc: 74.925% (24024/32064)
Loss: 0.919 | Acc: 74.841% (28787/38464)
Loss: 0.923 | Acc: 74.695% (33511/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7924, Accuracy: 4744/10000 (47.44%)

Epoch: 13
Loss: 1.178 | Acc: 64.062% (41/64)
Loss: 0.915 | Acc: 75.557% (4884/6464)
Loss: 0.911 | Acc: 75.389% (9698/12864)
Loss: 0.908 | Acc: 75.374% (14520/19264)
Loss: 0.911 | Acc: 75.160% (19289/25664)
Loss: 0.903 | Acc: 75.446% (24191/32064)
Loss: 0.903 | Acc: 75.385% (28996/38464)
Loss: 0.903 | Acc: 75.392% (33824/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2696, Accuracy: 6174/10000 (61.74%)

Epoch: 14
Loss: 1.158 | Acc: 64.062% (41/64)
Loss: 0.932 | Acc: 74.087% (4789/6464)
Loss: 0.915 | Acc: 74.720% (9612/12864)
Loss: 0.900 | Acc: 75.109% (14469/19264)
Loss: 0.895 | Acc: 75.390% (19348/25664)
Loss: 0.891 | Acc: 75.505% (24210/32064)
Loss: 0.888 | Acc: 75.666% (29104/38464)
Loss: 0.890 | Acc: 75.684% (33955/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7189, Accuracy: 4979/10000 (49.79%)

Epoch: 15
Loss: 1.159 | Acc: 64.062% (41/64)
Loss: 0.862 | Acc: 76.562% (4949/6464)
Loss: 0.875 | Acc: 76.391% (9827/12864)
Loss: 0.886 | Acc: 76.033% (14647/19264)
Loss: 0.879 | Acc: 76.290% (19579/25664)
Loss: 0.878 | Acc: 76.388% (24493/32064)
Loss: 0.879 | Acc: 76.243% (29326/38464)
Loss: 0.878 | Acc: 76.284% (34224/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0485, Accuracy: 7034/10000 (70.34%)

Epoch: 16
Loss: 0.866 | Acc: 73.438% (47/64)
Loss: 0.848 | Acc: 77.614% (5017/6464)
Loss: 0.849 | Acc: 77.589% (9981/12864)
Loss: 0.848 | Acc: 77.538% (14937/19264)
Loss: 0.853 | Acc: 77.155% (19801/25664)
Loss: 0.854 | Acc: 77.208% (24756/32064)
Loss: 0.857 | Acc: 77.179% (29686/38464)
Loss: 0.854 | Acc: 77.218% (34643/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5173, Accuracy: 5808/10000 (58.08%)

Epoch: 17
Loss: 1.040 | Acc: 65.625% (42/64)
Loss: 0.832 | Acc: 77.939% (5038/6464)
Loss: 0.847 | Acc: 77.425% (9960/12864)
Loss: 0.852 | Acc: 77.243% (14880/19264)
Loss: 0.847 | Acc: 77.443% (19875/25664)
Loss: 0.845 | Acc: 77.579% (24875/32064)
Loss: 0.846 | Acc: 77.436% (29785/38464)
Loss: 0.845 | Acc: 77.418% (34733/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1219, Accuracy: 6815/10000 (68.15%)

Epoch: 18
Loss: 0.673 | Acc: 78.125% (50/64)
Loss: 0.816 | Acc: 78.140% (5051/6464)
Loss: 0.818 | Acc: 78.335% (10077/12864)
Loss: 0.825 | Acc: 78.099% (15045/19264)
Loss: 0.830 | Acc: 78.008% (20020/25664)
Loss: 0.830 | Acc: 78.116% (25047/32064)
Loss: 0.831 | Acc: 78.050% (30021/38464)
Loss: 0.833 | Acc: 77.969% (34980/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0213, Accuracy: 7146/10000 (71.46%)

Epoch: 19
Loss: 1.060 | Acc: 73.438% (47/64)
Loss: 0.813 | Acc: 78.620% (5082/6464)
Loss: 0.811 | Acc: 78.553% (10105/12864)
Loss: 0.807 | Acc: 78.763% (15173/19264)
Loss: 0.810 | Acc: 78.694% (20196/25664)
Loss: 0.814 | Acc: 78.534% (25181/32064)
Loss: 0.815 | Acc: 78.554% (30215/38464)
Loss: 0.815 | Acc: 78.551% (35241/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0481, Accuracy: 7053/10000 (70.53%)

Epoch: 20
Loss: 0.660 | Acc: 84.375% (54/64)
Loss: 0.807 | Acc: 78.713% (5088/6464)
Loss: 0.807 | Acc: 79.066% (10171/12864)
Loss: 0.804 | Acc: 79.059% (15230/19264)
Loss: 0.806 | Acc: 79.048% (20287/25664)
Loss: 0.801 | Acc: 79.248% (25410/32064)
Loss: 0.805 | Acc: 79.123% (30434/38464)
Loss: 0.805 | Acc: 79.112% (35493/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1798, Accuracy: 6585/10000 (65.85%)

Epoch: 21
Loss: 0.846 | Acc: 78.125% (50/64)
Loss: 0.781 | Acc: 79.378% (5131/6464)
Loss: 0.787 | Acc: 79.143% (10181/12864)
Loss: 0.784 | Acc: 79.272% (15271/19264)
Loss: 0.793 | Acc: 79.134% (20309/25664)
Loss: 0.792 | Acc: 79.301% (25427/32064)
Loss: 0.791 | Acc: 79.321% (30510/38464)
Loss: 0.791 | Acc: 79.369% (35608/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0088, Accuracy: 7239/10000 (72.39%)

Epoch: 22
Loss: 0.677 | Acc: 82.812% (53/64)
Loss: 0.779 | Acc: 80.059% (5175/6464)
Loss: 0.789 | Acc: 79.641% (10245/12864)
Loss: 0.781 | Acc: 79.828% (15378/19264)
Loss: 0.790 | Acc: 79.504% (20404/25664)
Loss: 0.779 | Acc: 79.747% (25570/32064)
Loss: 0.778 | Acc: 79.685% (30650/38464)
Loss: 0.778 | Acc: 79.725% (35768/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9992, Accuracy: 7276/10000 (72.76%)

Epoch: 23
Loss: 0.784 | Acc: 81.250% (52/64)
Loss: 0.727 | Acc: 82.008% (5301/6464)
Loss: 0.758 | Acc: 80.784% (10392/12864)
Loss: 0.764 | Acc: 80.596% (15526/19264)
Loss: 0.762 | Acc: 80.514% (20663/25664)
Loss: 0.764 | Acc: 80.402% (25780/32064)
Loss: 0.764 | Acc: 80.431% (30937/38464)
Loss: 0.764 | Acc: 80.421% (36080/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1751, Accuracy: 6595/10000 (65.95%)

Epoch: 24
Loss: 0.879 | Acc: 78.125% (50/64)
Loss: 0.750 | Acc: 80.755% (5220/6464)
Loss: 0.762 | Acc: 80.473% (10352/12864)
Loss: 0.757 | Acc: 80.606% (15528/19264)
Loss: 0.758 | Acc: 80.580% (20680/25664)
Loss: 0.755 | Acc: 80.598% (25843/32064)
Loss: 0.753 | Acc: 80.662% (31026/38464)
Loss: 0.756 | Acc: 80.601% (36161/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5561, Accuracy: 5731/10000 (57.31%)

Epoch: 25
Loss: 0.929 | Acc: 76.562% (49/64)
Loss: 0.746 | Acc: 81.296% (5255/6464)
Loss: 0.755 | Acc: 81.025% (10423/12864)
Loss: 0.743 | Acc: 81.323% (15666/19264)
Loss: 0.740 | Acc: 81.347% (20877/25664)
Loss: 0.739 | Acc: 81.450% (26116/32064)
Loss: 0.741 | Acc: 81.385% (31304/38464)
Loss: 0.740 | Acc: 81.353% (36498/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3741, Accuracy: 5996/10000 (59.96%)

Epoch: 26
Loss: 0.609 | Acc: 87.500% (56/64)
Loss: 0.732 | Acc: 81.575% (5273/6464)
Loss: 0.730 | Acc: 81.623% (10500/12864)
Loss: 0.721 | Acc: 81.992% (15795/19264)
Loss: 0.732 | Acc: 81.608% (20944/25664)
Loss: 0.731 | Acc: 81.621% (26171/32064)
Loss: 0.729 | Acc: 81.721% (31433/38464)
Loss: 0.725 | Acc: 81.807% (36702/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9632, Accuracy: 7422/10000 (74.22%)

Epoch: 27
Loss: 0.709 | Acc: 79.688% (51/64)
Loss: 0.746 | Acc: 81.142% (5245/6464)
Loss: 0.716 | Acc: 82.191% (10573/12864)
Loss: 0.716 | Acc: 81.992% (15795/19264)
Loss: 0.713 | Acc: 82.185% (21092/25664)
Loss: 0.709 | Acc: 82.367% (26410/32064)
Loss: 0.712 | Acc: 82.303% (31657/38464)
Loss: 0.715 | Acc: 82.193% (36875/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1089, Accuracy: 7028/10000 (70.28%)

Epoch: 28
Loss: 0.959 | Acc: 73.438% (47/64)
Loss: 0.687 | Acc: 82.766% (5350/6464)
Loss: 0.705 | Acc: 82.416% (10602/12864)
Loss: 0.693 | Acc: 82.724% (15936/19264)
Loss: 0.696 | Acc: 82.719% (21229/25664)
Loss: 0.694 | Acc: 82.685% (26512/32064)
Loss: 0.701 | Acc: 82.558% (31755/38464)
Loss: 0.701 | Acc: 82.625% (37069/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2782, Accuracy: 6284/10000 (62.84%)

Epoch: 29
Loss: 0.657 | Acc: 79.688% (51/64)
Loss: 0.666 | Acc: 83.617% (5405/6464)
Loss: 0.673 | Acc: 83.442% (10734/12864)
Loss: 0.667 | Acc: 83.607% (16106/19264)
Loss: 0.678 | Acc: 83.350% (21391/25664)
Loss: 0.680 | Acc: 83.290% (26706/32064)
Loss: 0.681 | Acc: 83.286% (32035/38464)
Loss: 0.680 | Acc: 83.283% (37364/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9685, Accuracy: 7351/10000 (73.51%)

Epoch: 30
Loss: 1.035 | Acc: 73.438% (47/64)
Loss: 0.654 | Acc: 84.437% (5458/6464)
Loss: 0.667 | Acc: 83.877% (10790/12864)
Loss: 0.663 | Acc: 83.908% (16164/19264)
Loss: 0.659 | Acc: 83.946% (21544/25664)
Loss: 0.668 | Acc: 83.733% (26848/32064)
Loss: 0.669 | Acc: 83.748% (32213/38464)
Loss: 0.672 | Acc: 83.704% (37553/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0298, Accuracy: 7217/10000 (72.17%)

Epoch: 31
Loss: 0.461 | Acc: 85.938% (55/64)
Loss: 0.633 | Acc: 84.870% (5486/6464)
Loss: 0.651 | Acc: 84.204% (10832/12864)
Loss: 0.658 | Acc: 84.110% (16203/19264)
Loss: 0.655 | Acc: 84.126% (21590/25664)
Loss: 0.658 | Acc: 84.032% (26944/32064)
Loss: 0.657 | Acc: 84.058% (32332/38464)
Loss: 0.659 | Acc: 84.043% (37705/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8599, Accuracy: 7810/10000 (78.10%)

Epoch: 32
Loss: 0.814 | Acc: 81.250% (52/64)
Loss: 0.633 | Acc: 85.195% (5507/6464)
Loss: 0.632 | Acc: 85.005% (10935/12864)
Loss: 0.635 | Acc: 84.790% (16334/19264)
Loss: 0.629 | Acc: 85.041% (21825/25664)
Loss: 0.630 | Acc: 85.027% (27263/32064)
Loss: 0.633 | Acc: 84.965% (32681/38464)
Loss: 0.632 | Acc: 84.990% (38130/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8551, Accuracy: 7806/10000 (78.06%)

Epoch: 33
Loss: 0.509 | Acc: 87.500% (56/64)
Loss: 0.582 | Acc: 85.814% (5547/6464)
Loss: 0.603 | Acc: 85.440% (10991/12864)
Loss: 0.606 | Acc: 85.460% (16463/19264)
Loss: 0.612 | Acc: 85.380% (21912/25664)
Loss: 0.605 | Acc: 85.591% (27444/32064)
Loss: 0.611 | Acc: 85.457% (32870/38464)
Loss: 0.612 | Acc: 85.483% (38351/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8487, Accuracy: 7866/10000 (78.66%)

Epoch: 34
Loss: 0.724 | Acc: 85.938% (55/64)
Loss: 0.579 | Acc: 86.293% (5578/6464)
Loss: 0.580 | Acc: 86.124% (11079/12864)
Loss: 0.583 | Acc: 86.026% (16572/19264)
Loss: 0.587 | Acc: 85.938% (22055/25664)
Loss: 0.591 | Acc: 85.881% (27537/32064)
Loss: 0.592 | Acc: 85.849% (33021/38464)
Loss: 0.595 | Acc: 85.855% (38518/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8495, Accuracy: 7885/10000 (78.85%)

Epoch: 35
Loss: 0.495 | Acc: 90.625% (58/64)
Loss: 0.548 | Acc: 86.819% (5612/6464)
Loss: 0.573 | Acc: 86.451% (11121/12864)
Loss: 0.571 | Acc: 86.493% (16662/19264)
Loss: 0.567 | Acc: 86.619% (22230/25664)
Loss: 0.567 | Acc: 86.642% (27781/32064)
Loss: 0.572 | Acc: 86.535% (33285/38464)
Loss: 0.573 | Acc: 86.510% (38812/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8136, Accuracy: 8038/10000 (80.38%)

Epoch: 36
Loss: 0.489 | Acc: 85.938% (55/64)
Loss: 0.537 | Acc: 87.283% (5642/6464)
Loss: 0.552 | Acc: 86.909% (11180/12864)
Loss: 0.548 | Acc: 86.965% (16753/19264)
Loss: 0.553 | Acc: 86.701% (22251/25664)
Loss: 0.555 | Acc: 86.739% (27812/32064)
Loss: 0.559 | Acc: 86.702% (33349/38464)
Loss: 0.559 | Acc: 86.720% (38906/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8836, Accuracy: 7786/10000 (77.86%)

Epoch: 37
Loss: 0.550 | Acc: 87.500% (56/64)
Loss: 0.518 | Acc: 87.856% (5679/6464)
Loss: 0.516 | Acc: 87.974% (11317/12864)
Loss: 0.516 | Acc: 87.879% (16929/19264)
Loss: 0.515 | Acc: 87.897% (22558/25664)
Loss: 0.525 | Acc: 87.696% (28119/32064)
Loss: 0.529 | Acc: 87.609% (33698/38464)
Loss: 0.534 | Acc: 87.480% (39247/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8103, Accuracy: 8079/10000 (80.79%)

Epoch: 38
Loss: 0.749 | Acc: 82.812% (53/64)
Loss: 0.498 | Acc: 88.366% (5712/6464)
Loss: 0.494 | Acc: 88.479% (11382/12864)
Loss: 0.491 | Acc: 88.559% (17060/19264)
Loss: 0.494 | Acc: 88.474% (22706/25664)
Loss: 0.499 | Acc: 88.383% (28339/32064)
Loss: 0.502 | Acc: 88.231% (33937/38464)
Loss: 0.501 | Acc: 88.260% (39597/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8187, Accuracy: 8096/10000 (80.96%)

Epoch: 39
Loss: 0.294 | Acc: 93.750% (60/64)
Loss: 0.459 | Acc: 89.202% (5766/6464)
Loss: 0.458 | Acc: 89.265% (11483/12864)
Loss: 0.461 | Acc: 89.301% (17203/19264)
Loss: 0.464 | Acc: 89.129% (22874/25664)
Loss: 0.474 | Acc: 88.981% (28531/32064)
Loss: 0.474 | Acc: 88.907% (34197/38464)
Loss: 0.478 | Acc: 88.831% (39853/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8618, Accuracy: 8005/10000 (80.05%)

Epoch: 40
Loss: 0.330 | Acc: 92.188% (59/64)
Loss: 0.446 | Acc: 89.465% (5783/6464)
Loss: 0.433 | Acc: 89.708% (11540/12864)
Loss: 0.438 | Acc: 89.670% (17274/19264)
Loss: 0.444 | Acc: 89.514% (22973/25664)
Loss: 0.442 | Acc: 89.583% (28724/32064)
Loss: 0.442 | Acc: 89.549% (34444/38464)
Loss: 0.445 | Acc: 89.457% (40134/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8449, Accuracy: 8131/10000 (81.31%)

Epoch: 41
Loss: 0.553 | Acc: 84.375% (54/64)
Loss: 0.396 | Acc: 90.563% (5854/6464)
Loss: 0.418 | Acc: 90.229% (11607/12864)
Loss: 0.413 | Acc: 90.298% (17395/19264)
Loss: 0.417 | Acc: 90.130% (23131/25664)
Loss: 0.413 | Acc: 90.195% (28920/32064)
Loss: 0.415 | Acc: 90.082% (34649/38464)
Loss: 0.416 | Acc: 90.090% (40418/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8457, Accuracy: 8195/10000 (81.95%)

Epoch: 42
Loss: 0.327 | Acc: 92.188% (59/64)
Loss: 0.367 | Acc: 91.197% (5895/6464)
Loss: 0.377 | Acc: 90.788% (11679/12864)
Loss: 0.378 | Acc: 90.812% (17494/19264)
Loss: 0.385 | Acc: 90.691% (23275/25664)
Loss: 0.384 | Acc: 90.762% (29102/32064)
Loss: 0.384 | Acc: 90.760% (34910/38464)
Loss: 0.382 | Acc: 90.828% (40749/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9033, Accuracy: 8070/10000 (80.70%)

Epoch: 43
Loss: 0.251 | Acc: 95.312% (61/64)
Loss: 0.349 | Acc: 91.677% (5926/6464)
Loss: 0.350 | Acc: 91.682% (11794/12864)
Loss: 0.345 | Acc: 91.715% (17668/19264)
Loss: 0.340 | Acc: 91.860% (23575/25664)
Loss: 0.340 | Acc: 91.804% (29436/32064)
Loss: 0.342 | Acc: 91.743% (35288/38464)
Loss: 0.341 | Acc: 91.739% (41158/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8948, Accuracy: 8153/10000 (81.53%)

Epoch: 44
Loss: 0.179 | Acc: 96.875% (62/64)
Loss: 0.296 | Acc: 92.590% (5985/6464)
Loss: 0.313 | Acc: 92.032% (11839/12864)
Loss: 0.310 | Acc: 92.172% (17756/19264)
Loss: 0.314 | Acc: 92.176% (23656/25664)
Loss: 0.316 | Acc: 92.078% (29524/32064)
Loss: 0.313 | Acc: 92.164% (35450/38464)
Loss: 0.311 | Acc: 92.252% (41388/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8896, Accuracy: 8200/10000 (82.00%)

Epoch: 45
Loss: 0.328 | Acc: 89.062% (57/64)
Loss: 0.274 | Acc: 93.069% (6016/6464)
Loss: 0.277 | Acc: 93.004% (11964/12864)
Loss: 0.275 | Acc: 92.951% (17906/19264)
Loss: 0.279 | Acc: 92.854% (23830/25664)
Loss: 0.279 | Acc: 92.930% (29797/32064)
Loss: 0.277 | Acc: 93.004% (35773/38464)
Loss: 0.276 | Acc: 93.039% (41741/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8970, Accuracy: 8200/10000 (82.00%)

Epoch: 46
Loss: 0.218 | Acc: 93.750% (60/64)
Loss: 0.275 | Acc: 92.992% (6011/6464)
Loss: 0.270 | Acc: 93.027% (11967/12864)
Loss: 0.264 | Acc: 93.153% (17945/19264)
Loss: 0.261 | Acc: 93.197% (23918/25664)
Loss: 0.257 | Acc: 93.341% (29929/32064)
Loss: 0.257 | Acc: 93.363% (35911/38464)
Loss: 0.256 | Acc: 93.402% (41904/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9092, Accuracy: 8192/10000 (81.92%)

Epoch: 47
Loss: 0.128 | Acc: 98.438% (63/64)
Loss: 0.240 | Acc: 93.719% (6058/6464)
Loss: 0.233 | Acc: 93.944% (12085/12864)
Loss: 0.238 | Acc: 93.859% (18081/19264)
Loss: 0.237 | Acc: 93.855% (24087/25664)
Loss: 0.239 | Acc: 93.840% (30089/32064)
Loss: 0.237 | Acc: 93.875% (36108/38464)
Loss: 0.234 | Acc: 94.013% (42178/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9088, Accuracy: 8199/10000 (81.99%)
torch.Size([100, 10])
Test set: Average loss: 0.9088, Accuracy: 8199/10000 (81.99%)

Epoch: 48
Loss: 0.268 | Acc: 92.188% (59/64)
Loss: 0.219 | Acc: 94.384% (6101/6464)
Loss: 0.219 | Acc: 94.403% (12144/12864)
Loss: 0.223 | Acc: 94.207% (18148/19264)
Loss: 0.225 | Acc: 94.194% (24174/25664)
Loss: 0.224 | Acc: 94.205% (30206/32064)
Loss: 0.226 | Acc: 94.150% (36214/38464)
Loss: 0.225 | Acc: 94.165% (42246/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9179, Accuracy: 8195/10000 (81.95%)
torch.Size([100, 10])
Test set: Average loss: 0.9179, Accuracy: 8195/10000 (81.95%)

Epoch: 49
Loss: 0.267 | Acc: 92.188% (59/64)
Loss: 0.228 | Acc: 94.152% (6086/6464)
Loss: 0.230 | Acc: 94.053% (12099/12864)
Loss: 0.226 | Acc: 94.124% (18132/19264)
Loss: 0.224 | Acc: 94.120% (24155/25664)
Loss: 0.223 | Acc: 94.124% (30180/32064)
Loss: 0.225 | Acc: 94.119% (36202/38464)
Loss: 0.225 | Acc: 94.107% (42220/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9191, Accuracy: 8203/10000 (82.03%)
torch.Size([100, 10])
Test set: Average loss: 0.9191, Accuracy: 8203/10000 (82.03%)

Epoch: 50
Loss: 0.155 | Acc: 96.875% (62/64)
Loss: 1.351 | Acc: 58.168% (3760/6464)
Loss: 1.187 | Acc: 64.125% (8249/12864)
Loss: 1.108 | Acc: 67.188% (12943/19264)
Loss: 1.077 | Acc: 68.547% (17592/25664)
Loss: 1.050 | Acc: 69.667% (22338/32064)
Loss: 1.029 | Acc: 70.450% (27098/38464)
Loss: 1.013 | Acc: 71.053% (31877/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7171, Accuracy: 5173/10000 (51.73%)

Epoch: 51
Loss: 1.170 | Acc: 64.062% (41/64)
Loss: 0.880 | Acc: 76.067% (4917/6464)
Loss: 0.879 | Acc: 76.415% (9830/12864)
Loss: 0.881 | Acc: 76.246% (14688/19264)
Loss: 0.881 | Acc: 76.262% (19572/25664)
Loss: 0.878 | Acc: 76.363% (24485/32064)
Loss: 0.871 | Acc: 76.472% (29414/38464)
Loss: 0.868 | Acc: 76.580% (34357/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1039, Accuracy: 6905/10000 (69.05%)

Epoch: 52
Loss: 0.811 | Acc: 82.812% (53/64)
Loss: 0.846 | Acc: 77.259% (4994/6464)
Loss: 0.840 | Acc: 77.581% (9980/12864)
Loss: 0.835 | Acc: 77.762% (14980/19264)
Loss: 0.835 | Acc: 77.724% (19947/25664)
Loss: 0.834 | Acc: 77.710% (24917/32064)
Loss: 0.835 | Acc: 77.641% (29864/38464)
Loss: 0.839 | Acc: 77.686% (34853/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0535, Accuracy: 6997/10000 (69.97%)

Epoch: 53
Loss: 1.214 | Acc: 62.500% (40/64)
Loss: 0.794 | Acc: 79.254% (5123/6464)
Loss: 0.812 | Acc: 78.871% (10146/12864)
Loss: 0.823 | Acc: 78.436% (15110/19264)
Loss: 0.824 | Acc: 78.367% (20112/25664)
Loss: 0.828 | Acc: 78.297% (25105/32064)
Loss: 0.825 | Acc: 78.315% (30123/38464)
Loss: 0.826 | Acc: 78.259% (35110/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5349, Accuracy: 5648/10000 (56.48%)

Epoch: 54
Loss: 0.860 | Acc: 70.312% (45/64)
Loss: 0.777 | Acc: 78.945% (5103/6464)
Loss: 0.810 | Acc: 78.521% (10101/12864)
Loss: 0.807 | Acc: 78.634% (15148/19264)
Loss: 0.815 | Acc: 78.445% (20132/25664)
Loss: 0.818 | Acc: 78.318% (25112/32064)
Loss: 0.821 | Acc: 78.273% (30107/38464)
Loss: 0.822 | Acc: 78.335% (35144/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5387, Accuracy: 5774/10000 (57.74%)

Epoch: 55
Loss: 1.081 | Acc: 65.625% (42/64)
Loss: 0.806 | Acc: 78.496% (5074/6464)
Loss: 0.806 | Acc: 78.490% (10097/12864)
Loss: 0.809 | Acc: 78.686% (15158/19264)
Loss: 0.812 | Acc: 78.600% (20172/25664)
Loss: 0.811 | Acc: 78.640% (25215/32064)
Loss: 0.813 | Acc: 78.585% (30227/38464)
Loss: 0.815 | Acc: 78.546% (35239/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9682, Accuracy: 7354/10000 (73.54%)

Epoch: 56
Loss: 0.954 | Acc: 79.688% (51/64)
Loss: 0.818 | Acc: 78.991% (5106/6464)
Loss: 0.816 | Acc: 78.848% (10143/12864)
Loss: 0.803 | Acc: 79.132% (15244/19264)
Loss: 0.801 | Acc: 79.177% (20320/25664)
Loss: 0.804 | Acc: 79.142% (25376/32064)
Loss: 0.809 | Acc: 79.022% (30395/38464)
Loss: 0.810 | Acc: 79.003% (35444/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0627, Accuracy: 7102/10000 (71.02%)

Epoch: 57
Loss: 0.938 | Acc: 76.562% (49/64)
Loss: 0.801 | Acc: 78.744% (5090/6464)
Loss: 0.804 | Acc: 78.871% (10146/12864)
Loss: 0.803 | Acc: 79.132% (15244/19264)
Loss: 0.810 | Acc: 78.916% (20253/25664)
Loss: 0.810 | Acc: 78.998% (25330/32064)
Loss: 0.813 | Acc: 78.944% (30365/38464)
Loss: 0.808 | Acc: 78.941% (35416/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2869, Accuracy: 6389/10000 (63.89%)

Epoch: 58
Loss: 0.896 | Acc: 76.562% (49/64)
Loss: 0.792 | Acc: 79.533% (5141/6464)
Loss: 0.800 | Acc: 79.237% (10193/12864)
Loss: 0.797 | Acc: 79.267% (15270/19264)
Loss: 0.802 | Acc: 79.197% (20325/25664)
Loss: 0.800 | Acc: 79.266% (25416/32064)
Loss: 0.801 | Acc: 79.248% (30482/38464)
Loss: 0.802 | Acc: 79.193% (35529/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1972, Accuracy: 6687/10000 (66.87%)

Epoch: 59
Loss: 0.583 | Acc: 85.938% (55/64)
Loss: 0.803 | Acc: 79.316% (5127/6464)
Loss: 0.791 | Acc: 79.672% (10249/12864)
Loss: 0.794 | Acc: 79.433% (15302/19264)
Loss: 0.795 | Acc: 79.298% (20351/25664)
Loss: 0.798 | Acc: 79.201% (25395/32064)
Loss: 0.799 | Acc: 79.126% (30435/38464)
Loss: 0.803 | Acc: 79.050% (35465/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2761, Accuracy: 6241/10000 (62.41%)

Epoch: 60
Loss: 0.897 | Acc: 76.562% (49/64)
Loss: 0.805 | Acc: 79.285% (5125/6464)
Loss: 0.790 | Acc: 79.470% (10223/12864)
Loss: 0.803 | Acc: 79.184% (15254/19264)
Loss: 0.802 | Acc: 79.267% (20343/25664)
Loss: 0.796 | Acc: 79.450% (25475/32064)
Loss: 0.794 | Acc: 79.495% (30577/38464)
Loss: 0.794 | Acc: 79.409% (35626/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9190, Accuracy: 7574/10000 (75.74%)

Epoch: 61
Loss: 0.884 | Acc: 75.000% (48/64)
Loss: 0.769 | Acc: 80.012% (5172/6464)
Loss: 0.768 | Acc: 80.201% (10317/12864)
Loss: 0.777 | Acc: 79.921% (15396/19264)
Loss: 0.784 | Acc: 79.816% (20484/25664)
Loss: 0.789 | Acc: 79.684% (25550/32064)
Loss: 0.792 | Acc: 79.563% (30603/38464)
Loss: 0.791 | Acc: 79.612% (35717/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3106, Accuracy: 6188/10000 (61.88%)

Epoch: 62
Loss: 0.891 | Acc: 78.125% (50/64)
Loss: 0.775 | Acc: 80.322% (5192/6464)
Loss: 0.776 | Acc: 80.107% (10305/12864)
Loss: 0.784 | Acc: 79.989% (15409/19264)
Loss: 0.782 | Acc: 79.995% (20530/25664)
Loss: 0.783 | Acc: 79.931% (25629/32064)
Loss: 0.781 | Acc: 79.984% (30765/38464)
Loss: 0.784 | Acc: 79.866% (35831/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2265, Accuracy: 6616/10000 (66.16%)

Epoch: 63
Loss: 0.492 | Acc: 87.500% (56/64)
Loss: 0.774 | Acc: 79.827% (5160/6464)
Loss: 0.775 | Acc: 80.232% (10321/12864)
Loss: 0.772 | Acc: 80.399% (15488/19264)
Loss: 0.773 | Acc: 80.338% (20618/25664)
Loss: 0.773 | Acc: 80.405% (25781/32064)
Loss: 0.777 | Acc: 80.345% (30904/38464)
Loss: 0.776 | Acc: 80.401% (36071/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2041, Accuracy: 6585/10000 (65.85%)

Epoch: 64
Loss: 1.045 | Acc: 71.875% (46/64)
Loss: 0.793 | Acc: 79.363% (5130/6464)
Loss: 0.776 | Acc: 80.061% (10299/12864)
Loss: 0.766 | Acc: 80.368% (15482/19264)
Loss: 0.769 | Acc: 80.268% (20600/25664)
Loss: 0.767 | Acc: 80.377% (25772/32064)
Loss: 0.768 | Acc: 80.369% (30913/38464)
Loss: 0.771 | Acc: 80.238% (35998/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5379, Accuracy: 5658/10000 (56.58%)

Epoch: 65
Loss: 0.603 | Acc: 84.375% (54/64)
Loss: 0.748 | Acc: 80.616% (5211/6464)
Loss: 0.753 | Acc: 80.667% (10377/12864)
Loss: 0.759 | Acc: 80.622% (15531/19264)
Loss: 0.759 | Acc: 80.584% (20681/25664)
Loss: 0.766 | Acc: 80.392% (25777/32064)
Loss: 0.763 | Acc: 80.483% (30957/38464)
Loss: 0.765 | Acc: 80.441% (36089/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4684, Accuracy: 5782/10000 (57.82%)

Epoch: 66
Loss: 0.880 | Acc: 75.000% (48/64)
Loss: 0.728 | Acc: 81.776% (5286/6464)
Loss: 0.753 | Acc: 80.683% (10379/12864)
Loss: 0.752 | Acc: 80.700% (15546/19264)
Loss: 0.759 | Acc: 80.467% (20651/25664)
Loss: 0.756 | Acc: 80.573% (25835/32064)
Loss: 0.759 | Acc: 80.543% (30980/38464)
Loss: 0.757 | Acc: 80.548% (36137/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3605, Accuracy: 5841/10000 (58.41%)

Epoch: 67
Loss: 0.837 | Acc: 79.688% (51/64)
Loss: 0.748 | Acc: 81.095% (5242/6464)
Loss: 0.735 | Acc: 81.390% (10470/12864)
Loss: 0.736 | Acc: 81.515% (15703/19264)
Loss: 0.741 | Acc: 81.453% (20904/25664)
Loss: 0.745 | Acc: 81.287% (26064/32064)
Loss: 0.749 | Acc: 81.154% (31215/38464)
Loss: 0.753 | Acc: 81.040% (36358/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3103, Accuracy: 6395/10000 (63.95%)

Epoch: 68
Loss: 0.609 | Acc: 82.812% (53/64)
Loss: 0.745 | Acc: 80.987% (5235/6464)
Loss: 0.735 | Acc: 81.374% (10468/12864)
Loss: 0.740 | Acc: 81.260% (15654/19264)
Loss: 0.743 | Acc: 81.227% (20846/25664)
Loss: 0.743 | Acc: 81.278% (26061/32064)
Loss: 0.745 | Acc: 81.211% (31237/38464)
Loss: 0.741 | Acc: 81.214% (36436/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0486, Accuracy: 7134/10000 (71.34%)

Epoch: 69
Loss: 0.920 | Acc: 73.438% (47/64)
Loss: 0.693 | Acc: 82.828% (5354/6464)
Loss: 0.704 | Acc: 82.245% (10580/12864)
Loss: 0.723 | Acc: 81.821% (15762/19264)
Loss: 0.732 | Acc: 81.651% (20955/25664)
Loss: 0.735 | Acc: 81.581% (26158/32064)
Loss: 0.733 | Acc: 81.669% (31413/38464)
Loss: 0.735 | Acc: 81.620% (36618/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9911, Accuracy: 7321/10000 (73.21%)

Epoch: 70
Loss: 0.682 | Acc: 84.375% (54/64)
Loss: 0.705 | Acc: 82.054% (5304/6464)
Loss: 0.705 | Acc: 82.261% (10582/12864)
Loss: 0.710 | Acc: 82.153% (15826/19264)
Loss: 0.709 | Acc: 82.325% (21128/25664)
Loss: 0.714 | Acc: 82.176% (26349/32064)
Loss: 0.719 | Acc: 82.001% (31541/38464)
Loss: 0.724 | Acc: 81.838% (36716/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2817, Accuracy: 6303/10000 (63.03%)

Epoch: 71
Loss: 0.924 | Acc: 75.000% (48/64)
Loss: 0.703 | Acc: 82.147% (5310/6464)
Loss: 0.709 | Acc: 81.996% (10548/12864)
Loss: 0.709 | Acc: 81.982% (15793/19264)
Loss: 0.720 | Acc: 81.792% (20991/25664)
Loss: 0.720 | Acc: 81.955% (26278/32064)
Loss: 0.720 | Acc: 81.918% (31509/38464)
Loss: 0.717 | Acc: 82.003% (36790/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1999, Accuracy: 6702/10000 (67.02%)

Epoch: 72
Loss: 0.876 | Acc: 78.125% (50/64)
Loss: 0.707 | Acc: 82.426% (5328/6464)
Loss: 0.713 | Acc: 82.276% (10584/12864)
Loss: 0.716 | Acc: 82.236% (15842/19264)
Loss: 0.711 | Acc: 82.259% (21111/25664)
Loss: 0.712 | Acc: 82.342% (26402/32064)
Loss: 0.709 | Acc: 82.397% (31693/38464)
Loss: 0.711 | Acc: 82.380% (36959/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1767, Accuracy: 6818/10000 (68.18%)

Epoch: 73
Loss: 0.716 | Acc: 82.812% (53/64)
Loss: 0.673 | Acc: 83.075% (5370/6464)
Loss: 0.688 | Acc: 83.022% (10680/12864)
Loss: 0.694 | Acc: 82.880% (15966/19264)
Loss: 0.699 | Acc: 82.738% (21234/25664)
Loss: 0.701 | Acc: 82.660% (26504/32064)
Loss: 0.699 | Acc: 82.659% (31794/38464)
Loss: 0.700 | Acc: 82.643% (37077/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9568, Accuracy: 7427/10000 (74.27%)

Epoch: 74
Loss: 0.733 | Acc: 79.688% (51/64)
Loss: 0.653 | Acc: 83.834% (5419/6464)
Loss: 0.664 | Acc: 83.730% (10771/12864)
Loss: 0.679 | Acc: 83.300% (16047/19264)
Loss: 0.680 | Acc: 83.183% (21348/25664)
Loss: 0.680 | Acc: 83.290% (26706/32064)
Loss: 0.687 | Acc: 83.080% (31956/38464)
Loss: 0.687 | Acc: 83.136% (37298/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8555, Accuracy: 7772/10000 (77.72%)

Epoch: 75
Loss: 0.505 | Acc: 87.500% (56/64)
Loss: 0.644 | Acc: 84.483% (5461/6464)
Loss: 0.655 | Acc: 83.986% (10804/12864)
Loss: 0.661 | Acc: 83.866% (16156/19264)
Loss: 0.664 | Acc: 83.783% (21502/25664)
Loss: 0.668 | Acc: 83.645% (26820/32064)
Loss: 0.674 | Acc: 83.491% (32114/38464)
Loss: 0.678 | Acc: 83.372% (37404/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9194, Accuracy: 7528/10000 (75.28%)

Epoch: 76
Loss: 0.672 | Acc: 79.688% (51/64)
Loss: 0.658 | Acc: 84.019% (5431/6464)
Loss: 0.652 | Acc: 84.188% (10830/12864)
Loss: 0.663 | Acc: 83.980% (16178/19264)
Loss: 0.665 | Acc: 83.868% (21524/25664)
Loss: 0.671 | Acc: 83.748% (26853/32064)
Loss: 0.670 | Acc: 83.741% (32210/38464)
Loss: 0.667 | Acc: 83.818% (37604/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8605, Accuracy: 7788/10000 (77.88%)

Epoch: 77
Loss: 0.904 | Acc: 75.000% (48/64)
Loss: 0.647 | Acc: 84.282% (5448/6464)
Loss: 0.655 | Acc: 83.932% (10797/12864)
Loss: 0.659 | Acc: 83.825% (16148/19264)
Loss: 0.661 | Acc: 83.794% (21505/25664)
Loss: 0.660 | Acc: 83.857% (26888/32064)
Loss: 0.658 | Acc: 83.930% (32283/38464)
Loss: 0.653 | Acc: 84.027% (37698/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9245, Accuracy: 7577/10000 (75.77%)

Epoch: 78
Loss: 0.617 | Acc: 85.938% (55/64)
Loss: 0.623 | Acc: 85.736% (5542/6464)
Loss: 0.629 | Acc: 85.347% (10979/12864)
Loss: 0.638 | Acc: 85.039% (16382/19264)
Loss: 0.643 | Acc: 84.889% (21786/25664)
Loss: 0.646 | Acc: 84.787% (27186/32064)
Loss: 0.641 | Acc: 84.807% (32620/38464)
Loss: 0.642 | Acc: 84.732% (38014/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9964, Accuracy: 7329/10000 (73.29%)

Epoch: 79
Loss: 0.536 | Acc: 87.500% (56/64)
Loss: 0.612 | Acc: 85.582% (5532/6464)
Loss: 0.607 | Acc: 85.728% (11028/12864)
Loss: 0.606 | Acc: 85.704% (16510/19264)
Loss: 0.617 | Acc: 85.291% (21889/25664)
Loss: 0.622 | Acc: 85.105% (27288/32064)
Loss: 0.623 | Acc: 85.134% (32746/38464)
Loss: 0.623 | Acc: 85.124% (38190/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2077, Accuracy: 6536/10000 (65.36%)

Epoch: 80
Loss: 0.888 | Acc: 76.562% (49/64)
Loss: 0.641 | Acc: 84.483% (5461/6464)
Loss: 0.614 | Acc: 85.246% (10966/12864)
Loss: 0.607 | Acc: 85.439% (16459/19264)
Loss: 0.604 | Acc: 85.478% (21937/25664)
Loss: 0.609 | Acc: 85.417% (27388/32064)
Loss: 0.610 | Acc: 85.454% (32869/38464)
Loss: 0.612 | Acc: 85.418% (38322/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8723, Accuracy: 7745/10000 (77.45%)

Epoch: 81
Loss: 0.450 | Acc: 90.625% (58/64)
Loss: 0.588 | Acc: 86.030% (5561/6464)
Loss: 0.604 | Acc: 85.580% (11009/12864)
Loss: 0.597 | Acc: 85.808% (16530/19264)
Loss: 0.595 | Acc: 85.852% (22033/25664)
Loss: 0.593 | Acc: 85.913% (27547/32064)
Loss: 0.593 | Acc: 85.956% (33062/38464)
Loss: 0.597 | Acc: 85.835% (38509/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8974, Accuracy: 7728/10000 (77.28%)

Epoch: 82
Loss: 0.475 | Acc: 90.625% (58/64)
Loss: 0.597 | Acc: 85.938% (5555/6464)
Loss: 0.581 | Acc: 86.412% (11116/12864)
Loss: 0.570 | Acc: 86.633% (16689/19264)
Loss: 0.575 | Acc: 86.460% (22189/25664)
Loss: 0.578 | Acc: 86.377% (27696/32064)
Loss: 0.583 | Acc: 86.320% (33202/38464)
Loss: 0.582 | Acc: 86.316% (38725/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7822, Accuracy: 8132/10000 (81.32%)

Epoch: 83
Loss: 0.592 | Acc: 84.375% (54/64)
Loss: 0.531 | Acc: 87.748% (5672/6464)
Loss: 0.540 | Acc: 87.562% (11264/12864)
Loss: 0.535 | Acc: 87.760% (16906/19264)
Loss: 0.546 | Acc: 87.496% (22455/25664)
Loss: 0.547 | Acc: 87.335% (28003/32064)
Loss: 0.556 | Acc: 87.133% (33515/38464)
Loss: 0.556 | Acc: 87.143% (39096/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9351, Accuracy: 7650/10000 (76.50%)

Epoch: 84
Loss: 0.432 | Acc: 90.625% (58/64)
Loss: 0.539 | Acc: 87.485% (5655/6464)
Loss: 0.539 | Acc: 87.469% (11252/12864)
Loss: 0.546 | Acc: 87.282% (16814/19264)
Loss: 0.547 | Acc: 87.219% (22384/25664)
Loss: 0.542 | Acc: 87.291% (27989/32064)
Loss: 0.547 | Acc: 87.198% (33540/38464)
Loss: 0.546 | Acc: 87.230% (39135/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8492, Accuracy: 7978/10000 (79.78%)

Epoch: 85
Loss: 0.608 | Acc: 85.938% (55/64)
Loss: 0.513 | Acc: 88.026% (5690/6464)
Loss: 0.512 | Acc: 88.231% (11350/12864)
Loss: 0.514 | Acc: 88.113% (16974/19264)
Loss: 0.515 | Acc: 88.057% (22599/25664)
Loss: 0.513 | Acc: 88.139% (28261/32064)
Loss: 0.515 | Acc: 88.085% (33881/38464)
Loss: 0.517 | Acc: 88.010% (39485/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8896, Accuracy: 7881/10000 (78.81%)

Epoch: 86
Loss: 0.518 | Acc: 84.375% (54/64)
Loss: 0.482 | Acc: 88.676% (5732/6464)
Loss: 0.465 | Acc: 89.218% (11477/12864)
Loss: 0.476 | Acc: 88.985% (17142/19264)
Loss: 0.489 | Acc: 88.603% (22739/25664)
Loss: 0.490 | Acc: 88.613% (28413/32064)
Loss: 0.494 | Acc: 88.561% (34064/38464)
Loss: 0.496 | Acc: 88.523% (39715/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8291, Accuracy: 8048/10000 (80.48%)

Epoch: 87
Loss: 0.442 | Acc: 89.062% (57/64)
Loss: 0.476 | Acc: 88.769% (5738/6464)
Loss: 0.466 | Acc: 89.031% (11453/12864)
Loss: 0.473 | Acc: 88.896% (17125/19264)
Loss: 0.474 | Acc: 88.911% (22818/25664)
Loss: 0.475 | Acc: 88.888% (28501/32064)
Loss: 0.476 | Acc: 88.881% (34187/38464)
Loss: 0.472 | Acc: 89.022% (39939/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7900, Accuracy: 8232/10000 (82.32%)

Epoch: 88
Loss: 0.341 | Acc: 90.625% (58/64)
Loss: 0.438 | Acc: 89.588% (5791/6464)
Loss: 0.435 | Acc: 89.809% (11553/12864)
Loss: 0.440 | Acc: 89.701% (17280/19264)
Loss: 0.447 | Acc: 89.596% (22994/25664)
Loss: 0.445 | Acc: 89.608% (28732/32064)
Loss: 0.441 | Acc: 89.668% (34490/38464)
Loss: 0.442 | Acc: 89.626% (40210/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8440, Accuracy: 8081/10000 (80.81%)

Epoch: 89
Loss: 0.514 | Acc: 84.375% (54/64)
Loss: 0.401 | Acc: 90.517% (5851/6464)
Loss: 0.405 | Acc: 90.462% (11637/12864)
Loss: 0.406 | Acc: 90.433% (17421/19264)
Loss: 0.406 | Acc: 90.337% (23184/25664)
Loss: 0.411 | Acc: 90.257% (28940/32064)
Loss: 0.410 | Acc: 90.287% (34728/38464)
Loss: 0.412 | Acc: 90.257% (40493/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8468, Accuracy: 8152/10000 (81.52%)

Epoch: 90
Loss: 0.255 | Acc: 90.625% (58/64)
Loss: 0.370 | Acc: 91.136% (5891/6464)
Loss: 0.372 | Acc: 91.115% (11721/12864)
Loss: 0.372 | Acc: 91.149% (17559/19264)
Loss: 0.374 | Acc: 91.128% (23387/25664)
Loss: 0.381 | Acc: 90.943% (29160/32064)
Loss: 0.385 | Acc: 90.856% (34947/38464)
Loss: 0.384 | Acc: 90.901% (40782/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8363, Accuracy: 8242/10000 (82.42%)

Epoch: 91
Loss: 0.300 | Acc: 92.188% (59/64)
Loss: 0.351 | Acc: 91.708% (5928/6464)
Loss: 0.355 | Acc: 91.667% (11792/12864)
Loss: 0.357 | Acc: 91.461% (17619/19264)
Loss: 0.350 | Acc: 91.584% (23504/25664)
Loss: 0.350 | Acc: 91.551% (29355/32064)
Loss: 0.350 | Acc: 91.571% (35222/38464)
Loss: 0.349 | Acc: 91.563% (41079/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8838, Accuracy: 8187/10000 (81.87%)

Epoch: 92
Loss: 0.405 | Acc: 87.500% (56/64)
Loss: 0.299 | Acc: 92.481% (5978/6464)
Loss: 0.299 | Acc: 92.467% (11895/12864)
Loss: 0.305 | Acc: 92.416% (17803/19264)
Loss: 0.311 | Acc: 92.316% (23692/25664)
Loss: 0.318 | Acc: 92.100% (29531/32064)
Loss: 0.320 | Acc: 92.013% (35392/38464)
Loss: 0.320 | Acc: 92.040% (41293/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8750, Accuracy: 8206/10000 (82.06%)

Epoch: 93
Loss: 0.316 | Acc: 92.188% (59/64)
Loss: 0.273 | Acc: 93.224% (6026/6464)
Loss: 0.272 | Acc: 93.136% (11981/12864)
Loss: 0.272 | Acc: 93.070% (17929/19264)
Loss: 0.276 | Acc: 92.994% (23866/25664)
Loss: 0.275 | Acc: 93.020% (29826/32064)
Loss: 0.275 | Acc: 93.066% (35797/38464)
Loss: 0.276 | Acc: 93.014% (41730/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9168, Accuracy: 8225/10000 (82.25%)

Epoch: 94
Loss: 0.151 | Acc: 95.312% (61/64)
Loss: 0.242 | Acc: 93.642% (6053/6464)
Loss: 0.250 | Acc: 93.447% (12021/12864)
Loss: 0.254 | Acc: 93.361% (17985/19264)
Loss: 0.252 | Acc: 93.458% (23985/25664)
Loss: 0.251 | Acc: 93.541% (29993/32064)
Loss: 0.248 | Acc: 93.620% (36010/38464)
Loss: 0.246 | Acc: 93.676% (42027/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9188, Accuracy: 8214/10000 (82.14%)

Epoch: 95
Loss: 0.122 | Acc: 96.875% (62/64)
Loss: 0.208 | Acc: 94.601% (6115/6464)
Loss: 0.215 | Acc: 94.457% (12151/12864)
Loss: 0.218 | Acc: 94.326% (18171/19264)
Loss: 0.217 | Acc: 94.389% (24224/25664)
Loss: 0.219 | Acc: 94.374% (30260/32064)
Loss: 0.220 | Acc: 94.312% (36276/38464)
Loss: 0.219 | Acc: 94.334% (42322/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9436, Accuracy: 8195/10000 (81.95%)

Epoch: 96
Loss: 0.299 | Acc: 90.625% (58/64)
Loss: 0.212 | Acc: 94.431% (6104/6464)
Loss: 0.200 | Acc: 94.753% (12189/12864)
Loss: 0.208 | Acc: 94.508% (18206/19264)
Loss: 0.206 | Acc: 94.451% (24240/25664)
Loss: 0.203 | Acc: 94.564% (30321/32064)
Loss: 0.202 | Acc: 94.574% (36377/38464)
Loss: 0.202 | Acc: 94.630% (42455/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9447, Accuracy: 8223/10000 (82.23%)

Epoch: 97
Loss: 0.261 | Acc: 93.750% (60/64)
Loss: 0.190 | Acc: 95.003% (6141/6464)
Loss: 0.193 | Acc: 94.939% (12213/12864)
Loss: 0.192 | Acc: 94.985% (18298/19264)
Loss: 0.190 | Acc: 94.997% (24380/25664)
Loss: 0.187 | Acc: 95.063% (30481/32064)
Loss: 0.186 | Acc: 95.120% (36587/38464)
Loss: 0.184 | Acc: 95.114% (42672/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9454, Accuracy: 8217/10000 (82.17%)
torch.Size([100, 10])
Test set: Average loss: 0.9454, Accuracy: 8217/10000 (82.17%)

Epoch: 98
Loss: 0.112 | Acc: 98.438% (63/64)
Loss: 0.178 | Acc: 95.343% (6163/6464)
Loss: 0.177 | Acc: 95.188% (12245/12864)
Loss: 0.177 | Acc: 95.198% (18339/19264)
Loss: 0.178 | Acc: 95.219% (24437/25664)
Loss: 0.177 | Acc: 95.222% (30532/32064)
Loss: 0.177 | Acc: 95.227% (36628/38464)
Loss: 0.177 | Acc: 95.239% (42728/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9493, Accuracy: 8229/10000 (82.29%)
torch.Size([100, 10])
Test set: Average loss: 0.9493, Accuracy: 8229/10000 (82.29%)

Epoch: 99
Loss: 0.064 | Acc: 100.000% (64/64)
Loss: 0.162 | Acc: 95.854% (6196/6464)
Loss: 0.163 | Acc: 95.826% (12327/12864)
Loss: 0.164 | Acc: 95.717% (18439/19264)
Loss: 0.170 | Acc: 95.488% (24506/25664)
Loss: 0.173 | Acc: 95.406% (30591/32064)
Loss: 0.172 | Acc: 95.372% (36684/38464)
Loss: 0.172 | Acc: 95.350% (42778/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9499, Accuracy: 8231/10000 (82.31%)
torch.Size([100, 10])
Test set: Average loss: 0.9499, Accuracy: 8231/10000 (82.31%)

Epoch: 100
Loss: 0.175 | Acc: 92.188% (59/64)
Loss: 1.967 | Acc: 28.744% (1858/6464)
Loss: 1.640 | Acc: 43.532% (5600/12864)
Loss: 1.442 | Acc: 52.435% (10101/19264)
Loss: 1.327 | Acc: 57.466% (14748/25664)
Loss: 1.247 | Acc: 60.753% (19480/32064)
Loss: 1.193 | Acc: 63.036% (24246/38464)
Loss: 1.153 | Acc: 64.758% (29053/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6899, Accuracy: 4911/10000 (49.11%)

Epoch: 101
Loss: 1.109 | Acc: 65.625% (42/64)
Loss: 0.848 | Acc: 77.011% (4978/6464)
Loss: 0.854 | Acc: 76.803% (9880/12864)
Loss: 0.851 | Acc: 77.092% (14851/19264)
Loss: 0.846 | Acc: 77.404% (19865/25664)
Loss: 0.846 | Acc: 77.445% (24832/32064)
Loss: 0.843 | Acc: 77.623% (29857/38464)
Loss: 0.847 | Acc: 77.579% (34805/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1139, Accuracy: 6815/10000 (68.15%)

Epoch: 102
Loss: 0.603 | Acc: 82.812% (53/64)
Loss: 0.812 | Acc: 78.481% (5073/6464)
Loss: 0.817 | Acc: 78.537% (10103/12864)
Loss: 0.816 | Acc: 78.535% (15129/19264)
Loss: 0.817 | Acc: 78.437% (20130/25664)
Loss: 0.816 | Acc: 78.421% (25145/32064)
Loss: 0.818 | Acc: 78.403% (30157/38464)
Loss: 0.817 | Acc: 78.462% (35201/44864)
torch.Size([100, 10])
Test set: Average loss: 6.7018, Accuracy: 1365/10000 (13.65%)

Epoch: 103
Loss: 1.028 | Acc: 71.875% (46/64)
Loss: 0.809 | Acc: 78.914% (5101/6464)
Loss: 0.815 | Acc: 78.941% (10155/12864)
Loss: 0.808 | Acc: 79.101% (15238/19264)
Loss: 0.804 | Acc: 79.247% (20338/25664)
Loss: 0.806 | Acc: 79.123% (25370/32064)
Loss: 0.806 | Acc: 79.134% (30438/38464)
Loss: 0.806 | Acc: 79.072% (35475/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5139, Accuracy: 5906/10000 (59.06%)

Epoch: 104
Loss: 0.712 | Acc: 81.250% (52/64)
Loss: 0.776 | Acc: 79.688% (5151/6464)
Loss: 0.793 | Acc: 79.408% (10215/12864)
Loss: 0.792 | Acc: 79.662% (15346/19264)
Loss: 0.795 | Acc: 79.543% (20414/25664)
Loss: 0.796 | Acc: 79.525% (25499/32064)
Loss: 0.798 | Acc: 79.357% (30524/38464)
Loss: 0.797 | Acc: 79.335% (35593/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1554, Accuracy: 6656/10000 (66.56%)

Epoch: 105
Loss: 1.086 | Acc: 70.312% (45/64)
Loss: 0.777 | Acc: 80.399% (5197/6464)
Loss: 0.782 | Acc: 79.960% (10286/12864)
Loss: 0.785 | Acc: 79.667% (15347/19264)
Loss: 0.786 | Acc: 79.524% (20409/25664)
Loss: 0.789 | Acc: 79.485% (25486/32064)
Loss: 0.790 | Acc: 79.454% (30561/38464)
Loss: 0.791 | Acc: 79.413% (35628/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6619, Accuracy: 5309/10000 (53.09%)

Epoch: 106
Loss: 1.024 | Acc: 70.312% (45/64)
Loss: 0.789 | Acc: 79.966% (5169/6464)
Loss: 0.788 | Acc: 79.757% (10260/12864)
Loss: 0.783 | Acc: 79.765% (15366/19264)
Loss: 0.787 | Acc: 79.707% (20456/25664)
Loss: 0.789 | Acc: 79.638% (25535/32064)
Loss: 0.790 | Acc: 79.672% (30645/38464)
Loss: 0.793 | Acc: 79.547% (35688/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0414, Accuracy: 7126/10000 (71.26%)

Epoch: 107
Loss: 0.750 | Acc: 78.125% (50/64)
Loss: 0.771 | Acc: 80.306% (5191/6464)
Loss: 0.774 | Acc: 80.006% (10292/12864)
Loss: 0.778 | Acc: 79.931% (15398/19264)
Loss: 0.785 | Acc: 79.723% (20460/25664)
Loss: 0.787 | Acc: 79.591% (25520/32064)
Loss: 0.787 | Acc: 79.591% (30614/38464)
Loss: 0.786 | Acc: 79.663% (35740/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7605, Accuracy: 4933/10000 (49.33%)

Epoch: 108
Loss: 1.183 | Acc: 67.188% (43/64)
Loss: 0.789 | Acc: 79.425% (5134/6464)
Loss: 0.779 | Acc: 80.014% (10293/12864)
Loss: 0.788 | Acc: 79.781% (15369/19264)
Loss: 0.788 | Acc: 79.730% (20462/25664)
Loss: 0.785 | Acc: 79.815% (25592/32064)
Loss: 0.787 | Acc: 79.758% (30678/38464)
Loss: 0.787 | Acc: 79.670% (35743/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6568, Accuracy: 5400/10000 (54.00%)

Epoch: 109
Loss: 0.930 | Acc: 76.562% (49/64)
Loss: 0.793 | Acc: 79.394% (5132/6464)
Loss: 0.790 | Acc: 79.524% (10230/12864)
Loss: 0.783 | Acc: 79.828% (15378/19264)
Loss: 0.778 | Acc: 80.073% (20550/25664)
Loss: 0.779 | Acc: 80.056% (25669/32064)
Loss: 0.781 | Acc: 80.036% (30785/38464)
Loss: 0.781 | Acc: 80.078% (35926/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2796, Accuracy: 6386/10000 (63.86%)

Epoch: 110
Loss: 1.127 | Acc: 68.750% (44/64)
Loss: 0.791 | Acc: 79.502% (5139/6464)
Loss: 0.764 | Acc: 80.325% (10333/12864)
Loss: 0.763 | Acc: 80.393% (15487/19264)
Loss: 0.762 | Acc: 80.440% (20644/25664)
Loss: 0.766 | Acc: 80.311% (25751/32064)
Loss: 0.771 | Acc: 80.148% (30828/38464)
Loss: 0.771 | Acc: 80.149% (35958/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3761, Accuracy: 6127/10000 (61.27%)

Epoch: 111
Loss: 0.822 | Acc: 79.688% (51/64)
Loss: 0.778 | Acc: 80.059% (5175/6464)
Loss: 0.776 | Acc: 79.905% (10279/12864)
Loss: 0.768 | Acc: 79.999% (15411/19264)
Loss: 0.762 | Acc: 80.272% (20601/25664)
Loss: 0.768 | Acc: 80.215% (25720/32064)
Loss: 0.772 | Acc: 80.106% (30812/38464)
Loss: 0.774 | Acc: 80.060% (35918/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5899, Accuracy: 5364/10000 (53.64%)

Epoch: 112
Loss: 1.378 | Acc: 60.938% (39/64)
Loss: 0.757 | Acc: 80.925% (5231/6464)
Loss: 0.754 | Acc: 80.900% (10407/12864)
Loss: 0.760 | Acc: 80.892% (15583/19264)
Loss: 0.758 | Acc: 80.872% (20755/25664)
Loss: 0.761 | Acc: 80.720% (25882/32064)
Loss: 0.764 | Acc: 80.566% (30989/38464)
Loss: 0.768 | Acc: 80.432% (36085/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1538, Accuracy: 6627/10000 (66.27%)

Epoch: 113
Loss: 0.735 | Acc: 82.812% (53/64)
Loss: 0.743 | Acc: 81.281% (5254/6464)
Loss: 0.755 | Acc: 80.970% (10416/12864)
Loss: 0.753 | Acc: 80.975% (15599/19264)
Loss: 0.751 | Acc: 80.950% (20775/25664)
Loss: 0.746 | Acc: 81.060% (25991/32064)
Loss: 0.752 | Acc: 80.974% (31146/38464)
Loss: 0.757 | Acc: 80.911% (36300/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5569, Accuracy: 5410/10000 (54.10%)

Epoch: 114
Loss: 0.853 | Acc: 84.375% (54/64)
Loss: 0.741 | Acc: 81.807% (5288/6464)
Loss: 0.742 | Acc: 81.499% (10484/12864)
Loss: 0.749 | Acc: 81.089% (15621/19264)
Loss: 0.744 | Acc: 81.207% (20841/25664)
Loss: 0.749 | Acc: 81.063% (25992/32064)
Loss: 0.756 | Acc: 80.920% (31125/38464)
Loss: 0.757 | Acc: 80.911% (36300/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4482, Accuracy: 5758/10000 (57.58%)

Epoch: 115
Loss: 1.128 | Acc: 71.875% (46/64)
Loss: 0.725 | Acc: 81.900% (5294/6464)
Loss: 0.726 | Acc: 82.128% (10565/12864)
Loss: 0.743 | Acc: 81.541% (15708/19264)
Loss: 0.744 | Acc: 81.468% (20908/25664)
Loss: 0.745 | Acc: 81.300% (26068/32064)
Loss: 0.746 | Acc: 81.216% (31239/38464)
Loss: 0.747 | Acc: 81.114% (36391/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0864, Accuracy: 7037/10000 (70.37%)

Epoch: 116
Loss: 0.703 | Acc: 79.688% (51/64)
Loss: 0.742 | Acc: 80.972% (5234/6464)
Loss: 0.741 | Acc: 81.102% (10433/12864)
Loss: 0.743 | Acc: 81.110% (15625/19264)
Loss: 0.740 | Acc: 81.211% (20842/25664)
Loss: 0.747 | Acc: 81.054% (25989/32064)
Loss: 0.743 | Acc: 81.216% (31239/38464)
Loss: 0.743 | Acc: 81.179% (36420/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1133, Accuracy: 6899/10000 (68.99%)

Epoch: 117
Loss: 0.628 | Acc: 82.812% (53/64)
Loss: 0.745 | Acc: 81.095% (5242/6464)
Loss: 0.742 | Acc: 81.250% (10452/12864)
Loss: 0.733 | Acc: 81.515% (15703/19264)
Loss: 0.731 | Acc: 81.531% (20924/25664)
Loss: 0.740 | Acc: 81.312% (26072/32064)
Loss: 0.736 | Acc: 81.406% (31312/38464)
Loss: 0.734 | Acc: 81.462% (36547/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1264, Accuracy: 6905/10000 (69.05%)

Epoch: 118
Loss: 0.898 | Acc: 82.812% (53/64)
Loss: 0.713 | Acc: 82.085% (5306/6464)
Loss: 0.715 | Acc: 82.245% (10580/12864)
Loss: 0.710 | Acc: 82.304% (15855/19264)
Loss: 0.718 | Acc: 82.173% (21089/25664)
Loss: 0.726 | Acc: 82.002% (26293/32064)
Loss: 0.724 | Acc: 81.960% (31525/38464)
Loss: 0.727 | Acc: 81.903% (36745/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6699, Accuracy: 5375/10000 (53.75%)

Epoch: 119
Loss: 0.606 | Acc: 87.500% (56/64)
Loss: 0.732 | Acc: 81.590% (5274/6464)
Loss: 0.717 | Acc: 82.183% (10572/12864)
Loss: 0.714 | Acc: 82.247% (15844/19264)
Loss: 0.721 | Acc: 82.076% (21064/25664)
Loss: 0.721 | Acc: 82.108% (26327/32064)
Loss: 0.721 | Acc: 82.152% (31599/38464)
Loss: 0.724 | Acc: 82.006% (36791/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4032, Accuracy: 6027/10000 (60.27%)

Epoch: 120
Loss: 0.583 | Acc: 82.812% (53/64)
Loss: 0.712 | Acc: 82.317% (5321/6464)
Loss: 0.714 | Acc: 82.136% (10566/12864)
Loss: 0.711 | Acc: 82.288% (15852/19264)
Loss: 0.714 | Acc: 82.310% (21124/25664)
Loss: 0.710 | Acc: 82.479% (26446/32064)
Loss: 0.715 | Acc: 82.350% (31675/38464)
Loss: 0.715 | Acc: 82.331% (36937/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5218, Accuracy: 6016/10000 (60.16%)

Epoch: 121
Loss: 0.793 | Acc: 76.562% (49/64)
Loss: 0.671 | Acc: 83.493% (5397/6464)
Loss: 0.691 | Acc: 82.921% (10667/12864)
Loss: 0.696 | Acc: 82.735% (15938/19264)
Loss: 0.701 | Acc: 82.614% (21202/25664)
Loss: 0.700 | Acc: 82.660% (26504/32064)
Loss: 0.703 | Acc: 82.547% (31751/38464)
Loss: 0.704 | Acc: 82.578% (37048/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9960, Accuracy: 7241/10000 (72.41%)

Epoch: 122
Loss: 0.890 | Acc: 78.125% (50/64)
Loss: 0.674 | Acc: 83.400% (5391/6464)
Loss: 0.665 | Acc: 83.753% (10774/12864)
Loss: 0.673 | Acc: 83.430% (16072/19264)
Loss: 0.678 | Acc: 83.311% (21381/25664)
Loss: 0.682 | Acc: 83.202% (26678/32064)
Loss: 0.683 | Acc: 83.169% (31990/38464)
Loss: 0.687 | Acc: 83.020% (37246/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8485, Accuracy: 7840/10000 (78.40%)

Epoch: 123
Loss: 0.583 | Acc: 81.250% (52/64)
Loss: 0.686 | Acc: 83.122% (5373/6464)
Loss: 0.681 | Acc: 83.256% (10710/12864)
Loss: 0.683 | Acc: 83.254% (16038/19264)
Loss: 0.680 | Acc: 83.370% (21396/25664)
Loss: 0.683 | Acc: 83.227% (26686/32064)
Loss: 0.683 | Acc: 83.210% (32006/38464)
Loss: 0.687 | Acc: 83.138% (37299/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0140, Accuracy: 7322/10000 (73.22%)

Epoch: 124
Loss: 0.675 | Acc: 84.375% (54/64)
Loss: 0.662 | Acc: 83.803% (5417/6464)
Loss: 0.657 | Acc: 83.986% (10804/12864)
Loss: 0.665 | Acc: 83.913% (16165/19264)
Loss: 0.664 | Acc: 83.904% (21533/25664)
Loss: 0.669 | Acc: 83.795% (26868/32064)
Loss: 0.670 | Acc: 83.702% (32195/38464)
Loss: 0.675 | Acc: 83.506% (37464/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0450, Accuracy: 7131/10000 (71.31%)

Epoch: 125
Loss: 0.707 | Acc: 84.375% (54/64)
Loss: 0.648 | Acc: 84.081% (5435/6464)
Loss: 0.642 | Acc: 84.251% (10838/12864)
Loss: 0.656 | Acc: 83.882% (16159/19264)
Loss: 0.656 | Acc: 83.884% (21528/25664)
Loss: 0.661 | Acc: 83.792% (26867/32064)
Loss: 0.661 | Acc: 83.785% (32227/38464)
Loss: 0.665 | Acc: 83.760% (37578/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9505, Accuracy: 7475/10000 (74.75%)

Epoch: 126
Loss: 0.549 | Acc: 84.375% (54/64)
Loss: 0.617 | Acc: 84.994% (5494/6464)
Loss: 0.623 | Acc: 84.981% (10932/12864)
Loss: 0.645 | Acc: 84.489% (16276/19264)
Loss: 0.647 | Acc: 84.457% (21675/25664)
Loss: 0.648 | Acc: 84.431% (27072/32064)
Loss: 0.647 | Acc: 84.422% (32472/38464)
Loss: 0.650 | Acc: 84.328% (37833/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8984, Accuracy: 7678/10000 (76.78%)

Epoch: 127
Loss: 0.612 | Acc: 84.375% (54/64)
Loss: 0.616 | Acc: 85.566% (5531/6464)
Loss: 0.629 | Acc: 85.051% (10941/12864)
Loss: 0.637 | Acc: 84.847% (16345/19264)
Loss: 0.640 | Acc: 84.741% (21748/25664)
Loss: 0.642 | Acc: 84.656% (27144/32064)
Loss: 0.639 | Acc: 84.755% (32600/38464)
Loss: 0.637 | Acc: 84.796% (38043/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8203, Accuracy: 7931/10000 (79.31%)

Epoch: 128
Loss: 0.836 | Acc: 81.250% (52/64)
Loss: 0.598 | Acc: 85.860% (5550/6464)
Loss: 0.607 | Acc: 85.448% (10992/12864)
Loss: 0.614 | Acc: 85.169% (16407/19264)
Loss: 0.620 | Acc: 85.127% (21847/25664)
Loss: 0.624 | Acc: 85.089% (27283/32064)
Loss: 0.628 | Acc: 85.051% (32714/38464)
Loss: 0.630 | Acc: 84.997% (38133/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9140, Accuracy: 7658/10000 (76.58%)

Epoch: 129
Loss: 0.660 | Acc: 85.938% (55/64)
Loss: 0.594 | Acc: 86.154% (5569/6464)
Loss: 0.606 | Acc: 85.790% (11036/12864)
Loss: 0.600 | Acc: 85.766% (16522/19264)
Loss: 0.602 | Acc: 85.723% (22000/25664)
Loss: 0.611 | Acc: 85.485% (27410/32064)
Loss: 0.614 | Acc: 85.433% (32861/38464)
Loss: 0.615 | Acc: 85.438% (38331/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0862, Accuracy: 7106/10000 (71.06%)

Epoch: 130
Loss: 0.756 | Acc: 84.375% (54/64)
Loss: 0.609 | Acc: 85.458% (5524/6464)
Loss: 0.621 | Acc: 85.207% (10961/12864)
Loss: 0.604 | Acc: 85.797% (16528/19264)
Loss: 0.603 | Acc: 85.743% (22005/25664)
Loss: 0.597 | Acc: 85.938% (27555/32064)
Loss: 0.599 | Acc: 85.849% (33021/38464)
Loss: 0.598 | Acc: 85.799% (38493/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0491, Accuracy: 7053/10000 (70.53%)

Epoch: 131
Loss: 0.757 | Acc: 79.688% (51/64)
Loss: 0.563 | Acc: 86.959% (5621/6464)
Loss: 0.564 | Acc: 86.785% (11164/12864)
Loss: 0.561 | Acc: 86.862% (16733/19264)
Loss: 0.570 | Acc: 86.584% (22221/25664)
Loss: 0.577 | Acc: 86.486% (27731/32064)
Loss: 0.578 | Acc: 86.502% (33272/38464)
Loss: 0.581 | Acc: 86.368% (38748/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8358, Accuracy: 7961/10000 (79.61%)

Epoch: 132
Loss: 0.817 | Acc: 81.250% (52/64)
Loss: 0.541 | Acc: 87.500% (5656/6464)
Loss: 0.555 | Acc: 87.220% (11220/12864)
Loss: 0.556 | Acc: 87.173% (16793/19264)
Loss: 0.562 | Acc: 87.009% (22330/25664)
Loss: 0.566 | Acc: 86.873% (27855/32064)
Loss: 0.568 | Acc: 86.837% (33401/38464)
Loss: 0.567 | Acc: 86.800% (38942/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7705, Accuracy: 8185/10000 (81.85%)

Epoch: 133
Loss: 0.535 | Acc: 89.062% (57/64)
Loss: 0.487 | Acc: 88.660% (5731/6464)
Loss: 0.515 | Acc: 88.091% (11332/12864)
Loss: 0.532 | Acc: 87.718% (16898/19264)
Loss: 0.535 | Acc: 87.621% (22487/25664)
Loss: 0.546 | Acc: 87.310% (27995/32064)
Loss: 0.549 | Acc: 87.276% (33570/38464)
Loss: 0.549 | Acc: 87.253% (39145/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8931, Accuracy: 7787/10000 (77.87%)

Epoch: 134
Loss: 0.393 | Acc: 90.625% (58/64)
Loss: 0.543 | Acc: 87.268% (5641/6464)
Loss: 0.529 | Acc: 87.624% (11272/12864)
Loss: 0.527 | Acc: 87.754% (16905/19264)
Loss: 0.526 | Acc: 87.718% (22512/25664)
Loss: 0.535 | Acc: 87.512% (28060/32064)
Loss: 0.534 | Acc: 87.586% (33689/38464)
Loss: 0.527 | Acc: 87.741% (39364/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8288, Accuracy: 7968/10000 (79.68%)

Epoch: 135
Loss: 0.489 | Acc: 90.625% (58/64)
Loss: 0.471 | Acc: 89.001% (5753/6464)
Loss: 0.476 | Acc: 88.930% (11440/12864)
Loss: 0.481 | Acc: 88.844% (17115/19264)
Loss: 0.496 | Acc: 88.560% (22728/25664)
Loss: 0.500 | Acc: 88.461% (28364/32064)
Loss: 0.508 | Acc: 88.218% (33932/38464)
Loss: 0.507 | Acc: 88.240% (39588/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8148, Accuracy: 8098/10000 (80.98%)

Epoch: 136
Loss: 0.385 | Acc: 92.188% (59/64)
Loss: 0.495 | Acc: 88.243% (5704/6464)
Loss: 0.486 | Acc: 88.479% (11382/12864)
Loss: 0.475 | Acc: 88.886% (17123/19264)
Loss: 0.478 | Acc: 88.778% (22784/25664)
Loss: 0.481 | Acc: 88.723% (28448/32064)
Loss: 0.485 | Acc: 88.649% (34098/38464)
Loss: 0.485 | Acc: 88.695% (39792/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8925, Accuracy: 7873/10000 (78.73%)

Epoch: 137
Loss: 0.664 | Acc: 84.375% (54/64)
Loss: 0.445 | Acc: 89.372% (5777/6464)
Loss: 0.440 | Acc: 89.614% (11528/12864)
Loss: 0.447 | Acc: 89.519% (17245/19264)
Loss: 0.447 | Acc: 89.534% (22978/25664)
Loss: 0.452 | Acc: 89.474% (28689/32064)
Loss: 0.457 | Acc: 89.385% (34381/38464)
Loss: 0.458 | Acc: 89.310% (40068/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9056, Accuracy: 7844/10000 (78.44%)

Epoch: 138
Loss: 0.352 | Acc: 90.625% (58/64)
Loss: 0.419 | Acc: 90.022% (5819/6464)
Loss: 0.425 | Acc: 89.995% (11577/12864)
Loss: 0.417 | Acc: 90.236% (17383/19264)
Loss: 0.417 | Acc: 90.228% (23156/25664)
Loss: 0.421 | Acc: 90.123% (28897/32064)
Loss: 0.418 | Acc: 90.232% (34707/38464)
Loss: 0.424 | Acc: 90.139% (40440/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8064, Accuracy: 8235/10000 (82.35%)

Epoch: 139
Loss: 0.436 | Acc: 90.625% (58/64)
Loss: 0.388 | Acc: 90.795% (5869/6464)
Loss: 0.391 | Acc: 90.749% (11674/12864)
Loss: 0.391 | Acc: 90.734% (17479/19264)
Loss: 0.399 | Acc: 90.516% (23230/25664)
Loss: 0.402 | Acc: 90.397% (28985/32064)
Loss: 0.401 | Acc: 90.456% (34793/38464)
Loss: 0.401 | Acc: 90.447% (40578/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8681, Accuracy: 8162/10000 (81.62%)

Epoch: 140
Loss: 0.344 | Acc: 90.625% (58/64)
Loss: 0.358 | Acc: 91.429% (5910/6464)
Loss: 0.363 | Acc: 91.457% (11765/12864)
Loss: 0.357 | Acc: 91.622% (17650/19264)
Loss: 0.362 | Acc: 91.451% (23470/25664)
Loss: 0.358 | Acc: 91.542% (29352/32064)
Loss: 0.360 | Acc: 91.462% (35180/38464)
Loss: 0.363 | Acc: 91.334% (40976/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8701, Accuracy: 8200/10000 (82.00%)

Epoch: 141
Loss: 0.379 | Acc: 92.188% (59/64)
Loss: 0.324 | Acc: 92.079% (5952/6464)
Loss: 0.335 | Acc: 91.783% (11807/12864)
Loss: 0.330 | Acc: 91.969% (17717/19264)
Loss: 0.333 | Acc: 91.899% (23585/25664)
Loss: 0.329 | Acc: 92.016% (29504/32064)
Loss: 0.326 | Acc: 92.058% (35409/38464)
Loss: 0.332 | Acc: 91.929% (41243/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8974, Accuracy: 8190/10000 (81.90%)

Epoch: 142
Loss: 0.312 | Acc: 93.750% (60/64)
Loss: 0.311 | Acc: 92.265% (5964/6464)
Loss: 0.298 | Acc: 92.561% (11907/12864)
Loss: 0.296 | Acc: 92.608% (17840/19264)
Loss: 0.295 | Acc: 92.659% (23780/25664)
Loss: 0.294 | Acc: 92.652% (29708/32064)
Loss: 0.296 | Acc: 92.642% (35634/38464)
Loss: 0.297 | Acc: 92.622% (41554/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8721, Accuracy: 8266/10000 (82.66%)

Epoch: 143
Loss: 0.360 | Acc: 90.625% (58/64)
Loss: 0.276 | Acc: 92.930% (6007/6464)
Loss: 0.278 | Acc: 92.879% (11948/12864)
Loss: 0.267 | Acc: 93.210% (17956/19264)
Loss: 0.268 | Acc: 93.169% (23911/25664)
Loss: 0.267 | Acc: 93.186% (29879/32064)
Loss: 0.265 | Acc: 93.246% (35866/38464)
Loss: 0.268 | Acc: 93.173% (41801/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9178, Accuracy: 8263/10000 (82.63%)

Epoch: 144
Loss: 0.319 | Acc: 93.750% (60/64)
Loss: 0.244 | Acc: 93.580% (6049/6464)
Loss: 0.237 | Acc: 93.789% (12065/12864)
Loss: 0.238 | Acc: 93.776% (18065/19264)
Loss: 0.237 | Acc: 93.766% (24064/25664)
Loss: 0.234 | Acc: 93.844% (30090/32064)
Loss: 0.234 | Acc: 93.859% (36102/38464)
Loss: 0.236 | Acc: 93.830% (42096/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9408, Accuracy: 8202/10000 (82.02%)

Epoch: 145
Loss: 0.206 | Acc: 93.750% (60/64)
Loss: 0.199 | Acc: 94.616% (6116/6464)
Loss: 0.200 | Acc: 94.597% (12169/12864)
Loss: 0.203 | Acc: 94.539% (18212/19264)
Loss: 0.203 | Acc: 94.592% (24276/25664)
Loss: 0.201 | Acc: 94.614% (30337/32064)
Loss: 0.202 | Acc: 94.548% (36367/38464)
Loss: 0.203 | Acc: 94.541% (42415/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9632, Accuracy: 8150/10000 (81.50%)

Epoch: 146
Loss: 0.379 | Acc: 87.500% (56/64)
Loss: 0.176 | Acc: 95.374% (6165/6464)
Loss: 0.187 | Acc: 94.947% (12214/12864)
Loss: 0.190 | Acc: 94.913% (18284/19264)
Loss: 0.185 | Acc: 95.020% (24386/25664)
Loss: 0.187 | Acc: 95.054% (30478/32064)
Loss: 0.189 | Acc: 94.982% (36534/38464)
Loss: 0.189 | Acc: 94.989% (42616/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9650, Accuracy: 8168/10000 (81.68%)

Epoch: 147
Loss: 0.167 | Acc: 96.875% (62/64)
Loss: 0.173 | Acc: 95.251% (6157/6464)
Loss: 0.178 | Acc: 95.157% (12241/12864)
Loss: 0.179 | Acc: 95.053% (18311/19264)
Loss: 0.177 | Acc: 95.133% (24415/25664)
Loss: 0.176 | Acc: 95.178% (30518/32064)
Loss: 0.177 | Acc: 95.188% (36613/38464)
Loss: 0.177 | Acc: 95.228% (42723/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9592, Accuracy: 8171/10000 (81.71%)
torch.Size([100, 10])
Test set: Average loss: 0.9592, Accuracy: 8171/10000 (81.71%)

Epoch: 148
Loss: 0.082 | Acc: 98.438% (63/64)
Loss: 0.159 | Acc: 95.653% (6183/6464)
Loss: 0.161 | Acc: 95.491% (12284/12864)
Loss: 0.163 | Acc: 95.494% (18396/19264)
Loss: 0.162 | Acc: 95.511% (24512/25664)
Loss: 0.163 | Acc: 95.478% (30614/32064)
Loss: 0.165 | Acc: 95.403% (36696/38464)
Loss: 0.165 | Acc: 95.397% (42799/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9625, Accuracy: 8159/10000 (81.59%)
torch.Size([100, 10])
Test set: Average loss: 0.9625, Accuracy: 8159/10000 (81.59%)

Epoch: 149
Loss: 0.238 | Acc: 95.312% (61/64)
Loss: 0.168 | Acc: 95.514% (6174/6464)
Loss: 0.163 | Acc: 95.655% (12305/12864)
Loss: 0.159 | Acc: 95.764% (18448/19264)
Loss: 0.158 | Acc: 95.803% (24587/25664)
Loss: 0.158 | Acc: 95.762% (30705/32064)
Loss: 0.162 | Acc: 95.630% (36783/38464)
Loss: 0.162 | Acc: 95.622% (42900/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9741, Accuracy: 8177/10000 (81.77%)
torch.Size([100, 10])
Test set: Average loss: 0.9741, Accuracy: 8177/10000 (81.77%)

Epoch: 150
Loss: 0.083 | Acc: 98.438% (63/64)
Loss: 2.018 | Acc: 26.609% (1720/6464)
Loss: 1.654 | Acc: 43.113% (5546/12864)
Loss: 1.448 | Acc: 52.123% (10041/19264)
Loss: 1.327 | Acc: 57.423% (14737/25664)
Loss: 1.241 | Acc: 61.031% (19569/32064)
Loss: 1.183 | Acc: 63.449% (24405/38464)
Loss: 1.140 | Acc: 65.320% (29305/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8235, Accuracy: 4547/10000 (45.47%)

Epoch: 151
Loss: 1.037 | Acc: 67.188% (43/64)
Loss: 0.837 | Acc: 76.965% (4975/6464)
Loss: 0.839 | Acc: 77.052% (9912/12864)
Loss: 0.847 | Acc: 76.999% (14833/19264)
Loss: 0.843 | Acc: 77.217% (19817/25664)
Loss: 0.837 | Acc: 77.479% (24843/32064)
Loss: 0.837 | Acc: 77.605% (29850/38464)
Loss: 0.835 | Acc: 77.681% (34851/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7478, Accuracy: 5122/10000 (51.22%)

Epoch: 152
Loss: 0.773 | Acc: 76.562% (49/64)
Loss: 0.796 | Acc: 79.316% (5127/6464)
Loss: 0.784 | Acc: 79.462% (10222/12864)
Loss: 0.794 | Acc: 79.298% (15276/19264)
Loss: 0.798 | Acc: 79.177% (20320/25664)
Loss: 0.803 | Acc: 78.983% (25325/32064)
Loss: 0.807 | Acc: 78.902% (30349/38464)
Loss: 0.804 | Acc: 79.001% (35443/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6579, Accuracy: 5180/10000 (51.80%)

Epoch: 153
Loss: 0.857 | Acc: 76.562% (49/64)
Loss: 0.792 | Acc: 79.162% (5117/6464)
Loss: 0.780 | Acc: 79.610% (10241/12864)
Loss: 0.788 | Acc: 79.485% (15312/19264)
Loss: 0.785 | Acc: 79.688% (20451/25664)
Loss: 0.790 | Acc: 79.619% (25529/32064)
Loss: 0.794 | Acc: 79.495% (30577/38464)
Loss: 0.795 | Acc: 79.496% (35665/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1313, Accuracy: 6841/10000 (68.41%)

Epoch: 154
Loss: 0.883 | Acc: 79.688% (51/64)
Loss: 0.783 | Acc: 79.517% (5140/6464)
Loss: 0.793 | Acc: 79.361% (10209/12864)
Loss: 0.788 | Acc: 79.594% (15333/19264)
Loss: 0.787 | Acc: 79.649% (20441/25664)
Loss: 0.790 | Acc: 79.585% (25518/32064)
Loss: 0.788 | Acc: 79.581% (30610/38464)
Loss: 0.787 | Acc: 79.688% (35751/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9144, Accuracy: 4516/10000 (45.16%)

Epoch: 155
Loss: 1.257 | Acc: 60.938% (39/64)
Loss: 0.801 | Acc: 79.270% (5124/6464)
Loss: 0.797 | Acc: 79.462% (10222/12864)
Loss: 0.784 | Acc: 79.926% (15397/19264)
Loss: 0.782 | Acc: 79.949% (20518/25664)
Loss: 0.779 | Acc: 80.109% (25686/32064)
Loss: 0.783 | Acc: 80.002% (30772/38464)
Loss: 0.784 | Acc: 79.948% (35868/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0939, Accuracy: 6966/10000 (69.66%)

Epoch: 156
Loss: 0.584 | Acc: 85.938% (55/64)
Loss: 0.773 | Acc: 79.688% (5151/6464)
Loss: 0.774 | Acc: 79.967% (10287/12864)
Loss: 0.766 | Acc: 80.310% (15471/19264)
Loss: 0.764 | Acc: 80.338% (20618/25664)
Loss: 0.770 | Acc: 80.137% (25695/32064)
Loss: 0.775 | Acc: 80.025% (30781/38464)
Loss: 0.774 | Acc: 79.982% (35883/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2277, Accuracy: 6473/10000 (64.73%)

Epoch: 157
Loss: 0.700 | Acc: 81.250% (52/64)
Loss: 0.779 | Acc: 79.950% (5168/6464)
Loss: 0.765 | Acc: 80.434% (10347/12864)
Loss: 0.774 | Acc: 80.269% (15463/19264)
Loss: 0.779 | Acc: 80.175% (20576/25664)
Loss: 0.778 | Acc: 80.180% (25709/32064)
Loss: 0.773 | Acc: 80.296% (30885/38464)
Loss: 0.776 | Acc: 80.180% (35972/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0893, Accuracy: 6926/10000 (69.26%)

Epoch: 158
Loss: 0.770 | Acc: 84.375% (54/64)
Loss: 0.766 | Acc: 80.678% (5215/6464)
Loss: 0.761 | Acc: 80.581% (10366/12864)
Loss: 0.765 | Acc: 80.342% (15477/19264)
Loss: 0.765 | Acc: 80.358% (20623/25664)
Loss: 0.769 | Acc: 80.339% (25760/32064)
Loss: 0.770 | Acc: 80.343% (30903/38464)
Loss: 0.773 | Acc: 80.274% (36014/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9235, Accuracy: 7517/10000 (75.17%)

Epoch: 159
Loss: 0.961 | Acc: 76.562% (49/64)
Loss: 0.756 | Acc: 80.291% (5190/6464)
Loss: 0.753 | Acc: 80.488% (10354/12864)
Loss: 0.757 | Acc: 80.637% (15534/19264)
Loss: 0.757 | Acc: 80.603% (20686/25664)
Loss: 0.759 | Acc: 80.545% (25826/32064)
Loss: 0.764 | Acc: 80.452% (30945/38464)
Loss: 0.769 | Acc: 80.309% (36030/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1911, Accuracy: 6608/10000 (66.08%)

Epoch: 160
Loss: 0.883 | Acc: 73.438% (47/64)
Loss: 0.755 | Acc: 80.709% (5217/6464)
Loss: 0.772 | Acc: 80.426% (10346/12864)
Loss: 0.757 | Acc: 80.658% (15538/19264)
Loss: 0.757 | Acc: 80.712% (20714/25664)
Loss: 0.756 | Acc: 80.785% (25903/32064)
Loss: 0.764 | Acc: 80.535% (30977/38464)
Loss: 0.764 | Acc: 80.535% (36131/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5880, Accuracy: 3704/10000 (37.04%)

Epoch: 161
Loss: 1.445 | Acc: 62.500% (40/64)
Loss: 0.733 | Acc: 81.157% (5246/6464)
Loss: 0.748 | Acc: 80.877% (10404/12864)
Loss: 0.760 | Acc: 80.606% (15528/19264)
Loss: 0.762 | Acc: 80.564% (20676/25664)
Loss: 0.764 | Acc: 80.617% (25849/32064)
Loss: 0.764 | Acc: 80.600% (31002/38464)
Loss: 0.764 | Acc: 80.519% (36124/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1570, Accuracy: 6773/10000 (67.73%)

Epoch: 162
Loss: 0.733 | Acc: 81.250% (52/64)
Loss: 0.739 | Acc: 80.987% (5235/6464)
Loss: 0.746 | Acc: 80.939% (10412/12864)
Loss: 0.747 | Acc: 80.980% (15600/19264)
Loss: 0.749 | Acc: 81.040% (20798/25664)
Loss: 0.752 | Acc: 81.016% (25977/32064)
Loss: 0.753 | Acc: 80.998% (31155/38464)
Loss: 0.756 | Acc: 80.873% (36283/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8660, Accuracy: 7728/10000 (77.28%)

Epoch: 163
Loss: 0.412 | Acc: 87.500% (56/64)
Loss: 0.718 | Acc: 82.008% (5301/6464)
Loss: 0.734 | Acc: 81.639% (10502/12864)
Loss: 0.737 | Acc: 81.426% (15686/19264)
Loss: 0.745 | Acc: 81.223% (20845/25664)
Loss: 0.750 | Acc: 81.091% (26001/32064)
Loss: 0.752 | Acc: 81.071% (31183/38464)
Loss: 0.755 | Acc: 80.920% (36304/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2891, Accuracy: 6210/10000 (62.10%)

Epoch: 164
Loss: 0.974 | Acc: 73.438% (47/64)
Loss: 0.736 | Acc: 81.606% (5275/6464)
Loss: 0.717 | Acc: 81.911% (10537/12864)
Loss: 0.727 | Acc: 81.728% (15744/19264)
Loss: 0.741 | Acc: 81.398% (20890/25664)
Loss: 0.740 | Acc: 81.375% (26092/32064)
Loss: 0.744 | Acc: 81.307% (31274/38464)
Loss: 0.746 | Acc: 81.241% (36448/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0495, Accuracy: 7034/10000 (70.34%)

Epoch: 165
Loss: 0.752 | Acc: 81.250% (52/64)
Loss: 0.754 | Acc: 80.755% (5220/6464)
Loss: 0.744 | Acc: 81.102% (10433/12864)
Loss: 0.740 | Acc: 81.401% (15681/19264)
Loss: 0.741 | Acc: 81.375% (20884/25664)
Loss: 0.739 | Acc: 81.462% (26120/32064)
Loss: 0.734 | Acc: 81.536% (31362/38464)
Loss: 0.736 | Acc: 81.538% (36581/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1362, Accuracy: 6882/10000 (68.82%)

Epoch: 166
Loss: 0.905 | Acc: 75.000% (48/64)
Loss: 0.724 | Acc: 81.993% (5300/6464)
Loss: 0.726 | Acc: 81.786% (10521/12864)
Loss: 0.717 | Acc: 81.940% (15785/19264)
Loss: 0.726 | Acc: 81.632% (20950/25664)
Loss: 0.727 | Acc: 81.581% (26158/32064)
Loss: 0.732 | Acc: 81.468% (31336/38464)
Loss: 0.733 | Acc: 81.431% (36533/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9026, Accuracy: 7640/10000 (76.40%)

Epoch: 167
Loss: 0.586 | Acc: 85.938% (55/64)
Loss: 0.707 | Acc: 81.915% (5295/6464)
Loss: 0.718 | Acc: 81.950% (10542/12864)
Loss: 0.723 | Acc: 82.091% (15814/19264)
Loss: 0.720 | Acc: 82.201% (21096/25664)
Loss: 0.722 | Acc: 82.117% (26330/32064)
Loss: 0.723 | Acc: 82.033% (31553/38464)
Loss: 0.727 | Acc: 81.968% (36774/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0689, Accuracy: 7162/10000 (71.62%)

Epoch: 168
Loss: 0.453 | Acc: 85.938% (55/64)
Loss: 0.695 | Acc: 82.658% (5343/6464)
Loss: 0.716 | Acc: 82.074% (10558/12864)
Loss: 0.721 | Acc: 81.847% (15767/19264)
Loss: 0.721 | Acc: 81.959% (21034/25664)
Loss: 0.724 | Acc: 81.864% (26249/32064)
Loss: 0.725 | Acc: 81.877% (31493/38464)
Loss: 0.723 | Acc: 81.939% (36761/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9399, Accuracy: 7434/10000 (74.34%)

Epoch: 169
Loss: 0.641 | Acc: 82.812% (53/64)
Loss: 0.692 | Acc: 83.153% (5375/6464)
Loss: 0.701 | Acc: 82.859% (10659/12864)
Loss: 0.709 | Acc: 82.517% (15896/19264)
Loss: 0.712 | Acc: 82.477% (21167/25664)
Loss: 0.717 | Acc: 82.363% (26409/32064)
Loss: 0.716 | Acc: 82.371% (31683/38464)
Loss: 0.714 | Acc: 82.391% (36964/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1872, Accuracy: 3808/10000 (38.08%)

Epoch: 170
Loss: 1.180 | Acc: 64.062% (41/64)
Loss: 0.709 | Acc: 82.302% (5320/6464)
Loss: 0.702 | Acc: 82.540% (10618/12864)
Loss: 0.713 | Acc: 82.371% (15868/19264)
Loss: 0.710 | Acc: 82.575% (21192/25664)
Loss: 0.712 | Acc: 82.522% (26460/32064)
Loss: 0.708 | Acc: 82.659% (31794/38464)
Loss: 0.710 | Acc: 82.643% (37077/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6587, Accuracy: 6036/10000 (60.36%)

Epoch: 171
Loss: 0.992 | Acc: 73.438% (47/64)
Loss: 0.675 | Acc: 83.555% (5401/6464)
Loss: 0.683 | Acc: 83.318% (10718/12864)
Loss: 0.687 | Acc: 83.150% (16018/19264)
Loss: 0.691 | Acc: 83.140% (21337/25664)
Loss: 0.688 | Acc: 83.131% (26655/32064)
Loss: 0.693 | Acc: 82.974% (31915/38464)
Loss: 0.692 | Acc: 83.026% (37249/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2870, Accuracy: 6493/10000 (64.93%)

Epoch: 172
Loss: 1.079 | Acc: 70.312% (45/64)
Loss: 0.688 | Acc: 82.983% (5364/6464)
Loss: 0.679 | Acc: 83.217% (10705/12864)
Loss: 0.676 | Acc: 83.415% (16069/19264)
Loss: 0.677 | Acc: 83.315% (21382/25664)
Loss: 0.676 | Acc: 83.452% (26758/32064)
Loss: 0.678 | Acc: 83.322% (32049/38464)
Loss: 0.682 | Acc: 83.274% (37360/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3318, Accuracy: 6164/10000 (61.64%)

Epoch: 173
Loss: 0.583 | Acc: 87.500% (56/64)
Loss: 0.673 | Acc: 83.679% (5409/6464)
Loss: 0.658 | Acc: 83.916% (10795/12864)
Loss: 0.667 | Acc: 83.762% (16136/19264)
Loss: 0.670 | Acc: 83.572% (21448/25664)
Loss: 0.674 | Acc: 83.602% (26806/32064)
Loss: 0.675 | Acc: 83.470% (32106/38464)
Loss: 0.675 | Acc: 83.524% (37472/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9882, Accuracy: 4707/10000 (47.07%)

Epoch: 174
Loss: 1.051 | Acc: 70.312% (45/64)
Loss: 0.651 | Acc: 84.035% (5432/6464)
Loss: 0.650 | Acc: 84.072% (10815/12864)
Loss: 0.654 | Acc: 84.069% (16195/19264)
Loss: 0.667 | Acc: 83.888% (21529/25664)
Loss: 0.664 | Acc: 83.938% (26914/32064)
Loss: 0.662 | Acc: 84.021% (32318/38464)
Loss: 0.666 | Acc: 83.936% (37657/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8844, Accuracy: 7724/10000 (77.24%)

Epoch: 175
Loss: 0.632 | Acc: 84.375% (54/64)
Loss: 0.647 | Acc: 84.220% (5444/6464)
Loss: 0.634 | Acc: 84.569% (10879/12864)
Loss: 0.640 | Acc: 84.546% (16287/19264)
Loss: 0.648 | Acc: 84.352% (21648/25664)
Loss: 0.642 | Acc: 84.481% (27088/32064)
Loss: 0.648 | Acc: 84.318% (32432/38464)
Loss: 0.653 | Acc: 84.226% (37787/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9434, Accuracy: 7563/10000 (75.63%)

Epoch: 176
Loss: 0.729 | Acc: 82.812% (53/64)
Loss: 0.645 | Acc: 84.592% (5468/6464)
Loss: 0.645 | Acc: 84.585% (10881/12864)
Loss: 0.645 | Acc: 84.557% (16289/19264)
Loss: 0.650 | Acc: 84.426% (21667/25664)
Loss: 0.651 | Acc: 84.406% (27064/32064)
Loss: 0.647 | Acc: 84.531% (32514/38464)
Loss: 0.646 | Acc: 84.544% (37930/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9236, Accuracy: 7591/10000 (75.91%)

Epoch: 177
Loss: 0.423 | Acc: 90.625% (58/64)
Loss: 0.642 | Acc: 84.824% (5483/6464)
Loss: 0.628 | Acc: 85.044% (10940/12864)
Loss: 0.629 | Acc: 85.034% (16381/19264)
Loss: 0.631 | Acc: 84.905% (21790/25664)
Loss: 0.632 | Acc: 84.868% (27212/32064)
Loss: 0.637 | Acc: 84.739% (32594/38464)
Loss: 0.635 | Acc: 84.803% (38046/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9587, Accuracy: 7462/10000 (74.62%)

Epoch: 178
Loss: 0.518 | Acc: 89.062% (57/64)
Loss: 0.588 | Acc: 86.015% (5560/6464)
Loss: 0.604 | Acc: 85.704% (11025/12864)
Loss: 0.610 | Acc: 85.439% (16459/19264)
Loss: 0.613 | Acc: 85.302% (21892/25664)
Loss: 0.619 | Acc: 85.167% (27308/32064)
Loss: 0.618 | Acc: 85.212% (32776/38464)
Loss: 0.619 | Acc: 85.209% (38228/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1219, Accuracy: 6941/10000 (69.41%)

Epoch: 179
Loss: 0.660 | Acc: 84.375% (54/64)
Loss: 0.618 | Acc: 85.396% (5520/6464)
Loss: 0.607 | Acc: 85.735% (11029/12864)
Loss: 0.601 | Acc: 85.787% (16526/19264)
Loss: 0.601 | Acc: 85.766% (22011/25664)
Loss: 0.604 | Acc: 85.735% (27490/32064)
Loss: 0.601 | Acc: 85.818% (33009/38464)
Loss: 0.603 | Acc: 85.799% (38493/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8213, Accuracy: 7985/10000 (79.85%)

Epoch: 180
Loss: 0.442 | Acc: 92.188% (59/64)
Loss: 0.594 | Acc: 85.845% (5549/6464)
Loss: 0.599 | Acc: 85.728% (11028/12864)
Loss: 0.594 | Acc: 85.844% (16537/19264)
Loss: 0.589 | Acc: 86.023% (22077/25664)
Loss: 0.593 | Acc: 86.006% (27577/32064)
Loss: 0.595 | Acc: 85.930% (33052/38464)
Loss: 0.593 | Acc: 85.993% (38580/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0952, Accuracy: 7007/10000 (70.07%)

Epoch: 181
Loss: 0.778 | Acc: 78.125% (50/64)
Loss: 0.572 | Acc: 86.293% (5578/6464)
Loss: 0.555 | Acc: 86.948% (11185/12864)
Loss: 0.562 | Acc: 86.763% (16714/19264)
Loss: 0.569 | Acc: 86.623% (22231/25664)
Loss: 0.566 | Acc: 86.820% (27838/32064)
Loss: 0.571 | Acc: 86.738% (33363/38464)
Loss: 0.573 | Acc: 86.733% (38912/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8517, Accuracy: 7952/10000 (79.52%)

Epoch: 182
Loss: 0.643 | Acc: 82.812% (53/64)
Loss: 0.546 | Acc: 87.098% (5630/6464)
Loss: 0.533 | Acc: 87.446% (11249/12864)
Loss: 0.546 | Acc: 87.240% (16806/19264)
Loss: 0.551 | Acc: 87.075% (22347/25664)
Loss: 0.558 | Acc: 86.907% (27866/32064)
Loss: 0.558 | Acc: 86.941% (33441/38464)
Loss: 0.557 | Acc: 86.990% (39027/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7872, Accuracy: 8165/10000 (81.65%)

Epoch: 183
Loss: 0.411 | Acc: 93.750% (60/64)
Loss: 0.508 | Acc: 87.980% (5687/6464)
Loss: 0.525 | Acc: 87.694% (11281/12864)
Loss: 0.537 | Acc: 87.448% (16846/19264)
Loss: 0.536 | Acc: 87.434% (22439/25664)
Loss: 0.535 | Acc: 87.494% (28054/32064)
Loss: 0.537 | Acc: 87.451% (33637/38464)
Loss: 0.538 | Acc: 87.420% (39220/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8063, Accuracy: 8064/10000 (80.64%)

Epoch: 184
Loss: 0.623 | Acc: 87.500% (56/64)
Loss: 0.503 | Acc: 88.413% (5715/6464)
Loss: 0.516 | Acc: 87.982% (11318/12864)
Loss: 0.522 | Acc: 87.734% (16901/19264)
Loss: 0.519 | Acc: 87.944% (22570/25664)
Loss: 0.518 | Acc: 87.899% (28184/32064)
Loss: 0.518 | Acc: 87.882% (33803/38464)
Loss: 0.519 | Acc: 87.926% (39447/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7910, Accuracy: 8131/10000 (81.31%)

Epoch: 185
Loss: 0.493 | Acc: 85.938% (55/64)
Loss: 0.483 | Acc: 88.908% (5747/6464)
Loss: 0.481 | Acc: 88.969% (11445/12864)
Loss: 0.485 | Acc: 88.928% (17131/19264)
Loss: 0.496 | Acc: 88.548% (22725/25664)
Loss: 0.498 | Acc: 88.454% (28362/32064)
Loss: 0.498 | Acc: 88.478% (34032/38464)
Loss: 0.501 | Acc: 88.467% (39690/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8450, Accuracy: 8055/10000 (80.55%)

Epoch: 186
Loss: 0.232 | Acc: 96.875% (62/64)
Loss: 0.452 | Acc: 89.356% (5776/6464)
Loss: 0.467 | Acc: 89.024% (11452/12864)
Loss: 0.469 | Acc: 89.011% (17147/19264)
Loss: 0.476 | Acc: 88.860% (22805/25664)
Loss: 0.480 | Acc: 88.732% (28451/32064)
Loss: 0.480 | Acc: 88.766% (34143/38464)
Loss: 0.478 | Acc: 88.799% (39839/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8179, Accuracy: 8148/10000 (81.48%)

Epoch: 187
Loss: 0.280 | Acc: 93.750% (60/64)
Loss: 0.435 | Acc: 90.006% (5818/6464)
Loss: 0.436 | Acc: 89.902% (11565/12864)
Loss: 0.447 | Acc: 89.602% (17261/19264)
Loss: 0.452 | Acc: 89.468% (22961/25664)
Loss: 0.453 | Acc: 89.431% (28675/32064)
Loss: 0.456 | Acc: 89.424% (34396/38464)
Loss: 0.455 | Acc: 89.453% (40132/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8144, Accuracy: 8200/10000 (82.00%)

Epoch: 188
Loss: 0.565 | Acc: 84.375% (54/64)
Loss: 0.428 | Acc: 89.805% (5805/6464)
Loss: 0.421 | Acc: 90.104% (11591/12864)
Loss: 0.423 | Acc: 90.044% (17346/19264)
Loss: 0.424 | Acc: 90.083% (23119/25664)
Loss: 0.427 | Acc: 89.995% (28856/32064)
Loss: 0.425 | Acc: 90.074% (34646/38464)
Loss: 0.425 | Acc: 90.028% (40390/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8252, Accuracy: 8147/10000 (81.47%)

Epoch: 189
Loss: 0.232 | Acc: 95.312% (61/64)
Loss: 0.359 | Acc: 91.584% (5920/6464)
Loss: 0.381 | Acc: 91.107% (11720/12864)
Loss: 0.388 | Acc: 91.035% (17537/19264)
Loss: 0.394 | Acc: 90.847% (23315/25664)
Loss: 0.394 | Acc: 90.846% (29129/32064)
Loss: 0.396 | Acc: 90.804% (34927/38464)
Loss: 0.398 | Acc: 90.719% (40700/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8308, Accuracy: 8237/10000 (82.37%)

Epoch: 190
Loss: 0.316 | Acc: 93.750% (60/64)
Loss: 0.353 | Acc: 91.352% (5905/6464)
Loss: 0.350 | Acc: 91.519% (11773/12864)
Loss: 0.354 | Acc: 91.435% (17614/19264)
Loss: 0.358 | Acc: 91.385% (23453/25664)
Loss: 0.357 | Acc: 91.389% (29303/32064)
Loss: 0.359 | Acc: 91.361% (35141/38464)
Loss: 0.360 | Acc: 91.340% (40979/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9073, Accuracy: 8050/10000 (80.50%)

Epoch: 191
Loss: 0.372 | Acc: 90.625% (58/64)
Loss: 0.321 | Acc: 92.002% (5947/6464)
Loss: 0.320 | Acc: 92.125% (11851/12864)
Loss: 0.327 | Acc: 92.032% (17729/19264)
Loss: 0.326 | Acc: 92.036% (23620/25664)
Loss: 0.327 | Acc: 92.038% (29511/32064)
Loss: 0.332 | Acc: 91.881% (35341/38464)
Loss: 0.331 | Acc: 91.909% (41234/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8741, Accuracy: 8176/10000 (81.76%)

Epoch: 192
Loss: 0.192 | Acc: 96.875% (62/64)
Loss: 0.294 | Acc: 92.605% (5986/6464)
Loss: 0.289 | Acc: 92.778% (11935/12864)
Loss: 0.288 | Acc: 92.862% (17889/19264)
Loss: 0.289 | Acc: 92.877% (23836/25664)
Loss: 0.292 | Acc: 92.749% (29739/32064)
Loss: 0.290 | Acc: 92.765% (35681/38464)
Loss: 0.292 | Acc: 92.711% (41594/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9032, Accuracy: 8227/10000 (82.27%)

Epoch: 193
Loss: 0.162 | Acc: 93.750% (60/64)
Loss: 0.262 | Acc: 93.317% (6032/6464)
Loss: 0.259 | Acc: 93.416% (12017/12864)
Loss: 0.258 | Acc: 93.418% (17996/19264)
Loss: 0.262 | Acc: 93.294% (23943/25664)
Loss: 0.260 | Acc: 93.404% (29949/32064)
Loss: 0.258 | Acc: 93.417% (35932/38464)
Loss: 0.258 | Acc: 93.456% (41928/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9276, Accuracy: 8223/10000 (82.23%)

Epoch: 194
Loss: 0.182 | Acc: 95.312% (61/64)
Loss: 0.220 | Acc: 94.493% (6108/6464)
Loss: 0.226 | Acc: 94.162% (12113/12864)
Loss: 0.228 | Acc: 94.098% (18127/19264)
Loss: 0.227 | Acc: 94.105% (24151/25664)
Loss: 0.229 | Acc: 94.099% (30172/32064)
Loss: 0.230 | Acc: 94.049% (36175/38464)
Loss: 0.229 | Acc: 94.084% (42210/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9349, Accuracy: 8215/10000 (82.15%)

Epoch: 195
Loss: 0.290 | Acc: 93.750% (60/64)
Loss: 0.203 | Acc: 94.725% (6123/6464)
Loss: 0.202 | Acc: 94.628% (12173/12864)
Loss: 0.205 | Acc: 94.581% (18220/19264)
Loss: 0.207 | Acc: 94.537% (24262/25664)
Loss: 0.207 | Acc: 94.545% (30315/32064)
Loss: 0.205 | Acc: 94.587% (36382/38464)
Loss: 0.206 | Acc: 94.568% (42427/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9433, Accuracy: 8239/10000 (82.39%)

Epoch: 196
Loss: 0.265 | Acc: 93.750% (60/64)
Loss: 0.183 | Acc: 95.189% (6153/6464)
Loss: 0.180 | Acc: 95.297% (12259/12864)
Loss: 0.185 | Acc: 95.043% (18309/19264)
Loss: 0.185 | Acc: 95.090% (24404/25664)
Loss: 0.183 | Acc: 95.132% (30503/32064)
Loss: 0.183 | Acc: 95.073% (36569/38464)
Loss: 0.184 | Acc: 95.058% (42647/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9614, Accuracy: 8225/10000 (82.25%)

Epoch: 197
Loss: 0.095 | Acc: 98.438% (63/64)
Loss: 0.170 | Acc: 95.529% (6175/6464)
Loss: 0.172 | Acc: 95.398% (12272/12864)
Loss: 0.170 | Acc: 95.437% (18385/19264)
Loss: 0.170 | Acc: 95.429% (24491/25664)
Loss: 0.171 | Acc: 95.381% (30583/32064)
Loss: 0.171 | Acc: 95.393% (36692/38464)
Loss: 0.171 | Acc: 95.353% (42779/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9666, Accuracy: 8216/10000 (82.16%)
torch.Size([100, 10])
Test set: Average loss: 0.9666, Accuracy: 8216/10000 (82.16%)

Epoch: 198
Loss: 0.201 | Acc: 92.188% (59/64)
Loss: 0.175 | Acc: 95.251% (6157/6464)
Loss: 0.166 | Acc: 95.577% (12295/12864)
Loss: 0.165 | Acc: 95.634% (18423/19264)
Loss: 0.167 | Acc: 95.535% (24518/25664)
Loss: 0.165 | Acc: 95.509% (30624/32064)
Loss: 0.166 | Acc: 95.479% (36725/38464)
Loss: 0.165 | Acc: 95.509% (42849/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9633, Accuracy: 8220/10000 (82.20%)
torch.Size([100, 10])
Test set: Average loss: 0.9633, Accuracy: 8220/10000 (82.20%)

Epoch: 199
Loss: 0.035 | Acc: 100.000% (64/64)
Loss: 0.170 | Acc: 95.374% (6165/6464)
Loss: 0.168 | Acc: 95.429% (12276/12864)
Loss: 0.166 | Acc: 95.494% (18396/19264)
Loss: 0.162 | Acc: 95.632% (24543/25664)
Loss: 0.164 | Acc: 95.578% (30646/32064)
Loss: 0.162 | Acc: 95.650% (36791/38464)
Loss: 0.163 | Acc: 95.640% (42908/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9709, Accuracy: 8226/10000 (82.26%)
torch.Size([100, 10])
Test set: Average loss: 0.9709, Accuracy: 8226/10000 (82.26%)
8454
10000
-0.7887663245201111
