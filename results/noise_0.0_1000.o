==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.361 | Acc: 15.625% (10/64)
Loss: 2.835 | Acc: 16.801% (1086/6464)
Loss: 2.430 | Acc: 19.963% (2568/12864)
Loss: 2.259 | Acc: 21.958% (4230/19264)
Loss: 2.159 | Acc: 23.983% (6155/25664)
Loss: 2.083 | Acc: 25.742% (8254/32064)
Loss: 2.020 | Acc: 27.600% (10616/38464)
Loss: 1.966 | Acc: 29.177% (13090/44864)
torch.Size([100, 10])
Test set: Average loss: 3.3312, Accuracy: 1984/10000 (19.84%)

Epoch: 1
Loss: 1.983 | Acc: 35.938% (23/64)
Loss: 1.568 | Acc: 41.631% (2691/6464)
Loss: 1.538 | Acc: 42.817% (5508/12864)
Loss: 1.520 | Acc: 43.340% (8349/19264)
Loss: 1.501 | Acc: 44.233% (11352/25664)
Loss: 1.478 | Acc: 45.325% (14533/32064)
Loss: 1.459 | Acc: 46.051% (17713/38464)
Loss: 1.437 | Acc: 46.888% (21036/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5078, Accuracy: 4750/10000 (47.50%)

Epoch: 2
Loss: 1.194 | Acc: 53.125% (34/64)
Loss: 1.241 | Acc: 54.595% (3529/6464)
Loss: 1.236 | Acc: 55.372% (7123/12864)
Loss: 1.209 | Acc: 56.421% (10869/19264)
Loss: 1.186 | Acc: 57.407% (14733/25664)
Loss: 1.167 | Acc: 58.212% (18665/32064)
Loss: 1.149 | Acc: 58.951% (22675/38464)
Loss: 1.134 | Acc: 59.391% (26645/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0709, Accuracy: 6182/10000 (61.82%)

Epoch: 3
Loss: 1.087 | Acc: 68.750% (44/64)
Loss: 1.000 | Acc: 64.032% (4139/6464)
Loss: 0.996 | Acc: 64.443% (8290/12864)
Loss: 0.975 | Acc: 65.121% (12545/19264)
Loss: 0.960 | Acc: 65.824% (16893/25664)
Loss: 0.946 | Acc: 66.383% (21285/32064)
Loss: 0.934 | Acc: 66.818% (25701/38464)
Loss: 0.923 | Acc: 67.212% (30154/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5769, Accuracy: 5236/10000 (52.36%)

Epoch: 4
Loss: 1.635 | Acc: 51.562% (33/64)
Loss: 0.806 | Acc: 72.308% (4674/6464)
Loss: 0.797 | Acc: 72.217% (9290/12864)
Loss: 0.790 | Acc: 72.607% (13987/19264)
Loss: 0.780 | Acc: 72.713% (18661/25664)
Loss: 0.774 | Acc: 72.932% (23385/32064)
Loss: 0.765 | Acc: 73.393% (28230/38464)
Loss: 0.758 | Acc: 73.598% (33019/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4927, Accuracy: 5704/10000 (57.04%)

Epoch: 5
Loss: 0.995 | Acc: 70.312% (45/64)
Loss: 0.689 | Acc: 75.897% (4906/6464)
Loss: 0.680 | Acc: 76.469% (9837/12864)
Loss: 0.674 | Acc: 76.760% (14787/19264)
Loss: 0.674 | Acc: 76.687% (19681/25664)
Loss: 0.668 | Acc: 76.906% (24659/32064)
Loss: 0.665 | Acc: 77.067% (29643/38464)
Loss: 0.663 | Acc: 77.115% (34597/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2800, Accuracy: 5988/10000 (59.88%)

Epoch: 6
Loss: 0.760 | Acc: 78.125% (50/64)
Loss: 0.612 | Acc: 78.651% (5084/6464)
Loss: 0.613 | Acc: 78.708% (10125/12864)
Loss: 0.610 | Acc: 78.862% (15192/19264)
Loss: 0.605 | Acc: 78.928% (20256/25664)
Loss: 0.603 | Acc: 79.051% (25347/32064)
Loss: 0.602 | Acc: 79.100% (30425/38464)
Loss: 0.601 | Acc: 79.239% (35550/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5484, Accuracy: 5550/10000 (55.50%)

Epoch: 7
Loss: 0.616 | Acc: 76.562% (49/64)
Loss: 0.556 | Acc: 80.863% (5227/6464)
Loss: 0.564 | Acc: 80.737% (10386/12864)
Loss: 0.555 | Acc: 81.245% (15651/19264)
Loss: 0.555 | Acc: 81.223% (20845/25664)
Loss: 0.553 | Acc: 81.275% (26060/32064)
Loss: 0.556 | Acc: 81.107% (31197/38464)
Loss: 0.557 | Acc: 81.074% (36373/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8092, Accuracy: 7371/10000 (73.71%)

Epoch: 8
Loss: 0.759 | Acc: 82.812% (53/64)
Loss: 0.529 | Acc: 82.039% (5303/6464)
Loss: 0.523 | Acc: 82.097% (10561/12864)
Loss: 0.518 | Acc: 82.247% (15844/19264)
Loss: 0.520 | Acc: 82.138% (21080/25664)
Loss: 0.518 | Acc: 82.214% (26361/32064)
Loss: 0.523 | Acc: 82.053% (31561/38464)
Loss: 0.521 | Acc: 82.200% (36878/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8680, Accuracy: 7238/10000 (72.38%)

Epoch: 9
Loss: 0.554 | Acc: 78.125% (50/64)
Loss: 0.496 | Acc: 82.936% (5361/6464)
Loss: 0.492 | Acc: 83.085% (10688/12864)
Loss: 0.504 | Acc: 82.761% (15943/19264)
Loss: 0.504 | Acc: 82.668% (21216/25664)
Loss: 0.501 | Acc: 82.837% (26561/32064)
Loss: 0.503 | Acc: 82.722% (31818/38464)
Loss: 0.500 | Acc: 82.775% (37136/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9905, Accuracy: 6758/10000 (67.58%)

Epoch: 10
Loss: 0.670 | Acc: 76.562% (49/64)
Loss: 0.489 | Acc: 82.921% (5360/6464)
Loss: 0.473 | Acc: 83.543% (10747/12864)
Loss: 0.484 | Acc: 83.269% (16041/19264)
Loss: 0.482 | Acc: 83.502% (21430/25664)
Loss: 0.478 | Acc: 83.555% (26791/32064)
Loss: 0.480 | Acc: 83.527% (32128/38464)
Loss: 0.481 | Acc: 83.517% (37469/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5121, Accuracy: 8262/10000 (82.62%)

Epoch: 11
Loss: 0.566 | Acc: 79.688% (51/64)
Loss: 0.450 | Acc: 84.746% (5478/6464)
Loss: 0.459 | Acc: 84.235% (10836/12864)
Loss: 0.456 | Acc: 84.411% (16261/19264)
Loss: 0.460 | Acc: 84.328% (21642/25664)
Loss: 0.459 | Acc: 84.356% (27048/32064)
Loss: 0.458 | Acc: 84.354% (32446/38464)
Loss: 0.458 | Acc: 84.357% (37846/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7312, Accuracy: 7780/10000 (77.80%)

Epoch: 12
Loss: 0.534 | Acc: 81.250% (52/64)
Loss: 0.425 | Acc: 85.597% (5533/6464)
Loss: 0.424 | Acc: 85.673% (11021/12864)
Loss: 0.428 | Acc: 85.418% (16455/19264)
Loss: 0.434 | Acc: 85.213% (21869/25664)
Loss: 0.437 | Acc: 85.139% (27299/32064)
Loss: 0.439 | Acc: 85.061% (32718/38464)
Loss: 0.440 | Acc: 85.053% (38158/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0100, Accuracy: 6878/10000 (68.78%)

Epoch: 13
Loss: 0.732 | Acc: 79.688% (51/64)
Loss: 0.432 | Acc: 85.520% (5528/6464)
Loss: 0.432 | Acc: 85.316% (10975/12864)
Loss: 0.430 | Acc: 85.382% (16448/19264)
Loss: 0.429 | Acc: 85.357% (21906/25664)
Loss: 0.428 | Acc: 85.398% (27382/32064)
Loss: 0.427 | Acc: 85.340% (32825/38464)
Loss: 0.424 | Acc: 85.427% (38326/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9851, Accuracy: 5406/10000 (54.06%)

Epoch: 14
Loss: 0.815 | Acc: 71.875% (46/64)
Loss: 0.430 | Acc: 85.613% (5534/6464)
Loss: 0.421 | Acc: 85.541% (11004/12864)
Loss: 0.419 | Acc: 85.559% (16482/19264)
Loss: 0.418 | Acc: 85.715% (21998/25664)
Loss: 0.410 | Acc: 85.888% (27539/32064)
Loss: 0.412 | Acc: 85.831% (33014/38464)
Loss: 0.412 | Acc: 85.866% (38523/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4285, Accuracy: 5065/10000 (50.65%)

Epoch: 15
Loss: 0.746 | Acc: 68.750% (44/64)
Loss: 0.408 | Acc: 86.170% (5570/6464)
Loss: 0.394 | Acc: 86.427% (11118/12864)
Loss: 0.397 | Acc: 86.420% (16648/19264)
Loss: 0.394 | Acc: 86.502% (22200/25664)
Loss: 0.394 | Acc: 86.477% (27728/32064)
Loss: 0.393 | Acc: 86.541% (33287/38464)
Loss: 0.394 | Acc: 86.472% (38795/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5749, Accuracy: 8074/10000 (80.74%)

Epoch: 16
Loss: 0.453 | Acc: 81.250% (52/64)
Loss: 0.359 | Acc: 87.144% (5633/6464)
Loss: 0.365 | Acc: 87.197% (11217/12864)
Loss: 0.366 | Acc: 87.178% (16794/19264)
Loss: 0.376 | Acc: 87.025% (22334/25664)
Loss: 0.374 | Acc: 87.088% (27924/32064)
Loss: 0.377 | Acc: 86.993% (33461/38464)
Loss: 0.376 | Acc: 87.001% (39032/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8221, Accuracy: 5815/10000 (58.15%)

Epoch: 17
Loss: 0.630 | Acc: 79.688% (51/64)
Loss: 0.354 | Acc: 88.227% (5703/6464)
Loss: 0.370 | Acc: 87.430% (11247/12864)
Loss: 0.372 | Acc: 87.209% (16800/19264)
Loss: 0.369 | Acc: 87.371% (22423/25664)
Loss: 0.364 | Acc: 87.534% (28067/32064)
Loss: 0.368 | Acc: 87.373% (33607/38464)
Loss: 0.367 | Acc: 87.418% (39219/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7759, Accuracy: 7687/10000 (76.87%)

Epoch: 18
Loss: 0.543 | Acc: 84.375% (54/64)
Loss: 0.329 | Acc: 88.892% (5746/6464)
Loss: 0.338 | Acc: 88.441% (11377/12864)
Loss: 0.339 | Acc: 88.429% (17035/19264)
Loss: 0.342 | Acc: 88.248% (22648/25664)
Loss: 0.343 | Acc: 88.146% (28263/32064)
Loss: 0.347 | Acc: 87.997% (33847/38464)
Loss: 0.350 | Acc: 87.919% (39444/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5600, Accuracy: 8158/10000 (81.58%)

Epoch: 19
Loss: 0.330 | Acc: 89.062% (57/64)
Loss: 0.337 | Acc: 88.382% (5713/6464)
Loss: 0.334 | Acc: 88.487% (11383/12864)
Loss: 0.335 | Acc: 88.424% (17034/19264)
Loss: 0.334 | Acc: 88.505% (22714/25664)
Loss: 0.334 | Acc: 88.567% (28398/32064)
Loss: 0.335 | Acc: 88.480% (34033/38464)
Loss: 0.336 | Acc: 88.405% (39662/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5579, Accuracy: 6318/10000 (63.18%)

Epoch: 20
Loss: 0.315 | Acc: 87.500% (56/64)
Loss: 0.319 | Acc: 89.001% (5753/6464)
Loss: 0.315 | Acc: 89.039% (11454/12864)
Loss: 0.323 | Acc: 88.658% (17079/19264)
Loss: 0.324 | Acc: 88.673% (22757/25664)
Loss: 0.323 | Acc: 88.679% (28434/32064)
Loss: 0.324 | Acc: 88.688% (34113/38464)
Loss: 0.325 | Acc: 88.692% (39791/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8833, Accuracy: 5880/10000 (58.80%)

Epoch: 21
Loss: 0.586 | Acc: 76.562% (49/64)
Loss: 0.325 | Acc: 88.800% (5740/6464)
Loss: 0.325 | Acc: 89.024% (11452/12864)
Loss: 0.316 | Acc: 89.343% (17211/19264)
Loss: 0.319 | Acc: 89.203% (22893/25664)
Loss: 0.318 | Acc: 89.212% (28605/32064)
Loss: 0.317 | Acc: 89.221% (34318/38464)
Loss: 0.317 | Acc: 89.203% (40020/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1284, Accuracy: 6836/10000 (68.36%)

Epoch: 22
Loss: 0.445 | Acc: 84.375% (54/64)
Loss: 0.281 | Acc: 90.439% (5846/6464)
Loss: 0.293 | Acc: 89.956% (11572/12864)
Loss: 0.297 | Acc: 89.800% (17299/19264)
Loss: 0.301 | Acc: 89.631% (23003/25664)
Loss: 0.300 | Acc: 89.677% (28754/32064)
Loss: 0.301 | Acc: 89.671% (34491/38464)
Loss: 0.301 | Acc: 89.658% (40224/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0308, Accuracy: 7056/10000 (70.56%)

Epoch: 23
Loss: 0.396 | Acc: 87.500% (56/64)
Loss: 0.263 | Acc: 90.934% (5878/6464)
Loss: 0.277 | Acc: 90.392% (11628/12864)
Loss: 0.282 | Acc: 90.360% (17407/19264)
Loss: 0.288 | Acc: 90.251% (23162/25664)
Loss: 0.289 | Acc: 90.201% (28922/32064)
Loss: 0.289 | Acc: 90.165% (34681/38464)
Loss: 0.290 | Acc: 90.193% (40464/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8809, Accuracy: 7496/10000 (74.96%)

Epoch: 24
Loss: 0.352 | Acc: 84.375% (54/64)
Loss: 0.274 | Acc: 90.130% (5826/6464)
Loss: 0.285 | Acc: 90.011% (11579/12864)
Loss: 0.285 | Acc: 90.101% (17357/19264)
Loss: 0.283 | Acc: 90.298% (23174/25664)
Loss: 0.283 | Acc: 90.269% (28944/32064)
Loss: 0.282 | Acc: 90.334% (34746/38464)
Loss: 0.281 | Acc: 90.395% (40555/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1325, Accuracy: 6993/10000 (69.93%)

Epoch: 25
Loss: 0.588 | Acc: 81.250% (52/64)
Loss: 0.258 | Acc: 90.780% (5868/6464)
Loss: 0.262 | Acc: 90.959% (11701/12864)
Loss: 0.263 | Acc: 91.040% (17538/19264)
Loss: 0.256 | Acc: 91.221% (23411/25664)
Loss: 0.256 | Acc: 91.252% (29259/32064)
Loss: 0.258 | Acc: 91.231% (35091/38464)
Loss: 0.261 | Acc: 91.064% (40855/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1348, Accuracy: 7113/10000 (71.13%)

Epoch: 26
Loss: 0.346 | Acc: 89.062% (57/64)
Loss: 0.229 | Acc: 92.249% (5963/6464)
Loss: 0.238 | Acc: 91.954% (11829/12864)
Loss: 0.236 | Acc: 91.866% (17697/19264)
Loss: 0.241 | Acc: 91.661% (23524/25664)
Loss: 0.244 | Acc: 91.579% (29364/32064)
Loss: 0.244 | Acc: 91.584% (35227/38464)
Loss: 0.246 | Acc: 91.557% (41076/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4111, Accuracy: 8664/10000 (86.64%)

Epoch: 27
Loss: 0.311 | Acc: 89.062% (57/64)
Loss: 0.233 | Acc: 91.847% (5937/6464)
Loss: 0.233 | Acc: 91.923% (11825/12864)
Loss: 0.239 | Acc: 91.700% (17665/19264)
Loss: 0.240 | Acc: 91.697% (23533/25664)
Loss: 0.241 | Acc: 91.692% (29400/32064)
Loss: 0.240 | Acc: 91.785% (35304/38464)
Loss: 0.239 | Acc: 91.826% (41197/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6912, Accuracy: 8081/10000 (80.81%)

Epoch: 28
Loss: 0.514 | Acc: 82.812% (53/64)
Loss: 0.217 | Acc: 92.652% (5989/6464)
Loss: 0.217 | Acc: 92.716% (11927/12864)
Loss: 0.213 | Acc: 92.722% (17862/19264)
Loss: 0.217 | Acc: 92.589% (23762/25664)
Loss: 0.219 | Acc: 92.540% (29672/32064)
Loss: 0.222 | Acc: 92.460% (35564/38464)
Loss: 0.222 | Acc: 92.419% (41463/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8244, Accuracy: 7744/10000 (77.44%)

Epoch: 29
Loss: 0.291 | Acc: 89.062% (57/64)
Loss: 0.223 | Acc: 92.559% (5983/6464)
Loss: 0.208 | Acc: 92.988% (11962/12864)
Loss: 0.205 | Acc: 93.086% (17932/19264)
Loss: 0.209 | Acc: 92.904% (23843/25664)
Loss: 0.210 | Acc: 92.877% (29780/32064)
Loss: 0.211 | Acc: 92.796% (35693/38464)
Loss: 0.210 | Acc: 92.852% (41657/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4396, Accuracy: 8606/10000 (86.06%)

Epoch: 30
Loss: 0.270 | Acc: 92.188% (59/64)
Loss: 0.193 | Acc: 93.472% (6042/6464)
Loss: 0.185 | Acc: 93.672% (12050/12864)
Loss: 0.190 | Acc: 93.584% (18028/19264)
Loss: 0.190 | Acc: 93.567% (24013/25664)
Loss: 0.191 | Acc: 93.525% (29988/32064)
Loss: 0.193 | Acc: 93.446% (35943/38464)
Loss: 0.193 | Acc: 93.413% (41909/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7920, Accuracy: 7804/10000 (78.04%)

Epoch: 31
Loss: 0.119 | Acc: 96.875% (62/64)
Loss: 0.173 | Acc: 93.982% (6075/6464)
Loss: 0.178 | Acc: 93.696% (12053/12864)
Loss: 0.178 | Acc: 93.657% (18042/19264)
Loss: 0.178 | Acc: 93.727% (24054/25664)
Loss: 0.179 | Acc: 93.688% (30040/32064)
Loss: 0.179 | Acc: 93.685% (36035/38464)
Loss: 0.182 | Acc: 93.592% (41989/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3756, Accuracy: 8815/10000 (88.15%)

Epoch: 32
Loss: 0.141 | Acc: 93.750% (60/64)
Loss: 0.159 | Acc: 94.307% (6096/6464)
Loss: 0.157 | Acc: 94.279% (12128/12864)
Loss: 0.161 | Acc: 94.176% (18142/19264)
Loss: 0.164 | Acc: 94.210% (24178/25664)
Loss: 0.165 | Acc: 94.162% (30192/32064)
Loss: 0.167 | Acc: 94.135% (36208/38464)
Loss: 0.166 | Acc: 94.200% (42262/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4160, Accuracy: 8661/10000 (86.61%)

Epoch: 33
Loss: 0.045 | Acc: 100.000% (64/64)
Loss: 0.130 | Acc: 95.606% (6180/6464)
Loss: 0.133 | Acc: 95.600% (12298/12864)
Loss: 0.138 | Acc: 95.370% (18372/19264)
Loss: 0.140 | Acc: 95.328% (24465/25664)
Loss: 0.141 | Acc: 95.259% (30544/32064)
Loss: 0.142 | Acc: 95.222% (36626/38464)
Loss: 0.141 | Acc: 95.259% (42737/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5193, Accuracy: 8510/10000 (85.10%)

Epoch: 34
Loss: 0.219 | Acc: 90.625% (58/64)
Loss: 0.141 | Acc: 95.282% (6159/6464)
Loss: 0.131 | Acc: 95.678% (12308/12864)
Loss: 0.131 | Acc: 95.665% (18429/19264)
Loss: 0.132 | Acc: 95.554% (24523/25664)
Loss: 0.131 | Acc: 95.559% (30640/32064)
Loss: 0.130 | Acc: 95.546% (36751/38464)
Loss: 0.132 | Acc: 95.518% (42853/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3284, Accuracy: 9010/10000 (90.10%)

Epoch: 35
Loss: 0.141 | Acc: 95.312% (61/64)
Loss: 0.117 | Acc: 95.962% (6203/6464)
Loss: 0.116 | Acc: 96.098% (12362/12864)
Loss: 0.112 | Acc: 96.247% (18541/19264)
Loss: 0.111 | Acc: 96.232% (24697/25664)
Loss: 0.110 | Acc: 96.242% (30859/32064)
Loss: 0.114 | Acc: 96.116% (36970/38464)
Loss: 0.115 | Acc: 96.104% (43116/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2809, Accuracy: 9151/10000 (91.51%)

Epoch: 36
Loss: 0.143 | Acc: 96.875% (62/64)
Loss: 0.093 | Acc: 96.952% (6267/6464)
Loss: 0.097 | Acc: 96.859% (12460/12864)
Loss: 0.096 | Acc: 96.901% (18667/19264)
Loss: 0.098 | Acc: 96.801% (24843/25664)
Loss: 0.099 | Acc: 96.816% (31043/32064)
Loss: 0.099 | Acc: 96.784% (37227/38464)
Loss: 0.100 | Acc: 96.750% (43406/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2637, Accuracy: 9178/10000 (91.78%)

Epoch: 37
Loss: 0.047 | Acc: 98.438% (63/64)
Loss: 0.080 | Acc: 97.262% (6287/6464)
Loss: 0.077 | Acc: 97.419% (12532/12864)
Loss: 0.080 | Acc: 97.327% (18749/19264)
Loss: 0.080 | Acc: 97.323% (24977/25664)
Loss: 0.084 | Acc: 97.171% (31157/32064)
Loss: 0.084 | Acc: 97.127% (37359/38464)
Loss: 0.085 | Acc: 97.089% (43558/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2414, Accuracy: 9254/10000 (92.54%)

Epoch: 38
Loss: 0.141 | Acc: 96.875% (62/64)
Loss: 0.072 | Acc: 97.649% (6312/6464)
Loss: 0.064 | Acc: 97.792% (12580/12864)
Loss: 0.065 | Acc: 97.799% (18840/19264)
Loss: 0.066 | Acc: 97.779% (25094/25664)
Loss: 0.066 | Acc: 97.798% (31358/32064)
Loss: 0.069 | Acc: 97.704% (37581/38464)
Loss: 0.068 | Acc: 97.751% (43855/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3150, Accuracy: 9081/10000 (90.81%)

Epoch: 39
Loss: 0.032 | Acc: 100.000% (64/64)
Loss: 0.053 | Acc: 98.376% (6359/6464)
Loss: 0.056 | Acc: 98.189% (12631/12864)
Loss: 0.053 | Acc: 98.245% (18926/19264)
Loss: 0.054 | Acc: 98.208% (25204/25664)
Loss: 0.055 | Acc: 98.179% (31480/32064)
Loss: 0.056 | Acc: 98.146% (37751/38464)
Loss: 0.057 | Acc: 98.085% (44005/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4777, Accuracy: 8722/10000 (87.22%)

Epoch: 40
Loss: 0.169 | Acc: 96.875% (62/64)
Loss: 0.049 | Acc: 98.608% (6374/6464)
Loss: 0.046 | Acc: 98.601% (12684/12864)
Loss: 0.046 | Acc: 98.536% (18982/19264)
Loss: 0.047 | Acc: 98.449% (25266/25664)
Loss: 0.047 | Acc: 98.425% (31559/32064)
Loss: 0.047 | Acc: 98.419% (37856/38464)
Loss: 0.047 | Acc: 98.442% (44165/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2216, Accuracy: 9337/10000 (93.37%)

Epoch: 41
Loss: 0.045 | Acc: 96.875% (62/64)
Loss: 0.031 | Acc: 99.118% (6407/6464)
Loss: 0.035 | Acc: 98.904% (12723/12864)
Loss: 0.033 | Acc: 98.972% (19066/19264)
Loss: 0.035 | Acc: 98.847% (25368/25664)
Loss: 0.035 | Acc: 98.880% (31705/32064)
Loss: 0.035 | Acc: 98.872% (38030/38464)
Loss: 0.035 | Acc: 98.859% (44352/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2172, Accuracy: 9376/10000 (93.76%)

Epoch: 42
Loss: 0.017 | Acc: 100.000% (64/64)
Loss: 0.026 | Acc: 99.242% (6415/6464)
Loss: 0.028 | Acc: 99.207% (12762/12864)
Loss: 0.027 | Acc: 99.206% (19111/19264)
Loss: 0.026 | Acc: 99.264% (25475/25664)
Loss: 0.026 | Acc: 99.236% (31819/32064)
Loss: 0.026 | Acc: 99.236% (38170/38464)
Loss: 0.025 | Acc: 99.253% (44529/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2195, Accuracy: 9364/10000 (93.64%)

Epoch: 43
Loss: 0.023 | Acc: 100.000% (64/64)
Loss: 0.023 | Acc: 99.304% (6419/6464)
Loss: 0.024 | Acc: 99.339% (12779/12864)
Loss: 0.021 | Acc: 99.429% (19154/19264)
Loss: 0.021 | Acc: 99.451% (25523/25664)
Loss: 0.020 | Acc: 99.473% (31895/32064)
Loss: 0.020 | Acc: 99.490% (38268/38464)
Loss: 0.019 | Acc: 99.492% (44636/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2105, Accuracy: 9400/10000 (94.00%)

Epoch: 44
Loss: 0.060 | Acc: 98.438% (63/64)
Loss: 0.016 | Acc: 99.613% (6439/6464)
Loss: 0.016 | Acc: 99.604% (12813/12864)
Loss: 0.015 | Acc: 99.611% (19189/19264)
Loss: 0.015 | Acc: 99.618% (25566/25664)
Loss: 0.016 | Acc: 99.598% (31935/32064)
Loss: 0.016 | Acc: 99.602% (38311/38464)
Loss: 0.015 | Acc: 99.612% (44690/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2121, Accuracy: 9410/10000 (94.10%)

Epoch: 45
Loss: 0.031 | Acc: 98.438% (63/64)
Loss: 0.012 | Acc: 99.722% (6446/6464)
Loss: 0.012 | Acc: 99.743% (12831/12864)
Loss: 0.013 | Acc: 99.689% (19204/19264)
Loss: 0.012 | Acc: 99.688% (25584/25664)
Loss: 0.012 | Acc: 99.682% (31962/32064)
Loss: 0.013 | Acc: 99.675% (38339/38464)
Loss: 0.013 | Acc: 99.688% (44724/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2096, Accuracy: 9417/10000 (94.17%)

Epoch: 46
Loss: 0.038 | Acc: 98.438% (63/64)
Loss: 0.010 | Acc: 99.892% (6457/6464)
Loss: 0.010 | Acc: 99.860% (12846/12864)
Loss: 0.010 | Acc: 99.834% (19232/19264)
Loss: 0.010 | Acc: 99.809% (25615/25664)
Loss: 0.011 | Acc: 99.791% (31997/32064)
Loss: 0.010 | Acc: 99.797% (38386/38464)
Loss: 0.010 | Acc: 99.797% (44773/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2052, Accuracy: 9411/10000 (94.11%)

Epoch: 47
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.830% (6453/6464)
Loss: 0.010 | Acc: 99.813% (12840/12864)
Loss: 0.010 | Acc: 99.777% (19221/19264)
Loss: 0.010 | Acc: 99.797% (25612/25664)
Loss: 0.010 | Acc: 99.797% (31999/32064)
Loss: 0.010 | Acc: 99.784% (38381/38464)
Loss: 0.010 | Acc: 99.795% (44772/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2083, Accuracy: 9411/10000 (94.11%)
torch.Size([100, 10])
Test set: Average loss: 0.2083, Accuracy: 9411/10000 (94.11%)

Epoch: 48
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.783% (6450/6464)
Loss: 0.010 | Acc: 99.790% (12837/12864)
Loss: 0.010 | Acc: 99.772% (19220/19264)
Loss: 0.010 | Acc: 99.786% (25609/25664)
Loss: 0.009 | Acc: 99.794% (31998/32064)
Loss: 0.009 | Acc: 99.795% (38385/38464)
Loss: 0.009 | Acc: 99.784% (44767/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2013, Accuracy: 9421/10000 (94.21%)
torch.Size([100, 10])
Test set: Average loss: 0.2013, Accuracy: 9421/10000 (94.21%)

Epoch: 49
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.830% (6453/6464)
Loss: 0.010 | Acc: 99.782% (12836/12864)
Loss: 0.009 | Acc: 99.792% (19224/19264)
Loss: 0.010 | Acc: 99.793% (25611/25664)
Loss: 0.009 | Acc: 99.800% (32000/32064)
Loss: 0.009 | Acc: 99.805% (38389/38464)
Loss: 0.009 | Acc: 99.804% (44776/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2047, Accuracy: 9423/10000 (94.23%)
torch.Size([100, 10])
Test set: Average loss: 0.2047, Accuracy: 9423/10000 (94.23%)

Epoch: 50
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 2.029 | Acc: 25.480% (1647/6464)
Loss: 1.936 | Acc: 27.868% (3585/12864)
Loss: 1.844 | Acc: 31.193% (6009/19264)
Loss: 1.733 | Acc: 35.540% (9121/25664)
Loss: 1.612 | Acc: 40.475% (12978/32064)
Loss: 1.501 | Acc: 44.837% (17246/38464)
Loss: 1.403 | Acc: 48.665% (21833/44864)
torch.Size([100, 10])
Test set: Average loss: 5.5166, Accuracy: 2821/10000 (28.21%)

Epoch: 51
Loss: 1.603 | Acc: 50.000% (32/64)
Loss: 0.717 | Acc: 75.603% (4887/6464)
Loss: 0.690 | Acc: 76.438% (9833/12864)
Loss: 0.668 | Acc: 77.159% (14864/19264)
Loss: 0.653 | Acc: 77.685% (19937/25664)
Loss: 0.639 | Acc: 78.240% (25087/32064)
Loss: 0.624 | Acc: 78.707% (30274/38464)
Loss: 0.615 | Acc: 78.992% (35439/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0749, Accuracy: 6815/10000 (68.15%)

Epoch: 52
Loss: 0.627 | Acc: 76.562% (49/64)
Loss: 0.530 | Acc: 82.024% (5302/6464)
Loss: 0.519 | Acc: 82.424% (10603/12864)
Loss: 0.510 | Acc: 82.511% (15895/19264)
Loss: 0.506 | Acc: 82.645% (21210/25664)
Loss: 0.502 | Acc: 82.816% (26554/32064)
Loss: 0.499 | Acc: 82.961% (31910/38464)
Loss: 0.493 | Acc: 83.169% (37313/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8198, Accuracy: 7551/10000 (75.51%)

Epoch: 53
Loss: 0.673 | Acc: 75.000% (48/64)
Loss: 0.446 | Acc: 84.437% (5458/6464)
Loss: 0.448 | Acc: 84.593% (10882/12864)
Loss: 0.448 | Acc: 84.723% (16321/19264)
Loss: 0.445 | Acc: 84.788% (21760/25664)
Loss: 0.447 | Acc: 84.721% (27165/32064)
Loss: 0.446 | Acc: 84.747% (32597/38464)
Loss: 0.445 | Acc: 84.763% (38028/44864)
torch.Size([100, 10])
Test set: Average loss: 2.8512, Accuracy: 5306/10000 (53.06%)

Epoch: 54
Loss: 0.959 | Acc: 70.312% (45/64)
Loss: 0.433 | Acc: 85.350% (5517/6464)
Loss: 0.422 | Acc: 85.510% (11000/12864)
Loss: 0.421 | Acc: 85.403% (16452/19264)
Loss: 0.425 | Acc: 85.310% (21894/25664)
Loss: 0.427 | Acc: 85.245% (27333/32064)
Loss: 0.429 | Acc: 85.275% (32800/38464)
Loss: 0.428 | Acc: 85.371% (38301/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2799, Accuracy: 6461/10000 (64.61%)

Epoch: 55
Loss: 0.396 | Acc: 84.375% (54/64)
Loss: 0.418 | Acc: 85.535% (5529/6464)
Loss: 0.400 | Acc: 86.295% (11101/12864)
Loss: 0.403 | Acc: 86.270% (16619/19264)
Loss: 0.405 | Acc: 86.136% (22106/25664)
Loss: 0.403 | Acc: 86.231% (27649/32064)
Loss: 0.405 | Acc: 86.179% (33148/38464)
Loss: 0.405 | Acc: 86.129% (38641/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7350, Accuracy: 7696/10000 (76.96%)

Epoch: 56
Loss: 0.269 | Acc: 90.625% (58/64)
Loss: 0.378 | Acc: 87.237% (5639/6464)
Loss: 0.384 | Acc: 86.730% (11157/12864)
Loss: 0.387 | Acc: 86.659% (16694/19264)
Loss: 0.385 | Acc: 86.736% (22260/25664)
Loss: 0.389 | Acc: 86.655% (27785/32064)
Loss: 0.389 | Acc: 86.702% (33349/38464)
Loss: 0.391 | Acc: 86.662% (38880/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0037, Accuracy: 6888/10000 (68.88%)

Epoch: 57
Loss: 0.651 | Acc: 82.812% (53/64)
Loss: 0.376 | Acc: 86.943% (5620/6464)
Loss: 0.373 | Acc: 87.345% (11236/12864)
Loss: 0.377 | Acc: 87.209% (16800/19264)
Loss: 0.377 | Acc: 87.177% (22373/25664)
Loss: 0.380 | Acc: 87.004% (27897/32064)
Loss: 0.381 | Acc: 86.951% (33445/38464)
Loss: 0.380 | Acc: 87.012% (39037/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4625, Accuracy: 6438/10000 (64.38%)

Epoch: 58
Loss: 0.658 | Acc: 81.250% (52/64)
Loss: 0.364 | Acc: 87.717% (5670/6464)
Loss: 0.370 | Acc: 87.461% (11251/12864)
Loss: 0.366 | Acc: 87.573% (16870/19264)
Loss: 0.369 | Acc: 87.371% (22423/25664)
Loss: 0.365 | Acc: 87.494% (28054/32064)
Loss: 0.369 | Acc: 87.443% (33634/38464)
Loss: 0.370 | Acc: 87.422% (39221/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5257, Accuracy: 6153/10000 (61.53%)

Epoch: 59
Loss: 0.473 | Acc: 82.812% (53/64)
Loss: 0.365 | Acc: 87.252% (5640/6464)
Loss: 0.364 | Acc: 87.562% (11264/12864)
Loss: 0.365 | Acc: 87.604% (16876/19264)
Loss: 0.362 | Acc: 87.632% (22490/25664)
Loss: 0.363 | Acc: 87.581% (28082/32064)
Loss: 0.364 | Acc: 87.484% (33650/38464)
Loss: 0.365 | Acc: 87.500% (39256/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6060, Accuracy: 8102/10000 (81.02%)

Epoch: 60
Loss: 0.323 | Acc: 89.062% (57/64)
Loss: 0.358 | Acc: 87.964% (5686/6464)
Loss: 0.352 | Acc: 87.842% (11300/12864)
Loss: 0.356 | Acc: 87.619% (16879/19264)
Loss: 0.355 | Acc: 87.668% (22499/25664)
Loss: 0.353 | Acc: 87.799% (28152/32064)
Loss: 0.353 | Acc: 87.838% (33786/38464)
Loss: 0.352 | Acc: 87.819% (39399/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5196, Accuracy: 8275/10000 (82.75%)

Epoch: 61
Loss: 0.203 | Acc: 92.188% (59/64)
Loss: 0.331 | Acc: 88.134% (5697/6464)
Loss: 0.337 | Acc: 88.130% (11337/12864)
Loss: 0.343 | Acc: 88.206% (16992/19264)
Loss: 0.345 | Acc: 88.147% (22622/25664)
Loss: 0.345 | Acc: 88.046% (28231/32064)
Loss: 0.345 | Acc: 88.103% (33888/38464)
Loss: 0.346 | Acc: 88.062% (39508/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2084, Accuracy: 7048/10000 (70.48%)

Epoch: 62
Loss: 0.375 | Acc: 93.750% (60/64)
Loss: 0.320 | Acc: 89.016% (5754/6464)
Loss: 0.325 | Acc: 88.635% (11402/12864)
Loss: 0.333 | Acc: 88.424% (17034/19264)
Loss: 0.337 | Acc: 88.314% (22665/25664)
Loss: 0.339 | Acc: 88.242% (28294/32064)
Loss: 0.341 | Acc: 88.257% (33947/38464)
Loss: 0.343 | Acc: 88.202% (39571/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0451, Accuracy: 7485/10000 (74.85%)

Epoch: 63
Loss: 0.715 | Acc: 84.375% (54/64)
Loss: 0.315 | Acc: 89.171% (5764/6464)
Loss: 0.329 | Acc: 88.658% (11405/12864)
Loss: 0.328 | Acc: 88.684% (17084/19264)
Loss: 0.333 | Acc: 88.474% (22706/25664)
Loss: 0.332 | Acc: 88.613% (28413/32064)
Loss: 0.335 | Acc: 88.556% (34062/38464)
Loss: 0.334 | Acc: 88.617% (39757/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5901, Accuracy: 8188/10000 (81.88%)

Epoch: 64
Loss: 0.428 | Acc: 85.938% (55/64)
Loss: 0.328 | Acc: 88.629% (5729/6464)
Loss: 0.321 | Acc: 88.837% (11428/12864)
Loss: 0.320 | Acc: 89.000% (17145/19264)
Loss: 0.325 | Acc: 88.918% (22820/25664)
Loss: 0.324 | Acc: 88.854% (28490/32064)
Loss: 0.323 | Acc: 88.862% (34180/38464)
Loss: 0.329 | Acc: 88.726% (39806/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0658, Accuracy: 5718/10000 (57.18%)

Epoch: 65
Loss: 0.510 | Acc: 84.375% (54/64)
Loss: 0.325 | Acc: 89.124% (5761/6464)
Loss: 0.316 | Acc: 89.241% (11480/12864)
Loss: 0.313 | Acc: 89.265% (17196/19264)
Loss: 0.313 | Acc: 89.304% (22919/25664)
Loss: 0.316 | Acc: 89.309% (28636/32064)
Loss: 0.316 | Acc: 89.325% (34358/38464)
Loss: 0.315 | Acc: 89.372% (40096/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4650, Accuracy: 8429/10000 (84.29%)

Epoch: 66
Loss: 0.211 | Acc: 96.875% (62/64)
Loss: 0.277 | Acc: 90.532% (5852/6464)
Loss: 0.293 | Acc: 89.871% (11561/12864)
Loss: 0.304 | Acc: 89.613% (17263/19264)
Loss: 0.308 | Acc: 89.514% (22973/25664)
Loss: 0.306 | Acc: 89.533% (28708/32064)
Loss: 0.306 | Acc: 89.486% (34420/38464)
Loss: 0.307 | Acc: 89.435% (40124/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0359, Accuracy: 5569/10000 (55.69%)

Epoch: 67
Loss: 0.296 | Acc: 90.625% (58/64)
Loss: 0.300 | Acc: 89.851% (5808/6464)
Loss: 0.299 | Acc: 89.793% (11551/12864)
Loss: 0.297 | Acc: 89.914% (17321/19264)
Loss: 0.298 | Acc: 89.853% (23060/25664)
Loss: 0.300 | Acc: 89.833% (28804/32064)
Loss: 0.304 | Acc: 89.671% (34491/38464)
Loss: 0.305 | Acc: 89.575% (40187/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4743, Accuracy: 8438/10000 (84.38%)

Epoch: 68
Loss: 0.216 | Acc: 93.750% (60/64)
Loss: 0.299 | Acc: 89.898% (5811/6464)
Loss: 0.288 | Acc: 90.299% (11616/12864)
Loss: 0.291 | Acc: 90.085% (17354/19264)
Loss: 0.293 | Acc: 90.025% (23104/25664)
Loss: 0.291 | Acc: 90.098% (28889/32064)
Loss: 0.291 | Acc: 90.136% (34670/38464)
Loss: 0.293 | Acc: 90.052% (40401/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5456, Accuracy: 8202/10000 (82.02%)

Epoch: 69
Loss: 0.309 | Acc: 92.188% (59/64)
Loss: 0.267 | Acc: 90.702% (5863/6464)
Loss: 0.271 | Acc: 90.726% (11671/12864)
Loss: 0.277 | Acc: 90.568% (17447/19264)
Loss: 0.279 | Acc: 90.559% (23241/25664)
Loss: 0.283 | Acc: 90.413% (28990/32064)
Loss: 0.284 | Acc: 90.355% (34754/38464)
Loss: 0.283 | Acc: 90.391% (40553/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2747, Accuracy: 6870/10000 (68.70%)

Epoch: 70
Loss: 0.338 | Acc: 85.938% (55/64)
Loss: 0.262 | Acc: 90.826% (5871/6464)
Loss: 0.262 | Acc: 90.983% (11704/12864)
Loss: 0.263 | Acc: 90.947% (17520/19264)
Loss: 0.262 | Acc: 90.968% (23346/25664)
Loss: 0.267 | Acc: 90.815% (29119/32064)
Loss: 0.271 | Acc: 90.635% (34862/38464)
Loss: 0.275 | Acc: 90.498% (40601/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5077, Accuracy: 8357/10000 (83.57%)

Epoch: 71
Loss: 0.384 | Acc: 89.062% (57/64)
Loss: 0.250 | Acc: 91.445% (5911/6464)
Loss: 0.261 | Acc: 91.068% (11715/12864)
Loss: 0.261 | Acc: 91.056% (17541/19264)
Loss: 0.265 | Acc: 90.960% (23344/25664)
Loss: 0.265 | Acc: 90.993% (29176/32064)
Loss: 0.269 | Acc: 90.836% (34939/38464)
Loss: 0.267 | Acc: 90.884% (40774/44864)
torch.Size([100, 10])
Test set: Average loss: 3.0038, Accuracy: 4758/10000 (47.58%)

Epoch: 72
Loss: 0.566 | Acc: 81.250% (52/64)
Loss: 0.267 | Acc: 91.182% (5894/6464)
Loss: 0.257 | Acc: 91.301% (11745/12864)
Loss: 0.260 | Acc: 91.154% (17560/19264)
Loss: 0.262 | Acc: 91.120% (23385/25664)
Loss: 0.257 | Acc: 91.264% (29263/32064)
Loss: 0.256 | Acc: 91.262% (35103/38464)
Loss: 0.256 | Acc: 91.251% (40939/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8337, Accuracy: 7726/10000 (77.26%)

Epoch: 73
Loss: 0.295 | Acc: 89.062% (57/64)
Loss: 0.248 | Acc: 91.553% (5918/6464)
Loss: 0.247 | Acc: 91.402% (11758/12864)
Loss: 0.251 | Acc: 91.383% (17604/19264)
Loss: 0.250 | Acc: 91.443% (23468/25664)
Loss: 0.251 | Acc: 91.324% (29282/32064)
Loss: 0.248 | Acc: 91.480% (35187/38464)
Loss: 0.249 | Acc: 91.501% (41051/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5263, Accuracy: 8408/10000 (84.08%)

Epoch: 74
Loss: 0.334 | Acc: 92.188% (59/64)
Loss: 0.218 | Acc: 92.605% (5986/6464)
Loss: 0.219 | Acc: 92.421% (11889/12864)
Loss: 0.226 | Acc: 92.068% (17736/19264)
Loss: 0.230 | Acc: 91.938% (23595/25664)
Loss: 0.229 | Acc: 92.003% (29500/32064)
Loss: 0.234 | Acc: 91.865% (35335/38464)
Loss: 0.233 | Acc: 91.907% (41233/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6820, Accuracy: 7934/10000 (79.34%)

Epoch: 75
Loss: 0.452 | Acc: 89.062% (57/64)
Loss: 0.217 | Acc: 92.621% (5987/6464)
Loss: 0.214 | Acc: 92.833% (11942/12864)
Loss: 0.218 | Acc: 92.618% (17842/19264)
Loss: 0.225 | Acc: 92.328% (23695/25664)
Loss: 0.222 | Acc: 92.437% (29639/32064)
Loss: 0.222 | Acc: 92.421% (35549/38464)
Loss: 0.225 | Acc: 92.315% (41416/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4890, Accuracy: 8509/10000 (85.09%)

Epoch: 76
Loss: 0.192 | Acc: 95.312% (61/64)
Loss: 0.196 | Acc: 93.379% (6036/6464)
Loss: 0.199 | Acc: 93.237% (11994/12864)
Loss: 0.201 | Acc: 93.065% (17928/19264)
Loss: 0.206 | Acc: 92.869% (23834/25664)
Loss: 0.212 | Acc: 92.627% (29700/32064)
Loss: 0.215 | Acc: 92.531% (35591/38464)
Loss: 0.214 | Acc: 92.555% (41524/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4090, Accuracy: 8704/10000 (87.04%)

Epoch: 77
Loss: 0.158 | Acc: 96.875% (62/64)
Loss: 0.194 | Acc: 93.564% (6048/6464)
Loss: 0.191 | Acc: 93.408% (12016/12864)
Loss: 0.196 | Acc: 93.231% (17960/19264)
Loss: 0.199 | Acc: 93.041% (23878/25664)
Loss: 0.198 | Acc: 93.055% (29837/32064)
Loss: 0.199 | Acc: 93.027% (35782/38464)
Loss: 0.200 | Acc: 93.003% (41725/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3262, Accuracy: 8953/10000 (89.53%)

Epoch: 78
Loss: 0.209 | Acc: 92.188% (59/64)
Loss: 0.175 | Acc: 93.967% (6074/6464)
Loss: 0.175 | Acc: 93.937% (12084/12864)
Loss: 0.181 | Acc: 93.781% (18066/19264)
Loss: 0.185 | Acc: 93.699% (24047/25664)
Loss: 0.186 | Acc: 93.641% (30025/32064)
Loss: 0.187 | Acc: 93.581% (35995/38464)
Loss: 0.190 | Acc: 93.498% (41947/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4723, Accuracy: 8463/10000 (84.63%)

Epoch: 79
Loss: 0.150 | Acc: 95.312% (61/64)
Loss: 0.156 | Acc: 94.771% (6126/6464)
Loss: 0.161 | Acc: 94.504% (12157/12864)
Loss: 0.162 | Acc: 94.503% (18205/19264)
Loss: 0.166 | Acc: 94.405% (24228/25664)
Loss: 0.169 | Acc: 94.314% (30241/32064)
Loss: 0.168 | Acc: 94.314% (36277/38464)
Loss: 0.170 | Acc: 94.231% (42276/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8726, Accuracy: 6435/10000 (64.35%)

Epoch: 80
Loss: 0.975 | Acc: 81.250% (52/64)
Loss: 0.198 | Acc: 93.255% (6028/6464)
Loss: 0.178 | Acc: 93.921% (12082/12864)
Loss: 0.173 | Acc: 94.103% (18128/19264)
Loss: 0.172 | Acc: 94.128% (24157/25664)
Loss: 0.173 | Acc: 94.053% (30157/32064)
Loss: 0.170 | Acc: 94.184% (36227/38464)
Loss: 0.170 | Acc: 94.200% (42262/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3817, Accuracy: 8794/10000 (87.94%)

Epoch: 81
Loss: 0.185 | Acc: 95.312% (61/64)
Loss: 0.159 | Acc: 94.384% (6101/6464)
Loss: 0.159 | Acc: 94.558% (12164/12864)
Loss: 0.156 | Acc: 94.731% (18249/19264)
Loss: 0.152 | Acc: 94.806% (24331/25664)
Loss: 0.154 | Acc: 94.767% (30386/32064)
Loss: 0.155 | Acc: 94.735% (36439/38464)
Loss: 0.156 | Acc: 94.717% (42494/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3103, Accuracy: 9040/10000 (90.40%)

Epoch: 82
Loss: 0.083 | Acc: 95.312% (61/64)
Loss: 0.138 | Acc: 95.282% (6159/6464)
Loss: 0.132 | Acc: 95.351% (12266/12864)
Loss: 0.130 | Acc: 95.468% (18391/19264)
Loss: 0.129 | Acc: 95.515% (24513/25664)
Loss: 0.135 | Acc: 95.331% (30567/32064)
Loss: 0.136 | Acc: 95.346% (36674/38464)
Loss: 0.136 | Acc: 95.321% (42765/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9135, Accuracy: 7824/10000 (78.24%)

Epoch: 83
Loss: 0.148 | Acc: 95.312% (61/64)
Loss: 0.123 | Acc: 95.947% (6202/6464)
Loss: 0.121 | Acc: 95.973% (12346/12864)
Loss: 0.122 | Acc: 95.998% (18493/19264)
Loss: 0.122 | Acc: 95.940% (24622/25664)
Loss: 0.122 | Acc: 95.958% (30768/32064)
Loss: 0.121 | Acc: 95.986% (36920/38464)
Loss: 0.121 | Acc: 95.986% (43063/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3325, Accuracy: 9006/10000 (90.06%)

Epoch: 84
Loss: 0.029 | Acc: 98.438% (63/64)
Loss: 0.106 | Acc: 96.318% (6226/6464)
Loss: 0.103 | Acc: 96.440% (12406/12864)
Loss: 0.112 | Acc: 96.159% (18524/19264)
Loss: 0.110 | Acc: 96.205% (24690/25664)
Loss: 0.107 | Acc: 96.289% (30874/32064)
Loss: 0.109 | Acc: 96.248% (37021/38464)
Loss: 0.109 | Acc: 96.298% (43203/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2799, Accuracy: 9131/10000 (91.31%)

Epoch: 85
Loss: 0.012 | Acc: 100.000% (64/64)
Loss: 0.088 | Acc: 97.107% (6277/6464)
Loss: 0.091 | Acc: 96.976% (12475/12864)
Loss: 0.091 | Acc: 96.948% (18676/19264)
Loss: 0.094 | Acc: 96.918% (24873/25664)
Loss: 0.094 | Acc: 96.887% (31066/32064)
Loss: 0.094 | Acc: 96.867% (37259/38464)
Loss: 0.094 | Acc: 96.873% (43461/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3905, Accuracy: 8923/10000 (89.23%)

Epoch: 86
Loss: 0.071 | Acc: 95.312% (61/64)
Loss: 0.089 | Acc: 97.107% (6277/6464)
Loss: 0.083 | Acc: 97.279% (12514/12864)
Loss: 0.084 | Acc: 97.259% (18736/19264)
Loss: 0.084 | Acc: 97.218% (24950/25664)
Loss: 0.084 | Acc: 97.255% (31184/32064)
Loss: 0.083 | Acc: 97.205% (37389/38464)
Loss: 0.082 | Acc: 97.236% (43624/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2549, Accuracy: 9226/10000 (92.26%)

Epoch: 87
Loss: 0.033 | Acc: 98.438% (63/64)
Loss: 0.059 | Acc: 97.942% (6331/6464)
Loss: 0.057 | Acc: 98.049% (12613/12864)
Loss: 0.059 | Acc: 98.079% (18894/19264)
Loss: 0.059 | Acc: 98.009% (25153/25664)
Loss: 0.061 | Acc: 97.892% (31388/32064)
Loss: 0.063 | Acc: 97.790% (37614/38464)
Loss: 0.064 | Acc: 97.825% (43888/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2453, Accuracy: 9279/10000 (92.79%)

Epoch: 88
Loss: 0.099 | Acc: 96.875% (62/64)
Loss: 0.059 | Acc: 98.035% (6337/6464)
Loss: 0.054 | Acc: 98.189% (12631/12864)
Loss: 0.055 | Acc: 98.090% (18896/19264)
Loss: 0.055 | Acc: 98.114% (25180/25664)
Loss: 0.055 | Acc: 98.101% (31455/32064)
Loss: 0.055 | Acc: 98.074% (37723/38464)
Loss: 0.055 | Acc: 98.110% (44016/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2703, Accuracy: 9212/10000 (92.12%)

Epoch: 89
Loss: 0.042 | Acc: 100.000% (64/64)
Loss: 0.041 | Acc: 98.716% (6381/6464)
Loss: 0.043 | Acc: 98.624% (12687/12864)
Loss: 0.044 | Acc: 98.541% (18983/19264)
Loss: 0.043 | Acc: 98.582% (25300/25664)
Loss: 0.043 | Acc: 98.622% (31622/32064)
Loss: 0.043 | Acc: 98.632% (37938/38464)
Loss: 0.042 | Acc: 98.647% (44257/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2378, Accuracy: 9325/10000 (93.25%)

Epoch: 90
Loss: 0.027 | Acc: 100.000% (64/64)
Loss: 0.033 | Acc: 98.979% (6398/6464)
Loss: 0.033 | Acc: 98.943% (12728/12864)
Loss: 0.031 | Acc: 99.034% (19078/19264)
Loss: 0.031 | Acc: 99.030% (25415/25664)
Loss: 0.033 | Acc: 98.983% (31738/32064)
Loss: 0.033 | Acc: 98.978% (38071/38464)
Loss: 0.033 | Acc: 98.970% (44402/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2300, Accuracy: 9349/10000 (93.49%)

Epoch: 91
Loss: 0.028 | Acc: 98.438% (63/64)
Loss: 0.025 | Acc: 99.257% (6416/6464)
Loss: 0.024 | Acc: 99.293% (12773/12864)
Loss: 0.024 | Acc: 99.320% (19133/19264)
Loss: 0.024 | Acc: 99.303% (25485/25664)
Loss: 0.023 | Acc: 99.305% (31841/32064)
Loss: 0.025 | Acc: 99.275% (38185/38464)
Loss: 0.024 | Acc: 99.287% (44544/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2247, Accuracy: 9370/10000 (93.70%)

Epoch: 92
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.021 | Acc: 99.428% (6427/6464)
Loss: 0.021 | Acc: 99.425% (12790/12864)
Loss: 0.020 | Acc: 99.439% (19156/19264)
Loss: 0.019 | Acc: 99.466% (25527/25664)
Loss: 0.019 | Acc: 99.432% (31882/32064)
Loss: 0.020 | Acc: 99.423% (38242/38464)
Loss: 0.019 | Acc: 99.429% (44608/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2232, Accuracy: 9404/10000 (94.04%)

Epoch: 93
Loss: 0.055 | Acc: 98.438% (63/64)
Loss: 0.015 | Acc: 99.567% (6436/6464)
Loss: 0.015 | Acc: 99.588% (12811/12864)
Loss: 0.015 | Acc: 99.595% (19186/19264)
Loss: 0.015 | Acc: 99.583% (25557/25664)
Loss: 0.014 | Acc: 99.595% (31934/32064)
Loss: 0.014 | Acc: 99.592% (38307/38464)
Loss: 0.014 | Acc: 99.592% (44681/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2139, Accuracy: 9424/10000 (94.24%)

Epoch: 94
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.012 | Acc: 99.722% (6446/6464)
Loss: 0.013 | Acc: 99.697% (12825/12864)
Loss: 0.012 | Acc: 99.725% (19211/19264)
Loss: 0.012 | Acc: 99.719% (25592/25664)
Loss: 0.013 | Acc: 99.691% (31965/32064)
Loss: 0.013 | Acc: 99.678% (38340/38464)
Loss: 0.012 | Acc: 99.683% (44722/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2095, Accuracy: 9433/10000 (94.33%)

Epoch: 95
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.706% (6445/6464)
Loss: 0.009 | Acc: 99.728% (12829/12864)
Loss: 0.009 | Acc: 99.751% (19216/19264)
Loss: 0.009 | Acc: 99.747% (25599/25664)
Loss: 0.009 | Acc: 99.760% (31987/32064)
Loss: 0.009 | Acc: 99.787% (38382/38464)
Loss: 0.009 | Acc: 99.788% (44769/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2123, Accuracy: 9437/10000 (94.37%)

Epoch: 96
Loss: 0.022 | Acc: 98.438% (63/64)
Loss: 0.011 | Acc: 99.737% (6447/6464)
Loss: 0.009 | Acc: 99.821% (12841/12864)
Loss: 0.008 | Acc: 99.849% (19235/19264)
Loss: 0.008 | Acc: 99.844% (25624/25664)
Loss: 0.008 | Acc: 99.835% (32011/32064)
Loss: 0.008 | Acc: 99.847% (38405/38464)
Loss: 0.008 | Acc: 99.837% (44791/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2089, Accuracy: 9426/10000 (94.26%)

Epoch: 97
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.814% (6452/6464)
Loss: 0.007 | Acc: 99.876% (12848/12864)
Loss: 0.008 | Acc: 99.844% (19234/19264)
Loss: 0.007 | Acc: 99.852% (25626/25664)
Loss: 0.008 | Acc: 99.838% (32012/32064)
Loss: 0.008 | Acc: 99.828% (38398/38464)
Loss: 0.008 | Acc: 99.846% (44795/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2083, Accuracy: 9432/10000 (94.32%)
torch.Size([100, 10])
Test set: Average loss: 0.2083, Accuracy: 9432/10000 (94.32%)

Epoch: 98
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.861% (6455/6464)
Loss: 0.008 | Acc: 99.845% (12844/12864)
Loss: 0.008 | Acc: 99.834% (19232/19264)
Loss: 0.007 | Acc: 99.856% (25627/25664)
Loss: 0.007 | Acc: 99.850% (32016/32064)
Loss: 0.007 | Acc: 99.852% (38407/38464)
Loss: 0.007 | Acc: 99.853% (44798/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2071, Accuracy: 9435/10000 (94.35%)
torch.Size([100, 10])
Test set: Average loss: 0.2071, Accuracy: 9435/10000 (94.35%)

Epoch: 99
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.830% (6453/6464)
Loss: 0.008 | Acc: 99.852% (12845/12864)
Loss: 0.008 | Acc: 99.849% (19235/19264)
Loss: 0.008 | Acc: 99.844% (25624/25664)
Loss: 0.007 | Acc: 99.860% (32019/32064)
Loss: 0.007 | Acc: 99.860% (38410/38464)
Loss: 0.007 | Acc: 99.860% (44801/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2063, Accuracy: 9442/10000 (94.42%)
torch.Size([100, 10])
Test set: Average loss: 0.2063, Accuracy: 9442/10000 (94.42%)

Epoch: 100
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 1.994 | Acc: 28.125% (1818/6464)
Loss: 1.694 | Acc: 38.596% (4965/12864)
Loss: 1.418 | Acc: 49.268% (9491/19264)
Loss: 1.233 | Acc: 56.047% (14384/25664)
Loss: 1.110 | Acc: 60.635% (19442/32064)
Loss: 1.019 | Acc: 64.011% (24621/38464)
Loss: 0.948 | Acc: 66.648% (29901/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0769, Accuracy: 7109/10000 (71.09%)

Epoch: 101
Loss: 0.632 | Acc: 81.250% (52/64)
Loss: 0.471 | Acc: 83.973% (5428/6464)
Loss: 0.480 | Acc: 83.940% (10798/12864)
Loss: 0.473 | Acc: 83.903% (16163/19264)
Loss: 0.462 | Acc: 84.254% (21623/25664)
Loss: 0.457 | Acc: 84.422% (27069/32064)
Loss: 0.453 | Acc: 84.586% (32535/38464)
Loss: 0.452 | Acc: 84.582% (37947/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4849, Accuracy: 6667/10000 (66.67%)

Epoch: 102
Loss: 0.555 | Acc: 84.375% (54/64)
Loss: 0.385 | Acc: 87.067% (5628/6464)
Loss: 0.400 | Acc: 86.381% (11112/12864)
Loss: 0.403 | Acc: 86.337% (16632/19264)
Loss: 0.401 | Acc: 86.444% (22185/25664)
Loss: 0.402 | Acc: 86.377% (27696/32064)
Loss: 0.398 | Acc: 86.504% (33273/38464)
Loss: 0.397 | Acc: 86.573% (38840/44864)
torch.Size([100, 10])
Test set: Average loss: 19.2347, Accuracy: 1336/10000 (13.36%)

Epoch: 103
Loss: 0.854 | Acc: 71.875% (46/64)
Loss: 0.387 | Acc: 86.974% (5622/6464)
Loss: 0.382 | Acc: 87.212% (11219/12864)
Loss: 0.379 | Acc: 87.199% (16798/19264)
Loss: 0.371 | Acc: 87.426% (22437/25664)
Loss: 0.371 | Acc: 87.503% (28057/32064)
Loss: 0.372 | Acc: 87.443% (33634/38464)
Loss: 0.374 | Acc: 87.362% (39194/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9379, Accuracy: 7073/10000 (70.73%)

Epoch: 104
Loss: 0.578 | Acc: 78.125% (50/64)
Loss: 0.366 | Acc: 87.531% (5658/6464)
Loss: 0.364 | Acc: 87.523% (11259/12864)
Loss: 0.357 | Acc: 87.905% (16934/19264)
Loss: 0.359 | Acc: 87.781% (22528/25664)
Loss: 0.358 | Acc: 87.827% (28161/32064)
Loss: 0.358 | Acc: 87.812% (33776/38464)
Loss: 0.360 | Acc: 87.723% (39356/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5803, Accuracy: 8100/10000 (81.00%)

Epoch: 105
Loss: 0.478 | Acc: 82.812% (53/64)
Loss: 0.360 | Acc: 88.150% (5698/6464)
Loss: 0.352 | Acc: 87.990% (11319/12864)
Loss: 0.352 | Acc: 87.962% (16945/19264)
Loss: 0.355 | Acc: 87.812% (22536/25664)
Loss: 0.354 | Acc: 87.896% (28183/32064)
Loss: 0.354 | Acc: 87.841% (33787/38464)
Loss: 0.354 | Acc: 87.792% (39387/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8385, Accuracy: 5679/10000 (56.79%)

Epoch: 106
Loss: 0.594 | Acc: 79.688% (51/64)
Loss: 0.350 | Acc: 87.809% (5676/6464)
Loss: 0.339 | Acc: 88.106% (11334/12864)
Loss: 0.333 | Acc: 88.419% (17033/19264)
Loss: 0.342 | Acc: 88.120% (22615/25664)
Loss: 0.342 | Acc: 88.139% (28261/32064)
Loss: 0.344 | Acc: 88.080% (33879/38464)
Loss: 0.346 | Acc: 88.066% (39510/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5324, Accuracy: 8361/10000 (83.61%)

Epoch: 107
Loss: 0.444 | Acc: 84.375% (54/64)
Loss: 0.323 | Acc: 89.001% (5753/6464)
Loss: 0.330 | Acc: 88.565% (11393/12864)
Loss: 0.333 | Acc: 88.626% (17073/19264)
Loss: 0.335 | Acc: 88.556% (22727/25664)
Loss: 0.341 | Acc: 88.358% (28331/32064)
Loss: 0.341 | Acc: 88.402% (34003/38464)
Loss: 0.339 | Acc: 88.436% (39676/44864)
torch.Size([100, 10])
Test set: Average loss: 5.6755, Accuracy: 3080/10000 (30.80%)

Epoch: 108
Loss: 0.577 | Acc: 84.375% (54/64)
Loss: 0.338 | Acc: 88.660% (5731/6464)
Loss: 0.339 | Acc: 88.417% (11374/12864)
Loss: 0.340 | Acc: 88.408% (17031/19264)
Loss: 0.343 | Acc: 88.318% (22666/25664)
Loss: 0.338 | Acc: 88.457% (28363/32064)
Loss: 0.341 | Acc: 88.400% (34002/38464)
Loss: 0.341 | Acc: 88.407% (39663/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8823, Accuracy: 7456/10000 (74.56%)

Epoch: 109
Loss: 0.295 | Acc: 85.938% (55/64)
Loss: 0.337 | Acc: 88.243% (5704/6464)
Loss: 0.333 | Acc: 88.549% (11391/12864)
Loss: 0.331 | Acc: 88.606% (17069/19264)
Loss: 0.332 | Acc: 88.638% (22748/25664)
Loss: 0.334 | Acc: 88.610% (28412/32064)
Loss: 0.332 | Acc: 88.688% (34113/38464)
Loss: 0.331 | Acc: 88.697% (39793/44864)
torch.Size([100, 10])
Test set: Average loss: 2.7038, Accuracy: 4954/10000 (49.54%)

Epoch: 110
Loss: 0.781 | Acc: 78.125% (50/64)
Loss: 0.323 | Acc: 89.171% (5764/6464)
Loss: 0.321 | Acc: 89.241% (11480/12864)
Loss: 0.321 | Acc: 89.177% (17179/19264)
Loss: 0.321 | Acc: 89.117% (22871/25664)
Loss: 0.325 | Acc: 88.975% (28529/32064)
Loss: 0.326 | Acc: 88.964% (34219/38464)
Loss: 0.326 | Acc: 88.924% (39895/44864)
torch.Size([100, 10])
Test set: Average loss: 3.1313, Accuracy: 4543/10000 (45.43%)

Epoch: 111
Loss: 0.537 | Acc: 81.250% (52/64)
Loss: 0.301 | Acc: 89.913% (5812/6464)
Loss: 0.323 | Acc: 89.117% (11464/12864)
Loss: 0.315 | Acc: 89.338% (17210/19264)
Loss: 0.312 | Acc: 89.394% (22942/25664)
Loss: 0.316 | Acc: 89.290% (28630/32064)
Loss: 0.319 | Acc: 89.185% (34304/38464)
Loss: 0.320 | Acc: 89.181% (40010/44864)
torch.Size([100, 10])
Test set: Average loss: 12.2230, Accuracy: 2965/10000 (29.65%)

Epoch: 112
Loss: 0.944 | Acc: 75.000% (48/64)
Loss: 0.304 | Acc: 89.527% (5787/6464)
Loss: 0.303 | Acc: 89.443% (11506/12864)
Loss: 0.306 | Acc: 89.550% (17251/19264)
Loss: 0.307 | Acc: 89.596% (22994/25664)
Loss: 0.312 | Acc: 89.440% (28678/32064)
Loss: 0.314 | Acc: 89.411% (34391/38464)
Loss: 0.314 | Acc: 89.359% (40090/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6414, Accuracy: 7951/10000 (79.51%)

Epoch: 113
Loss: 0.373 | Acc: 84.375% (54/64)
Loss: 0.301 | Acc: 90.084% (5823/6464)
Loss: 0.301 | Acc: 90.026% (11581/12864)
Loss: 0.299 | Acc: 89.883% (17315/19264)
Loss: 0.303 | Acc: 89.690% (23018/25664)
Loss: 0.304 | Acc: 89.652% (28746/32064)
Loss: 0.305 | Acc: 89.603% (34465/38464)
Loss: 0.306 | Acc: 89.609% (40202/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3465, Accuracy: 6612/10000 (66.12%)

Epoch: 114
Loss: 0.451 | Acc: 89.062% (57/64)
Loss: 0.291 | Acc: 89.851% (5808/6464)
Loss: 0.302 | Acc: 89.443% (11506/12864)
Loss: 0.303 | Acc: 89.602% (17261/19264)
Loss: 0.301 | Acc: 89.694% (23019/25664)
Loss: 0.300 | Acc: 89.724% (28769/32064)
Loss: 0.304 | Acc: 89.603% (34465/38464)
Loss: 0.305 | Acc: 89.638% (40215/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0885, Accuracy: 6856/10000 (68.56%)

Epoch: 115
Loss: 0.462 | Acc: 84.375% (54/64)
Loss: 0.279 | Acc: 90.408% (5844/6464)
Loss: 0.282 | Acc: 90.368% (11625/12864)
Loss: 0.286 | Acc: 90.220% (17380/19264)
Loss: 0.288 | Acc: 90.192% (23147/25664)
Loss: 0.292 | Acc: 90.042% (28871/32064)
Loss: 0.293 | Acc: 90.022% (34626/38464)
Loss: 0.296 | Acc: 90.016% (40385/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5015, Accuracy: 8421/10000 (84.21%)

Epoch: 116
Loss: 0.244 | Acc: 93.750% (60/64)
Loss: 0.276 | Acc: 90.640% (5859/6464)
Loss: 0.277 | Acc: 90.602% (11655/12864)
Loss: 0.284 | Acc: 90.267% (17389/19264)
Loss: 0.283 | Acc: 90.321% (23180/25664)
Loss: 0.286 | Acc: 90.213% (28926/32064)
Loss: 0.287 | Acc: 90.188% (34690/38464)
Loss: 0.291 | Acc: 90.066% (40407/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8764, Accuracy: 7513/10000 (75.13%)

Epoch: 117
Loss: 0.334 | Acc: 90.625% (58/64)
Loss: 0.271 | Acc: 90.733% (5865/6464)
Loss: 0.280 | Acc: 90.337% (11621/12864)
Loss: 0.273 | Acc: 90.635% (17460/19264)
Loss: 0.273 | Acc: 90.602% (23252/25664)
Loss: 0.277 | Acc: 90.516% (29023/32064)
Loss: 0.279 | Acc: 90.466% (34797/38464)
Loss: 0.279 | Acc: 90.480% (40593/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3039, Accuracy: 6469/10000 (64.69%)

Epoch: 118
Loss: 0.514 | Acc: 87.500% (56/64)
Loss: 0.267 | Acc: 91.089% (5888/6464)
Loss: 0.262 | Acc: 91.332% (11749/12864)
Loss: 0.261 | Acc: 91.367% (17601/19264)
Loss: 0.268 | Acc: 91.061% (23370/25664)
Loss: 0.269 | Acc: 90.952% (29163/32064)
Loss: 0.271 | Acc: 90.911% (34968/38464)
Loss: 0.271 | Acc: 90.848% (40758/44864)
torch.Size([100, 10])
Test set: Average loss: 3.3131, Accuracy: 4153/10000 (41.53%)

Epoch: 119
Loss: 0.281 | Acc: 92.188% (59/64)
Loss: 0.269 | Acc: 90.470% (5848/6464)
Loss: 0.263 | Acc: 90.951% (11700/12864)
Loss: 0.265 | Acc: 90.822% (17496/19264)
Loss: 0.269 | Acc: 90.656% (23266/25664)
Loss: 0.267 | Acc: 90.672% (29073/32064)
Loss: 0.265 | Acc: 90.794% (34923/38464)
Loss: 0.268 | Acc: 90.745% (40712/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4732, Accuracy: 8447/10000 (84.47%)

Epoch: 120
Loss: 0.254 | Acc: 92.188% (59/64)
Loss: 0.250 | Acc: 91.677% (5926/6464)
Loss: 0.252 | Acc: 91.270% (11741/12864)
Loss: 0.254 | Acc: 91.321% (17592/19264)
Loss: 0.256 | Acc: 91.241% (23416/25664)
Loss: 0.254 | Acc: 91.292% (29272/32064)
Loss: 0.257 | Acc: 91.181% (35072/38464)
Loss: 0.257 | Acc: 91.160% (40898/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1354, Accuracy: 7033/10000 (70.33%)

Epoch: 121
Loss: 0.265 | Acc: 92.188% (59/64)
Loss: 0.220 | Acc: 92.512% (5980/6464)
Loss: 0.239 | Acc: 91.744% (11802/12864)
Loss: 0.247 | Acc: 91.440% (17615/19264)
Loss: 0.247 | Acc: 91.510% (23485/25664)
Loss: 0.247 | Acc: 91.486% (29334/32064)
Loss: 0.249 | Acc: 91.460% (35179/38464)
Loss: 0.250 | Acc: 91.443% (41025/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6619, Accuracy: 8095/10000 (80.95%)

Epoch: 122
Loss: 0.370 | Acc: 82.812% (53/64)
Loss: 0.211 | Acc: 92.713% (5993/6464)
Loss: 0.219 | Acc: 92.545% (11905/12864)
Loss: 0.229 | Acc: 92.265% (17774/19264)
Loss: 0.232 | Acc: 92.125% (23643/25664)
Loss: 0.235 | Acc: 92.032% (29509/32064)
Loss: 0.237 | Acc: 91.930% (35360/38464)
Loss: 0.241 | Acc: 91.780% (41176/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6329, Accuracy: 8005/10000 (80.05%)

Epoch: 123
Loss: 0.427 | Acc: 85.938% (55/64)
Loss: 0.209 | Acc: 93.054% (6015/6464)
Loss: 0.212 | Acc: 92.802% (11938/12864)
Loss: 0.216 | Acc: 92.598% (17838/19264)
Loss: 0.219 | Acc: 92.468% (23731/25664)
Loss: 0.224 | Acc: 92.300% (29595/32064)
Loss: 0.226 | Acc: 92.268% (35490/38464)
Loss: 0.226 | Acc: 92.281% (41401/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5986, Accuracy: 8262/10000 (82.62%)

Epoch: 124
Loss: 0.347 | Acc: 87.500% (56/64)
Loss: 0.224 | Acc: 92.605% (5986/6464)
Loss: 0.221 | Acc: 92.724% (11928/12864)
Loss: 0.218 | Acc: 92.733% (17864/19264)
Loss: 0.221 | Acc: 92.476% (23733/25664)
Loss: 0.225 | Acc: 92.343% (29609/32064)
Loss: 0.223 | Acc: 92.414% (35546/38464)
Loss: 0.224 | Acc: 92.370% (41441/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4771, Accuracy: 8490/10000 (84.90%)

Epoch: 125
Loss: 0.143 | Acc: 92.188% (59/64)
Loss: 0.189 | Acc: 93.642% (6053/6464)
Loss: 0.194 | Acc: 93.354% (12009/12864)
Loss: 0.201 | Acc: 93.054% (17926/19264)
Loss: 0.204 | Acc: 92.943% (23853/25664)
Loss: 0.205 | Acc: 92.830% (29765/32064)
Loss: 0.205 | Acc: 92.806% (35697/38464)
Loss: 0.206 | Acc: 92.780% (41625/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6787, Accuracy: 7904/10000 (79.04%)

Epoch: 126
Loss: 0.335 | Acc: 89.062% (57/64)
Loss: 0.198 | Acc: 93.069% (6016/6464)
Loss: 0.191 | Acc: 93.455% (12022/12864)
Loss: 0.198 | Acc: 93.200% (17954/19264)
Loss: 0.200 | Acc: 93.181% (23914/25664)
Loss: 0.200 | Acc: 93.167% (29873/32064)
Loss: 0.202 | Acc: 93.103% (35811/38464)
Loss: 0.200 | Acc: 93.186% (41807/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4183, Accuracy: 8692/10000 (86.92%)

Epoch: 127
Loss: 0.370 | Acc: 85.938% (55/64)
Loss: 0.185 | Acc: 93.936% (6072/6464)
Loss: 0.186 | Acc: 93.750% (12060/12864)
Loss: 0.187 | Acc: 93.812% (18072/19264)
Loss: 0.186 | Acc: 93.766% (24064/25664)
Loss: 0.187 | Acc: 93.694% (30042/32064)
Loss: 0.190 | Acc: 93.597% (36001/38464)
Loss: 0.190 | Acc: 93.587% (41987/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4520, Accuracy: 8655/10000 (86.55%)

Epoch: 128
Loss: 0.146 | Acc: 93.750% (60/64)
Loss: 0.164 | Acc: 94.230% (6091/6464)
Loss: 0.165 | Acc: 94.216% (12120/12864)
Loss: 0.168 | Acc: 94.129% (18133/19264)
Loss: 0.171 | Acc: 94.163% (24166/25664)
Loss: 0.174 | Acc: 94.053% (30157/32064)
Loss: 0.176 | Acc: 93.997% (36155/38464)
Loss: 0.178 | Acc: 93.886% (42121/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2807, Accuracy: 9107/10000 (91.07%)

Epoch: 129
Loss: 0.092 | Acc: 98.438% (63/64)
Loss: 0.159 | Acc: 94.539% (6111/6464)
Loss: 0.152 | Acc: 94.729% (12186/12864)
Loss: 0.157 | Acc: 94.518% (18208/19264)
Loss: 0.162 | Acc: 94.416% (24231/25664)
Loss: 0.164 | Acc: 94.343% (30250/32064)
Loss: 0.167 | Acc: 94.280% (36264/38464)
Loss: 0.166 | Acc: 94.301% (42307/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5004, Accuracy: 8486/10000 (84.86%)

Epoch: 130
Loss: 0.220 | Acc: 95.312% (61/64)
Loss: 0.150 | Acc: 95.111% (6148/6464)
Loss: 0.151 | Acc: 94.877% (12205/12864)
Loss: 0.149 | Acc: 95.011% (18303/19264)
Loss: 0.150 | Acc: 94.927% (24362/25664)
Loss: 0.150 | Acc: 94.935% (30440/32064)
Loss: 0.150 | Acc: 94.917% (36509/38464)
Loss: 0.151 | Acc: 94.838% (42548/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3192, Accuracy: 8989/10000 (89.89%)

Epoch: 131
Loss: 0.359 | Acc: 87.500% (56/64)
Loss: 0.130 | Acc: 95.483% (6172/6464)
Loss: 0.137 | Acc: 95.312% (12261/12864)
Loss: 0.134 | Acc: 95.437% (18385/19264)
Loss: 0.137 | Acc: 95.320% (24463/25664)
Loss: 0.136 | Acc: 95.384% (30584/32064)
Loss: 0.137 | Acc: 95.323% (36665/38464)
Loss: 0.140 | Acc: 95.228% (42723/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4271, Accuracy: 8755/10000 (87.55%)

Epoch: 132
Loss: 0.197 | Acc: 92.188% (59/64)
Loss: 0.124 | Acc: 95.777% (6191/6464)
Loss: 0.119 | Acc: 96.105% (12363/12864)
Loss: 0.124 | Acc: 95.873% (18469/19264)
Loss: 0.123 | Acc: 95.835% (24595/25664)
Loss: 0.126 | Acc: 95.690% (30682/32064)
Loss: 0.125 | Acc: 95.757% (36832/38464)
Loss: 0.126 | Acc: 95.756% (42960/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4740, Accuracy: 8626/10000 (86.26%)

Epoch: 133
Loss: 0.147 | Acc: 95.312% (61/64)
Loss: 0.116 | Acc: 95.993% (6205/6464)
Loss: 0.117 | Acc: 95.950% (12343/12864)
Loss: 0.115 | Acc: 96.039% (18501/19264)
Loss: 0.115 | Acc: 96.100% (24663/25664)
Loss: 0.116 | Acc: 96.092% (30811/32064)
Loss: 0.117 | Acc: 96.051% (36945/38464)
Loss: 0.117 | Acc: 96.086% (43108/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3141, Accuracy: 9097/10000 (90.97%)

Epoch: 134
Loss: 0.097 | Acc: 96.875% (62/64)
Loss: 0.085 | Acc: 97.215% (6284/6464)
Loss: 0.091 | Acc: 96.992% (12477/12864)
Loss: 0.092 | Acc: 96.917% (18670/19264)
Loss: 0.094 | Acc: 96.770% (24835/25664)
Loss: 0.094 | Acc: 96.816% (31043/32064)
Loss: 0.096 | Acc: 96.711% (37199/38464)
Loss: 0.096 | Acc: 96.710% (43388/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2976, Accuracy: 9117/10000 (91.17%)

Epoch: 135
Loss: 0.051 | Acc: 96.875% (62/64)
Loss: 0.082 | Acc: 97.401% (6296/6464)
Loss: 0.081 | Acc: 97.357% (12524/12864)
Loss: 0.080 | Acc: 97.327% (18749/19264)
Loss: 0.082 | Acc: 97.241% (24956/25664)
Loss: 0.082 | Acc: 97.252% (31183/32064)
Loss: 0.083 | Acc: 97.231% (37399/38464)
Loss: 0.083 | Acc: 97.209% (43612/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5021, Accuracy: 8602/10000 (86.02%)

Epoch: 136
Loss: 0.153 | Acc: 96.875% (62/64)
Loss: 0.088 | Acc: 96.968% (6268/6464)
Loss: 0.081 | Acc: 97.240% (12509/12864)
Loss: 0.079 | Acc: 97.363% (18756/19264)
Loss: 0.078 | Acc: 97.366% (24988/25664)
Loss: 0.078 | Acc: 97.411% (31234/32064)
Loss: 0.080 | Acc: 97.338% (37440/38464)
Loss: 0.079 | Acc: 97.339% (43670/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5773, Accuracy: 8559/10000 (85.59%)

Epoch: 137
Loss: 0.058 | Acc: 98.438% (63/64)
Loss: 0.072 | Acc: 97.463% (6300/6464)
Loss: 0.062 | Acc: 97.808% (12582/12864)
Loss: 0.060 | Acc: 97.908% (18861/19264)
Loss: 0.060 | Acc: 97.923% (25131/25664)
Loss: 0.061 | Acc: 97.907% (31393/32064)
Loss: 0.060 | Acc: 97.933% (37669/38464)
Loss: 0.060 | Acc: 97.972% (43954/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3001, Accuracy: 9140/10000 (91.40%)

Epoch: 138
Loss: 0.128 | Acc: 93.750% (60/64)
Loss: 0.056 | Acc: 98.113% (6342/6464)
Loss: 0.056 | Acc: 98.181% (12630/12864)
Loss: 0.055 | Acc: 98.173% (18912/19264)
Loss: 0.054 | Acc: 98.204% (25203/25664)
Loss: 0.053 | Acc: 98.260% (31506/32064)
Loss: 0.051 | Acc: 98.295% (37808/38464)
Loss: 0.052 | Acc: 98.266% (44086/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2384, Accuracy: 9316/10000 (93.16%)

Epoch: 139
Loss: 0.025 | Acc: 98.438% (63/64)
Loss: 0.036 | Acc: 98.871% (6391/6464)
Loss: 0.036 | Acc: 98.881% (12720/12864)
Loss: 0.036 | Acc: 98.832% (19039/19264)
Loss: 0.035 | Acc: 98.835% (25365/25664)
Loss: 0.037 | Acc: 98.787% (31675/32064)
Loss: 0.036 | Acc: 98.796% (38001/38464)
Loss: 0.037 | Acc: 98.772% (44313/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2488, Accuracy: 9297/10000 (92.97%)

Epoch: 140
Loss: 0.010 | Acc: 100.000% (64/64)
Loss: 0.035 | Acc: 98.778% (6385/6464)
Loss: 0.030 | Acc: 99.044% (12741/12864)
Loss: 0.029 | Acc: 99.081% (19087/19264)
Loss: 0.030 | Acc: 99.077% (25427/25664)
Loss: 0.030 | Acc: 99.058% (31762/32064)
Loss: 0.030 | Acc: 99.080% (38110/38464)
Loss: 0.031 | Acc: 99.044% (44435/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2210, Accuracy: 9405/10000 (94.05%)

Epoch: 141
Loss: 0.044 | Acc: 96.875% (62/64)
Loss: 0.022 | Acc: 99.288% (6418/6464)
Loss: 0.023 | Acc: 99.293% (12773/12864)
Loss: 0.021 | Acc: 99.367% (19142/19264)
Loss: 0.021 | Acc: 99.384% (25506/25664)
Loss: 0.021 | Acc: 99.401% (31872/32064)
Loss: 0.022 | Acc: 99.376% (38224/38464)
Loss: 0.022 | Acc: 99.356% (44575/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2147, Accuracy: 9417/10000 (94.17%)

Epoch: 142
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.014 | Acc: 99.582% (6437/6464)
Loss: 0.014 | Acc: 99.604% (12813/12864)
Loss: 0.015 | Acc: 99.554% (19178/19264)
Loss: 0.016 | Acc: 99.529% (25543/25664)
Loss: 0.015 | Acc: 99.573% (31927/32064)
Loss: 0.015 | Acc: 99.597% (38309/38464)
Loss: 0.015 | Acc: 99.588% (44679/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2075, Accuracy: 9409/10000 (94.09%)

Epoch: 143
Loss: 0.013 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.799% (6451/6464)
Loss: 0.012 | Acc: 99.720% (12828/12864)
Loss: 0.012 | Acc: 99.725% (19211/19264)
Loss: 0.012 | Acc: 99.739% (25597/25664)
Loss: 0.012 | Acc: 99.738% (31980/32064)
Loss: 0.012 | Acc: 99.724% (38358/38464)
Loss: 0.011 | Acc: 99.728% (44742/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2048, Accuracy: 9448/10000 (94.48%)

Epoch: 144
Loss: 0.013 | Acc: 100.000% (64/64)
Loss: 0.012 | Acc: 99.722% (6446/6464)
Loss: 0.011 | Acc: 99.736% (12830/12864)
Loss: 0.011 | Acc: 99.714% (19209/19264)
Loss: 0.011 | Acc: 99.708% (25589/25664)
Loss: 0.011 | Acc: 99.719% (31974/32064)
Loss: 0.011 | Acc: 99.722% (38357/38464)
Loss: 0.010 | Acc: 99.733% (44744/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2029, Accuracy: 9456/10000 (94.56%)

Epoch: 145
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.737% (6447/6464)
Loss: 0.009 | Acc: 99.728% (12829/12864)
Loss: 0.009 | Acc: 99.751% (19216/19264)
Loss: 0.009 | Acc: 99.751% (25600/25664)
Loss: 0.009 | Acc: 99.757% (31986/32064)
Loss: 0.009 | Acc: 99.766% (38374/38464)
Loss: 0.008 | Acc: 99.773% (44762/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2011, Accuracy: 9461/10000 (94.61%)

Epoch: 146
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.876% (6456/6464)
Loss: 0.008 | Acc: 99.845% (12844/12864)
Loss: 0.008 | Acc: 99.829% (19231/19264)
Loss: 0.008 | Acc: 99.809% (25615/25664)
Loss: 0.008 | Acc: 99.807% (32002/32064)
Loss: 0.008 | Acc: 99.808% (38390/38464)
Loss: 0.008 | Acc: 99.802% (44775/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2024, Accuracy: 9457/10000 (94.57%)

Epoch: 147
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.006 | Acc: 99.892% (6457/6464)
Loss: 0.006 | Acc: 99.868% (12847/12864)
Loss: 0.007 | Acc: 99.855% (19236/19264)
Loss: 0.007 | Acc: 99.856% (25627/25664)
Loss: 0.007 | Acc: 99.857% (32018/32064)
Loss: 0.007 | Acc: 99.857% (38409/38464)
Loss: 0.007 | Acc: 99.844% (44794/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1990, Accuracy: 9456/10000 (94.56%)
torch.Size([100, 10])
Test set: Average loss: 0.1990, Accuracy: 9456/10000 (94.56%)

Epoch: 148
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.005 | Acc: 99.938% (6460/6464)
Loss: 0.006 | Acc: 99.907% (12852/12864)
Loss: 0.006 | Acc: 99.891% (19243/19264)
Loss: 0.006 | Acc: 99.899% (25638/25664)
Loss: 0.006 | Acc: 99.897% (32031/32064)
Loss: 0.006 | Acc: 99.901% (38426/38464)
Loss: 0.006 | Acc: 99.891% (44815/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1976, Accuracy: 9465/10000 (94.65%)
torch.Size([100, 10])
Test set: Average loss: 0.1976, Accuracy: 9465/10000 (94.65%)

Epoch: 149
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 0.006 | Acc: 99.892% (6457/6464)
Loss: 0.006 | Acc: 99.907% (12852/12864)
Loss: 0.006 | Acc: 99.896% (19244/19264)
Loss: 0.006 | Acc: 99.906% (25640/25664)
Loss: 0.006 | Acc: 99.910% (32035/32064)
Loss: 0.006 | Acc: 99.906% (38428/38464)
Loss: 0.006 | Acc: 99.900% (44819/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2008, Accuracy: 9466/10000 (94.66%)
torch.Size([100, 10])
Test set: Average loss: 0.2008, Accuracy: 9466/10000 (94.66%)

Epoch: 150
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 2.014 | Acc: 26.408% (1707/6464)
Loss: 1.887 | Acc: 29.998% (3859/12864)
Loss: 1.808 | Acc: 32.558% (6272/19264)
Loss: 1.728 | Acc: 35.813% (9191/25664)
Loss: 1.643 | Acc: 39.396% (12632/32064)
Loss: 1.552 | Acc: 43.079% (16570/38464)
Loss: 1.465 | Acc: 46.594% (20904/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6735, Accuracy: 5100/10000 (51.00%)

Epoch: 151
Loss: 1.025 | Acc: 65.625% (42/64)
Loss: 0.740 | Acc: 74.335% (4805/6464)
Loss: 0.708 | Acc: 75.529% (9716/12864)
Loss: 0.682 | Acc: 76.428% (14723/19264)
Loss: 0.662 | Acc: 77.190% (19810/25664)
Loss: 0.637 | Acc: 78.103% (25043/32064)
Loss: 0.622 | Acc: 78.679% (30263/38464)
Loss: 0.608 | Acc: 79.164% (35516/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8242, Accuracy: 5279/10000 (52.79%)

Epoch: 152
Loss: 0.852 | Acc: 68.750% (44/64)
Loss: 0.473 | Acc: 83.354% (5388/6464)
Loss: 0.467 | Acc: 83.854% (10787/12864)
Loss: 0.462 | Acc: 84.157% (16212/19264)
Loss: 0.469 | Acc: 83.748% (21493/25664)
Loss: 0.466 | Acc: 83.873% (26893/32064)
Loss: 0.460 | Acc: 84.164% (32373/38464)
Loss: 0.456 | Acc: 84.297% (37819/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6094, Accuracy: 6042/10000 (60.42%)

Epoch: 153
Loss: 0.962 | Acc: 73.438% (47/64)
Loss: 0.421 | Acc: 85.489% (5526/6464)
Loss: 0.410 | Acc: 85.976% (11060/12864)
Loss: 0.407 | Acc: 85.963% (16560/19264)
Loss: 0.400 | Acc: 86.397% (22173/25664)
Loss: 0.401 | Acc: 86.359% (27690/32064)
Loss: 0.401 | Acc: 86.348% (33213/38464)
Loss: 0.399 | Acc: 86.383% (38755/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9359, Accuracy: 7166/10000 (71.66%)

Epoch: 154
Loss: 0.379 | Acc: 87.500% (56/64)
Loss: 0.393 | Acc: 86.309% (5579/6464)
Loss: 0.390 | Acc: 86.528% (11131/12864)
Loss: 0.388 | Acc: 86.695% (16701/19264)
Loss: 0.384 | Acc: 86.830% (22284/25664)
Loss: 0.380 | Acc: 87.023% (27903/32064)
Loss: 0.378 | Acc: 87.107% (33505/38464)
Loss: 0.377 | Acc: 87.166% (39106/44864)
torch.Size([100, 10])
Test set: Average loss: 5.1887, Accuracy: 4518/10000 (45.18%)

Epoch: 155
Loss: 1.376 | Acc: 71.875% (46/64)
Loss: 0.378 | Acc: 87.454% (5653/6464)
Loss: 0.370 | Acc: 87.562% (11264/12864)
Loss: 0.364 | Acc: 87.708% (16896/19264)
Loss: 0.360 | Acc: 87.948% (22571/25664)
Loss: 0.359 | Acc: 87.924% (28192/32064)
Loss: 0.361 | Acc: 87.864% (33796/38464)
Loss: 0.362 | Acc: 87.790% (39386/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2623, Accuracy: 6793/10000 (67.93%)

Epoch: 156
Loss: 0.291 | Acc: 90.625% (58/64)
Loss: 0.359 | Acc: 87.717% (5670/6464)
Loss: 0.352 | Acc: 87.896% (11307/12864)
Loss: 0.353 | Acc: 87.827% (16919/19264)
Loss: 0.351 | Acc: 87.874% (22552/25664)
Loss: 0.351 | Acc: 87.921% (28191/32064)
Loss: 0.353 | Acc: 87.934% (33823/38464)
Loss: 0.354 | Acc: 87.883% (39428/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6630, Accuracy: 6238/10000 (62.38%)

Epoch: 157
Loss: 0.474 | Acc: 81.250% (52/64)
Loss: 0.346 | Acc: 88.243% (5704/6464)
Loss: 0.339 | Acc: 88.324% (11362/12864)
Loss: 0.342 | Acc: 88.331% (17016/19264)
Loss: 0.339 | Acc: 88.396% (22686/25664)
Loss: 0.344 | Acc: 88.267% (28302/32064)
Loss: 0.345 | Acc: 88.228% (33936/38464)
Loss: 0.343 | Acc: 88.271% (39602/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3131, Accuracy: 6656/10000 (66.56%)

Epoch: 158
Loss: 0.565 | Acc: 79.688% (51/64)
Loss: 0.331 | Acc: 88.954% (5750/6464)
Loss: 0.331 | Acc: 88.946% (11442/12864)
Loss: 0.326 | Acc: 89.037% (17152/19264)
Loss: 0.323 | Acc: 89.062% (22857/25664)
Loss: 0.331 | Acc: 88.844% (28487/32064)
Loss: 0.334 | Acc: 88.766% (34143/38464)
Loss: 0.336 | Acc: 88.690% (39790/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5845, Accuracy: 8090/10000 (80.90%)

Epoch: 159
Loss: 0.600 | Acc: 82.812% (53/64)
Loss: 0.310 | Acc: 89.202% (5766/6464)
Loss: 0.327 | Acc: 88.705% (11411/12864)
Loss: 0.329 | Acc: 88.611% (17070/19264)
Loss: 0.329 | Acc: 88.657% (22753/25664)
Loss: 0.327 | Acc: 88.772% (28464/32064)
Loss: 0.330 | Acc: 88.628% (34090/38464)
Loss: 0.332 | Acc: 88.590% (39745/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4863, Accuracy: 4967/10000 (49.67%)

Epoch: 160
Loss: 0.831 | Acc: 78.125% (50/64)
Loss: 0.303 | Acc: 90.207% (5831/6464)
Loss: 0.319 | Acc: 89.506% (11514/12864)
Loss: 0.319 | Acc: 89.384% (17219/19264)
Loss: 0.323 | Acc: 89.070% (22859/25664)
Loss: 0.318 | Acc: 89.349% (28649/32064)
Loss: 0.319 | Acc: 89.265% (34335/38464)
Loss: 0.322 | Acc: 89.176% (40008/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7198, Accuracy: 7738/10000 (77.38%)

Epoch: 161
Loss: 0.355 | Acc: 90.625% (58/64)
Loss: 0.302 | Acc: 90.161% (5828/6464)
Loss: 0.310 | Acc: 89.801% (11552/12864)
Loss: 0.309 | Acc: 89.706% (17281/19264)
Loss: 0.315 | Acc: 89.355% (22932/25664)
Loss: 0.319 | Acc: 89.187% (28597/32064)
Loss: 0.320 | Acc: 89.127% (34282/38464)
Loss: 0.320 | Acc: 89.107% (39977/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8852, Accuracy: 7448/10000 (74.48%)

Epoch: 162
Loss: 0.363 | Acc: 89.062% (57/64)
Loss: 0.297 | Acc: 89.991% (5817/6464)
Loss: 0.296 | Acc: 90.112% (11592/12864)
Loss: 0.300 | Acc: 90.054% (17348/19264)
Loss: 0.303 | Acc: 89.869% (23064/25664)
Loss: 0.309 | Acc: 89.571% (28720/32064)
Loss: 0.310 | Acc: 89.554% (34446/38464)
Loss: 0.313 | Acc: 89.381% (40100/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4725, Accuracy: 8566/10000 (85.66%)

Epoch: 163
Loss: 0.237 | Acc: 95.312% (61/64)
Loss: 0.307 | Acc: 89.821% (5806/6464)
Loss: 0.304 | Acc: 89.700% (11539/12864)
Loss: 0.305 | Acc: 89.597% (17260/19264)
Loss: 0.308 | Acc: 89.627% (23002/25664)
Loss: 0.309 | Acc: 89.583% (28724/32064)
Loss: 0.306 | Acc: 89.712% (34507/38464)
Loss: 0.307 | Acc: 89.593% (40195/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0870, Accuracy: 7049/10000 (70.49%)

Epoch: 164
Loss: 0.276 | Acc: 89.062% (57/64)
Loss: 0.288 | Acc: 90.145% (5827/6464)
Loss: 0.283 | Acc: 90.368% (11625/12864)
Loss: 0.291 | Acc: 90.049% (17347/19264)
Loss: 0.296 | Acc: 89.892% (23070/25664)
Loss: 0.300 | Acc: 89.770% (28784/32064)
Loss: 0.300 | Acc: 89.770% (34529/38464)
Loss: 0.301 | Acc: 89.762% (40271/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5408, Accuracy: 8317/10000 (83.17%)

Epoch: 165
Loss: 0.324 | Acc: 87.500% (56/64)
Loss: 0.284 | Acc: 90.331% (5839/6464)
Loss: 0.299 | Acc: 89.902% (11565/12864)
Loss: 0.293 | Acc: 90.116% (17360/19264)
Loss: 0.291 | Acc: 90.103% (23124/25664)
Loss: 0.291 | Acc: 90.204% (28923/32064)
Loss: 0.289 | Acc: 90.235% (34708/38464)
Loss: 0.290 | Acc: 90.248% (40489/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2329, Accuracy: 6632/10000 (66.32%)

Epoch: 166
Loss: 1.310 | Acc: 67.188% (43/64)
Loss: 0.286 | Acc: 90.486% (5849/6464)
Loss: 0.279 | Acc: 90.508% (11643/12864)
Loss: 0.282 | Acc: 90.345% (17404/19264)
Loss: 0.282 | Acc: 90.290% (23172/25664)
Loss: 0.283 | Acc: 90.257% (28940/32064)
Loss: 0.285 | Acc: 90.225% (34704/38464)
Loss: 0.284 | Acc: 90.308% (40516/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7170, Accuracy: 7801/10000 (78.01%)

Epoch: 167
Loss: 0.293 | Acc: 87.500% (56/64)
Loss: 0.278 | Acc: 90.517% (5851/6464)
Loss: 0.274 | Acc: 90.633% (11659/12864)
Loss: 0.269 | Acc: 90.765% (17485/19264)
Loss: 0.273 | Acc: 90.641% (23262/25664)
Loss: 0.277 | Acc: 90.503% (29019/32064)
Loss: 0.278 | Acc: 90.487% (34805/38464)
Loss: 0.279 | Acc: 90.456% (40582/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0530, Accuracy: 7269/10000 (72.69%)

Epoch: 168
Loss: 0.321 | Acc: 87.500% (56/64)
Loss: 0.262 | Acc: 90.934% (5878/6464)
Loss: 0.259 | Acc: 91.146% (11725/12864)
Loss: 0.266 | Acc: 90.921% (17515/19264)
Loss: 0.265 | Acc: 90.820% (23308/25664)
Loss: 0.269 | Acc: 90.690% (29079/32064)
Loss: 0.269 | Acc: 90.612% (34853/38464)
Loss: 0.269 | Acc: 90.692% (40688/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8281, Accuracy: 7754/10000 (77.54%)

Epoch: 169
Loss: 0.236 | Acc: 90.625% (58/64)
Loss: 0.246 | Acc: 91.600% (5921/6464)
Loss: 0.254 | Acc: 91.371% (11754/12864)
Loss: 0.258 | Acc: 91.253% (17579/19264)
Loss: 0.259 | Acc: 91.260% (23421/25664)
Loss: 0.261 | Acc: 91.218% (29248/32064)
Loss: 0.263 | Acc: 91.145% (35058/38464)
Loss: 0.264 | Acc: 91.089% (40866/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5829, Accuracy: 8224/10000 (82.24%)

Epoch: 170
Loss: 0.209 | Acc: 92.188% (59/64)
Loss: 0.250 | Acc: 91.337% (5904/6464)
Loss: 0.251 | Acc: 91.332% (11749/12864)
Loss: 0.252 | Acc: 91.326% (17593/19264)
Loss: 0.249 | Acc: 91.404% (23458/25664)
Loss: 0.253 | Acc: 91.289% (29271/32064)
Loss: 0.253 | Acc: 91.311% (35122/38464)
Loss: 0.257 | Acc: 91.216% (40923/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1866, Accuracy: 7010/10000 (70.10%)

Epoch: 171
Loss: 0.485 | Acc: 82.812% (53/64)
Loss: 0.249 | Acc: 91.259% (5899/6464)
Loss: 0.243 | Acc: 91.597% (11783/12864)
Loss: 0.248 | Acc: 91.487% (17624/19264)
Loss: 0.246 | Acc: 91.564% (23499/25664)
Loss: 0.245 | Acc: 91.635% (29382/32064)
Loss: 0.244 | Acc: 91.740% (35287/38464)
Loss: 0.245 | Acc: 91.697% (41139/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4692, Accuracy: 8533/10000 (85.33%)

Epoch: 172
Loss: 0.208 | Acc: 95.312% (61/64)
Loss: 0.243 | Acc: 91.816% (5935/6464)
Loss: 0.235 | Acc: 91.915% (11824/12864)
Loss: 0.233 | Acc: 92.042% (17731/19264)
Loss: 0.236 | Acc: 91.926% (23592/25664)
Loss: 0.238 | Acc: 91.885% (29462/32064)
Loss: 0.237 | Acc: 91.889% (35344/38464)
Loss: 0.236 | Acc: 91.889% (41225/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5681, Accuracy: 6330/10000 (63.30%)

Epoch: 173
Loss: 0.303 | Acc: 93.750% (60/64)
Loss: 0.247 | Acc: 91.538% (5917/6464)
Loss: 0.230 | Acc: 92.141% (11853/12864)
Loss: 0.230 | Acc: 92.193% (17760/19264)
Loss: 0.229 | Acc: 92.230% (23670/25664)
Loss: 0.226 | Acc: 92.318% (29601/32064)
Loss: 0.229 | Acc: 92.265% (35489/38464)
Loss: 0.230 | Acc: 92.241% (41383/44864)
torch.Size([100, 10])
Test set: Average loss: 3.0142, Accuracy: 4672/10000 (46.72%)

Epoch: 174
Loss: 0.411 | Acc: 85.938% (55/64)
Loss: 0.229 | Acc: 92.450% (5976/6464)
Loss: 0.222 | Acc: 92.522% (11902/12864)
Loss: 0.221 | Acc: 92.603% (17839/19264)
Loss: 0.223 | Acc: 92.460% (23729/25664)
Loss: 0.222 | Acc: 92.421% (29634/32064)
Loss: 0.220 | Acc: 92.471% (35568/38464)
Loss: 0.221 | Acc: 92.390% (41450/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3410, Accuracy: 8853/10000 (88.53%)

Epoch: 175
Loss: 0.148 | Acc: 95.312% (61/64)
Loss: 0.195 | Acc: 93.317% (6032/6464)
Loss: 0.198 | Acc: 93.291% (12001/12864)
Loss: 0.198 | Acc: 93.304% (17974/19264)
Loss: 0.202 | Acc: 93.162% (23909/25664)
Loss: 0.205 | Acc: 93.008% (29822/32064)
Loss: 0.207 | Acc: 92.949% (35752/38464)
Loss: 0.207 | Acc: 92.954% (41703/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8020, Accuracy: 7905/10000 (79.05%)

Epoch: 176
Loss: 0.278 | Acc: 93.750% (60/64)
Loss: 0.178 | Acc: 93.998% (6076/6464)
Loss: 0.186 | Acc: 93.820% (12069/12864)
Loss: 0.190 | Acc: 93.589% (18029/19264)
Loss: 0.191 | Acc: 93.536% (24005/25664)
Loss: 0.190 | Acc: 93.519% (29986/32064)
Loss: 0.190 | Acc: 93.482% (35957/38464)
Loss: 0.194 | Acc: 93.367% (41888/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7474, Accuracy: 7929/10000 (79.29%)

Epoch: 177
Loss: 0.283 | Acc: 89.062% (57/64)
Loss: 0.191 | Acc: 93.472% (6042/6464)
Loss: 0.189 | Acc: 93.470% (12024/12864)
Loss: 0.185 | Acc: 93.620% (18035/19264)
Loss: 0.188 | Acc: 93.508% (23998/25664)
Loss: 0.191 | Acc: 93.460% (29967/32064)
Loss: 0.196 | Acc: 93.347% (35905/38464)
Loss: 0.192 | Acc: 93.487% (41942/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4418, Accuracy: 6801/10000 (68.01%)

Epoch: 178
Loss: 0.258 | Acc: 92.188% (59/64)
Loss: 0.164 | Acc: 94.369% (6100/6464)
Loss: 0.163 | Acc: 94.395% (12143/12864)
Loss: 0.169 | Acc: 94.176% (18142/19264)
Loss: 0.174 | Acc: 93.972% (24117/25664)
Loss: 0.174 | Acc: 94.012% (30144/32064)
Loss: 0.175 | Acc: 93.935% (36131/38464)
Loss: 0.175 | Acc: 93.984% (42165/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6676, Accuracy: 8145/10000 (81.45%)

Epoch: 179
Loss: 0.228 | Acc: 89.062% (57/64)
Loss: 0.162 | Acc: 94.864% (6132/6464)
Loss: 0.163 | Acc: 94.660% (12177/12864)
Loss: 0.158 | Acc: 94.778% (18258/19264)
Loss: 0.163 | Acc: 94.627% (24285/25664)
Loss: 0.161 | Acc: 94.664% (30353/32064)
Loss: 0.159 | Acc: 94.699% (36425/38464)
Loss: 0.160 | Acc: 94.657% (42467/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4259, Accuracy: 8660/10000 (86.60%)

Epoch: 180
Loss: 0.179 | Acc: 93.750% (60/64)
Loss: 0.158 | Acc: 94.291% (6095/6464)
Loss: 0.151 | Acc: 94.714% (12184/12864)
Loss: 0.147 | Acc: 94.897% (18281/19264)
Loss: 0.148 | Acc: 94.919% (24360/25664)
Loss: 0.148 | Acc: 94.957% (30447/32064)
Loss: 0.151 | Acc: 94.839% (36479/38464)
Loss: 0.150 | Acc: 94.871% (42563/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6023, Accuracy: 8380/10000 (83.80%)

Epoch: 181
Loss: 0.140 | Acc: 93.750% (60/64)
Loss: 0.145 | Acc: 95.142% (6150/6464)
Loss: 0.145 | Acc: 95.048% (12227/12864)
Loss: 0.141 | Acc: 95.198% (18339/19264)
Loss: 0.144 | Acc: 95.153% (24420/25664)
Loss: 0.143 | Acc: 95.203% (30526/32064)
Loss: 0.142 | Acc: 95.206% (36620/38464)
Loss: 0.140 | Acc: 95.281% (42747/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3238, Accuracy: 8955/10000 (89.55%)

Epoch: 182
Loss: 0.055 | Acc: 98.438% (63/64)
Loss: 0.104 | Acc: 96.442% (6234/6464)
Loss: 0.112 | Acc: 96.137% (12367/12864)
Loss: 0.116 | Acc: 96.029% (18499/19264)
Loss: 0.116 | Acc: 96.002% (24638/25664)
Loss: 0.119 | Acc: 95.952% (30766/32064)
Loss: 0.123 | Acc: 95.806% (36851/38464)
Loss: 0.123 | Acc: 95.825% (42991/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2414, Accuracy: 9243/10000 (92.43%)

Epoch: 183
Loss: 0.084 | Acc: 96.875% (62/64)
Loss: 0.107 | Acc: 96.643% (6247/6464)
Loss: 0.110 | Acc: 96.362% (12396/12864)
Loss: 0.110 | Acc: 96.273% (18546/19264)
Loss: 0.108 | Acc: 96.337% (24724/25664)
Loss: 0.110 | Acc: 96.273% (30869/32064)
Loss: 0.112 | Acc: 96.204% (37004/38464)
Loss: 0.111 | Acc: 96.220% (43168/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4919, Accuracy: 8575/10000 (85.75%)

Epoch: 184
Loss: 0.281 | Acc: 90.625% (58/64)
Loss: 0.098 | Acc: 96.627% (6246/6464)
Loss: 0.097 | Acc: 96.564% (12422/12864)
Loss: 0.100 | Acc: 96.434% (18577/19264)
Loss: 0.100 | Acc: 96.435% (24749/25664)
Loss: 0.099 | Acc: 96.445% (30924/32064)
Loss: 0.099 | Acc: 96.469% (37106/38464)
Loss: 0.100 | Acc: 96.496% (43292/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2723, Accuracy: 9153/10000 (91.53%)

Epoch: 185
Loss: 0.110 | Acc: 95.312% (61/64)
Loss: 0.080 | Acc: 97.231% (6285/6464)
Loss: 0.082 | Acc: 97.100% (12491/12864)
Loss: 0.086 | Acc: 97.020% (18690/19264)
Loss: 0.087 | Acc: 96.972% (24887/25664)
Loss: 0.088 | Acc: 96.956% (31088/32064)
Loss: 0.087 | Acc: 97.010% (37314/38464)
Loss: 0.086 | Acc: 97.069% (43549/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5650, Accuracy: 8496/10000 (84.96%)

Epoch: 186
Loss: 0.029 | Acc: 100.000% (64/64)
Loss: 0.074 | Acc: 97.432% (6298/6464)
Loss: 0.070 | Acc: 97.715% (12570/12864)
Loss: 0.072 | Acc: 97.612% (18804/19264)
Loss: 0.072 | Acc: 97.654% (25062/25664)
Loss: 0.072 | Acc: 97.599% (31294/32064)
Loss: 0.071 | Acc: 97.600% (37541/38464)
Loss: 0.070 | Acc: 97.669% (43818/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3355, Accuracy: 9017/10000 (90.17%)

Epoch: 187
Loss: 0.063 | Acc: 98.438% (63/64)
Loss: 0.072 | Acc: 97.819% (6323/6464)
Loss: 0.067 | Acc: 97.878% (12591/12864)
Loss: 0.066 | Acc: 97.924% (18864/19264)
Loss: 0.062 | Acc: 98.013% (25154/25664)
Loss: 0.062 | Acc: 97.976% (31415/32064)
Loss: 0.062 | Acc: 97.977% (37686/38464)
Loss: 0.061 | Acc: 98.012% (43972/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2255, Accuracy: 9295/10000 (92.95%)

Epoch: 188
Loss: 0.083 | Acc: 98.438% (63/64)
Loss: 0.051 | Acc: 98.221% (6349/6464)
Loss: 0.051 | Acc: 98.274% (12642/12864)
Loss: 0.048 | Acc: 98.448% (18965/19264)
Loss: 0.047 | Acc: 98.469% (25271/25664)
Loss: 0.046 | Acc: 98.500% (31583/32064)
Loss: 0.045 | Acc: 98.534% (37900/38464)
Loss: 0.046 | Acc: 98.495% (44189/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2218, Accuracy: 9343/10000 (93.43%)

Epoch: 189
Loss: 0.037 | Acc: 98.438% (63/64)
Loss: 0.035 | Acc: 98.948% (6396/6464)
Loss: 0.036 | Acc: 99.005% (12736/12864)
Loss: 0.036 | Acc: 98.925% (19057/19264)
Loss: 0.035 | Acc: 98.944% (25393/25664)
Loss: 0.035 | Acc: 98.940% (31724/32064)
Loss: 0.035 | Acc: 98.960% (38064/38464)
Loss: 0.035 | Acc: 98.932% (44385/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2270, Accuracy: 9343/10000 (93.43%)

Epoch: 190
Loss: 0.035 | Acc: 98.438% (63/64)
Loss: 0.032 | Acc: 98.902% (6393/6464)
Loss: 0.030 | Acc: 99.083% (12746/12864)
Loss: 0.030 | Acc: 99.102% (19091/19264)
Loss: 0.029 | Acc: 99.108% (25435/25664)
Loss: 0.028 | Acc: 99.136% (31787/32064)
Loss: 0.028 | Acc: 99.142% (38134/38464)
Loss: 0.028 | Acc: 99.135% (44476/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2204, Accuracy: 9377/10000 (93.77%)

Epoch: 191
Loss: 0.012 | Acc: 100.000% (64/64)
Loss: 0.022 | Acc: 99.288% (6418/6464)
Loss: 0.023 | Acc: 99.254% (12768/12864)
Loss: 0.022 | Acc: 99.346% (19138/19264)
Loss: 0.022 | Acc: 99.334% (25493/25664)
Loss: 0.022 | Acc: 99.323% (31847/32064)
Loss: 0.022 | Acc: 99.342% (38211/38464)
Loss: 0.022 | Acc: 99.329% (44563/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2084, Accuracy: 9419/10000 (94.19%)

Epoch: 192
Loss: 0.020 | Acc: 100.000% (64/64)
Loss: 0.017 | Acc: 99.551% (6435/6464)
Loss: 0.017 | Acc: 99.487% (12798/12864)
Loss: 0.016 | Acc: 99.554% (19178/19264)
Loss: 0.015 | Acc: 99.610% (25564/25664)
Loss: 0.014 | Acc: 99.632% (31946/32064)
Loss: 0.014 | Acc: 99.644% (38327/38464)
Loss: 0.015 | Acc: 99.630% (44698/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2160, Accuracy: 9438/10000 (94.38%)

Epoch: 193
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.752% (6448/6464)
Loss: 0.012 | Acc: 99.712% (12827/12864)
Loss: 0.012 | Acc: 99.714% (19209/19264)
Loss: 0.012 | Acc: 99.677% (25581/25664)
Loss: 0.013 | Acc: 99.638% (31948/32064)
Loss: 0.013 | Acc: 99.659% (38333/38464)
Loss: 0.012 | Acc: 99.672% (44717/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1995, Accuracy: 9465/10000 (94.65%)

Epoch: 194
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.799% (6451/6464)
Loss: 0.009 | Acc: 99.743% (12831/12864)
Loss: 0.009 | Acc: 99.756% (19217/19264)
Loss: 0.009 | Acc: 99.758% (25602/25664)
Loss: 0.009 | Acc: 99.766% (31989/32064)
Loss: 0.009 | Acc: 99.769% (38375/38464)
Loss: 0.009 | Acc: 99.757% (44755/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2013, Accuracy: 9470/10000 (94.70%)

Epoch: 195
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.783% (6450/6464)
Loss: 0.009 | Acc: 99.821% (12841/12864)
Loss: 0.008 | Acc: 99.808% (19227/19264)
Loss: 0.008 | Acc: 99.817% (25617/25664)
Loss: 0.008 | Acc: 99.813% (32004/32064)
Loss: 0.008 | Acc: 99.818% (38394/38464)
Loss: 0.008 | Acc: 99.824% (44785/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1962, Accuracy: 9476/10000 (94.76%)

Epoch: 196
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.006 | Acc: 99.892% (6457/6464)
Loss: 0.007 | Acc: 99.883% (12849/12864)
Loss: 0.007 | Acc: 99.875% (19240/19264)
Loss: 0.007 | Acc: 99.875% (25632/25664)
Loss: 0.007 | Acc: 99.881% (32026/32064)
Loss: 0.007 | Acc: 99.867% (38413/38464)
Loss: 0.007 | Acc: 99.857% (44800/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1957, Accuracy: 9475/10000 (94.75%)

Epoch: 197
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.845% (6454/6464)
Loss: 0.007 | Acc: 99.829% (12842/12864)
Loss: 0.007 | Acc: 99.839% (19233/19264)
Loss: 0.007 | Acc: 99.848% (25625/25664)
Loss: 0.007 | Acc: 99.857% (32018/32064)
Loss: 0.007 | Acc: 99.857% (38409/38464)
Loss: 0.007 | Acc: 99.860% (44801/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1943, Accuracy: 9469/10000 (94.69%)
torch.Size([100, 10])
Test set: Average loss: 0.1943, Accuracy: 9469/10000 (94.69%)

Epoch: 198
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.783% (6450/6464)
Loss: 0.007 | Acc: 99.821% (12841/12864)
Loss: 0.007 | Acc: 99.829% (19231/19264)
Loss: 0.007 | Acc: 99.840% (25623/25664)
Loss: 0.007 | Acc: 99.841% (32013/32064)
Loss: 0.007 | Acc: 99.839% (38402/38464)
Loss: 0.007 | Acc: 99.842% (44793/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1940, Accuracy: 9485/10000 (94.85%)
torch.Size([100, 10])
Test set: Average loss: 0.1940, Accuracy: 9485/10000 (94.85%)

Epoch: 199
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.830% (6453/6464)
Loss: 0.007 | Acc: 99.821% (12841/12864)
Loss: 0.007 | Acc: 99.855% (19236/19264)
Loss: 0.007 | Acc: 99.871% (25631/25664)
Loss: 0.007 | Acc: 99.857% (32018/32064)
Loss: 0.007 | Acc: 99.841% (38403/38464)
Loss: 0.007 | Acc: 99.840% (44792/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1946, Accuracy: 9480/10000 (94.80%)
torch.Size([100, 10])
Test set: Average loss: 0.1946, Accuracy: 9480/10000 (94.80%)
9556
10000
-0.14288955926895142
