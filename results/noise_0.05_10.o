==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.355 | Acc: 15.625% (10/64)
Loss: 2.884 | Acc: 16.569% (1071/6464)
Loss: 2.481 | Acc: 19.426% (2499/12864)
Loss: 2.319 | Acc: 21.205% (4085/19264)
Loss: 2.221 | Acc: 23.028% (5910/25664)
Loss: 2.151 | Acc: 24.554% (7873/32064)
Loss: 2.094 | Acc: 26.045% (10018/38464)
Loss: 2.045 | Acc: 27.516% (12345/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1990, Accuracy: 3142/10000 (31.42%)

Epoch: 1
Loss: 1.966 | Acc: 32.812% (21/64)
Loss: 1.670 | Acc: 39.434% (2549/6464)
Loss: 1.652 | Acc: 40.174% (5168/12864)
Loss: 1.635 | Acc: 40.724% (7845/19264)
Loss: 1.624 | Acc: 41.221% (10579/25664)
Loss: 1.606 | Acc: 42.072% (13490/32064)
Loss: 1.591 | Acc: 42.666% (16411/38464)
Loss: 1.577 | Acc: 43.405% (19473/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7060, Accuracy: 4251/10000 (42.51%)

Epoch: 2
Loss: 1.287 | Acc: 56.250% (36/64)
Loss: 1.413 | Acc: 50.480% (3263/6464)
Loss: 1.420 | Acc: 50.272% (6467/12864)
Loss: 1.405 | Acc: 51.126% (9849/19264)
Loss: 1.386 | Acc: 51.952% (13333/25664)
Loss: 1.373 | Acc: 52.648% (16881/32064)
Loss: 1.364 | Acc: 53.146% (20442/38464)
Loss: 1.355 | Acc: 53.611% (24052/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4025, Accuracy: 5300/10000 (53.00%)

Epoch: 3
Loss: 1.111 | Acc: 65.625% (42/64)
Loss: 1.253 | Acc: 58.308% (3769/6464)
Loss: 1.249 | Acc: 58.434% (7517/12864)
Loss: 1.228 | Acc: 59.375% (11438/19264)
Loss: 1.209 | Acc: 59.885% (15369/25664)
Loss: 1.199 | Acc: 60.177% (19295/32064)
Loss: 1.188 | Acc: 60.649% (23328/38464)
Loss: 1.179 | Acc: 61.165% (27441/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8454, Accuracy: 4260/10000 (42.60%)

Epoch: 4
Loss: 1.409 | Acc: 54.688% (35/64)
Loss: 1.076 | Acc: 65.594% (4240/6464)
Loss: 1.065 | Acc: 65.765% (8460/12864)
Loss: 1.054 | Acc: 66.300% (12772/19264)
Loss: 1.047 | Acc: 66.603% (17093/25664)
Loss: 1.039 | Acc: 66.950% (21467/32064)
Loss: 1.028 | Acc: 67.294% (25884/38464)
Loss: 1.020 | Acc: 67.584% (30321/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5032, Accuracy: 5272/10000 (52.72%)

Epoch: 5
Loss: 1.444 | Acc: 54.688% (35/64)
Loss: 0.930 | Acc: 70.869% (4581/6464)
Loss: 0.938 | Acc: 70.880% (9118/12864)
Loss: 0.935 | Acc: 71.107% (13698/19264)
Loss: 0.934 | Acc: 71.178% (18267/25664)
Loss: 0.927 | Acc: 71.304% (22863/32064)
Loss: 0.924 | Acc: 71.482% (27495/38464)
Loss: 0.922 | Acc: 71.668% (32153/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1468, Accuracy: 6405/10000 (64.05%)

Epoch: 6
Loss: 1.012 | Acc: 75.000% (48/64)
Loss: 0.874 | Acc: 74.087% (4789/6464)
Loss: 0.873 | Acc: 73.795% (9493/12864)
Loss: 0.865 | Acc: 73.972% (14250/19264)
Loss: 0.863 | Acc: 74.018% (18996/25664)
Loss: 0.857 | Acc: 74.127% (23768/32064)
Loss: 0.856 | Acc: 74.202% (28541/38464)
Loss: 0.855 | Acc: 74.206% (33292/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6175, Accuracy: 5102/10000 (51.02%)

Epoch: 7
Loss: 1.066 | Acc: 65.625% (42/64)
Loss: 0.819 | Acc: 75.217% (4862/6464)
Loss: 0.823 | Acc: 75.396% (9699/12864)
Loss: 0.827 | Acc: 75.395% (14524/19264)
Loss: 0.826 | Acc: 75.460% (19366/25664)
Loss: 0.819 | Acc: 75.758% (24291/32064)
Loss: 0.821 | Acc: 75.676% (29108/38464)
Loss: 0.816 | Acc: 75.727% (33974/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2456, Accuracy: 6198/10000 (61.98%)

Epoch: 8
Loss: 1.125 | Acc: 68.750% (44/64)
Loss: 0.809 | Acc: 76.145% (4922/6464)
Loss: 0.795 | Acc: 76.298% (9815/12864)
Loss: 0.785 | Acc: 76.609% (14758/19264)
Loss: 0.784 | Acc: 76.777% (19704/25664)
Loss: 0.783 | Acc: 76.765% (24614/32064)
Loss: 0.785 | Acc: 76.703% (29503/38464)
Loss: 0.781 | Acc: 76.863% (34484/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1401, Accuracy: 6415/10000 (64.15%)

Epoch: 9
Loss: 0.893 | Acc: 71.875% (46/64)
Loss: 0.758 | Acc: 78.264% (5059/6464)
Loss: 0.761 | Acc: 78.109% (10048/12864)
Loss: 0.769 | Acc: 77.788% (14985/19264)
Loss: 0.763 | Acc: 77.907% (19994/25664)
Loss: 0.765 | Acc: 77.932% (24988/32064)
Loss: 0.762 | Acc: 77.972% (29991/38464)
Loss: 0.757 | Acc: 78.098% (35038/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2096, Accuracy: 6293/10000 (62.93%)

Epoch: 10
Loss: 0.785 | Acc: 78.125% (50/64)
Loss: 0.748 | Acc: 78.017% (5043/6464)
Loss: 0.725 | Acc: 79.143% (10181/12864)
Loss: 0.733 | Acc: 78.753% (15171/19264)
Loss: 0.730 | Acc: 78.772% (20216/25664)
Loss: 0.735 | Acc: 78.624% (25210/32064)
Loss: 0.735 | Acc: 78.687% (30266/38464)
Loss: 0.737 | Acc: 78.618% (35271/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8582, Accuracy: 7459/10000 (74.59%)

Epoch: 11
Loss: 1.005 | Acc: 70.312% (45/64)
Loss: 0.707 | Acc: 79.192% (5119/6464)
Loss: 0.723 | Acc: 78.832% (10141/12864)
Loss: 0.714 | Acc: 79.174% (15252/19264)
Loss: 0.719 | Acc: 79.095% (20299/25664)
Loss: 0.717 | Acc: 79.167% (25384/32064)
Loss: 0.717 | Acc: 79.181% (30456/38464)
Loss: 0.719 | Acc: 79.179% (35523/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0303, Accuracy: 7006/10000 (70.06%)

Epoch: 12
Loss: 0.682 | Acc: 82.812% (53/64)
Loss: 0.689 | Acc: 80.384% (5196/6464)
Loss: 0.692 | Acc: 80.418% (10345/12864)
Loss: 0.692 | Acc: 80.295% (15468/19264)
Loss: 0.696 | Acc: 80.163% (20573/25664)
Loss: 0.700 | Acc: 80.102% (25684/32064)
Loss: 0.699 | Acc: 80.077% (30801/38464)
Loss: 0.703 | Acc: 80.000% (35891/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6746, Accuracy: 4955/10000 (49.55%)

Epoch: 13
Loss: 0.738 | Acc: 76.562% (49/64)
Loss: 0.688 | Acc: 80.554% (5207/6464)
Loss: 0.689 | Acc: 80.410% (10344/12864)
Loss: 0.689 | Acc: 80.336% (15476/19264)
Loss: 0.692 | Acc: 80.214% (20586/25664)
Loss: 0.685 | Acc: 80.520% (25818/32064)
Loss: 0.686 | Acc: 80.499% (30963/38464)
Loss: 0.685 | Acc: 80.592% (36157/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8543, Accuracy: 4987/10000 (49.87%)

Epoch: 14
Loss: 0.878 | Acc: 68.750% (44/64)
Loss: 0.700 | Acc: 79.796% (5158/6464)
Loss: 0.692 | Acc: 80.037% (10296/12864)
Loss: 0.679 | Acc: 80.492% (15506/19264)
Loss: 0.674 | Acc: 80.728% (20718/25664)
Loss: 0.670 | Acc: 81.010% (25975/32064)
Loss: 0.667 | Acc: 81.073% (31184/38464)
Loss: 0.670 | Acc: 81.023% (36350/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3629, Accuracy: 6073/10000 (60.73%)

Epoch: 15
Loss: 0.980 | Acc: 73.438% (47/64)
Loss: 0.658 | Acc: 81.853% (5291/6464)
Loss: 0.650 | Acc: 81.965% (10544/12864)
Loss: 0.662 | Acc: 81.567% (15713/19264)
Loss: 0.657 | Acc: 81.694% (20966/25664)
Loss: 0.658 | Acc: 81.755% (26214/32064)
Loss: 0.658 | Acc: 81.637% (31401/38464)
Loss: 0.656 | Acc: 81.656% (36634/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7777, Accuracy: 7749/10000 (77.49%)

Epoch: 16
Loss: 0.777 | Acc: 79.688% (51/64)
Loss: 0.615 | Acc: 83.106% (5372/6464)
Loss: 0.614 | Acc: 82.774% (10648/12864)
Loss: 0.627 | Acc: 82.537% (15900/19264)
Loss: 0.631 | Acc: 82.407% (21149/25664)
Loss: 0.632 | Acc: 82.370% (26411/32064)
Loss: 0.637 | Acc: 82.199% (31617/38464)
Loss: 0.638 | Acc: 82.188% (36873/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3614, Accuracy: 6127/10000 (61.27%)

Epoch: 17
Loss: 0.637 | Acc: 81.250% (52/64)
Loss: 0.587 | Acc: 83.818% (5418/6464)
Loss: 0.622 | Acc: 82.540% (10618/12864)
Loss: 0.629 | Acc: 82.548% (15902/19264)
Loss: 0.627 | Acc: 82.637% (21208/25664)
Loss: 0.627 | Acc: 82.653% (26502/32064)
Loss: 0.628 | Acc: 82.612% (31776/38464)
Loss: 0.627 | Acc: 82.645% (37078/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9772, Accuracy: 7324/10000 (73.24%)

Epoch: 18
Loss: 0.664 | Acc: 79.688% (51/64)
Loss: 0.600 | Acc: 83.462% (5395/6464)
Loss: 0.599 | Acc: 83.396% (10728/12864)
Loss: 0.603 | Acc: 83.306% (16048/19264)
Loss: 0.605 | Acc: 83.362% (21394/25664)
Loss: 0.610 | Acc: 83.134% (26656/32064)
Loss: 0.612 | Acc: 83.098% (31963/38464)
Loss: 0.612 | Acc: 83.078% (37272/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8095, Accuracy: 7723/10000 (77.23%)

Epoch: 19
Loss: 0.682 | Acc: 85.938% (55/64)
Loss: 0.601 | Acc: 83.679% (5409/6464)
Loss: 0.591 | Acc: 83.862% (10788/12864)
Loss: 0.585 | Acc: 84.027% (16187/19264)
Loss: 0.588 | Acc: 83.907% (21534/25664)
Loss: 0.595 | Acc: 83.648% (26821/32064)
Loss: 0.599 | Acc: 83.585% (32150/38464)
Loss: 0.600 | Acc: 83.510% (37466/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1912, Accuracy: 6576/10000 (65.76%)

Epoch: 20
Loss: 0.544 | Acc: 85.938% (55/64)
Loss: 0.579 | Acc: 84.282% (5448/6464)
Loss: 0.586 | Acc: 84.126% (10822/12864)
Loss: 0.583 | Acc: 84.261% (16232/19264)
Loss: 0.583 | Acc: 84.250% (21622/25664)
Loss: 0.582 | Acc: 84.266% (27019/32064)
Loss: 0.583 | Acc: 84.245% (32404/38464)
Loss: 0.583 | Acc: 84.281% (37812/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0913, Accuracy: 6747/10000 (67.47%)

Epoch: 21
Loss: 0.574 | Acc: 82.812% (53/64)
Loss: 0.584 | Acc: 83.834% (5419/6464)
Loss: 0.581 | Acc: 84.033% (10810/12864)
Loss: 0.577 | Acc: 84.230% (16226/19264)
Loss: 0.579 | Acc: 84.262% (21625/25664)
Loss: 0.577 | Acc: 84.400% (27062/32064)
Loss: 0.575 | Acc: 84.513% (32507/38464)
Loss: 0.573 | Acc: 84.573% (37943/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9794, Accuracy: 7088/10000 (70.88%)

Epoch: 22
Loss: 0.632 | Acc: 82.812% (53/64)
Loss: 0.542 | Acc: 85.319% (5515/6464)
Loss: 0.564 | Acc: 84.740% (10901/12864)
Loss: 0.558 | Acc: 84.925% (16360/19264)
Loss: 0.561 | Acc: 84.835% (21772/25664)
Loss: 0.559 | Acc: 84.886% (27218/32064)
Loss: 0.559 | Acc: 84.957% (32678/38464)
Loss: 0.558 | Acc: 85.008% (38138/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0931, Accuracy: 6885/10000 (68.85%)

Epoch: 23
Loss: 0.603 | Acc: 81.250% (52/64)
Loss: 0.511 | Acc: 86.742% (5607/6464)
Loss: 0.533 | Acc: 85.805% (11038/12864)
Loss: 0.542 | Acc: 85.465% (16464/19264)
Loss: 0.543 | Acc: 85.404% (21918/25664)
Loss: 0.547 | Acc: 85.351% (27367/32064)
Loss: 0.544 | Acc: 85.477% (32878/38464)
Loss: 0.545 | Acc: 85.478% (38349/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2250, Accuracy: 6397/10000 (63.97%)

Epoch: 24
Loss: 0.872 | Acc: 76.562% (49/64)
Loss: 0.523 | Acc: 86.077% (5564/6464)
Loss: 0.531 | Acc: 85.751% (11031/12864)
Loss: 0.537 | Acc: 85.719% (16513/19264)
Loss: 0.539 | Acc: 85.809% (22022/25664)
Loss: 0.536 | Acc: 85.928% (27552/32064)
Loss: 0.537 | Acc: 85.862% (33026/38464)
Loss: 0.538 | Acc: 85.844% (38513/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1671, Accuracy: 6789/10000 (67.89%)

Epoch: 25
Loss: 0.796 | Acc: 78.125% (50/64)
Loss: 0.506 | Acc: 86.897% (5617/6464)
Loss: 0.515 | Acc: 86.552% (11134/12864)
Loss: 0.517 | Acc: 86.550% (16673/19264)
Loss: 0.517 | Acc: 86.549% (22212/25664)
Loss: 0.516 | Acc: 86.639% (27780/32064)
Loss: 0.519 | Acc: 86.528% (33282/38464)
Loss: 0.519 | Acc: 86.481% (38799/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8595, Accuracy: 7614/10000 (76.14%)

Epoch: 26
Loss: 0.416 | Acc: 90.625% (58/64)
Loss: 0.516 | Acc: 86.278% (5577/6464)
Loss: 0.508 | Acc: 86.933% (11183/12864)
Loss: 0.501 | Acc: 87.017% (16763/19264)
Loss: 0.509 | Acc: 86.892% (22300/25664)
Loss: 0.508 | Acc: 86.826% (27840/32064)
Loss: 0.505 | Acc: 86.892% (33422/38464)
Loss: 0.504 | Acc: 86.914% (38993/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8733, Accuracy: 7523/10000 (75.23%)

Epoch: 27
Loss: 0.580 | Acc: 75.000% (48/64)
Loss: 0.508 | Acc: 86.618% (5599/6464)
Loss: 0.491 | Acc: 87.158% (11212/12864)
Loss: 0.492 | Acc: 87.131% (16785/19264)
Loss: 0.494 | Acc: 87.103% (22354/25664)
Loss: 0.492 | Acc: 87.179% (27953/32064)
Loss: 0.493 | Acc: 87.248% (33559/38464)
Loss: 0.493 | Acc: 87.246% (39142/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9026, Accuracy: 7478/10000 (74.78%)

Epoch: 28
Loss: 0.593 | Acc: 84.375% (54/64)
Loss: 0.457 | Acc: 88.366% (5712/6464)
Loss: 0.479 | Acc: 87.803% (11295/12864)
Loss: 0.472 | Acc: 87.957% (16944/19264)
Loss: 0.476 | Acc: 87.870% (22551/25664)
Loss: 0.478 | Acc: 87.837% (28164/32064)
Loss: 0.482 | Acc: 87.729% (33744/38464)
Loss: 0.480 | Acc: 87.796% (39389/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7892, Accuracy: 7815/10000 (78.15%)

Epoch: 29
Loss: 0.334 | Acc: 95.312% (61/64)
Loss: 0.459 | Acc: 88.537% (5723/6464)
Loss: 0.466 | Acc: 88.363% (11367/12864)
Loss: 0.456 | Acc: 88.652% (17078/19264)
Loss: 0.460 | Acc: 88.439% (22697/25664)
Loss: 0.461 | Acc: 88.470% (28367/32064)
Loss: 0.463 | Acc: 88.444% (34019/38464)
Loss: 0.464 | Acc: 88.394% (39657/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6491, Accuracy: 8267/10000 (82.67%)

Epoch: 30
Loss: 0.457 | Acc: 89.062% (57/64)
Loss: 0.432 | Acc: 89.248% (5769/6464)
Loss: 0.434 | Acc: 89.140% (11467/12864)
Loss: 0.434 | Acc: 89.213% (17186/19264)
Loss: 0.436 | Acc: 89.113% (22870/25664)
Loss: 0.446 | Acc: 88.900% (28505/32064)
Loss: 0.448 | Acc: 88.795% (34154/38464)
Loss: 0.449 | Acc: 88.777% (39829/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8176, Accuracy: 7771/10000 (77.71%)

Epoch: 31
Loss: 0.418 | Acc: 87.500% (56/64)
Loss: 0.421 | Acc: 89.774% (5803/6464)
Loss: 0.425 | Acc: 89.622% (11529/12864)
Loss: 0.426 | Acc: 89.587% (17258/19264)
Loss: 0.428 | Acc: 89.444% (22955/25664)
Loss: 0.430 | Acc: 89.337% (28645/32064)
Loss: 0.428 | Acc: 89.369% (34375/38464)
Loss: 0.430 | Acc: 89.314% (40070/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6487, Accuracy: 8327/10000 (83.27%)

Epoch: 32
Loss: 0.618 | Acc: 82.812% (53/64)
Loss: 0.401 | Acc: 90.254% (5834/6464)
Loss: 0.407 | Acc: 90.096% (11590/12864)
Loss: 0.410 | Acc: 89.940% (17326/19264)
Loss: 0.407 | Acc: 89.928% (23079/25664)
Loss: 0.408 | Acc: 89.911% (28829/32064)
Loss: 0.412 | Acc: 89.775% (34531/38464)
Loss: 0.411 | Acc: 89.838% (40305/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6795, Accuracy: 8236/10000 (82.36%)

Epoch: 33
Loss: 0.308 | Acc: 93.750% (60/64)
Loss: 0.366 | Acc: 90.903% (5876/6464)
Loss: 0.394 | Acc: 90.438% (11634/12864)
Loss: 0.399 | Acc: 90.329% (17401/19264)
Loss: 0.402 | Acc: 90.216% (23153/25664)
Loss: 0.394 | Acc: 90.382% (28980/32064)
Loss: 0.397 | Acc: 90.253% (34715/38464)
Loss: 0.396 | Acc: 90.262% (40495/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6953, Accuracy: 8215/10000 (82.15%)

Epoch: 34
Loss: 0.583 | Acc: 87.500% (56/64)
Loss: 0.380 | Acc: 90.795% (5869/6464)
Loss: 0.374 | Acc: 90.983% (11704/12864)
Loss: 0.371 | Acc: 91.087% (17547/19264)
Loss: 0.373 | Acc: 90.972% (23347/25664)
Loss: 0.378 | Acc: 90.859% (29133/32064)
Loss: 0.379 | Acc: 90.851% (34945/38464)
Loss: 0.381 | Acc: 90.810% (40741/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5741, Accuracy: 8566/10000 (85.66%)

Epoch: 35
Loss: 0.244 | Acc: 95.312% (61/64)
Loss: 0.331 | Acc: 91.460% (5912/6464)
Loss: 0.351 | Acc: 91.332% (11749/12864)
Loss: 0.352 | Acc: 91.445% (17616/19264)
Loss: 0.351 | Acc: 91.478% (23477/25664)
Loss: 0.352 | Acc: 91.483% (29333/32064)
Loss: 0.358 | Acc: 91.296% (35116/38464)
Loss: 0.360 | Acc: 91.276% (40950/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5664, Accuracy: 8610/10000 (86.10%)

Epoch: 36
Loss: 0.244 | Acc: 96.875% (62/64)
Loss: 0.339 | Acc: 91.940% (5943/6464)
Loss: 0.335 | Acc: 92.094% (11847/12864)
Loss: 0.335 | Acc: 92.016% (17726/19264)
Loss: 0.336 | Acc: 92.028% (23618/25664)
Loss: 0.338 | Acc: 91.972% (29490/32064)
Loss: 0.339 | Acc: 91.964% (35373/38464)
Loss: 0.340 | Acc: 91.953% (41254/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6955, Accuracy: 8178/10000 (81.78%)

Epoch: 37
Loss: 0.315 | Acc: 92.188% (59/64)
Loss: 0.303 | Acc: 93.023% (6013/6464)
Loss: 0.302 | Acc: 93.035% (11968/12864)
Loss: 0.309 | Acc: 92.743% (17866/19264)
Loss: 0.303 | Acc: 92.780% (23811/25664)
Loss: 0.313 | Acc: 92.534% (29670/32064)
Loss: 0.318 | Acc: 92.427% (35551/38464)
Loss: 0.321 | Acc: 92.384% (41447/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5647, Accuracy: 8644/10000 (86.44%)

Epoch: 38
Loss: 0.585 | Acc: 85.938% (55/64)
Loss: 0.282 | Acc: 93.348% (6034/6464)
Loss: 0.288 | Acc: 93.284% (12000/12864)
Loss: 0.286 | Acc: 93.402% (17993/19264)
Loss: 0.287 | Acc: 93.364% (23961/25664)
Loss: 0.290 | Acc: 93.295% (29914/32064)
Loss: 0.292 | Acc: 93.207% (35851/38464)
Loss: 0.292 | Acc: 93.231% (41827/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5846, Accuracy: 8640/10000 (86.40%)

Epoch: 39
Loss: 0.194 | Acc: 95.312% (61/64)
Loss: 0.260 | Acc: 93.905% (6070/6464)
Loss: 0.257 | Acc: 94.014% (12094/12864)
Loss: 0.256 | Acc: 94.025% (18113/19264)
Loss: 0.257 | Acc: 93.964% (24115/25664)
Loss: 0.259 | Acc: 93.909% (30111/32064)
Loss: 0.261 | Acc: 93.875% (36108/38464)
Loss: 0.264 | Acc: 93.759% (42064/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6133, Accuracy: 8551/10000 (85.51%)

Epoch: 40
Loss: 0.150 | Acc: 96.875% (62/64)
Loss: 0.240 | Acc: 94.183% (6088/6464)
Loss: 0.236 | Acc: 94.341% (12136/12864)
Loss: 0.241 | Acc: 94.352% (18176/19264)
Loss: 0.245 | Acc: 94.241% (24186/25664)
Loss: 0.241 | Acc: 94.311% (30240/32064)
Loss: 0.242 | Acc: 94.252% (36253/38464)
Loss: 0.244 | Acc: 94.220% (42271/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6330, Accuracy: 8542/10000 (85.42%)

Epoch: 41
Loss: 0.331 | Acc: 90.625% (58/64)
Loss: 0.223 | Acc: 94.570% (6113/6464)
Loss: 0.221 | Acc: 94.823% (12198/12864)
Loss: 0.220 | Acc: 94.783% (18259/19264)
Loss: 0.223 | Acc: 94.736% (24313/25664)
Loss: 0.221 | Acc: 94.826% (30405/32064)
Loss: 0.221 | Acc: 94.795% (36462/38464)
Loss: 0.220 | Acc: 94.813% (42537/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6186, Accuracy: 8626/10000 (86.26%)

Epoch: 42
Loss: 0.125 | Acc: 96.875% (62/64)
Loss: 0.192 | Acc: 95.405% (6167/6464)
Loss: 0.197 | Acc: 95.204% (12247/12864)
Loss: 0.200 | Acc: 95.167% (18333/19264)
Loss: 0.199 | Acc: 95.223% (24438/25664)
Loss: 0.196 | Acc: 95.266% (30546/32064)
Loss: 0.198 | Acc: 95.209% (36621/38464)
Loss: 0.198 | Acc: 95.221% (42720/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5836, Accuracy: 8770/10000 (87.70%)

Epoch: 43
Loss: 0.195 | Acc: 93.750% (60/64)
Loss: 0.164 | Acc: 95.993% (6205/6464)
Loss: 0.170 | Acc: 95.872% (12333/12864)
Loss: 0.170 | Acc: 95.909% (18476/19264)
Loss: 0.170 | Acc: 95.874% (24605/25664)
Loss: 0.169 | Acc: 95.914% (30754/32064)
Loss: 0.171 | Acc: 95.890% (36883/38464)
Loss: 0.169 | Acc: 95.939% (43042/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6039, Accuracy: 8752/10000 (87.52%)

Epoch: 44
Loss: 0.095 | Acc: 98.438% (63/64)
Loss: 0.135 | Acc: 96.519% (6239/6464)
Loss: 0.148 | Acc: 96.308% (12389/12864)
Loss: 0.145 | Acc: 96.403% (18571/19264)
Loss: 0.148 | Acc: 96.357% (24729/25664)
Loss: 0.150 | Acc: 96.267% (30867/32064)
Loss: 0.150 | Acc: 96.277% (37032/38464)
Loss: 0.147 | Acc: 96.356% (43229/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5943, Accuracy: 8795/10000 (87.95%)

Epoch: 45
Loss: 0.088 | Acc: 98.438% (63/64)
Loss: 0.121 | Acc: 96.813% (6258/6464)
Loss: 0.131 | Acc: 96.688% (12438/12864)
Loss: 0.128 | Acc: 96.776% (18643/19264)
Loss: 0.136 | Acc: 96.563% (24782/25664)
Loss: 0.137 | Acc: 96.588% (30970/32064)
Loss: 0.139 | Acc: 96.542% (37134/38464)
Loss: 0.142 | Acc: 96.514% (43300/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5648, Accuracy: 8821/10000 (88.21%)

Epoch: 46
Loss: 0.108 | Acc: 98.438% (63/64)
Loss: 0.143 | Acc: 96.550% (6241/6464)
Loss: 0.148 | Acc: 96.401% (12401/12864)
Loss: 0.147 | Acc: 96.465% (18583/19264)
Loss: 0.148 | Acc: 96.415% (24744/25664)
Loss: 0.150 | Acc: 96.429% (30919/32064)
Loss: 0.151 | Acc: 96.384% (37073/38464)
Loss: 0.151 | Acc: 96.351% (43227/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5597, Accuracy: 8806/10000 (88.06%)

Epoch: 47
Loss: 0.060 | Acc: 98.438% (63/64)
Loss: 0.152 | Acc: 96.334% (6227/6464)
Loss: 0.149 | Acc: 96.362% (12396/12864)
Loss: 0.152 | Acc: 96.356% (18562/19264)
Loss: 0.151 | Acc: 96.431% (24748/25664)
Loss: 0.154 | Acc: 96.304% (30879/32064)
Loss: 0.155 | Acc: 96.311% (37045/38464)
Loss: 0.154 | Acc: 96.340% (43222/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5540, Accuracy: 8829/10000 (88.29%)
torch.Size([100, 10])
Test set: Average loss: 0.5540, Accuracy: 8829/10000 (88.29%)

Epoch: 48
Loss: 0.074 | Acc: 98.438% (63/64)
Loss: 0.150 | Acc: 96.411% (6232/6464)
Loss: 0.150 | Acc: 96.447% (12407/12864)
Loss: 0.152 | Acc: 96.320% (18555/19264)
Loss: 0.153 | Acc: 96.298% (24714/25664)
Loss: 0.154 | Acc: 96.248% (30861/32064)
Loss: 0.156 | Acc: 96.178% (36994/38464)
Loss: 0.155 | Acc: 96.222% (43169/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5536, Accuracy: 8802/10000 (88.02%)
torch.Size([100, 10])
Test set: Average loss: 0.5536, Accuracy: 8802/10000 (88.02%)

Epoch: 49
Loss: 0.162 | Acc: 95.312% (61/64)
Loss: 0.152 | Acc: 96.488% (6237/6464)
Loss: 0.156 | Acc: 96.284% (12386/12864)
Loss: 0.155 | Acc: 96.299% (18551/19264)
Loss: 0.153 | Acc: 96.314% (24718/25664)
Loss: 0.152 | Acc: 96.354% (30895/32064)
Loss: 0.153 | Acc: 96.355% (37062/38464)
Loss: 0.153 | Acc: 96.327% (43216/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5517, Accuracy: 8804/10000 (88.04%)
torch.Size([100, 10])
Test set: Average loss: 0.5517, Accuracy: 8804/10000 (88.04%)

Epoch: 50
Loss: 0.104 | Acc: 96.875% (62/64)
Loss: 1.433 | Acc: 51.903% (3355/6464)
Loss: 1.165 | Acc: 62.197% (8001/12864)
Loss: 1.042 | Acc: 66.824% (12873/19264)
Loss: 0.977 | Acc: 69.537% (17846/25664)
Loss: 0.934 | Acc: 71.164% (22818/32064)
Loss: 0.900 | Acc: 72.457% (27870/38464)
Loss: 0.874 | Acc: 73.397% (32929/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1803, Accuracy: 4862/10000 (48.62%)

Epoch: 51
Loss: 0.976 | Acc: 68.750% (44/64)
Loss: 0.679 | Acc: 80.507% (5204/6464)
Loss: 0.678 | Acc: 80.340% (10335/12864)
Loss: 0.680 | Acc: 80.461% (15500/19264)
Loss: 0.682 | Acc: 80.549% (20672/25664)
Loss: 0.675 | Acc: 80.907% (25942/32064)
Loss: 0.670 | Acc: 81.008% (31159/38464)
Loss: 0.670 | Acc: 81.110% (36389/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8763, Accuracy: 7498/10000 (74.98%)

Epoch: 52
Loss: 0.675 | Acc: 81.250% (52/64)
Loss: 0.639 | Acc: 82.256% (5317/6464)
Loss: 0.627 | Acc: 82.455% (10607/12864)
Loss: 0.627 | Acc: 82.475% (15888/19264)
Loss: 0.631 | Acc: 82.353% (21135/25664)
Loss: 0.633 | Acc: 82.323% (26396/32064)
Loss: 0.633 | Acc: 82.381% (31687/38464)
Loss: 0.635 | Acc: 82.409% (36972/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1565, Accuracy: 6735/10000 (67.35%)

Epoch: 53
Loss: 0.890 | Acc: 71.875% (46/64)
Loss: 0.602 | Acc: 83.308% (5385/6464)
Loss: 0.604 | Acc: 83.388% (10727/12864)
Loss: 0.614 | Acc: 83.072% (16003/19264)
Loss: 0.615 | Acc: 83.019% (21306/25664)
Loss: 0.622 | Acc: 82.862% (26569/32064)
Loss: 0.622 | Acc: 82.815% (31854/38464)
Loss: 0.623 | Acc: 82.828% (37160/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0750, Accuracy: 4572/10000 (45.72%)

Epoch: 54
Loss: 1.078 | Acc: 68.750% (44/64)
Loss: 0.605 | Acc: 83.153% (5375/6464)
Loss: 0.602 | Acc: 83.388% (10727/12864)
Loss: 0.598 | Acc: 83.321% (16051/19264)
Loss: 0.607 | Acc: 83.101% (21327/25664)
Loss: 0.614 | Acc: 82.884% (26576/32064)
Loss: 0.618 | Acc: 82.805% (31850/38464)
Loss: 0.621 | Acc: 82.806% (37150/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2025, Accuracy: 6740/10000 (67.40%)

Epoch: 55
Loss: 0.582 | Acc: 79.688% (51/64)
Loss: 0.611 | Acc: 83.277% (5383/6464)
Loss: 0.608 | Acc: 83.388% (10727/12864)
Loss: 0.606 | Acc: 83.544% (16094/19264)
Loss: 0.612 | Acc: 83.381% (21399/25664)
Loss: 0.605 | Acc: 83.514% (26778/32064)
Loss: 0.608 | Acc: 83.397% (32078/38464)
Loss: 0.611 | Acc: 83.285% (37365/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9851, Accuracy: 5219/10000 (52.19%)

Epoch: 56
Loss: 0.507 | Acc: 84.375% (54/64)
Loss: 0.588 | Acc: 84.545% (5465/6464)
Loss: 0.603 | Acc: 83.901% (10793/12864)
Loss: 0.596 | Acc: 83.991% (16180/19264)
Loss: 0.593 | Acc: 83.880% (21527/25664)
Loss: 0.601 | Acc: 83.754% (26855/32064)
Loss: 0.602 | Acc: 83.686% (32189/38464)
Loss: 0.605 | Acc: 83.521% (37471/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9636, Accuracy: 7402/10000 (74.02%)

Epoch: 57
Loss: 0.730 | Acc: 81.250% (52/64)
Loss: 0.596 | Acc: 83.462% (5395/6464)
Loss: 0.591 | Acc: 83.652% (10761/12864)
Loss: 0.590 | Acc: 83.887% (16160/19264)
Loss: 0.592 | Acc: 83.841% (21517/25664)
Loss: 0.592 | Acc: 83.854% (26887/32064)
Loss: 0.598 | Acc: 83.772% (32222/38464)
Loss: 0.596 | Acc: 83.791% (37592/44864)
torch.Size([100, 10])
Test set: Average loss: 2.8146, Accuracy: 3947/10000 (39.47%)

Epoch: 58
Loss: 0.785 | Acc: 76.562% (49/64)
Loss: 0.594 | Acc: 84.019% (5431/6464)
Loss: 0.603 | Acc: 83.738% (10772/12864)
Loss: 0.599 | Acc: 83.991% (16180/19264)
Loss: 0.597 | Acc: 84.044% (21569/25664)
Loss: 0.594 | Acc: 84.048% (26949/32064)
Loss: 0.596 | Acc: 83.949% (32290/38464)
Loss: 0.600 | Acc: 83.847% (37617/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8492, Accuracy: 7635/10000 (76.35%)

Epoch: 59
Loss: 0.451 | Acc: 87.500% (56/64)
Loss: 0.595 | Acc: 83.973% (5428/6464)
Loss: 0.582 | Acc: 84.297% (10844/12864)
Loss: 0.586 | Acc: 84.105% (16202/19264)
Loss: 0.587 | Acc: 84.145% (21595/25664)
Loss: 0.588 | Acc: 84.110% (26969/32064)
Loss: 0.589 | Acc: 84.055% (32331/38464)
Loss: 0.591 | Acc: 83.998% (37685/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7709, Accuracy: 7828/10000 (78.28%)

Epoch: 60
Loss: 0.657 | Acc: 78.125% (50/64)
Loss: 0.567 | Acc: 84.313% (5450/6464)
Loss: 0.571 | Acc: 84.258% (10839/12864)
Loss: 0.589 | Acc: 83.934% (16169/19264)
Loss: 0.588 | Acc: 84.017% (21562/25664)
Loss: 0.584 | Acc: 84.150% (26982/32064)
Loss: 0.584 | Acc: 84.203% (32388/38464)
Loss: 0.586 | Acc: 84.161% (37758/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7640, Accuracy: 7833/10000 (78.33%)

Epoch: 61
Loss: 0.813 | Acc: 81.250% (52/64)
Loss: 0.567 | Acc: 84.777% (5480/6464)
Loss: 0.573 | Acc: 84.577% (10880/12864)
Loss: 0.580 | Acc: 84.375% (16254/19264)
Loss: 0.585 | Acc: 84.231% (21617/25664)
Loss: 0.583 | Acc: 84.253% (27015/32064)
Loss: 0.584 | Acc: 84.279% (32417/38464)
Loss: 0.582 | Acc: 84.344% (37840/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0126, Accuracy: 7044/10000 (70.44%)

Epoch: 62
Loss: 0.541 | Acc: 85.938% (55/64)
Loss: 0.548 | Acc: 85.582% (5532/6464)
Loss: 0.556 | Acc: 85.285% (10971/12864)
Loss: 0.568 | Acc: 85.029% (16380/19264)
Loss: 0.571 | Acc: 84.924% (21795/25664)
Loss: 0.574 | Acc: 84.784% (27185/32064)
Loss: 0.574 | Acc: 84.700% (32579/38464)
Loss: 0.575 | Acc: 84.611% (37960/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7632, Accuracy: 7860/10000 (78.60%)

Epoch: 63
Loss: 0.360 | Acc: 87.500% (56/64)
Loss: 0.558 | Acc: 85.195% (5507/6464)
Loss: 0.567 | Acc: 84.857% (10916/12864)
Loss: 0.566 | Acc: 84.764% (16329/19264)
Loss: 0.561 | Acc: 84.831% (21771/25664)
Loss: 0.563 | Acc: 84.868% (27212/32064)
Loss: 0.567 | Acc: 84.716% (32585/38464)
Loss: 0.566 | Acc: 84.816% (38052/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9294, Accuracy: 7529/10000 (75.29%)

Epoch: 64
Loss: 0.766 | Acc: 78.125% (50/64)
Loss: 0.567 | Acc: 84.669% (5473/6464)
Loss: 0.548 | Acc: 85.370% (10982/12864)
Loss: 0.548 | Acc: 85.335% (16439/19264)
Loss: 0.551 | Acc: 85.232% (21874/25664)
Loss: 0.551 | Acc: 85.308% (27353/32064)
Loss: 0.554 | Acc: 85.220% (32779/38464)
Loss: 0.561 | Acc: 84.986% (38128/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1881, Accuracy: 6613/10000 (66.13%)

Epoch: 65
Loss: 0.475 | Acc: 81.250% (52/64)
Loss: 0.556 | Acc: 85.040% (5497/6464)
Loss: 0.552 | Acc: 85.308% (10974/12864)
Loss: 0.552 | Acc: 85.304% (16433/19264)
Loss: 0.558 | Acc: 85.076% (21834/25664)
Loss: 0.561 | Acc: 85.083% (27281/32064)
Loss: 0.558 | Acc: 85.106% (32735/38464)
Loss: 0.561 | Acc: 85.050% (38157/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3353, Accuracy: 5964/10000 (59.64%)

Epoch: 66
Loss: 0.800 | Acc: 78.125% (50/64)
Loss: 0.530 | Acc: 85.829% (5548/6464)
Loss: 0.538 | Acc: 85.502% (10999/12864)
Loss: 0.545 | Acc: 85.439% (16459/19264)
Loss: 0.551 | Acc: 85.404% (21918/25664)
Loss: 0.546 | Acc: 85.460% (27402/32064)
Loss: 0.548 | Acc: 85.436% (32862/38464)
Loss: 0.547 | Acc: 85.436% (38330/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2043, Accuracy: 6442/10000 (64.42%)

Epoch: 67
Loss: 0.544 | Acc: 87.500% (56/64)
Loss: 0.555 | Acc: 85.241% (5510/6464)
Loss: 0.539 | Acc: 85.557% (11006/12864)
Loss: 0.537 | Acc: 85.787% (16526/19264)
Loss: 0.537 | Acc: 85.860% (22035/25664)
Loss: 0.542 | Acc: 85.654% (27464/32064)
Loss: 0.544 | Acc: 85.519% (32894/38464)
Loss: 0.548 | Acc: 85.496% (38357/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9178, Accuracy: 7383/10000 (73.83%)

Epoch: 68
Loss: 0.469 | Acc: 87.500% (56/64)
Loss: 0.548 | Acc: 84.994% (5494/6464)
Loss: 0.538 | Acc: 85.611% (11013/12864)
Loss: 0.540 | Acc: 85.688% (16507/19264)
Loss: 0.539 | Acc: 85.715% (21998/25664)
Loss: 0.536 | Acc: 85.878% (27536/32064)
Loss: 0.539 | Acc: 85.766% (32989/38464)
Loss: 0.536 | Acc: 85.837% (38510/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8734, Accuracy: 7531/10000 (75.31%)

Epoch: 69
Loss: 0.698 | Acc: 75.000% (48/64)
Loss: 0.502 | Acc: 86.618% (5599/6464)
Loss: 0.509 | Acc: 86.637% (11145/12864)
Loss: 0.524 | Acc: 86.223% (16610/19264)
Loss: 0.525 | Acc: 86.167% (22114/25664)
Loss: 0.529 | Acc: 86.131% (27617/32064)
Loss: 0.525 | Acc: 86.262% (33180/38464)
Loss: 0.525 | Acc: 86.314% (38724/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8688, Accuracy: 7512/10000 (75.12%)

Epoch: 70
Loss: 0.468 | Acc: 89.062% (57/64)
Loss: 0.496 | Acc: 87.361% (5647/6464)
Loss: 0.500 | Acc: 87.197% (11217/12864)
Loss: 0.500 | Acc: 87.043% (16768/19264)
Loss: 0.502 | Acc: 87.025% (22334/25664)
Loss: 0.507 | Acc: 86.901% (27864/32064)
Loss: 0.511 | Acc: 86.780% (33379/38464)
Loss: 0.515 | Acc: 86.660% (38879/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7935, Accuracy: 7795/10000 (77.95%)

Epoch: 71
Loss: 0.688 | Acc: 81.250% (52/64)
Loss: 0.504 | Acc: 87.036% (5626/6464)
Loss: 0.503 | Acc: 86.824% (11169/12864)
Loss: 0.503 | Acc: 86.965% (16753/19264)
Loss: 0.504 | Acc: 86.982% (22323/25664)
Loss: 0.512 | Acc: 86.820% (27838/32064)
Loss: 0.511 | Acc: 86.756% (33370/38464)
Loss: 0.508 | Acc: 86.813% (38948/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2294, Accuracy: 6523/10000 (65.23%)

Epoch: 72
Loss: 0.667 | Acc: 76.562% (49/64)
Loss: 0.501 | Acc: 86.974% (5622/6464)
Loss: 0.505 | Acc: 87.057% (11199/12864)
Loss: 0.507 | Acc: 86.903% (16741/19264)
Loss: 0.499 | Acc: 87.130% (22361/25664)
Loss: 0.499 | Acc: 87.163% (27948/32064)
Loss: 0.496 | Acc: 87.172% (33530/38464)
Loss: 0.497 | Acc: 87.181% (39113/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7972, Accuracy: 7846/10000 (78.46%)

Epoch: 73
Loss: 0.313 | Acc: 90.625% (58/64)
Loss: 0.470 | Acc: 87.624% (5664/6464)
Loss: 0.479 | Acc: 87.516% (11258/12864)
Loss: 0.486 | Acc: 87.287% (16815/19264)
Loss: 0.490 | Acc: 87.332% (22413/25664)
Loss: 0.490 | Acc: 87.347% (28007/32064)
Loss: 0.486 | Acc: 87.555% (33677/38464)
Loss: 0.490 | Acc: 87.520% (39265/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6712, Accuracy: 8192/10000 (81.92%)

Epoch: 74
Loss: 0.381 | Acc: 90.625% (58/64)
Loss: 0.450 | Acc: 88.227% (5703/6464)
Loss: 0.460 | Acc: 88.114% (11335/12864)
Loss: 0.469 | Acc: 88.019% (16956/19264)
Loss: 0.471 | Acc: 87.917% (22563/25664)
Loss: 0.473 | Acc: 87.915% (28189/32064)
Loss: 0.479 | Acc: 87.781% (33764/38464)
Loss: 0.478 | Acc: 87.794% (39388/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8557, Accuracy: 7589/10000 (75.89%)

Epoch: 75
Loss: 0.512 | Acc: 84.375% (54/64)
Loss: 0.439 | Acc: 88.908% (5747/6464)
Loss: 0.457 | Acc: 88.456% (11379/12864)
Loss: 0.458 | Acc: 88.362% (17022/19264)
Loss: 0.459 | Acc: 88.381% (22682/25664)
Loss: 0.463 | Acc: 88.258% (28299/32064)
Loss: 0.466 | Acc: 88.215% (33931/38464)
Loss: 0.465 | Acc: 88.278% (39605/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5704, Accuracy: 8566/10000 (85.66%)

Epoch: 76
Loss: 0.583 | Acc: 85.938% (55/64)
Loss: 0.455 | Acc: 88.676% (5732/6464)
Loss: 0.447 | Acc: 88.946% (11442/12864)
Loss: 0.455 | Acc: 88.710% (17089/19264)
Loss: 0.458 | Acc: 88.529% (22720/25664)
Loss: 0.459 | Acc: 88.489% (28373/32064)
Loss: 0.461 | Acc: 88.394% (34000/38464)
Loss: 0.457 | Acc: 88.483% (39697/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6561, Accuracy: 8299/10000 (82.99%)

Epoch: 77
Loss: 0.733 | Acc: 84.375% (54/64)
Loss: 0.446 | Acc: 89.078% (5758/6464)
Loss: 0.448 | Acc: 88.954% (11443/12864)
Loss: 0.447 | Acc: 88.953% (17136/19264)
Loss: 0.452 | Acc: 88.696% (22763/25664)
Loss: 0.448 | Acc: 88.797% (28472/32064)
Loss: 0.445 | Acc: 88.805% (34158/38464)
Loss: 0.444 | Acc: 88.782% (39831/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6874, Accuracy: 8219/10000 (82.19%)

Epoch: 78
Loss: 0.466 | Acc: 87.500% (56/64)
Loss: 0.415 | Acc: 89.650% (5795/6464)
Loss: 0.416 | Acc: 89.513% (11515/12864)
Loss: 0.426 | Acc: 89.410% (17224/19264)
Loss: 0.431 | Acc: 89.355% (22932/25664)
Loss: 0.434 | Acc: 89.218% (28607/32064)
Loss: 0.432 | Acc: 89.255% (34331/38464)
Loss: 0.429 | Acc: 89.299% (40063/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6516, Accuracy: 8301/10000 (83.01%)

Epoch: 79
Loss: 0.364 | Acc: 95.312% (61/64)
Loss: 0.400 | Acc: 90.563% (5854/6464)
Loss: 0.397 | Acc: 90.462% (11637/12864)
Loss: 0.399 | Acc: 90.365% (17408/19264)
Loss: 0.406 | Acc: 90.146% (23135/25664)
Loss: 0.410 | Acc: 90.070% (28880/32064)
Loss: 0.409 | Acc: 90.058% (34640/38464)
Loss: 0.410 | Acc: 89.961% (40360/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8734, Accuracy: 5639/10000 (56.39%)

Epoch: 80
Loss: 0.634 | Acc: 79.688% (51/64)
Loss: 0.433 | Acc: 89.496% (5785/6464)
Loss: 0.409 | Acc: 90.112% (11592/12864)
Loss: 0.410 | Acc: 89.976% (17333/19264)
Loss: 0.408 | Acc: 90.025% (23104/25664)
Loss: 0.408 | Acc: 90.036% (28869/32064)
Loss: 0.406 | Acc: 90.110% (34660/38464)
Loss: 0.408 | Acc: 90.059% (40404/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6227, Accuracy: 8390/10000 (83.90%)

Epoch: 81
Loss: 0.206 | Acc: 95.312% (61/64)
Loss: 0.368 | Acc: 90.950% (5879/6464)
Loss: 0.389 | Acc: 90.578% (11652/12864)
Loss: 0.392 | Acc: 90.542% (17442/19264)
Loss: 0.390 | Acc: 90.633% (23260/25664)
Loss: 0.386 | Acc: 90.731% (29092/32064)
Loss: 0.389 | Acc: 90.690% (34883/38464)
Loss: 0.388 | Acc: 90.650% (40669/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5701, Accuracy: 8597/10000 (85.97%)

Epoch: 82
Loss: 0.290 | Acc: 92.188% (59/64)
Loss: 0.382 | Acc: 90.934% (5878/6464)
Loss: 0.368 | Acc: 91.091% (11718/12864)
Loss: 0.357 | Acc: 91.367% (17601/19264)
Loss: 0.363 | Acc: 91.256% (23420/25664)
Loss: 0.367 | Acc: 91.177% (29235/32064)
Loss: 0.369 | Acc: 91.158% (35063/38464)
Loss: 0.370 | Acc: 91.180% (40907/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9038, Accuracy: 7640/10000 (76.40%)

Epoch: 83
Loss: 0.491 | Acc: 87.500% (56/64)
Loss: 0.351 | Acc: 91.476% (5913/6464)
Loss: 0.357 | Acc: 91.379% (11755/12864)
Loss: 0.346 | Acc: 91.777% (17680/19264)
Loss: 0.351 | Acc: 91.545% (23494/25664)
Loss: 0.352 | Acc: 91.470% (29329/32064)
Loss: 0.358 | Acc: 91.441% (35172/38464)
Loss: 0.357 | Acc: 91.490% (41046/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7502, Accuracy: 8115/10000 (81.15%)

Epoch: 84
Loss: 0.190 | Acc: 96.875% (62/64)
Loss: 0.336 | Acc: 92.064% (5951/6464)
Loss: 0.335 | Acc: 92.118% (11850/12864)
Loss: 0.347 | Acc: 91.767% (17678/19264)
Loss: 0.345 | Acc: 91.852% (23573/25664)
Loss: 0.341 | Acc: 91.960% (29486/32064)
Loss: 0.341 | Acc: 91.961% (35372/38464)
Loss: 0.339 | Acc: 91.996% (41273/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6741, Accuracy: 8313/10000 (83.13%)

Epoch: 85
Loss: 0.599 | Acc: 87.500% (56/64)
Loss: 0.322 | Acc: 92.327% (5968/6464)
Loss: 0.312 | Acc: 92.794% (11937/12864)
Loss: 0.317 | Acc: 92.577% (17834/19264)
Loss: 0.313 | Acc: 92.710% (23793/25664)
Loss: 0.312 | Acc: 92.749% (29739/32064)
Loss: 0.314 | Acc: 92.705% (35658/38464)
Loss: 0.317 | Acc: 92.620% (41553/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5740, Accuracy: 8604/10000 (86.04%)

Epoch: 86
Loss: 0.241 | Acc: 95.312% (61/64)
Loss: 0.283 | Acc: 93.441% (6040/6464)
Loss: 0.279 | Acc: 93.431% (12019/12864)
Loss: 0.292 | Acc: 93.195% (17953/19264)
Loss: 0.296 | Acc: 93.080% (23888/25664)
Loss: 0.294 | Acc: 93.114% (29856/32064)
Loss: 0.294 | Acc: 93.123% (35819/38464)
Loss: 0.297 | Acc: 93.008% (41727/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5891, Accuracy: 8623/10000 (86.23%)

Epoch: 87
Loss: 0.311 | Acc: 90.625% (58/64)
Loss: 0.302 | Acc: 93.131% (6020/6464)
Loss: 0.279 | Acc: 93.509% (12029/12864)
Loss: 0.278 | Acc: 93.527% (18017/19264)
Loss: 0.277 | Acc: 93.497% (23995/25664)
Loss: 0.279 | Acc: 93.388% (29944/32064)
Loss: 0.281 | Acc: 93.313% (35892/38464)
Loss: 0.279 | Acc: 93.416% (41910/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5850, Accuracy: 8700/10000 (87.00%)

Epoch: 88
Loss: 0.173 | Acc: 95.312% (61/64)
Loss: 0.245 | Acc: 94.152% (6086/6464)
Loss: 0.248 | Acc: 94.154% (12112/12864)
Loss: 0.249 | Acc: 94.160% (18139/19264)
Loss: 0.250 | Acc: 94.159% (24165/25664)
Loss: 0.249 | Acc: 94.143% (30186/32064)
Loss: 0.249 | Acc: 94.130% (36206/38464)
Loss: 0.253 | Acc: 94.060% (42199/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5558, Accuracy: 8780/10000 (87.80%)

Epoch: 89
Loss: 0.258 | Acc: 93.750% (60/64)
Loss: 0.219 | Acc: 94.740% (6124/6464)
Loss: 0.226 | Acc: 94.613% (12171/12864)
Loss: 0.230 | Acc: 94.539% (18212/19264)
Loss: 0.228 | Acc: 94.615% (24282/25664)
Loss: 0.230 | Acc: 94.583% (30327/32064)
Loss: 0.227 | Acc: 94.652% (36407/38464)
Loss: 0.228 | Acc: 94.668% (42472/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5827, Accuracy: 8754/10000 (87.54%)

Epoch: 90
Loss: 0.067 | Acc: 100.000% (64/64)
Loss: 0.202 | Acc: 95.204% (6154/6464)
Loss: 0.202 | Acc: 95.289% (12258/12864)
Loss: 0.203 | Acc: 95.281% (18355/19264)
Loss: 0.201 | Acc: 95.293% (24456/25664)
Loss: 0.205 | Acc: 95.188% (30521/32064)
Loss: 0.205 | Acc: 95.180% (36610/38464)
Loss: 0.205 | Acc: 95.185% (42704/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5708, Accuracy: 8843/10000 (88.43%)

Epoch: 91
Loss: 0.272 | Acc: 93.750% (60/64)
Loss: 0.183 | Acc: 95.684% (6185/6464)
Loss: 0.181 | Acc: 95.647% (12304/12864)
Loss: 0.176 | Acc: 95.790% (18453/19264)
Loss: 0.175 | Acc: 95.858% (24601/25664)
Loss: 0.176 | Acc: 95.824% (30725/32064)
Loss: 0.180 | Acc: 95.752% (36830/38464)
Loss: 0.181 | Acc: 95.740% (42953/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5807, Accuracy: 8842/10000 (88.42%)

Epoch: 92
Loss: 0.241 | Acc: 92.188% (59/64)
Loss: 0.143 | Acc: 96.612% (6245/6464)
Loss: 0.142 | Acc: 96.564% (12422/12864)
Loss: 0.147 | Acc: 96.434% (18577/19264)
Loss: 0.152 | Acc: 96.294% (24713/25664)
Loss: 0.156 | Acc: 96.220% (30852/32064)
Loss: 0.156 | Acc: 96.209% (37006/38464)
Loss: 0.157 | Acc: 96.202% (43160/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6131, Accuracy: 8801/10000 (88.01%)

Epoch: 93
Loss: 0.139 | Acc: 98.438% (63/64)
Loss: 0.134 | Acc: 96.782% (6256/6464)
Loss: 0.134 | Acc: 96.758% (12447/12864)
Loss: 0.132 | Acc: 96.756% (18639/19264)
Loss: 0.134 | Acc: 96.700% (24817/25664)
Loss: 0.133 | Acc: 96.654% (30991/32064)
Loss: 0.131 | Acc: 96.735% (37208/38464)
Loss: 0.133 | Acc: 96.686% (43377/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6115, Accuracy: 8819/10000 (88.19%)

Epoch: 94
Loss: 0.081 | Acc: 95.312% (61/64)
Loss: 0.118 | Acc: 97.045% (6273/6464)
Loss: 0.120 | Acc: 96.984% (12476/12864)
Loss: 0.118 | Acc: 97.067% (18699/19264)
Loss: 0.119 | Acc: 97.078% (24914/25664)
Loss: 0.120 | Acc: 97.075% (31126/32064)
Loss: 0.120 | Acc: 97.052% (37330/38464)
Loss: 0.118 | Acc: 97.062% (43546/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6133, Accuracy: 8857/10000 (88.57%)

Epoch: 95
Loss: 0.064 | Acc: 98.438% (63/64)
Loss: 0.097 | Acc: 97.447% (6299/6464)
Loss: 0.101 | Acc: 97.442% (12535/12864)
Loss: 0.104 | Acc: 97.368% (18757/19264)
Loss: 0.107 | Acc: 97.249% (24958/25664)
Loss: 0.109 | Acc: 97.215% (31171/32064)
Loss: 0.112 | Acc: 97.158% (37371/38464)
Loss: 0.112 | Acc: 97.187% (43602/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5752, Accuracy: 8845/10000 (88.45%)

Epoch: 96
Loss: 0.086 | Acc: 98.438% (63/64)
Loss: 0.120 | Acc: 97.045% (6273/6464)
Loss: 0.118 | Acc: 97.108% (12492/12864)
Loss: 0.123 | Acc: 97.005% (18687/19264)
Loss: 0.123 | Acc: 96.976% (24888/25664)
Loss: 0.122 | Acc: 97.015% (31107/32064)
Loss: 0.123 | Acc: 96.992% (37307/38464)
Loss: 0.124 | Acc: 96.989% (43513/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5627, Accuracy: 8830/10000 (88.30%)

Epoch: 97
Loss: 0.078 | Acc: 96.875% (62/64)
Loss: 0.122 | Acc: 97.123% (6278/6464)
Loss: 0.123 | Acc: 97.038% (12483/12864)
Loss: 0.124 | Acc: 96.979% (18682/19264)
Loss: 0.123 | Acc: 96.988% (24891/25664)
Loss: 0.124 | Acc: 96.987% (31098/32064)
Loss: 0.126 | Acc: 96.948% (37290/38464)
Loss: 0.124 | Acc: 96.940% (43491/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5561, Accuracy: 8848/10000 (88.48%)
torch.Size([100, 10])
Test set: Average loss: 0.5561, Accuracy: 8848/10000 (88.48%)

Epoch: 98
Loss: 0.122 | Acc: 98.438% (63/64)
Loss: 0.128 | Acc: 96.921% (6265/6464)
Loss: 0.125 | Acc: 96.976% (12475/12864)
Loss: 0.124 | Acc: 97.005% (18687/19264)
Loss: 0.124 | Acc: 96.972% (24887/25664)
Loss: 0.124 | Acc: 96.984% (31097/32064)
Loss: 0.125 | Acc: 96.956% (37293/38464)
Loss: 0.125 | Acc: 96.964% (43502/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5585, Accuracy: 8832/10000 (88.32%)
torch.Size([100, 10])
Test set: Average loss: 0.5585, Accuracy: 8832/10000 (88.32%)

Epoch: 99
Loss: 0.025 | Acc: 100.000% (64/64)
Loss: 0.128 | Acc: 96.658% (6248/6464)
Loss: 0.121 | Acc: 96.922% (12468/12864)
Loss: 0.124 | Acc: 96.917% (18670/19264)
Loss: 0.125 | Acc: 96.898% (24868/25664)
Loss: 0.125 | Acc: 96.912% (31074/32064)
Loss: 0.124 | Acc: 96.950% (37291/38464)
Loss: 0.124 | Acc: 96.957% (43499/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5568, Accuracy: 8839/10000 (88.39%)
torch.Size([100, 10])
Test set: Average loss: 0.5568, Accuracy: 8839/10000 (88.39%)

Epoch: 100
Loss: 0.147 | Acc: 95.312% (61/64)
Loss: 1.994 | Acc: 27.150% (1755/6464)
Loss: 1.685 | Acc: 40.127% (5162/12864)
Loss: 1.420 | Acc: 51.043% (9833/19264)
Loss: 1.267 | Acc: 57.368% (14723/25664)
Loss: 1.166 | Acc: 61.334% (19666/32064)
Loss: 1.094 | Acc: 64.333% (24745/38464)
Loss: 1.038 | Acc: 66.597% (29878/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0145, Accuracy: 4544/10000 (45.44%)

Epoch: 101
Loss: 0.702 | Acc: 75.000% (48/64)
Loss: 0.642 | Acc: 81.652% (5278/6464)
Loss: 0.656 | Acc: 81.468% (10480/12864)
Loss: 0.660 | Acc: 81.401% (15681/19264)
Loss: 0.651 | Acc: 81.764% (20984/25664)
Loss: 0.649 | Acc: 81.833% (26239/32064)
Loss: 0.648 | Acc: 81.910% (31506/38464)
Loss: 0.651 | Acc: 81.847% (36720/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8308, Accuracy: 7652/10000 (76.52%)

Epoch: 102
Loss: 0.523 | Acc: 85.938% (55/64)
Loss: 0.586 | Acc: 83.942% (5426/6464)
Loss: 0.600 | Acc: 83.574% (10751/12864)
Loss: 0.604 | Acc: 83.363% (16059/19264)
Loss: 0.606 | Acc: 83.241% (21363/25664)
Loss: 0.609 | Acc: 83.243% (26691/32064)
Loss: 0.610 | Acc: 83.189% (31998/38464)
Loss: 0.611 | Acc: 83.218% (37335/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1465, Accuracy: 4712/10000 (47.12%)

Epoch: 103
Loss: 0.611 | Acc: 81.250% (52/64)
Loss: 0.600 | Acc: 83.571% (5402/6464)
Loss: 0.604 | Acc: 83.528% (10745/12864)
Loss: 0.598 | Acc: 83.700% (16124/19264)
Loss: 0.600 | Acc: 83.810% (21509/25664)
Loss: 0.600 | Acc: 83.854% (26887/32064)
Loss: 0.599 | Acc: 83.847% (32251/38464)
Loss: 0.599 | Acc: 83.751% (37574/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8755, Accuracy: 5006/10000 (50.06%)

Epoch: 104
Loss: 0.728 | Acc: 78.125% (50/64)
Loss: 0.598 | Acc: 83.648% (5407/6464)
Loss: 0.605 | Acc: 83.730% (10771/12864)
Loss: 0.599 | Acc: 83.934% (16169/19264)
Loss: 0.598 | Acc: 83.806% (21508/25664)
Loss: 0.596 | Acc: 83.829% (26879/32064)
Loss: 0.595 | Acc: 83.821% (32241/38464)
Loss: 0.595 | Acc: 83.804% (37598/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9645, Accuracy: 7120/10000 (71.20%)

Epoch: 105
Loss: 0.866 | Acc: 76.562% (49/64)
Loss: 0.588 | Acc: 84.158% (5440/6464)
Loss: 0.582 | Acc: 84.383% (10855/12864)
Loss: 0.583 | Acc: 84.266% (16233/19264)
Loss: 0.581 | Acc: 84.320% (21640/25664)
Loss: 0.587 | Acc: 84.179% (26991/32064)
Loss: 0.590 | Acc: 84.034% (32323/38464)
Loss: 0.590 | Acc: 84.058% (37712/44864)
torch.Size([100, 10])
Test set: Average loss: 3.3465, Accuracy: 2892/10000 (28.92%)

Epoch: 106
Loss: 0.707 | Acc: 79.688% (51/64)
Loss: 0.598 | Acc: 83.957% (5427/6464)
Loss: 0.585 | Acc: 84.134% (10823/12864)
Loss: 0.576 | Acc: 84.417% (16262/19264)
Loss: 0.579 | Acc: 84.375% (21654/25664)
Loss: 0.583 | Acc: 84.253% (27015/32064)
Loss: 0.584 | Acc: 84.227% (32397/38464)
Loss: 0.585 | Acc: 84.212% (37781/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5120, Accuracy: 5784/10000 (57.84%)

Epoch: 107
Loss: 0.594 | Acc: 76.562% (49/64)
Loss: 0.561 | Acc: 84.855% (5485/6464)
Loss: 0.574 | Acc: 84.251% (10838/12864)
Loss: 0.579 | Acc: 84.468% (16272/19264)
Loss: 0.580 | Acc: 84.535% (21695/25664)
Loss: 0.580 | Acc: 84.515% (27099/32064)
Loss: 0.579 | Acc: 84.484% (32496/38464)
Loss: 0.575 | Acc: 84.547% (37931/44864)
torch.Size([100, 10])
Test set: Average loss: 2.6050, Accuracy: 3960/10000 (39.60%)

Epoch: 108
Loss: 0.878 | Acc: 79.688% (51/64)
Loss: 0.575 | Acc: 84.715% (5476/6464)
Loss: 0.572 | Acc: 84.818% (10911/12864)
Loss: 0.576 | Acc: 84.629% (16303/19264)
Loss: 0.576 | Acc: 84.550% (21699/25664)
Loss: 0.573 | Acc: 84.578% (27119/32064)
Loss: 0.578 | Acc: 84.469% (32490/38464)
Loss: 0.580 | Acc: 84.411% (37870/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3434, Accuracy: 4065/10000 (40.65%)

Epoch: 109
Loss: 0.902 | Acc: 73.438% (47/64)
Loss: 0.585 | Acc: 84.236% (5445/6464)
Loss: 0.588 | Acc: 84.173% (10828/12864)
Loss: 0.584 | Acc: 84.256% (16231/19264)
Loss: 0.574 | Acc: 84.546% (21698/25664)
Loss: 0.575 | Acc: 84.506% (27096/32064)
Loss: 0.578 | Acc: 84.482% (32495/38464)
Loss: 0.577 | Acc: 84.524% (37921/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3109, Accuracy: 6331/10000 (63.31%)

Epoch: 110
Loss: 0.931 | Acc: 73.438% (47/64)
Loss: 0.586 | Acc: 83.895% (5423/6464)
Loss: 0.571 | Acc: 84.484% (10868/12864)
Loss: 0.572 | Acc: 84.567% (16291/19264)
Loss: 0.570 | Acc: 84.632% (21720/25664)
Loss: 0.573 | Acc: 84.556% (27112/32064)
Loss: 0.572 | Acc: 84.544% (32519/38464)
Loss: 0.574 | Acc: 84.533% (37925/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9029, Accuracy: 7474/10000 (74.74%)

Epoch: 111
Loss: 0.754 | Acc: 78.125% (50/64)
Loss: 0.581 | Acc: 84.762% (5479/6464)
Loss: 0.574 | Acc: 84.764% (10904/12864)
Loss: 0.568 | Acc: 84.847% (16345/19264)
Loss: 0.563 | Acc: 84.979% (21809/25664)
Loss: 0.563 | Acc: 84.999% (27254/32064)
Loss: 0.567 | Acc: 84.942% (32672/38464)
Loss: 0.566 | Acc: 84.928% (38102/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2627, Accuracy: 5528/10000 (55.28%)

Epoch: 112
Loss: 1.024 | Acc: 67.188% (43/64)
Loss: 0.552 | Acc: 85.025% (5496/6464)
Loss: 0.545 | Acc: 85.354% (10980/12864)
Loss: 0.553 | Acc: 85.123% (16398/19264)
Loss: 0.552 | Acc: 85.205% (21867/25664)
Loss: 0.556 | Acc: 85.108% (27289/32064)
Loss: 0.560 | Acc: 84.986% (32689/38464)
Loss: 0.560 | Acc: 84.979% (38125/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1729, Accuracy: 6470/10000 (64.70%)

Epoch: 113
Loss: 0.603 | Acc: 84.375% (54/64)
Loss: 0.551 | Acc: 85.303% (5514/6464)
Loss: 0.552 | Acc: 85.471% (10995/12864)
Loss: 0.548 | Acc: 85.543% (16479/19264)
Loss: 0.550 | Acc: 85.345% (21903/25664)
Loss: 0.547 | Acc: 85.385% (27378/32064)
Loss: 0.548 | Acc: 85.368% (32836/38464)
Loss: 0.551 | Acc: 85.340% (38287/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8384, Accuracy: 4932/10000 (49.32%)

Epoch: 114
Loss: 0.605 | Acc: 84.375% (54/64)
Loss: 0.551 | Acc: 85.504% (5527/6464)
Loss: 0.542 | Acc: 85.642% (11017/12864)
Loss: 0.545 | Acc: 85.444% (16460/19264)
Loss: 0.545 | Acc: 85.505% (21944/25664)
Loss: 0.544 | Acc: 85.635% (27458/32064)
Loss: 0.546 | Acc: 85.553% (32907/38464)
Loss: 0.547 | Acc: 85.527% (38371/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0748, Accuracy: 7054/10000 (70.54%)

Epoch: 115
Loss: 0.636 | Acc: 84.375% (54/64)
Loss: 0.512 | Acc: 86.835% (5613/6464)
Loss: 0.512 | Acc: 86.824% (11169/12864)
Loss: 0.524 | Acc: 86.483% (16660/19264)
Loss: 0.528 | Acc: 86.315% (22152/25664)
Loss: 0.530 | Acc: 86.153% (27624/32064)
Loss: 0.533 | Acc: 86.086% (33112/38464)
Loss: 0.537 | Acc: 85.929% (38551/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9850, Accuracy: 7348/10000 (73.48%)

Epoch: 116
Loss: 0.450 | Acc: 90.625% (58/64)
Loss: 0.512 | Acc: 86.417% (5586/6464)
Loss: 0.526 | Acc: 86.101% (11076/12864)
Loss: 0.533 | Acc: 85.958% (16559/19264)
Loss: 0.531 | Acc: 86.086% (22093/25664)
Loss: 0.538 | Acc: 85.909% (27546/32064)
Loss: 0.536 | Acc: 85.958% (33063/38464)
Loss: 0.538 | Acc: 85.842% (38512/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9477, Accuracy: 7480/10000 (74.80%)

Epoch: 117
Loss: 0.508 | Acc: 87.500% (56/64)
Loss: 0.526 | Acc: 86.200% (5572/6464)
Loss: 0.519 | Acc: 86.264% (11097/12864)
Loss: 0.510 | Acc: 86.654% (16693/19264)
Loss: 0.513 | Acc: 86.686% (22247/25664)
Loss: 0.523 | Acc: 86.383% (27698/32064)
Loss: 0.525 | Acc: 86.242% (33172/38464)
Loss: 0.526 | Acc: 86.185% (38666/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6868, Accuracy: 8090/10000 (80.90%)

Epoch: 118
Loss: 0.611 | Acc: 85.938% (55/64)
Loss: 0.503 | Acc: 86.881% (5616/6464)
Loss: 0.516 | Acc: 86.536% (11132/12864)
Loss: 0.512 | Acc: 86.623% (16687/19264)
Loss: 0.514 | Acc: 86.561% (22215/25664)
Loss: 0.517 | Acc: 86.480% (27729/32064)
Loss: 0.516 | Acc: 86.535% (33285/38464)
Loss: 0.518 | Acc: 86.535% (38823/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2220, Accuracy: 6339/10000 (63.39%)

Epoch: 119
Loss: 0.368 | Acc: 89.062% (57/64)
Loss: 0.511 | Acc: 86.417% (5586/6464)
Loss: 0.505 | Acc: 86.668% (11149/12864)
Loss: 0.504 | Acc: 86.758% (16713/19264)
Loss: 0.506 | Acc: 86.810% (22279/25664)
Loss: 0.509 | Acc: 86.851% (27848/32064)
Loss: 0.507 | Acc: 86.951% (33445/38464)
Loss: 0.512 | Acc: 86.787% (38936/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8040, Accuracy: 7778/10000 (77.78%)

Epoch: 120
Loss: 0.385 | Acc: 93.750% (60/64)
Loss: 0.511 | Acc: 86.572% (5596/6464)
Loss: 0.507 | Acc: 86.746% (11159/12864)
Loss: 0.507 | Acc: 86.752% (16712/19264)
Loss: 0.507 | Acc: 86.873% (22295/25664)
Loss: 0.503 | Acc: 87.013% (27900/32064)
Loss: 0.506 | Acc: 86.936% (33439/38464)
Loss: 0.504 | Acc: 87.003% (39033/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0274, Accuracy: 7193/10000 (71.93%)

Epoch: 121
Loss: 0.531 | Acc: 87.500% (56/64)
Loss: 0.469 | Acc: 87.980% (5687/6464)
Loss: 0.471 | Acc: 87.982% (11318/12864)
Loss: 0.486 | Acc: 87.474% (16851/19264)
Loss: 0.492 | Acc: 87.477% (22450/25664)
Loss: 0.492 | Acc: 87.403% (28025/32064)
Loss: 0.494 | Acc: 87.354% (33600/38464)
Loss: 0.496 | Acc: 87.362% (39194/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9220, Accuracy: 7403/10000 (74.03%)

Epoch: 122
Loss: 0.830 | Acc: 70.312% (45/64)
Loss: 0.487 | Acc: 86.928% (5619/6464)
Loss: 0.468 | Acc: 87.772% (11291/12864)
Loss: 0.468 | Acc: 87.848% (16923/19264)
Loss: 0.474 | Acc: 87.761% (22523/25664)
Loss: 0.479 | Acc: 87.647% (28103/32064)
Loss: 0.475 | Acc: 87.705% (33735/38464)
Loss: 0.480 | Acc: 87.594% (39298/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7345, Accuracy: 8046/10000 (80.46%)

Epoch: 123
Loss: 0.447 | Acc: 85.938% (55/64)
Loss: 0.475 | Acc: 88.150% (5698/6464)
Loss: 0.475 | Acc: 88.169% (11342/12864)
Loss: 0.476 | Acc: 88.019% (16956/19264)
Loss: 0.474 | Acc: 88.042% (22595/25664)
Loss: 0.476 | Acc: 88.011% (28220/32064)
Loss: 0.478 | Acc: 87.893% (33807/38464)
Loss: 0.476 | Acc: 87.986% (39474/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9669, Accuracy: 7364/10000 (73.64%)

Epoch: 124
Loss: 0.479 | Acc: 90.625% (58/64)
Loss: 0.458 | Acc: 88.351% (5711/6464)
Loss: 0.452 | Acc: 88.635% (11402/12864)
Loss: 0.453 | Acc: 88.756% (17098/19264)
Loss: 0.456 | Acc: 88.622% (22744/25664)
Loss: 0.462 | Acc: 88.461% (28364/32064)
Loss: 0.461 | Acc: 88.446% (34020/38464)
Loss: 0.465 | Acc: 88.394% (39657/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8770, Accuracy: 7668/10000 (76.68%)

Epoch: 125
Loss: 0.475 | Acc: 82.812% (53/64)
Loss: 0.424 | Acc: 88.985% (5752/6464)
Loss: 0.438 | Acc: 88.549% (11391/12864)
Loss: 0.448 | Acc: 88.336% (17017/19264)
Loss: 0.448 | Acc: 88.349% (22674/25664)
Loss: 0.452 | Acc: 88.336% (28324/32064)
Loss: 0.453 | Acc: 88.340% (33979/38464)
Loss: 0.457 | Acc: 88.273% (39603/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1721, Accuracy: 6841/10000 (68.41%)

Epoch: 126
Loss: 0.510 | Acc: 85.938% (55/64)
Loss: 0.418 | Acc: 89.681% (5797/6464)
Loss: 0.422 | Acc: 89.599% (11526/12864)
Loss: 0.435 | Acc: 89.166% (17177/19264)
Loss: 0.439 | Acc: 89.125% (22873/25664)
Loss: 0.437 | Acc: 89.072% (28560/32064)
Loss: 0.438 | Acc: 89.044% (34250/38464)
Loss: 0.439 | Acc: 89.000% (39929/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6097, Accuracy: 8408/10000 (84.08%)

Epoch: 127
Loss: 0.491 | Acc: 85.938% (55/64)
Loss: 0.411 | Acc: 89.991% (5817/6464)
Loss: 0.427 | Acc: 89.700% (11539/12864)
Loss: 0.433 | Acc: 89.478% (17237/19264)
Loss: 0.435 | Acc: 89.335% (22927/25664)
Loss: 0.435 | Acc: 89.300% (28633/32064)
Loss: 0.430 | Acc: 89.400% (34387/38464)
Loss: 0.430 | Acc: 89.388% (40103/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9572, Accuracy: 7546/10000 (75.46%)

Epoch: 128
Loss: 0.611 | Acc: 84.375% (54/64)
Loss: 0.402 | Acc: 90.145% (5827/6464)
Loss: 0.412 | Acc: 89.646% (11532/12864)
Loss: 0.411 | Acc: 89.654% (17271/19264)
Loss: 0.415 | Acc: 89.709% (23023/25664)
Loss: 0.417 | Acc: 89.664% (28750/32064)
Loss: 0.420 | Acc: 89.572% (34453/38464)
Loss: 0.419 | Acc: 89.651% (40221/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7105, Accuracy: 8228/10000 (82.28%)

Epoch: 129
Loss: 0.503 | Acc: 89.062% (57/64)
Loss: 0.399 | Acc: 90.347% (5840/6464)
Loss: 0.402 | Acc: 90.361% (11624/12864)
Loss: 0.392 | Acc: 90.563% (17446/19264)
Loss: 0.398 | Acc: 90.337% (23184/25664)
Loss: 0.401 | Acc: 90.241% (28935/32064)
Loss: 0.407 | Acc: 90.139% (34671/38464)
Loss: 0.409 | Acc: 90.121% (40432/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8899, Accuracy: 7679/10000 (76.79%)

Epoch: 130
Loss: 0.336 | Acc: 93.750% (60/64)
Loss: 0.394 | Acc: 90.517% (5851/6464)
Loss: 0.399 | Acc: 90.477% (11639/12864)
Loss: 0.388 | Acc: 90.750% (17482/19264)
Loss: 0.391 | Acc: 90.520% (23231/25664)
Loss: 0.389 | Acc: 90.622% (29057/32064)
Loss: 0.389 | Acc: 90.583% (34842/38464)
Loss: 0.391 | Acc: 90.491% (40598/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6242, Accuracy: 8356/10000 (83.56%)

Epoch: 131
Loss: 0.709 | Acc: 85.938% (55/64)
Loss: 0.354 | Acc: 91.553% (5918/6464)
Loss: 0.371 | Acc: 90.936% (11698/12864)
Loss: 0.369 | Acc: 90.968% (17524/19264)
Loss: 0.371 | Acc: 90.960% (23344/25664)
Loss: 0.374 | Acc: 90.946% (29161/32064)
Loss: 0.375 | Acc: 90.960% (34987/38464)
Loss: 0.378 | Acc: 90.870% (40768/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5750, Accuracy: 8593/10000 (85.93%)

Epoch: 132
Loss: 0.343 | Acc: 92.188% (59/64)
Loss: 0.320 | Acc: 92.373% (5971/6464)
Loss: 0.345 | Acc: 91.729% (11800/12864)
Loss: 0.348 | Acc: 91.726% (17670/19264)
Loss: 0.357 | Acc: 91.443% (23468/25664)
Loss: 0.361 | Acc: 91.374% (29298/32064)
Loss: 0.360 | Acc: 91.371% (35145/38464)
Loss: 0.362 | Acc: 91.298% (40960/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7042, Accuracy: 8202/10000 (82.02%)

Epoch: 133
Loss: 0.434 | Acc: 87.500% (56/64)
Loss: 0.305 | Acc: 92.837% (6001/6464)
Loss: 0.326 | Acc: 92.242% (11866/12864)
Loss: 0.333 | Acc: 92.146% (17751/19264)
Loss: 0.337 | Acc: 92.028% (23618/25664)
Loss: 0.340 | Acc: 91.904% (29468/32064)
Loss: 0.341 | Acc: 91.850% (35329/38464)
Loss: 0.344 | Acc: 91.820% (41194/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5608, Accuracy: 8719/10000 (87.19%)

Epoch: 134
Loss: 0.137 | Acc: 96.875% (62/64)
Loss: 0.311 | Acc: 92.837% (6001/6464)
Loss: 0.311 | Acc: 92.809% (11939/12864)
Loss: 0.313 | Acc: 92.733% (17864/19264)
Loss: 0.322 | Acc: 92.488% (23736/25664)
Loss: 0.325 | Acc: 92.375% (29619/32064)
Loss: 0.327 | Acc: 92.356% (35524/38464)
Loss: 0.322 | Acc: 92.448% (41476/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6343, Accuracy: 8450/10000 (84.50%)

Epoch: 135
Loss: 0.229 | Acc: 93.750% (60/64)
Loss: 0.283 | Acc: 93.193% (6024/6464)
Loss: 0.288 | Acc: 93.081% (11974/12864)
Loss: 0.297 | Acc: 92.847% (17886/19264)
Loss: 0.306 | Acc: 92.682% (23786/25664)
Loss: 0.308 | Acc: 92.655% (29709/32064)
Loss: 0.310 | Acc: 92.637% (35632/38464)
Loss: 0.309 | Acc: 92.702% (41590/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5564, Accuracy: 8706/10000 (87.06%)

Epoch: 136
Loss: 0.269 | Acc: 92.188% (59/64)
Loss: 0.292 | Acc: 92.915% (6006/6464)
Loss: 0.287 | Acc: 93.183% (11987/12864)
Loss: 0.279 | Acc: 93.423% (17997/19264)
Loss: 0.283 | Acc: 93.376% (23964/25664)
Loss: 0.288 | Acc: 93.245% (29898/32064)
Loss: 0.289 | Acc: 93.227% (35859/38464)
Loss: 0.287 | Acc: 93.295% (41856/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5727, Accuracy: 8708/10000 (87.08%)

Epoch: 137
Loss: 0.243 | Acc: 93.750% (60/64)
Loss: 0.263 | Acc: 93.595% (6050/6464)
Loss: 0.260 | Acc: 93.766% (12062/12864)
Loss: 0.257 | Acc: 93.989% (18106/19264)
Loss: 0.258 | Acc: 93.968% (24116/25664)
Loss: 0.261 | Acc: 93.875% (30100/32064)
Loss: 0.264 | Acc: 93.792% (36076/38464)
Loss: 0.265 | Acc: 93.810% (42087/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6855, Accuracy: 8353/10000 (83.53%)

Epoch: 138
Loss: 0.229 | Acc: 96.875% (62/64)
Loss: 0.251 | Acc: 94.230% (6091/6464)
Loss: 0.248 | Acc: 94.193% (12117/12864)
Loss: 0.240 | Acc: 94.430% (18191/19264)
Loss: 0.243 | Acc: 94.268% (24193/25664)
Loss: 0.242 | Acc: 94.277% (30229/32064)
Loss: 0.239 | Acc: 94.351% (36291/38464)
Loss: 0.243 | Acc: 94.312% (42312/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8437, Accuracy: 8056/10000 (80.56%)

Epoch: 139
Loss: 0.632 | Acc: 81.250% (52/64)
Loss: 0.225 | Acc: 94.632% (6117/6464)
Loss: 0.226 | Acc: 94.613% (12171/12864)
Loss: 0.224 | Acc: 94.695% (18242/19264)
Loss: 0.226 | Acc: 94.709% (24306/25664)
Loss: 0.224 | Acc: 94.754% (30382/32064)
Loss: 0.223 | Acc: 94.767% (36451/38464)
Loss: 0.221 | Acc: 94.831% (42545/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6071, Accuracy: 8704/10000 (87.04%)

Epoch: 140
Loss: 0.272 | Acc: 92.188% (59/64)
Loss: 0.193 | Acc: 95.452% (6170/6464)
Loss: 0.193 | Acc: 95.561% (12293/12864)
Loss: 0.193 | Acc: 95.499% (18397/19264)
Loss: 0.194 | Acc: 95.457% (24498/25664)
Loss: 0.192 | Acc: 95.487% (30617/32064)
Loss: 0.192 | Acc: 95.494% (36731/38464)
Loss: 0.194 | Acc: 95.455% (42825/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6019, Accuracy: 8789/10000 (87.89%)

Epoch: 141
Loss: 0.232 | Acc: 93.750% (60/64)
Loss: 0.162 | Acc: 96.101% (6212/6464)
Loss: 0.175 | Acc: 95.802% (12324/12864)
Loss: 0.175 | Acc: 95.795% (18454/19264)
Loss: 0.175 | Acc: 95.772% (24579/25664)
Loss: 0.171 | Acc: 95.927% (30758/32064)
Loss: 0.171 | Acc: 95.903% (36888/38464)
Loss: 0.173 | Acc: 95.870% (43011/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6138, Accuracy: 8749/10000 (87.49%)

Epoch: 142
Loss: 0.035 | Acc: 100.000% (64/64)
Loss: 0.148 | Acc: 96.303% (6225/6464)
Loss: 0.150 | Acc: 96.261% (12383/12864)
Loss: 0.152 | Acc: 96.221% (18536/19264)
Loss: 0.151 | Acc: 96.267% (24706/25664)
Loss: 0.147 | Acc: 96.345% (30892/32064)
Loss: 0.147 | Acc: 96.358% (37063/38464)
Loss: 0.149 | Acc: 96.293% (43201/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6033, Accuracy: 8844/10000 (88.44%)

Epoch: 143
Loss: 0.085 | Acc: 98.438% (63/64)
Loss: 0.133 | Acc: 96.566% (6242/6464)
Loss: 0.128 | Acc: 96.797% (12452/12864)
Loss: 0.129 | Acc: 96.808% (18649/19264)
Loss: 0.133 | Acc: 96.707% (24819/25664)
Loss: 0.132 | Acc: 96.685% (31001/32064)
Loss: 0.129 | Acc: 96.742% (37211/38464)
Loss: 0.131 | Acc: 96.706% (43386/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6056, Accuracy: 8831/10000 (88.31%)

Epoch: 144
Loss: 0.105 | Acc: 98.438% (63/64)
Loss: 0.110 | Acc: 97.262% (6287/6464)
Loss: 0.107 | Acc: 97.295% (12516/12864)
Loss: 0.114 | Acc: 97.155% (18716/19264)
Loss: 0.113 | Acc: 97.195% (24944/25664)
Loss: 0.112 | Acc: 97.184% (31161/32064)
Loss: 0.112 | Acc: 97.218% (37394/38464)
Loss: 0.114 | Acc: 97.163% (43591/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6086, Accuracy: 8839/10000 (88.39%)

Epoch: 145
Loss: 0.021 | Acc: 100.000% (64/64)
Loss: 0.096 | Acc: 97.540% (6305/6464)
Loss: 0.099 | Acc: 97.512% (12544/12864)
Loss: 0.098 | Acc: 97.488% (18780/19264)
Loss: 0.101 | Acc: 97.405% (24998/25664)
Loss: 0.103 | Acc: 97.371% (31221/32064)
Loss: 0.105 | Acc: 97.296% (37424/38464)
Loss: 0.107 | Acc: 97.314% (43659/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5918, Accuracy: 8827/10000 (88.27%)

Epoch: 146
Loss: 0.277 | Acc: 93.750% (60/64)
Loss: 0.105 | Acc: 97.494% (6302/6464)
Loss: 0.105 | Acc: 97.442% (12535/12864)
Loss: 0.114 | Acc: 97.223% (18729/19264)
Loss: 0.113 | Acc: 97.245% (24957/25664)
Loss: 0.115 | Acc: 97.234% (31177/32064)
Loss: 0.117 | Acc: 97.140% (37364/38464)
Loss: 0.117 | Acc: 97.156% (43588/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5682, Accuracy: 8862/10000 (88.62%)

Epoch: 147
Loss: 0.086 | Acc: 98.438% (63/64)
Loss: 0.113 | Acc: 97.169% (6281/6464)
Loss: 0.116 | Acc: 97.015% (12480/12864)
Loss: 0.118 | Acc: 97.036% (18693/19264)
Loss: 0.116 | Acc: 97.128% (24927/25664)
Loss: 0.117 | Acc: 97.075% (31126/32064)
Loss: 0.117 | Acc: 97.044% (37327/38464)
Loss: 0.118 | Acc: 97.004% (43520/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5647, Accuracy: 8834/10000 (88.34%)
torch.Size([100, 10])
Test set: Average loss: 0.5647, Accuracy: 8834/10000 (88.34%)

Epoch: 148
Loss: 0.034 | Acc: 100.000% (64/64)
Loss: 0.112 | Acc: 97.169% (6281/6464)
Loss: 0.116 | Acc: 97.046% (12484/12864)
Loss: 0.119 | Acc: 97.046% (18695/19264)
Loss: 0.119 | Acc: 97.070% (24912/25664)
Loss: 0.118 | Acc: 97.090% (31131/32064)
Loss: 0.119 | Acc: 97.088% (37344/38464)
Loss: 0.118 | Acc: 97.091% (43559/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5621, Accuracy: 8857/10000 (88.57%)
torch.Size([100, 10])
Test set: Average loss: 0.5621, Accuracy: 8857/10000 (88.57%)

Epoch: 149
Loss: 0.225 | Acc: 92.188% (59/64)
Loss: 0.116 | Acc: 97.153% (6280/6464)
Loss: 0.114 | Acc: 97.233% (12508/12864)
Loss: 0.117 | Acc: 97.119% (18709/19264)
Loss: 0.118 | Acc: 97.085% (24916/25664)
Loss: 0.118 | Acc: 97.062% (31122/32064)
Loss: 0.119 | Acc: 97.023% (37319/38464)
Loss: 0.119 | Acc: 97.038% (43535/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5633, Accuracy: 8855/10000 (88.55%)
torch.Size([100, 10])
Test set: Average loss: 0.5633, Accuracy: 8855/10000 (88.55%)

Epoch: 150
Loss: 0.073 | Acc: 98.438% (63/64)
Loss: 1.706 | Acc: 40.176% (2597/6464)
Loss: 1.305 | Acc: 56.639% (7286/12864)
Loss: 1.148 | Acc: 62.811% (12100/19264)
Loss: 1.048 | Acc: 66.790% (17141/25664)
Loss: 0.979 | Acc: 69.445% (22267/32064)
Loss: 0.929 | Acc: 71.350% (27444/38464)
Loss: 0.893 | Acc: 72.624% (32582/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4907, Accuracy: 3178/10000 (31.78%)

Epoch: 151
Loss: 0.740 | Acc: 76.562% (49/64)
Loss: 0.654 | Acc: 81.544% (5271/6464)
Loss: 0.637 | Acc: 82.105% (10562/12864)
Loss: 0.644 | Acc: 81.805% (15759/19264)
Loss: 0.640 | Acc: 82.010% (21047/25664)
Loss: 0.634 | Acc: 82.282% (26383/32064)
Loss: 0.632 | Acc: 82.316% (31662/38464)
Loss: 0.631 | Acc: 82.373% (36956/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6360, Accuracy: 5367/10000 (53.67%)

Epoch: 152
Loss: 0.927 | Acc: 70.312% (45/64)
Loss: 0.603 | Acc: 83.199% (5378/6464)
Loss: 0.584 | Acc: 83.722% (10770/12864)
Loss: 0.593 | Acc: 83.690% (16122/19264)
Loss: 0.598 | Acc: 83.490% (21427/25664)
Loss: 0.601 | Acc: 83.486% (26769/32064)
Loss: 0.604 | Acc: 83.488% (32113/38464)
Loss: 0.602 | Acc: 83.619% (37515/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6613, Accuracy: 5288/10000 (52.88%)

Epoch: 153
Loss: 1.161 | Acc: 67.188% (43/64)
Loss: 0.597 | Acc: 83.632% (5406/6464)
Loss: 0.582 | Acc: 84.196% (10831/12864)
Loss: 0.586 | Acc: 84.152% (16211/19264)
Loss: 0.582 | Acc: 84.352% (21648/25664)
Loss: 0.584 | Acc: 84.256% (27016/32064)
Loss: 0.586 | Acc: 84.245% (32404/38464)
Loss: 0.586 | Acc: 84.290% (37816/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3197, Accuracy: 6166/10000 (61.66%)

Epoch: 154
Loss: 0.658 | Acc: 81.250% (52/64)
Loss: 0.586 | Acc: 83.864% (5421/6464)
Loss: 0.596 | Acc: 83.621% (10757/12864)
Loss: 0.593 | Acc: 83.799% (16143/19264)
Loss: 0.588 | Acc: 84.059% (21573/25664)
Loss: 0.587 | Acc: 84.088% (26962/32064)
Loss: 0.589 | Acc: 84.058% (32332/38464)
Loss: 0.585 | Acc: 84.145% (37751/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3309, Accuracy: 6182/10000 (61.82%)

Epoch: 155
Loss: 1.000 | Acc: 78.125% (50/64)
Loss: 0.603 | Acc: 84.019% (5431/6464)
Loss: 0.594 | Acc: 84.087% (10817/12864)
Loss: 0.580 | Acc: 84.479% (16274/19264)
Loss: 0.578 | Acc: 84.391% (21658/25664)
Loss: 0.575 | Acc: 84.434% (27073/32064)
Loss: 0.579 | Acc: 84.396% (32462/38464)
Loss: 0.583 | Acc: 84.284% (37813/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3873, Accuracy: 5931/10000 (59.31%)

Epoch: 156
Loss: 0.539 | Acc: 84.375% (54/64)
Loss: 0.558 | Acc: 84.669% (5473/6464)
Loss: 0.556 | Acc: 84.857% (10916/12864)
Loss: 0.558 | Acc: 84.998% (16374/19264)
Loss: 0.562 | Acc: 84.944% (21800/25664)
Loss: 0.561 | Acc: 84.921% (27229/32064)
Loss: 0.567 | Acc: 84.770% (32606/38464)
Loss: 0.569 | Acc: 84.803% (38046/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6984, Accuracy: 5488/10000 (54.88%)

Epoch: 157
Loss: 0.712 | Acc: 81.250% (52/64)
Loss: 0.548 | Acc: 85.876% (5551/6464)
Loss: 0.545 | Acc: 85.588% (11010/12864)
Loss: 0.563 | Acc: 85.200% (16413/19264)
Loss: 0.565 | Acc: 85.174% (21859/25664)
Loss: 0.566 | Acc: 85.102% (27287/32064)
Loss: 0.565 | Acc: 85.176% (32762/38464)
Loss: 0.566 | Acc: 85.155% (38204/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9656, Accuracy: 7258/10000 (72.58%)

Epoch: 158
Loss: 0.746 | Acc: 82.812% (53/64)
Loss: 0.563 | Acc: 85.566% (5531/6464)
Loss: 0.556 | Acc: 85.207% (10961/12864)
Loss: 0.564 | Acc: 84.925% (16360/19264)
Loss: 0.562 | Acc: 85.061% (21830/25664)
Loss: 0.567 | Acc: 84.933% (27233/32064)
Loss: 0.567 | Acc: 84.918% (32663/38464)
Loss: 0.568 | Acc: 84.894% (38087/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8262, Accuracy: 7652/10000 (76.52%)

Epoch: 159
Loss: 0.523 | Acc: 85.938% (55/64)
Loss: 0.557 | Acc: 84.684% (5474/6464)
Loss: 0.553 | Acc: 85.090% (10946/12864)
Loss: 0.554 | Acc: 85.257% (16424/19264)
Loss: 0.556 | Acc: 85.115% (21844/25664)
Loss: 0.556 | Acc: 85.077% (27279/32064)
Loss: 0.561 | Acc: 84.937% (32670/38464)
Loss: 0.563 | Acc: 84.912% (38095/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4738, Accuracy: 4673/10000 (46.73%)

Epoch: 160
Loss: 0.853 | Acc: 75.000% (48/64)
Loss: 0.558 | Acc: 85.071% (5499/6464)
Loss: 0.571 | Acc: 84.725% (10899/12864)
Loss: 0.558 | Acc: 84.936% (16362/19264)
Loss: 0.558 | Acc: 85.022% (21820/25664)
Loss: 0.551 | Acc: 85.270% (27341/32064)
Loss: 0.557 | Acc: 85.054% (32715/38464)
Loss: 0.557 | Acc: 85.050% (38157/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9201, Accuracy: 7325/10000 (73.25%)

Epoch: 161
Loss: 1.046 | Acc: 71.875% (46/64)
Loss: 0.537 | Acc: 85.736% (5542/6464)
Loss: 0.538 | Acc: 85.588% (11010/12864)
Loss: 0.548 | Acc: 85.372% (16446/19264)
Loss: 0.553 | Acc: 85.244% (21877/25664)
Loss: 0.559 | Acc: 85.173% (27310/32064)
Loss: 0.558 | Acc: 85.236% (32785/38464)
Loss: 0.560 | Acc: 85.186% (38218/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1527, Accuracy: 6682/10000 (66.82%)

Epoch: 162
Loss: 0.640 | Acc: 84.375% (54/64)
Loss: 0.534 | Acc: 85.984% (5558/6464)
Loss: 0.533 | Acc: 86.124% (11079/12864)
Loss: 0.536 | Acc: 85.854% (16539/19264)
Loss: 0.541 | Acc: 85.743% (22005/25664)
Loss: 0.545 | Acc: 85.651% (27463/32064)
Loss: 0.546 | Acc: 85.628% (32936/38464)
Loss: 0.551 | Acc: 85.452% (38337/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6368, Accuracy: 8321/10000 (83.21%)

Epoch: 163
Loss: 0.450 | Acc: 89.062% (57/64)
Loss: 0.521 | Acc: 86.170% (5570/6464)
Loss: 0.529 | Acc: 86.124% (11079/12864)
Loss: 0.533 | Acc: 85.984% (16564/19264)
Loss: 0.542 | Acc: 85.739% (22004/25664)
Loss: 0.545 | Acc: 85.644% (27461/32064)
Loss: 0.542 | Acc: 85.670% (32952/38464)
Loss: 0.544 | Acc: 85.617% (38411/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9102, Accuracy: 7311/10000 (73.11%)

Epoch: 164
Loss: 0.722 | Acc: 82.812% (53/64)
Loss: 0.537 | Acc: 85.829% (5548/6464)
Loss: 0.519 | Acc: 86.318% (11104/12864)
Loss: 0.529 | Acc: 86.109% (16588/19264)
Loss: 0.541 | Acc: 85.704% (21995/25664)
Loss: 0.536 | Acc: 85.894% (27541/32064)
Loss: 0.537 | Acc: 85.909% (33044/38464)
Loss: 0.540 | Acc: 85.822% (38503/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7353, Accuracy: 7924/10000 (79.24%)

Epoch: 165
Loss: 0.355 | Acc: 93.750% (60/64)
Loss: 0.531 | Acc: 86.231% (5574/6464)
Loss: 0.532 | Acc: 86.171% (11085/12864)
Loss: 0.532 | Acc: 86.150% (16596/19264)
Loss: 0.531 | Acc: 86.167% (22114/25664)
Loss: 0.529 | Acc: 86.203% (27640/32064)
Loss: 0.529 | Acc: 86.200% (33156/38464)
Loss: 0.530 | Acc: 86.180% (38664/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2343, Accuracy: 6457/10000 (64.57%)

Epoch: 166
Loss: 0.863 | Acc: 78.125% (50/64)
Loss: 0.516 | Acc: 86.634% (5600/6464)
Loss: 0.517 | Acc: 86.505% (11128/12864)
Loss: 0.520 | Acc: 86.503% (16664/19264)
Loss: 0.522 | Acc: 86.553% (22213/25664)
Loss: 0.523 | Acc: 86.468% (27725/32064)
Loss: 0.525 | Acc: 86.387% (33228/38464)
Loss: 0.527 | Acc: 86.325% (38729/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1676, Accuracy: 5105/10000 (51.05%)

Epoch: 167
Loss: 0.819 | Acc: 76.562% (49/64)
Loss: 0.520 | Acc: 85.922% (5554/6464)
Loss: 0.513 | Acc: 86.396% (11114/12864)
Loss: 0.517 | Acc: 86.431% (16650/19264)
Loss: 0.515 | Acc: 86.347% (22160/25664)
Loss: 0.520 | Acc: 86.187% (27635/32064)
Loss: 0.521 | Acc: 86.257% (33178/38464)
Loss: 0.522 | Acc: 86.294% (38715/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9331, Accuracy: 7442/10000 (74.42%)

Epoch: 168
Loss: 0.411 | Acc: 90.625% (58/64)
Loss: 0.489 | Acc: 87.485% (5655/6464)
Loss: 0.496 | Acc: 87.243% (11223/12864)
Loss: 0.500 | Acc: 87.064% (16772/19264)
Loss: 0.503 | Acc: 87.013% (22331/25664)
Loss: 0.506 | Acc: 86.954% (27881/32064)
Loss: 0.512 | Acc: 86.814% (33392/38464)
Loss: 0.511 | Acc: 86.854% (38966/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8620, Accuracy: 7532/10000 (75.32%)

Epoch: 169
Loss: 0.571 | Acc: 82.812% (53/64)
Loss: 0.495 | Acc: 87.129% (5632/6464)
Loss: 0.498 | Acc: 87.010% (11193/12864)
Loss: 0.503 | Acc: 87.002% (16760/19264)
Loss: 0.503 | Acc: 87.029% (22335/25664)
Loss: 0.504 | Acc: 87.032% (27906/32064)
Loss: 0.509 | Acc: 86.920% (33433/38464)
Loss: 0.505 | Acc: 86.990% (39027/44864)
torch.Size([100, 10])
Test set: Average loss: 4.6024, Accuracy: 1331/10000 (13.31%)

Epoch: 170
Loss: 1.157 | Acc: 67.188% (43/64)
Loss: 0.517 | Acc: 86.433% (5587/6464)
Loss: 0.508 | Acc: 86.886% (11177/12864)
Loss: 0.507 | Acc: 86.960% (16752/19264)
Loss: 0.508 | Acc: 86.904% (22303/25664)
Loss: 0.509 | Acc: 86.836% (27843/32064)
Loss: 0.504 | Acc: 86.988% (33459/38464)
Loss: 0.505 | Acc: 87.012% (39037/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8132, Accuracy: 7805/10000 (78.05%)

Epoch: 171
Loss: 0.625 | Acc: 84.375% (54/64)
Loss: 0.476 | Acc: 87.546% (5659/6464)
Loss: 0.473 | Acc: 87.655% (11276/12864)
Loss: 0.485 | Acc: 87.567% (16869/19264)
Loss: 0.486 | Acc: 87.543% (22467/25664)
Loss: 0.485 | Acc: 87.559% (28075/32064)
Loss: 0.488 | Acc: 87.510% (33660/38464)
Loss: 0.490 | Acc: 87.451% (39234/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7991, Accuracy: 7841/10000 (78.41%)

Epoch: 172
Loss: 0.953 | Acc: 81.250% (52/64)
Loss: 0.481 | Acc: 87.562% (5660/6464)
Loss: 0.474 | Acc: 87.959% (11315/12864)
Loss: 0.473 | Acc: 88.024% (16957/19264)
Loss: 0.476 | Acc: 87.897% (22558/25664)
Loss: 0.476 | Acc: 87.921% (28191/32064)
Loss: 0.475 | Acc: 87.945% (33827/38464)
Loss: 0.477 | Acc: 87.906% (39438/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3209, Accuracy: 6234/10000 (62.34%)

Epoch: 173
Loss: 0.481 | Acc: 89.062% (57/64)
Loss: 0.463 | Acc: 88.150% (5698/6464)
Loss: 0.463 | Acc: 88.145% (11339/12864)
Loss: 0.470 | Acc: 88.123% (16976/19264)
Loss: 0.467 | Acc: 88.147% (22622/25664)
Loss: 0.466 | Acc: 88.142% (28262/32064)
Loss: 0.467 | Acc: 88.140% (33902/38464)
Loss: 0.468 | Acc: 88.137% (39542/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0129, Accuracy: 4839/10000 (48.39%)

Epoch: 174
Loss: 0.646 | Acc: 84.375% (54/64)
Loss: 0.455 | Acc: 88.614% (5728/6464)
Loss: 0.457 | Acc: 88.534% (11389/12864)
Loss: 0.456 | Acc: 88.502% (17049/19264)
Loss: 0.465 | Acc: 88.307% (22663/25664)
Loss: 0.461 | Acc: 88.398% (28344/32064)
Loss: 0.462 | Acc: 88.387% (33997/38464)
Loss: 0.462 | Acc: 88.421% (39669/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8286, Accuracy: 7753/10000 (77.53%)

Epoch: 175
Loss: 0.437 | Acc: 90.625% (58/64)
Loss: 0.450 | Acc: 88.660% (5731/6464)
Loss: 0.439 | Acc: 89.094% (11461/12864)
Loss: 0.449 | Acc: 88.855% (17117/19264)
Loss: 0.453 | Acc: 88.704% (22765/25664)
Loss: 0.447 | Acc: 88.807% (28475/32064)
Loss: 0.451 | Acc: 88.745% (34135/38464)
Loss: 0.452 | Acc: 88.742% (39813/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5854, Accuracy: 8484/10000 (84.84%)

Epoch: 176
Loss: 0.514 | Acc: 93.750% (60/64)
Loss: 0.421 | Acc: 89.975% (5816/6464)
Loss: 0.434 | Acc: 89.459% (11508/12864)
Loss: 0.434 | Acc: 89.281% (17199/19264)
Loss: 0.441 | Acc: 89.148% (22879/25664)
Loss: 0.438 | Acc: 89.156% (28587/32064)
Loss: 0.435 | Acc: 89.185% (34304/38464)
Loss: 0.437 | Acc: 89.167% (40004/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6028, Accuracy: 8414/10000 (84.14%)

Epoch: 177
Loss: 0.278 | Acc: 90.625% (58/64)
Loss: 0.424 | Acc: 89.403% (5779/6464)
Loss: 0.429 | Acc: 89.358% (11495/12864)
Loss: 0.420 | Acc: 89.602% (17261/19264)
Loss: 0.425 | Acc: 89.526% (22976/25664)
Loss: 0.428 | Acc: 89.427% (28674/32064)
Loss: 0.431 | Acc: 89.400% (34387/38464)
Loss: 0.429 | Acc: 89.464% (40137/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8948, Accuracy: 7531/10000 (75.31%)

Epoch: 178
Loss: 0.293 | Acc: 92.188% (59/64)
Loss: 0.373 | Acc: 90.640% (5859/6464)
Loss: 0.384 | Acc: 90.431% (11633/12864)
Loss: 0.395 | Acc: 90.210% (17378/19264)
Loss: 0.403 | Acc: 89.931% (23080/25664)
Loss: 0.411 | Acc: 89.767% (28783/32064)
Loss: 0.409 | Acc: 89.848% (34559/38464)
Loss: 0.411 | Acc: 89.778% (40278/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9447, Accuracy: 7432/10000 (74.32%)

Epoch: 179
Loss: 0.480 | Acc: 85.938% (55/64)
Loss: 0.405 | Acc: 90.161% (5828/6464)
Loss: 0.406 | Acc: 90.058% (11585/12864)
Loss: 0.396 | Acc: 90.324% (17400/19264)
Loss: 0.398 | Acc: 90.157% (23138/25664)
Loss: 0.398 | Acc: 90.188% (28918/32064)
Loss: 0.400 | Acc: 90.100% (34656/38464)
Loss: 0.399 | Acc: 90.117% (40430/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5761, Accuracy: 8571/10000 (85.71%)

Epoch: 180
Loss: 0.273 | Acc: 93.750% (60/64)
Loss: 0.385 | Acc: 90.517% (5851/6464)
Loss: 0.387 | Acc: 90.625% (11658/12864)
Loss: 0.386 | Acc: 90.542% (17442/19264)
Loss: 0.379 | Acc: 90.773% (23296/25664)
Loss: 0.383 | Acc: 90.703% (29083/32064)
Loss: 0.383 | Acc: 90.719% (34894/38464)
Loss: 0.385 | Acc: 90.681% (40683/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5751, Accuracy: 8576/10000 (85.76%)

Epoch: 181
Loss: 0.483 | Acc: 89.062% (57/64)
Loss: 0.369 | Acc: 90.826% (5871/6464)
Loss: 0.358 | Acc: 91.309% (11746/12864)
Loss: 0.363 | Acc: 91.175% (17564/19264)
Loss: 0.365 | Acc: 91.159% (23395/25664)
Loss: 0.362 | Acc: 91.239% (29255/32064)
Loss: 0.365 | Acc: 91.249% (35098/38464)
Loss: 0.366 | Acc: 91.271% (40948/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7124, Accuracy: 8163/10000 (81.63%)

Epoch: 182
Loss: 0.314 | Acc: 89.062% (57/64)
Loss: 0.363 | Acc: 91.584% (5920/6464)
Loss: 0.346 | Acc: 91.970% (11831/12864)
Loss: 0.350 | Acc: 91.845% (17693/19264)
Loss: 0.351 | Acc: 91.833% (23568/25664)
Loss: 0.354 | Acc: 91.742% (29416/32064)
Loss: 0.354 | Acc: 91.670% (35260/38464)
Loss: 0.354 | Acc: 91.653% (41119/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5542, Accuracy: 8664/10000 (86.64%)

Epoch: 183
Loss: 0.401 | Acc: 92.188% (59/64)
Loss: 0.318 | Acc: 92.791% (5998/6464)
Loss: 0.328 | Acc: 92.452% (11893/12864)
Loss: 0.335 | Acc: 92.188% (17759/19264)
Loss: 0.337 | Acc: 92.176% (23656/25664)
Loss: 0.339 | Acc: 92.035% (29510/32064)
Loss: 0.340 | Acc: 92.021% (35395/38464)
Loss: 0.339 | Acc: 92.096% (41318/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5472, Accuracy: 8704/10000 (87.04%)

Epoch: 184
Loss: 0.300 | Acc: 90.625% (58/64)
Loss: 0.317 | Acc: 92.528% (5981/6464)
Loss: 0.321 | Acc: 92.265% (11869/12864)
Loss: 0.324 | Acc: 92.307% (17782/19264)
Loss: 0.323 | Acc: 92.375% (23707/25664)
Loss: 0.319 | Acc: 92.471% (29650/32064)
Loss: 0.321 | Acc: 92.468% (35567/38464)
Loss: 0.322 | Acc: 92.477% (41489/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6589, Accuracy: 8368/10000 (83.68%)

Epoch: 185
Loss: 0.415 | Acc: 92.188% (59/64)
Loss: 0.291 | Acc: 93.255% (6028/6464)
Loss: 0.298 | Acc: 93.175% (11986/12864)
Loss: 0.292 | Acc: 93.283% (17970/19264)
Loss: 0.301 | Acc: 93.142% (23904/25664)
Loss: 0.303 | Acc: 93.092% (29849/32064)
Loss: 0.303 | Acc: 93.090% (35806/38464)
Loss: 0.304 | Acc: 93.041% (41742/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5717, Accuracy: 8655/10000 (86.55%)

Epoch: 186
Loss: 0.174 | Acc: 96.875% (62/64)
Loss: 0.276 | Acc: 93.472% (6042/6464)
Loss: 0.269 | Acc: 93.742% (12059/12864)
Loss: 0.266 | Acc: 93.864% (18082/19264)
Loss: 0.276 | Acc: 93.645% (24033/25664)
Loss: 0.280 | Acc: 93.529% (29989/32064)
Loss: 0.283 | Acc: 93.477% (35955/38464)
Loss: 0.281 | Acc: 93.538% (41965/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5646, Accuracy: 8686/10000 (86.86%)

Epoch: 187
Loss: 0.229 | Acc: 95.312% (61/64)
Loss: 0.242 | Acc: 94.725% (6123/6464)
Loss: 0.247 | Acc: 94.403% (12144/12864)
Loss: 0.257 | Acc: 94.129% (18133/19264)
Loss: 0.258 | Acc: 94.116% (24154/25664)
Loss: 0.261 | Acc: 93.996% (30139/32064)
Loss: 0.262 | Acc: 93.989% (36152/38464)
Loss: 0.263 | Acc: 93.906% (42130/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6672, Accuracy: 8485/10000 (84.85%)

Epoch: 188
Loss: 0.264 | Acc: 93.750% (60/64)
Loss: 0.244 | Acc: 94.121% (6084/6464)
Loss: 0.238 | Acc: 94.496% (12156/12864)
Loss: 0.240 | Acc: 94.414% (18188/19264)
Loss: 0.239 | Acc: 94.444% (24238/25664)
Loss: 0.239 | Acc: 94.389% (30265/32064)
Loss: 0.239 | Acc: 94.379% (36302/38464)
Loss: 0.239 | Acc: 94.370% (42338/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5499, Accuracy: 8799/10000 (87.99%)

Epoch: 189
Loss: 0.177 | Acc: 96.875% (62/64)
Loss: 0.197 | Acc: 95.498% (6173/6464)
Loss: 0.204 | Acc: 95.281% (12257/12864)
Loss: 0.211 | Acc: 95.079% (18316/19264)
Loss: 0.214 | Acc: 95.055% (24395/25664)
Loss: 0.216 | Acc: 95.022% (30468/32064)
Loss: 0.218 | Acc: 94.936% (36516/38464)
Loss: 0.218 | Acc: 94.956% (42601/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5573, Accuracy: 8817/10000 (88.17%)

Epoch: 190
Loss: 0.254 | Acc: 92.188% (59/64)
Loss: 0.184 | Acc: 95.591% (6179/6464)
Loss: 0.182 | Acc: 95.647% (12304/12864)
Loss: 0.187 | Acc: 95.458% (18389/19264)
Loss: 0.191 | Acc: 95.414% (24487/25664)
Loss: 0.190 | Acc: 95.440% (30602/32064)
Loss: 0.192 | Acc: 95.458% (36717/38464)
Loss: 0.192 | Acc: 95.440% (42818/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6206, Accuracy: 8705/10000 (87.05%)

Epoch: 191
Loss: 0.271 | Acc: 95.312% (61/64)
Loss: 0.179 | Acc: 95.668% (6184/6464)
Loss: 0.170 | Acc: 95.903% (12337/12864)
Loss: 0.167 | Acc: 96.029% (18499/19264)
Loss: 0.167 | Acc: 96.010% (24640/25664)
Loss: 0.168 | Acc: 96.011% (30785/32064)
Loss: 0.171 | Acc: 95.923% (36896/38464)
Loss: 0.173 | Acc: 95.888% (43019/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5903, Accuracy: 8785/10000 (87.85%)

Epoch: 192
Loss: 0.115 | Acc: 96.875% (62/64)
Loss: 0.142 | Acc: 96.566% (6242/6464)
Loss: 0.139 | Acc: 96.549% (12420/12864)
Loss: 0.140 | Acc: 96.564% (18602/19264)
Loss: 0.142 | Acc: 96.524% (24772/25664)
Loss: 0.144 | Acc: 96.482% (30936/32064)
Loss: 0.146 | Acc: 96.443% (37096/38464)
Loss: 0.149 | Acc: 96.351% (43227/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6076, Accuracy: 8831/10000 (88.31%)

Epoch: 193
Loss: 0.131 | Acc: 96.875% (62/64)
Loss: 0.137 | Acc: 96.689% (6250/6464)
Loss: 0.139 | Acc: 96.549% (12420/12864)
Loss: 0.139 | Acc: 96.543% (18598/19264)
Loss: 0.138 | Acc: 96.552% (24779/25664)
Loss: 0.134 | Acc: 96.669% (30996/32064)
Loss: 0.133 | Acc: 96.758% (37217/38464)
Loss: 0.132 | Acc: 96.743% (43403/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6043, Accuracy: 8842/10000 (88.42%)

Epoch: 194
Loss: 0.149 | Acc: 96.875% (62/64)
Loss: 0.111 | Acc: 97.200% (6283/6464)
Loss: 0.113 | Acc: 97.170% (12500/12864)
Loss: 0.110 | Acc: 97.295% (18743/19264)
Loss: 0.112 | Acc: 97.230% (24953/25664)
Loss: 0.110 | Acc: 97.296% (31197/32064)
Loss: 0.110 | Acc: 97.283% (37419/38464)
Loss: 0.109 | Acc: 97.301% (43653/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6087, Accuracy: 8841/10000 (88.41%)

Epoch: 195
Loss: 0.226 | Acc: 96.875% (62/64)
Loss: 0.099 | Acc: 97.571% (6307/6464)
Loss: 0.102 | Acc: 97.520% (12545/12864)
Loss: 0.107 | Acc: 97.358% (18755/19264)
Loss: 0.107 | Acc: 97.350% (24984/25664)
Loss: 0.106 | Acc: 97.362% (31218/32064)
Loss: 0.109 | Acc: 97.294% (37423/38464)
Loss: 0.110 | Acc: 97.252% (43631/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5849, Accuracy: 8851/10000 (88.51%)

Epoch: 196
Loss: 0.134 | Acc: 96.875% (62/64)
Loss: 0.110 | Acc: 97.277% (6288/6464)
Loss: 0.108 | Acc: 97.318% (12519/12864)
Loss: 0.113 | Acc: 97.207% (18726/19264)
Loss: 0.115 | Acc: 97.163% (24936/25664)
Loss: 0.113 | Acc: 97.224% (31174/32064)
Loss: 0.115 | Acc: 97.158% (37371/38464)
Loss: 0.114 | Acc: 97.192% (43604/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5677, Accuracy: 8851/10000 (88.51%)

Epoch: 197
Loss: 0.094 | Acc: 98.438% (63/64)
Loss: 0.111 | Acc: 97.231% (6285/6464)
Loss: 0.115 | Acc: 97.170% (12500/12864)
Loss: 0.115 | Acc: 97.171% (18719/19264)
Loss: 0.115 | Acc: 97.152% (24933/25664)
Loss: 0.117 | Acc: 97.118% (31140/32064)
Loss: 0.117 | Acc: 97.117% (37355/38464)
Loss: 0.118 | Acc: 97.091% (43559/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5663, Accuracy: 8838/10000 (88.38%)
torch.Size([100, 10])
Test set: Average loss: 0.5663, Accuracy: 8838/10000 (88.38%)

Epoch: 198
Loss: 0.035 | Acc: 100.000% (64/64)
Loss: 0.121 | Acc: 96.921% (6265/6464)
Loss: 0.121 | Acc: 97.038% (12483/12864)
Loss: 0.116 | Acc: 97.145% (18714/19264)
Loss: 0.117 | Acc: 97.109% (24922/25664)
Loss: 0.118 | Acc: 97.096% (31133/32064)
Loss: 0.118 | Acc: 97.101% (37349/38464)
Loss: 0.117 | Acc: 97.134% (43578/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5660, Accuracy: 8851/10000 (88.51%)
torch.Size([100, 10])
Test set: Average loss: 0.5660, Accuracy: 8851/10000 (88.51%)

Epoch: 199
Loss: 0.038 | Acc: 100.000% (64/64)
Loss: 0.122 | Acc: 96.875% (6262/6464)
Loss: 0.118 | Acc: 97.046% (12484/12864)
Loss: 0.118 | Acc: 97.005% (18687/19264)
Loss: 0.115 | Acc: 97.101% (24920/25664)
Loss: 0.116 | Acc: 97.090% (31131/32064)
Loss: 0.114 | Acc: 97.151% (37368/38464)
Loss: 0.115 | Acc: 97.140% (43581/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5680, Accuracy: 8855/10000 (88.55%)
torch.Size([100, 10])
Test set: Average loss: 0.5680, Accuracy: 8855/10000 (88.55%)
9045
10000
-0.4663136303424835
