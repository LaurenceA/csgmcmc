==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.355 | Acc: 15.625% (10/64)
Loss: 2.894 | Acc: 15.919% (1029/6464)
Loss: 2.478 | Acc: 19.341% (2488/12864)
Loss: 2.308 | Acc: 21.564% (4154/19264)
Loss: 2.205 | Acc: 23.554% (6045/25664)
Loss: 2.131 | Acc: 25.190% (8077/32064)
Loss: 2.076 | Acc: 26.521% (10201/38464)
Loss: 2.027 | Acc: 27.989% (12557/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1809, Accuracy: 2833/10000 (28.33%)

Epoch: 1
Loss: 2.061 | Acc: 29.688% (19/64)
Loss: 1.683 | Acc: 38.629% (2497/6464)
Loss: 1.666 | Acc: 39.583% (5092/12864)
Loss: 1.649 | Acc: 40.355% (7774/19264)
Loss: 1.636 | Acc: 40.851% (10484/25664)
Loss: 1.619 | Acc: 41.670% (13361/32064)
Loss: 1.604 | Acc: 42.398% (16308/38464)
Loss: 1.590 | Acc: 43.092% (19333/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6553, Accuracy: 4345/10000 (43.45%)

Epoch: 2
Loss: 1.251 | Acc: 54.688% (35/64)
Loss: 1.435 | Acc: 50.263% (3249/6464)
Loss: 1.439 | Acc: 50.459% (6491/12864)
Loss: 1.422 | Acc: 51.100% (9844/19264)
Loss: 1.402 | Acc: 51.796% (13293/25664)
Loss: 1.387 | Acc: 52.523% (16841/32064)
Loss: 1.378 | Acc: 52.985% (20380/38464)
Loss: 1.369 | Acc: 53.312% (23918/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5700, Accuracy: 4935/10000 (49.35%)

Epoch: 3
Loss: 1.179 | Acc: 64.062% (41/64)
Loss: 1.273 | Acc: 57.689% (3729/6464)
Loss: 1.268 | Acc: 57.711% (7424/12864)
Loss: 1.248 | Acc: 58.602% (11289/19264)
Loss: 1.230 | Acc: 59.211% (15196/25664)
Loss: 1.220 | Acc: 59.522% (19085/32064)
Loss: 1.208 | Acc: 59.960% (23063/38464)
Loss: 1.199 | Acc: 60.316% (27060/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8180, Accuracy: 4460/10000 (44.60%)

Epoch: 4
Loss: 1.249 | Acc: 59.375% (38/64)
Loss: 1.112 | Acc: 63.676% (4116/6464)
Loss: 1.104 | Acc: 64.109% (8247/12864)
Loss: 1.097 | Acc: 64.602% (12445/19264)
Loss: 1.090 | Acc: 64.822% (16636/25664)
Loss: 1.084 | Acc: 65.076% (20866/32064)
Loss: 1.075 | Acc: 65.352% (25137/38464)
Loss: 1.068 | Acc: 65.696% (29474/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2481, Accuracy: 5975/10000 (59.75%)

Epoch: 5
Loss: 1.304 | Acc: 59.375% (38/64)
Loss: 0.970 | Acc: 68.502% (4428/6464)
Loss: 0.982 | Acc: 68.680% (8835/12864)
Loss: 0.979 | Acc: 69.077% (13307/19264)
Loss: 0.975 | Acc: 69.350% (17798/25664)
Loss: 0.968 | Acc: 69.586% (22312/32064)
Loss: 0.966 | Acc: 69.728% (26820/38464)
Loss: 0.962 | Acc: 69.940% (31378/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4550, Accuracy: 5537/10000 (55.37%)

Epoch: 6
Loss: 0.957 | Acc: 68.750% (44/64)
Loss: 0.905 | Acc: 72.649% (4696/6464)
Loss: 0.908 | Acc: 72.458% (9321/12864)
Loss: 0.901 | Acc: 72.482% (13963/19264)
Loss: 0.899 | Acc: 72.569% (18624/25664)
Loss: 0.893 | Acc: 72.667% (23300/32064)
Loss: 0.893 | Acc: 72.759% (27986/38464)
Loss: 0.889 | Acc: 72.858% (32687/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8009, Accuracy: 4712/10000 (47.12%)

Epoch: 7
Loss: 1.116 | Acc: 65.625% (42/64)
Loss: 0.851 | Acc: 74.319% (4804/6464)
Loss: 0.856 | Acc: 73.958% (9514/12864)
Loss: 0.856 | Acc: 74.273% (14308/19264)
Loss: 0.853 | Acc: 74.556% (19134/25664)
Loss: 0.847 | Acc: 74.604% (23921/32064)
Loss: 0.848 | Acc: 74.563% (28680/38464)
Loss: 0.841 | Acc: 74.744% (33533/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1250, Accuracy: 6558/10000 (65.58%)

Epoch: 8
Loss: 1.140 | Acc: 60.938% (39/64)
Loss: 0.835 | Acc: 74.938% (4844/6464)
Loss: 0.816 | Acc: 75.451% (9706/12864)
Loss: 0.806 | Acc: 75.857% (14613/19264)
Loss: 0.805 | Acc: 75.912% (19482/25664)
Loss: 0.803 | Acc: 75.876% (24329/32064)
Loss: 0.806 | Acc: 75.887% (29189/38464)
Loss: 0.801 | Acc: 75.992% (34093/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4726, Accuracy: 5504/10000 (55.04%)

Epoch: 9
Loss: 1.033 | Acc: 65.625% (42/64)
Loss: 0.771 | Acc: 77.877% (5034/6464)
Loss: 0.777 | Acc: 77.822% (10011/12864)
Loss: 0.783 | Acc: 77.310% (14893/19264)
Loss: 0.779 | Acc: 77.342% (19849/25664)
Loss: 0.782 | Acc: 77.277% (24778/32064)
Loss: 0.780 | Acc: 77.223% (29703/38464)
Loss: 0.773 | Acc: 77.407% (34728/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1211, Accuracy: 6425/10000 (64.25%)

Epoch: 10
Loss: 0.808 | Acc: 76.562% (49/64)
Loss: 0.760 | Acc: 77.599% (5016/6464)
Loss: 0.743 | Acc: 78.397% (10085/12864)
Loss: 0.752 | Acc: 78.006% (15027/19264)
Loss: 0.747 | Acc: 78.051% (20031/25664)
Loss: 0.751 | Acc: 78.038% (25022/32064)
Loss: 0.751 | Acc: 78.138% (30055/38464)
Loss: 0.752 | Acc: 78.080% (35030/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8258, Accuracy: 7615/10000 (76.15%)

Epoch: 11
Loss: 1.038 | Acc: 65.625% (42/64)
Loss: 0.724 | Acc: 78.403% (5068/6464)
Loss: 0.735 | Acc: 78.521% (10101/12864)
Loss: 0.726 | Acc: 78.945% (15208/19264)
Loss: 0.728 | Acc: 78.928% (20256/25664)
Loss: 0.729 | Acc: 78.836% (25278/32064)
Loss: 0.727 | Acc: 78.900% (30348/38464)
Loss: 0.730 | Acc: 78.885% (35391/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0205, Accuracy: 6934/10000 (69.34%)

Epoch: 12
Loss: 0.766 | Acc: 78.125% (50/64)
Loss: 0.706 | Acc: 79.564% (5143/6464)
Loss: 0.707 | Acc: 79.921% (10281/12864)
Loss: 0.702 | Acc: 80.061% (15423/19264)
Loss: 0.706 | Acc: 79.781% (20475/25664)
Loss: 0.708 | Acc: 79.747% (25570/32064)
Loss: 0.708 | Acc: 79.786% (30689/38464)
Loss: 0.710 | Acc: 79.743% (35776/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5296, Accuracy: 5277/10000 (52.77%)

Epoch: 13
Loss: 0.840 | Acc: 76.562% (49/64)
Loss: 0.702 | Acc: 80.415% (5198/6464)
Loss: 0.703 | Acc: 80.131% (10308/12864)
Loss: 0.696 | Acc: 80.342% (15477/19264)
Loss: 0.699 | Acc: 80.229% (20590/25664)
Loss: 0.693 | Acc: 80.477% (25804/32064)
Loss: 0.695 | Acc: 80.348% (30905/38464)
Loss: 0.695 | Acc: 80.387% (36065/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4201, Accuracy: 5787/10000 (57.87%)

Epoch: 14
Loss: 0.872 | Acc: 71.875% (46/64)
Loss: 0.705 | Acc: 80.121% (5179/6464)
Loss: 0.694 | Acc: 80.169% (10313/12864)
Loss: 0.686 | Acc: 80.347% (15478/19264)
Loss: 0.679 | Acc: 80.627% (20692/25664)
Loss: 0.675 | Acc: 80.841% (25921/32064)
Loss: 0.674 | Acc: 80.873% (31107/38464)
Loss: 0.676 | Acc: 80.869% (36281/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5682, Accuracy: 5406/10000 (54.06%)

Epoch: 15
Loss: 0.983 | Acc: 70.312% (45/64)
Loss: 0.665 | Acc: 81.714% (5282/6464)
Loss: 0.661 | Acc: 81.328% (10462/12864)
Loss: 0.671 | Acc: 80.990% (15602/19264)
Loss: 0.664 | Acc: 81.238% (20849/25664)
Loss: 0.664 | Acc: 81.225% (26044/32064)
Loss: 0.664 | Acc: 81.203% (31234/38464)
Loss: 0.663 | Acc: 81.252% (36453/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9273, Accuracy: 7333/10000 (73.33%)

Epoch: 16
Loss: 0.727 | Acc: 79.688% (51/64)
Loss: 0.621 | Acc: 82.983% (5364/6464)
Loss: 0.622 | Acc: 82.525% (10616/12864)
Loss: 0.631 | Acc: 82.345% (15863/19264)
Loss: 0.638 | Acc: 82.111% (21073/25664)
Loss: 0.636 | Acc: 82.239% (26369/32064)
Loss: 0.637 | Acc: 82.204% (31619/38464)
Loss: 0.639 | Acc: 82.200% (36878/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1845, Accuracy: 6640/10000 (66.40%)

Epoch: 17
Loss: 0.616 | Acc: 81.250% (52/64)
Loss: 0.610 | Acc: 82.859% (5356/6464)
Loss: 0.636 | Acc: 82.012% (10550/12864)
Loss: 0.637 | Acc: 82.190% (15833/19264)
Loss: 0.635 | Acc: 82.286% (21118/25664)
Loss: 0.634 | Acc: 82.401% (26421/32064)
Loss: 0.634 | Acc: 82.371% (31683/38464)
Loss: 0.633 | Acc: 82.369% (36954/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8485, Accuracy: 7601/10000 (76.01%)

Epoch: 18
Loss: 0.660 | Acc: 79.688% (51/64)
Loss: 0.600 | Acc: 83.462% (5395/6464)
Loss: 0.601 | Acc: 83.294% (10715/12864)
Loss: 0.606 | Acc: 83.176% (16023/19264)
Loss: 0.611 | Acc: 83.077% (21321/25664)
Loss: 0.615 | Acc: 83.012% (26617/32064)
Loss: 0.616 | Acc: 82.935% (31900/38464)
Loss: 0.615 | Acc: 82.960% (37219/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8769, Accuracy: 7483/10000 (74.83%)

Epoch: 19
Loss: 0.682 | Acc: 82.812% (53/64)
Loss: 0.605 | Acc: 83.230% (5380/6464)
Loss: 0.596 | Acc: 83.691% (10766/12864)
Loss: 0.588 | Acc: 83.861% (16155/19264)
Loss: 0.592 | Acc: 83.802% (21507/25664)
Loss: 0.600 | Acc: 83.645% (26820/32064)
Loss: 0.603 | Acc: 83.621% (32164/38464)
Loss: 0.603 | Acc: 83.628% (37519/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1550, Accuracy: 6747/10000 (67.47%)

Epoch: 20
Loss: 0.581 | Acc: 87.500% (56/64)
Loss: 0.583 | Acc: 83.648% (5407/6464)
Loss: 0.586 | Acc: 83.885% (10791/12864)
Loss: 0.585 | Acc: 83.965% (16175/19264)
Loss: 0.584 | Acc: 83.985% (21554/25664)
Loss: 0.583 | Acc: 84.051% (26950/32064)
Loss: 0.586 | Acc: 84.068% (32336/38464)
Loss: 0.587 | Acc: 84.063% (37714/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2667, Accuracy: 4224/10000 (42.24%)

Epoch: 21
Loss: 0.634 | Acc: 78.125% (50/64)
Loss: 0.594 | Acc: 83.447% (5394/6464)
Loss: 0.585 | Acc: 83.815% (10782/12864)
Loss: 0.578 | Acc: 84.147% (16210/19264)
Loss: 0.580 | Acc: 84.180% (21604/25664)
Loss: 0.581 | Acc: 84.163% (26986/32064)
Loss: 0.579 | Acc: 84.209% (32390/38464)
Loss: 0.578 | Acc: 84.181% (37767/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9082, Accuracy: 7387/10000 (73.87%)

Epoch: 22
Loss: 0.670 | Acc: 76.562% (49/64)
Loss: 0.552 | Acc: 85.442% (5523/6464)
Loss: 0.566 | Acc: 84.942% (10927/12864)
Loss: 0.562 | Acc: 84.977% (16370/19264)
Loss: 0.566 | Acc: 84.893% (21787/25664)
Loss: 0.564 | Acc: 84.843% (27204/32064)
Loss: 0.565 | Acc: 84.853% (32638/38464)
Loss: 0.562 | Acc: 84.894% (38087/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8726, Accuracy: 7573/10000 (75.73%)

Epoch: 23
Loss: 0.598 | Acc: 81.250% (52/64)
Loss: 0.523 | Acc: 86.324% (5580/6464)
Loss: 0.537 | Acc: 85.922% (11053/12864)
Loss: 0.544 | Acc: 85.543% (16479/19264)
Loss: 0.546 | Acc: 85.431% (21925/25664)
Loss: 0.550 | Acc: 85.364% (27371/32064)
Loss: 0.548 | Acc: 85.379% (32840/38464)
Loss: 0.548 | Acc: 85.394% (38311/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0680, Accuracy: 6826/10000 (68.26%)

Epoch: 24
Loss: 0.811 | Acc: 79.688% (51/64)
Loss: 0.534 | Acc: 85.458% (5524/6464)
Loss: 0.543 | Acc: 85.393% (10985/12864)
Loss: 0.543 | Acc: 85.569% (16484/19264)
Loss: 0.546 | Acc: 85.634% (21977/25664)
Loss: 0.542 | Acc: 85.704% (27480/32064)
Loss: 0.541 | Acc: 85.717% (32970/38464)
Loss: 0.543 | Acc: 85.674% (38437/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0377, Accuracy: 7096/10000 (70.96%)

Epoch: 25
Loss: 0.783 | Acc: 76.562% (49/64)
Loss: 0.524 | Acc: 86.170% (5570/6464)
Loss: 0.528 | Acc: 86.272% (11098/12864)
Loss: 0.525 | Acc: 86.348% (16634/19264)
Loss: 0.523 | Acc: 86.386% (22170/25664)
Loss: 0.521 | Acc: 86.393% (27701/32064)
Loss: 0.524 | Acc: 86.299% (33194/38464)
Loss: 0.527 | Acc: 86.129% (38641/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5273, Accuracy: 5859/10000 (58.59%)

Epoch: 26
Loss: 0.562 | Acc: 85.938% (55/64)
Loss: 0.520 | Acc: 86.108% (5566/6464)
Loss: 0.512 | Acc: 86.559% (11135/12864)
Loss: 0.509 | Acc: 86.534% (16670/19264)
Loss: 0.516 | Acc: 86.397% (22173/25664)
Loss: 0.515 | Acc: 86.399% (27703/32064)
Loss: 0.512 | Acc: 86.538% (33286/38464)
Loss: 0.511 | Acc: 86.557% (38833/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1980, Accuracy: 6738/10000 (67.38%)

Epoch: 27
Loss: 0.583 | Acc: 79.688% (51/64)
Loss: 0.515 | Acc: 86.850% (5614/6464)
Loss: 0.496 | Acc: 87.430% (11247/12864)
Loss: 0.497 | Acc: 87.272% (16812/19264)
Loss: 0.495 | Acc: 87.231% (22387/25664)
Loss: 0.493 | Acc: 87.325% (28000/32064)
Loss: 0.494 | Acc: 87.341% (33595/38464)
Loss: 0.496 | Acc: 87.290% (39162/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7840, Accuracy: 7811/10000 (78.11%)

Epoch: 28
Loss: 0.668 | Acc: 71.875% (46/64)
Loss: 0.466 | Acc: 87.454% (5653/6464)
Loss: 0.481 | Acc: 87.446% (11249/12864)
Loss: 0.477 | Acc: 87.583% (16872/19264)
Loss: 0.482 | Acc: 87.539% (22466/25664)
Loss: 0.484 | Acc: 87.525% (28064/32064)
Loss: 0.486 | Acc: 87.477% (33647/38464)
Loss: 0.485 | Acc: 87.529% (39269/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8676, Accuracy: 7588/10000 (75.88%)

Epoch: 29
Loss: 0.354 | Acc: 87.500% (56/64)
Loss: 0.459 | Acc: 88.351% (5711/6464)
Loss: 0.460 | Acc: 88.472% (11381/12864)
Loss: 0.454 | Acc: 88.590% (17066/19264)
Loss: 0.460 | Acc: 88.400% (22687/25664)
Loss: 0.463 | Acc: 88.217% (28286/32064)
Loss: 0.464 | Acc: 88.212% (33930/38464)
Loss: 0.465 | Acc: 88.209% (39574/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6764, Accuracy: 8161/10000 (81.61%)

Epoch: 30
Loss: 0.457 | Acc: 87.500% (56/64)
Loss: 0.430 | Acc: 89.248% (5769/6464)
Loss: 0.433 | Acc: 89.047% (11455/12864)
Loss: 0.436 | Acc: 89.011% (17147/19264)
Loss: 0.439 | Acc: 88.903% (22816/25664)
Loss: 0.447 | Acc: 88.732% (28451/32064)
Loss: 0.450 | Acc: 88.636% (34093/38464)
Loss: 0.451 | Acc: 88.657% (39775/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8423, Accuracy: 7728/10000 (77.28%)

Epoch: 31
Loss: 0.373 | Acc: 90.625% (58/64)
Loss: 0.430 | Acc: 89.619% (5793/6464)
Loss: 0.434 | Acc: 89.428% (11504/12864)
Loss: 0.435 | Acc: 89.431% (17228/19264)
Loss: 0.435 | Acc: 89.300% (22918/25664)
Loss: 0.436 | Acc: 89.181% (28595/32064)
Loss: 0.432 | Acc: 89.281% (34341/38464)
Loss: 0.435 | Acc: 89.123% (39984/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6172, Accuracy: 8396/10000 (83.96%)

Epoch: 32
Loss: 0.618 | Acc: 87.500% (56/64)
Loss: 0.406 | Acc: 89.712% (5799/6464)
Loss: 0.412 | Acc: 89.708% (11540/12864)
Loss: 0.416 | Acc: 89.670% (17274/19264)
Loss: 0.411 | Acc: 89.733% (23029/25664)
Loss: 0.411 | Acc: 89.749% (28777/32064)
Loss: 0.415 | Acc: 89.653% (34484/38464)
Loss: 0.414 | Acc: 89.718% (40251/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8037, Accuracy: 7886/10000 (78.86%)

Epoch: 33
Loss: 0.317 | Acc: 93.750% (60/64)
Loss: 0.376 | Acc: 90.501% (5850/6464)
Loss: 0.401 | Acc: 90.058% (11585/12864)
Loss: 0.405 | Acc: 89.914% (17321/19264)
Loss: 0.404 | Acc: 89.947% (23084/25664)
Loss: 0.398 | Acc: 90.126% (28898/32064)
Loss: 0.401 | Acc: 90.017% (34624/38464)
Loss: 0.401 | Acc: 90.037% (40394/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6313, Accuracy: 8363/10000 (83.63%)

Epoch: 34
Loss: 0.459 | Acc: 90.625% (58/64)
Loss: 0.390 | Acc: 90.393% (5843/6464)
Loss: 0.379 | Acc: 90.656% (11662/12864)
Loss: 0.375 | Acc: 90.677% (17468/19264)
Loss: 0.377 | Acc: 90.617% (23256/25664)
Loss: 0.376 | Acc: 90.719% (29088/32064)
Loss: 0.378 | Acc: 90.734% (34900/38464)
Loss: 0.379 | Acc: 90.768% (40722/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5582, Accuracy: 8608/10000 (86.08%)

Epoch: 35
Loss: 0.242 | Acc: 95.312% (61/64)
Loss: 0.329 | Acc: 91.971% (5945/6464)
Loss: 0.348 | Acc: 91.760% (11804/12864)
Loss: 0.352 | Acc: 91.622% (17650/19264)
Loss: 0.351 | Acc: 91.634% (23517/25664)
Loss: 0.349 | Acc: 91.682% (29397/32064)
Loss: 0.353 | Acc: 91.564% (35219/38464)
Loss: 0.357 | Acc: 91.450% (41028/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5904, Accuracy: 8517/10000 (85.17%)

Epoch: 36
Loss: 0.218 | Acc: 96.875% (62/64)
Loss: 0.331 | Acc: 92.450% (5976/6464)
Loss: 0.332 | Acc: 92.226% (11864/12864)
Loss: 0.331 | Acc: 92.281% (17777/19264)
Loss: 0.334 | Acc: 92.106% (23638/25664)
Loss: 0.339 | Acc: 91.922% (29474/32064)
Loss: 0.338 | Acc: 91.935% (35362/38464)
Loss: 0.339 | Acc: 91.884% (41223/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6413, Accuracy: 8383/10000 (83.83%)

Epoch: 37
Loss: 0.383 | Acc: 90.625% (58/64)
Loss: 0.316 | Acc: 92.543% (5982/6464)
Loss: 0.311 | Acc: 92.716% (11927/12864)
Loss: 0.311 | Acc: 92.733% (17864/19264)
Loss: 0.303 | Acc: 92.943% (23853/25664)
Loss: 0.313 | Acc: 92.687% (29719/32064)
Loss: 0.317 | Acc: 92.554% (35600/38464)
Loss: 0.320 | Acc: 92.471% (41486/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5539, Accuracy: 8696/10000 (86.96%)

Epoch: 38
Loss: 0.588 | Acc: 87.500% (56/64)
Loss: 0.293 | Acc: 92.992% (6011/6464)
Loss: 0.290 | Acc: 93.074% (11973/12864)
Loss: 0.292 | Acc: 92.997% (17915/19264)
Loss: 0.291 | Acc: 93.072% (23886/25664)
Loss: 0.295 | Acc: 92.977% (29812/32064)
Loss: 0.297 | Acc: 92.874% (35723/38464)
Loss: 0.296 | Acc: 92.907% (41682/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5648, Accuracy: 8723/10000 (87.23%)

Epoch: 39
Loss: 0.147 | Acc: 93.750% (60/64)
Loss: 0.270 | Acc: 93.348% (6034/6464)
Loss: 0.265 | Acc: 93.680% (12051/12864)
Loss: 0.260 | Acc: 93.958% (18100/19264)
Loss: 0.261 | Acc: 93.929% (24106/25664)
Loss: 0.263 | Acc: 93.897% (30107/32064)
Loss: 0.263 | Acc: 93.883% (36111/38464)
Loss: 0.266 | Acc: 93.750% (42060/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6614, Accuracy: 8435/10000 (84.35%)

Epoch: 40
Loss: 0.191 | Acc: 96.875% (62/64)
Loss: 0.252 | Acc: 93.765% (6061/6464)
Loss: 0.243 | Acc: 93.983% (12090/12864)
Loss: 0.248 | Acc: 94.004% (18109/19264)
Loss: 0.250 | Acc: 94.038% (24134/25664)
Loss: 0.246 | Acc: 94.102% (30173/32064)
Loss: 0.246 | Acc: 94.122% (36203/38464)
Loss: 0.247 | Acc: 94.142% (42236/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7563, Accuracy: 8285/10000 (82.85%)

Epoch: 41
Loss: 0.312 | Acc: 90.625% (58/64)
Loss: 0.214 | Acc: 94.895% (6134/6464)
Loss: 0.224 | Acc: 94.675% (12179/12864)
Loss: 0.220 | Acc: 94.819% (18266/19264)
Loss: 0.220 | Acc: 94.853% (24343/25664)
Loss: 0.219 | Acc: 94.854% (30414/32064)
Loss: 0.220 | Acc: 94.816% (36470/38464)
Loss: 0.220 | Acc: 94.829% (42544/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6026, Accuracy: 8676/10000 (86.76%)

Epoch: 42
Loss: 0.098 | Acc: 98.438% (63/64)
Loss: 0.186 | Acc: 95.637% (6182/6464)
Loss: 0.193 | Acc: 95.359% (12267/12864)
Loss: 0.198 | Acc: 95.261% (18351/19264)
Loss: 0.197 | Acc: 95.316% (24462/25664)
Loss: 0.194 | Acc: 95.390% (30586/32064)
Loss: 0.195 | Acc: 95.357% (36678/38464)
Loss: 0.195 | Acc: 95.350% (42778/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6084, Accuracy: 8727/10000 (87.27%)

Epoch: 43
Loss: 0.124 | Acc: 95.312% (61/64)
Loss: 0.166 | Acc: 96.040% (6208/6464)
Loss: 0.174 | Acc: 95.662% (12306/12864)
Loss: 0.169 | Acc: 95.852% (18465/19264)
Loss: 0.171 | Acc: 95.796% (24585/25664)
Loss: 0.169 | Acc: 95.868% (30739/32064)
Loss: 0.171 | Acc: 95.832% (36861/38464)
Loss: 0.169 | Acc: 95.892% (43021/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5859, Accuracy: 8779/10000 (87.79%)

Epoch: 44
Loss: 0.117 | Acc: 98.438% (63/64)
Loss: 0.136 | Acc: 96.411% (6232/6464)
Loss: 0.150 | Acc: 96.191% (12374/12864)
Loss: 0.146 | Acc: 96.304% (18552/19264)
Loss: 0.149 | Acc: 96.279% (24709/25664)
Loss: 0.151 | Acc: 96.211% (30849/32064)
Loss: 0.150 | Acc: 96.228% (37013/38464)
Loss: 0.148 | Acc: 96.287% (43198/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5868, Accuracy: 8840/10000 (88.40%)

Epoch: 45
Loss: 0.160 | Acc: 95.312% (61/64)
Loss: 0.146 | Acc: 96.318% (6226/6464)
Loss: 0.185 | Acc: 95.647% (12304/12864)
Loss: 0.208 | Acc: 95.266% (18352/19264)
Loss: 0.238 | Acc: 94.642% (24289/25664)
Loss: 0.257 | Acc: 94.265% (30225/32064)
Loss: 0.278 | Acc: 93.786% (36074/38464)
Loss: 0.296 | Acc: 93.358% (41884/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5667, Accuracy: 8594/10000 (85.94%)

Epoch: 46
Loss: 0.386 | Acc: 90.625% (58/64)
Loss: 0.446 | Acc: 89.759% (5802/6464)
Loss: 0.447 | Acc: 89.692% (11538/12864)
Loss: 0.450 | Acc: 89.556% (17252/19264)
Loss: 0.455 | Acc: 89.234% (22901/25664)
Loss: 0.460 | Acc: 89.165% (28590/32064)
Loss: 0.465 | Acc: 89.016% (34239/38464)
Loss: 0.471 | Acc: 88.735% (39810/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5969, Accuracy: 8459/10000 (84.59%)

Epoch: 47
Loss: 0.250 | Acc: 93.750% (60/64)
Loss: 0.499 | Acc: 88.212% (5702/6464)
Loss: 0.503 | Acc: 87.733% (11286/12864)
Loss: 0.506 | Acc: 87.630% (16881/19264)
Loss: 0.508 | Acc: 87.477% (22450/25664)
Loss: 0.515 | Acc: 87.213% (27964/32064)
Loss: 0.519 | Acc: 87.105% (33504/38464)
Loss: 0.520 | Acc: 87.070% (39063/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6024, Accuracy: 8456/10000 (84.56%)
torch.Size([100, 10])
Test set: Average loss: 0.6024, Accuracy: 8456/10000 (84.56%)

Epoch: 48
Loss: 0.493 | Acc: 85.938% (55/64)
Loss: 0.526 | Acc: 86.665% (5602/6464)
Loss: 0.521 | Acc: 87.002% (11192/12864)
Loss: 0.524 | Acc: 87.064% (16772/19264)
Loss: 0.528 | Acc: 86.943% (22313/25664)
Loss: 0.531 | Acc: 86.895% (27862/32064)
Loss: 0.534 | Acc: 86.746% (33366/38464)
Loss: 0.535 | Acc: 86.657% (38878/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6084, Accuracy: 8420/10000 (84.20%)
torch.Size([100, 10])
Test set: Average loss: 0.6084, Accuracy: 8420/10000 (84.20%)

Epoch: 49
Loss: 0.727 | Acc: 78.125% (50/64)
Loss: 0.542 | Acc: 86.463% (5589/6464)
Loss: 0.546 | Acc: 86.186% (11087/12864)
Loss: 0.540 | Acc: 86.540% (16671/19264)
Loss: 0.540 | Acc: 86.557% (22214/25664)
Loss: 0.539 | Acc: 86.543% (27749/32064)
Loss: 0.539 | Acc: 86.455% (33254/38464)
Loss: 0.541 | Acc: 86.432% (38777/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6106, Accuracy: 8399/10000 (83.99%)
torch.Size([100, 10])
Test set: Average loss: 0.6106, Accuracy: 8399/10000 (83.99%)

Epoch: 50
Loss: 0.484 | Acc: 85.938% (55/64)
Loss: 1.805 | Acc: 36.046% (2330/6464)
Loss: 1.483 | Acc: 48.935% (6295/12864)
Loss: 1.312 | Acc: 55.913% (10771/19264)
Loss: 1.212 | Acc: 60.209% (15452/25664)
Loss: 1.139 | Acc: 63.089% (20229/32064)
Loss: 1.087 | Acc: 65.188% (25074/38464)
Loss: 1.046 | Acc: 66.811% (29974/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3345, Accuracy: 4364/10000 (43.64%)

Epoch: 51
Loss: 0.989 | Acc: 73.438% (47/64)
Loss: 0.745 | Acc: 78.156% (5052/6464)
Loss: 0.742 | Acc: 78.374% (10082/12864)
Loss: 0.743 | Acc: 78.483% (15119/19264)
Loss: 0.740 | Acc: 78.487% (20143/25664)
Loss: 0.733 | Acc: 78.755% (25252/32064)
Loss: 0.726 | Acc: 79.006% (30389/38464)
Loss: 0.723 | Acc: 79.153% (35511/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0852, Accuracy: 6927/10000 (69.27%)

Epoch: 52
Loss: 0.863 | Acc: 75.000% (48/64)
Loss: 0.678 | Acc: 81.250% (5252/6464)
Loss: 0.671 | Acc: 81.227% (10449/12864)
Loss: 0.664 | Acc: 81.447% (15690/19264)
Loss: 0.665 | Acc: 81.347% (20877/25664)
Loss: 0.667 | Acc: 81.315% (26073/32064)
Loss: 0.665 | Acc: 81.401% (31310/38464)
Loss: 0.667 | Acc: 81.384% (36512/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2200, Accuracy: 6696/10000 (66.96%)

Epoch: 53
Loss: 0.793 | Acc: 70.312% (45/64)
Loss: 0.626 | Acc: 82.379% (5325/6464)
Loss: 0.630 | Acc: 82.400% (10600/12864)
Loss: 0.642 | Acc: 82.112% (15818/19264)
Loss: 0.643 | Acc: 82.057% (21059/25664)
Loss: 0.649 | Acc: 81.933% (26271/32064)
Loss: 0.648 | Acc: 81.884% (31496/38464)
Loss: 0.648 | Acc: 81.932% (36758/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1469, Accuracy: 6737/10000 (67.37%)

Epoch: 54
Loss: 0.845 | Acc: 75.000% (48/64)
Loss: 0.616 | Acc: 83.246% (5381/6464)
Loss: 0.624 | Acc: 82.758% (10646/12864)
Loss: 0.618 | Acc: 82.885% (15967/19264)
Loss: 0.626 | Acc: 82.703% (21225/25664)
Loss: 0.633 | Acc: 82.479% (26446/32064)
Loss: 0.637 | Acc: 82.384% (31688/38464)
Loss: 0.640 | Acc: 82.275% (36912/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1514, Accuracy: 6829/10000 (68.29%)

Epoch: 55
Loss: 0.784 | Acc: 76.562% (49/64)
Loss: 0.636 | Acc: 82.101% (5307/6464)
Loss: 0.632 | Acc: 82.618% (10628/12864)
Loss: 0.628 | Acc: 82.641% (15920/19264)
Loss: 0.633 | Acc: 82.493% (21171/25664)
Loss: 0.626 | Acc: 82.660% (26504/32064)
Loss: 0.627 | Acc: 82.607% (31774/38464)
Loss: 0.629 | Acc: 82.594% (37055/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0641, Accuracy: 6947/10000 (69.47%)

Epoch: 56
Loss: 0.555 | Acc: 85.938% (55/64)
Loss: 0.612 | Acc: 83.338% (5387/6464)
Loss: 0.621 | Acc: 82.929% (10668/12864)
Loss: 0.614 | Acc: 83.108% (16010/19264)
Loss: 0.613 | Acc: 83.085% (21323/25664)
Loss: 0.617 | Acc: 83.025% (26621/32064)
Loss: 0.619 | Acc: 82.909% (31890/38464)
Loss: 0.621 | Acc: 82.824% (37158/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8325, Accuracy: 7576/10000 (75.76%)

Epoch: 57
Loss: 0.620 | Acc: 82.812% (53/64)
Loss: 0.610 | Acc: 82.936% (5361/6464)
Loss: 0.608 | Acc: 83.139% (10695/12864)
Loss: 0.609 | Acc: 83.217% (16031/19264)
Loss: 0.612 | Acc: 83.190% (21350/25664)
Loss: 0.610 | Acc: 83.255% (26695/32064)
Loss: 0.613 | Acc: 83.197% (32001/38464)
Loss: 0.612 | Acc: 83.209% (37331/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3142, Accuracy: 6246/10000 (62.46%)

Epoch: 58
Loss: 0.878 | Acc: 76.562% (49/64)
Loss: 0.612 | Acc: 82.936% (5361/6464)
Loss: 0.613 | Acc: 83.155% (10697/12864)
Loss: 0.608 | Acc: 83.435% (16073/19264)
Loss: 0.608 | Acc: 83.374% (21397/25664)
Loss: 0.606 | Acc: 83.408% (26744/32064)
Loss: 0.606 | Acc: 83.413% (32084/38464)
Loss: 0.610 | Acc: 83.294% (37369/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7261, Accuracy: 7986/10000 (79.86%)

Epoch: 59
Loss: 0.451 | Acc: 89.062% (57/64)
Loss: 0.605 | Acc: 83.803% (5417/6464)
Loss: 0.592 | Acc: 84.103% (10819/12864)
Loss: 0.595 | Acc: 83.913% (16165/19264)
Loss: 0.599 | Acc: 83.767% (21498/25664)
Loss: 0.599 | Acc: 83.723% (26845/32064)
Loss: 0.602 | Acc: 83.668% (32182/38464)
Loss: 0.605 | Acc: 83.606% (37509/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7552, Accuracy: 7898/10000 (78.98%)

Epoch: 60
Loss: 0.580 | Acc: 87.500% (56/64)
Loss: 0.585 | Acc: 83.818% (5418/6464)
Loss: 0.585 | Acc: 83.947% (10799/12864)
Loss: 0.598 | Acc: 83.669% (16118/19264)
Loss: 0.600 | Acc: 83.646% (21467/25664)
Loss: 0.596 | Acc: 83.826% (26878/32064)
Loss: 0.597 | Acc: 83.782% (32226/38464)
Loss: 0.597 | Acc: 83.811% (37601/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8803, Accuracy: 7496/10000 (74.96%)

Epoch: 61
Loss: 0.764 | Acc: 78.125% (50/64)
Loss: 0.574 | Acc: 84.715% (5476/6464)
Loss: 0.582 | Acc: 84.196% (10831/12864)
Loss: 0.590 | Acc: 83.934% (16169/19264)
Loss: 0.595 | Acc: 83.900% (21532/25664)
Loss: 0.595 | Acc: 83.864% (26890/32064)
Loss: 0.595 | Acc: 83.889% (32267/38464)
Loss: 0.594 | Acc: 83.862% (37624/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1113, Accuracy: 6934/10000 (69.34%)

Epoch: 62
Loss: 0.596 | Acc: 84.375% (54/64)
Loss: 0.564 | Acc: 84.607% (5469/6464)
Loss: 0.571 | Acc: 84.725% (10899/12864)
Loss: 0.579 | Acc: 84.588% (16295/19264)
Loss: 0.580 | Acc: 84.453% (21674/25664)
Loss: 0.585 | Acc: 84.297% (27029/32064)
Loss: 0.584 | Acc: 84.302% (32426/38464)
Loss: 0.586 | Acc: 84.170% (37762/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7020, Accuracy: 8079/10000 (80.79%)

Epoch: 63
Loss: 0.335 | Acc: 82.812% (53/64)
Loss: 0.566 | Acc: 84.653% (5472/6464)
Loss: 0.574 | Acc: 84.507% (10871/12864)
Loss: 0.572 | Acc: 84.526% (16283/19264)
Loss: 0.571 | Acc: 84.484% (21682/25664)
Loss: 0.573 | Acc: 84.437% (27074/32064)
Loss: 0.577 | Acc: 84.375% (32454/38464)
Loss: 0.576 | Acc: 84.462% (37893/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2022, Accuracy: 6535/10000 (65.35%)

Epoch: 64
Loss: 0.862 | Acc: 79.688% (51/64)
Loss: 0.575 | Acc: 84.653% (5472/6464)
Loss: 0.556 | Acc: 85.323% (10976/12864)
Loss: 0.557 | Acc: 84.977% (16370/19264)
Loss: 0.561 | Acc: 84.987% (21811/25664)
Loss: 0.563 | Acc: 84.961% (27242/32064)
Loss: 0.565 | Acc: 84.911% (32660/38464)
Loss: 0.571 | Acc: 84.741% (38018/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5490, Accuracy: 5163/10000 (51.63%)

Epoch: 65
Loss: 0.593 | Acc: 85.938% (55/64)
Loss: 0.569 | Acc: 84.406% (5456/6464)
Loss: 0.560 | Acc: 84.966% (10930/12864)
Loss: 0.561 | Acc: 84.899% (16355/19264)
Loss: 0.566 | Acc: 84.823% (21769/25664)
Loss: 0.570 | Acc: 84.771% (27181/32064)
Loss: 0.567 | Acc: 84.788% (32613/38464)
Loss: 0.569 | Acc: 84.812% (38050/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2503, Accuracy: 6282/10000 (62.82%)

Epoch: 66
Loss: 0.636 | Acc: 82.812% (53/64)
Loss: 0.528 | Acc: 86.123% (5567/6464)
Loss: 0.545 | Acc: 85.673% (11021/12864)
Loss: 0.552 | Acc: 85.382% (16448/19264)
Loss: 0.560 | Acc: 85.092% (21838/25664)
Loss: 0.556 | Acc: 85.223% (27326/32064)
Loss: 0.557 | Acc: 85.210% (32775/38464)
Loss: 0.556 | Acc: 85.195% (38222/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4477, Accuracy: 5954/10000 (59.54%)

Epoch: 67
Loss: 0.634 | Acc: 82.812% (53/64)
Loss: 0.567 | Acc: 84.978% (5493/6464)
Loss: 0.547 | Acc: 85.487% (10997/12864)
Loss: 0.544 | Acc: 85.782% (16525/19264)
Loss: 0.544 | Acc: 85.813% (22023/25664)
Loss: 0.546 | Acc: 85.635% (27458/32064)
Loss: 0.549 | Acc: 85.480% (32879/38464)
Loss: 0.554 | Acc: 85.351% (38292/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8445, Accuracy: 7643/10000 (76.43%)

Epoch: 68
Loss: 0.426 | Acc: 85.938% (55/64)
Loss: 0.546 | Acc: 85.272% (5512/6464)
Loss: 0.541 | Acc: 85.463% (10994/12864)
Loss: 0.544 | Acc: 85.424% (16456/19264)
Loss: 0.545 | Acc: 85.388% (21914/25664)
Loss: 0.545 | Acc: 85.401% (27383/32064)
Loss: 0.547 | Acc: 85.366% (32835/38464)
Loss: 0.544 | Acc: 85.396% (38312/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6921, Accuracy: 8130/10000 (81.30%)

Epoch: 69
Loss: 0.772 | Acc: 78.125% (50/64)
Loss: 0.517 | Acc: 86.433% (5587/6464)
Loss: 0.523 | Acc: 86.342% (11107/12864)
Loss: 0.532 | Acc: 86.176% (16601/19264)
Loss: 0.534 | Acc: 86.043% (22082/25664)
Loss: 0.537 | Acc: 85.938% (27555/32064)
Loss: 0.534 | Acc: 85.982% (33072/38464)
Loss: 0.534 | Acc: 85.991% (38579/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2686, Accuracy: 6442/10000 (64.42%)

Epoch: 70
Loss: 0.572 | Acc: 85.938% (55/64)
Loss: 0.510 | Acc: 86.974% (5622/6464)
Loss: 0.509 | Acc: 86.878% (11176/12864)
Loss: 0.509 | Acc: 86.706% (16703/19264)
Loss: 0.509 | Acc: 86.748% (22263/25664)
Loss: 0.514 | Acc: 86.621% (27774/32064)
Loss: 0.519 | Acc: 86.457% (33255/38464)
Loss: 0.524 | Acc: 86.305% (38720/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7334, Accuracy: 7926/10000 (79.26%)

Epoch: 71
Loss: 0.801 | Acc: 81.250% (52/64)
Loss: 0.497 | Acc: 87.515% (5657/6464)
Loss: 0.497 | Acc: 87.368% (11239/12864)
Loss: 0.505 | Acc: 87.085% (16776/19264)
Loss: 0.507 | Acc: 86.916% (22306/25664)
Loss: 0.514 | Acc: 86.786% (27827/32064)
Loss: 0.513 | Acc: 86.730% (33360/38464)
Loss: 0.511 | Acc: 86.740% (38915/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6835, Accuracy: 5193/10000 (51.93%)

Epoch: 72
Loss: 0.582 | Acc: 78.125% (50/64)
Loss: 0.513 | Acc: 86.479% (5590/6464)
Loss: 0.514 | Acc: 86.754% (11160/12864)
Loss: 0.514 | Acc: 86.633% (16689/19264)
Loss: 0.507 | Acc: 86.744% (22262/25664)
Loss: 0.508 | Acc: 86.780% (27825/32064)
Loss: 0.505 | Acc: 86.918% (33432/38464)
Loss: 0.507 | Acc: 86.903% (38988/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9535, Accuracy: 7329/10000 (73.29%)

Epoch: 73
Loss: 0.430 | Acc: 87.500% (56/64)
Loss: 0.468 | Acc: 88.181% (5700/6464)
Loss: 0.483 | Acc: 87.640% (11274/12864)
Loss: 0.492 | Acc: 87.287% (16815/19264)
Loss: 0.496 | Acc: 87.227% (22386/25664)
Loss: 0.498 | Acc: 87.210% (27963/32064)
Loss: 0.495 | Acc: 87.287% (33574/38464)
Loss: 0.498 | Acc: 87.192% (39118/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8529, Accuracy: 7610/10000 (76.10%)

Epoch: 74
Loss: 0.584 | Acc: 79.688% (51/64)
Loss: 0.467 | Acc: 87.454% (5653/6464)
Loss: 0.470 | Acc: 87.803% (11295/12864)
Loss: 0.475 | Acc: 87.760% (16906/19264)
Loss: 0.476 | Acc: 87.749% (22520/25664)
Loss: 0.480 | Acc: 87.675% (28112/32064)
Loss: 0.488 | Acc: 87.477% (33647/38464)
Loss: 0.486 | Acc: 87.491% (39252/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6801, Accuracy: 8145/10000 (81.45%)

Epoch: 75
Loss: 0.464 | Acc: 87.500% (56/64)
Loss: 0.445 | Acc: 88.660% (5731/6464)
Loss: 0.458 | Acc: 88.619% (11400/12864)
Loss: 0.461 | Acc: 88.460% (17041/19264)
Loss: 0.462 | Acc: 88.400% (22687/25664)
Loss: 0.469 | Acc: 88.142% (28262/32064)
Loss: 0.473 | Acc: 88.051% (33868/38464)
Loss: 0.472 | Acc: 88.100% (39525/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6416, Accuracy: 8321/10000 (83.21%)

Epoch: 76
Loss: 0.547 | Acc: 85.938% (55/64)
Loss: 0.462 | Acc: 88.397% (5714/6464)
Loss: 0.459 | Acc: 88.425% (11375/12864)
Loss: 0.464 | Acc: 88.403% (17030/19264)
Loss: 0.465 | Acc: 88.303% (22662/25664)
Loss: 0.465 | Acc: 88.286% (28308/32064)
Loss: 0.466 | Acc: 88.233% (33938/38464)
Loss: 0.462 | Acc: 88.372% (39647/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6707, Accuracy: 8252/10000 (82.52%)

Epoch: 77
Loss: 0.655 | Acc: 84.375% (54/64)
Loss: 0.444 | Acc: 88.815% (5741/6464)
Loss: 0.449 | Acc: 88.845% (11429/12864)
Loss: 0.450 | Acc: 88.725% (17092/19264)
Loss: 0.454 | Acc: 88.533% (22721/25664)
Loss: 0.453 | Acc: 88.610% (28412/32064)
Loss: 0.452 | Acc: 88.537% (34055/38464)
Loss: 0.450 | Acc: 88.574% (39738/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6680, Accuracy: 8270/10000 (82.70%)

Epoch: 78
Loss: 0.464 | Acc: 92.188% (59/64)
Loss: 0.417 | Acc: 89.635% (5794/6464)
Loss: 0.413 | Acc: 89.715% (11541/12864)
Loss: 0.427 | Acc: 89.338% (17210/19264)
Loss: 0.436 | Acc: 89.175% (22886/25664)
Loss: 0.439 | Acc: 89.069% (28559/32064)
Loss: 0.439 | Acc: 89.060% (34256/38464)
Loss: 0.435 | Acc: 89.120% (39983/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6242, Accuracy: 8384/10000 (83.84%)

Epoch: 79
Loss: 0.457 | Acc: 92.188% (59/64)
Loss: 0.407 | Acc: 90.300% (5837/6464)
Loss: 0.403 | Acc: 90.283% (11614/12864)
Loss: 0.405 | Acc: 90.277% (17391/19264)
Loss: 0.411 | Acc: 90.154% (23137/25664)
Loss: 0.414 | Acc: 90.042% (28871/32064)
Loss: 0.412 | Acc: 90.089% (34652/38464)
Loss: 0.415 | Acc: 89.932% (40347/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1599, Accuracy: 6667/10000 (66.67%)

Epoch: 80
Loss: 0.590 | Acc: 85.938% (55/64)
Loss: 0.436 | Acc: 88.923% (5748/6464)
Loss: 0.417 | Acc: 89.638% (11531/12864)
Loss: 0.417 | Acc: 89.696% (17279/19264)
Loss: 0.416 | Acc: 89.737% (23030/25664)
Loss: 0.414 | Acc: 89.848% (28809/32064)
Loss: 0.414 | Acc: 89.855% (34562/38464)
Loss: 0.414 | Acc: 89.874% (40321/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6350, Accuracy: 8321/10000 (83.21%)

Epoch: 81
Loss: 0.179 | Acc: 95.312% (61/64)
Loss: 0.378 | Acc: 90.656% (5860/6464)
Loss: 0.398 | Acc: 90.182% (11601/12864)
Loss: 0.400 | Acc: 90.158% (17368/19264)
Loss: 0.398 | Acc: 90.317% (23179/25664)
Loss: 0.394 | Acc: 90.419% (28992/32064)
Loss: 0.398 | Acc: 90.316% (34739/38464)
Loss: 0.398 | Acc: 90.324% (40523/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5787, Accuracy: 8581/10000 (85.81%)

Epoch: 82
Loss: 0.341 | Acc: 93.750% (60/64)
Loss: 0.395 | Acc: 90.501% (5850/6464)
Loss: 0.377 | Acc: 90.858% (11688/12864)
Loss: 0.363 | Acc: 91.134% (17556/19264)
Loss: 0.371 | Acc: 91.007% (23356/25664)
Loss: 0.375 | Acc: 90.893% (29144/32064)
Loss: 0.377 | Acc: 90.841% (34941/38464)
Loss: 0.379 | Acc: 90.848% (40758/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7957, Accuracy: 7855/10000 (78.55%)

Epoch: 83
Loss: 0.526 | Acc: 84.375% (54/64)
Loss: 0.341 | Acc: 91.863% (5938/6464)
Loss: 0.351 | Acc: 91.713% (11798/12864)
Loss: 0.345 | Acc: 91.793% (17683/19264)
Loss: 0.350 | Acc: 91.615% (23512/25664)
Loss: 0.355 | Acc: 91.427% (29315/32064)
Loss: 0.361 | Acc: 91.340% (35133/38464)
Loss: 0.360 | Acc: 91.392% (41002/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6478, Accuracy: 8352/10000 (83.52%)

Epoch: 84
Loss: 0.258 | Acc: 92.188% (59/64)
Loss: 0.340 | Acc: 92.033% (5949/6464)
Loss: 0.345 | Acc: 91.830% (11813/12864)
Loss: 0.352 | Acc: 91.637% (17653/19264)
Loss: 0.352 | Acc: 91.704% (23535/25664)
Loss: 0.347 | Acc: 91.801% (29435/32064)
Loss: 0.349 | Acc: 91.756% (35293/38464)
Loss: 0.348 | Acc: 91.766% (41170/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5347, Accuracy: 8738/10000 (87.38%)

Epoch: 85
Loss: 0.359 | Acc: 92.188% (59/64)
Loss: 0.319 | Acc: 92.590% (5985/6464)
Loss: 0.315 | Acc: 92.817% (11940/12864)
Loss: 0.317 | Acc: 92.649% (17848/19264)
Loss: 0.316 | Acc: 92.659% (23780/25664)
Loss: 0.318 | Acc: 92.602% (29692/32064)
Loss: 0.320 | Acc: 92.523% (35588/38464)
Loss: 0.323 | Acc: 92.475% (41488/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5996, Accuracy: 8573/10000 (85.73%)

Epoch: 86
Loss: 0.160 | Acc: 95.312% (61/64)
Loss: 0.291 | Acc: 93.209% (6025/6464)
Loss: 0.286 | Acc: 93.322% (12005/12864)
Loss: 0.296 | Acc: 93.096% (17934/19264)
Loss: 0.302 | Acc: 92.963% (23858/25664)
Loss: 0.300 | Acc: 92.973% (29811/32064)
Loss: 0.302 | Acc: 92.900% (35733/38464)
Loss: 0.306 | Acc: 92.765% (41618/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6570, Accuracy: 8369/10000 (83.69%)

Epoch: 87
Loss: 0.315 | Acc: 93.750% (60/64)
Loss: 0.313 | Acc: 92.915% (6006/6464)
Loss: 0.291 | Acc: 93.400% (12015/12864)
Loss: 0.289 | Acc: 93.470% (18006/19264)
Loss: 0.286 | Acc: 93.501% (23996/25664)
Loss: 0.286 | Acc: 93.507% (29982/32064)
Loss: 0.287 | Acc: 93.482% (35957/38464)
Loss: 0.284 | Acc: 93.545% (41968/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5448, Accuracy: 8799/10000 (87.99%)

Epoch: 88
Loss: 0.366 | Acc: 89.062% (57/64)
Loss: 0.258 | Acc: 93.982% (6075/6464)
Loss: 0.261 | Acc: 93.905% (12080/12864)
Loss: 0.261 | Acc: 93.963% (18101/19264)
Loss: 0.261 | Acc: 94.015% (24128/25664)
Loss: 0.261 | Acc: 93.971% (30131/32064)
Loss: 0.260 | Acc: 93.958% (36140/38464)
Loss: 0.264 | Acc: 93.864% (42111/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5688, Accuracy: 8731/10000 (87.31%)

Epoch: 89
Loss: 0.317 | Acc: 90.625% (58/64)
Loss: 0.237 | Acc: 94.415% (6103/6464)
Loss: 0.244 | Acc: 94.271% (12127/12864)
Loss: 0.244 | Acc: 94.222% (18151/19264)
Loss: 0.242 | Acc: 94.288% (24198/25664)
Loss: 0.243 | Acc: 94.302% (30237/32064)
Loss: 0.241 | Acc: 94.392% (36307/38464)
Loss: 0.239 | Acc: 94.457% (42377/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5488, Accuracy: 8814/10000 (88.14%)

Epoch: 90
Loss: 0.108 | Acc: 98.438% (63/64)
Loss: 0.210 | Acc: 95.173% (6152/6464)
Loss: 0.211 | Acc: 95.196% (12246/12864)
Loss: 0.217 | Acc: 95.037% (18308/19264)
Loss: 0.216 | Acc: 95.012% (24384/25664)
Loss: 0.218 | Acc: 94.976% (30453/32064)
Loss: 0.219 | Acc: 94.897% (36501/38464)
Loss: 0.218 | Acc: 94.911% (42581/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5671, Accuracy: 8775/10000 (87.75%)

Epoch: 91
Loss: 0.253 | Acc: 92.188% (59/64)
Loss: 0.203 | Acc: 95.452% (6170/6464)
Loss: 0.197 | Acc: 95.499% (12285/12864)
Loss: 0.193 | Acc: 95.572% (18411/19264)
Loss: 0.192 | Acc: 95.531% (24517/25664)
Loss: 0.195 | Acc: 95.443% (30603/32064)
Loss: 0.196 | Acc: 95.393% (36692/38464)
Loss: 0.196 | Acc: 95.375% (42789/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5711, Accuracy: 8814/10000 (88.14%)

Epoch: 92
Loss: 0.249 | Acc: 93.750% (60/64)
Loss: 0.154 | Acc: 96.318% (6226/6464)
Loss: 0.154 | Acc: 96.339% (12393/12864)
Loss: 0.162 | Acc: 96.169% (18526/19264)
Loss: 0.169 | Acc: 95.994% (24636/25664)
Loss: 0.172 | Acc: 95.967% (30771/32064)
Loss: 0.172 | Acc: 95.939% (36902/38464)
Loss: 0.172 | Acc: 95.959% (43051/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5853, Accuracy: 8846/10000 (88.46%)

Epoch: 93
Loss: 0.196 | Acc: 93.750% (60/64)
Loss: 0.149 | Acc: 96.303% (6225/6464)
Loss: 0.153 | Acc: 96.284% (12386/12864)
Loss: 0.149 | Acc: 96.356% (18562/19264)
Loss: 0.149 | Acc: 96.349% (24727/25664)
Loss: 0.148 | Acc: 96.379% (30903/32064)
Loss: 0.147 | Acc: 96.428% (37090/38464)
Loss: 0.148 | Acc: 96.400% (43249/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5946, Accuracy: 8831/10000 (88.31%)

Epoch: 94
Loss: 0.094 | Acc: 98.438% (63/64)
Loss: 0.136 | Acc: 96.829% (6259/6464)
Loss: 0.138 | Acc: 96.696% (12439/12864)
Loss: 0.135 | Acc: 96.802% (18648/19264)
Loss: 0.135 | Acc: 96.781% (24838/25664)
Loss: 0.134 | Acc: 96.834% (31049/32064)
Loss: 0.133 | Acc: 96.846% (37251/38464)
Loss: 0.131 | Acc: 96.882% (43465/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5897, Accuracy: 8880/10000 (88.80%)

Epoch: 95
Loss: 0.056 | Acc: 98.438% (63/64)
Loss: 0.128 | Acc: 96.952% (6267/6464)
Loss: 0.155 | Acc: 96.409% (12402/12864)
Loss: 0.177 | Acc: 96.029% (18499/19264)
Loss: 0.201 | Acc: 95.519% (24514/25664)
Loss: 0.221 | Acc: 95.147% (30508/32064)
Loss: 0.240 | Acc: 94.694% (36423/38464)
Loss: 0.256 | Acc: 94.354% (42331/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5677, Accuracy: 8640/10000 (86.40%)

Epoch: 96
Loss: 0.393 | Acc: 90.625% (58/64)
Loss: 0.382 | Acc: 91.445% (5911/6464)
Loss: 0.389 | Acc: 91.255% (11739/12864)
Loss: 0.401 | Acc: 90.994% (17529/19264)
Loss: 0.407 | Acc: 90.859% (23318/25664)
Loss: 0.411 | Acc: 90.672% (29073/32064)
Loss: 0.417 | Acc: 90.386% (34766/38464)
Loss: 0.422 | Acc: 90.166% (40452/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5889, Accuracy: 8507/10000 (85.07%)

Epoch: 97
Loss: 0.368 | Acc: 93.750% (60/64)
Loss: 0.465 | Acc: 88.815% (5741/6464)
Loss: 0.459 | Acc: 89.055% (11456/12864)
Loss: 0.459 | Acc: 89.078% (17160/19264)
Loss: 0.461 | Acc: 88.957% (22830/25664)
Loss: 0.466 | Acc: 88.841% (28486/32064)
Loss: 0.466 | Acc: 88.758% (34140/38464)
Loss: 0.469 | Acc: 88.643% (39769/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5960, Accuracy: 8479/10000 (84.79%)
torch.Size([100, 10])
Test set: Average loss: 0.5960, Accuracy: 8479/10000 (84.79%)

Epoch: 98
Loss: 0.264 | Acc: 93.750% (60/64)
Loss: 0.477 | Acc: 88.506% (5721/6464)
Loss: 0.475 | Acc: 88.433% (11376/12864)
Loss: 0.475 | Acc: 88.424% (17034/19264)
Loss: 0.479 | Acc: 88.307% (22663/25664)
Loss: 0.480 | Acc: 88.292% (28310/32064)
Loss: 0.486 | Acc: 88.080% (33879/38464)
Loss: 0.487 | Acc: 88.111% (39530/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5975, Accuracy: 8469/10000 (84.69%)
torch.Size([100, 10])
Test set: Average loss: 0.5975, Accuracy: 8469/10000 (84.69%)

Epoch: 99
Loss: 0.347 | Acc: 92.188% (59/64)
Loss: 0.489 | Acc: 88.258% (5705/6464)
Loss: 0.478 | Acc: 88.402% (11372/12864)
Loss: 0.483 | Acc: 88.180% (16987/19264)
Loss: 0.482 | Acc: 88.221% (22641/25664)
Loss: 0.483 | Acc: 88.252% (28297/32064)
Loss: 0.484 | Acc: 88.184% (33919/38464)
Loss: 0.487 | Acc: 88.102% (39526/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5955, Accuracy: 8499/10000 (84.99%)
torch.Size([100, 10])
Test set: Average loss: 0.5955, Accuracy: 8499/10000 (84.99%)

Epoch: 100
Loss: 0.480 | Acc: 85.938% (55/64)
Loss: 1.870 | Acc: 33.137% (2142/6464)
Loss: 1.565 | Acc: 45.678% (5876/12864)
Loss: 1.373 | Acc: 53.488% (10304/19264)
Loss: 1.254 | Acc: 58.397% (14987/25664)
Loss: 1.165 | Acc: 61.932% (19858/32064)
Loss: 1.103 | Acc: 64.434% (24784/38464)
Loss: 1.054 | Acc: 66.251% (29723/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4165, Accuracy: 5975/10000 (59.75%)

Epoch: 101
Loss: 0.675 | Acc: 79.688% (51/64)
Loss: 0.685 | Acc: 80.446% (5200/6464)
Loss: 0.701 | Acc: 79.921% (10281/12864)
Loss: 0.699 | Acc: 80.015% (15414/19264)
Loss: 0.689 | Acc: 80.428% (20641/25664)
Loss: 0.689 | Acc: 80.545% (25826/32064)
Loss: 0.687 | Acc: 80.600% (31002/38464)
Loss: 0.689 | Acc: 80.599% (36160/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1932, Accuracy: 6380/10000 (63.80%)

Epoch: 102
Loss: 0.435 | Acc: 89.062% (57/64)
Loss: 0.618 | Acc: 83.045% (5368/6464)
Loss: 0.632 | Acc: 82.408% (10601/12864)
Loss: 0.638 | Acc: 82.200% (15835/19264)
Loss: 0.642 | Acc: 82.107% (21072/25664)
Loss: 0.646 | Acc: 82.039% (26305/32064)
Loss: 0.646 | Acc: 82.082% (31572/38464)
Loss: 0.644 | Acc: 82.186% (36872/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0193, Accuracy: 5089/10000 (50.89%)

Epoch: 103
Loss: 0.623 | Acc: 81.250% (52/64)
Loss: 0.625 | Acc: 82.565% (5337/6464)
Loss: 0.623 | Acc: 83.007% (10678/12864)
Loss: 0.621 | Acc: 82.927% (15975/19264)
Loss: 0.621 | Acc: 83.031% (21309/25664)
Loss: 0.621 | Acc: 83.012% (26617/32064)
Loss: 0.620 | Acc: 83.028% (31936/38464)
Loss: 0.618 | Acc: 83.078% (37272/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2150, Accuracy: 4858/10000 (48.58%)

Epoch: 104
Loss: 1.218 | Acc: 62.500% (40/64)
Loss: 0.619 | Acc: 83.354% (5388/6464)
Loss: 0.622 | Acc: 83.186% (10701/12864)
Loss: 0.615 | Acc: 83.441% (16074/19264)
Loss: 0.613 | Acc: 83.413% (21407/25664)
Loss: 0.612 | Acc: 83.467% (26763/32064)
Loss: 0.612 | Acc: 83.410% (32083/38464)
Loss: 0.613 | Acc: 83.383% (37409/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2381, Accuracy: 6148/10000 (61.48%)

Epoch: 105
Loss: 0.772 | Acc: 76.562% (49/64)
Loss: 0.592 | Acc: 84.004% (5430/6464)
Loss: 0.593 | Acc: 83.901% (10793/12864)
Loss: 0.596 | Acc: 83.835% (16150/19264)
Loss: 0.597 | Acc: 83.689% (21478/25664)
Loss: 0.602 | Acc: 83.561% (26793/32064)
Loss: 0.604 | Acc: 83.525% (32127/38464)
Loss: 0.603 | Acc: 83.617% (37514/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5911, Accuracy: 5509/10000 (55.09%)

Epoch: 106
Loss: 0.652 | Acc: 84.375% (54/64)
Loss: 0.600 | Acc: 84.019% (5431/6464)
Loss: 0.589 | Acc: 84.103% (10819/12864)
Loss: 0.587 | Acc: 84.095% (16200/19264)
Loss: 0.591 | Acc: 84.098% (21583/25664)
Loss: 0.599 | Acc: 83.817% (26875/32064)
Loss: 0.602 | Acc: 83.689% (32190/38464)
Loss: 0.603 | Acc: 83.610% (37511/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1725, Accuracy: 6790/10000 (67.90%)

Epoch: 107
Loss: 0.487 | Acc: 84.375% (54/64)
Loss: 0.585 | Acc: 83.834% (5419/6464)
Loss: 0.584 | Acc: 83.924% (10796/12864)
Loss: 0.594 | Acc: 83.866% (16156/19264)
Loss: 0.598 | Acc: 83.740% (21491/25664)
Loss: 0.598 | Acc: 83.651% (26822/32064)
Loss: 0.595 | Acc: 83.699% (32194/38464)
Loss: 0.591 | Acc: 83.911% (37646/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6078, Accuracy: 5810/10000 (58.10%)

Epoch: 108
Loss: 0.896 | Acc: 73.438% (47/64)
Loss: 0.605 | Acc: 83.385% (5390/6464)
Loss: 0.595 | Acc: 83.846% (10786/12864)
Loss: 0.595 | Acc: 83.835% (16150/19264)
Loss: 0.595 | Acc: 83.892% (21530/25664)
Loss: 0.592 | Acc: 83.842% (26883/32064)
Loss: 0.596 | Acc: 83.816% (32239/38464)
Loss: 0.597 | Acc: 83.791% (37592/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0706, Accuracy: 4596/10000 (45.96%)

Epoch: 109
Loss: 0.712 | Acc: 76.562% (49/64)
Loss: 0.588 | Acc: 84.004% (5430/6464)
Loss: 0.592 | Acc: 84.220% (10834/12864)
Loss: 0.586 | Acc: 84.432% (16265/19264)
Loss: 0.579 | Acc: 84.609% (21714/25664)
Loss: 0.583 | Acc: 84.450% (27078/32064)
Loss: 0.585 | Acc: 84.383% (32457/38464)
Loss: 0.586 | Acc: 84.379% (37856/44864)
torch.Size([100, 10])
Test set: Average loss: 4.9382, Accuracy: 1837/10000 (18.37%)

Epoch: 110
Loss: 0.956 | Acc: 71.875% (46/64)
Loss: 0.603 | Acc: 83.648% (5407/6464)
Loss: 0.588 | Acc: 84.150% (10825/12864)
Loss: 0.584 | Acc: 84.282% (16236/19264)
Loss: 0.583 | Acc: 84.344% (21646/25664)
Loss: 0.586 | Acc: 84.260% (27017/32064)
Loss: 0.586 | Acc: 84.258% (32409/38464)
Loss: 0.587 | Acc: 84.210% (37780/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7795, Accuracy: 7784/10000 (77.84%)

Epoch: 111
Loss: 0.690 | Acc: 82.812% (53/64)
Loss: 0.574 | Acc: 85.102% (5501/6464)
Loss: 0.580 | Acc: 84.686% (10894/12864)
Loss: 0.574 | Acc: 84.806% (16337/19264)
Loss: 0.573 | Acc: 84.811% (21766/25664)
Loss: 0.574 | Acc: 84.768% (27180/32064)
Loss: 0.578 | Acc: 84.666% (32566/38464)
Loss: 0.579 | Acc: 84.625% (37966/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4390, Accuracy: 5969/10000 (59.69%)

Epoch: 112
Loss: 1.035 | Acc: 70.312% (45/64)
Loss: 0.565 | Acc: 84.623% (5470/6464)
Loss: 0.559 | Acc: 84.857% (10916/12864)
Loss: 0.566 | Acc: 84.816% (16339/19264)
Loss: 0.567 | Acc: 84.761% (21753/25664)
Loss: 0.569 | Acc: 84.702% (27159/32064)
Loss: 0.571 | Acc: 84.705% (32581/38464)
Loss: 0.572 | Acc: 84.665% (37984/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9824, Accuracy: 7037/10000 (70.37%)

Epoch: 113
Loss: 0.585 | Acc: 82.812% (53/64)
Loss: 0.560 | Acc: 85.551% (5530/6464)
Loss: 0.562 | Acc: 85.222% (10963/12864)
Loss: 0.558 | Acc: 85.309% (16434/19264)
Loss: 0.558 | Acc: 85.185% (21862/25664)
Loss: 0.556 | Acc: 85.114% (27291/32064)
Loss: 0.559 | Acc: 85.048% (32713/38464)
Loss: 0.561 | Acc: 85.044% (38154/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9281, Accuracy: 7317/10000 (73.17%)

Epoch: 114
Loss: 0.554 | Acc: 89.062% (57/64)
Loss: 0.561 | Acc: 85.164% (5505/6464)
Loss: 0.549 | Acc: 85.207% (10961/12864)
Loss: 0.556 | Acc: 84.930% (16361/19264)
Loss: 0.552 | Acc: 85.139% (21850/25664)
Loss: 0.551 | Acc: 85.217% (27324/32064)
Loss: 0.553 | Acc: 85.139% (32748/38464)
Loss: 0.555 | Acc: 85.148% (38201/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5814, Accuracy: 5740/10000 (57.40%)

Epoch: 115
Loss: 1.008 | Acc: 65.625% (42/64)
Loss: 0.538 | Acc: 85.350% (5517/6464)
Loss: 0.528 | Acc: 86.000% (11063/12864)
Loss: 0.540 | Acc: 85.745% (16518/19264)
Loss: 0.542 | Acc: 85.649% (21981/25664)
Loss: 0.544 | Acc: 85.498% (27414/32064)
Loss: 0.546 | Acc: 85.475% (32877/38464)
Loss: 0.548 | Acc: 85.487% (38353/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0269, Accuracy: 7220/10000 (72.20%)

Epoch: 116
Loss: 0.507 | Acc: 89.062% (57/64)
Loss: 0.526 | Acc: 86.371% (5583/6464)
Loss: 0.538 | Acc: 85.922% (11053/12864)
Loss: 0.546 | Acc: 85.725% (16514/19264)
Loss: 0.541 | Acc: 85.770% (22012/25664)
Loss: 0.546 | Acc: 85.694% (27477/32064)
Loss: 0.545 | Acc: 85.722% (32972/38464)
Loss: 0.548 | Acc: 85.572% (38391/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9313, Accuracy: 7429/10000 (74.29%)

Epoch: 117
Loss: 0.518 | Acc: 84.375% (54/64)
Loss: 0.538 | Acc: 86.092% (5565/6464)
Loss: 0.532 | Acc: 85.844% (11043/12864)
Loss: 0.522 | Acc: 86.135% (16593/19264)
Loss: 0.527 | Acc: 86.023% (22077/25664)
Loss: 0.533 | Acc: 85.881% (27537/32064)
Loss: 0.536 | Acc: 85.800% (33002/38464)
Loss: 0.536 | Acc: 85.775% (38482/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7008, Accuracy: 8075/10000 (80.75%)

Epoch: 118
Loss: 0.688 | Acc: 82.812% (53/64)
Loss: 0.529 | Acc: 86.402% (5585/6464)
Loss: 0.529 | Acc: 86.077% (11073/12864)
Loss: 0.521 | Acc: 86.275% (16620/19264)
Loss: 0.524 | Acc: 86.202% (22123/25664)
Loss: 0.526 | Acc: 86.134% (27618/32064)
Loss: 0.528 | Acc: 86.049% (33098/38464)
Loss: 0.531 | Acc: 85.964% (38567/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1340, Accuracy: 6646/10000 (66.46%)

Epoch: 119
Loss: 0.487 | Acc: 89.062% (57/64)
Loss: 0.538 | Acc: 85.907% (5553/6464)
Loss: 0.519 | Acc: 86.194% (11088/12864)
Loss: 0.517 | Acc: 86.394% (16643/19264)
Loss: 0.520 | Acc: 86.351% (22161/25664)
Loss: 0.523 | Acc: 86.380% (27697/32064)
Loss: 0.521 | Acc: 86.429% (33244/38464)
Loss: 0.524 | Acc: 86.310% (38722/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2213, Accuracy: 6533/10000 (65.33%)

Epoch: 120
Loss: 0.636 | Acc: 79.688% (51/64)
Loss: 0.531 | Acc: 86.200% (5572/6464)
Loss: 0.520 | Acc: 86.373% (11111/12864)
Loss: 0.518 | Acc: 86.529% (16669/19264)
Loss: 0.519 | Acc: 86.545% (22211/25664)
Loss: 0.517 | Acc: 86.670% (27790/32064)
Loss: 0.516 | Acc: 86.626% (33320/38464)
Loss: 0.514 | Acc: 86.666% (38882/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2259, Accuracy: 7022/10000 (70.22%)

Epoch: 121
Loss: 0.468 | Acc: 84.375% (54/64)
Loss: 0.461 | Acc: 88.490% (5720/6464)
Loss: 0.478 | Acc: 87.780% (11292/12864)
Loss: 0.490 | Acc: 87.360% (16829/19264)
Loss: 0.499 | Acc: 87.180% (22374/25664)
Loss: 0.497 | Acc: 87.201% (27960/32064)
Loss: 0.501 | Acc: 87.141% (33518/38464)
Loss: 0.502 | Acc: 87.074% (39065/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8450, Accuracy: 7595/10000 (75.95%)

Epoch: 122
Loss: 0.745 | Acc: 78.125% (50/64)
Loss: 0.477 | Acc: 87.763% (5673/6464)
Loss: 0.468 | Acc: 87.966% (11316/12864)
Loss: 0.473 | Acc: 87.822% (16918/19264)
Loss: 0.478 | Acc: 87.707% (22509/25664)
Loss: 0.486 | Acc: 87.587% (28084/32064)
Loss: 0.485 | Acc: 87.568% (33682/38464)
Loss: 0.489 | Acc: 87.484% (39249/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7505, Accuracy: 7978/10000 (79.78%)

Epoch: 123
Loss: 0.482 | Acc: 82.812% (53/64)
Loss: 0.477 | Acc: 88.196% (5701/6464)
Loss: 0.487 | Acc: 87.819% (11297/12864)
Loss: 0.484 | Acc: 87.786% (16911/19264)
Loss: 0.482 | Acc: 87.944% (22570/25664)
Loss: 0.481 | Acc: 87.909% (28187/32064)
Loss: 0.482 | Acc: 87.872% (33799/38464)
Loss: 0.483 | Acc: 87.801% (39391/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6328, Accuracy: 8369/10000 (83.69%)

Epoch: 124
Loss: 0.477 | Acc: 90.625% (58/64)
Loss: 0.455 | Acc: 88.830% (5742/6464)
Loss: 0.460 | Acc: 88.650% (11404/12864)
Loss: 0.460 | Acc: 88.590% (17066/19264)
Loss: 0.464 | Acc: 88.396% (22686/25664)
Loss: 0.469 | Acc: 88.189% (28277/32064)
Loss: 0.470 | Acc: 88.194% (33923/38464)
Loss: 0.472 | Acc: 88.142% (39544/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9443, Accuracy: 7457/10000 (74.57%)

Epoch: 125
Loss: 0.490 | Acc: 85.938% (55/64)
Loss: 0.441 | Acc: 88.506% (5721/6464)
Loss: 0.443 | Acc: 88.643% (11403/12864)
Loss: 0.453 | Acc: 88.491% (17047/19264)
Loss: 0.453 | Acc: 88.525% (22719/25664)
Loss: 0.458 | Acc: 88.423% (28352/32064)
Loss: 0.457 | Acc: 88.467% (34028/38464)
Loss: 0.462 | Acc: 88.416% (39667/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8850, Accuracy: 7423/10000 (74.23%)

Epoch: 126
Loss: 0.457 | Acc: 89.062% (57/64)
Loss: 0.439 | Acc: 88.722% (5735/6464)
Loss: 0.433 | Acc: 89.218% (11477/12864)
Loss: 0.446 | Acc: 88.948% (17135/19264)
Loss: 0.452 | Acc: 88.646% (22750/25664)
Loss: 0.450 | Acc: 88.645% (28423/32064)
Loss: 0.451 | Acc: 88.634% (34092/38464)
Loss: 0.451 | Acc: 88.668% (39780/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7667, Accuracy: 8004/10000 (80.04%)

Epoch: 127
Loss: 0.640 | Acc: 84.375% (54/64)
Loss: 0.439 | Acc: 88.985% (5752/6464)
Loss: 0.445 | Acc: 88.961% (11444/12864)
Loss: 0.446 | Acc: 88.995% (17144/19264)
Loss: 0.446 | Acc: 88.883% (22811/25664)
Loss: 0.444 | Acc: 88.960% (28524/32064)
Loss: 0.442 | Acc: 89.047% (34251/38464)
Loss: 0.439 | Acc: 89.138% (39991/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6857, Accuracy: 8199/10000 (81.99%)

Epoch: 128
Loss: 0.535 | Acc: 85.938% (55/64)
Loss: 0.407 | Acc: 90.347% (5840/6464)
Loss: 0.422 | Acc: 89.871% (11561/12864)
Loss: 0.423 | Acc: 89.820% (17303/19264)
Loss: 0.430 | Acc: 89.627% (23002/25664)
Loss: 0.431 | Acc: 89.518% (28703/32064)
Loss: 0.432 | Acc: 89.489% (34421/38464)
Loss: 0.431 | Acc: 89.439% (40126/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6747, Accuracy: 8240/10000 (82.40%)

Epoch: 129
Loss: 0.412 | Acc: 92.188% (59/64)
Loss: 0.408 | Acc: 89.975% (5816/6464)
Loss: 0.413 | Acc: 89.832% (11556/12864)
Loss: 0.401 | Acc: 90.127% (17362/19264)
Loss: 0.404 | Acc: 90.134% (23132/25664)
Loss: 0.408 | Acc: 90.095% (28888/32064)
Loss: 0.416 | Acc: 89.926% (34589/38464)
Loss: 0.415 | Acc: 90.021% (40387/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9692, Accuracy: 7442/10000 (74.42%)

Epoch: 130
Loss: 0.434 | Acc: 90.625% (58/64)
Loss: 0.404 | Acc: 90.393% (5843/6464)
Loss: 0.409 | Acc: 90.205% (11604/12864)
Loss: 0.400 | Acc: 90.464% (17427/19264)
Loss: 0.400 | Acc: 90.395% (23199/25664)
Loss: 0.398 | Acc: 90.513% (29022/32064)
Loss: 0.400 | Acc: 90.453% (34792/38464)
Loss: 0.401 | Acc: 90.442% (40576/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8335, Accuracy: 7667/10000 (76.67%)

Epoch: 131
Loss: 0.647 | Acc: 82.812% (53/64)
Loss: 0.368 | Acc: 90.842% (5872/6464)
Loss: 0.379 | Acc: 90.850% (11687/12864)
Loss: 0.372 | Acc: 91.025% (17535/19264)
Loss: 0.375 | Acc: 90.921% (23334/25664)
Loss: 0.381 | Acc: 90.837% (29126/32064)
Loss: 0.382 | Acc: 90.794% (34923/38464)
Loss: 0.385 | Acc: 90.752% (40715/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5900, Accuracy: 8535/10000 (85.35%)

Epoch: 132
Loss: 0.416 | Acc: 92.188% (59/64)
Loss: 0.332 | Acc: 92.017% (5948/6464)
Loss: 0.356 | Acc: 91.737% (11801/12864)
Loss: 0.361 | Acc: 91.487% (17624/19264)
Loss: 0.372 | Acc: 91.143% (23391/25664)
Loss: 0.375 | Acc: 91.087% (29206/32064)
Loss: 0.374 | Acc: 91.158% (35063/38464)
Loss: 0.376 | Acc: 91.091% (40867/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6328, Accuracy: 8413/10000 (84.13%)

Epoch: 133
Loss: 0.380 | Acc: 92.188% (59/64)
Loss: 0.328 | Acc: 92.079% (5952/6464)
Loss: 0.342 | Acc: 91.814% (11811/12864)
Loss: 0.347 | Acc: 91.866% (17697/19264)
Loss: 0.352 | Acc: 91.767% (23551/25664)
Loss: 0.352 | Acc: 91.713% (29407/32064)
Loss: 0.353 | Acc: 91.712% (35276/38464)
Loss: 0.356 | Acc: 91.624% (41106/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8418, Accuracy: 8012/10000 (80.12%)

Epoch: 134
Loss: 0.185 | Acc: 95.312% (61/64)
Loss: 0.336 | Acc: 92.110% (5954/6464)
Loss: 0.330 | Acc: 92.320% (11876/12864)
Loss: 0.327 | Acc: 92.463% (17812/19264)
Loss: 0.335 | Acc: 92.246% (23674/25664)
Loss: 0.339 | Acc: 92.150% (29547/32064)
Loss: 0.340 | Acc: 92.136% (35439/38464)
Loss: 0.334 | Acc: 92.252% (41388/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6361, Accuracy: 8426/10000 (84.26%)

Epoch: 135
Loss: 0.290 | Acc: 93.750% (60/64)
Loss: 0.292 | Acc: 93.363% (6035/6464)
Loss: 0.295 | Acc: 93.175% (11986/12864)
Loss: 0.302 | Acc: 93.008% (17917/19264)
Loss: 0.313 | Acc: 92.784% (23812/25664)
Loss: 0.315 | Acc: 92.743% (29737/32064)
Loss: 0.318 | Acc: 92.663% (35642/38464)
Loss: 0.317 | Acc: 92.622% (41554/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5927, Accuracy: 8566/10000 (85.66%)

Epoch: 136
Loss: 0.213 | Acc: 93.750% (60/64)
Loss: 0.298 | Acc: 92.961% (6009/6464)
Loss: 0.298 | Acc: 93.058% (11971/12864)
Loss: 0.291 | Acc: 93.283% (17970/19264)
Loss: 0.297 | Acc: 93.103% (23894/25664)
Loss: 0.301 | Acc: 92.980% (29813/32064)
Loss: 0.303 | Acc: 92.973% (35761/38464)
Loss: 0.301 | Acc: 93.017% (41731/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6327, Accuracy: 8481/10000 (84.81%)

Epoch: 137
Loss: 0.254 | Acc: 95.312% (61/64)
Loss: 0.286 | Acc: 93.255% (6028/6464)
Loss: 0.277 | Acc: 93.688% (12052/12864)
Loss: 0.273 | Acc: 93.776% (18065/19264)
Loss: 0.272 | Acc: 93.785% (24069/25664)
Loss: 0.275 | Acc: 93.741% (30057/32064)
Loss: 0.276 | Acc: 93.719% (36048/38464)
Loss: 0.276 | Acc: 93.692% (42034/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6307, Accuracy: 8476/10000 (84.76%)

Epoch: 138
Loss: 0.344 | Acc: 90.625% (58/64)
Loss: 0.260 | Acc: 94.276% (6094/6464)
Loss: 0.262 | Acc: 94.154% (12112/12864)
Loss: 0.255 | Acc: 94.352% (18176/19264)
Loss: 0.257 | Acc: 94.194% (24174/25664)
Loss: 0.256 | Acc: 94.240% (30217/32064)
Loss: 0.253 | Acc: 94.283% (36265/38464)
Loss: 0.257 | Acc: 94.223% (42272/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6682, Accuracy: 8442/10000 (84.42%)

Epoch: 139
Loss: 0.440 | Acc: 89.062% (57/64)
Loss: 0.236 | Acc: 94.941% (6137/6464)
Loss: 0.232 | Acc: 94.838% (12200/12864)
Loss: 0.232 | Acc: 94.814% (18265/19264)
Loss: 0.236 | Acc: 94.701% (24304/25664)
Loss: 0.237 | Acc: 94.636% (30344/32064)
Loss: 0.238 | Acc: 94.595% (36385/38464)
Loss: 0.236 | Acc: 94.648% (42463/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5720, Accuracy: 8784/10000 (87.84%)

Epoch: 140
Loss: 0.324 | Acc: 92.188% (59/64)
Loss: 0.210 | Acc: 95.065% (6145/6464)
Loss: 0.208 | Acc: 95.134% (12238/12864)
Loss: 0.213 | Acc: 95.100% (18320/19264)
Loss: 0.214 | Acc: 95.055% (24395/25664)
Loss: 0.213 | Acc: 95.116% (30498/32064)
Loss: 0.212 | Acc: 95.183% (36611/38464)
Loss: 0.214 | Acc: 95.083% (42658/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5629, Accuracy: 8838/10000 (88.38%)

Epoch: 141
Loss: 0.225 | Acc: 93.750% (60/64)
Loss: 0.178 | Acc: 95.916% (6200/6464)
Loss: 0.193 | Acc: 95.577% (12295/12864)
Loss: 0.188 | Acc: 95.691% (18434/19264)
Loss: 0.190 | Acc: 95.632% (24543/25664)
Loss: 0.187 | Acc: 95.734% (30696/32064)
Loss: 0.187 | Acc: 95.710% (36814/38464)
Loss: 0.190 | Acc: 95.618% (42898/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6043, Accuracy: 8721/10000 (87.21%)

Epoch: 142
Loss: 0.050 | Acc: 100.000% (64/64)
Loss: 0.164 | Acc: 96.225% (6220/6464)
Loss: 0.166 | Acc: 96.137% (12367/12864)
Loss: 0.168 | Acc: 96.050% (18503/19264)
Loss: 0.166 | Acc: 96.103% (24664/25664)
Loss: 0.164 | Acc: 96.142% (30827/32064)
Loss: 0.165 | Acc: 96.134% (36977/38464)
Loss: 0.166 | Acc: 96.093% (43111/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5704, Accuracy: 8851/10000 (88.51%)

Epoch: 143
Loss: 0.142 | Acc: 96.875% (62/64)
Loss: 0.160 | Acc: 96.256% (6222/6464)
Loss: 0.155 | Acc: 96.331% (12392/12864)
Loss: 0.153 | Acc: 96.408% (18572/19264)
Loss: 0.155 | Acc: 96.318% (24719/25664)
Loss: 0.154 | Acc: 96.376% (30902/32064)
Loss: 0.150 | Acc: 96.462% (37103/38464)
Loss: 0.151 | Acc: 96.463% (43277/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5928, Accuracy: 8842/10000 (88.42%)

Epoch: 144
Loss: 0.137 | Acc: 96.875% (62/64)
Loss: 0.132 | Acc: 96.875% (6262/6464)
Loss: 0.129 | Acc: 96.922% (12468/12864)
Loss: 0.133 | Acc: 96.833% (18654/19264)
Loss: 0.133 | Acc: 96.840% (24853/25664)
Loss: 0.132 | Acc: 96.853% (31055/32064)
Loss: 0.132 | Acc: 96.839% (37248/38464)
Loss: 0.132 | Acc: 96.815% (43435/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5999, Accuracy: 8831/10000 (88.31%)

Epoch: 145
Loss: 0.033 | Acc: 100.000% (64/64)
Loss: 0.139 | Acc: 96.643% (6247/6464)
Loss: 0.156 | Acc: 96.339% (12393/12864)
Loss: 0.176 | Acc: 95.967% (18487/19264)
Loss: 0.194 | Acc: 95.519% (24514/25664)
Loss: 0.209 | Acc: 95.210% (30528/32064)
Loss: 0.227 | Acc: 94.839% (36479/38464)
Loss: 0.240 | Acc: 94.541% (42415/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5618, Accuracy: 8595/10000 (85.95%)

Epoch: 146
Loss: 0.463 | Acc: 92.188% (59/64)
Loss: 0.348 | Acc: 92.110% (5954/6464)
Loss: 0.357 | Acc: 91.970% (11831/12864)
Loss: 0.372 | Acc: 91.632% (17652/19264)
Loss: 0.377 | Acc: 91.463% (23473/25664)
Loss: 0.386 | Acc: 91.133% (29221/32064)
Loss: 0.394 | Acc: 90.804% (34927/38464)
Loss: 0.398 | Acc: 90.685% (40685/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5808, Accuracy: 8509/10000 (85.09%)

Epoch: 147
Loss: 0.425 | Acc: 90.625% (58/64)
Loss: 0.434 | Acc: 89.217% (5767/6464)
Loss: 0.442 | Acc: 89.187% (11473/12864)
Loss: 0.446 | Acc: 89.083% (17161/19264)
Loss: 0.440 | Acc: 89.222% (22898/25664)
Loss: 0.444 | Acc: 89.122% (28576/32064)
Loss: 0.446 | Acc: 89.114% (34277/38464)
Loss: 0.449 | Acc: 88.978% (39919/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5954, Accuracy: 8443/10000 (84.43%)
torch.Size([100, 10])
Test set: Average loss: 0.5954, Accuracy: 8443/10000 (84.43%)

Epoch: 148
Loss: 0.203 | Acc: 98.438% (63/64)
Loss: 0.457 | Acc: 88.753% (5737/6464)
Loss: 0.460 | Acc: 88.853% (11430/12864)
Loss: 0.463 | Acc: 88.793% (17105/19264)
Loss: 0.463 | Acc: 88.657% (22753/25664)
Loss: 0.463 | Acc: 88.698% (28440/32064)
Loss: 0.463 | Acc: 88.673% (34107/38464)
Loss: 0.462 | Acc: 88.664% (39778/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5911, Accuracy: 8470/10000 (84.70%)
torch.Size([100, 10])
Test set: Average loss: 0.5911, Accuracy: 8470/10000 (84.70%)

Epoch: 149
Loss: 0.563 | Acc: 87.500% (56/64)
Loss: 0.456 | Acc: 88.985% (5752/6464)
Loss: 0.453 | Acc: 89.117% (11464/12864)
Loss: 0.463 | Acc: 88.642% (17076/19264)
Loss: 0.463 | Acc: 88.688% (22761/25664)
Loss: 0.462 | Acc: 88.610% (28412/32064)
Loss: 0.467 | Acc: 88.491% (34037/38464)
Loss: 0.464 | Acc: 88.550% (39727/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5962, Accuracy: 8453/10000 (84.53%)
torch.Size([100, 10])
Test set: Average loss: 0.5962, Accuracy: 8453/10000 (84.53%)

Epoch: 150
Loss: 0.491 | Acc: 84.375% (54/64)
Loss: 1.886 | Acc: 32.132% (2077/6464)
Loss: 1.589 | Acc: 43.983% (5658/12864)
Loss: 1.420 | Acc: 51.204% (9864/19264)
Loss: 1.292 | Acc: 56.515% (14504/25664)
Loss: 1.194 | Acc: 60.526% (19407/32064)
Loss: 1.126 | Acc: 63.319% (24355/38464)
Loss: 1.074 | Acc: 65.402% (29342/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5216, Accuracy: 5272/10000 (52.72%)

Epoch: 151
Loss: 0.606 | Acc: 79.688% (51/64)
Loss: 0.699 | Acc: 80.028% (5173/6464)
Loss: 0.692 | Acc: 80.107% (10305/12864)
Loss: 0.698 | Acc: 80.020% (15415/19264)
Loss: 0.692 | Acc: 80.299% (20608/25664)
Loss: 0.687 | Acc: 80.579% (25837/32064)
Loss: 0.684 | Acc: 80.636% (31016/38464)
Loss: 0.682 | Acc: 80.688% (36200/44864)
torch.Size([100, 10])
Test set: Average loss: 2.6003, Accuracy: 3851/10000 (38.51%)

Epoch: 152
Loss: 0.929 | Acc: 68.750% (44/64)
Loss: 0.639 | Acc: 81.915% (5295/6464)
Loss: 0.619 | Acc: 82.696% (10638/12864)
Loss: 0.627 | Acc: 82.662% (15924/19264)
Loss: 0.630 | Acc: 82.532% (21181/25664)
Loss: 0.634 | Acc: 82.473% (26444/32064)
Loss: 0.636 | Acc: 82.495% (31731/38464)
Loss: 0.633 | Acc: 82.583% (37050/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4286, Accuracy: 4219/10000 (42.19%)

Epoch: 153
Loss: 0.954 | Acc: 70.312% (45/64)
Loss: 0.629 | Acc: 82.410% (5327/6464)
Loss: 0.612 | Acc: 83.022% (10680/12864)
Loss: 0.613 | Acc: 83.088% (16006/19264)
Loss: 0.609 | Acc: 83.303% (21379/25664)
Loss: 0.613 | Acc: 83.199% (26677/32064)
Loss: 0.616 | Acc: 83.143% (31980/38464)
Loss: 0.615 | Acc: 83.223% (37337/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0131, Accuracy: 7021/10000 (70.21%)

Epoch: 154
Loss: 0.713 | Acc: 84.375% (54/64)
Loss: 0.620 | Acc: 82.766% (5350/6464)
Loss: 0.612 | Acc: 83.256% (10710/12864)
Loss: 0.613 | Acc: 83.352% (16057/19264)
Loss: 0.607 | Acc: 83.689% (21478/25664)
Loss: 0.605 | Acc: 83.748% (26853/32064)
Loss: 0.607 | Acc: 83.611% (32160/38464)
Loss: 0.604 | Acc: 83.684% (37544/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7304, Accuracy: 5361/10000 (53.61%)

Epoch: 155
Loss: 1.030 | Acc: 73.438% (47/64)
Loss: 0.611 | Acc: 83.617% (5405/6464)
Loss: 0.610 | Acc: 83.512% (10743/12864)
Loss: 0.599 | Acc: 83.752% (16134/19264)
Loss: 0.597 | Acc: 83.833% (21515/25664)
Loss: 0.594 | Acc: 83.917% (26907/32064)
Loss: 0.596 | Acc: 83.858% (32255/38464)
Loss: 0.600 | Acc: 83.798% (37595/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0887, Accuracy: 6857/10000 (68.57%)

Epoch: 156
Loss: 0.546 | Acc: 85.938% (55/64)
Loss: 0.567 | Acc: 84.421% (5457/6464)
Loss: 0.570 | Acc: 84.523% (10873/12864)
Loss: 0.575 | Acc: 84.370% (16253/19264)
Loss: 0.578 | Acc: 84.324% (21641/25664)
Loss: 0.579 | Acc: 84.325% (27038/32064)
Loss: 0.586 | Acc: 84.162% (32372/38464)
Loss: 0.586 | Acc: 84.208% (37779/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2514, Accuracy: 6452/10000 (64.52%)

Epoch: 157
Loss: 0.571 | Acc: 87.500% (56/64)
Loss: 0.583 | Acc: 84.127% (5438/6464)
Loss: 0.576 | Acc: 84.056% (10813/12864)
Loss: 0.588 | Acc: 84.017% (16185/19264)
Loss: 0.588 | Acc: 84.083% (21579/25664)
Loss: 0.589 | Acc: 84.041% (26947/32064)
Loss: 0.588 | Acc: 84.076% (32339/38464)
Loss: 0.590 | Acc: 84.027% (37698/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8807, Accuracy: 7508/10000 (75.08%)

Epoch: 158
Loss: 0.646 | Acc: 82.812% (53/64)
Loss: 0.568 | Acc: 84.777% (5480/6464)
Loss: 0.566 | Acc: 84.437% (10862/12864)
Loss: 0.575 | Acc: 84.167% (16214/19264)
Loss: 0.575 | Acc: 84.394% (21659/25664)
Loss: 0.579 | Acc: 84.338% (27042/32064)
Loss: 0.579 | Acc: 84.359% (32448/38464)
Loss: 0.583 | Acc: 84.255% (37800/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8946, Accuracy: 7436/10000 (74.36%)

Epoch: 159
Loss: 0.496 | Acc: 84.375% (54/64)
Loss: 0.564 | Acc: 84.731% (5477/6464)
Loss: 0.571 | Acc: 84.554% (10877/12864)
Loss: 0.569 | Acc: 84.801% (16336/19264)
Loss: 0.572 | Acc: 84.648% (21724/25664)
Loss: 0.569 | Acc: 84.706% (27160/32064)
Loss: 0.572 | Acc: 84.640% (32556/38464)
Loss: 0.576 | Acc: 84.486% (37904/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4057, Accuracy: 6474/10000 (64.74%)

Epoch: 160
Loss: 0.687 | Acc: 73.438% (47/64)
Loss: 0.578 | Acc: 84.684% (5474/6464)
Loss: 0.585 | Acc: 84.624% (10886/12864)
Loss: 0.575 | Acc: 84.681% (16313/19264)
Loss: 0.575 | Acc: 84.601% (21712/25664)
Loss: 0.567 | Acc: 84.902% (27223/32064)
Loss: 0.571 | Acc: 84.747% (32597/38464)
Loss: 0.570 | Acc: 84.796% (38043/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3872, Accuracy: 6153/10000 (61.53%)

Epoch: 161
Loss: 0.987 | Acc: 78.125% (50/64)
Loss: 0.547 | Acc: 85.613% (5534/6464)
Loss: 0.549 | Acc: 85.362% (10981/12864)
Loss: 0.556 | Acc: 85.278% (16428/19264)
Loss: 0.559 | Acc: 85.178% (21860/25664)
Loss: 0.569 | Acc: 85.024% (27262/32064)
Loss: 0.569 | Acc: 84.978% (32686/38464)
Loss: 0.569 | Acc: 84.968% (38120/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0184, Accuracy: 7130/10000 (71.30%)

Epoch: 162
Loss: 0.641 | Acc: 84.375% (54/64)
Loss: 0.551 | Acc: 85.381% (5519/6464)
Loss: 0.548 | Acc: 85.798% (11037/12864)
Loss: 0.552 | Acc: 85.382% (16448/19264)
Loss: 0.554 | Acc: 85.295% (21890/25664)
Loss: 0.559 | Acc: 85.177% (27311/32064)
Loss: 0.559 | Acc: 85.103% (32734/38464)
Loss: 0.562 | Acc: 85.048% (38156/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8842, Accuracy: 7486/10000 (74.86%)

Epoch: 163
Loss: 0.435 | Acc: 89.062% (57/64)
Loss: 0.540 | Acc: 85.705% (5540/6464)
Loss: 0.546 | Acc: 85.580% (11009/12864)
Loss: 0.549 | Acc: 85.579% (16486/19264)
Loss: 0.556 | Acc: 85.337% (21901/25664)
Loss: 0.558 | Acc: 85.173% (27310/32064)
Loss: 0.556 | Acc: 85.298% (32809/38464)
Loss: 0.559 | Acc: 85.193% (38221/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3046, Accuracy: 6370/10000 (63.70%)

Epoch: 164
Loss: 0.753 | Acc: 81.250% (52/64)
Loss: 0.539 | Acc: 85.907% (5553/6464)
Loss: 0.529 | Acc: 85.899% (11050/12864)
Loss: 0.537 | Acc: 85.761% (16521/19264)
Loss: 0.549 | Acc: 85.400% (21917/25664)
Loss: 0.546 | Acc: 85.513% (27419/32064)
Loss: 0.546 | Acc: 85.574% (32915/38464)
Loss: 0.548 | Acc: 85.536% (38375/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8970, Accuracy: 7508/10000 (75.08%)

Epoch: 165
Loss: 0.507 | Acc: 87.500% (56/64)
Loss: 0.550 | Acc: 85.535% (5529/6464)
Loss: 0.556 | Acc: 85.471% (10995/12864)
Loss: 0.551 | Acc: 85.600% (16490/19264)
Loss: 0.548 | Acc: 85.708% (21996/25664)
Loss: 0.544 | Acc: 85.753% (27496/32064)
Loss: 0.539 | Acc: 85.917% (33047/38464)
Loss: 0.541 | Acc: 85.815% (38500/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2122, Accuracy: 6504/10000 (65.04%)

Epoch: 166
Loss: 0.886 | Acc: 71.875% (46/64)
Loss: 0.522 | Acc: 86.185% (5571/6464)
Loss: 0.529 | Acc: 85.984% (11061/12864)
Loss: 0.528 | Acc: 85.958% (16559/19264)
Loss: 0.531 | Acc: 85.973% (22064/25664)
Loss: 0.531 | Acc: 86.040% (27588/32064)
Loss: 0.534 | Acc: 85.958% (33063/38464)
Loss: 0.534 | Acc: 85.975% (38572/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0772, Accuracy: 7109/10000 (71.09%)

Epoch: 167
Loss: 0.677 | Acc: 76.562% (49/64)
Loss: 0.517 | Acc: 86.139% (5568/6464)
Loss: 0.516 | Acc: 86.264% (11097/12864)
Loss: 0.523 | Acc: 86.275% (16620/19264)
Loss: 0.521 | Acc: 86.249% (22135/25664)
Loss: 0.527 | Acc: 86.075% (27599/32064)
Loss: 0.530 | Acc: 86.008% (33082/38464)
Loss: 0.530 | Acc: 86.065% (38612/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8910, Accuracy: 7538/10000 (75.38%)

Epoch: 168
Loss: 0.472 | Acc: 85.938% (55/64)
Loss: 0.490 | Acc: 87.175% (5635/6464)
Loss: 0.507 | Acc: 86.598% (11140/12864)
Loss: 0.514 | Acc: 86.451% (16654/19264)
Loss: 0.516 | Acc: 86.456% (22188/25664)
Loss: 0.518 | Acc: 86.443% (27717/32064)
Loss: 0.522 | Acc: 86.351% (33214/38464)
Loss: 0.522 | Acc: 86.386% (38756/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0478, Accuracy: 7104/10000 (71.04%)

Epoch: 169
Loss: 0.626 | Acc: 81.250% (52/64)
Loss: 0.505 | Acc: 86.959% (5621/6464)
Loss: 0.510 | Acc: 86.785% (11164/12864)
Loss: 0.514 | Acc: 86.721% (16706/19264)
Loss: 0.515 | Acc: 86.577% (22219/25664)
Loss: 0.517 | Acc: 86.589% (27764/32064)
Loss: 0.521 | Acc: 86.512% (33276/38464)
Loss: 0.518 | Acc: 86.508% (38811/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2428, Accuracy: 6648/10000 (66.48%)

Epoch: 170
Loss: 0.993 | Acc: 78.125% (50/64)
Loss: 0.523 | Acc: 86.417% (5586/6464)
Loss: 0.517 | Acc: 86.637% (11145/12864)
Loss: 0.516 | Acc: 86.711% (16704/19264)
Loss: 0.519 | Acc: 86.456% (22188/25664)
Loss: 0.516 | Acc: 86.527% (27744/32064)
Loss: 0.512 | Acc: 86.671% (33337/38464)
Loss: 0.513 | Acc: 86.591% (38848/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4973, Accuracy: 6116/10000 (61.16%)

Epoch: 171
Loss: 0.914 | Acc: 76.562% (49/64)
Loss: 0.491 | Acc: 87.778% (5674/6464)
Loss: 0.481 | Acc: 87.694% (11281/12864)
Loss: 0.496 | Acc: 87.240% (16806/19264)
Loss: 0.493 | Acc: 87.317% (22409/25664)
Loss: 0.492 | Acc: 87.316% (27997/32064)
Loss: 0.494 | Acc: 87.271% (33568/38464)
Loss: 0.497 | Acc: 87.241% (39140/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8442, Accuracy: 7608/10000 (76.08%)

Epoch: 172
Loss: 1.132 | Acc: 70.312% (45/64)
Loss: 0.484 | Acc: 87.871% (5680/6464)
Loss: 0.484 | Acc: 87.780% (11292/12864)
Loss: 0.484 | Acc: 87.791% (16912/19264)
Loss: 0.487 | Acc: 87.597% (22481/25664)
Loss: 0.484 | Acc: 87.712% (28124/32064)
Loss: 0.484 | Acc: 87.638% (33709/38464)
Loss: 0.486 | Acc: 87.669% (39332/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2995, Accuracy: 4640/10000 (46.40%)

Epoch: 173
Loss: 0.689 | Acc: 81.250% (52/64)
Loss: 0.475 | Acc: 87.949% (5685/6464)
Loss: 0.475 | Acc: 87.912% (11309/12864)
Loss: 0.479 | Acc: 87.863% (16926/19264)
Loss: 0.476 | Acc: 87.890% (22556/25664)
Loss: 0.473 | Acc: 88.015% (28221/32064)
Loss: 0.477 | Acc: 87.895% (33808/38464)
Loss: 0.479 | Acc: 87.863% (39419/44864)
torch.Size([100, 10])
Test set: Average loss: 2.6730, Accuracy: 3582/10000 (35.82%)

Epoch: 174
Loss: 0.844 | Acc: 75.000% (48/64)
Loss: 0.479 | Acc: 87.763% (5673/6464)
Loss: 0.477 | Acc: 87.803% (11295/12864)
Loss: 0.470 | Acc: 88.097% (16971/19264)
Loss: 0.478 | Acc: 87.921% (22564/25664)
Loss: 0.473 | Acc: 88.049% (28232/32064)
Loss: 0.472 | Acc: 88.114% (33892/38464)
Loss: 0.472 | Acc: 88.071% (39512/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8139, Accuracy: 7796/10000 (77.96%)

Epoch: 175
Loss: 0.444 | Acc: 92.188% (59/64)
Loss: 0.449 | Acc: 88.645% (5730/6464)
Loss: 0.446 | Acc: 88.565% (11393/12864)
Loss: 0.455 | Acc: 88.466% (17042/19264)
Loss: 0.460 | Acc: 88.310% (22664/25664)
Loss: 0.454 | Acc: 88.442% (28358/32064)
Loss: 0.459 | Acc: 88.301% (33964/38464)
Loss: 0.461 | Acc: 88.271% (39602/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8929, Accuracy: 7549/10000 (75.49%)

Epoch: 176
Loss: 0.469 | Acc: 89.062% (57/64)
Loss: 0.436 | Acc: 89.124% (5761/6464)
Loss: 0.443 | Acc: 88.993% (11448/12864)
Loss: 0.446 | Acc: 88.751% (17097/19264)
Loss: 0.452 | Acc: 88.587% (22735/25664)
Loss: 0.450 | Acc: 88.626% (28417/32064)
Loss: 0.447 | Acc: 88.704% (34119/38464)
Loss: 0.449 | Acc: 88.657% (39775/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5949, Accuracy: 5995/10000 (59.95%)

Epoch: 177
Loss: 0.380 | Acc: 87.500% (56/64)
Loss: 0.439 | Acc: 89.248% (5769/6464)
Loss: 0.436 | Acc: 89.319% (11490/12864)
Loss: 0.426 | Acc: 89.592% (17259/19264)
Loss: 0.433 | Acc: 89.386% (22940/25664)
Loss: 0.434 | Acc: 89.281% (28627/32064)
Loss: 0.439 | Acc: 89.049% (34252/38464)
Loss: 0.438 | Acc: 89.089% (39969/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7526, Accuracy: 7928/10000 (79.28%)

Epoch: 178
Loss: 0.428 | Acc: 92.188% (59/64)
Loss: 0.384 | Acc: 90.501% (5850/6464)
Loss: 0.396 | Acc: 90.299% (11616/12864)
Loss: 0.407 | Acc: 89.919% (17322/19264)
Loss: 0.412 | Acc: 89.834% (23055/25664)
Loss: 0.418 | Acc: 89.811% (28797/32064)
Loss: 0.418 | Acc: 89.770% (34529/38464)
Loss: 0.420 | Acc: 89.745% (40263/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0083, Accuracy: 7175/10000 (71.75%)

Epoch: 179
Loss: 0.445 | Acc: 90.625% (58/64)
Loss: 0.409 | Acc: 90.207% (5831/6464)
Loss: 0.412 | Acc: 90.003% (11578/12864)
Loss: 0.404 | Acc: 90.173% (17371/19264)
Loss: 0.405 | Acc: 90.060% (23113/25664)
Loss: 0.405 | Acc: 90.120% (28896/32064)
Loss: 0.407 | Acc: 90.126% (34666/38464)
Loss: 0.407 | Acc: 90.103% (40424/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5947, Accuracy: 8469/10000 (84.69%)

Epoch: 180
Loss: 0.393 | Acc: 87.500% (56/64)
Loss: 0.397 | Acc: 90.347% (5840/6464)
Loss: 0.405 | Acc: 90.019% (11580/12864)
Loss: 0.397 | Acc: 90.334% (17402/19264)
Loss: 0.394 | Acc: 90.387% (23197/25664)
Loss: 0.397 | Acc: 90.329% (28963/32064)
Loss: 0.397 | Acc: 90.274% (34723/38464)
Loss: 0.398 | Acc: 90.210% (40472/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6331, Accuracy: 8378/10000 (83.78%)

Epoch: 181
Loss: 0.364 | Acc: 87.500% (56/64)
Loss: 0.379 | Acc: 90.873% (5874/6464)
Loss: 0.376 | Acc: 91.014% (11708/12864)
Loss: 0.378 | Acc: 90.936% (17518/19264)
Loss: 0.379 | Acc: 90.945% (23340/25664)
Loss: 0.374 | Acc: 91.127% (29219/32064)
Loss: 0.379 | Acc: 91.020% (35010/38464)
Loss: 0.381 | Acc: 90.942% (40800/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9591, Accuracy: 7484/10000 (74.84%)

Epoch: 182
Loss: 0.416 | Acc: 89.062% (57/64)
Loss: 0.383 | Acc: 90.919% (5877/6464)
Loss: 0.367 | Acc: 91.301% (11745/12864)
Loss: 0.366 | Acc: 91.461% (17619/19264)
Loss: 0.363 | Acc: 91.494% (23481/25664)
Loss: 0.368 | Acc: 91.311% (29278/32064)
Loss: 0.365 | Acc: 91.361% (35141/38464)
Loss: 0.365 | Acc: 91.387% (41000/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5612, Accuracy: 8645/10000 (86.45%)

Epoch: 183
Loss: 0.412 | Acc: 93.750% (60/64)
Loss: 0.337 | Acc: 91.925% (5942/6464)
Loss: 0.345 | Acc: 91.674% (11793/12864)
Loss: 0.349 | Acc: 91.705% (17666/19264)
Loss: 0.348 | Acc: 91.724% (23540/25664)
Loss: 0.348 | Acc: 91.757% (29421/32064)
Loss: 0.349 | Acc: 91.704% (35273/38464)
Loss: 0.349 | Acc: 91.731% (41154/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5689, Accuracy: 8596/10000 (85.96%)

Epoch: 184
Loss: 0.406 | Acc: 90.625% (58/64)
Loss: 0.328 | Acc: 92.435% (5975/6464)
Loss: 0.329 | Acc: 92.242% (11866/12864)
Loss: 0.337 | Acc: 92.146% (17751/19264)
Loss: 0.335 | Acc: 92.262% (23678/25664)
Loss: 0.330 | Acc: 92.384% (29622/32064)
Loss: 0.335 | Acc: 92.252% (35484/38464)
Loss: 0.335 | Acc: 92.214% (41371/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5788, Accuracy: 8614/10000 (86.14%)

Epoch: 185
Loss: 0.276 | Acc: 93.750% (60/64)
Loss: 0.293 | Acc: 93.100% (6018/6464)
Loss: 0.302 | Acc: 92.825% (11941/12864)
Loss: 0.302 | Acc: 92.956% (17907/19264)
Loss: 0.313 | Acc: 92.752% (23804/25664)
Loss: 0.314 | Acc: 92.771% (29746/32064)
Loss: 0.314 | Acc: 92.798% (35694/38464)
Loss: 0.316 | Acc: 92.734% (41604/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5810, Accuracy: 8654/10000 (86.54%)

Epoch: 186
Loss: 0.211 | Acc: 93.750% (60/64)
Loss: 0.286 | Acc: 93.626% (6052/6464)
Loss: 0.285 | Acc: 93.618% (12043/12864)
Loss: 0.283 | Acc: 93.594% (18030/19264)
Loss: 0.293 | Acc: 93.286% (23941/25664)
Loss: 0.300 | Acc: 93.170% (29874/32064)
Loss: 0.300 | Acc: 93.149% (35829/38464)
Loss: 0.298 | Acc: 93.220% (41822/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5996, Accuracy: 8589/10000 (85.89%)

Epoch: 187
Loss: 0.270 | Acc: 95.312% (61/64)
Loss: 0.274 | Acc: 93.502% (6044/6464)
Loss: 0.267 | Acc: 93.983% (12090/12864)
Loss: 0.276 | Acc: 93.833% (18076/19264)
Loss: 0.277 | Acc: 93.805% (24074/25664)
Loss: 0.278 | Acc: 93.791% (30073/32064)
Loss: 0.278 | Acc: 93.784% (36073/38464)
Loss: 0.278 | Acc: 93.732% (42052/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5788, Accuracy: 8680/10000 (86.80%)

Epoch: 188
Loss: 0.324 | Acc: 92.188% (59/64)
Loss: 0.268 | Acc: 93.967% (6074/6464)
Loss: 0.262 | Acc: 94.139% (12110/12864)
Loss: 0.260 | Acc: 94.170% (18141/19264)
Loss: 0.261 | Acc: 94.147% (24162/25664)
Loss: 0.260 | Acc: 94.121% (30179/32064)
Loss: 0.258 | Acc: 94.166% (36220/38464)
Loss: 0.257 | Acc: 94.218% (42270/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5679, Accuracy: 8713/10000 (87.13%)

Epoch: 189
Loss: 0.200 | Acc: 95.312% (61/64)
Loss: 0.214 | Acc: 95.266% (6158/6464)
Loss: 0.226 | Acc: 94.869% (12204/12864)
Loss: 0.234 | Acc: 94.731% (18249/19264)
Loss: 0.234 | Acc: 94.794% (24328/25664)
Loss: 0.235 | Acc: 94.723% (30372/32064)
Loss: 0.236 | Acc: 94.691% (36422/38464)
Loss: 0.237 | Acc: 94.655% (42466/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5597, Accuracy: 8789/10000 (87.89%)

Epoch: 190
Loss: 0.270 | Acc: 93.750% (60/64)
Loss: 0.202 | Acc: 95.390% (6166/6464)
Loss: 0.203 | Acc: 95.452% (12279/12864)
Loss: 0.209 | Acc: 95.338% (18366/19264)
Loss: 0.210 | Acc: 95.297% (24457/25664)
Loss: 0.207 | Acc: 95.375% (30581/32064)
Loss: 0.209 | Acc: 95.372% (36684/38464)
Loss: 0.208 | Acc: 95.366% (42785/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5885, Accuracy: 8722/10000 (87.22%)

Epoch: 191
Loss: 0.368 | Acc: 92.188% (59/64)
Loss: 0.197 | Acc: 95.514% (6174/6464)
Loss: 0.190 | Acc: 95.701% (12311/12864)
Loss: 0.189 | Acc: 95.665% (18429/19264)
Loss: 0.188 | Acc: 95.702% (24561/25664)
Loss: 0.189 | Acc: 95.693% (30683/32064)
Loss: 0.191 | Acc: 95.661% (36795/38464)
Loss: 0.193 | Acc: 95.602% (42891/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5843, Accuracy: 8766/10000 (87.66%)

Epoch: 192
Loss: 0.110 | Acc: 98.438% (63/64)
Loss: 0.174 | Acc: 96.163% (6216/6464)
Loss: 0.163 | Acc: 96.323% (12391/12864)
Loss: 0.164 | Acc: 96.294% (18550/19264)
Loss: 0.166 | Acc: 96.236% (24698/25664)
Loss: 0.167 | Acc: 96.201% (30846/32064)
Loss: 0.169 | Acc: 96.170% (36991/38464)
Loss: 0.171 | Acc: 96.131% (43128/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5817, Accuracy: 8874/10000 (88.74%)

Epoch: 193
Loss: 0.100 | Acc: 98.438% (63/64)
Loss: 0.156 | Acc: 96.566% (6242/6464)
Loss: 0.157 | Acc: 96.463% (12409/12864)
Loss: 0.155 | Acc: 96.460% (18582/19264)
Loss: 0.155 | Acc: 96.388% (24737/25664)
Loss: 0.153 | Acc: 96.457% (30928/32064)
Loss: 0.152 | Acc: 96.477% (37109/38464)
Loss: 0.150 | Acc: 96.478% (43284/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5818, Accuracy: 8854/10000 (88.54%)

Epoch: 194
Loss: 0.156 | Acc: 96.875% (62/64)
Loss: 0.132 | Acc: 96.875% (6262/6464)
Loss: 0.136 | Acc: 96.859% (12460/12864)
Loss: 0.134 | Acc: 96.875% (18662/19264)
Loss: 0.135 | Acc: 96.785% (24839/25664)
Loss: 0.133 | Acc: 96.866% (31059/32064)
Loss: 0.133 | Acc: 96.867% (37259/38464)
Loss: 0.132 | Acc: 96.893% (43470/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5940, Accuracy: 8839/10000 (88.39%)

Epoch: 195
Loss: 0.175 | Acc: 96.875% (62/64)
Loss: 0.135 | Acc: 96.689% (6250/6464)
Loss: 0.153 | Acc: 96.486% (12412/12864)
Loss: 0.173 | Acc: 96.018% (18497/19264)
Loss: 0.188 | Acc: 95.679% (24555/25664)
Loss: 0.201 | Acc: 95.328% (30566/32064)
Loss: 0.218 | Acc: 94.910% (36506/38464)
Loss: 0.233 | Acc: 94.613% (42447/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5559, Accuracy: 8657/10000 (86.57%)

Epoch: 196
Loss: 0.389 | Acc: 89.062% (57/64)
Loss: 0.324 | Acc: 92.481% (5978/6464)
Loss: 0.336 | Acc: 92.195% (11860/12864)
Loss: 0.349 | Acc: 91.969% (17717/19264)
Loss: 0.358 | Acc: 91.739% (23544/25664)
Loss: 0.361 | Acc: 91.623% (29378/32064)
Loss: 0.368 | Acc: 91.418% (35163/38464)
Loss: 0.371 | Acc: 91.262% (40944/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5734, Accuracy: 8566/10000 (85.66%)

Epoch: 197
Loss: 0.244 | Acc: 92.188% (59/64)
Loss: 0.407 | Acc: 90.532% (5852/6464)
Loss: 0.415 | Acc: 90.197% (11603/12864)
Loss: 0.417 | Acc: 90.158% (17368/19264)
Loss: 0.424 | Acc: 89.803% (23047/25664)
Loss: 0.429 | Acc: 89.636% (28741/32064)
Loss: 0.427 | Acc: 89.681% (34495/38464)
Loss: 0.428 | Acc: 89.707% (40246/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5845, Accuracy: 8522/10000 (85.22%)
torch.Size([100, 10])
Test set: Average loss: 0.5845, Accuracy: 8522/10000 (85.22%)

Epoch: 198
Loss: 0.216 | Acc: 95.312% (61/64)
Loss: 0.441 | Acc: 89.465% (5783/6464)
Loss: 0.444 | Acc: 89.350% (11494/12864)
Loss: 0.437 | Acc: 89.436% (17229/19264)
Loss: 0.443 | Acc: 89.261% (22908/25664)
Loss: 0.445 | Acc: 89.222% (28608/32064)
Loss: 0.447 | Acc: 89.174% (34300/38464)
Loss: 0.446 | Acc: 89.234% (40034/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5800, Accuracy: 8535/10000 (85.35%)
torch.Size([100, 10])
Test set: Average loss: 0.5800, Accuracy: 8535/10000 (85.35%)

Epoch: 199
Loss: 0.340 | Acc: 87.500% (56/64)
Loss: 0.439 | Acc: 88.939% (5749/6464)
Loss: 0.442 | Acc: 89.086% (11460/12864)
Loss: 0.454 | Acc: 88.767% (17100/19264)
Loss: 0.449 | Acc: 88.887% (22812/25664)
Loss: 0.452 | Acc: 88.854% (28490/32064)
Loss: 0.447 | Acc: 89.003% (34234/38464)
Loss: 0.446 | Acc: 89.062% (39957/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5820, Accuracy: 8530/10000 (85.30%)
torch.Size([100, 10])
Test set: Average loss: 0.5820, Accuracy: 8530/10000 (85.30%)
8790
10000
-0.5246672034263611
