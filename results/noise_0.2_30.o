==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.403 | Acc: 12.500% (8/64)
Loss: 2.799 | Acc: 15.579% (1007/6464)
Loss: 2.475 | Acc: 17.755% (2284/12864)
Loss: 2.352 | Acc: 19.586% (3773/19264)
Loss: 2.275 | Acc: 21.162% (5431/25664)
Loss: 2.223 | Acc: 22.539% (7227/32064)
Loss: 2.188 | Acc: 23.567% (9065/38464)
Loss: 2.155 | Acc: 24.494% (10989/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1459, Accuracy: 2445/10000 (24.45%)

Epoch: 1
Loss: 2.207 | Acc: 15.625% (10/64)
Loss: 1.908 | Acc: 32.751% (2117/6464)
Loss: 1.916 | Acc: 32.774% (4216/12864)
Loss: 1.907 | Acc: 33.275% (6410/19264)
Loss: 1.898 | Acc: 33.561% (8613/25664)
Loss: 1.891 | Acc: 33.982% (10896/32064)
Loss: 1.882 | Acc: 34.391% (13228/38464)
Loss: 1.874 | Acc: 34.903% (15659/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9325, Accuracy: 3352/10000 (33.52%)

Epoch: 2
Loss: 1.588 | Acc: 53.125% (34/64)
Loss: 1.788 | Acc: 39.310% (2541/6464)
Loss: 1.782 | Acc: 39.646% (5100/12864)
Loss: 1.771 | Acc: 40.391% (7781/19264)
Loss: 1.765 | Acc: 40.555% (10408/25664)
Loss: 1.755 | Acc: 41.049% (13162/32064)
Loss: 1.751 | Acc: 41.454% (15945/38464)
Loss: 1.747 | Acc: 41.684% (18701/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7668, Accuracy: 4112/10000 (41.12%)

Epoch: 3
Loss: 2.035 | Acc: 28.125% (18/64)
Loss: 1.682 | Acc: 44.663% (2887/6464)
Loss: 1.696 | Acc: 44.831% (5767/12864)
Loss: 1.677 | Acc: 45.338% (8734/19264)
Loss: 1.671 | Acc: 45.842% (11765/25664)
Loss: 1.665 | Acc: 46.145% (14796/32064)
Loss: 1.656 | Acc: 46.506% (17888/38464)
Loss: 1.647 | Acc: 46.893% (21038/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0734, Accuracy: 3461/10000 (34.61%)

Epoch: 4
Loss: 1.869 | Acc: 42.188% (27/64)
Loss: 1.579 | Acc: 50.897% (3290/6464)
Loss: 1.576 | Acc: 50.731% (6526/12864)
Loss: 1.571 | Acc: 51.023% (9829/19264)
Loss: 1.566 | Acc: 51.068% (13106/25664)
Loss: 1.563 | Acc: 51.076% (16377/32064)
Loss: 1.558 | Acc: 51.331% (19744/38464)
Loss: 1.553 | Acc: 51.583% (23142/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6495, Accuracy: 4807/10000 (48.07%)

Epoch: 5
Loss: 1.771 | Acc: 48.438% (31/64)
Loss: 1.513 | Acc: 52.831% (3415/6464)
Loss: 1.518 | Acc: 53.016% (6820/12864)
Loss: 1.507 | Acc: 53.639% (10333/19264)
Loss: 1.504 | Acc: 53.807% (13809/25664)
Loss: 1.495 | Acc: 54.179% (17372/32064)
Loss: 1.496 | Acc: 54.227% (20858/38464)
Loss: 1.492 | Acc: 54.346% (24382/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7533, Accuracy: 4463/10000 (44.63%)

Epoch: 6
Loss: 1.421 | Acc: 56.250% (36/64)
Loss: 1.459 | Acc: 55.910% (3614/6464)
Loss: 1.460 | Acc: 55.776% (7175/12864)
Loss: 1.455 | Acc: 56.136% (10814/19264)
Loss: 1.445 | Acc: 56.562% (14516/25664)
Loss: 1.438 | Acc: 56.908% (18247/32064)
Loss: 1.437 | Acc: 57.103% (21964/38464)
Loss: 1.435 | Acc: 57.213% (25668/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0168, Accuracy: 3565/10000 (35.65%)

Epoch: 7
Loss: 1.705 | Acc: 45.312% (29/64)
Loss: 1.406 | Acc: 59.174% (3825/6464)
Loss: 1.393 | Acc: 59.383% (7639/12864)
Loss: 1.392 | Acc: 59.546% (11471/19264)
Loss: 1.385 | Acc: 59.792% (15345/25664)
Loss: 1.380 | Acc: 59.905% (19208/32064)
Loss: 1.380 | Acc: 60.035% (23092/38464)
Loss: 1.373 | Acc: 60.146% (26984/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5554, Accuracy: 5374/10000 (53.74%)

Epoch: 8
Loss: 1.360 | Acc: 60.938% (39/64)
Loss: 1.360 | Acc: 60.690% (3923/6464)
Loss: 1.346 | Acc: 61.000% (7847/12864)
Loss: 1.343 | Acc: 61.166% (11783/19264)
Loss: 1.341 | Acc: 61.300% (15732/25664)
Loss: 1.336 | Acc: 61.508% (19722/32064)
Loss: 1.335 | Acc: 61.561% (23679/38464)
Loss: 1.333 | Acc: 61.713% (27687/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8691, Accuracy: 4555/10000 (45.55%)

Epoch: 9
Loss: 1.640 | Acc: 50.000% (32/64)
Loss: 1.290 | Acc: 63.490% (4104/6464)
Loss: 1.307 | Acc: 63.044% (8110/12864)
Loss: 1.315 | Acc: 62.604% (12060/19264)
Loss: 1.311 | Acc: 62.675% (16085/25664)
Loss: 1.312 | Acc: 62.799% (20136/32064)
Loss: 1.310 | Acc: 62.877% (24185/38464)
Loss: 1.305 | Acc: 63.064% (28293/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4913, Accuracy: 5510/10000 (55.10%)

Epoch: 10
Loss: 1.123 | Acc: 65.625% (42/64)
Loss: 1.274 | Acc: 63.861% (4128/6464)
Loss: 1.278 | Acc: 64.086% (8244/12864)
Loss: 1.278 | Acc: 64.068% (12342/19264)
Loss: 1.273 | Acc: 64.183% (16472/25664)
Loss: 1.276 | Acc: 64.259% (20604/32064)
Loss: 1.279 | Acc: 64.156% (24677/38464)
Loss: 1.278 | Acc: 64.190% (28798/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5519, Accuracy: 5426/10000 (54.26%)

Epoch: 11
Loss: 1.348 | Acc: 56.250% (36/64)
Loss: 1.266 | Acc: 64.542% (4172/6464)
Loss: 1.263 | Acc: 64.855% (8343/12864)
Loss: 1.259 | Acc: 64.966% (12515/19264)
Loss: 1.266 | Acc: 64.822% (16636/25664)
Loss: 1.266 | Acc: 64.814% (20782/32064)
Loss: 1.259 | Acc: 64.978% (24993/38464)
Loss: 1.258 | Acc: 65.005% (29164/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4487, Accuracy: 5867/10000 (58.67%)

Epoch: 12
Loss: 1.350 | Acc: 57.812% (37/64)
Loss: 1.240 | Acc: 65.470% (4232/6464)
Loss: 1.242 | Acc: 65.920% (8480/12864)
Loss: 1.240 | Acc: 65.916% (12698/19264)
Loss: 1.242 | Acc: 65.863% (16903/25664)
Loss: 1.243 | Acc: 65.868% (21120/32064)
Loss: 1.242 | Acc: 65.833% (25322/38464)
Loss: 1.244 | Acc: 65.748% (29497/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4025, Accuracy: 5980/10000 (59.80%)

Epoch: 13
Loss: 1.453 | Acc: 57.812% (37/64)
Loss: 1.220 | Acc: 66.909% (4325/6464)
Loss: 1.223 | Acc: 66.566% (8563/12864)
Loss: 1.221 | Acc: 66.616% (12833/19264)
Loss: 1.225 | Acc: 66.638% (17102/25664)
Loss: 1.222 | Acc: 66.813% (21423/32064)
Loss: 1.224 | Acc: 66.772% (25683/38464)
Loss: 1.226 | Acc: 66.646% (29900/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4679, Accuracy: 5815/10000 (58.15%)

Epoch: 14
Loss: 1.343 | Acc: 57.812% (37/64)
Loss: 1.235 | Acc: 66.228% (4281/6464)
Loss: 1.215 | Acc: 66.978% (8616/12864)
Loss: 1.216 | Acc: 66.866% (12881/19264)
Loss: 1.216 | Acc: 67.047% (17207/25664)
Loss: 1.214 | Acc: 67.097% (21514/32064)
Loss: 1.213 | Acc: 67.159% (25832/38464)
Loss: 1.216 | Acc: 67.056% (30084/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8389, Accuracy: 4539/10000 (45.39%)

Epoch: 15
Loss: 1.463 | Acc: 59.375% (38/64)
Loss: 1.200 | Acc: 67.512% (4364/6464)
Loss: 1.199 | Acc: 67.646% (8702/12864)
Loss: 1.202 | Acc: 67.489% (13001/19264)
Loss: 1.200 | Acc: 67.601% (17349/25664)
Loss: 1.194 | Acc: 67.849% (21755/32064)
Loss: 1.197 | Acc: 67.713% (26045/38464)
Loss: 1.197 | Acc: 67.731% (30387/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4091, Accuracy: 6031/10000 (60.31%)

Epoch: 16
Loss: 1.396 | Acc: 62.500% (40/64)
Loss: 1.170 | Acc: 68.843% (4450/6464)
Loss: 1.171 | Acc: 68.688% (8836/12864)
Loss: 1.178 | Acc: 68.605% (13216/19264)
Loss: 1.188 | Acc: 68.282% (17524/25664)
Loss: 1.184 | Acc: 68.435% (21943/32064)
Loss: 1.188 | Acc: 68.360% (26294/38464)
Loss: 1.181 | Acc: 68.491% (30728/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8551, Accuracy: 4741/10000 (47.41%)

Epoch: 17
Loss: 1.178 | Acc: 67.188% (43/64)
Loss: 1.163 | Acc: 69.369% (4484/6464)
Loss: 1.178 | Acc: 68.758% (8845/12864)
Loss: 1.178 | Acc: 68.631% (13221/19264)
Loss: 1.171 | Acc: 68.879% (17677/25664)
Loss: 1.171 | Acc: 68.953% (22109/32064)
Loss: 1.171 | Acc: 69.057% (26562/38464)
Loss: 1.170 | Acc: 69.020% (30965/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3891, Accuracy: 6088/10000 (60.88%)

Epoch: 18
Loss: 1.252 | Acc: 67.188% (43/64)
Loss: 1.122 | Acc: 70.204% (4538/6464)
Loss: 1.133 | Acc: 69.823% (8982/12864)
Loss: 1.149 | Acc: 69.420% (13373/19264)
Loss: 1.151 | Acc: 69.420% (17816/25664)
Loss: 1.151 | Acc: 69.402% (22253/32064)
Loss: 1.157 | Acc: 69.223% (26626/38464)
Loss: 1.157 | Acc: 69.267% (31076/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5073, Accuracy: 5615/10000 (56.15%)

Epoch: 19
Loss: 1.659 | Acc: 48.438% (31/64)
Loss: 1.138 | Acc: 69.879% (4517/6464)
Loss: 1.144 | Acc: 69.924% (8995/12864)
Loss: 1.134 | Acc: 70.287% (13540/19264)
Loss: 1.132 | Acc: 70.367% (18059/25664)
Loss: 1.136 | Acc: 70.297% (22540/32064)
Loss: 1.140 | Acc: 70.170% (26990/38464)
Loss: 1.142 | Acc: 70.150% (31472/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3888, Accuracy: 6092/10000 (60.92%)

Epoch: 20
Loss: 1.022 | Acc: 75.000% (48/64)
Loss: 1.116 | Acc: 70.808% (4577/6464)
Loss: 1.123 | Acc: 70.538% (9074/12864)
Loss: 1.124 | Acc: 70.598% (13600/19264)
Loss: 1.125 | Acc: 70.566% (18110/25664)
Loss: 1.131 | Acc: 70.450% (22589/32064)
Loss: 1.132 | Acc: 70.502% (27118/38464)
Loss: 1.132 | Acc: 70.471% (31616/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7332, Accuracy: 4955/10000 (49.55%)

Epoch: 21
Loss: 1.026 | Acc: 71.875% (46/64)
Loss: 1.118 | Acc: 70.220% (4539/6464)
Loss: 1.116 | Acc: 70.546% (9075/12864)
Loss: 1.113 | Acc: 70.681% (13616/19264)
Loss: 1.120 | Acc: 70.519% (18098/25664)
Loss: 1.117 | Acc: 70.696% (22668/32064)
Loss: 1.121 | Acc: 70.656% (27177/38464)
Loss: 1.121 | Acc: 70.665% (31703/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5807, Accuracy: 5467/10000 (54.67%)

Epoch: 22
Loss: 0.968 | Acc: 76.562% (49/64)
Loss: 1.104 | Acc: 71.473% (4620/6464)
Loss: 1.117 | Acc: 70.896% (9120/12864)
Loss: 1.113 | Acc: 71.076% (13692/19264)
Loss: 1.115 | Acc: 71.002% (18222/25664)
Loss: 1.109 | Acc: 71.139% (22810/32064)
Loss: 1.109 | Acc: 71.131% (27360/38464)
Loss: 1.108 | Acc: 71.160% (31925/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7200, Accuracy: 4891/10000 (48.91%)

Epoch: 23
Loss: 1.049 | Acc: 73.438% (47/64)
Loss: 1.076 | Acc: 72.401% (4680/6464)
Loss: 1.085 | Acc: 72.132% (9279/12864)
Loss: 1.093 | Acc: 72.093% (13888/19264)
Loss: 1.098 | Acc: 71.902% (18453/25664)
Loss: 1.099 | Acc: 71.813% (23026/32064)
Loss: 1.096 | Acc: 71.872% (27645/38464)
Loss: 1.096 | Acc: 71.962% (32285/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3589, Accuracy: 6147/10000 (61.47%)

Epoch: 24
Loss: 1.183 | Acc: 71.875% (46/64)
Loss: 1.091 | Acc: 71.968% (4652/6464)
Loss: 1.100 | Acc: 71.720% (9226/12864)
Loss: 1.092 | Acc: 71.963% (13863/19264)
Loss: 1.096 | Acc: 72.007% (18480/25664)
Loss: 1.093 | Acc: 71.997% (23085/32064)
Loss: 1.091 | Acc: 71.963% (27680/38464)
Loss: 1.092 | Acc: 71.908% (32261/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3814, Accuracy: 6222/10000 (62.22%)

Epoch: 25
Loss: 1.194 | Acc: 64.062% (41/64)
Loss: 1.068 | Acc: 72.710% (4700/6464)
Loss: 1.072 | Acc: 72.823% (9368/12864)
Loss: 1.073 | Acc: 72.892% (14042/19264)
Loss: 1.070 | Acc: 72.958% (18724/25664)
Loss: 1.075 | Acc: 72.789% (23339/32064)
Loss: 1.079 | Acc: 72.658% (27947/38464)
Loss: 1.077 | Acc: 72.686% (32610/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3132, Accuracy: 6444/10000 (64.44%)

Epoch: 26
Loss: 0.986 | Acc: 75.000% (48/64)
Loss: 1.079 | Acc: 72.741% (4702/6464)
Loss: 1.074 | Acc: 72.823% (9368/12864)
Loss: 1.066 | Acc: 73.152% (14092/19264)
Loss: 1.071 | Acc: 72.888% (18706/25664)
Loss: 1.073 | Acc: 72.779% (23336/32064)
Loss: 1.066 | Acc: 72.889% (28036/38464)
Loss: 1.062 | Acc: 73.010% (32755/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3841, Accuracy: 6230/10000 (62.30%)

Epoch: 27
Loss: 1.429 | Acc: 54.688% (35/64)
Loss: 1.083 | Acc: 72.401% (4680/6464)
Loss: 1.047 | Acc: 73.577% (9465/12864)
Loss: 1.049 | Acc: 73.463% (14152/19264)
Loss: 1.048 | Acc: 73.531% (18871/25664)
Loss: 1.048 | Acc: 73.668% (23621/32064)
Loss: 1.045 | Acc: 73.713% (28353/38464)
Loss: 1.047 | Acc: 73.669% (33051/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3212, Accuracy: 6475/10000 (64.75%)

Epoch: 28
Loss: 1.223 | Acc: 60.938% (39/64)
Loss: 1.044 | Acc: 73.314% (4739/6464)
Loss: 1.047 | Acc: 73.445% (9448/12864)
Loss: 1.036 | Acc: 73.650% (14188/19264)
Loss: 1.037 | Acc: 73.663% (18905/25664)
Loss: 1.033 | Acc: 73.843% (23677/32064)
Loss: 1.039 | Acc: 73.661% (28333/38464)
Loss: 1.041 | Acc: 73.667% (33050/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6008, Accuracy: 5372/10000 (53.72%)

Epoch: 29
Loss: 0.983 | Acc: 75.000% (48/64)
Loss: 1.004 | Acc: 75.155% (4858/6464)
Loss: 1.018 | Acc: 74.674% (9606/12864)
Loss: 1.008 | Acc: 74.948% (14438/19264)
Loss: 1.016 | Acc: 74.743% (19182/25664)
Loss: 1.019 | Acc: 74.635% (23931/32064)
Loss: 1.022 | Acc: 74.566% (28681/38464)
Loss: 1.017 | Acc: 74.675% (33502/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1911, Accuracy: 6918/10000 (69.18%)

Epoch: 30
Loss: 1.345 | Acc: 65.625% (42/64)
Loss: 0.982 | Acc: 75.959% (4910/6464)
Loss: 0.998 | Acc: 75.358% (9694/12864)
Loss: 0.997 | Acc: 75.234% (14493/19264)
Loss: 0.998 | Acc: 75.222% (19305/25664)
Loss: 1.006 | Acc: 74.922% (24023/32064)
Loss: 1.010 | Acc: 74.865% (28796/38464)
Loss: 1.009 | Acc: 74.926% (33615/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2474, Accuracy: 6738/10000 (67.38%)

Epoch: 31
Loss: 0.689 | Acc: 79.688% (51/64)
Loss: 0.970 | Acc: 76.098% (4919/6464)
Loss: 0.989 | Acc: 75.567% (9721/12864)
Loss: 0.989 | Acc: 75.659% (14575/19264)
Loss: 0.989 | Acc: 75.674% (19421/25664)
Loss: 0.992 | Acc: 75.483% (24203/32064)
Loss: 0.990 | Acc: 75.499% (29040/38464)
Loss: 0.995 | Acc: 75.308% (33786/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1660, Accuracy: 7087/10000 (70.87%)

Epoch: 32
Loss: 0.925 | Acc: 75.000% (48/64)
Loss: 0.978 | Acc: 75.712% (4894/6464)
Loss: 0.981 | Acc: 75.645% (9731/12864)
Loss: 0.986 | Acc: 75.607% (14565/19264)
Loss: 0.983 | Acc: 75.623% (19408/25664)
Loss: 0.979 | Acc: 75.802% (24305/32064)
Loss: 0.982 | Acc: 75.699% (29117/38464)
Loss: 0.980 | Acc: 75.744% (33982/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3338, Accuracy: 6497/10000 (64.97%)

Epoch: 33
Loss: 1.041 | Acc: 71.875% (46/64)
Loss: 0.922 | Acc: 77.429% (5005/6464)
Loss: 0.940 | Acc: 76.959% (9900/12864)
Loss: 0.938 | Acc: 77.009% (14835/19264)
Loss: 0.947 | Acc: 76.742% (19695/25664)
Loss: 0.945 | Acc: 76.778% (24618/32064)
Loss: 0.951 | Acc: 76.583% (29457/38464)
Loss: 0.955 | Acc: 76.487% (34315/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2790, Accuracy: 6598/10000 (65.98%)

Epoch: 34
Loss: 1.001 | Acc: 78.125% (50/64)
Loss: 0.924 | Acc: 77.058% (4981/6464)
Loss: 0.920 | Acc: 77.270% (9940/12864)
Loss: 0.924 | Acc: 77.175% (14867/19264)
Loss: 0.928 | Acc: 77.135% (19796/25664)
Loss: 0.930 | Acc: 77.149% (24737/32064)
Loss: 0.933 | Acc: 77.075% (29646/38464)
Loss: 0.938 | Acc: 76.939% (34518/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2570, Accuracy: 6750/10000 (67.50%)

Epoch: 35
Loss: 0.877 | Acc: 81.250% (52/64)
Loss: 0.865 | Acc: 78.759% (5091/6464)
Loss: 0.887 | Acc: 78.234% (10064/12864)
Loss: 0.893 | Acc: 78.063% (15038/19264)
Loss: 0.895 | Acc: 78.067% (20035/25664)
Loss: 0.900 | Acc: 77.957% (24996/32064)
Loss: 0.905 | Acc: 77.878% (29955/38464)
Loss: 0.908 | Acc: 77.771% (34891/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2345, Accuracy: 6922/10000 (69.22%)

Epoch: 36
Loss: 0.983 | Acc: 75.000% (48/64)
Loss: 0.880 | Acc: 78.790% (5093/6464)
Loss: 0.883 | Acc: 78.389% (10084/12864)
Loss: 0.881 | Acc: 78.421% (15107/19264)
Loss: 0.888 | Acc: 78.129% (20051/25664)
Loss: 0.893 | Acc: 78.006% (25012/32064)
Loss: 0.894 | Acc: 77.982% (29995/38464)
Loss: 0.895 | Acc: 77.998% (34993/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1722, Accuracy: 7149/10000 (71.49%)

Epoch: 37
Loss: 0.764 | Acc: 79.688% (51/64)
Loss: 0.863 | Acc: 78.806% (5094/6464)
Loss: 0.858 | Acc: 79.027% (10166/12864)
Loss: 0.855 | Acc: 78.940% (15207/19264)
Loss: 0.851 | Acc: 79.010% (20277/25664)
Loss: 0.858 | Acc: 78.886% (25294/32064)
Loss: 0.864 | Acc: 78.757% (30293/38464)
Loss: 0.868 | Acc: 78.687% (35302/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2474, Accuracy: 6879/10000 (68.79%)

Epoch: 38
Loss: 0.828 | Acc: 76.562% (49/64)
Loss: 0.823 | Acc: 79.517% (5140/6464)
Loss: 0.818 | Acc: 79.928% (10282/12864)
Loss: 0.823 | Acc: 79.828% (15378/19264)
Loss: 0.837 | Acc: 79.446% (20389/25664)
Loss: 0.839 | Acc: 79.391% (25456/32064)
Loss: 0.838 | Acc: 79.368% (30528/38464)
Loss: 0.838 | Acc: 79.344% (35597/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2041, Accuracy: 7062/10000 (70.62%)

Epoch: 39
Loss: 0.993 | Acc: 73.438% (47/64)
Loss: 0.774 | Acc: 80.987% (5235/6464)
Loss: 0.774 | Acc: 81.126% (10436/12864)
Loss: 0.784 | Acc: 80.689% (15544/19264)
Loss: 0.787 | Acc: 80.603% (20686/25664)
Loss: 0.794 | Acc: 80.392% (25777/32064)
Loss: 0.797 | Acc: 80.363% (30911/38464)
Loss: 0.803 | Acc: 80.191% (35977/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2653, Accuracy: 6879/10000 (68.79%)

Epoch: 40
Loss: 0.542 | Acc: 90.625% (58/64)
Loss: 0.760 | Acc: 81.080% (5241/6464)
Loss: 0.759 | Acc: 81.172% (10442/12864)
Loss: 0.764 | Acc: 81.110% (15625/19264)
Loss: 0.766 | Acc: 81.040% (20798/25664)
Loss: 0.769 | Acc: 80.929% (25949/32064)
Loss: 0.771 | Acc: 80.811% (31083/38464)
Loss: 0.769 | Acc: 80.853% (36274/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2558, Accuracy: 7091/10000 (70.91%)

Epoch: 41
Loss: 0.948 | Acc: 73.438% (47/64)
Loss: 0.716 | Acc: 82.085% (5306/6464)
Loss: 0.722 | Acc: 81.872% (10532/12864)
Loss: 0.725 | Acc: 81.696% (15738/19264)
Loss: 0.729 | Acc: 81.640% (20952/25664)
Loss: 0.731 | Acc: 81.646% (26179/32064)
Loss: 0.735 | Acc: 81.500% (31348/38464)
Loss: 0.737 | Acc: 81.462% (36547/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2587, Accuracy: 7133/10000 (71.33%)

Epoch: 42
Loss: 0.627 | Acc: 89.062% (57/64)
Loss: 0.684 | Acc: 82.534% (5335/6464)
Loss: 0.675 | Acc: 82.727% (10642/12864)
Loss: 0.677 | Acc: 82.729% (15937/19264)
Loss: 0.685 | Acc: 82.567% (21190/25664)
Loss: 0.687 | Acc: 82.547% (26468/32064)
Loss: 0.687 | Acc: 82.547% (31751/38464)
Loss: 0.683 | Acc: 82.648% (37079/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2997, Accuracy: 7135/10000 (71.35%)

Epoch: 43
Loss: 0.598 | Acc: 89.062% (57/64)
Loss: 0.627 | Acc: 83.849% (5420/6464)
Loss: 0.636 | Acc: 83.551% (10748/12864)
Loss: 0.641 | Acc: 83.461% (16078/19264)
Loss: 0.636 | Acc: 83.600% (21455/25664)
Loss: 0.633 | Acc: 83.608% (26808/32064)
Loss: 0.637 | Acc: 83.538% (32132/38464)
Loss: 0.639 | Acc: 83.539% (37479/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3015, Accuracy: 7093/10000 (70.93%)

Epoch: 44
Loss: 0.403 | Acc: 89.062% (57/64)
Loss: 0.588 | Acc: 84.576% (5467/6464)
Loss: 0.589 | Acc: 84.530% (10874/12864)
Loss: 0.588 | Acc: 84.474% (16273/19264)
Loss: 0.592 | Acc: 84.414% (21664/25664)
Loss: 0.592 | Acc: 84.412% (27066/32064)
Loss: 0.587 | Acc: 84.536% (32516/38464)
Loss: 0.587 | Acc: 84.527% (37922/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3536, Accuracy: 7125/10000 (71.25%)

Epoch: 45
Loss: 0.441 | Acc: 85.938% (55/64)
Loss: 0.535 | Acc: 85.798% (5546/6464)
Loss: 0.544 | Acc: 85.689% (11023/12864)
Loss: 0.549 | Acc: 85.553% (16481/19264)
Loss: 0.553 | Acc: 85.376% (21911/25664)
Loss: 0.552 | Acc: 85.385% (27378/32064)
Loss: 0.548 | Acc: 85.485% (32881/38464)
Loss: 0.546 | Acc: 85.563% (38387/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3460, Accuracy: 7110/10000 (71.10%)

Epoch: 46
Loss: 0.383 | Acc: 90.625% (58/64)
Loss: 0.525 | Acc: 85.922% (5554/6464)
Loss: 0.512 | Acc: 86.264% (11097/12864)
Loss: 0.514 | Acc: 86.228% (16611/19264)
Loss: 0.517 | Acc: 86.206% (22124/25664)
Loss: 0.517 | Acc: 86.262% (27659/32064)
Loss: 0.516 | Acc: 86.288% (33190/38464)
Loss: 0.517 | Acc: 86.274% (38706/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3415, Accuracy: 7101/10000 (71.01%)

Epoch: 47
Loss: 0.204 | Acc: 98.438% (63/64)
Loss: 0.495 | Acc: 86.726% (5606/6464)
Loss: 0.490 | Acc: 86.800% (11166/12864)
Loss: 0.494 | Acc: 86.758% (16713/19264)
Loss: 0.492 | Acc: 86.771% (22269/25664)
Loss: 0.494 | Acc: 86.670% (27790/32064)
Loss: 0.494 | Acc: 86.691% (33345/38464)
Loss: 0.493 | Acc: 86.756% (38922/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3639, Accuracy: 7110/10000 (71.10%)
torch.Size([100, 10])
Test set: Average loss: 1.3639, Accuracy: 7110/10000 (71.10%)

Epoch: 48
Loss: 0.462 | Acc: 87.500% (56/64)
Loss: 0.456 | Acc: 88.026% (5690/6464)
Loss: 0.473 | Acc: 87.306% (11231/12864)
Loss: 0.475 | Acc: 87.048% (16769/19264)
Loss: 0.477 | Acc: 87.106% (22355/25664)
Loss: 0.477 | Acc: 87.144% (27942/32064)
Loss: 0.477 | Acc: 87.131% (33514/38464)
Loss: 0.477 | Acc: 87.123% (39087/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3598, Accuracy: 7118/10000 (71.18%)
torch.Size([100, 10])
Test set: Average loss: 1.3598, Accuracy: 7118/10000 (71.18%)

Epoch: 49
Loss: 0.425 | Acc: 92.188% (59/64)
Loss: 0.481 | Acc: 86.897% (5617/6464)
Loss: 0.486 | Acc: 86.870% (11175/12864)
Loss: 0.486 | Acc: 86.919% (16744/19264)
Loss: 0.480 | Acc: 87.040% (22338/25664)
Loss: 0.476 | Acc: 87.160% (27947/32064)
Loss: 0.473 | Acc: 87.235% (33554/38464)
Loss: 0.472 | Acc: 87.290% (39162/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3677, Accuracy: 7104/10000 (71.04%)
torch.Size([100, 10])
Test set: Average loss: 1.3677, Accuracy: 7104/10000 (71.04%)

Epoch: 50
Loss: 0.424 | Acc: 89.062% (57/64)
Loss: 1.681 | Acc: 47.014% (3039/6464)
Loss: 1.505 | Acc: 54.936% (7067/12864)
Loss: 1.429 | Acc: 58.155% (11203/19264)
Loss: 1.390 | Acc: 59.769% (15339/25664)
Loss: 1.362 | Acc: 61.075% (19583/32064)
Loss: 1.339 | Acc: 61.985% (23842/38464)
Loss: 1.324 | Acc: 62.627% (28097/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7373, Accuracy: 4919/10000 (49.19%)

Epoch: 51
Loss: 1.021 | Acc: 70.312% (45/64)
Loss: 1.194 | Acc: 67.930% (4391/6464)
Loss: 1.186 | Acc: 68.416% (8801/12864)
Loss: 1.195 | Acc: 68.080% (13115/19264)
Loss: 1.192 | Acc: 68.130% (17485/25664)
Loss: 1.189 | Acc: 68.270% (21890/32064)
Loss: 1.186 | Acc: 68.339% (26286/38464)
Loss: 1.183 | Acc: 68.425% (30698/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5766, Accuracy: 5594/10000 (55.94%)

Epoch: 52
Loss: 1.210 | Acc: 68.750% (44/64)
Loss: 1.167 | Acc: 69.199% (4473/6464)
Loss: 1.161 | Acc: 69.317% (8917/12864)
Loss: 1.153 | Acc: 69.632% (13414/19264)
Loss: 1.157 | Acc: 69.490% (17834/25664)
Loss: 1.159 | Acc: 69.352% (22237/32064)
Loss: 1.159 | Acc: 69.283% (26649/38464)
Loss: 1.162 | Acc: 69.254% (31070/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5555, Accuracy: 5653/10000 (56.53%)

Epoch: 53
Loss: 1.421 | Acc: 62.500% (40/64)
Loss: 1.133 | Acc: 70.189% (4537/6464)
Loss: 1.140 | Acc: 70.274% (9040/12864)
Loss: 1.145 | Acc: 70.089% (13502/19264)
Loss: 1.151 | Acc: 69.759% (17903/25664)
Loss: 1.154 | Acc: 69.683% (22343/32064)
Loss: 1.150 | Acc: 69.793% (26845/38464)
Loss: 1.151 | Acc: 69.746% (31291/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9206, Accuracy: 3461/10000 (34.61%)

Epoch: 54
Loss: 1.325 | Acc: 59.375% (38/64)
Loss: 1.147 | Acc: 69.895% (4518/6464)
Loss: 1.152 | Acc: 69.652% (8960/12864)
Loss: 1.146 | Acc: 69.949% (13475/19264)
Loss: 1.143 | Acc: 69.993% (17963/25664)
Loss: 1.145 | Acc: 69.888% (22409/32064)
Loss: 1.147 | Acc: 69.834% (26861/38464)
Loss: 1.148 | Acc: 69.818% (31323/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6376, Accuracy: 5516/10000 (55.16%)

Epoch: 55
Loss: 1.361 | Acc: 64.062% (41/64)
Loss: 1.133 | Acc: 70.065% (4529/6464)
Loss: 1.140 | Acc: 70.064% (9013/12864)
Loss: 1.145 | Acc: 69.970% (13479/19264)
Loss: 1.149 | Acc: 69.845% (17925/25664)
Loss: 1.146 | Acc: 69.854% (22398/32064)
Loss: 1.144 | Acc: 69.842% (26864/38464)
Loss: 1.144 | Acc: 69.880% (31351/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3856, Accuracy: 6121/10000 (61.21%)

Epoch: 56
Loss: 1.470 | Acc: 60.938% (39/64)
Loss: 1.135 | Acc: 70.854% (4580/6464)
Loss: 1.136 | Acc: 70.569% (9078/12864)
Loss: 1.132 | Acc: 70.759% (13631/19264)
Loss: 1.133 | Acc: 70.675% (18138/25664)
Loss: 1.137 | Acc: 70.525% (22613/32064)
Loss: 1.138 | Acc: 70.437% (27093/38464)
Loss: 1.137 | Acc: 70.486% (31623/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3793, Accuracy: 6237/10000 (62.37%)

Epoch: 57
Loss: 1.375 | Acc: 65.625% (42/64)
Loss: 1.133 | Acc: 69.833% (4514/6464)
Loss: 1.140 | Acc: 69.893% (8991/12864)
Loss: 1.139 | Acc: 70.048% (13494/19264)
Loss: 1.140 | Acc: 70.032% (17973/25664)
Loss: 1.135 | Acc: 70.169% (22499/32064)
Loss: 1.141 | Acc: 70.024% (26934/38464)
Loss: 1.136 | Acc: 70.150% (31472/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8911, Accuracy: 4524/10000 (45.24%)

Epoch: 58
Loss: 1.375 | Acc: 62.500% (40/64)
Loss: 1.138 | Acc: 69.879% (4517/6464)
Loss: 1.149 | Acc: 69.846% (8985/12864)
Loss: 1.135 | Acc: 70.344% (13551/19264)
Loss: 1.135 | Acc: 70.359% (18057/25664)
Loss: 1.136 | Acc: 70.397% (22572/32064)
Loss: 1.136 | Acc: 70.383% (27072/38464)
Loss: 1.133 | Acc: 70.446% (31605/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3532, Accuracy: 6349/10000 (63.49%)

Epoch: 59
Loss: 0.924 | Acc: 76.562% (49/64)
Loss: 1.132 | Acc: 70.204% (4538/6464)
Loss: 1.126 | Acc: 70.398% (9056/12864)
Loss: 1.127 | Acc: 70.432% (13568/19264)
Loss: 1.119 | Acc: 70.737% (18154/25664)
Loss: 1.122 | Acc: 70.652% (22654/32064)
Loss: 1.126 | Acc: 70.572% (27145/38464)
Loss: 1.131 | Acc: 70.373% (31572/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4282, Accuracy: 5973/10000 (59.73%)

Epoch: 60
Loss: 1.078 | Acc: 70.312% (45/64)
Loss: 1.126 | Acc: 70.761% (4574/6464)
Loss: 1.120 | Acc: 70.608% (9083/12864)
Loss: 1.135 | Acc: 70.167% (13517/19264)
Loss: 1.136 | Acc: 70.235% (18025/25664)
Loss: 1.133 | Acc: 70.453% (22590/32064)
Loss: 1.129 | Acc: 70.606% (27158/38464)
Loss: 1.128 | Acc: 70.651% (31697/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3143, Accuracy: 6510/10000 (65.10%)

Epoch: 61
Loss: 1.220 | Acc: 68.750% (44/64)
Loss: 1.111 | Acc: 70.854% (4580/6464)
Loss: 1.112 | Acc: 71.043% (9139/12864)
Loss: 1.118 | Acc: 70.904% (13659/19264)
Loss: 1.124 | Acc: 70.761% (18160/25664)
Loss: 1.122 | Acc: 70.886% (22729/32064)
Loss: 1.122 | Acc: 70.879% (27263/38464)
Loss: 1.119 | Acc: 70.968% (31839/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4798, Accuracy: 5792/10000 (57.92%)

Epoch: 62
Loss: 1.157 | Acc: 73.438% (47/64)
Loss: 1.107 | Acc: 72.014% (4655/6464)
Loss: 1.099 | Acc: 72.186% (9286/12864)
Loss: 1.114 | Acc: 71.740% (13820/19264)
Loss: 1.109 | Acc: 71.715% (18405/25664)
Loss: 1.115 | Acc: 71.460% (22913/32064)
Loss: 1.115 | Acc: 71.365% (27450/38464)
Loss: 1.116 | Acc: 71.282% (31980/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3572, Accuracy: 6463/10000 (64.63%)

Epoch: 63
Loss: 0.926 | Acc: 75.000% (48/64)
Loss: 1.095 | Acc: 71.906% (4648/6464)
Loss: 1.102 | Acc: 71.603% (9211/12864)
Loss: 1.097 | Acc: 71.917% (13854/19264)
Loss: 1.108 | Acc: 71.380% (18319/25664)
Loss: 1.107 | Acc: 71.423% (22901/32064)
Loss: 1.111 | Acc: 71.321% (27433/38464)
Loss: 1.113 | Acc: 71.262% (31971/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5957, Accuracy: 5362/10000 (53.62%)

Epoch: 64
Loss: 1.077 | Acc: 71.875% (46/64)
Loss: 1.112 | Acc: 71.488% (4621/6464)
Loss: 1.107 | Acc: 71.634% (9215/12864)
Loss: 1.095 | Acc: 71.870% (13845/19264)
Loss: 1.102 | Acc: 71.704% (18402/25664)
Loss: 1.105 | Acc: 71.650% (22974/32064)
Loss: 1.103 | Acc: 71.719% (27586/38464)
Loss: 1.106 | Acc: 71.610% (32127/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6130, Accuracy: 5203/10000 (52.03%)

Epoch: 65
Loss: 1.027 | Acc: 75.000% (48/64)
Loss: 1.088 | Acc: 72.200% (4667/6464)
Loss: 1.087 | Acc: 72.271% (9297/12864)
Loss: 1.104 | Acc: 71.740% (13820/19264)
Loss: 1.100 | Acc: 71.898% (18452/25664)
Loss: 1.102 | Acc: 71.825% (23030/32064)
Loss: 1.103 | Acc: 71.781% (27610/38464)
Loss: 1.100 | Acc: 71.853% (32236/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2312, Accuracy: 6743/10000 (67.43%)

Epoch: 66
Loss: 0.953 | Acc: 76.562% (49/64)
Loss: 1.049 | Acc: 73.453% (4748/6464)
Loss: 1.082 | Acc: 72.326% (9304/12864)
Loss: 1.089 | Acc: 72.000% (13870/19264)
Loss: 1.094 | Acc: 71.813% (18430/25664)
Loss: 1.095 | Acc: 71.916% (23059/32064)
Loss: 1.096 | Acc: 71.930% (27667/38464)
Loss: 1.094 | Acc: 72.038% (32319/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6476, Accuracy: 5326/10000 (53.26%)

Epoch: 67
Loss: 1.429 | Acc: 57.812% (37/64)
Loss: 1.090 | Acc: 72.447% (4683/6464)
Loss: 1.078 | Acc: 72.715% (9354/12864)
Loss: 1.082 | Acc: 72.612% (13988/19264)
Loss: 1.090 | Acc: 72.401% (18581/25664)
Loss: 1.088 | Acc: 72.446% (23229/32064)
Loss: 1.087 | Acc: 72.390% (27844/38464)
Loss: 1.088 | Acc: 72.285% (32430/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6288, Accuracy: 5249/10000 (52.49%)

Epoch: 68
Loss: 1.035 | Acc: 71.875% (46/64)
Loss: 1.093 | Acc: 71.813% (4642/6464)
Loss: 1.074 | Acc: 72.481% (9324/12864)
Loss: 1.076 | Acc: 72.576% (13981/19264)
Loss: 1.077 | Acc: 72.541% (18617/25664)
Loss: 1.080 | Acc: 72.514% (23251/32064)
Loss: 1.083 | Acc: 72.385% (27842/38464)
Loss: 1.079 | Acc: 72.499% (32526/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6003, Accuracy: 5288/10000 (52.88%)

Epoch: 69
Loss: 1.188 | Acc: 65.625% (42/64)
Loss: 1.042 | Acc: 73.407% (4745/6464)
Loss: 1.052 | Acc: 73.321% (9432/12864)
Loss: 1.066 | Acc: 72.898% (14043/19264)
Loss: 1.070 | Acc: 72.923% (18715/25664)
Loss: 1.070 | Acc: 72.829% (23352/32064)
Loss: 1.069 | Acc: 72.847% (28020/38464)
Loss: 1.070 | Acc: 72.878% (32696/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3804, Accuracy: 6189/10000 (61.89%)

Epoch: 70
Loss: 1.176 | Acc: 68.750% (44/64)
Loss: 1.022 | Acc: 74.257% (4800/6464)
Loss: 1.024 | Acc: 74.215% (9547/12864)
Loss: 1.038 | Acc: 73.905% (14237/19264)
Loss: 1.041 | Acc: 73.835% (18949/25664)
Loss: 1.052 | Acc: 73.553% (23584/32064)
Loss: 1.057 | Acc: 73.360% (28217/38464)
Loss: 1.062 | Acc: 73.248% (32862/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4744, Accuracy: 5824/10000 (58.24%)

Epoch: 71
Loss: 1.111 | Acc: 70.312% (45/64)
Loss: 1.029 | Acc: 73.933% (4779/6464)
Loss: 1.034 | Acc: 73.888% (9505/12864)
Loss: 1.046 | Acc: 73.567% (14172/19264)
Loss: 1.047 | Acc: 73.543% (18874/25664)
Loss: 1.048 | Acc: 73.540% (23580/32064)
Loss: 1.052 | Acc: 73.476% (28262/38464)
Loss: 1.051 | Acc: 73.453% (32954/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8190, Accuracy: 4836/10000 (48.36%)

Epoch: 72
Loss: 1.110 | Acc: 62.500% (40/64)
Loss: 1.035 | Acc: 73.886% (4776/6464)
Loss: 1.039 | Acc: 73.818% (9496/12864)
Loss: 1.050 | Acc: 73.349% (14130/19264)
Loss: 1.049 | Acc: 73.449% (18850/25664)
Loss: 1.047 | Acc: 73.565% (23588/32064)
Loss: 1.045 | Acc: 73.674% (28338/38464)
Loss: 1.048 | Acc: 73.643% (33039/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4544, Accuracy: 5911/10000 (59.11%)

Epoch: 73
Loss: 1.124 | Acc: 71.875% (46/64)
Loss: 1.031 | Acc: 74.025% (4785/6464)
Loss: 1.035 | Acc: 74.036% (9524/12864)
Loss: 1.038 | Acc: 74.034% (14262/19264)
Loss: 1.041 | Acc: 73.948% (18978/25664)
Loss: 1.040 | Acc: 73.999% (23727/32064)
Loss: 1.037 | Acc: 74.054% (28484/38464)
Loss: 1.039 | Acc: 73.972% (33187/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3016, Accuracy: 6583/10000 (65.83%)

Epoch: 74
Loss: 1.114 | Acc: 71.875% (46/64)
Loss: 1.009 | Acc: 75.015% (4849/6464)
Loss: 1.013 | Acc: 74.775% (9619/12864)
Loss: 1.022 | Acc: 74.543% (14360/19264)
Loss: 1.026 | Acc: 74.470% (19112/25664)
Loss: 1.023 | Acc: 74.579% (23913/32064)
Loss: 1.030 | Acc: 74.301% (28579/38464)
Loss: 1.029 | Acc: 74.305% (33336/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2211, Accuracy: 6836/10000 (68.36%)

Epoch: 75
Loss: 0.930 | Acc: 81.250% (52/64)
Loss: 1.006 | Acc: 75.062% (4852/6464)
Loss: 1.016 | Acc: 74.642% (9602/12864)
Loss: 1.017 | Acc: 74.533% (14358/19264)
Loss: 1.017 | Acc: 74.513% (19123/25664)
Loss: 1.015 | Acc: 74.582% (23914/32064)
Loss: 1.019 | Acc: 74.535% (28669/38464)
Loss: 1.019 | Acc: 74.583% (33461/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2863, Accuracy: 6647/10000 (66.47%)

Epoch: 76
Loss: 0.862 | Acc: 79.688% (51/64)
Loss: 0.982 | Acc: 75.928% (4908/6464)
Loss: 0.980 | Acc: 75.832% (9755/12864)
Loss: 0.994 | Acc: 75.535% (14551/19264)
Loss: 1.000 | Acc: 75.343% (19336/25664)
Loss: 1.006 | Acc: 75.190% (24109/32064)
Loss: 1.007 | Acc: 75.094% (28884/38464)
Loss: 1.004 | Acc: 75.234% (33753/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2153, Accuracy: 6874/10000 (68.74%)

Epoch: 77
Loss: 0.983 | Acc: 78.125% (50/64)
Loss: 0.977 | Acc: 75.480% (4879/6464)
Loss: 0.990 | Acc: 75.334% (9691/12864)
Loss: 0.988 | Acc: 75.483% (14541/19264)
Loss: 0.994 | Acc: 75.218% (19304/25664)
Loss: 0.994 | Acc: 75.203% (24113/32064)
Loss: 0.994 | Acc: 75.226% (28935/38464)
Loss: 0.993 | Acc: 75.290% (33778/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2728, Accuracy: 6661/10000 (66.61%)

Epoch: 78
Loss: 0.872 | Acc: 76.562% (49/64)
Loss: 0.967 | Acc: 76.454% (4942/6464)
Loss: 0.975 | Acc: 76.026% (9780/12864)
Loss: 0.984 | Acc: 75.742% (14591/19264)
Loss: 0.985 | Acc: 75.682% (19423/25664)
Loss: 0.985 | Acc: 75.674% (24264/32064)
Loss: 0.980 | Acc: 75.746% (29135/38464)
Loss: 0.982 | Acc: 75.709% (33966/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2089, Accuracy: 6863/10000 (68.63%)

Epoch: 79
Loss: 1.060 | Acc: 71.875% (46/64)
Loss: 0.942 | Acc: 77.150% (4987/6464)
Loss: 0.954 | Acc: 76.625% (9857/12864)
Loss: 0.955 | Acc: 76.651% (14766/19264)
Loss: 0.963 | Acc: 76.422% (19613/25664)
Loss: 0.964 | Acc: 76.441% (24510/32064)
Loss: 0.963 | Acc: 76.469% (29413/38464)
Loss: 0.961 | Acc: 76.518% (34329/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4348, Accuracy: 5996/10000 (59.96%)

Epoch: 80
Loss: 1.418 | Acc: 60.938% (39/64)
Loss: 0.979 | Acc: 75.944% (4909/6464)
Loss: 0.960 | Acc: 76.454% (9835/12864)
Loss: 0.960 | Acc: 76.448% (14727/19264)
Loss: 0.954 | Acc: 76.562% (19649/25664)
Loss: 0.952 | Acc: 76.669% (24583/32064)
Loss: 0.955 | Acc: 76.586% (29458/38464)
Loss: 0.954 | Acc: 76.594% (34363/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2190, Accuracy: 6957/10000 (69.57%)

Epoch: 81
Loss: 0.859 | Acc: 78.125% (50/64)
Loss: 0.936 | Acc: 76.903% (4971/6464)
Loss: 0.939 | Acc: 76.873% (9889/12864)
Loss: 0.940 | Acc: 76.926% (14819/19264)
Loss: 0.945 | Acc: 76.773% (19703/25664)
Loss: 0.941 | Acc: 76.943% (24671/32064)
Loss: 0.939 | Acc: 76.991% (29614/38464)
Loss: 0.943 | Acc: 76.839% (34473/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2777, Accuracy: 6717/10000 (67.17%)

Epoch: 82
Loss: 0.855 | Acc: 81.250% (52/64)
Loss: 0.933 | Acc: 76.918% (4972/6464)
Loss: 0.930 | Acc: 77.169% (9927/12864)
Loss: 0.920 | Acc: 77.398% (14910/19264)
Loss: 0.918 | Acc: 77.517% (19894/25664)
Loss: 0.920 | Acc: 77.433% (24828/32064)
Loss: 0.923 | Acc: 77.428% (29782/38464)
Loss: 0.924 | Acc: 77.427% (34737/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1602, Accuracy: 7163/10000 (71.63%)

Epoch: 83
Loss: 1.129 | Acc: 70.312% (45/64)
Loss: 0.856 | Acc: 79.378% (5131/6464)
Loss: 0.878 | Acc: 78.560% (10106/12864)
Loss: 0.882 | Acc: 78.374% (15098/19264)
Loss: 0.896 | Acc: 78.086% (20040/25664)
Loss: 0.896 | Acc: 78.063% (25030/32064)
Loss: 0.899 | Acc: 78.029% (30013/38464)
Loss: 0.900 | Acc: 78.072% (35026/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3889, Accuracy: 6437/10000 (64.37%)

Epoch: 84
Loss: 0.685 | Acc: 82.812% (53/64)
Loss: 0.875 | Acc: 78.666% (5085/6464)
Loss: 0.881 | Acc: 78.428% (10089/12864)
Loss: 0.887 | Acc: 78.234% (15071/19264)
Loss: 0.891 | Acc: 78.164% (20060/25664)
Loss: 0.882 | Acc: 78.396% (25137/32064)
Loss: 0.883 | Acc: 78.416% (30162/38464)
Loss: 0.885 | Acc: 78.357% (35154/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1798, Accuracy: 7159/10000 (71.59%)

Epoch: 85
Loss: 0.913 | Acc: 76.562% (49/64)
Loss: 0.846 | Acc: 79.254% (5123/6464)
Loss: 0.847 | Acc: 79.167% (10184/12864)
Loss: 0.846 | Acc: 79.267% (15270/19264)
Loss: 0.847 | Acc: 79.247% (20338/25664)
Loss: 0.845 | Acc: 79.385% (25454/32064)
Loss: 0.852 | Acc: 79.300% (30502/38464)
Loss: 0.856 | Acc: 79.211% (35537/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1930, Accuracy: 7059/10000 (70.59%)

Epoch: 86
Loss: 0.859 | Acc: 78.125% (50/64)
Loss: 0.821 | Acc: 80.167% (5182/6464)
Loss: 0.815 | Acc: 80.271% (10326/12864)
Loss: 0.805 | Acc: 80.435% (15495/19264)
Loss: 0.819 | Acc: 80.007% (20533/25664)
Loss: 0.826 | Acc: 79.815% (25592/32064)
Loss: 0.830 | Acc: 79.745% (30673/38464)
Loss: 0.833 | Acc: 79.679% (35747/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1643, Accuracy: 7214/10000 (72.14%)

Epoch: 87
Loss: 0.578 | Acc: 85.938% (55/64)
Loss: 0.800 | Acc: 80.415% (5198/6464)
Loss: 0.787 | Acc: 80.644% (10374/12864)
Loss: 0.800 | Acc: 80.248% (15459/19264)
Loss: 0.806 | Acc: 80.081% (20552/25664)
Loss: 0.806 | Acc: 80.146% (25698/32064)
Loss: 0.806 | Acc: 80.163% (30834/38464)
Loss: 0.802 | Acc: 80.256% (36006/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2257, Accuracy: 7066/10000 (70.66%)

Epoch: 88
Loss: 0.544 | Acc: 85.938% (55/64)
Loss: 0.758 | Acc: 81.281% (5254/6464)
Loss: 0.764 | Acc: 81.071% (10429/12864)
Loss: 0.760 | Acc: 81.250% (15652/19264)
Loss: 0.767 | Acc: 81.028% (20795/25664)
Loss: 0.771 | Acc: 80.932% (25950/32064)
Loss: 0.771 | Acc: 80.982% (31149/38464)
Loss: 0.773 | Acc: 80.983% (36332/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2338, Accuracy: 7143/10000 (71.43%)

Epoch: 89
Loss: 0.578 | Acc: 85.938% (55/64)
Loss: 0.713 | Acc: 82.132% (5309/6464)
Loss: 0.722 | Acc: 82.167% (10570/12864)
Loss: 0.726 | Acc: 82.008% (15798/19264)
Loss: 0.732 | Acc: 81.764% (20984/25664)
Loss: 0.735 | Acc: 81.671% (26187/32064)
Loss: 0.735 | Acc: 81.718% (31432/38464)
Loss: 0.738 | Acc: 81.658% (36635/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3031, Accuracy: 7041/10000 (70.41%)

Epoch: 90
Loss: 0.800 | Acc: 75.000% (48/64)
Loss: 0.677 | Acc: 82.952% (5362/6464)
Loss: 0.690 | Acc: 82.587% (10624/12864)
Loss: 0.687 | Acc: 82.620% (15916/19264)
Loss: 0.687 | Acc: 82.551% (21186/25664)
Loss: 0.693 | Acc: 82.398% (26420/32064)
Loss: 0.697 | Acc: 82.298% (31655/38464)
Loss: 0.696 | Acc: 82.380% (36959/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2705, Accuracy: 7117/10000 (71.17%)

Epoch: 91
Loss: 0.494 | Acc: 89.062% (57/64)
Loss: 0.642 | Acc: 83.540% (5400/6464)
Loss: 0.636 | Acc: 83.512% (10743/12864)
Loss: 0.650 | Acc: 83.124% (16013/19264)
Loss: 0.647 | Acc: 83.303% (21379/25664)
Loss: 0.650 | Acc: 83.240% (26690/32064)
Loss: 0.651 | Acc: 83.288% (32036/38464)
Loss: 0.649 | Acc: 83.336% (37388/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3235, Accuracy: 7075/10000 (70.75%)

Epoch: 92
Loss: 0.755 | Acc: 82.812% (53/64)
Loss: 0.577 | Acc: 85.334% (5516/6464)
Loss: 0.577 | Acc: 85.261% (10968/12864)
Loss: 0.581 | Acc: 85.081% (16390/19264)
Loss: 0.589 | Acc: 84.796% (21762/25664)
Loss: 0.598 | Acc: 84.540% (27107/32064)
Loss: 0.599 | Acc: 84.482% (32495/38464)
Loss: 0.600 | Acc: 84.455% (37890/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3532, Accuracy: 7076/10000 (70.76%)

Epoch: 93
Loss: 0.477 | Acc: 87.500% (56/64)
Loss: 0.537 | Acc: 85.752% (5543/6464)
Loss: 0.531 | Acc: 85.992% (11062/12864)
Loss: 0.531 | Acc: 86.010% (16569/19264)
Loss: 0.540 | Acc: 85.801% (22020/25664)
Loss: 0.539 | Acc: 85.794% (27509/32064)
Loss: 0.544 | Acc: 85.633% (32938/38464)
Loss: 0.544 | Acc: 85.610% (38408/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3991, Accuracy: 7125/10000 (71.25%)

Epoch: 94
Loss: 0.406 | Acc: 90.625% (58/64)
Loss: 0.485 | Acc: 86.788% (5610/6464)
Loss: 0.493 | Acc: 86.676% (11150/12864)
Loss: 0.496 | Acc: 86.555% (16674/19264)
Loss: 0.494 | Acc: 86.452% (22187/25664)
Loss: 0.496 | Acc: 86.549% (27751/32064)
Loss: 0.494 | Acc: 86.624% (33319/38464)
Loss: 0.491 | Acc: 86.709% (38901/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4347, Accuracy: 7081/10000 (70.81%)

Epoch: 95
Loss: 0.317 | Acc: 89.062% (57/64)
Loss: 0.430 | Acc: 88.072% (5693/6464)
Loss: 0.439 | Acc: 87.858% (11302/12864)
Loss: 0.446 | Acc: 87.786% (16911/19264)
Loss: 0.447 | Acc: 87.820% (22538/25664)
Loss: 0.452 | Acc: 87.706% (28122/32064)
Loss: 0.457 | Acc: 87.557% (33678/38464)
Loss: 0.456 | Acc: 87.562% (39284/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4393, Accuracy: 7079/10000 (70.79%)

Epoch: 96
Loss: 0.461 | Acc: 90.625% (58/64)
Loss: 0.446 | Acc: 87.608% (5663/6464)
Loss: 0.434 | Acc: 87.873% (11304/12864)
Loss: 0.437 | Acc: 87.739% (16902/19264)
Loss: 0.436 | Acc: 87.792% (22531/25664)
Loss: 0.434 | Acc: 87.999% (28216/32064)
Loss: 0.432 | Acc: 87.999% (33848/38464)
Loss: 0.431 | Acc: 88.008% (39484/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4427, Accuracy: 7086/10000 (70.86%)

Epoch: 97
Loss: 0.607 | Acc: 79.688% (51/64)
Loss: 0.409 | Acc: 88.753% (5737/6464)
Loss: 0.412 | Acc: 88.542% (11390/12864)
Loss: 0.409 | Acc: 88.517% (17052/19264)
Loss: 0.405 | Acc: 88.657% (22753/25664)
Loss: 0.404 | Acc: 88.729% (28450/32064)
Loss: 0.402 | Acc: 88.803% (34157/38464)
Loss: 0.404 | Acc: 88.739% (39812/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4506, Accuracy: 7065/10000 (70.65%)
torch.Size([100, 10])
Test set: Average loss: 1.4506, Accuracy: 7065/10000 (70.65%)

Epoch: 98
Loss: 0.275 | Acc: 93.750% (60/64)
Loss: 0.398 | Acc: 88.784% (5739/6464)
Loss: 0.403 | Acc: 88.689% (11409/12864)
Loss: 0.399 | Acc: 88.839% (17114/19264)
Loss: 0.397 | Acc: 88.922% (22821/25664)
Loss: 0.395 | Acc: 88.956% (28523/32064)
Loss: 0.395 | Acc: 88.948% (34213/38464)
Loss: 0.394 | Acc: 88.973% (39917/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4517, Accuracy: 7106/10000 (71.06%)
torch.Size([100, 10])
Test set: Average loss: 1.4517, Accuracy: 7106/10000 (71.06%)

Epoch: 99
Loss: 0.214 | Acc: 95.312% (61/64)
Loss: 0.371 | Acc: 89.743% (5801/6464)
Loss: 0.379 | Acc: 89.373% (11497/12864)
Loss: 0.380 | Acc: 89.353% (17213/19264)
Loss: 0.381 | Acc: 89.285% (22914/25664)
Loss: 0.382 | Acc: 89.231% (28611/32064)
Loss: 0.383 | Acc: 89.218% (34317/38464)
Loss: 0.382 | Acc: 89.219% (40027/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4505, Accuracy: 7095/10000 (70.95%)
torch.Size([100, 10])
Test set: Average loss: 1.4505, Accuracy: 7095/10000 (70.95%)

Epoch: 100
Loss: 0.389 | Acc: 87.500% (56/64)
Loss: 1.605 | Acc: 50.820% (3285/6464)
Loss: 1.462 | Acc: 56.608% (7282/12864)
Loss: 1.379 | Acc: 59.910% (11541/19264)
Loss: 1.335 | Acc: 61.744% (15846/25664)
Loss: 1.305 | Acc: 63.033% (20211/32064)
Loss: 1.285 | Acc: 63.826% (24550/38464)
Loss: 1.271 | Acc: 64.495% (28935/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8374, Accuracy: 4542/10000 (45.42%)

Epoch: 101
Loss: 1.358 | Acc: 59.375% (38/64)
Loss: 1.136 | Acc: 70.251% (4541/6464)
Loss: 1.147 | Acc: 69.784% (8977/12864)
Loss: 1.143 | Acc: 69.757% (13438/19264)
Loss: 1.144 | Acc: 69.794% (17912/25664)
Loss: 1.144 | Acc: 69.785% (22376/32064)
Loss: 1.142 | Acc: 69.839% (26863/38464)
Loss: 1.144 | Acc: 69.911% (31365/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2677, Accuracy: 6606/10000 (66.06%)

Epoch: 102
Loss: 0.821 | Acc: 76.562% (49/64)
Loss: 1.121 | Acc: 70.606% (4564/6464)
Loss: 1.117 | Acc: 70.903% (9121/12864)
Loss: 1.125 | Acc: 70.536% (13588/19264)
Loss: 1.124 | Acc: 70.593% (18117/25664)
Loss: 1.124 | Acc: 70.646% (22652/32064)
Loss: 1.127 | Acc: 70.554% (27138/38464)
Loss: 1.127 | Acc: 70.604% (31676/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6339, Accuracy: 5182/10000 (51.82%)

Epoch: 103
Loss: 1.298 | Acc: 60.938% (39/64)
Loss: 1.136 | Acc: 70.050% (4528/6464)
Loss: 1.132 | Acc: 70.390% (9055/12864)
Loss: 1.127 | Acc: 70.660% (13612/19264)
Loss: 1.121 | Acc: 70.870% (18188/25664)
Loss: 1.122 | Acc: 70.824% (22709/32064)
Loss: 1.124 | Acc: 70.851% (27252/38464)
Loss: 1.124 | Acc: 70.821% (31773/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7329, Accuracy: 5126/10000 (51.26%)

Epoch: 104
Loss: 1.204 | Acc: 70.312% (45/64)
Loss: 1.086 | Acc: 71.829% (4643/6464)
Loss: 1.110 | Acc: 71.393% (9184/12864)
Loss: 1.108 | Acc: 71.403% (13755/19264)
Loss: 1.114 | Acc: 71.201% (18273/25664)
Loss: 1.116 | Acc: 71.301% (22862/32064)
Loss: 1.120 | Acc: 71.105% (27350/38464)
Loss: 1.121 | Acc: 71.070% (31885/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6857, Accuracy: 5077/10000 (50.77%)

Epoch: 105
Loss: 1.506 | Acc: 57.812% (37/64)
Loss: 1.131 | Acc: 70.823% (4578/6464)
Loss: 1.112 | Acc: 71.315% (9174/12864)
Loss: 1.114 | Acc: 71.351% (13745/19264)
Loss: 1.107 | Acc: 71.462% (18340/25664)
Loss: 1.110 | Acc: 71.435% (22905/32064)
Loss: 1.114 | Acc: 71.347% (27443/38464)
Loss: 1.116 | Acc: 71.204% (31945/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5950, Accuracy: 5548/10000 (55.48%)

Epoch: 106
Loss: 1.208 | Acc: 65.625% (42/64)
Loss: 1.106 | Acc: 71.643% (4631/6464)
Loss: 1.122 | Acc: 70.989% (9132/12864)
Loss: 1.116 | Acc: 71.200% (13716/19264)
Loss: 1.118 | Acc: 71.146% (18259/25664)
Loss: 1.117 | Acc: 71.105% (22799/32064)
Loss: 1.120 | Acc: 70.965% (27296/38464)
Loss: 1.121 | Acc: 70.943% (31828/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6792, Accuracy: 5305/10000 (53.05%)

Epoch: 107
Loss: 1.113 | Acc: 68.750% (44/64)
Loss: 1.059 | Acc: 72.896% (4712/6464)
Loss: 1.081 | Acc: 72.139% (9280/12864)
Loss: 1.097 | Acc: 71.859% (13843/19264)
Loss: 1.107 | Acc: 71.594% (18374/25664)
Loss: 1.105 | Acc: 71.641% (22971/32064)
Loss: 1.110 | Acc: 71.514% (27507/38464)
Loss: 1.112 | Acc: 71.496% (32076/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9462, Accuracy: 4638/10000 (46.38%)

Epoch: 108
Loss: 1.442 | Acc: 57.812% (37/64)
Loss: 1.103 | Acc: 71.457% (4619/6464)
Loss: 1.102 | Acc: 71.556% (9205/12864)
Loss: 1.107 | Acc: 71.501% (13774/19264)
Loss: 1.107 | Acc: 71.552% (18363/25664)
Loss: 1.106 | Acc: 71.579% (22951/32064)
Loss: 1.111 | Acc: 71.376% (27454/38464)
Loss: 1.111 | Acc: 71.353% (32012/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9520, Accuracy: 4424/10000 (44.24%)

Epoch: 109
Loss: 1.276 | Acc: 65.625% (42/64)
Loss: 1.126 | Acc: 70.545% (4560/6464)
Loss: 1.112 | Acc: 71.074% (9143/12864)
Loss: 1.108 | Acc: 71.273% (13730/19264)
Loss: 1.107 | Acc: 71.462% (18340/25664)
Loss: 1.109 | Acc: 71.392% (22891/32064)
Loss: 1.112 | Acc: 71.256% (27408/38464)
Loss: 1.111 | Acc: 71.313% (31994/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7388, Accuracy: 4933/10000 (49.33%)

Epoch: 110
Loss: 1.416 | Acc: 60.938% (39/64)
Loss: 1.105 | Acc: 71.334% (4611/6464)
Loss: 1.089 | Acc: 72.015% (9264/12864)
Loss: 1.088 | Acc: 72.031% (13876/19264)
Loss: 1.093 | Acc: 71.933% (18461/25664)
Loss: 1.098 | Acc: 71.750% (23006/32064)
Loss: 1.100 | Acc: 71.685% (27573/38464)
Loss: 1.100 | Acc: 71.708% (32171/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4333, Accuracy: 5978/10000 (59.78%)

Epoch: 111
Loss: 1.064 | Acc: 71.875% (46/64)
Loss: 1.096 | Acc: 71.813% (4642/6464)
Loss: 1.099 | Acc: 71.891% (9248/12864)
Loss: 1.097 | Acc: 71.968% (13864/19264)
Loss: 1.092 | Acc: 72.113% (18507/25664)
Loss: 1.100 | Acc: 71.859% (23041/32064)
Loss: 1.100 | Acc: 71.802% (27618/38464)
Loss: 1.103 | Acc: 71.706% (32170/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4476, Accuracy: 5748/10000 (57.48%)

Epoch: 112
Loss: 1.335 | Acc: 62.500% (40/64)
Loss: 1.079 | Acc: 72.432% (4682/6464)
Loss: 1.069 | Acc: 72.551% (9333/12864)
Loss: 1.081 | Acc: 72.254% (13919/19264)
Loss: 1.084 | Acc: 72.245% (18541/25664)
Loss: 1.084 | Acc: 72.284% (23177/32064)
Loss: 1.090 | Acc: 72.138% (27747/38464)
Loss: 1.094 | Acc: 72.020% (32311/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4280, Accuracy: 5994/10000 (59.94%)

Epoch: 113
Loss: 1.155 | Acc: 71.875% (46/64)
Loss: 1.073 | Acc: 72.432% (4682/6464)
Loss: 1.083 | Acc: 72.178% (9285/12864)
Loss: 1.080 | Acc: 72.384% (13944/19264)
Loss: 1.082 | Acc: 72.245% (18541/25664)
Loss: 1.081 | Acc: 72.128% (23127/32064)
Loss: 1.087 | Acc: 71.963% (27680/38464)
Loss: 1.090 | Acc: 71.946% (32278/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9138, Accuracy: 4414/10000 (44.14%)

Epoch: 114
Loss: 1.082 | Acc: 73.438% (47/64)
Loss: 1.075 | Acc: 72.741% (4702/6464)
Loss: 1.074 | Acc: 72.738% (9357/12864)
Loss: 1.079 | Acc: 72.430% (13953/19264)
Loss: 1.081 | Acc: 72.311% (18558/25664)
Loss: 1.083 | Acc: 72.284% (23177/32064)
Loss: 1.090 | Acc: 72.104% (27734/38464)
Loss: 1.090 | Acc: 72.136% (32363/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4376, Accuracy: 6051/10000 (60.51%)

Epoch: 115
Loss: 0.914 | Acc: 73.438% (47/64)
Loss: 1.057 | Acc: 73.159% (4729/6464)
Loss: 1.066 | Acc: 73.025% (9394/12864)
Loss: 1.077 | Acc: 72.726% (14010/19264)
Loss: 1.082 | Acc: 72.650% (18645/25664)
Loss: 1.080 | Acc: 72.627% (23287/32064)
Loss: 1.079 | Acc: 72.619% (27932/38464)
Loss: 1.079 | Acc: 72.615% (32578/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4553, Accuracy: 5996/10000 (59.96%)

Epoch: 116
Loss: 1.057 | Acc: 73.438% (47/64)
Loss: 1.063 | Acc: 72.834% (4708/6464)
Loss: 1.067 | Acc: 72.839% (9370/12864)
Loss: 1.069 | Acc: 72.835% (14031/19264)
Loss: 1.074 | Acc: 72.740% (18668/25664)
Loss: 1.078 | Acc: 72.648% (23294/32064)
Loss: 1.077 | Acc: 72.642% (27941/38464)
Loss: 1.077 | Acc: 72.593% (32568/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0685, Accuracy: 4237/10000 (42.37%)

Epoch: 117
Loss: 0.944 | Acc: 73.438% (47/64)
Loss: 1.078 | Acc: 72.416% (4681/6464)
Loss: 1.084 | Acc: 72.303% (9301/12864)
Loss: 1.072 | Acc: 72.706% (14006/19264)
Loss: 1.072 | Acc: 72.806% (18685/25664)
Loss: 1.078 | Acc: 72.742% (23324/32064)
Loss: 1.073 | Acc: 72.884% (28034/38464)
Loss: 1.069 | Acc: 72.976% (32740/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4291, Accuracy: 6154/10000 (61.54%)

Epoch: 118
Loss: 1.396 | Acc: 71.875% (46/64)
Loss: 1.035 | Acc: 73.855% (4774/6464)
Loss: 1.048 | Acc: 73.857% (9501/12864)
Loss: 1.055 | Acc: 73.614% (14181/19264)
Loss: 1.055 | Acc: 73.504% (18864/25664)
Loss: 1.061 | Acc: 73.328% (23512/32064)
Loss: 1.062 | Acc: 73.287% (28189/38464)
Loss: 1.064 | Acc: 73.235% (32856/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5022, Accuracy: 5785/10000 (57.85%)

Epoch: 119
Loss: 0.933 | Acc: 75.000% (48/64)
Loss: 1.040 | Acc: 73.886% (4776/6464)
Loss: 1.042 | Acc: 73.997% (9519/12864)
Loss: 1.042 | Acc: 73.858% (14228/19264)
Loss: 1.051 | Acc: 73.648% (18901/25664)
Loss: 1.056 | Acc: 73.434% (23546/32064)
Loss: 1.054 | Acc: 73.492% (28268/38464)
Loss: 1.053 | Acc: 73.527% (32987/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3721, Accuracy: 6323/10000 (63.23%)

Epoch: 120
Loss: 0.971 | Acc: 75.000% (48/64)
Loss: 1.051 | Acc: 73.267% (4736/6464)
Loss: 1.048 | Acc: 73.632% (9472/12864)
Loss: 1.043 | Acc: 73.707% (14199/19264)
Loss: 1.042 | Acc: 73.702% (18915/25664)
Loss: 1.041 | Acc: 73.809% (23666/32064)
Loss: 1.044 | Acc: 73.674% (28338/38464)
Loss: 1.048 | Acc: 73.578% (33010/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2872, Accuracy: 6630/10000 (66.30%)

Epoch: 121
Loss: 1.149 | Acc: 70.312% (45/64)
Loss: 0.992 | Acc: 75.665% (4891/6464)
Loss: 1.021 | Acc: 74.635% (9601/12864)
Loss: 1.033 | Acc: 74.325% (14318/19264)
Loss: 1.040 | Acc: 73.882% (18961/25664)
Loss: 1.032 | Acc: 74.124% (23767/32064)
Loss: 1.038 | Acc: 74.043% (28480/38464)
Loss: 1.042 | Acc: 73.928% (33167/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2741, Accuracy: 6558/10000 (65.58%)

Epoch: 122
Loss: 1.007 | Acc: 70.312% (45/64)
Loss: 1.021 | Acc: 74.242% (4799/6464)
Loss: 1.012 | Acc: 74.611% (9598/12864)
Loss: 1.017 | Acc: 74.413% (14335/19264)
Loss: 1.016 | Acc: 74.587% (19142/25664)
Loss: 1.022 | Acc: 74.467% (23877/32064)
Loss: 1.023 | Acc: 74.462% (28641/38464)
Loss: 1.027 | Acc: 74.307% (33337/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4370, Accuracy: 5941/10000 (59.41%)

Epoch: 123
Loss: 1.041 | Acc: 68.750% (44/64)
Loss: 1.003 | Acc: 74.768% (4833/6464)
Loss: 1.013 | Acc: 74.860% (9630/12864)
Loss: 1.015 | Acc: 74.730% (14396/19264)
Loss: 1.015 | Acc: 74.739% (19181/25664)
Loss: 1.018 | Acc: 74.607% (23922/32064)
Loss: 1.019 | Acc: 74.589% (28690/38464)
Loss: 1.021 | Acc: 74.561% (33451/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1801, Accuracy: 7064/10000 (70.64%)

Epoch: 124
Loss: 0.896 | Acc: 75.000% (48/64)
Loss: 1.004 | Acc: 75.325% (4869/6464)
Loss: 0.994 | Acc: 75.365% (9695/12864)
Loss: 1.006 | Acc: 75.093% (14466/19264)
Loss: 1.002 | Acc: 75.230% (19307/25664)
Loss: 1.008 | Acc: 74.935% (24027/32064)
Loss: 1.006 | Acc: 75.003% (28849/38464)
Loss: 1.013 | Acc: 74.777% (33548/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2395, Accuracy: 6825/10000 (68.25%)

Epoch: 125
Loss: 1.042 | Acc: 70.312% (45/64)
Loss: 0.988 | Acc: 75.464% (4878/6464)
Loss: 0.982 | Acc: 75.676% (9735/12864)
Loss: 1.001 | Acc: 75.161% (14479/19264)
Loss: 1.000 | Acc: 75.257% (19314/25664)
Loss: 1.003 | Acc: 75.253% (24129/32064)
Loss: 1.002 | Acc: 75.252% (28945/38464)
Loss: 1.003 | Acc: 75.218% (33746/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2769, Accuracy: 6610/10000 (66.10%)

Epoch: 126
Loss: 0.895 | Acc: 76.562% (49/64)
Loss: 0.963 | Acc: 76.006% (4913/6464)
Loss: 0.964 | Acc: 76.143% (9795/12864)
Loss: 0.977 | Acc: 75.841% (14610/19264)
Loss: 0.983 | Acc: 75.651% (19415/25664)
Loss: 0.987 | Acc: 75.589% (24237/32064)
Loss: 0.986 | Acc: 75.629% (29090/38464)
Loss: 0.989 | Acc: 75.506% (33875/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1726, Accuracy: 7060/10000 (70.60%)

Epoch: 127
Loss: 0.852 | Acc: 81.250% (52/64)
Loss: 0.953 | Acc: 76.423% (4940/6464)
Loss: 0.966 | Acc: 76.306% (9816/12864)
Loss: 0.974 | Acc: 76.059% (14652/19264)
Loss: 0.979 | Acc: 75.935% (19488/25664)
Loss: 0.984 | Acc: 75.777% (24297/32064)
Loss: 0.979 | Acc: 75.931% (29206/38464)
Loss: 0.976 | Acc: 76.028% (34109/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2028, Accuracy: 6930/10000 (69.30%)

Epoch: 128
Loss: 1.260 | Acc: 70.312% (45/64)
Loss: 0.933 | Acc: 76.934% (4973/6464)
Loss: 0.952 | Acc: 76.524% (9844/12864)
Loss: 0.955 | Acc: 76.511% (14739/19264)
Loss: 0.957 | Acc: 76.617% (19663/25664)
Loss: 0.961 | Acc: 76.594% (24559/32064)
Loss: 0.964 | Acc: 76.440% (29402/38464)
Loss: 0.967 | Acc: 76.342% (34250/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3048, Accuracy: 6553/10000 (65.53%)

Epoch: 129
Loss: 0.850 | Acc: 79.688% (51/64)
Loss: 0.934 | Acc: 77.197% (4990/6464)
Loss: 0.942 | Acc: 77.037% (9910/12864)
Loss: 0.931 | Acc: 77.180% (14868/19264)
Loss: 0.936 | Acc: 76.979% (19756/25664)
Loss: 0.949 | Acc: 76.656% (24579/32064)
Loss: 0.952 | Acc: 76.633% (29476/38464)
Loss: 0.955 | Acc: 76.618% (34374/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2628, Accuracy: 6783/10000 (67.83%)

Epoch: 130
Loss: 1.070 | Acc: 73.438% (47/64)
Loss: 0.938 | Acc: 76.980% (4976/6464)
Loss: 0.955 | Acc: 76.609% (9855/12864)
Loss: 0.947 | Acc: 76.864% (14807/19264)
Loss: 0.945 | Acc: 76.937% (19745/25664)
Loss: 0.940 | Acc: 77.027% (24698/32064)
Loss: 0.940 | Acc: 76.971% (29606/38464)
Loss: 0.940 | Acc: 77.013% (34551/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3105, Accuracy: 6517/10000 (65.17%)

Epoch: 131
Loss: 0.864 | Acc: 79.688% (51/64)
Loss: 0.902 | Acc: 77.924% (5037/6464)
Loss: 0.898 | Acc: 78.172% (10056/12864)
Loss: 0.903 | Acc: 78.156% (15056/19264)
Loss: 0.910 | Acc: 77.907% (19994/25664)
Loss: 0.918 | Acc: 77.716% (24919/32064)
Loss: 0.920 | Acc: 77.634% (29861/38464)
Loss: 0.923 | Acc: 77.492% (34766/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3124, Accuracy: 6610/10000 (66.10%)

Epoch: 132
Loss: 1.161 | Acc: 73.438% (47/64)
Loss: 0.887 | Acc: 78.636% (5083/6464)
Loss: 0.900 | Acc: 78.039% (10039/12864)
Loss: 0.897 | Acc: 77.985% (15023/19264)
Loss: 0.900 | Acc: 77.891% (19990/25664)
Loss: 0.906 | Acc: 77.760% (24933/32064)
Loss: 0.906 | Acc: 77.816% (29931/38464)
Loss: 0.906 | Acc: 77.800% (34904/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2056, Accuracy: 6984/10000 (69.84%)

Epoch: 133
Loss: 0.942 | Acc: 73.438% (47/64)
Loss: 0.849 | Acc: 79.486% (5138/6464)
Loss: 0.877 | Acc: 78.296% (10072/12864)
Loss: 0.884 | Acc: 78.218% (15068/19264)
Loss: 0.890 | Acc: 78.094% (20042/25664)
Loss: 0.893 | Acc: 77.991% (25007/32064)
Loss: 0.890 | Acc: 78.076% (30031/38464)
Loss: 0.888 | Acc: 78.225% (35095/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2367, Accuracy: 7025/10000 (70.25%)

Epoch: 134
Loss: 0.872 | Acc: 76.562% (49/64)
Loss: 0.842 | Acc: 79.455% (5136/6464)
Loss: 0.846 | Acc: 79.493% (10226/12864)
Loss: 0.854 | Acc: 79.267% (15270/19264)
Loss: 0.854 | Acc: 79.161% (20316/25664)
Loss: 0.859 | Acc: 79.001% (25331/32064)
Loss: 0.860 | Acc: 78.993% (30384/38464)
Loss: 0.859 | Acc: 79.021% (35452/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2127, Accuracy: 6993/10000 (69.93%)

Epoch: 135
Loss: 0.899 | Acc: 81.250% (52/64)
Loss: 0.801 | Acc: 80.817% (5224/6464)
Loss: 0.811 | Acc: 80.333% (10334/12864)
Loss: 0.820 | Acc: 80.061% (15423/19264)
Loss: 0.831 | Acc: 79.730% (20462/25664)
Loss: 0.833 | Acc: 79.625% (25531/32064)
Loss: 0.839 | Acc: 79.454% (30561/38464)
Loss: 0.837 | Acc: 79.549% (35689/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1859, Accuracy: 7200/10000 (72.00%)

Epoch: 136
Loss: 1.228 | Acc: 70.312% (45/64)
Loss: 0.796 | Acc: 80.461% (5201/6464)
Loss: 0.799 | Acc: 80.325% (10333/12864)
Loss: 0.795 | Acc: 80.466% (15501/19264)
Loss: 0.806 | Acc: 80.233% (20591/25664)
Loss: 0.806 | Acc: 80.261% (25735/32064)
Loss: 0.813 | Acc: 80.059% (30794/38464)
Loss: 0.813 | Acc: 80.071% (35923/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3103, Accuracy: 6868/10000 (68.68%)

Epoch: 137
Loss: 0.779 | Acc: 81.250% (52/64)
Loss: 0.762 | Acc: 80.941% (5232/6464)
Loss: 0.763 | Acc: 81.211% (10447/12864)
Loss: 0.771 | Acc: 81.068% (15617/19264)
Loss: 0.770 | Acc: 80.997% (20787/25664)
Loss: 0.774 | Acc: 80.863% (25928/32064)
Loss: 0.780 | Acc: 80.746% (31058/38464)
Loss: 0.780 | Acc: 80.766% (36235/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1953, Accuracy: 7211/10000 (72.11%)

Epoch: 138
Loss: 0.786 | Acc: 78.125% (50/64)
Loss: 0.739 | Acc: 81.436% (5264/6464)
Loss: 0.743 | Acc: 81.491% (10483/12864)
Loss: 0.742 | Acc: 81.546% (15709/19264)
Loss: 0.738 | Acc: 81.597% (20941/25664)
Loss: 0.742 | Acc: 81.509% (26135/32064)
Loss: 0.737 | Acc: 81.682% (31418/38464)
Loss: 0.740 | Acc: 81.649% (36631/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2199, Accuracy: 7224/10000 (72.24%)

Epoch: 139
Loss: 0.562 | Acc: 87.500% (56/64)
Loss: 0.685 | Acc: 82.472% (5331/6464)
Loss: 0.690 | Acc: 82.509% (10614/12864)
Loss: 0.694 | Acc: 82.356% (15865/19264)
Loss: 0.703 | Acc: 82.197% (21095/25664)
Loss: 0.706 | Acc: 82.129% (26334/32064)
Loss: 0.707 | Acc: 82.173% (31607/38464)
Loss: 0.709 | Acc: 82.182% (36870/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2561, Accuracy: 7075/10000 (70.75%)

Epoch: 140
Loss: 0.562 | Acc: 81.250% (52/64)
Loss: 0.649 | Acc: 83.385% (5390/6464)
Loss: 0.660 | Acc: 83.170% (10699/12864)
Loss: 0.662 | Acc: 83.119% (16012/19264)
Loss: 0.664 | Acc: 83.019% (21306/25664)
Loss: 0.662 | Acc: 83.112% (26649/32064)
Loss: 0.665 | Acc: 83.065% (31950/38464)
Loss: 0.667 | Acc: 83.013% (37243/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3225, Accuracy: 7123/10000 (71.23%)

Epoch: 141
Loss: 0.459 | Acc: 87.500% (56/64)
Loss: 0.585 | Acc: 85.133% (5503/6464)
Loss: 0.600 | Acc: 84.499% (10870/12864)
Loss: 0.611 | Acc: 84.209% (16222/19264)
Loss: 0.617 | Acc: 84.032% (21566/25664)
Loss: 0.616 | Acc: 84.085% (26961/32064)
Loss: 0.614 | Acc: 84.133% (32361/38464)
Loss: 0.618 | Acc: 84.034% (37701/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3452, Accuracy: 7078/10000 (70.78%)

Epoch: 142
Loss: 0.554 | Acc: 89.062% (57/64)
Loss: 0.581 | Acc: 84.313% (5450/6464)
Loss: 0.571 | Acc: 84.795% (10908/12864)
Loss: 0.575 | Acc: 84.629% (16303/19264)
Loss: 0.568 | Acc: 84.854% (21777/25664)
Loss: 0.569 | Acc: 84.908% (27225/32064)
Loss: 0.571 | Acc: 84.872% (32645/38464)
Loss: 0.574 | Acc: 84.801% (38045/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3468, Accuracy: 7158/10000 (71.58%)

Epoch: 143
Loss: 0.511 | Acc: 89.062% (57/64)
Loss: 0.514 | Acc: 86.170% (5570/6464)
Loss: 0.513 | Acc: 86.194% (11088/12864)
Loss: 0.512 | Acc: 86.244% (16614/19264)
Loss: 0.516 | Acc: 86.183% (22118/25664)
Loss: 0.515 | Acc: 86.243% (27653/32064)
Loss: 0.515 | Acc: 86.255% (33177/38464)
Loss: 0.516 | Acc: 86.198% (38672/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3938, Accuracy: 7079/10000 (70.79%)

Epoch: 144
Loss: 0.526 | Acc: 89.062% (57/64)
Loss: 0.459 | Acc: 87.500% (5656/6464)
Loss: 0.467 | Acc: 87.321% (11233/12864)
Loss: 0.463 | Acc: 87.355% (16828/19264)
Loss: 0.463 | Acc: 87.332% (22413/25664)
Loss: 0.461 | Acc: 87.391% (28021/32064)
Loss: 0.461 | Acc: 87.380% (33610/38464)
Loss: 0.460 | Acc: 87.393% (39208/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4604, Accuracy: 7054/10000 (70.54%)

Epoch: 145
Loss: 0.355 | Acc: 92.188% (59/64)
Loss: 0.402 | Acc: 88.629% (5729/6464)
Loss: 0.409 | Acc: 88.689% (11409/12864)
Loss: 0.414 | Acc: 88.595% (17067/19264)
Loss: 0.415 | Acc: 88.556% (22727/25664)
Loss: 0.416 | Acc: 88.514% (28381/32064)
Loss: 0.418 | Acc: 88.449% (34021/38464)
Loss: 0.420 | Acc: 88.423% (39670/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4722, Accuracy: 6998/10000 (69.98%)

Epoch: 146
Loss: 0.600 | Acc: 79.688% (51/64)
Loss: 0.382 | Acc: 89.356% (5776/6464)
Loss: 0.392 | Acc: 89.164% (11470/12864)
Loss: 0.402 | Acc: 88.870% (17120/19264)
Loss: 0.396 | Acc: 89.051% (22854/25664)
Loss: 0.398 | Acc: 89.022% (28544/32064)
Loss: 0.399 | Acc: 88.974% (34223/38464)
Loss: 0.398 | Acc: 89.005% (39931/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4789, Accuracy: 7056/10000 (70.56%)

Epoch: 147
Loss: 0.195 | Acc: 95.312% (61/64)
Loss: 0.356 | Acc: 90.068% (5822/6464)
Loss: 0.359 | Acc: 90.182% (11601/12864)
Loss: 0.369 | Acc: 89.737% (17287/19264)
Loss: 0.367 | Acc: 89.830% (23054/25664)
Loss: 0.371 | Acc: 89.677% (28754/32064)
Loss: 0.373 | Acc: 89.564% (34450/38464)
Loss: 0.374 | Acc: 89.531% (40167/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4745, Accuracy: 7058/10000 (70.58%)
torch.Size([100, 10])
Test set: Average loss: 1.4745, Accuracy: 7058/10000 (70.58%)

Epoch: 148
Loss: 0.209 | Acc: 93.750% (60/64)
Loss: 0.340 | Acc: 90.548% (5853/6464)
Loss: 0.344 | Acc: 90.345% (11622/12864)
Loss: 0.351 | Acc: 90.111% (17359/19264)
Loss: 0.353 | Acc: 89.974% (23091/25664)
Loss: 0.352 | Acc: 90.064% (28878/32064)
Loss: 0.355 | Acc: 89.923% (34588/38464)
Loss: 0.357 | Acc: 89.852% (40311/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4858, Accuracy: 7044/10000 (70.44%)
torch.Size([100, 10])
Test set: Average loss: 1.4858, Accuracy: 7044/10000 (70.44%)

Epoch: 149
Loss: 0.310 | Acc: 92.188% (59/64)
Loss: 0.364 | Acc: 89.712% (5799/6464)
Loss: 0.349 | Acc: 90.073% (11587/12864)
Loss: 0.352 | Acc: 89.987% (17335/19264)
Loss: 0.348 | Acc: 90.064% (23114/25664)
Loss: 0.348 | Acc: 90.085% (28885/32064)
Loss: 0.353 | Acc: 89.894% (34577/38464)
Loss: 0.351 | Acc: 89.999% (40377/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5002, Accuracy: 7052/10000 (70.52%)
torch.Size([100, 10])
Test set: Average loss: 1.5002, Accuracy: 7052/10000 (70.52%)

Epoch: 150
Loss: 0.256 | Acc: 92.188% (59/64)
Loss: 1.893 | Acc: 35.489% (2294/6464)
Loss: 1.631 | Acc: 48.228% (6204/12864)
Loss: 1.513 | Acc: 53.571% (10320/19264)
Loss: 1.444 | Acc: 56.873% (14596/25664)
Loss: 1.391 | Acc: 59.253% (18999/32064)
Loss: 1.356 | Acc: 60.730% (23359/38464)
Loss: 1.331 | Acc: 61.791% (27722/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7439, Accuracy: 4894/10000 (48.94%)

Epoch: 151
Loss: 0.961 | Acc: 68.750% (44/64)
Loss: 1.157 | Acc: 68.967% (4458/6464)
Loss: 1.152 | Acc: 69.325% (8918/12864)
Loss: 1.159 | Acc: 69.093% (13310/19264)
Loss: 1.154 | Acc: 69.241% (17770/25664)
Loss: 1.150 | Acc: 69.508% (22287/32064)
Loss: 1.146 | Acc: 69.772% (26837/38464)
Loss: 1.145 | Acc: 69.844% (31335/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4897, Accuracy: 3147/10000 (31.47%)

Epoch: 152
Loss: 1.324 | Acc: 65.625% (42/64)
Loss: 1.115 | Acc: 71.241% (4605/6464)
Loss: 1.104 | Acc: 71.549% (9204/12864)
Loss: 1.122 | Acc: 71.117% (13700/19264)
Loss: 1.127 | Acc: 70.839% (18180/25664)
Loss: 1.131 | Acc: 70.668% (22659/32064)
Loss: 1.132 | Acc: 70.728% (27205/38464)
Loss: 1.127 | Acc: 70.908% (31812/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6772, Accuracy: 4862/10000 (48.62%)

Epoch: 153
Loss: 1.143 | Acc: 64.062% (41/64)
Loss: 1.131 | Acc: 70.142% (4534/6464)
Loss: 1.097 | Acc: 71.727% (9227/12864)
Loss: 1.115 | Acc: 71.039% (13685/19264)
Loss: 1.112 | Acc: 71.232% (18281/25664)
Loss: 1.115 | Acc: 71.254% (22847/32064)
Loss: 1.118 | Acc: 71.022% (27318/38464)
Loss: 1.120 | Acc: 70.950% (31831/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2768, Accuracy: 6601/10000 (66.01%)

Epoch: 154
Loss: 1.225 | Acc: 70.312% (45/64)
Loss: 1.081 | Acc: 71.875% (4646/6464)
Loss: 1.094 | Acc: 71.447% (9191/12864)
Loss: 1.104 | Acc: 71.283% (13732/19264)
Loss: 1.107 | Acc: 71.259% (18288/25664)
Loss: 1.112 | Acc: 71.158% (22816/32064)
Loss: 1.112 | Acc: 71.220% (27394/38464)
Loss: 1.114 | Acc: 71.209% (31947/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8071, Accuracy: 4554/10000 (45.54%)

Epoch: 155
Loss: 1.297 | Acc: 60.938% (39/64)
Loss: 1.110 | Acc: 71.179% (4601/6464)
Loss: 1.111 | Acc: 71.424% (9188/12864)
Loss: 1.098 | Acc: 71.818% (13835/19264)
Loss: 1.104 | Acc: 71.594% (18374/25664)
Loss: 1.103 | Acc: 71.672% (22981/32064)
Loss: 1.107 | Acc: 71.566% (27527/38464)
Loss: 1.108 | Acc: 71.556% (32103/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3938, Accuracy: 6100/10000 (61.00%)

Epoch: 156
Loss: 0.867 | Acc: 79.688% (51/64)
Loss: 1.106 | Acc: 71.519% (4623/6464)
Loss: 1.092 | Acc: 71.875% (9246/12864)
Loss: 1.087 | Acc: 72.031% (13876/19264)
Loss: 1.089 | Acc: 72.066% (18495/25664)
Loss: 1.097 | Acc: 71.753% (23007/32064)
Loss: 1.103 | Acc: 71.584% (27534/38464)
Loss: 1.104 | Acc: 71.614% (32129/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7016, Accuracy: 5283/10000 (52.83%)

Epoch: 157
Loss: 1.068 | Acc: 68.750% (44/64)
Loss: 1.107 | Acc: 71.024% (4591/6464)
Loss: 1.093 | Acc: 71.813% (9238/12864)
Loss: 1.104 | Acc: 71.470% (13768/19264)
Loss: 1.107 | Acc: 71.505% (18351/25664)
Loss: 1.109 | Acc: 71.392% (22891/32064)
Loss: 1.108 | Acc: 71.430% (27475/38464)
Loss: 1.107 | Acc: 71.460% (32060/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2971, Accuracy: 6498/10000 (64.98%)

Epoch: 158
Loss: 1.395 | Acc: 62.500% (40/64)
Loss: 1.096 | Acc: 72.123% (4662/6464)
Loss: 1.095 | Acc: 71.929% (9253/12864)
Loss: 1.094 | Acc: 71.932% (13857/19264)
Loss: 1.094 | Acc: 71.972% (18471/25664)
Loss: 1.095 | Acc: 71.937% (23066/32064)
Loss: 1.097 | Acc: 71.854% (27638/38464)
Loss: 1.100 | Acc: 71.750% (32190/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3163, Accuracy: 6445/10000 (64.45%)

Epoch: 159
Loss: 1.007 | Acc: 75.000% (48/64)
Loss: 1.086 | Acc: 72.308% (4674/6464)
Loss: 1.086 | Acc: 72.194% (9287/12864)
Loss: 1.086 | Acc: 72.399% (13947/19264)
Loss: 1.091 | Acc: 72.163% (18520/25664)
Loss: 1.089 | Acc: 72.059% (23105/32064)
Loss: 1.094 | Acc: 71.976% (27685/38464)
Loss: 1.097 | Acc: 71.897% (32256/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5063, Accuracy: 5613/10000 (56.13%)

Epoch: 160
Loss: 1.051 | Acc: 65.625% (42/64)
Loss: 1.092 | Acc: 71.782% (4640/6464)
Loss: 1.097 | Acc: 71.549% (9204/12864)
Loss: 1.089 | Acc: 71.968% (13864/19264)
Loss: 1.088 | Acc: 71.992% (18476/25664)
Loss: 1.087 | Acc: 72.093% (23116/32064)
Loss: 1.092 | Acc: 71.961% (27679/38464)
Loss: 1.094 | Acc: 71.895% (32255/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6529, Accuracy: 5084/10000 (50.84%)

Epoch: 161
Loss: 1.622 | Acc: 60.938% (39/64)
Loss: 1.099 | Acc: 71.581% (4627/6464)
Loss: 1.089 | Acc: 72.046% (9268/12864)
Loss: 1.098 | Acc: 71.859% (13843/19264)
Loss: 1.101 | Acc: 71.781% (18422/25664)
Loss: 1.098 | Acc: 71.863% (23042/32064)
Loss: 1.099 | Acc: 71.878% (27647/38464)
Loss: 1.097 | Acc: 71.975% (32291/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5110, Accuracy: 5752/10000 (57.52%)

Epoch: 162
Loss: 1.114 | Acc: 73.438% (47/64)
Loss: 1.064 | Acc: 72.478% (4685/6464)
Loss: 1.071 | Acc: 72.613% (9341/12864)
Loss: 1.070 | Acc: 72.669% (13999/19264)
Loss: 1.080 | Acc: 72.463% (18597/25664)
Loss: 1.085 | Acc: 72.343% (23196/32064)
Loss: 1.086 | Acc: 72.262% (27795/38464)
Loss: 1.089 | Acc: 72.174% (32380/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4423, Accuracy: 6037/10000 (60.37%)

Epoch: 163
Loss: 0.953 | Acc: 73.438% (47/64)
Loss: 1.045 | Acc: 73.623% (4759/6464)
Loss: 1.062 | Acc: 73.033% (9395/12864)
Loss: 1.070 | Acc: 72.861% (14036/19264)
Loss: 1.078 | Acc: 72.584% (18628/25664)
Loss: 1.080 | Acc: 72.561% (23266/32064)
Loss: 1.084 | Acc: 72.408% (27851/38464)
Loss: 1.087 | Acc: 72.334% (32452/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3535, Accuracy: 6424/10000 (64.24%)

Epoch: 164
Loss: 1.106 | Acc: 70.312% (45/64)
Loss: 1.069 | Acc: 72.695% (4699/6464)
Loss: 1.054 | Acc: 73.165% (9412/12864)
Loss: 1.066 | Acc: 72.892% (14042/19264)
Loss: 1.072 | Acc: 72.631% (18640/25664)
Loss: 1.074 | Acc: 72.617% (23284/32064)
Loss: 1.077 | Acc: 72.533% (27899/38464)
Loss: 1.080 | Acc: 72.423% (32492/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2789, Accuracy: 6550/10000 (65.50%)

Epoch: 165
Loss: 1.366 | Acc: 68.750% (44/64)
Loss: 1.081 | Acc: 72.339% (4676/6464)
Loss: 1.074 | Acc: 72.629% (9343/12864)
Loss: 1.070 | Acc: 72.918% (14047/19264)
Loss: 1.069 | Acc: 72.943% (18720/25664)
Loss: 1.072 | Acc: 72.935% (23386/32064)
Loss: 1.070 | Acc: 72.933% (28053/38464)
Loss: 1.071 | Acc: 72.949% (32728/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4274, Accuracy: 6002/10000 (60.02%)

Epoch: 166
Loss: 1.428 | Acc: 59.375% (38/64)
Loss: 1.041 | Acc: 74.165% (4794/6464)
Loss: 1.049 | Acc: 73.935% (9511/12864)
Loss: 1.047 | Acc: 73.785% (14214/19264)
Loss: 1.057 | Acc: 73.519% (18868/25664)
Loss: 1.060 | Acc: 73.444% (23549/32064)
Loss: 1.064 | Acc: 73.217% (28162/38464)
Loss: 1.067 | Acc: 73.183% (32833/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5919, Accuracy: 5455/10000 (54.55%)

Epoch: 167
Loss: 0.930 | Acc: 75.000% (48/64)
Loss: 1.063 | Acc: 72.386% (4679/6464)
Loss: 1.070 | Acc: 72.746% (9358/12864)
Loss: 1.063 | Acc: 73.085% (14079/19264)
Loss: 1.060 | Acc: 73.231% (18794/25664)
Loss: 1.059 | Acc: 73.250% (23487/32064)
Loss: 1.059 | Acc: 73.211% (28160/38464)
Loss: 1.063 | Acc: 73.121% (32805/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9257, Accuracy: 4862/10000 (48.62%)

Epoch: 168
Loss: 0.811 | Acc: 81.250% (52/64)
Loss: 1.051 | Acc: 73.515% (4752/6464)
Loss: 1.059 | Acc: 73.181% (9414/12864)
Loss: 1.059 | Acc: 73.100% (14082/19264)
Loss: 1.060 | Acc: 73.032% (18743/25664)
Loss: 1.061 | Acc: 73.079% (23432/32064)
Loss: 1.062 | Acc: 73.003% (28080/38464)
Loss: 1.061 | Acc: 73.134% (32811/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5683, Accuracy: 5662/10000 (56.62%)

Epoch: 169
Loss: 1.154 | Acc: 64.062% (41/64)
Loss: 1.033 | Acc: 73.809% (4771/6464)
Loss: 1.048 | Acc: 73.228% (9420/12864)
Loss: 1.058 | Acc: 73.214% (14104/19264)
Loss: 1.050 | Acc: 73.574% (18882/25664)
Loss: 1.054 | Acc: 73.550% (23583/32064)
Loss: 1.051 | Acc: 73.588% (28305/38464)
Loss: 1.054 | Acc: 73.471% (32962/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4485, Accuracy: 5919/10000 (59.19%)

Epoch: 170
Loss: 1.481 | Acc: 65.625% (42/64)
Loss: 1.024 | Acc: 74.954% (4845/6464)
Loss: 1.033 | Acc: 74.596% (9596/12864)
Loss: 1.041 | Acc: 74.206% (14295/19264)
Loss: 1.042 | Acc: 74.049% (19004/25664)
Loss: 1.041 | Acc: 73.983% (23722/32064)
Loss: 1.039 | Acc: 74.009% (28467/38464)
Loss: 1.044 | Acc: 73.852% (33133/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5516, Accuracy: 5731/10000 (57.31%)

Epoch: 171
Loss: 1.041 | Acc: 70.312% (45/64)
Loss: 1.013 | Acc: 74.722% (4830/6464)
Loss: 1.021 | Acc: 74.627% (9600/12864)
Loss: 1.020 | Acc: 74.714% (14393/19264)
Loss: 1.026 | Acc: 74.540% (19130/25664)
Loss: 1.030 | Acc: 74.264% (23812/32064)
Loss: 1.033 | Acc: 74.189% (28536/38464)
Loss: 1.037 | Acc: 74.093% (33241/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3569, Accuracy: 6306/10000 (63.06%)

Epoch: 172
Loss: 1.258 | Acc: 67.188% (43/64)
Loss: 1.022 | Acc: 74.196% (4796/6464)
Loss: 1.014 | Acc: 74.572% (9593/12864)
Loss: 1.014 | Acc: 74.720% (14394/19264)
Loss: 1.016 | Acc: 74.657% (19160/25664)
Loss: 1.019 | Acc: 74.582% (23914/32064)
Loss: 1.020 | Acc: 74.462% (28641/38464)
Loss: 1.023 | Acc: 74.394% (33376/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7820, Accuracy: 5231/10000 (52.31%)

Epoch: 173
Loss: 1.133 | Acc: 71.875% (46/64)
Loss: 1.028 | Acc: 74.180% (4795/6464)
Loss: 1.015 | Acc: 74.697% (9609/12864)
Loss: 1.019 | Acc: 74.595% (14370/19264)
Loss: 1.022 | Acc: 74.478% (19114/25664)
Loss: 1.023 | Acc: 74.482% (23882/32064)
Loss: 1.022 | Acc: 74.542% (28672/38464)
Loss: 1.019 | Acc: 74.648% (33490/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4959, Accuracy: 5862/10000 (58.62%)

Epoch: 174
Loss: 1.199 | Acc: 64.062% (41/64)
Loss: 1.000 | Acc: 75.232% (4863/6464)
Loss: 0.999 | Acc: 75.241% (9679/12864)
Loss: 0.990 | Acc: 75.488% (14542/19264)
Loss: 0.998 | Acc: 75.323% (19331/25664)
Loss: 1.002 | Acc: 75.206% (24114/32064)
Loss: 1.000 | Acc: 75.257% (28947/38464)
Loss: 1.003 | Acc: 75.189% (33733/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2158, Accuracy: 6851/10000 (68.51%)

Epoch: 175
Loss: 1.189 | Acc: 73.438% (47/64)
Loss: 0.971 | Acc: 76.083% (4918/6464)
Loss: 0.971 | Acc: 76.003% (9777/12864)
Loss: 0.982 | Acc: 75.716% (14586/19264)
Loss: 0.988 | Acc: 75.577% (19396/25664)
Loss: 0.982 | Acc: 75.739% (24285/32064)
Loss: 0.985 | Acc: 75.608% (29082/38464)
Loss: 0.992 | Acc: 75.424% (33838/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5596, Accuracy: 5536/10000 (55.36%)

Epoch: 176
Loss: 1.182 | Acc: 70.312% (45/64)
Loss: 0.981 | Acc: 76.253% (4929/6464)
Loss: 0.989 | Acc: 75.762% (9746/12864)
Loss: 0.986 | Acc: 75.685% (14580/19264)
Loss: 0.988 | Acc: 75.647% (19414/25664)
Loss: 0.988 | Acc: 75.618% (24246/32064)
Loss: 0.985 | Acc: 75.772% (29145/38464)
Loss: 0.984 | Acc: 75.807% (34010/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2469, Accuracy: 6851/10000 (68.51%)

Epoch: 177
Loss: 0.943 | Acc: 81.250% (52/64)
Loss: 0.987 | Acc: 76.067% (4917/6464)
Loss: 0.965 | Acc: 76.423% (9831/12864)
Loss: 0.967 | Acc: 76.381% (14714/19264)
Loss: 0.969 | Acc: 76.305% (19583/25664)
Loss: 0.973 | Acc: 76.204% (24434/32064)
Loss: 0.978 | Acc: 76.011% (29237/38464)
Loss: 0.975 | Acc: 76.119% (34150/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4610, Accuracy: 6036/10000 (60.36%)

Epoch: 178
Loss: 0.756 | Acc: 81.250% (52/64)
Loss: 0.918 | Acc: 77.181% (4989/6464)
Loss: 0.939 | Acc: 76.772% (9876/12864)
Loss: 0.948 | Acc: 76.386% (14715/19264)
Loss: 0.952 | Acc: 76.352% (19595/25664)
Loss: 0.954 | Acc: 76.372% (24488/32064)
Loss: 0.955 | Acc: 76.396% (29385/38464)
Loss: 0.959 | Acc: 76.342% (34250/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6257, Accuracy: 5657/10000 (56.57%)

Epoch: 179
Loss: 0.993 | Acc: 75.000% (48/64)
Loss: 0.956 | Acc: 76.593% (4951/6464)
Loss: 0.947 | Acc: 76.788% (9878/12864)
Loss: 0.943 | Acc: 76.915% (14817/19264)
Loss: 0.945 | Acc: 76.929% (19743/25664)
Loss: 0.942 | Acc: 77.071% (24712/32064)
Loss: 0.939 | Acc: 77.059% (29640/38464)
Loss: 0.941 | Acc: 77.089% (34585/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1644, Accuracy: 7116/10000 (71.16%)

Epoch: 180
Loss: 0.629 | Acc: 84.375% (54/64)
Loss: 0.914 | Acc: 77.785% (5028/6464)
Loss: 0.925 | Acc: 77.449% (9963/12864)
Loss: 0.917 | Acc: 77.632% (14955/19264)
Loss: 0.918 | Acc: 77.587% (19912/25664)
Loss: 0.924 | Acc: 77.464% (24838/32064)
Loss: 0.927 | Acc: 77.454% (29792/38464)
Loss: 0.928 | Acc: 77.365% (34709/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1798, Accuracy: 7089/10000 (70.89%)

Epoch: 181
Loss: 0.945 | Acc: 75.000% (48/64)
Loss: 0.880 | Acc: 78.342% (5064/6464)
Loss: 0.880 | Acc: 78.428% (10089/12864)
Loss: 0.891 | Acc: 78.068% (15039/19264)
Loss: 0.899 | Acc: 77.922% (19998/25664)
Loss: 0.899 | Acc: 78.022% (25017/32064)
Loss: 0.907 | Acc: 77.883% (29957/38464)
Loss: 0.911 | Acc: 77.786% (34898/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2051, Accuracy: 6967/10000 (69.67%)

Epoch: 182
Loss: 1.093 | Acc: 67.188% (43/64)
Loss: 0.883 | Acc: 78.620% (5082/6464)
Loss: 0.860 | Acc: 79.260% (10196/12864)
Loss: 0.873 | Acc: 78.862% (15192/19264)
Loss: 0.880 | Acc: 78.620% (20177/25664)
Loss: 0.886 | Acc: 78.499% (25170/32064)
Loss: 0.889 | Acc: 78.427% (30166/38464)
Loss: 0.890 | Acc: 78.453% (35197/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1654, Accuracy: 7198/10000 (71.98%)

Epoch: 183
Loss: 0.874 | Acc: 78.125% (50/64)
Loss: 0.855 | Acc: 79.316% (5127/6464)
Loss: 0.860 | Acc: 79.112% (10177/12864)
Loss: 0.870 | Acc: 78.836% (15187/19264)
Loss: 0.870 | Acc: 78.834% (20232/25664)
Loss: 0.873 | Acc: 78.743% (25248/32064)
Loss: 0.874 | Acc: 78.707% (30274/38464)
Loss: 0.874 | Acc: 78.734% (35323/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1910, Accuracy: 7057/10000 (70.57%)

Epoch: 184
Loss: 0.771 | Acc: 81.250% (52/64)
Loss: 0.830 | Acc: 79.332% (5128/6464)
Loss: 0.843 | Acc: 79.050% (10169/12864)
Loss: 0.853 | Acc: 78.992% (15217/19264)
Loss: 0.851 | Acc: 79.197% (20325/25664)
Loss: 0.850 | Acc: 79.251% (25411/32064)
Loss: 0.849 | Acc: 79.334% (30515/38464)
Loss: 0.851 | Acc: 79.286% (35571/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2312, Accuracy: 7019/10000 (70.19%)

Epoch: 185
Loss: 0.923 | Acc: 78.125% (50/64)
Loss: 0.793 | Acc: 80.384% (5196/6464)
Loss: 0.800 | Acc: 80.356% (10337/12864)
Loss: 0.801 | Acc: 80.430% (15494/19264)
Loss: 0.814 | Acc: 80.151% (20570/25664)
Loss: 0.820 | Acc: 79.943% (25633/32064)
Loss: 0.820 | Acc: 79.992% (30768/38464)
Loss: 0.825 | Acc: 79.886% (35840/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1999, Accuracy: 7102/10000 (71.02%)

Epoch: 186
Loss: 0.381 | Acc: 93.750% (60/64)
Loss: 0.773 | Acc: 80.801% (5223/6464)
Loss: 0.780 | Acc: 80.900% (10407/12864)
Loss: 0.794 | Acc: 80.622% (15531/19264)
Loss: 0.800 | Acc: 80.486% (20656/25664)
Loss: 0.804 | Acc: 80.377% (25772/32064)
Loss: 0.801 | Acc: 80.447% (30943/38464)
Loss: 0.801 | Acc: 80.461% (36098/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2221, Accuracy: 7108/10000 (71.08%)

Epoch: 187
Loss: 0.581 | Acc: 89.062% (57/64)
Loss: 0.764 | Acc: 80.987% (5235/6464)
Loss: 0.758 | Acc: 81.312% (10460/12864)
Loss: 0.758 | Acc: 81.162% (15635/19264)
Loss: 0.767 | Acc: 80.985% (20784/25664)
Loss: 0.769 | Acc: 80.919% (25946/32064)
Loss: 0.774 | Acc: 80.863% (31103/38464)
Loss: 0.775 | Acc: 80.826% (36262/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2422, Accuracy: 7104/10000 (71.04%)

Epoch: 188
Loss: 0.655 | Acc: 87.500% (56/64)
Loss: 0.733 | Acc: 81.668% (5279/6464)
Loss: 0.732 | Acc: 81.670% (10506/12864)
Loss: 0.736 | Acc: 81.510% (15702/19264)
Loss: 0.736 | Acc: 81.511% (20919/25664)
Loss: 0.736 | Acc: 81.500% (26132/32064)
Loss: 0.735 | Acc: 81.557% (31370/38464)
Loss: 0.739 | Acc: 81.457% (36545/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2600, Accuracy: 7148/10000 (71.48%)

Epoch: 189
Loss: 0.577 | Acc: 82.812% (53/64)
Loss: 0.673 | Acc: 82.565% (5337/6464)
Loss: 0.677 | Acc: 82.610% (10627/12864)
Loss: 0.679 | Acc: 82.761% (15943/19264)
Loss: 0.685 | Acc: 82.625% (21205/25664)
Loss: 0.691 | Acc: 82.473% (26444/32064)
Loss: 0.695 | Acc: 82.350% (31675/38464)
Loss: 0.699 | Acc: 82.217% (36886/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2653, Accuracy: 7287/10000 (72.87%)

Epoch: 190
Loss: 0.689 | Acc: 79.688% (51/64)
Loss: 0.636 | Acc: 83.586% (5403/6464)
Loss: 0.635 | Acc: 83.909% (10794/12864)
Loss: 0.644 | Acc: 83.612% (16107/19264)
Loss: 0.647 | Acc: 83.588% (21452/25664)
Loss: 0.643 | Acc: 83.673% (26829/32064)
Loss: 0.644 | Acc: 83.639% (32171/38464)
Loss: 0.646 | Acc: 83.566% (37491/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3778, Accuracy: 6942/10000 (69.42%)

Epoch: 191
Loss: 0.837 | Acc: 73.438% (47/64)
Loss: 0.599 | Acc: 84.267% (5447/6464)
Loss: 0.587 | Acc: 84.787% (10907/12864)
Loss: 0.592 | Acc: 84.738% (16324/19264)
Loss: 0.595 | Acc: 84.597% (21711/25664)
Loss: 0.599 | Acc: 84.475% (27086/32064)
Loss: 0.604 | Acc: 84.349% (32444/38464)
Loss: 0.605 | Acc: 84.308% (37824/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3252, Accuracy: 7136/10000 (71.36%)

Epoch: 192
Loss: 0.698 | Acc: 82.812% (53/64)
Loss: 0.552 | Acc: 85.226% (5509/6464)
Loss: 0.547 | Acc: 85.424% (10989/12864)
Loss: 0.549 | Acc: 85.424% (16456/19264)
Loss: 0.553 | Acc: 85.376% (21911/25664)
Loss: 0.558 | Acc: 85.342% (27364/32064)
Loss: 0.557 | Acc: 85.337% (32824/38464)
Loss: 0.560 | Acc: 85.242% (38243/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4167, Accuracy: 7135/10000 (71.35%)

Epoch: 193
Loss: 0.416 | Acc: 87.500% (56/64)
Loss: 0.493 | Acc: 86.850% (5614/6464)
Loss: 0.503 | Acc: 86.373% (11111/12864)
Loss: 0.505 | Acc: 86.394% (16643/19264)
Loss: 0.506 | Acc: 86.440% (22184/25664)
Loss: 0.505 | Acc: 86.468% (27725/32064)
Loss: 0.504 | Acc: 86.481% (33264/38464)
Loss: 0.503 | Acc: 86.490% (38803/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4834, Accuracy: 6978/10000 (69.78%)

Epoch: 194
Loss: 0.481 | Acc: 87.500% (56/64)
Loss: 0.454 | Acc: 87.330% (5645/6464)
Loss: 0.447 | Acc: 87.687% (11280/12864)
Loss: 0.446 | Acc: 87.827% (16919/19264)
Loss: 0.452 | Acc: 87.668% (22499/25664)
Loss: 0.451 | Acc: 87.650% (28104/32064)
Loss: 0.454 | Acc: 87.594% (33692/38464)
Loss: 0.455 | Acc: 87.558% (39282/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4549, Accuracy: 7129/10000 (71.29%)

Epoch: 195
Loss: 0.338 | Acc: 89.062% (57/64)
Loss: 0.397 | Acc: 88.567% (5725/6464)
Loss: 0.401 | Acc: 88.759% (11418/12864)
Loss: 0.408 | Acc: 88.507% (17050/19264)
Loss: 0.409 | Acc: 88.517% (22717/25664)
Loss: 0.412 | Acc: 88.445% (28359/32064)
Loss: 0.414 | Acc: 88.374% (33992/38464)
Loss: 0.415 | Acc: 88.389% (39655/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4866, Accuracy: 7099/10000 (70.99%)

Epoch: 196
Loss: 0.607 | Acc: 79.688% (51/64)
Loss: 0.371 | Acc: 89.697% (5798/6464)
Loss: 0.376 | Acc: 89.490% (11512/12864)
Loss: 0.385 | Acc: 89.166% (17177/19264)
Loss: 0.385 | Acc: 89.133% (22875/25664)
Loss: 0.382 | Acc: 89.222% (28608/32064)
Loss: 0.384 | Acc: 89.211% (34314/38464)
Loss: 0.384 | Acc: 89.259% (40045/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4909, Accuracy: 7088/10000 (70.88%)

Epoch: 197
Loss: 0.345 | Acc: 92.188% (59/64)
Loss: 0.351 | Acc: 90.192% (5830/6464)
Loss: 0.354 | Acc: 90.182% (11601/12864)
Loss: 0.357 | Acc: 90.028% (17343/19264)
Loss: 0.363 | Acc: 89.818% (23051/25664)
Loss: 0.364 | Acc: 89.767% (28783/32064)
Loss: 0.364 | Acc: 89.780% (34533/38464)
Loss: 0.365 | Acc: 89.745% (40263/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5056, Accuracy: 7067/10000 (70.67%)
torch.Size([100, 10])
Test set: Average loss: 1.5056, Accuracy: 7067/10000 (70.67%)

Epoch: 198
Loss: 0.318 | Acc: 89.062% (57/64)
Loss: 0.359 | Acc: 89.573% (5790/6464)
Loss: 0.348 | Acc: 90.042% (11583/12864)
Loss: 0.350 | Acc: 89.997% (17337/19264)
Loss: 0.351 | Acc: 89.955% (23086/25664)
Loss: 0.352 | Acc: 89.930% (28835/32064)
Loss: 0.352 | Acc: 89.962% (34603/38464)
Loss: 0.351 | Acc: 89.967% (40363/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5026, Accuracy: 7047/10000 (70.47%)
torch.Size([100, 10])
Test set: Average loss: 1.5026, Accuracy: 7047/10000 (70.47%)

Epoch: 199
Loss: 0.231 | Acc: 95.312% (61/64)
Loss: 0.354 | Acc: 90.207% (5831/6464)
Loss: 0.347 | Acc: 90.462% (11637/12864)
Loss: 0.348 | Acc: 90.277% (17391/19264)
Loss: 0.343 | Acc: 90.399% (23200/25664)
Loss: 0.345 | Acc: 90.260% (28941/32064)
Loss: 0.342 | Acc: 90.368% (34759/38464)
Loss: 0.344 | Acc: 90.306% (40515/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5111, Accuracy: 7020/10000 (70.20%)
torch.Size([100, 10])
Test set: Average loss: 1.5111, Accuracy: 7020/10000 (70.20%)
7434
10000
-1.2223308086395264
