==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.358 | Acc: 15.625% (10/64)
Loss: 3.107 | Acc: 13.629% (881/6464)
Loss: 2.618 | Acc: 16.768% (2157/12864)
Loss: 2.439 | Acc: 18.272% (3520/19264)
Loss: 2.338 | Acc: 19.759% (5071/25664)
Loss: 2.271 | Acc: 20.949% (6717/32064)
Loss: 2.224 | Acc: 21.893% (8421/38464)
Loss: 2.183 | Acc: 22.880% (10265/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2067, Accuracy: 2450/10000 (24.50%)

Epoch: 1
Loss: 2.247 | Acc: 23.438% (15/64)
Loss: 1.883 | Acc: 31.498% (2036/6464)
Loss: 1.874 | Acc: 32.292% (4154/12864)
Loss: 1.858 | Acc: 32.812% (6321/19264)
Loss: 1.847 | Acc: 33.261% (8536/25664)
Loss: 1.835 | Acc: 33.938% (10882/32064)
Loss: 1.823 | Acc: 34.489% (13266/38464)
Loss: 1.811 | Acc: 35.093% (15744/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8551, Accuracy: 3531/10000 (35.31%)

Epoch: 2
Loss: 1.490 | Acc: 48.438% (31/64)
Loss: 1.697 | Acc: 40.377% (2610/6464)
Loss: 1.693 | Acc: 40.026% (5149/12864)
Loss: 1.680 | Acc: 40.838% (7867/19264)
Loss: 1.668 | Acc: 41.342% (10610/25664)
Loss: 1.658 | Acc: 41.795% (13401/32064)
Loss: 1.652 | Acc: 42.219% (16239/38464)
Loss: 1.646 | Acc: 42.506% (19070/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7284, Accuracy: 4076/10000 (40.76%)

Epoch: 3
Loss: 1.701 | Acc: 35.938% (23/64)
Loss: 1.570 | Acc: 46.117% (2981/6464)
Loss: 1.576 | Acc: 46.370% (5965/12864)
Loss: 1.556 | Acc: 47.212% (9095/19264)
Loss: 1.543 | Acc: 47.869% (12285/25664)
Loss: 1.534 | Acc: 48.244% (15469/32064)
Loss: 1.522 | Acc: 48.630% (18705/38464)
Loss: 1.512 | Acc: 49.169% (22059/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7665, Accuracy: 4215/10000 (42.15%)

Epoch: 4
Loss: 1.680 | Acc: 45.312% (29/64)
Loss: 1.433 | Acc: 53.481% (3457/6464)
Loss: 1.418 | Acc: 53.545% (6888/12864)
Loss: 1.409 | Acc: 53.992% (10401/19264)
Loss: 1.401 | Acc: 54.345% (13947/25664)
Loss: 1.394 | Acc: 54.694% (17537/32064)
Loss: 1.385 | Acc: 55.124% (21203/38464)
Loss: 1.380 | Acc: 55.463% (24883/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5656, Accuracy: 4919/10000 (49.19%)

Epoch: 5
Loss: 1.712 | Acc: 46.875% (30/64)
Loss: 1.298 | Acc: 57.859% (3740/6464)
Loss: 1.314 | Acc: 57.735% (7427/12864)
Loss: 1.309 | Acc: 58.051% (11183/19264)
Loss: 1.306 | Acc: 58.237% (14946/25664)
Loss: 1.297 | Acc: 58.511% (18761/32064)
Loss: 1.295 | Acc: 58.618% (22547/38464)
Loss: 1.288 | Acc: 59.047% (26491/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8702, Accuracy: 4429/10000 (44.29%)

Epoch: 6
Loss: 1.395 | Acc: 54.688% (35/64)
Loss: 1.239 | Acc: 61.912% (4002/6464)
Loss: 1.238 | Acc: 61.575% (7921/12864)
Loss: 1.226 | Acc: 61.960% (11936/19264)
Loss: 1.224 | Acc: 62.032% (15920/25664)
Loss: 1.213 | Acc: 62.335% (19987/32064)
Loss: 1.212 | Acc: 62.391% (23998/38464)
Loss: 1.208 | Acc: 62.620% (28094/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8890, Accuracy: 4119/10000 (41.19%)

Epoch: 7
Loss: 1.474 | Acc: 51.562% (33/64)
Loss: 1.155 | Acc: 64.944% (4198/6464)
Loss: 1.158 | Acc: 64.770% (8332/12864)
Loss: 1.155 | Acc: 65.038% (12529/19264)
Loss: 1.148 | Acc: 65.317% (16763/25664)
Loss: 1.140 | Acc: 65.656% (21052/32064)
Loss: 1.136 | Acc: 65.867% (25335/38464)
Loss: 1.129 | Acc: 66.106% (29658/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1905, Accuracy: 6534/10000 (65.34%)

Epoch: 8
Loss: 1.150 | Acc: 68.750% (44/64)
Loss: 1.095 | Acc: 67.141% (4340/6464)
Loss: 1.085 | Acc: 67.708% (8710/12864)
Loss: 1.083 | Acc: 68.060% (13111/19264)
Loss: 1.079 | Acc: 68.356% (17543/25664)
Loss: 1.074 | Acc: 68.382% (21926/32064)
Loss: 1.075 | Acc: 68.339% (26286/38464)
Loss: 1.071 | Acc: 68.474% (30720/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2411, Accuracy: 6319/10000 (63.19%)

Epoch: 9
Loss: 1.302 | Acc: 56.250% (36/64)
Loss: 1.027 | Acc: 71.071% (4594/6464)
Loss: 1.040 | Acc: 70.281% (9041/12864)
Loss: 1.040 | Acc: 69.996% (13484/19264)
Loss: 1.034 | Acc: 70.098% (17990/25664)
Loss: 1.038 | Acc: 69.991% (22442/32064)
Loss: 1.036 | Acc: 70.024% (26934/38464)
Loss: 1.031 | Acc: 70.206% (31497/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3707, Accuracy: 5783/10000 (57.83%)

Epoch: 10
Loss: 0.987 | Acc: 70.312% (45/64)
Loss: 1.017 | Acc: 70.761% (4574/6464)
Loss: 1.002 | Acc: 71.424% (9188/12864)
Loss: 1.002 | Acc: 71.304% (13736/19264)
Loss: 0.992 | Acc: 71.509% (18352/25664)
Loss: 0.997 | Acc: 71.491% (22923/32064)
Loss: 0.996 | Acc: 71.607% (27543/38464)
Loss: 0.996 | Acc: 71.614% (32129/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1932, Accuracy: 6592/10000 (65.92%)

Epoch: 11
Loss: 1.151 | Acc: 64.062% (41/64)
Loss: 0.977 | Acc: 72.540% (4689/6464)
Loss: 0.977 | Acc: 72.823% (9368/12864)
Loss: 0.964 | Acc: 73.059% (14074/19264)
Loss: 0.965 | Acc: 72.966% (18726/25664)
Loss: 0.966 | Acc: 72.720% (23317/32064)
Loss: 0.966 | Acc: 72.684% (27957/38464)
Loss: 0.970 | Acc: 72.577% (32561/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2256, Accuracy: 6529/10000 (65.29%)

Epoch: 12
Loss: 0.903 | Acc: 76.562% (49/64)
Loss: 0.949 | Acc: 73.778% (4769/6464)
Loss: 0.948 | Acc: 73.539% (9460/12864)
Loss: 0.948 | Acc: 73.521% (14163/19264)
Loss: 0.945 | Acc: 73.679% (18909/25664)
Loss: 0.945 | Acc: 73.572% (23590/32064)
Loss: 0.947 | Acc: 73.458% (28255/38464)
Loss: 0.951 | Acc: 73.386% (32924/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4994, Accuracy: 5222/10000 (52.22%)

Epoch: 13
Loss: 1.250 | Acc: 62.500% (40/64)
Loss: 0.937 | Acc: 74.489% (4815/6464)
Loss: 0.934 | Acc: 74.448% (9577/12864)
Loss: 0.932 | Acc: 74.315% (14316/19264)
Loss: 0.933 | Acc: 74.287% (19065/25664)
Loss: 0.923 | Acc: 74.701% (23952/32064)
Loss: 0.924 | Acc: 74.652% (28714/38464)
Loss: 0.925 | Acc: 74.699% (33513/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1990, Accuracy: 6503/10000 (65.03%)

Epoch: 14
Loss: 1.106 | Acc: 68.750% (44/64)
Loss: 0.952 | Acc: 73.422% (4746/6464)
Loss: 0.935 | Acc: 73.803% (9494/12864)
Loss: 0.920 | Acc: 74.315% (14316/19264)
Loss: 0.914 | Acc: 74.567% (19137/25664)
Loss: 0.910 | Acc: 74.869% (24006/32064)
Loss: 0.908 | Acc: 74.930% (28821/38464)
Loss: 0.910 | Acc: 74.949% (33625/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8844, Accuracy: 4926/10000 (49.26%)

Epoch: 15
Loss: 1.086 | Acc: 70.312% (45/64)
Loss: 0.878 | Acc: 75.975% (4911/6464)
Loss: 0.885 | Acc: 76.018% (9779/12864)
Loss: 0.896 | Acc: 75.540% (14552/19264)
Loss: 0.891 | Acc: 75.565% (19393/25664)
Loss: 0.891 | Acc: 75.661% (24260/32064)
Loss: 0.891 | Acc: 75.718% (29124/38464)
Loss: 0.889 | Acc: 75.771% (33994/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0406, Accuracy: 7061/10000 (70.61%)

Epoch: 16
Loss: 0.921 | Acc: 73.438% (47/64)
Loss: 0.864 | Acc: 76.856% (4968/6464)
Loss: 0.863 | Acc: 76.562% (9849/12864)
Loss: 0.865 | Acc: 76.552% (14747/19264)
Loss: 0.870 | Acc: 76.348% (19594/25664)
Loss: 0.870 | Acc: 76.388% (24493/32064)
Loss: 0.874 | Acc: 76.321% (29356/38464)
Loss: 0.870 | Acc: 76.418% (34284/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8120, Accuracy: 5046/10000 (50.46%)

Epoch: 17
Loss: 0.978 | Acc: 70.312% (45/64)
Loss: 0.846 | Acc: 77.398% (5003/6464)
Loss: 0.865 | Acc: 76.765% (9875/12864)
Loss: 0.867 | Acc: 76.718% (14779/19264)
Loss: 0.862 | Acc: 76.909% (19738/25664)
Loss: 0.860 | Acc: 77.062% (24709/32064)
Loss: 0.860 | Acc: 77.015% (29623/38464)
Loss: 0.858 | Acc: 77.051% (34568/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1943, Accuracy: 6702/10000 (67.02%)

Epoch: 18
Loss: 0.796 | Acc: 76.562% (49/64)
Loss: 0.831 | Acc: 77.800% (5029/6464)
Loss: 0.834 | Acc: 77.876% (10018/12864)
Loss: 0.838 | Acc: 77.834% (14994/19264)
Loss: 0.842 | Acc: 77.696% (19940/25664)
Loss: 0.840 | Acc: 77.685% (24909/32064)
Loss: 0.844 | Acc: 77.571% (29837/38464)
Loss: 0.844 | Acc: 77.532% (34784/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0681, Accuracy: 6943/10000 (69.43%)

Epoch: 19
Loss: 1.128 | Acc: 71.875% (46/64)
Loss: 0.829 | Acc: 78.342% (5064/6464)
Loss: 0.827 | Acc: 78.343% (10078/12864)
Loss: 0.818 | Acc: 78.561% (15134/19264)
Loss: 0.821 | Acc: 78.398% (20120/25664)
Loss: 0.822 | Acc: 78.309% (25109/32064)
Loss: 0.824 | Acc: 78.258% (30101/38464)
Loss: 0.824 | Acc: 78.228% (35096/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6228, Accuracy: 5418/10000 (54.18%)

Epoch: 20
Loss: 0.770 | Acc: 79.688% (51/64)
Loss: 0.818 | Acc: 78.512% (5075/6464)
Loss: 0.815 | Acc: 78.591% (10110/12864)
Loss: 0.814 | Acc: 78.509% (15124/19264)
Loss: 0.814 | Acc: 78.620% (20177/25664)
Loss: 0.812 | Acc: 78.633% (25213/32064)
Loss: 0.812 | Acc: 78.687% (30266/38464)
Loss: 0.813 | Acc: 78.689% (35303/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5559, Accuracy: 5490/10000 (54.90%)

Epoch: 21
Loss: 0.879 | Acc: 73.438% (47/64)
Loss: 0.799 | Acc: 79.131% (5115/6464)
Loss: 0.802 | Acc: 78.957% (10157/12864)
Loss: 0.794 | Acc: 79.293% (15275/19264)
Loss: 0.804 | Acc: 78.928% (20256/25664)
Loss: 0.802 | Acc: 79.082% (25357/32064)
Loss: 0.803 | Acc: 79.105% (30427/38464)
Loss: 0.801 | Acc: 79.226% (35544/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4059, Accuracy: 5905/10000 (59.05%)

Epoch: 22
Loss: 0.730 | Acc: 84.375% (54/64)
Loss: 0.788 | Acc: 79.935% (5167/6464)
Loss: 0.796 | Acc: 79.485% (10225/12864)
Loss: 0.790 | Acc: 79.506% (15316/19264)
Loss: 0.798 | Acc: 79.321% (20357/25664)
Loss: 0.788 | Acc: 79.585% (25518/32064)
Loss: 0.787 | Acc: 79.555% (30600/38464)
Loss: 0.787 | Acc: 79.547% (35688/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4149, Accuracy: 5843/10000 (58.43%)

Epoch: 23
Loss: 0.909 | Acc: 76.562% (49/64)
Loss: 0.739 | Acc: 81.436% (5264/6464)
Loss: 0.768 | Acc: 80.442% (10348/12864)
Loss: 0.772 | Acc: 80.316% (15472/19264)
Loss: 0.769 | Acc: 80.249% (20595/25664)
Loss: 0.771 | Acc: 80.171% (25706/32064)
Loss: 0.771 | Acc: 80.194% (30846/38464)
Loss: 0.771 | Acc: 80.243% (36000/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9628, Accuracy: 7337/10000 (73.37%)

Epoch: 24
Loss: 0.861 | Acc: 76.562% (49/64)
Loss: 0.751 | Acc: 80.476% (5202/6464)
Loss: 0.765 | Acc: 80.216% (10319/12864)
Loss: 0.761 | Acc: 80.482% (15504/19264)
Loss: 0.767 | Acc: 80.401% (20634/25664)
Loss: 0.763 | Acc: 80.464% (25800/32064)
Loss: 0.763 | Acc: 80.408% (30928/38464)
Loss: 0.765 | Acc: 80.345% (36046/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2284, Accuracy: 6657/10000 (66.57%)

Epoch: 25
Loss: 0.804 | Acc: 79.688% (51/64)
Loss: 0.743 | Acc: 81.451% (5265/6464)
Loss: 0.753 | Acc: 81.157% (10440/12864)
Loss: 0.746 | Acc: 81.250% (15652/19264)
Loss: 0.744 | Acc: 81.242% (20850/25664)
Loss: 0.744 | Acc: 81.241% (26049/32064)
Loss: 0.746 | Acc: 81.201% (31233/38464)
Loss: 0.747 | Acc: 81.176% (36419/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3653, Accuracy: 6036/10000 (60.36%)

Epoch: 26
Loss: 0.567 | Acc: 87.500% (56/64)
Loss: 0.738 | Acc: 81.420% (5263/6464)
Loss: 0.741 | Acc: 81.188% (10444/12864)
Loss: 0.730 | Acc: 81.447% (15690/19264)
Loss: 0.741 | Acc: 81.254% (20853/25664)
Loss: 0.739 | Acc: 81.300% (26068/32064)
Loss: 0.734 | Acc: 81.481% (31341/38464)
Loss: 0.730 | Acc: 81.591% (36605/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9265, Accuracy: 7586/10000 (75.86%)

Epoch: 27
Loss: 0.681 | Acc: 73.438% (47/64)
Loss: 0.749 | Acc: 81.002% (5236/6464)
Loss: 0.721 | Acc: 81.670% (10506/12864)
Loss: 0.721 | Acc: 81.593% (15718/19264)
Loss: 0.720 | Acc: 81.745% (20979/25664)
Loss: 0.714 | Acc: 81.958% (26279/32064)
Loss: 0.717 | Acc: 81.934% (31515/38464)
Loss: 0.719 | Acc: 81.970% (36775/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9961, Accuracy: 7302/10000 (73.02%)

Epoch: 28
Loss: 0.953 | Acc: 78.125% (50/64)
Loss: 0.688 | Acc: 82.503% (5333/6464)
Loss: 0.707 | Acc: 82.222% (10577/12864)
Loss: 0.695 | Acc: 82.600% (15912/19264)
Loss: 0.698 | Acc: 82.540% (21183/25664)
Loss: 0.697 | Acc: 82.597% (26484/32064)
Loss: 0.704 | Acc: 82.407% (31697/38464)
Loss: 0.703 | Acc: 82.485% (37006/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0391, Accuracy: 7140/10000 (71.40%)

Epoch: 29
Loss: 0.734 | Acc: 76.562% (49/64)
Loss: 0.666 | Acc: 83.632% (5406/6464)
Loss: 0.676 | Acc: 83.388% (10727/12864)
Loss: 0.673 | Acc: 83.316% (16050/19264)
Loss: 0.684 | Acc: 82.961% (21291/25664)
Loss: 0.683 | Acc: 82.997% (26612/32064)
Loss: 0.685 | Acc: 82.981% (31918/38464)
Loss: 0.685 | Acc: 82.991% (37233/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0430, Accuracy: 7080/10000 (70.80%)

Epoch: 30
Loss: 1.058 | Acc: 71.875% (46/64)
Loss: 0.652 | Acc: 84.251% (5446/6464)
Loss: 0.665 | Acc: 83.699% (10767/12864)
Loss: 0.664 | Acc: 83.788% (16141/19264)
Loss: 0.661 | Acc: 83.791% (21504/25664)
Loss: 0.670 | Acc: 83.552% (26790/32064)
Loss: 0.672 | Acc: 83.504% (32119/38464)
Loss: 0.675 | Acc: 83.450% (37439/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8438, Accuracy: 7883/10000 (78.83%)

Epoch: 31
Loss: 0.506 | Acc: 85.938% (55/64)
Loss: 0.629 | Acc: 84.607% (5469/6464)
Loss: 0.644 | Acc: 84.313% (10846/12864)
Loss: 0.654 | Acc: 84.084% (16198/19264)
Loss: 0.655 | Acc: 83.966% (21549/25664)
Loss: 0.658 | Acc: 83.870% (26892/32064)
Loss: 0.656 | Acc: 83.925% (32281/38464)
Loss: 0.659 | Acc: 83.865% (37625/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9838, Accuracy: 7396/10000 (73.96%)

Epoch: 32
Loss: 0.811 | Acc: 79.688% (51/64)
Loss: 0.643 | Acc: 84.793% (5481/6464)
Loss: 0.643 | Acc: 84.632% (10887/12864)
Loss: 0.641 | Acc: 84.681% (16313/19264)
Loss: 0.634 | Acc: 84.858% (21778/25664)
Loss: 0.633 | Acc: 84.805% (27192/32064)
Loss: 0.638 | Acc: 84.684% (32573/38464)
Loss: 0.637 | Acc: 84.772% (38032/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9027, Accuracy: 7608/10000 (76.08%)

Epoch: 33
Loss: 0.493 | Acc: 89.062% (57/64)
Loss: 0.593 | Acc: 85.690% (5539/6464)
Loss: 0.612 | Acc: 85.362% (10981/12864)
Loss: 0.611 | Acc: 85.434% (16458/19264)
Loss: 0.617 | Acc: 85.232% (21874/25664)
Loss: 0.612 | Acc: 85.361% (27370/32064)
Loss: 0.618 | Acc: 85.176% (32762/38464)
Loss: 0.618 | Acc: 85.193% (38221/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9415, Accuracy: 7518/10000 (75.18%)

Epoch: 34
Loss: 0.822 | Acc: 79.688% (51/64)
Loss: 0.591 | Acc: 85.829% (5548/6464)
Loss: 0.581 | Acc: 86.046% (11069/12864)
Loss: 0.586 | Acc: 85.849% (16538/19264)
Loss: 0.590 | Acc: 85.719% (21999/25664)
Loss: 0.596 | Acc: 85.679% (27472/32064)
Loss: 0.596 | Acc: 85.743% (32980/38464)
Loss: 0.598 | Acc: 85.775% (38482/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8310, Accuracy: 7985/10000 (79.85%)

Epoch: 35
Loss: 0.487 | Acc: 90.625% (58/64)
Loss: 0.549 | Acc: 86.711% (5605/6464)
Loss: 0.573 | Acc: 86.217% (11091/12864)
Loss: 0.576 | Acc: 86.239% (16613/19264)
Loss: 0.573 | Acc: 86.315% (22152/25664)
Loss: 0.574 | Acc: 86.312% (27675/32064)
Loss: 0.577 | Acc: 86.255% (33177/38464)
Loss: 0.578 | Acc: 86.227% (38685/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8150, Accuracy: 8066/10000 (80.66%)

Epoch: 36
Loss: 0.498 | Acc: 87.500% (56/64)
Loss: 0.541 | Acc: 87.175% (5635/6464)
Loss: 0.556 | Acc: 86.863% (11174/12864)
Loss: 0.553 | Acc: 86.887% (16738/19264)
Loss: 0.556 | Acc: 86.760% (22266/25664)
Loss: 0.558 | Acc: 86.730% (27809/32064)
Loss: 0.558 | Acc: 86.780% (33379/38464)
Loss: 0.559 | Acc: 86.807% (38945/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8662, Accuracy: 7871/10000 (78.71%)

Epoch: 37
Loss: 0.653 | Acc: 81.250% (52/64)
Loss: 0.521 | Acc: 87.856% (5679/6464)
Loss: 0.516 | Acc: 87.865% (11303/12864)
Loss: 0.516 | Acc: 87.863% (16926/19264)
Loss: 0.517 | Acc: 87.823% (22539/25664)
Loss: 0.525 | Acc: 87.619% (28094/32064)
Loss: 0.527 | Acc: 87.534% (33669/38464)
Loss: 0.533 | Acc: 87.366% (39196/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8490, Accuracy: 7968/10000 (79.68%)

Epoch: 38
Loss: 0.683 | Acc: 81.250% (52/64)
Loss: 0.491 | Acc: 88.196% (5701/6464)
Loss: 0.498 | Acc: 88.145% (11339/12864)
Loss: 0.497 | Acc: 88.040% (16960/19264)
Loss: 0.498 | Acc: 88.077% (22604/25664)
Loss: 0.503 | Acc: 87.965% (28205/32064)
Loss: 0.503 | Acc: 87.965% (33835/38464)
Loss: 0.503 | Acc: 87.993% (39477/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8505, Accuracy: 7981/10000 (79.81%)

Epoch: 39
Loss: 0.354 | Acc: 90.625% (58/64)
Loss: 0.459 | Acc: 89.295% (5772/6464)
Loss: 0.456 | Acc: 89.303% (11488/12864)
Loss: 0.460 | Acc: 89.187% (17181/19264)
Loss: 0.461 | Acc: 89.121% (22872/25664)
Loss: 0.468 | Acc: 88.938% (28517/32064)
Loss: 0.469 | Acc: 88.888% (34190/38464)
Loss: 0.475 | Acc: 88.737% (39811/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8611, Accuracy: 8021/10000 (80.21%)

Epoch: 40
Loss: 0.336 | Acc: 90.625% (58/64)
Loss: 0.435 | Acc: 89.434% (5781/6464)
Loss: 0.428 | Acc: 89.684% (11537/12864)
Loss: 0.435 | Acc: 89.556% (17252/19264)
Loss: 0.442 | Acc: 89.409% (22946/25664)
Loss: 0.440 | Acc: 89.402% (28666/32064)
Loss: 0.439 | Acc: 89.434% (34400/38464)
Loss: 0.441 | Acc: 89.383% (40101/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8374, Accuracy: 8121/10000 (81.21%)

Epoch: 41
Loss: 0.618 | Acc: 81.250% (52/64)
Loss: 0.392 | Acc: 90.347% (5840/6464)
Loss: 0.411 | Acc: 89.925% (11568/12864)
Loss: 0.407 | Acc: 90.038% (17345/19264)
Loss: 0.409 | Acc: 89.974% (23091/25664)
Loss: 0.405 | Acc: 90.132% (28900/32064)
Loss: 0.407 | Acc: 90.071% (34645/38464)
Loss: 0.409 | Acc: 90.008% (40381/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8494, Accuracy: 8187/10000 (81.87%)

Epoch: 42
Loss: 0.303 | Acc: 93.750% (60/64)
Loss: 0.365 | Acc: 90.934% (5878/6464)
Loss: 0.371 | Acc: 90.633% (11659/12864)
Loss: 0.374 | Acc: 90.630% (17459/19264)
Loss: 0.376 | Acc: 90.500% (23226/25664)
Loss: 0.377 | Acc: 90.538% (29030/32064)
Loss: 0.376 | Acc: 90.568% (34836/38464)
Loss: 0.374 | Acc: 90.703% (40693/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8765, Accuracy: 8162/10000 (81.62%)

Epoch: 43
Loss: 0.238 | Acc: 93.750% (60/64)
Loss: 0.338 | Acc: 91.414% (5909/6464)
Loss: 0.337 | Acc: 91.472% (11767/12864)
Loss: 0.333 | Acc: 91.616% (17649/19264)
Loss: 0.331 | Acc: 91.685% (23530/25664)
Loss: 0.330 | Acc: 91.623% (29378/32064)
Loss: 0.333 | Acc: 91.577% (35224/38464)
Loss: 0.332 | Acc: 91.586% (41089/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8946, Accuracy: 8155/10000 (81.55%)

Epoch: 44
Loss: 0.242 | Acc: 96.875% (62/64)
Loss: 0.287 | Acc: 92.775% (5997/6464)
Loss: 0.296 | Acc: 92.483% (11897/12864)
Loss: 0.289 | Acc: 92.624% (17843/19264)
Loss: 0.293 | Acc: 92.499% (23739/25664)
Loss: 0.297 | Acc: 92.396% (29626/32064)
Loss: 0.295 | Acc: 92.481% (35572/38464)
Loss: 0.292 | Acc: 92.537% (41516/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9109, Accuracy: 8227/10000 (82.27%)

Epoch: 45
Loss: 0.451 | Acc: 89.062% (57/64)
Loss: 0.304 | Acc: 92.157% (5957/6464)
Loss: 0.351 | Acc: 91.301% (11745/12864)
Loss: 0.384 | Acc: 90.583% (17450/19264)
Loss: 0.420 | Acc: 89.799% (23046/25664)
Loss: 0.445 | Acc: 89.315% (28638/32064)
Loss: 0.467 | Acc: 88.894% (34192/38464)
Loss: 0.488 | Acc: 88.429% (39673/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8093, Accuracy: 8059/10000 (80.59%)

Epoch: 46
Loss: 0.617 | Acc: 81.250% (52/64)
Loss: 0.659 | Acc: 84.313% (5450/6464)
Loss: 0.671 | Acc: 83.901% (10793/12864)
Loss: 0.669 | Acc: 84.115% (16204/19264)
Loss: 0.673 | Acc: 83.896% (21531/25664)
Loss: 0.675 | Acc: 83.864% (26890/32064)
Loss: 0.680 | Acc: 83.743% (32211/38464)
Loss: 0.683 | Acc: 83.662% (37534/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8319, Accuracy: 7948/10000 (79.48%)

Epoch: 47
Loss: 0.442 | Acc: 93.750% (60/64)
Loss: 0.721 | Acc: 82.797% (5352/6464)
Loss: 0.721 | Acc: 82.572% (10622/12864)
Loss: 0.723 | Acc: 82.480% (15889/19264)
Loss: 0.722 | Acc: 82.450% (21160/25664)
Loss: 0.732 | Acc: 82.313% (26393/32064)
Loss: 0.732 | Acc: 82.189% (31613/38464)
Loss: 0.731 | Acc: 82.204% (36880/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8426, Accuracy: 7894/10000 (78.94%)
torch.Size([100, 10])
Test set: Average loss: 0.8426, Accuracy: 7894/10000 (78.94%)

Epoch: 48
Loss: 0.807 | Acc: 81.250% (52/64)
Loss: 0.745 | Acc: 81.683% (5280/6464)
Loss: 0.731 | Acc: 82.082% (10559/12864)
Loss: 0.741 | Acc: 81.888% (15775/19264)
Loss: 0.745 | Acc: 81.803% (20994/25664)
Loss: 0.740 | Acc: 81.871% (26251/32064)
Loss: 0.743 | Acc: 81.809% (31467/38464)
Loss: 0.742 | Acc: 81.834% (36714/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8407, Accuracy: 7898/10000 (78.98%)
torch.Size([100, 10])
Test set: Average loss: 0.8407, Accuracy: 7898/10000 (78.98%)

Epoch: 49
Loss: 0.884 | Acc: 79.688% (51/64)
Loss: 0.742 | Acc: 81.853% (5291/6464)
Loss: 0.753 | Acc: 81.468% (10480/12864)
Loss: 0.752 | Acc: 81.530% (15706/19264)
Loss: 0.754 | Acc: 81.386% (20887/25664)
Loss: 0.753 | Acc: 81.387% (26096/32064)
Loss: 0.750 | Acc: 81.484% (31342/38464)
Loss: 0.748 | Acc: 81.558% (36590/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8453, Accuracy: 7854/10000 (78.54%)
torch.Size([100, 10])
Test set: Average loss: 0.8453, Accuracy: 7854/10000 (78.54%)

Epoch: 50
Loss: 0.744 | Acc: 81.250% (52/64)
Loss: 1.647 | Acc: 44.291% (2863/6464)
Loss: 1.406 | Acc: 54.252% (6979/12864)
Loss: 1.288 | Acc: 59.401% (11443/19264)
Loss: 1.230 | Acc: 62.087% (15934/25664)
Loss: 1.185 | Acc: 64.022% (20528/32064)
Loss: 1.150 | Acc: 65.552% (25214/38464)
Loss: 1.123 | Acc: 66.570% (29866/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4497, Accuracy: 3733/10000 (37.33%)

Epoch: 51
Loss: 0.987 | Acc: 70.312% (45/64)
Loss: 0.929 | Acc: 73.902% (4777/6464)
Loss: 0.925 | Acc: 74.572% (9593/12864)
Loss: 0.923 | Acc: 74.808% (14411/19264)
Loss: 0.922 | Acc: 74.797% (19196/25664)
Loss: 0.917 | Acc: 74.913% (24020/32064)
Loss: 0.909 | Acc: 75.081% (28879/38464)
Loss: 0.906 | Acc: 75.241% (33756/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7346, Accuracy: 5093/10000 (50.93%)

Epoch: 52
Loss: 1.046 | Acc: 70.312% (45/64)
Loss: 0.890 | Acc: 75.712% (4894/6464)
Loss: 0.871 | Acc: 76.244% (9808/12864)
Loss: 0.862 | Acc: 76.500% (14737/19264)
Loss: 0.861 | Acc: 76.637% (19668/25664)
Loss: 0.859 | Acc: 76.821% (24632/32064)
Loss: 0.860 | Acc: 76.757% (29524/38464)
Loss: 0.864 | Acc: 76.734% (34426/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1149, Accuracy: 6846/10000 (68.46%)

Epoch: 53
Loss: 1.356 | Acc: 64.062% (41/64)
Loss: 0.820 | Acc: 78.450% (5071/6464)
Loss: 0.834 | Acc: 78.265% (10068/12864)
Loss: 0.845 | Acc: 78.026% (15031/19264)
Loss: 0.846 | Acc: 78.035% (20027/25664)
Loss: 0.851 | Acc: 77.816% (24951/32064)
Loss: 0.847 | Acc: 77.870% (29952/38464)
Loss: 0.848 | Acc: 77.739% (34877/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5659, Accuracy: 5652/10000 (56.52%)

Epoch: 54
Loss: 0.800 | Acc: 73.438% (47/64)
Loss: 0.798 | Acc: 78.496% (5074/6464)
Loss: 0.833 | Acc: 77.907% (10022/12864)
Loss: 0.830 | Acc: 77.907% (15008/19264)
Loss: 0.836 | Acc: 77.778% (19961/25664)
Loss: 0.839 | Acc: 77.663% (24902/32064)
Loss: 0.842 | Acc: 77.488% (29805/38464)
Loss: 0.843 | Acc: 77.510% (34774/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0472, Accuracy: 7025/10000 (70.25%)

Epoch: 55
Loss: 0.939 | Acc: 75.000% (48/64)
Loss: 0.817 | Acc: 78.233% (5057/6464)
Loss: 0.817 | Acc: 78.187% (10058/12864)
Loss: 0.825 | Acc: 78.006% (15027/19264)
Loss: 0.830 | Acc: 77.926% (19999/25664)
Loss: 0.827 | Acc: 78.050% (25026/32064)
Loss: 0.829 | Acc: 77.987% (29997/38464)
Loss: 0.832 | Acc: 77.951% (34972/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2464, Accuracy: 6471/10000 (64.71%)

Epoch: 56
Loss: 1.146 | Acc: 73.438% (47/64)
Loss: 0.837 | Acc: 77.800% (5029/6464)
Loss: 0.830 | Acc: 77.946% (10027/12864)
Loss: 0.819 | Acc: 78.385% (15100/19264)
Loss: 0.820 | Acc: 78.351% (20108/25664)
Loss: 0.822 | Acc: 78.284% (25101/32064)
Loss: 0.825 | Acc: 78.177% (30070/38464)
Loss: 0.827 | Acc: 78.127% (35051/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2262, Accuracy: 6531/10000 (65.31%)

Epoch: 57
Loss: 1.032 | Acc: 71.875% (46/64)
Loss: 0.825 | Acc: 77.800% (5029/6464)
Loss: 0.822 | Acc: 78.211% (10061/12864)
Loss: 0.818 | Acc: 78.390% (15101/19264)
Loss: 0.825 | Acc: 78.293% (20093/25664)
Loss: 0.825 | Acc: 78.309% (25109/32064)
Loss: 0.827 | Acc: 78.304% (30119/38464)
Loss: 0.821 | Acc: 78.435% (35189/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2971, Accuracy: 6164/10000 (61.64%)

Epoch: 58
Loss: 1.050 | Acc: 68.750% (44/64)
Loss: 0.820 | Acc: 78.775% (5092/6464)
Loss: 0.826 | Acc: 78.413% (10087/12864)
Loss: 0.817 | Acc: 78.623% (15146/19264)
Loss: 0.820 | Acc: 78.573% (20165/25664)
Loss: 0.817 | Acc: 78.705% (25236/32064)
Loss: 0.817 | Acc: 78.637% (30247/38464)
Loss: 0.816 | Acc: 78.655% (35288/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2316, Accuracy: 4282/10000 (42.82%)

Epoch: 59
Loss: 0.760 | Acc: 78.125% (50/64)
Loss: 0.825 | Acc: 78.326% (5063/6464)
Loss: 0.818 | Acc: 78.382% (10083/12864)
Loss: 0.816 | Acc: 78.442% (15111/19264)
Loss: 0.813 | Acc: 78.503% (20147/25664)
Loss: 0.813 | Acc: 78.555% (25188/32064)
Loss: 0.812 | Acc: 78.619% (30240/38464)
Loss: 0.816 | Acc: 78.557% (35244/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2546, Accuracy: 6261/10000 (62.61%)

Epoch: 60
Loss: 1.011 | Acc: 71.875% (46/64)
Loss: 0.824 | Acc: 78.527% (5076/6464)
Loss: 0.801 | Acc: 79.097% (10175/12864)
Loss: 0.815 | Acc: 78.629% (15147/19264)
Loss: 0.812 | Acc: 78.702% (20198/25664)
Loss: 0.806 | Acc: 78.877% (25291/32064)
Loss: 0.805 | Acc: 78.965% (30373/38464)
Loss: 0.805 | Acc: 78.916% (35405/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1252, Accuracy: 6895/10000 (68.95%)

Epoch: 61
Loss: 0.971 | Acc: 78.125% (50/64)
Loss: 0.784 | Acc: 79.718% (5153/6464)
Loss: 0.786 | Acc: 79.509% (10228/12864)
Loss: 0.793 | Acc: 79.293% (15275/19264)
Loss: 0.799 | Acc: 79.200% (20326/25664)
Loss: 0.801 | Acc: 79.145% (25377/32064)
Loss: 0.802 | Acc: 79.139% (30440/38464)
Loss: 0.801 | Acc: 79.202% (35533/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1835, Accuracy: 6611/10000 (66.11%)

Epoch: 62
Loss: 0.898 | Acc: 76.562% (49/64)
Loss: 0.806 | Acc: 79.069% (5111/6464)
Loss: 0.787 | Acc: 79.757% (10260/12864)
Loss: 0.791 | Acc: 79.698% (15353/19264)
Loss: 0.793 | Acc: 79.442% (20388/25664)
Loss: 0.794 | Acc: 79.419% (25465/32064)
Loss: 0.794 | Acc: 79.365% (30527/38464)
Loss: 0.796 | Acc: 79.295% (35575/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9406, Accuracy: 7531/10000 (75.31%)

Epoch: 63
Loss: 0.511 | Acc: 84.375% (54/64)
Loss: 0.770 | Acc: 80.337% (5193/6464)
Loss: 0.782 | Acc: 80.006% (10292/12864)
Loss: 0.779 | Acc: 80.181% (15446/19264)
Loss: 0.783 | Acc: 79.999% (20531/25664)
Loss: 0.779 | Acc: 80.090% (25680/32064)
Loss: 0.785 | Acc: 79.815% (30700/38464)
Loss: 0.786 | Acc: 79.844% (35821/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0427, Accuracy: 7250/10000 (72.50%)

Epoch: 64
Loss: 0.959 | Acc: 71.875% (46/64)
Loss: 0.793 | Acc: 79.208% (5120/6464)
Loss: 0.780 | Acc: 79.804% (10266/12864)
Loss: 0.770 | Acc: 80.217% (15453/19264)
Loss: 0.779 | Acc: 79.917% (20510/25664)
Loss: 0.775 | Acc: 80.090% (25680/32064)
Loss: 0.777 | Acc: 80.044% (30788/38464)
Loss: 0.781 | Acc: 79.922% (35856/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2520, Accuracy: 6239/10000 (62.39%)

Epoch: 65
Loss: 0.665 | Acc: 81.250% (52/64)
Loss: 0.757 | Acc: 80.709% (5217/6464)
Loss: 0.760 | Acc: 80.628% (10372/12864)
Loss: 0.770 | Acc: 80.373% (15483/19264)
Loss: 0.771 | Acc: 80.252% (20596/25664)
Loss: 0.777 | Acc: 80.168% (25705/32064)
Loss: 0.776 | Acc: 80.142% (30826/38464)
Loss: 0.776 | Acc: 80.144% (35956/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0007, Accuracy: 7301/10000 (73.01%)

Epoch: 66
Loss: 0.841 | Acc: 81.250% (52/64)
Loss: 0.728 | Acc: 81.699% (5281/6464)
Loss: 0.754 | Acc: 80.714% (10383/12864)
Loss: 0.758 | Acc: 80.617% (15530/19264)
Loss: 0.765 | Acc: 80.404% (20635/25664)
Loss: 0.761 | Acc: 80.558% (25830/32064)
Loss: 0.765 | Acc: 80.452% (30945/38464)
Loss: 0.763 | Acc: 80.523% (36126/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0730, Accuracy: 6935/10000 (69.35%)

Epoch: 67
Loss: 0.845 | Acc: 76.562% (49/64)
Loss: 0.749 | Acc: 81.219% (5250/6464)
Loss: 0.743 | Acc: 80.986% (10418/12864)
Loss: 0.741 | Acc: 81.234% (15649/19264)
Loss: 0.749 | Acc: 81.071% (20806/25664)
Loss: 0.752 | Acc: 81.000% (25972/32064)
Loss: 0.758 | Acc: 80.803% (31080/38464)
Loss: 0.761 | Acc: 80.702% (36206/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1997, Accuracy: 6507/10000 (65.07%)

Epoch: 68
Loss: 0.636 | Acc: 81.250% (52/64)
Loss: 0.751 | Acc: 80.647% (5213/6464)
Loss: 0.748 | Acc: 80.854% (10401/12864)
Loss: 0.753 | Acc: 80.819% (15569/19264)
Loss: 0.754 | Acc: 80.814% (20740/25664)
Loss: 0.754 | Acc: 80.763% (25896/32064)
Loss: 0.755 | Acc: 80.753% (31061/38464)
Loss: 0.751 | Acc: 80.826% (36262/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3150, Accuracy: 6476/10000 (64.76%)

Epoch: 69
Loss: 0.918 | Acc: 73.438% (47/64)
Loss: 0.705 | Acc: 81.822% (5289/6464)
Loss: 0.716 | Acc: 81.678% (10507/12864)
Loss: 0.733 | Acc: 81.276% (15657/19264)
Loss: 0.739 | Acc: 81.168% (20831/25664)
Loss: 0.743 | Acc: 81.066% (25993/32064)
Loss: 0.740 | Acc: 81.149% (31213/38464)
Loss: 0.743 | Acc: 81.154% (36409/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9065, Accuracy: 7620/10000 (76.20%)

Epoch: 70
Loss: 0.699 | Acc: 85.938% (55/64)
Loss: 0.716 | Acc: 82.024% (5302/6464)
Loss: 0.718 | Acc: 81.786% (10521/12864)
Loss: 0.723 | Acc: 81.676% (15734/19264)
Loss: 0.722 | Acc: 81.799% (20993/25664)
Loss: 0.727 | Acc: 81.708% (26199/32064)
Loss: 0.732 | Acc: 81.559% (31371/38464)
Loss: 0.737 | Acc: 81.393% (36516/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9618, Accuracy: 7331/10000 (73.31%)

Epoch: 71
Loss: 0.839 | Acc: 78.125% (50/64)
Loss: 0.705 | Acc: 82.565% (5337/6464)
Loss: 0.713 | Acc: 82.253% (10581/12864)
Loss: 0.716 | Acc: 82.340% (15862/19264)
Loss: 0.725 | Acc: 82.080% (21065/25664)
Loss: 0.726 | Acc: 82.117% (26330/32064)
Loss: 0.725 | Acc: 82.030% (31552/38464)
Loss: 0.723 | Acc: 82.037% (36805/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1174, Accuracy: 6841/10000 (68.41%)

Epoch: 72
Loss: 0.852 | Acc: 75.000% (48/64)
Loss: 0.709 | Acc: 82.488% (5332/6464)
Loss: 0.714 | Acc: 82.175% (10571/12864)
Loss: 0.722 | Acc: 81.920% (15781/19264)
Loss: 0.716 | Acc: 82.057% (21059/25664)
Loss: 0.718 | Acc: 82.023% (26300/32064)
Loss: 0.714 | Acc: 82.129% (31590/38464)
Loss: 0.717 | Acc: 82.130% (36847/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3176, Accuracy: 6347/10000 (63.47%)

Epoch: 73
Loss: 0.709 | Acc: 81.250% (52/64)
Loss: 0.677 | Acc: 82.735% (5348/6464)
Loss: 0.696 | Acc: 82.416% (10602/12864)
Loss: 0.705 | Acc: 82.205% (15836/19264)
Loss: 0.709 | Acc: 82.201% (21096/25664)
Loss: 0.710 | Acc: 82.232% (26367/32064)
Loss: 0.705 | Acc: 82.443% (31711/38464)
Loss: 0.708 | Acc: 82.360% (36950/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8999, Accuracy: 7710/10000 (77.10%)

Epoch: 74
Loss: 0.704 | Acc: 82.812% (53/64)
Loss: 0.667 | Acc: 83.648% (5407/6464)
Loss: 0.673 | Acc: 83.543% (10747/12864)
Loss: 0.686 | Acc: 83.077% (16004/19264)
Loss: 0.686 | Acc: 83.151% (21340/25664)
Loss: 0.688 | Acc: 83.143% (26659/32064)
Loss: 0.696 | Acc: 82.911% (31891/38464)
Loss: 0.694 | Acc: 83.015% (37244/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3444, Accuracy: 6094/10000 (60.94%)

Epoch: 75
Loss: 0.563 | Acc: 90.625% (58/64)
Loss: 0.670 | Acc: 83.957% (5427/6464)
Loss: 0.672 | Acc: 83.808% (10781/12864)
Loss: 0.674 | Acc: 83.643% (16113/19264)
Loss: 0.674 | Acc: 83.592% (21453/25664)
Loss: 0.678 | Acc: 83.396% (26740/32064)
Loss: 0.685 | Acc: 83.244% (32019/38464)
Loss: 0.686 | Acc: 83.220% (37336/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8752, Accuracy: 7716/10000 (77.16%)

Epoch: 76
Loss: 0.558 | Acc: 85.938% (55/64)
Loss: 0.670 | Acc: 83.895% (5423/6464)
Loss: 0.661 | Acc: 83.909% (10794/12864)
Loss: 0.669 | Acc: 83.825% (16148/19264)
Loss: 0.670 | Acc: 83.802% (21507/25664)
Loss: 0.677 | Acc: 83.620% (26812/32064)
Loss: 0.676 | Acc: 83.605% (32158/38464)
Loss: 0.674 | Acc: 83.677% (37541/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8447, Accuracy: 7837/10000 (78.37%)

Epoch: 77
Loss: 0.759 | Acc: 79.688% (51/64)
Loss: 0.655 | Acc: 83.988% (5429/6464)
Loss: 0.661 | Acc: 83.823% (10783/12864)
Loss: 0.666 | Acc: 83.799% (16143/19264)
Loss: 0.666 | Acc: 83.826% (21513/25664)
Loss: 0.664 | Acc: 83.873% (26893/32064)
Loss: 0.661 | Acc: 83.969% (32298/38464)
Loss: 0.657 | Acc: 84.112% (37736/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8461, Accuracy: 7873/10000 (78.73%)

Epoch: 78
Loss: 0.678 | Acc: 79.688% (51/64)
Loss: 0.640 | Acc: 84.561% (5466/6464)
Loss: 0.639 | Acc: 84.515% (10872/12864)
Loss: 0.645 | Acc: 84.536% (16285/19264)
Loss: 0.650 | Acc: 84.433% (21669/25664)
Loss: 0.654 | Acc: 84.313% (27034/32064)
Loss: 0.648 | Acc: 84.440% (32479/38464)
Loss: 0.649 | Acc: 84.362% (37848/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1192, Accuracy: 6861/10000 (68.61%)

Epoch: 79
Loss: 0.528 | Acc: 87.500% (56/64)
Loss: 0.608 | Acc: 85.705% (5540/6464)
Loss: 0.611 | Acc: 85.525% (11002/12864)
Loss: 0.613 | Acc: 85.460% (16463/19264)
Loss: 0.624 | Acc: 85.221% (21871/25664)
Loss: 0.627 | Acc: 85.233% (27329/32064)
Loss: 0.628 | Acc: 85.220% (32779/38464)
Loss: 0.628 | Acc: 85.182% (38216/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0797, Accuracy: 7013/10000 (70.13%)

Epoch: 80
Loss: 0.953 | Acc: 73.438% (47/64)
Loss: 0.663 | Acc: 83.849% (5420/6464)
Loss: 0.633 | Acc: 84.670% (10892/12864)
Loss: 0.623 | Acc: 85.071% (16388/19264)
Loss: 0.617 | Acc: 85.228% (21873/25664)
Loss: 0.619 | Acc: 85.220% (27325/32064)
Loss: 0.621 | Acc: 85.152% (32753/38464)
Loss: 0.623 | Acc: 85.122% (38189/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9096, Accuracy: 7593/10000 (75.93%)

Epoch: 81
Loss: 0.464 | Acc: 90.625% (58/64)
Loss: 0.597 | Acc: 85.752% (5543/6464)
Loss: 0.617 | Acc: 85.448% (10992/12864)
Loss: 0.610 | Acc: 85.600% (16490/19264)
Loss: 0.610 | Acc: 85.450% (21930/25664)
Loss: 0.606 | Acc: 85.591% (27444/32064)
Loss: 0.606 | Acc: 85.613% (32930/38464)
Loss: 0.609 | Acc: 85.523% (38369/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8620, Accuracy: 7822/10000 (78.22%)

Epoch: 82
Loss: 0.477 | Acc: 90.625% (58/64)
Loss: 0.591 | Acc: 86.185% (5571/6464)
Loss: 0.580 | Acc: 86.598% (11140/12864)
Loss: 0.572 | Acc: 86.763% (16714/19264)
Loss: 0.578 | Acc: 86.612% (22228/25664)
Loss: 0.582 | Acc: 86.424% (27711/32064)
Loss: 0.588 | Acc: 86.247% (33174/38464)
Loss: 0.587 | Acc: 86.263% (38701/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8445, Accuracy: 7931/10000 (79.31%)

Epoch: 83
Loss: 0.598 | Acc: 84.375% (54/64)
Loss: 0.551 | Acc: 87.067% (5628/6464)
Loss: 0.556 | Acc: 86.816% (11168/12864)
Loss: 0.551 | Acc: 87.017% (16763/19264)
Loss: 0.562 | Acc: 86.806% (22278/25664)
Loss: 0.563 | Acc: 86.783% (27826/32064)
Loss: 0.571 | Acc: 86.645% (33327/38464)
Loss: 0.570 | Acc: 86.649% (38874/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8417, Accuracy: 7992/10000 (79.92%)

Epoch: 84
Loss: 0.485 | Acc: 89.062% (57/64)
Loss: 0.537 | Acc: 87.639% (5665/6464)
Loss: 0.542 | Acc: 87.523% (11259/12864)
Loss: 0.555 | Acc: 87.194% (16797/19264)
Loss: 0.556 | Acc: 87.122% (22359/25664)
Loss: 0.552 | Acc: 87.154% (27945/32064)
Loss: 0.556 | Acc: 87.066% (33489/38464)
Loss: 0.555 | Acc: 87.097% (39075/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7636, Accuracy: 8223/10000 (82.23%)

Epoch: 85
Loss: 0.605 | Acc: 87.500% (56/64)
Loss: 0.529 | Acc: 87.608% (5663/6464)
Loss: 0.525 | Acc: 87.655% (11276/12864)
Loss: 0.526 | Acc: 87.640% (16883/19264)
Loss: 0.527 | Acc: 87.594% (22480/25664)
Loss: 0.525 | Acc: 87.737% (28132/32064)
Loss: 0.530 | Acc: 87.659% (33717/38464)
Loss: 0.531 | Acc: 87.603% (39302/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9162, Accuracy: 7764/10000 (77.64%)

Epoch: 86
Loss: 0.520 | Acc: 85.938% (55/64)
Loss: 0.499 | Acc: 88.351% (5711/6464)
Loss: 0.484 | Acc: 88.744% (11416/12864)
Loss: 0.493 | Acc: 88.564% (17061/19264)
Loss: 0.505 | Acc: 88.291% (22659/25664)
Loss: 0.506 | Acc: 88.314% (28317/32064)
Loss: 0.509 | Acc: 88.233% (33938/38464)
Loss: 0.510 | Acc: 88.233% (39585/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8167, Accuracy: 8095/10000 (80.95%)

Epoch: 87
Loss: 0.494 | Acc: 89.062% (57/64)
Loss: 0.497 | Acc: 88.614% (5728/6464)
Loss: 0.478 | Acc: 88.899% (11436/12864)
Loss: 0.485 | Acc: 88.772% (17101/19264)
Loss: 0.487 | Acc: 88.751% (22777/25664)
Loss: 0.487 | Acc: 88.776% (28465/32064)
Loss: 0.488 | Acc: 88.714% (34123/38464)
Loss: 0.485 | Acc: 88.813% (39845/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7818, Accuracy: 8232/10000 (82.32%)

Epoch: 88
Loss: 0.451 | Acc: 92.188% (59/64)
Loss: 0.448 | Acc: 89.759% (5802/6464)
Loss: 0.448 | Acc: 89.754% (11546/12864)
Loss: 0.455 | Acc: 89.566% (17254/19264)
Loss: 0.461 | Acc: 89.448% (22956/25664)
Loss: 0.461 | Acc: 89.434% (28676/32064)
Loss: 0.458 | Acc: 89.452% (34407/38464)
Loss: 0.460 | Acc: 89.441% (40127/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7921, Accuracy: 8195/10000 (81.95%)

Epoch: 89
Loss: 0.546 | Acc: 85.938% (55/64)
Loss: 0.419 | Acc: 90.207% (5831/6464)
Loss: 0.422 | Acc: 90.205% (11604/12864)
Loss: 0.422 | Acc: 90.173% (17371/19264)
Loss: 0.423 | Acc: 90.126% (23130/25664)
Loss: 0.428 | Acc: 90.017% (28863/32064)
Loss: 0.427 | Acc: 90.056% (34639/38464)
Loss: 0.428 | Acc: 90.070% (40409/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8018, Accuracy: 8201/10000 (82.01%)

Epoch: 90
Loss: 0.231 | Acc: 93.750% (60/64)
Loss: 0.395 | Acc: 90.702% (5863/6464)
Loss: 0.393 | Acc: 90.726% (11671/12864)
Loss: 0.397 | Acc: 90.594% (17452/19264)
Loss: 0.394 | Acc: 90.644% (23263/25664)
Loss: 0.399 | Acc: 90.544% (29032/32064)
Loss: 0.401 | Acc: 90.526% (34820/38464)
Loss: 0.401 | Acc: 90.525% (40613/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8385, Accuracy: 8192/10000 (81.92%)

Epoch: 91
Loss: 0.364 | Acc: 92.188% (59/64)
Loss: 0.374 | Acc: 91.074% (5887/6464)
Loss: 0.376 | Acc: 90.850% (11687/12864)
Loss: 0.377 | Acc: 90.786% (17489/19264)
Loss: 0.373 | Acc: 90.933% (23337/25664)
Loss: 0.372 | Acc: 90.974% (29170/32064)
Loss: 0.371 | Acc: 91.028% (35013/38464)
Loss: 0.370 | Acc: 91.084% (40864/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8577, Accuracy: 8193/10000 (81.93%)

Epoch: 92
Loss: 0.384 | Acc: 92.188% (59/64)
Loss: 0.329 | Acc: 91.940% (5943/6464)
Loss: 0.318 | Acc: 92.257% (11868/12864)
Loss: 0.324 | Acc: 92.156% (17753/19264)
Loss: 0.331 | Acc: 91.950% (23598/25664)
Loss: 0.340 | Acc: 91.751% (29419/32064)
Loss: 0.340 | Acc: 91.746% (35289/38464)
Loss: 0.339 | Acc: 91.760% (41167/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8667, Accuracy: 8225/10000 (82.25%)

Epoch: 93
Loss: 0.347 | Acc: 90.625% (58/64)
Loss: 0.285 | Acc: 92.868% (6003/6464)
Loss: 0.292 | Acc: 92.786% (11936/12864)
Loss: 0.292 | Acc: 92.717% (17861/19264)
Loss: 0.297 | Acc: 92.530% (23747/25664)
Loss: 0.297 | Acc: 92.506% (29661/32064)
Loss: 0.297 | Acc: 92.567% (35605/38464)
Loss: 0.298 | Acc: 92.537% (41516/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8809, Accuracy: 8204/10000 (82.04%)

Epoch: 94
Loss: 0.171 | Acc: 95.312% (61/64)
Loss: 0.261 | Acc: 93.425% (6039/6464)
Loss: 0.266 | Acc: 93.369% (12011/12864)
Loss: 0.269 | Acc: 93.246% (17963/19264)
Loss: 0.268 | Acc: 93.247% (23931/25664)
Loss: 0.267 | Acc: 93.242% (29897/32064)
Loss: 0.265 | Acc: 93.279% (35879/38464)
Loss: 0.264 | Acc: 93.322% (41868/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9094, Accuracy: 8239/10000 (82.39%)

Epoch: 95
Loss: 0.184 | Acc: 93.750% (60/64)
Loss: 0.257 | Acc: 93.162% (6022/6464)
Loss: 0.301 | Acc: 92.413% (11888/12864)
Loss: 0.334 | Acc: 91.694% (17664/19264)
Loss: 0.359 | Acc: 91.307% (23433/25664)
Loss: 0.384 | Acc: 90.812% (29118/32064)
Loss: 0.407 | Acc: 90.300% (34733/38464)
Loss: 0.427 | Acc: 89.829% (40301/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7972, Accuracy: 8093/10000 (80.93%)

Epoch: 96
Loss: 0.595 | Acc: 85.938% (55/64)
Loss: 0.574 | Acc: 86.711% (5605/6464)
Loss: 0.579 | Acc: 86.762% (11161/12864)
Loss: 0.596 | Acc: 86.322% (16629/19264)
Loss: 0.604 | Acc: 86.039% (22081/25664)
Loss: 0.607 | Acc: 85.909% (27546/32064)
Loss: 0.610 | Acc: 85.745% (32981/38464)
Loss: 0.615 | Acc: 85.599% (38403/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8106, Accuracy: 8036/10000 (80.36%)

Epoch: 97
Loss: 0.689 | Acc: 85.938% (55/64)
Loss: 0.662 | Acc: 84.097% (5436/6464)
Loss: 0.663 | Acc: 84.126% (10822/12864)
Loss: 0.658 | Acc: 84.230% (16226/19264)
Loss: 0.665 | Acc: 83.958% (21547/25664)
Loss: 0.665 | Acc: 84.001% (26934/32064)
Loss: 0.662 | Acc: 84.125% (32358/38464)
Loss: 0.663 | Acc: 84.108% (37734/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8212, Accuracy: 8007/10000 (80.07%)
torch.Size([100, 10])
Test set: Average loss: 0.8212, Accuracy: 8007/10000 (80.07%)

Epoch: 98
Loss: 0.438 | Acc: 92.188% (59/64)
Loss: 0.695 | Acc: 83.199% (5378/6464)
Loss: 0.685 | Acc: 83.489% (10740/12864)
Loss: 0.686 | Acc: 83.306% (16048/19264)
Loss: 0.686 | Acc: 83.479% (21424/25664)
Loss: 0.683 | Acc: 83.620% (26812/32064)
Loss: 0.687 | Acc: 83.457% (32101/38464)
Loss: 0.685 | Acc: 83.535% (37477/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8250, Accuracy: 7977/10000 (79.77%)
torch.Size([100, 10])
Test set: Average loss: 0.8250, Accuracy: 7977/10000 (79.77%)

Epoch: 99
Loss: 0.456 | Acc: 87.500% (56/64)
Loss: 0.675 | Acc: 83.818% (5418/6464)
Loss: 0.674 | Acc: 83.870% (10789/12864)
Loss: 0.675 | Acc: 83.737% (16131/19264)
Loss: 0.683 | Acc: 83.522% (21435/25664)
Loss: 0.686 | Acc: 83.483% (26768/32064)
Loss: 0.686 | Acc: 83.538% (32132/38464)
Loss: 0.687 | Acc: 83.495% (37459/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8255, Accuracy: 7978/10000 (79.78%)
torch.Size([100, 10])
Test set: Average loss: 0.8255, Accuracy: 7978/10000 (79.78%)

Epoch: 100
Loss: 0.682 | Acc: 75.000% (48/64)
Loss: 1.797 | Acc: 37.562% (2428/6464)
Loss: 1.505 | Acc: 50.381% (6481/12864)
Loss: 1.361 | Acc: 56.598% (10903/19264)
Loss: 1.272 | Acc: 60.400% (15501/25664)
Loss: 1.210 | Acc: 62.987% (20196/32064)
Loss: 1.166 | Acc: 64.858% (24947/38464)
Loss: 1.133 | Acc: 66.178% (29690/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3552, Accuracy: 6136/10000 (61.36%)

Epoch: 101
Loss: 0.855 | Acc: 75.000% (48/64)
Loss: 0.866 | Acc: 76.609% (4952/6464)
Loss: 0.869 | Acc: 76.384% (9826/12864)
Loss: 0.871 | Acc: 76.428% (14723/19264)
Loss: 0.867 | Acc: 76.637% (19668/25664)
Loss: 0.868 | Acc: 76.659% (24580/32064)
Loss: 0.864 | Acc: 76.851% (29560/38464)
Loss: 0.868 | Acc: 76.774% (34444/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9254, Accuracy: 3833/10000 (38.33%)

Epoch: 102
Loss: 1.016 | Acc: 70.312% (45/64)
Loss: 0.833 | Acc: 78.079% (5047/6464)
Loss: 0.837 | Acc: 77.721% (9998/12864)
Loss: 0.833 | Acc: 77.974% (15021/19264)
Loss: 0.833 | Acc: 78.043% (20029/25664)
Loss: 0.831 | Acc: 78.153% (25059/32064)
Loss: 0.832 | Acc: 78.161% (30064/38464)
Loss: 0.831 | Acc: 78.203% (35085/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1189, Accuracy: 4055/10000 (40.55%)

Epoch: 103
Loss: 0.915 | Acc: 62.500% (40/64)
Loss: 0.826 | Acc: 78.233% (5057/6464)
Loss: 0.827 | Acc: 78.382% (10083/12864)
Loss: 0.818 | Acc: 78.660% (15153/19264)
Loss: 0.818 | Acc: 78.667% (20189/25664)
Loss: 0.820 | Acc: 78.646% (25217/32064)
Loss: 0.820 | Acc: 78.658% (30255/38464)
Loss: 0.820 | Acc: 78.638% (35280/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3495, Accuracy: 6126/10000 (61.26%)

Epoch: 104
Loss: 0.810 | Acc: 79.688% (51/64)
Loss: 0.801 | Acc: 78.991% (5106/6464)
Loss: 0.811 | Acc: 78.856% (10144/12864)
Loss: 0.808 | Acc: 78.971% (15213/19264)
Loss: 0.812 | Acc: 78.912% (20252/25664)
Loss: 0.812 | Acc: 79.004% (25332/32064)
Loss: 0.814 | Acc: 78.850% (30329/38464)
Loss: 0.812 | Acc: 78.843% (35372/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2949, Accuracy: 6347/10000 (63.47%)

Epoch: 105
Loss: 1.083 | Acc: 68.750% (44/64)
Loss: 0.796 | Acc: 78.868% (5098/6464)
Loss: 0.793 | Acc: 79.229% (10192/12864)
Loss: 0.794 | Acc: 79.335% (15283/19264)
Loss: 0.795 | Acc: 79.313% (20355/25664)
Loss: 0.800 | Acc: 79.323% (25434/32064)
Loss: 0.801 | Acc: 79.282% (30495/38464)
Loss: 0.803 | Acc: 79.166% (35517/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9861, Accuracy: 4451/10000 (44.51%)

Epoch: 106
Loss: 1.124 | Acc: 70.312% (45/64)
Loss: 0.813 | Acc: 78.666% (5085/6464)
Loss: 0.804 | Acc: 78.996% (10162/12864)
Loss: 0.797 | Acc: 79.303% (15277/19264)
Loss: 0.801 | Acc: 79.267% (20343/25664)
Loss: 0.802 | Acc: 79.210% (25398/32064)
Loss: 0.803 | Acc: 79.186% (30458/38464)
Loss: 0.807 | Acc: 79.001% (35443/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1449, Accuracy: 6799/10000 (67.99%)

Epoch: 107
Loss: 0.801 | Acc: 75.000% (48/64)
Loss: 0.769 | Acc: 80.600% (5210/6464)
Loss: 0.779 | Acc: 80.037% (10296/12864)
Loss: 0.782 | Acc: 79.926% (15397/19264)
Loss: 0.789 | Acc: 79.734% (20463/25664)
Loss: 0.794 | Acc: 79.479% (25484/32064)
Loss: 0.794 | Acc: 79.422% (30549/38464)
Loss: 0.795 | Acc: 79.456% (35647/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9541, Accuracy: 3093/10000 (30.93%)

Epoch: 108
Loss: 1.157 | Acc: 68.750% (44/64)
Loss: 0.786 | Acc: 79.749% (5155/6464)
Loss: 0.787 | Acc: 79.656% (10247/12864)
Loss: 0.796 | Acc: 79.407% (15297/19264)
Loss: 0.795 | Acc: 79.504% (20404/25664)
Loss: 0.790 | Acc: 79.631% (25533/32064)
Loss: 0.794 | Acc: 79.589% (30613/38464)
Loss: 0.796 | Acc: 79.511% (35672/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2542, Accuracy: 4041/10000 (40.41%)

Epoch: 109
Loss: 1.057 | Acc: 68.750% (44/64)
Loss: 0.806 | Acc: 79.425% (5134/6464)
Loss: 0.796 | Acc: 79.688% (10251/12864)
Loss: 0.792 | Acc: 79.791% (15371/19264)
Loss: 0.786 | Acc: 79.945% (20517/25664)
Loss: 0.787 | Acc: 79.928% (25628/32064)
Loss: 0.791 | Acc: 79.802% (30695/38464)
Loss: 0.793 | Acc: 79.656% (35737/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5740, Accuracy: 5388/10000 (53.88%)

Epoch: 110
Loss: 1.079 | Acc: 65.625% (42/64)
Loss: 0.800 | Acc: 79.409% (5133/6464)
Loss: 0.776 | Acc: 80.271% (10326/12864)
Loss: 0.775 | Acc: 80.248% (15459/19264)
Loss: 0.773 | Acc: 80.210% (20585/25664)
Loss: 0.778 | Acc: 80.031% (25661/32064)
Loss: 0.783 | Acc: 79.893% (30730/38464)
Loss: 0.783 | Acc: 79.839% (35819/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0311, Accuracy: 7109/10000 (71.09%)

Epoch: 111
Loss: 0.893 | Acc: 73.438% (47/64)
Loss: 0.788 | Acc: 79.811% (5159/6464)
Loss: 0.782 | Acc: 79.711% (10254/12864)
Loss: 0.776 | Acc: 79.973% (15406/19264)
Loss: 0.772 | Acc: 79.956% (20520/25664)
Loss: 0.779 | Acc: 79.937% (25631/32064)
Loss: 0.782 | Acc: 79.846% (30712/38464)
Loss: 0.783 | Acc: 79.855% (35826/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2389, Accuracy: 6414/10000 (64.14%)

Epoch: 112
Loss: 1.217 | Acc: 65.625% (42/64)
Loss: 0.759 | Acc: 80.569% (5208/6464)
Loss: 0.762 | Acc: 80.364% (10338/12864)
Loss: 0.771 | Acc: 80.144% (15439/19264)
Loss: 0.771 | Acc: 80.093% (20555/25664)
Loss: 0.771 | Acc: 80.087% (25679/32064)
Loss: 0.775 | Acc: 80.064% (30796/38464)
Loss: 0.777 | Acc: 80.006% (35894/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9402, Accuracy: 7467/10000 (74.67%)

Epoch: 113
Loss: 0.761 | Acc: 81.250% (52/64)
Loss: 0.755 | Acc: 80.894% (5229/6464)
Loss: 0.765 | Acc: 80.512% (10357/12864)
Loss: 0.761 | Acc: 80.746% (15555/19264)
Loss: 0.759 | Acc: 80.677% (20705/25664)
Loss: 0.754 | Acc: 80.689% (25872/32064)
Loss: 0.761 | Acc: 80.488% (30959/38464)
Loss: 0.767 | Acc: 80.350% (36048/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4788, Accuracy: 5954/10000 (59.54%)

Epoch: 114
Loss: 0.944 | Acc: 82.812% (53/64)
Loss: 0.755 | Acc: 80.910% (5230/6464)
Loss: 0.760 | Acc: 80.613% (10370/12864)
Loss: 0.762 | Acc: 80.471% (15502/19264)
Loss: 0.757 | Acc: 80.669% (20703/25664)
Loss: 0.760 | Acc: 80.614% (25848/32064)
Loss: 0.767 | Acc: 80.371% (30914/38464)
Loss: 0.767 | Acc: 80.452% (36094/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1390, Accuracy: 6744/10000 (67.44%)

Epoch: 115
Loss: 0.936 | Acc: 68.750% (44/64)
Loss: 0.723 | Acc: 81.931% (5296/6464)
Loss: 0.734 | Acc: 81.639% (10502/12864)
Loss: 0.749 | Acc: 81.183% (15639/19264)
Loss: 0.750 | Acc: 81.079% (20808/25664)
Loss: 0.750 | Acc: 80.960% (25959/32064)
Loss: 0.752 | Acc: 80.847% (31097/38464)
Loss: 0.753 | Acc: 80.842% (36269/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1250, Accuracy: 6901/10000 (69.01%)

Epoch: 116
Loss: 0.796 | Acc: 79.688% (51/64)
Loss: 0.753 | Acc: 81.095% (5242/6464)
Loss: 0.750 | Acc: 81.095% (10432/12864)
Loss: 0.751 | Acc: 80.949% (15594/19264)
Loss: 0.749 | Acc: 81.001% (20788/25664)
Loss: 0.758 | Acc: 80.829% (25917/32064)
Loss: 0.754 | Acc: 80.951% (31137/38464)
Loss: 0.753 | Acc: 80.947% (36316/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3316, Accuracy: 6221/10000 (62.21%)

Epoch: 117
Loss: 0.628 | Acc: 79.688% (51/64)
Loss: 0.763 | Acc: 80.863% (5227/6464)
Loss: 0.752 | Acc: 81.157% (10440/12864)
Loss: 0.744 | Acc: 81.468% (15694/19264)
Loss: 0.741 | Acc: 81.585% (20938/25664)
Loss: 0.749 | Acc: 81.312% (26072/32064)
Loss: 0.748 | Acc: 81.242% (31249/38464)
Loss: 0.745 | Acc: 81.241% (36448/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0568, Accuracy: 6990/10000 (69.90%)

Epoch: 118
Loss: 0.859 | Acc: 79.688% (51/64)
Loss: 0.708 | Acc: 82.132% (5309/6464)
Loss: 0.718 | Acc: 82.097% (10561/12864)
Loss: 0.714 | Acc: 82.236% (15842/19264)
Loss: 0.723 | Acc: 81.994% (21043/25664)
Loss: 0.731 | Acc: 81.687% (26192/32064)
Loss: 0.731 | Acc: 81.692% (31422/38464)
Loss: 0.734 | Acc: 81.622% (36619/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3045, Accuracy: 6503/10000 (65.03%)

Epoch: 119
Loss: 0.624 | Acc: 84.375% (54/64)
Loss: 0.737 | Acc: 81.250% (5252/6464)
Loss: 0.724 | Acc: 81.740% (10515/12864)
Loss: 0.722 | Acc: 81.728% (15744/19264)
Loss: 0.726 | Acc: 81.718% (20972/25664)
Loss: 0.728 | Acc: 81.730% (26206/32064)
Loss: 0.729 | Acc: 81.754% (31446/38464)
Loss: 0.731 | Acc: 81.729% (36667/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9903, Accuracy: 7344/10000 (73.44%)

Epoch: 120
Loss: 0.523 | Acc: 89.062% (57/64)
Loss: 0.727 | Acc: 81.389% (5261/6464)
Loss: 0.724 | Acc: 81.849% (10529/12864)
Loss: 0.722 | Acc: 81.863% (15770/19264)
Loss: 0.724 | Acc: 81.901% (21019/25664)
Loss: 0.720 | Acc: 82.070% (26315/32064)
Loss: 0.724 | Acc: 81.970% (31529/38464)
Loss: 0.722 | Acc: 82.068% (36819/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9753, Accuracy: 7391/10000 (73.91%)

Epoch: 121
Loss: 0.675 | Acc: 87.500% (56/64)
Loss: 0.677 | Acc: 83.323% (5386/6464)
Loss: 0.700 | Acc: 82.727% (10642/12864)
Loss: 0.705 | Acc: 82.652% (15922/19264)
Loss: 0.711 | Acc: 82.392% (21145/25664)
Loss: 0.709 | Acc: 82.432% (26431/32064)
Loss: 0.711 | Acc: 82.319% (31663/38464)
Loss: 0.713 | Acc: 82.324% (36934/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0129, Accuracy: 7244/10000 (72.44%)

Epoch: 122
Loss: 0.862 | Acc: 76.562% (49/64)
Loss: 0.694 | Acc: 82.812% (5353/6464)
Loss: 0.683 | Acc: 83.139% (10695/12864)
Loss: 0.687 | Acc: 82.979% (15985/19264)
Loss: 0.691 | Acc: 82.925% (21282/25664)
Loss: 0.692 | Acc: 82.987% (26609/32064)
Loss: 0.693 | Acc: 82.903% (31888/38464)
Loss: 0.697 | Acc: 82.759% (37129/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5285, Accuracy: 5838/10000 (58.38%)

Epoch: 123
Loss: 0.607 | Acc: 85.938% (55/64)
Loss: 0.691 | Acc: 83.060% (5369/6464)
Loss: 0.691 | Acc: 82.929% (10668/12864)
Loss: 0.694 | Acc: 82.916% (15973/19264)
Loss: 0.691 | Acc: 82.992% (21299/25664)
Loss: 0.693 | Acc: 83.003% (26614/32064)
Loss: 0.693 | Acc: 82.992% (31922/38464)
Loss: 0.695 | Acc: 82.953% (37216/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8664, Accuracy: 7812/10000 (78.12%)

Epoch: 124
Loss: 0.598 | Acc: 87.500% (56/64)
Loss: 0.673 | Acc: 83.617% (5405/6464)
Loss: 0.670 | Acc: 83.637% (10759/12864)
Loss: 0.676 | Acc: 83.555% (16096/19264)
Loss: 0.673 | Acc: 83.623% (21461/25664)
Loss: 0.681 | Acc: 83.405% (26743/32064)
Loss: 0.680 | Acc: 83.481% (32110/38464)
Loss: 0.685 | Acc: 83.347% (37393/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0140, Accuracy: 7255/10000 (72.55%)

Epoch: 125
Loss: 0.709 | Acc: 81.250% (52/64)
Loss: 0.653 | Acc: 84.189% (5442/6464)
Loss: 0.648 | Acc: 84.134% (10823/12864)
Loss: 0.667 | Acc: 83.586% (16102/19264)
Loss: 0.665 | Acc: 83.728% (21488/25664)
Loss: 0.669 | Acc: 83.617% (26811/32064)
Loss: 0.668 | Acc: 83.683% (32188/38464)
Loss: 0.673 | Acc: 83.561% (37489/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8663, Accuracy: 7754/10000 (77.54%)

Epoch: 126
Loss: 0.566 | Acc: 81.250% (52/64)
Loss: 0.640 | Acc: 84.390% (5455/6464)
Loss: 0.642 | Acc: 84.235% (10836/12864)
Loss: 0.662 | Acc: 83.835% (16150/19264)
Loss: 0.664 | Acc: 83.798% (21506/25664)
Loss: 0.666 | Acc: 83.851% (26886/32064)
Loss: 0.663 | Acc: 83.923% (32280/38464)
Loss: 0.664 | Acc: 83.880% (37632/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8713, Accuracy: 7775/10000 (77.75%)

Epoch: 127
Loss: 0.677 | Acc: 79.688% (51/64)
Loss: 0.637 | Acc: 84.731% (5477/6464)
Loss: 0.644 | Acc: 84.593% (10882/12864)
Loss: 0.651 | Acc: 84.427% (16264/19264)
Loss: 0.653 | Acc: 84.348% (21647/25664)
Loss: 0.655 | Acc: 84.350% (27046/32064)
Loss: 0.651 | Acc: 84.432% (32476/38464)
Loss: 0.649 | Acc: 84.547% (37931/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9088, Accuracy: 7654/10000 (76.54%)

Epoch: 128
Loss: 0.863 | Acc: 76.562% (49/64)
Loss: 0.616 | Acc: 85.210% (5508/6464)
Loss: 0.619 | Acc: 85.121% (10950/12864)
Loss: 0.627 | Acc: 84.884% (16352/19264)
Loss: 0.631 | Acc: 84.804% (21764/25664)
Loss: 0.635 | Acc: 84.662% (27146/32064)
Loss: 0.639 | Acc: 84.541% (32518/38464)
Loss: 0.640 | Acc: 84.527% (37922/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9909, Accuracy: 7408/10000 (74.08%)

Epoch: 129
Loss: 0.655 | Acc: 85.938% (55/64)
Loss: 0.615 | Acc: 85.210% (5508/6464)
Loss: 0.621 | Acc: 85.082% (10945/12864)
Loss: 0.615 | Acc: 85.278% (16428/19264)
Loss: 0.618 | Acc: 85.244% (21877/25664)
Loss: 0.626 | Acc: 85.027% (27263/32064)
Loss: 0.629 | Acc: 84.976% (32685/38464)
Loss: 0.627 | Acc: 85.095% (38177/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1548, Accuracy: 6880/10000 (68.80%)

Epoch: 130
Loss: 0.835 | Acc: 81.250% (52/64)
Loss: 0.625 | Acc: 85.210% (5508/6464)
Loss: 0.635 | Acc: 85.145% (10953/12864)
Loss: 0.617 | Acc: 85.559% (16482/19264)
Loss: 0.615 | Acc: 85.509% (21945/25664)
Loss: 0.610 | Acc: 85.651% (27463/32064)
Loss: 0.612 | Acc: 85.555% (32908/38464)
Loss: 0.610 | Acc: 85.632% (38418/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9519, Accuracy: 7502/10000 (75.02%)

Epoch: 131
Loss: 0.769 | Acc: 75.000% (48/64)
Loss: 0.583 | Acc: 86.587% (5597/6464)
Loss: 0.584 | Acc: 86.303% (11102/12864)
Loss: 0.579 | Acc: 86.394% (16643/19264)
Loss: 0.583 | Acc: 86.315% (22152/25664)
Loss: 0.589 | Acc: 86.156% (27625/32064)
Loss: 0.589 | Acc: 86.158% (33140/38464)
Loss: 0.593 | Acc: 86.053% (38607/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8951, Accuracy: 7730/10000 (77.30%)

Epoch: 132
Loss: 0.772 | Acc: 82.812% (53/64)
Loss: 0.562 | Acc: 86.850% (5614/6464)
Loss: 0.574 | Acc: 86.552% (11134/12864)
Loss: 0.574 | Acc: 86.472% (16658/19264)
Loss: 0.580 | Acc: 86.436% (22183/25664)
Loss: 0.582 | Acc: 86.380% (27697/32064)
Loss: 0.581 | Acc: 86.450% (33252/38464)
Loss: 0.580 | Acc: 86.508% (38811/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2419, Accuracy: 6848/10000 (68.48%)

Epoch: 133
Loss: 0.591 | Acc: 82.812% (53/64)
Loss: 0.519 | Acc: 87.639% (5665/6464)
Loss: 0.543 | Acc: 87.034% (11196/12864)
Loss: 0.556 | Acc: 86.893% (16739/19264)
Loss: 0.558 | Acc: 86.853% (22290/25664)
Loss: 0.566 | Acc: 86.683% (27794/32064)
Loss: 0.567 | Acc: 86.668% (33336/38464)
Loss: 0.565 | Acc: 86.747% (38918/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9077, Accuracy: 7761/10000 (77.61%)

Epoch: 134
Loss: 0.412 | Acc: 90.625% (58/64)
Loss: 0.553 | Acc: 87.345% (5646/6464)
Loss: 0.547 | Acc: 87.453% (11250/12864)
Loss: 0.542 | Acc: 87.562% (16868/19264)
Loss: 0.540 | Acc: 87.590% (22479/25664)
Loss: 0.547 | Acc: 87.410% (28027/32064)
Loss: 0.546 | Acc: 87.448% (33636/38464)
Loss: 0.541 | Acc: 87.516% (39263/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8255, Accuracy: 7973/10000 (79.73%)

Epoch: 135
Loss: 0.529 | Acc: 89.062% (57/64)
Loss: 0.494 | Acc: 88.660% (5731/6464)
Loss: 0.494 | Acc: 88.666% (11406/12864)
Loss: 0.498 | Acc: 88.476% (17044/19264)
Loss: 0.510 | Acc: 88.182% (22631/25664)
Loss: 0.514 | Acc: 88.093% (28246/32064)
Loss: 0.522 | Acc: 87.885% (33804/38464)
Loss: 0.520 | Acc: 87.928% (39448/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7782, Accuracy: 8215/10000 (82.15%)

Epoch: 136
Loss: 0.406 | Acc: 92.188% (59/64)
Loss: 0.508 | Acc: 87.902% (5682/6464)
Loss: 0.506 | Acc: 88.153% (11340/12864)
Loss: 0.493 | Acc: 88.647% (17077/19264)
Loss: 0.496 | Acc: 88.603% (22739/25664)
Loss: 0.499 | Acc: 88.532% (28387/32064)
Loss: 0.502 | Acc: 88.415% (34008/38464)
Loss: 0.502 | Acc: 88.421% (39669/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9192, Accuracy: 7802/10000 (78.02%)

Epoch: 137
Loss: 0.536 | Acc: 89.062% (57/64)
Loss: 0.465 | Acc: 89.217% (5767/6464)
Loss: 0.466 | Acc: 89.117% (11464/12864)
Loss: 0.470 | Acc: 89.172% (17178/19264)
Loss: 0.469 | Acc: 89.199% (22892/25664)
Loss: 0.475 | Acc: 89.047% (28552/32064)
Loss: 0.476 | Acc: 89.021% (34241/38464)
Loss: 0.476 | Acc: 89.042% (39948/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8723, Accuracy: 7974/10000 (79.74%)

Epoch: 138
Loss: 0.385 | Acc: 92.188% (59/64)
Loss: 0.448 | Acc: 89.681% (5797/6464)
Loss: 0.448 | Acc: 89.684% (11537/12864)
Loss: 0.442 | Acc: 89.815% (17302/19264)
Loss: 0.438 | Acc: 89.877% (23066/25664)
Loss: 0.441 | Acc: 89.795% (28792/32064)
Loss: 0.438 | Acc: 89.837% (34555/38464)
Loss: 0.445 | Acc: 89.687% (40237/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8921, Accuracy: 7872/10000 (78.72%)

Epoch: 139
Loss: 0.497 | Acc: 89.062% (57/64)
Loss: 0.421 | Acc: 89.991% (5817/6464)
Loss: 0.417 | Acc: 90.050% (11584/12864)
Loss: 0.417 | Acc: 90.210% (17378/19264)
Loss: 0.426 | Acc: 90.002% (23098/25664)
Loss: 0.430 | Acc: 89.951% (28842/32064)
Loss: 0.430 | Acc: 89.978% (34609/38464)
Loss: 0.429 | Acc: 90.001% (40378/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8197, Accuracy: 8206/10000 (82.06%)

Epoch: 140
Loss: 0.339 | Acc: 89.062% (57/64)
Loss: 0.390 | Acc: 90.857% (5873/6464)
Loss: 0.391 | Acc: 90.726% (11671/12864)
Loss: 0.386 | Acc: 90.853% (17502/19264)
Loss: 0.391 | Acc: 90.754% (23291/25664)
Loss: 0.389 | Acc: 90.834% (29125/32064)
Loss: 0.390 | Acc: 90.797% (34924/38464)
Loss: 0.392 | Acc: 90.736% (40708/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8410, Accuracy: 8199/10000 (81.99%)

Epoch: 141
Loss: 0.420 | Acc: 89.062% (57/64)
Loss: 0.344 | Acc: 91.847% (5937/6464)
Loss: 0.359 | Acc: 91.503% (11771/12864)
Loss: 0.361 | Acc: 91.450% (17617/19264)
Loss: 0.362 | Acc: 91.416% (23461/25664)
Loss: 0.358 | Acc: 91.548% (29354/32064)
Loss: 0.356 | Acc: 91.574% (35223/38464)
Loss: 0.362 | Acc: 91.419% (41014/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8419, Accuracy: 8255/10000 (82.55%)

Epoch: 142
Loss: 0.342 | Acc: 92.188% (59/64)
Loss: 0.340 | Acc: 91.600% (5921/6464)
Loss: 0.329 | Acc: 91.947% (11828/12864)
Loss: 0.327 | Acc: 91.995% (17722/19264)
Loss: 0.327 | Acc: 91.989% (23608/25664)
Loss: 0.328 | Acc: 91.941% (29480/32064)
Loss: 0.329 | Acc: 91.980% (35379/38464)
Loss: 0.331 | Acc: 91.893% (41227/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8527, Accuracy: 8230/10000 (82.30%)

Epoch: 143
Loss: 0.397 | Acc: 89.062% (57/64)
Loss: 0.309 | Acc: 92.342% (5969/6464)
Loss: 0.308 | Acc: 92.289% (11872/12864)
Loss: 0.298 | Acc: 92.665% (17851/19264)
Loss: 0.300 | Acc: 92.604% (23766/25664)
Loss: 0.298 | Acc: 92.587% (29687/32064)
Loss: 0.297 | Acc: 92.648% (35636/38464)
Loss: 0.301 | Acc: 92.571% (41531/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8866, Accuracy: 8258/10000 (82.58%)

Epoch: 144
Loss: 0.280 | Acc: 93.750% (60/64)
Loss: 0.269 | Acc: 93.147% (6021/6464)
Loss: 0.266 | Acc: 93.245% (11995/12864)
Loss: 0.268 | Acc: 93.272% (17968/19264)
Loss: 0.268 | Acc: 93.290% (23942/25664)
Loss: 0.265 | Acc: 93.354% (29933/32064)
Loss: 0.267 | Acc: 93.331% (35899/38464)
Loss: 0.268 | Acc: 93.275% (41847/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8822, Accuracy: 8263/10000 (82.63%)

Epoch: 145
Loss: 0.220 | Acc: 96.875% (62/64)
Loss: 0.271 | Acc: 93.162% (6022/6464)
Loss: 0.296 | Acc: 92.771% (11934/12864)
Loss: 0.322 | Acc: 92.177% (17757/19264)
Loss: 0.346 | Acc: 91.654% (23522/25664)
Loss: 0.364 | Acc: 91.336% (29286/32064)
Loss: 0.387 | Acc: 90.846% (34943/38464)
Loss: 0.404 | Acc: 90.478% (40592/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7917, Accuracy: 8119/10000 (81.19%)

Epoch: 146
Loss: 0.687 | Acc: 85.938% (55/64)
Loss: 0.520 | Acc: 88.057% (5692/6464)
Loss: 0.541 | Acc: 87.609% (11270/12864)
Loss: 0.560 | Acc: 87.209% (16800/19264)
Loss: 0.565 | Acc: 87.056% (22342/25664)
Loss: 0.574 | Acc: 86.692% (27797/32064)
Loss: 0.586 | Acc: 86.312% (33199/38464)
Loss: 0.593 | Acc: 86.036% (38599/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8005, Accuracy: 8066/10000 (80.66%)

Epoch: 147
Loss: 0.685 | Acc: 82.812% (53/64)
Loss: 0.620 | Acc: 85.319% (5515/6464)
Loss: 0.631 | Acc: 84.935% (10926/12864)
Loss: 0.634 | Acc: 85.039% (16382/19264)
Loss: 0.630 | Acc: 85.158% (21855/25664)
Loss: 0.635 | Acc: 84.961% (27242/32064)
Loss: 0.640 | Acc: 84.848% (32636/38464)
Loss: 0.643 | Acc: 84.736% (38016/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8049, Accuracy: 8056/10000 (80.56%)
torch.Size([100, 10])
Test set: Average loss: 0.8049, Accuracy: 8056/10000 (80.56%)

Epoch: 148
Loss: 0.367 | Acc: 93.750% (60/64)
Loss: 0.638 | Acc: 84.777% (5480/6464)
Loss: 0.652 | Acc: 84.383% (10855/12864)
Loss: 0.652 | Acc: 84.385% (16256/19264)
Loss: 0.651 | Acc: 84.406% (21662/25664)
Loss: 0.654 | Acc: 84.350% (27046/32064)
Loss: 0.657 | Acc: 84.323% (32434/38464)
Loss: 0.659 | Acc: 84.272% (37808/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8109, Accuracy: 8021/10000 (80.21%)
torch.Size([100, 10])
Test set: Average loss: 0.8109, Accuracy: 8021/10000 (80.21%)

Epoch: 149
Loss: 0.616 | Acc: 84.375% (54/64)
Loss: 0.659 | Acc: 84.452% (5459/6464)
Loss: 0.656 | Acc: 84.468% (10866/12864)
Loss: 0.658 | Acc: 84.359% (16251/19264)
Loss: 0.657 | Acc: 84.281% (21630/25664)
Loss: 0.655 | Acc: 84.303% (27031/32064)
Loss: 0.661 | Acc: 84.133% (32361/38464)
Loss: 0.660 | Acc: 84.132% (37745/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8121, Accuracy: 8023/10000 (80.23%)
torch.Size([100, 10])
Test set: Average loss: 0.8121, Accuracy: 8023/10000 (80.23%)

Epoch: 150
Loss: 0.439 | Acc: 87.500% (56/64)
Loss: 1.923 | Acc: 31.467% (2034/6464)
Loss: 1.665 | Acc: 42.879% (5516/12864)
Loss: 1.515 | Acc: 49.699% (9574/19264)
Loss: 1.409 | Acc: 54.325% (13942/25664)
Loss: 1.329 | Acc: 57.809% (18536/32064)
Loss: 1.269 | Acc: 60.293% (23191/38464)
Loss: 1.226 | Acc: 62.137% (27877/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6903, Accuracy: 4961/10000 (49.61%)

Epoch: 151
Loss: 0.728 | Acc: 79.688% (51/64)
Loss: 0.890 | Acc: 75.820% (4901/6464)
Loss: 0.890 | Acc: 75.808% (9752/12864)
Loss: 0.898 | Acc: 75.514% (14547/19264)
Loss: 0.890 | Acc: 75.744% (19439/25664)
Loss: 0.881 | Acc: 76.173% (24424/32064)
Loss: 0.881 | Acc: 76.271% (29337/38464)
Loss: 0.879 | Acc: 76.346% (34252/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9953, Accuracy: 4566/10000 (45.66%)

Epoch: 152
Loss: 0.980 | Acc: 73.438% (47/64)
Loss: 0.837 | Acc: 78.063% (5046/6464)
Loss: 0.824 | Acc: 78.343% (10078/12864)
Loss: 0.832 | Acc: 78.120% (15049/19264)
Loss: 0.834 | Acc: 77.969% (20010/25664)
Loss: 0.836 | Acc: 77.919% (24984/32064)
Loss: 0.838 | Acc: 77.943% (29980/38464)
Loss: 0.835 | Acc: 78.038% (35011/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6022, Accuracy: 5406/10000 (54.06%)

Epoch: 153
Loss: 1.066 | Acc: 67.188% (43/64)
Loss: 0.817 | Acc: 78.342% (5064/6464)
Loss: 0.802 | Acc: 78.957% (10157/12864)
Loss: 0.809 | Acc: 79.018% (15222/19264)
Loss: 0.809 | Acc: 79.025% (20281/25664)
Loss: 0.813 | Acc: 78.980% (25324/32064)
Loss: 0.816 | Acc: 78.858% (30332/38464)
Loss: 0.817 | Acc: 78.832% (35367/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8028, Accuracy: 5020/10000 (50.20%)

Epoch: 154
Loss: 1.061 | Acc: 71.875% (46/64)
Loss: 0.817 | Acc: 78.156% (5052/6464)
Loss: 0.820 | Acc: 78.133% (10051/12864)
Loss: 0.811 | Acc: 78.706% (15162/19264)
Loss: 0.810 | Acc: 78.799% (20223/25664)
Loss: 0.812 | Acc: 78.814% (25271/32064)
Loss: 0.809 | Acc: 78.931% (30360/38464)
Loss: 0.807 | Acc: 79.066% (35472/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2905, Accuracy: 6286/10000 (62.86%)

Epoch: 155
Loss: 1.063 | Acc: 65.625% (42/64)
Loss: 0.806 | Acc: 79.378% (5131/6464)
Loss: 0.809 | Acc: 79.112% (10177/12864)
Loss: 0.799 | Acc: 79.501% (15315/19264)
Loss: 0.799 | Acc: 79.317% (20356/25664)
Loss: 0.797 | Acc: 79.319% (25433/32064)
Loss: 0.800 | Acc: 79.290% (30498/38464)
Loss: 0.802 | Acc: 79.211% (35537/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0134, Accuracy: 7296/10000 (72.96%)

Epoch: 156
Loss: 0.582 | Acc: 85.938% (55/64)
Loss: 0.785 | Acc: 79.703% (5152/6464)
Loss: 0.782 | Acc: 79.773% (10262/12864)
Loss: 0.779 | Acc: 79.957% (15403/19264)
Loss: 0.780 | Acc: 79.894% (20504/25664)
Loss: 0.787 | Acc: 79.656% (25541/32064)
Loss: 0.791 | Acc: 79.519% (30586/38464)
Loss: 0.791 | Acc: 79.491% (35663/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1068, Accuracy: 6842/10000 (68.42%)

Epoch: 157
Loss: 0.694 | Acc: 82.812% (53/64)
Loss: 0.792 | Acc: 79.517% (5140/6464)
Loss: 0.777 | Acc: 79.866% (10274/12864)
Loss: 0.791 | Acc: 79.501% (15315/19264)
Loss: 0.795 | Acc: 79.520% (20408/25664)
Loss: 0.794 | Acc: 79.472% (25482/32064)
Loss: 0.790 | Acc: 79.651% (30637/38464)
Loss: 0.793 | Acc: 79.625% (35723/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9316, Accuracy: 5087/10000 (50.87%)

Epoch: 158
Loss: 0.907 | Acc: 73.438% (47/64)
Loss: 0.784 | Acc: 79.858% (5162/6464)
Loss: 0.773 | Acc: 80.185% (10315/12864)
Loss: 0.778 | Acc: 79.963% (15404/19264)
Loss: 0.778 | Acc: 80.023% (20537/25664)
Loss: 0.786 | Acc: 79.803% (25588/32064)
Loss: 0.785 | Acc: 79.856% (30716/38464)
Loss: 0.787 | Acc: 79.846% (35822/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0937, Accuracy: 6916/10000 (69.16%)

Epoch: 159
Loss: 0.872 | Acc: 76.562% (49/64)
Loss: 0.770 | Acc: 80.244% (5187/6464)
Loss: 0.763 | Acc: 80.387% (10341/12864)
Loss: 0.765 | Acc: 80.456% (15499/19264)
Loss: 0.765 | Acc: 80.369% (20626/25664)
Loss: 0.766 | Acc: 80.293% (25745/32064)
Loss: 0.771 | Acc: 80.179% (30840/38464)
Loss: 0.774 | Acc: 80.084% (35929/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7423, Accuracy: 5223/10000 (52.23%)

Epoch: 160
Loss: 0.872 | Acc: 75.000% (48/64)
Loss: 0.779 | Acc: 80.043% (5174/6464)
Loss: 0.791 | Acc: 79.859% (10273/12864)
Loss: 0.775 | Acc: 80.196% (15449/19264)
Loss: 0.775 | Acc: 80.143% (20568/25664)
Loss: 0.772 | Acc: 80.277% (25740/32064)
Loss: 0.780 | Acc: 80.064% (30796/38464)
Loss: 0.779 | Acc: 80.133% (35951/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1208, Accuracy: 6794/10000 (67.94%)

Epoch: 161
Loss: 1.248 | Acc: 70.312% (45/64)
Loss: 0.746 | Acc: 80.554% (5207/6464)
Loss: 0.758 | Acc: 80.255% (10324/12864)
Loss: 0.774 | Acc: 79.895% (15391/19264)
Loss: 0.774 | Acc: 79.999% (20531/25664)
Loss: 0.778 | Acc: 79.968% (25641/32064)
Loss: 0.778 | Acc: 80.018% (30778/38464)
Loss: 0.779 | Acc: 80.000% (35891/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4902, Accuracy: 5783/10000 (57.83%)

Epoch: 162
Loss: 0.753 | Acc: 78.125% (50/64)
Loss: 0.757 | Acc: 80.090% (5177/6464)
Loss: 0.760 | Acc: 80.512% (10357/12864)
Loss: 0.761 | Acc: 80.482% (15504/19264)
Loss: 0.763 | Acc: 80.428% (20641/25664)
Loss: 0.765 | Acc: 80.377% (25772/32064)
Loss: 0.766 | Acc: 80.423% (30934/38464)
Loss: 0.769 | Acc: 80.358% (36052/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9351, Accuracy: 7516/10000 (75.16%)

Epoch: 163
Loss: 0.489 | Acc: 85.938% (55/64)
Loss: 0.738 | Acc: 81.188% (5248/6464)
Loss: 0.745 | Acc: 81.056% (10427/12864)
Loss: 0.748 | Acc: 80.985% (15601/19264)
Loss: 0.758 | Acc: 80.736% (20720/25664)
Loss: 0.762 | Acc: 80.717% (25881/32064)
Loss: 0.763 | Acc: 80.699% (31040/38464)
Loss: 0.765 | Acc: 80.657% (36186/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3246, Accuracy: 6041/10000 (60.41%)

Epoch: 164
Loss: 1.035 | Acc: 75.000% (48/64)
Loss: 0.748 | Acc: 81.420% (5263/6464)
Loss: 0.730 | Acc: 81.631% (10501/12864)
Loss: 0.735 | Acc: 81.432% (15687/19264)
Loss: 0.752 | Acc: 80.763% (20727/25664)
Loss: 0.752 | Acc: 80.763% (25896/32064)
Loss: 0.754 | Acc: 80.727% (31051/38464)
Loss: 0.756 | Acc: 80.699% (36205/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1283, Accuracy: 6768/10000 (67.68%)

Epoch: 165
Loss: 0.757 | Acc: 82.812% (53/64)
Loss: 0.769 | Acc: 80.337% (5193/6464)
Loss: 0.755 | Acc: 80.690% (10380/12864)
Loss: 0.751 | Acc: 80.762% (15558/19264)
Loss: 0.752 | Acc: 80.771% (20729/25664)
Loss: 0.750 | Acc: 80.845% (25922/32064)
Loss: 0.747 | Acc: 81.019% (31163/38464)
Loss: 0.749 | Acc: 81.045% (36360/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0734, Accuracy: 7092/10000 (70.92%)

Epoch: 166
Loss: 1.071 | Acc: 67.188% (43/64)
Loss: 0.740 | Acc: 81.173% (5247/6464)
Loss: 0.734 | Acc: 81.258% (10453/12864)
Loss: 0.730 | Acc: 81.354% (15672/19264)
Loss: 0.738 | Acc: 81.207% (20841/25664)
Loss: 0.739 | Acc: 81.222% (26043/32064)
Loss: 0.743 | Acc: 81.073% (31184/38464)
Loss: 0.743 | Acc: 81.127% (36397/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0189, Accuracy: 7222/10000 (72.22%)

Epoch: 167
Loss: 0.625 | Acc: 87.500% (56/64)
Loss: 0.721 | Acc: 81.838% (5290/6464)
Loss: 0.731 | Acc: 81.701% (10510/12864)
Loss: 0.736 | Acc: 81.691% (15737/19264)
Loss: 0.732 | Acc: 81.706% (20969/25664)
Loss: 0.735 | Acc: 81.484% (26127/32064)
Loss: 0.738 | Acc: 81.390% (31306/38464)
Loss: 0.741 | Acc: 81.375% (36508/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4287, Accuracy: 6499/10000 (64.99%)

Epoch: 168
Loss: 0.551 | Acc: 84.375% (54/64)
Loss: 0.713 | Acc: 82.163% (5311/6464)
Loss: 0.726 | Acc: 81.794% (10522/12864)
Loss: 0.731 | Acc: 81.754% (15749/19264)
Loss: 0.729 | Acc: 81.831% (21001/25664)
Loss: 0.732 | Acc: 81.805% (26230/32064)
Loss: 0.733 | Acc: 81.786% (31458/38464)
Loss: 0.732 | Acc: 81.867% (36729/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4016, Accuracy: 6265/10000 (62.65%)

Epoch: 169
Loss: 0.666 | Acc: 79.688% (51/64)
Loss: 0.708 | Acc: 82.163% (5311/6464)
Loss: 0.716 | Acc: 81.957% (10543/12864)
Loss: 0.722 | Acc: 81.795% (15757/19264)
Loss: 0.724 | Acc: 81.858% (21008/25664)
Loss: 0.729 | Acc: 81.808% (26231/32064)
Loss: 0.728 | Acc: 81.869% (31490/38464)
Loss: 0.727 | Acc: 81.896% (36742/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0571, Accuracy: 7040/10000 (70.40%)

Epoch: 170
Loss: 1.032 | Acc: 71.875% (46/64)
Loss: 0.703 | Acc: 82.843% (5355/6464)
Loss: 0.700 | Acc: 82.859% (10659/12864)
Loss: 0.715 | Acc: 82.382% (15870/19264)
Loss: 0.716 | Acc: 82.290% (21119/25664)
Loss: 0.717 | Acc: 82.164% (26345/32064)
Loss: 0.715 | Acc: 82.225% (31627/38464)
Loss: 0.718 | Acc: 82.191% (36874/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6156, Accuracy: 5841/10000 (58.41%)

Epoch: 171
Loss: 0.932 | Acc: 75.000% (48/64)
Loss: 0.678 | Acc: 83.385% (5390/6464)
Loss: 0.692 | Acc: 82.937% (10669/12864)
Loss: 0.696 | Acc: 82.802% (15951/19264)
Loss: 0.702 | Acc: 82.742% (21235/25664)
Loss: 0.697 | Acc: 82.853% (26566/32064)
Loss: 0.703 | Acc: 82.664% (31796/38464)
Loss: 0.702 | Acc: 82.690% (37098/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3888, Accuracy: 5930/10000 (59.30%)

Epoch: 172
Loss: 1.043 | Acc: 71.875% (46/64)
Loss: 0.700 | Acc: 82.627% (5341/6464)
Loss: 0.693 | Acc: 82.875% (10661/12864)
Loss: 0.691 | Acc: 82.953% (15980/19264)
Loss: 0.691 | Acc: 82.968% (21293/25664)
Loss: 0.689 | Acc: 83.115% (26650/32064)
Loss: 0.691 | Acc: 83.020% (31933/38464)
Loss: 0.694 | Acc: 82.995% (37235/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4212, Accuracy: 6078/10000 (60.78%)

Epoch: 173
Loss: 0.691 | Acc: 84.375% (54/64)
Loss: 0.694 | Acc: 82.828% (5354/6464)
Loss: 0.684 | Acc: 82.945% (10670/12864)
Loss: 0.686 | Acc: 83.145% (16017/19264)
Loss: 0.685 | Acc: 83.097% (21326/25664)
Loss: 0.685 | Acc: 83.177% (26670/32064)
Loss: 0.687 | Acc: 83.145% (31981/38464)
Loss: 0.686 | Acc: 83.176% (37316/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2158, Accuracy: 6657/10000 (66.57%)

Epoch: 174
Loss: 0.858 | Acc: 75.000% (48/64)
Loss: 0.664 | Acc: 83.756% (5414/6464)
Loss: 0.660 | Acc: 84.010% (10807/12864)
Loss: 0.663 | Acc: 83.820% (16147/19264)
Loss: 0.675 | Acc: 83.529% (21437/25664)
Loss: 0.676 | Acc: 83.461% (26761/32064)
Loss: 0.674 | Acc: 83.494% (32115/38464)
Loss: 0.678 | Acc: 83.408% (37420/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8401, Accuracy: 7834/10000 (78.34%)

Epoch: 175
Loss: 0.645 | Acc: 82.812% (53/64)
Loss: 0.649 | Acc: 84.236% (5445/6464)
Loss: 0.643 | Acc: 84.593% (10882/12864)
Loss: 0.647 | Acc: 84.422% (16263/19264)
Loss: 0.658 | Acc: 84.130% (21591/25664)
Loss: 0.653 | Acc: 84.222% (27005/32064)
Loss: 0.657 | Acc: 84.203% (32388/38464)
Loss: 0.663 | Acc: 84.036% (37702/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7868, Accuracy: 8098/10000 (80.98%)

Epoch: 176
Loss: 0.671 | Acc: 85.938% (55/64)
Loss: 0.650 | Acc: 84.839% (5484/6464)
Loss: 0.652 | Acc: 84.608% (10884/12864)
Loss: 0.656 | Acc: 84.323% (16244/19264)
Loss: 0.663 | Acc: 84.091% (21581/25664)
Loss: 0.663 | Acc: 84.113% (26970/32064)
Loss: 0.659 | Acc: 84.193% (32384/38464)
Loss: 0.658 | Acc: 84.170% (37762/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0137, Accuracy: 7281/10000 (72.81%)

Epoch: 177
Loss: 0.619 | Acc: 84.375% (54/64)
Loss: 0.657 | Acc: 84.421% (5457/6464)
Loss: 0.635 | Acc: 85.020% (10937/12864)
Loss: 0.637 | Acc: 84.982% (16371/19264)
Loss: 0.641 | Acc: 84.737% (21747/25664)
Loss: 0.643 | Acc: 84.671% (27149/32064)
Loss: 0.648 | Acc: 84.570% (32529/38464)
Loss: 0.645 | Acc: 84.694% (37997/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9899, Accuracy: 7334/10000 (73.34%)

Epoch: 178
Loss: 0.486 | Acc: 87.500% (56/64)
Loss: 0.607 | Acc: 85.396% (5520/6464)
Loss: 0.619 | Acc: 85.331% (10977/12864)
Loss: 0.624 | Acc: 85.091% (16392/19264)
Loss: 0.625 | Acc: 85.111% (21843/25664)
Loss: 0.630 | Acc: 85.014% (27259/32064)
Loss: 0.632 | Acc: 84.913% (32661/38464)
Loss: 0.632 | Acc: 84.919% (38098/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0734, Accuracy: 7060/10000 (70.60%)

Epoch: 179
Loss: 0.554 | Acc: 85.938% (55/64)
Loss: 0.628 | Acc: 85.334% (5516/6464)
Loss: 0.622 | Acc: 85.362% (10981/12864)
Loss: 0.613 | Acc: 85.662% (16502/19264)
Loss: 0.614 | Acc: 85.509% (21945/25664)
Loss: 0.617 | Acc: 85.473% (27406/32064)
Loss: 0.614 | Acc: 85.576% (32916/38464)
Loss: 0.614 | Acc: 85.614% (38410/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8165, Accuracy: 8039/10000 (80.39%)

Epoch: 180
Loss: 0.567 | Acc: 81.250% (52/64)
Loss: 0.607 | Acc: 85.736% (5542/6464)
Loss: 0.619 | Acc: 85.253% (10967/12864)
Loss: 0.608 | Acc: 85.626% (16495/19264)
Loss: 0.602 | Acc: 85.875% (22039/25664)
Loss: 0.606 | Acc: 85.753% (27496/32064)
Loss: 0.608 | Acc: 85.735% (32977/38464)
Loss: 0.606 | Acc: 85.755% (38473/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0214, Accuracy: 7287/10000 (72.87%)

Epoch: 181
Loss: 0.631 | Acc: 87.500% (56/64)
Loss: 0.592 | Acc: 85.814% (5547/6464)
Loss: 0.577 | Acc: 86.427% (11118/12864)
Loss: 0.583 | Acc: 86.337% (16632/19264)
Loss: 0.588 | Acc: 86.261% (22138/25664)
Loss: 0.586 | Acc: 86.359% (27690/32064)
Loss: 0.591 | Acc: 86.317% (33201/38464)
Loss: 0.592 | Acc: 86.263% (38701/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8642, Accuracy: 7834/10000 (78.34%)

Epoch: 182
Loss: 0.699 | Acc: 81.250% (52/64)
Loss: 0.560 | Acc: 86.928% (5619/6464)
Loss: 0.549 | Acc: 87.220% (11220/12864)
Loss: 0.560 | Acc: 86.976% (16755/19264)
Loss: 0.565 | Acc: 86.869% (22294/25664)
Loss: 0.570 | Acc: 86.723% (27807/32064)
Loss: 0.570 | Acc: 86.725% (33358/38464)
Loss: 0.571 | Acc: 86.706% (38900/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8169, Accuracy: 8022/10000 (80.22%)

Epoch: 183
Loss: 0.518 | Acc: 90.625% (58/64)
Loss: 0.537 | Acc: 87.423% (5651/6464)
Loss: 0.551 | Acc: 87.220% (11220/12864)
Loss: 0.561 | Acc: 87.048% (16769/19264)
Loss: 0.559 | Acc: 87.087% (22350/25664)
Loss: 0.556 | Acc: 87.185% (27955/32064)
Loss: 0.557 | Acc: 87.066% (33489/38464)
Loss: 0.558 | Acc: 87.065% (39061/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9793, Accuracy: 7535/10000 (75.35%)

Epoch: 184
Loss: 0.703 | Acc: 82.812% (53/64)
Loss: 0.524 | Acc: 87.778% (5674/6464)
Loss: 0.540 | Acc: 87.212% (11219/12864)
Loss: 0.544 | Acc: 87.220% (16802/19264)
Loss: 0.541 | Acc: 87.473% (22449/25664)
Loss: 0.539 | Acc: 87.472% (28047/32064)
Loss: 0.540 | Acc: 87.440% (33633/38464)
Loss: 0.539 | Acc: 87.520% (39265/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7438, Accuracy: 8258/10000 (82.58%)

Epoch: 185
Loss: 0.468 | Acc: 90.625% (58/64)
Loss: 0.507 | Acc: 88.366% (5712/6464)
Loss: 0.500 | Acc: 88.557% (11392/12864)
Loss: 0.506 | Acc: 88.491% (17047/19264)
Loss: 0.515 | Acc: 88.233% (22644/25664)
Loss: 0.515 | Acc: 88.230% (28290/32064)
Loss: 0.515 | Acc: 88.225% (33935/38464)
Loss: 0.518 | Acc: 88.160% (39552/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7595, Accuracy: 8245/10000 (82.45%)

Epoch: 186
Loss: 0.247 | Acc: 95.312% (61/64)
Loss: 0.489 | Acc: 88.567% (5725/6464)
Loss: 0.494 | Acc: 88.619% (11400/12864)
Loss: 0.492 | Acc: 88.694% (17086/19264)
Loss: 0.498 | Acc: 88.505% (22714/25664)
Loss: 0.502 | Acc: 88.408% (28347/32064)
Loss: 0.501 | Acc: 88.470% (34029/38464)
Loss: 0.499 | Acc: 88.552% (39728/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8368, Accuracy: 8058/10000 (80.58%)

Epoch: 187
Loss: 0.271 | Acc: 96.875% (62/64)
Loss: 0.463 | Acc: 89.124% (5761/6464)
Loss: 0.465 | Acc: 89.303% (11488/12864)
Loss: 0.470 | Acc: 89.140% (17172/19264)
Loss: 0.475 | Acc: 89.101% (22867/25664)
Loss: 0.475 | Acc: 89.094% (28567/32064)
Loss: 0.476 | Acc: 89.083% (34265/38464)
Loss: 0.477 | Acc: 89.056% (39954/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8113, Accuracy: 8170/10000 (81.70%)

Epoch: 188
Loss: 0.567 | Acc: 87.500% (56/64)
Loss: 0.453 | Acc: 89.434% (5781/6464)
Loss: 0.446 | Acc: 89.646% (11532/12864)
Loss: 0.448 | Acc: 89.701% (17280/19264)
Loss: 0.447 | Acc: 89.690% (23018/25664)
Loss: 0.450 | Acc: 89.674% (28753/32064)
Loss: 0.450 | Acc: 89.720% (34510/38464)
Loss: 0.451 | Acc: 89.675% (40232/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7805, Accuracy: 8233/10000 (82.33%)

Epoch: 189
Loss: 0.149 | Acc: 98.438% (63/64)
Loss: 0.393 | Acc: 90.981% (5881/6464)
Loss: 0.406 | Acc: 90.524% (11645/12864)
Loss: 0.412 | Acc: 90.464% (17427/19264)
Loss: 0.418 | Acc: 90.383% (23196/25664)
Loss: 0.418 | Acc: 90.347% (28969/32064)
Loss: 0.421 | Acc: 90.258% (34717/38464)
Loss: 0.424 | Acc: 90.190% (40463/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8372, Accuracy: 8185/10000 (81.85%)

Epoch: 190
Loss: 0.561 | Acc: 84.375% (54/64)
Loss: 0.388 | Acc: 90.811% (5870/6464)
Loss: 0.382 | Acc: 91.068% (11715/12864)
Loss: 0.389 | Acc: 90.838% (17499/19264)
Loss: 0.391 | Acc: 90.890% (23326/25664)
Loss: 0.388 | Acc: 91.009% (29181/32064)
Loss: 0.391 | Acc: 90.992% (34999/38464)
Loss: 0.391 | Acc: 90.959% (40808/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8468, Accuracy: 8148/10000 (81.48%)

Epoch: 191
Loss: 0.437 | Acc: 87.500% (56/64)
Loss: 0.353 | Acc: 91.940% (5943/6464)
Loss: 0.353 | Acc: 91.861% (11817/12864)
Loss: 0.361 | Acc: 91.539% (17634/19264)
Loss: 0.361 | Acc: 91.467% (23474/25664)
Loss: 0.359 | Acc: 91.520% (29345/32064)
Loss: 0.364 | Acc: 91.348% (35136/38464)
Loss: 0.363 | Acc: 91.405% (41008/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8280, Accuracy: 8244/10000 (82.44%)

Epoch: 192
Loss: 0.136 | Acc: 95.312% (61/64)
Loss: 0.326 | Acc: 91.770% (5932/6464)
Loss: 0.324 | Acc: 91.954% (11829/12864)
Loss: 0.324 | Acc: 92.032% (17729/19264)
Loss: 0.326 | Acc: 92.055% (23625/25664)
Loss: 0.330 | Acc: 92.060% (29518/32064)
Loss: 0.330 | Acc: 92.032% (35399/38464)
Loss: 0.334 | Acc: 91.947% (41251/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8494, Accuracy: 8296/10000 (82.96%)

Epoch: 193
Loss: 0.240 | Acc: 93.750% (60/64)
Loss: 0.317 | Acc: 92.342% (5969/6464)
Loss: 0.307 | Acc: 92.491% (11898/12864)
Loss: 0.304 | Acc: 92.603% (17839/19264)
Loss: 0.306 | Acc: 92.441% (23724/25664)
Loss: 0.303 | Acc: 92.562% (29679/32064)
Loss: 0.300 | Acc: 92.648% (35636/38464)
Loss: 0.300 | Acc: 92.676% (41578/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9384, Accuracy: 8051/10000 (80.51%)

Epoch: 194
Loss: 0.259 | Acc: 93.750% (60/64)
Loss: 0.271 | Acc: 93.410% (6038/6464)
Loss: 0.274 | Acc: 93.229% (11993/12864)
Loss: 0.272 | Acc: 93.314% (17976/19264)
Loss: 0.270 | Acc: 93.294% (23943/25664)
Loss: 0.271 | Acc: 93.307% (29918/32064)
Loss: 0.272 | Acc: 93.298% (35886/38464)
Loss: 0.271 | Acc: 93.333% (41873/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8852, Accuracy: 8275/10000 (82.75%)

Epoch: 195
Loss: 0.328 | Acc: 93.750% (60/64)
Loss: 0.259 | Acc: 93.533% (6046/6464)
Loss: 0.289 | Acc: 92.926% (11954/12864)
Loss: 0.321 | Acc: 92.136% (17749/19264)
Loss: 0.341 | Acc: 91.712% (23537/25664)
Loss: 0.362 | Acc: 91.249% (29258/32064)
Loss: 0.383 | Acc: 90.778% (34917/38464)
Loss: 0.400 | Acc: 90.440% (40575/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7926, Accuracy: 8129/10000 (81.29%)

Epoch: 196
Loss: 0.819 | Acc: 78.125% (50/64)
Loss: 0.514 | Acc: 88.011% (5689/6464)
Loss: 0.532 | Acc: 87.570% (11265/12864)
Loss: 0.548 | Acc: 87.240% (16806/19264)
Loss: 0.554 | Acc: 87.040% (22338/25664)
Loss: 0.555 | Acc: 87.023% (27903/32064)
Loss: 0.564 | Acc: 86.691% (33345/38464)
Loss: 0.569 | Acc: 86.591% (38848/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8040, Accuracy: 8084/10000 (80.84%)

Epoch: 197
Loss: 0.462 | Acc: 89.062% (57/64)
Loss: 0.612 | Acc: 85.025% (5496/6464)
Loss: 0.609 | Acc: 85.300% (10973/12864)
Loss: 0.611 | Acc: 85.356% (16443/19264)
Loss: 0.619 | Acc: 85.037% (21824/25664)
Loss: 0.624 | Acc: 84.827% (27199/32064)
Loss: 0.624 | Acc: 84.887% (32651/38464)
Loss: 0.629 | Acc: 84.870% (38076/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8075, Accuracy: 8035/10000 (80.35%)
torch.Size([100, 10])
Test set: Average loss: 0.8075, Accuracy: 8035/10000 (80.35%)

Epoch: 198
Loss: 0.717 | Acc: 81.250% (52/64)
Loss: 0.637 | Acc: 84.793% (5481/6464)
Loss: 0.641 | Acc: 84.663% (10891/12864)
Loss: 0.638 | Acc: 84.723% (16321/19264)
Loss: 0.640 | Acc: 84.531% (21694/25664)
Loss: 0.641 | Acc: 84.500% (27094/32064)
Loss: 0.643 | Acc: 84.458% (32486/38464)
Loss: 0.642 | Acc: 84.518% (37918/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8063, Accuracy: 8069/10000 (80.69%)
torch.Size([100, 10])
Test set: Average loss: 0.8063, Accuracy: 8069/10000 (80.69%)

Epoch: 199
Loss: 0.298 | Acc: 93.750% (60/64)
Loss: 0.650 | Acc: 84.452% (5459/6464)
Loss: 0.644 | Acc: 84.655% (10890/12864)
Loss: 0.650 | Acc: 84.406% (16260/19264)
Loss: 0.649 | Acc: 84.352% (21648/25664)
Loss: 0.648 | Acc: 84.378% (27055/32064)
Loss: 0.642 | Acc: 84.549% (32521/38464)
Loss: 0.642 | Acc: 84.618% (37963/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8063, Accuracy: 8066/10000 (80.66%)
torch.Size([100, 10])
Test set: Average loss: 0.8063, Accuracy: 8066/10000 (80.66%)
8322
10000
-0.746067464351654
