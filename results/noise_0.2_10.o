==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.403 | Acc: 12.500% (8/64)
Loss: 2.902 | Acc: 14.465% (935/6464)
Loss: 2.532 | Acc: 16.775% (2158/12864)
Loss: 2.392 | Acc: 18.511% (3566/19264)
Loss: 2.309 | Acc: 20.051% (5146/25664)
Loss: 2.254 | Acc: 21.220% (6804/32064)
Loss: 2.216 | Acc: 22.252% (8559/38464)
Loss: 2.181 | Acc: 23.299% (10453/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1082, Accuracy: 2562/10000 (25.62%)

Epoch: 1
Loss: 2.230 | Acc: 20.312% (13/64)
Loss: 1.923 | Acc: 32.256% (2085/6464)
Loss: 1.927 | Acc: 32.128% (4133/12864)
Loss: 1.918 | Acc: 32.610% (6282/19264)
Loss: 1.910 | Acc: 33.311% (8549/25664)
Loss: 1.904 | Acc: 33.804% (10839/32064)
Loss: 1.894 | Acc: 34.242% (13171/38464)
Loss: 1.887 | Acc: 34.674% (15556/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9290, Accuracy: 3502/10000 (35.02%)

Epoch: 2
Loss: 1.658 | Acc: 48.438% (31/64)
Loss: 1.819 | Acc: 38.676% (2500/6464)
Loss: 1.814 | Acc: 38.363% (4935/12864)
Loss: 1.803 | Acc: 38.870% (7488/19264)
Loss: 1.796 | Acc: 39.242% (10071/25664)
Loss: 1.788 | Acc: 39.552% (12682/32064)
Loss: 1.785 | Acc: 39.848% (15327/38464)
Loss: 1.782 | Acc: 39.889% (17896/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8184, Accuracy: 3891/10000 (38.91%)

Epoch: 3
Loss: 2.090 | Acc: 29.688% (19/64)
Loss: 1.724 | Acc: 42.450% (2744/6464)
Loss: 1.741 | Acc: 42.118% (5418/12864)
Loss: 1.722 | Acc: 42.956% (8275/19264)
Loss: 1.718 | Acc: 43.329% (11120/25664)
Loss: 1.713 | Acc: 43.616% (13985/32064)
Loss: 1.704 | Acc: 44.000% (16924/38464)
Loss: 1.695 | Acc: 44.399% (19919/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9220, Accuracy: 3766/10000 (37.66%)

Epoch: 4
Loss: 1.778 | Acc: 40.625% (26/64)
Loss: 1.621 | Acc: 48.824% (3156/6464)
Loss: 1.622 | Acc: 48.492% (6238/12864)
Loss: 1.616 | Acc: 48.718% (9385/19264)
Loss: 1.607 | Acc: 48.948% (12562/25664)
Loss: 1.602 | Acc: 49.139% (15756/32064)
Loss: 1.596 | Acc: 49.415% (19007/38464)
Loss: 1.589 | Acc: 49.764% (22326/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6315, Accuracy: 4771/10000 (47.71%)

Epoch: 5
Loss: 1.848 | Acc: 42.188% (27/64)
Loss: 1.526 | Acc: 52.614% (3401/6464)
Loss: 1.539 | Acc: 52.021% (6692/12864)
Loss: 1.530 | Acc: 52.507% (10115/19264)
Loss: 1.527 | Acc: 52.657% (13514/25664)
Loss: 1.516 | Acc: 53.197% (17057/32064)
Loss: 1.516 | Acc: 53.216% (20469/38464)
Loss: 1.512 | Acc: 53.361% (23940/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9393, Accuracy: 4040/10000 (40.40%)

Epoch: 6
Loss: 1.476 | Acc: 50.000% (32/64)
Loss: 1.479 | Acc: 55.322% (3576/6464)
Loss: 1.478 | Acc: 54.928% (7066/12864)
Loss: 1.475 | Acc: 55.129% (10620/19264)
Loss: 1.465 | Acc: 55.397% (14217/25664)
Loss: 1.459 | Acc: 55.664% (17848/32064)
Loss: 1.458 | Acc: 55.787% (21458/38464)
Loss: 1.457 | Acc: 55.911% (25084/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0279, Accuracy: 3694/10000 (36.94%)

Epoch: 7
Loss: 1.570 | Acc: 43.750% (28/64)
Loss: 1.439 | Acc: 57.379% (3709/6464)
Loss: 1.423 | Acc: 57.494% (7396/12864)
Loss: 1.423 | Acc: 57.745% (11124/19264)
Loss: 1.417 | Acc: 58.128% (14918/25664)
Loss: 1.412 | Acc: 58.280% (18687/32064)
Loss: 1.411 | Acc: 58.387% (22458/38464)
Loss: 1.405 | Acc: 58.570% (26277/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4902, Accuracy: 5590/10000 (55.90%)

Epoch: 8
Loss: 1.380 | Acc: 56.250% (36/64)
Loss: 1.390 | Acc: 58.911% (3808/6464)
Loss: 1.379 | Acc: 59.616% (7669/12864)
Loss: 1.373 | Acc: 59.702% (11501/19264)
Loss: 1.372 | Acc: 59.870% (15365/25664)
Loss: 1.365 | Acc: 60.198% (19302/32064)
Loss: 1.364 | Acc: 60.264% (23180/38464)
Loss: 1.360 | Acc: 60.436% (27114/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5612, Accuracy: 5465/10000 (54.65%)

Epoch: 9
Loss: 1.516 | Acc: 50.000% (32/64)
Loss: 1.304 | Acc: 62.856% (4063/6464)
Loss: 1.321 | Acc: 62.438% (8032/12864)
Loss: 1.331 | Acc: 61.919% (11928/19264)
Loss: 1.328 | Acc: 61.939% (15896/25664)
Loss: 1.329 | Acc: 61.960% (19867/32064)
Loss: 1.328 | Acc: 62.011% (23852/38464)
Loss: 1.322 | Acc: 62.270% (27937/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5067, Accuracy: 5417/10000 (54.17%)

Epoch: 10
Loss: 1.135 | Acc: 68.750% (44/64)
Loss: 1.292 | Acc: 63.877% (4129/6464)
Loss: 1.296 | Acc: 63.495% (8168/12864)
Loss: 1.297 | Acc: 63.533% (12239/19264)
Loss: 1.291 | Acc: 63.634% (16331/25664)
Loss: 1.294 | Acc: 63.626% (20401/32064)
Loss: 1.297 | Acc: 63.543% (24441/38464)
Loss: 1.295 | Acc: 63.557% (28514/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7259, Accuracy: 4916/10000 (49.16%)

Epoch: 11
Loss: 1.371 | Acc: 62.500% (40/64)
Loss: 1.285 | Acc: 63.397% (4098/6464)
Loss: 1.284 | Acc: 63.635% (8186/12864)
Loss: 1.278 | Acc: 64.057% (12340/19264)
Loss: 1.283 | Acc: 63.844% (16385/25664)
Loss: 1.282 | Acc: 64.028% (20530/32064)
Loss: 1.276 | Acc: 64.117% (24662/38464)
Loss: 1.276 | Acc: 64.123% (28768/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4700, Accuracy: 5725/10000 (57.25%)

Epoch: 12
Loss: 1.279 | Acc: 65.625% (42/64)
Loss: 1.248 | Acc: 64.944% (4198/6464)
Loss: 1.253 | Acc: 65.462% (8421/12864)
Loss: 1.253 | Acc: 65.324% (12584/19264)
Loss: 1.254 | Acc: 65.344% (16770/25664)
Loss: 1.257 | Acc: 65.235% (20917/32064)
Loss: 1.256 | Acc: 65.264% (25103/38464)
Loss: 1.257 | Acc: 65.230% (29265/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4385, Accuracy: 5819/10000 (58.19%)

Epoch: 13
Loss: 1.415 | Acc: 60.938% (39/64)
Loss: 1.235 | Acc: 66.445% (4295/6464)
Loss: 1.239 | Acc: 66.006% (8491/12864)
Loss: 1.235 | Acc: 66.154% (12744/19264)
Loss: 1.240 | Acc: 66.015% (16942/25664)
Loss: 1.237 | Acc: 66.211% (21230/32064)
Loss: 1.239 | Acc: 66.070% (25413/38464)
Loss: 1.239 | Acc: 66.104% (29657/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3988, Accuracy: 6011/10000 (60.11%)

Epoch: 14
Loss: 1.282 | Acc: 62.500% (40/64)
Loss: 1.245 | Acc: 65.733% (4249/6464)
Loss: 1.231 | Acc: 66.068% (8499/12864)
Loss: 1.231 | Acc: 66.113% (12736/19264)
Loss: 1.230 | Acc: 66.326% (17022/25664)
Loss: 1.228 | Acc: 66.473% (21314/32064)
Loss: 1.226 | Acc: 66.496% (25577/38464)
Loss: 1.228 | Acc: 66.503% (29836/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8292, Accuracy: 4346/10000 (43.46%)

Epoch: 15
Loss: 1.492 | Acc: 56.250% (36/64)
Loss: 1.221 | Acc: 66.940% (4327/6464)
Loss: 1.216 | Acc: 67.289% (8656/12864)
Loss: 1.219 | Acc: 67.042% (12915/19264)
Loss: 1.215 | Acc: 67.254% (17260/25664)
Loss: 1.209 | Acc: 67.365% (21600/32064)
Loss: 1.213 | Acc: 67.216% (25854/38464)
Loss: 1.212 | Acc: 67.237% (30165/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3800, Accuracy: 6122/10000 (61.22%)

Epoch: 16
Loss: 1.451 | Acc: 59.375% (38/64)
Loss: 1.195 | Acc: 67.234% (4346/6464)
Loss: 1.189 | Acc: 67.778% (8719/12864)
Loss: 1.195 | Acc: 67.701% (13042/19264)
Loss: 1.202 | Acc: 67.480% (17318/25664)
Loss: 1.199 | Acc: 67.652% (21692/32064)
Loss: 1.203 | Acc: 67.606% (26004/38464)
Loss: 1.196 | Acc: 67.814% (30424/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4282, Accuracy: 5978/10000 (59.78%)

Epoch: 17
Loss: 1.181 | Acc: 57.812% (37/64)
Loss: 1.180 | Acc: 68.750% (4444/6464)
Loss: 1.192 | Acc: 68.330% (8790/12864)
Loss: 1.192 | Acc: 68.200% (13138/19264)
Loss: 1.187 | Acc: 68.372% (17547/25664)
Loss: 1.185 | Acc: 68.451% (21948/32064)
Loss: 1.184 | Acc: 68.464% (26334/38464)
Loss: 1.184 | Acc: 68.411% (30692/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4414, Accuracy: 5998/10000 (59.98%)

Epoch: 18
Loss: 1.188 | Acc: 67.188% (43/64)
Loss: 1.140 | Acc: 69.261% (4477/6464)
Loss: 1.148 | Acc: 69.248% (8908/12864)
Loss: 1.164 | Acc: 68.963% (13285/19264)
Loss: 1.167 | Acc: 69.085% (17730/25664)
Loss: 1.166 | Acc: 69.031% (22134/32064)
Loss: 1.173 | Acc: 68.810% (26467/38464)
Loss: 1.171 | Acc: 68.853% (30890/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4460, Accuracy: 5867/10000 (58.67%)

Epoch: 19
Loss: 1.669 | Acc: 53.125% (34/64)
Loss: 1.157 | Acc: 69.415% (4487/6464)
Loss: 1.160 | Acc: 69.279% (8912/12864)
Loss: 1.152 | Acc: 69.440% (13377/19264)
Loss: 1.149 | Acc: 69.568% (17854/25664)
Loss: 1.154 | Acc: 69.433% (22263/32064)
Loss: 1.157 | Acc: 69.353% (26676/38464)
Loss: 1.159 | Acc: 69.301% (31091/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3883, Accuracy: 6126/10000 (61.26%)

Epoch: 20
Loss: 1.131 | Acc: 68.750% (44/64)
Loss: 1.123 | Acc: 70.699% (4570/6464)
Loss: 1.130 | Acc: 70.367% (9052/12864)
Loss: 1.134 | Acc: 70.126% (13509/19264)
Loss: 1.137 | Acc: 69.938% (17949/25664)
Loss: 1.143 | Acc: 69.879% (22406/32064)
Loss: 1.144 | Acc: 69.930% (26898/38464)
Loss: 1.145 | Acc: 69.914% (31366/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7901, Accuracy: 4755/10000 (47.55%)

Epoch: 21
Loss: 1.005 | Acc: 76.562% (49/64)
Loss: 1.130 | Acc: 69.740% (4508/6464)
Loss: 1.127 | Acc: 70.134% (9022/12864)
Loss: 1.124 | Acc: 70.344% (13551/19264)
Loss: 1.133 | Acc: 70.164% (18007/25664)
Loss: 1.132 | Acc: 70.128% (22486/32064)
Loss: 1.136 | Acc: 69.990% (26921/38464)
Loss: 1.135 | Acc: 70.096% (31448/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3243, Accuracy: 6330/10000 (63.30%)

Epoch: 22
Loss: 1.020 | Acc: 75.000% (48/64)
Loss: 1.123 | Acc: 70.792% (4576/6464)
Loss: 1.133 | Acc: 70.235% (9035/12864)
Loss: 1.129 | Acc: 70.333% (13549/19264)
Loss: 1.130 | Acc: 70.371% (18060/25664)
Loss: 1.123 | Acc: 70.603% (22638/32064)
Loss: 1.123 | Acc: 70.609% (27159/38464)
Loss: 1.121 | Acc: 70.700% (31719/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4535, Accuracy: 5823/10000 (58.23%)

Epoch: 23
Loss: 1.067 | Acc: 71.875% (46/64)
Loss: 1.092 | Acc: 71.380% (4614/6464)
Loss: 1.103 | Acc: 71.175% (9156/12864)
Loss: 1.107 | Acc: 71.200% (13716/19264)
Loss: 1.110 | Acc: 71.174% (18266/25664)
Loss: 1.111 | Acc: 71.211% (22833/32064)
Loss: 1.107 | Acc: 71.267% (27412/38464)
Loss: 1.108 | Acc: 71.271% (31975/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2957, Accuracy: 6418/10000 (64.18%)

Epoch: 24
Loss: 1.272 | Acc: 65.625% (42/64)
Loss: 1.100 | Acc: 71.442% (4618/6464)
Loss: 1.113 | Acc: 71.035% (9138/12864)
Loss: 1.102 | Acc: 71.408% (13756/19264)
Loss: 1.109 | Acc: 71.404% (18325/25664)
Loss: 1.104 | Acc: 71.470% (22916/32064)
Loss: 1.102 | Acc: 71.519% (27509/38464)
Loss: 1.102 | Acc: 71.550% (32100/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2789, Accuracy: 6605/10000 (66.05%)

Epoch: 25
Loss: 1.198 | Acc: 68.750% (44/64)
Loss: 1.071 | Acc: 72.525% (4688/6464)
Loss: 1.082 | Acc: 72.233% (9292/12864)
Loss: 1.083 | Acc: 72.244% (13917/19264)
Loss: 1.080 | Acc: 72.276% (18549/25664)
Loss: 1.086 | Acc: 72.134% (23129/32064)
Loss: 1.089 | Acc: 72.052% (27714/38464)
Loss: 1.089 | Acc: 72.038% (32319/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3471, Accuracy: 6281/10000 (62.81%)

Epoch: 26
Loss: 0.999 | Acc: 75.000% (48/64)
Loss: 1.091 | Acc: 72.277% (4672/6464)
Loss: 1.085 | Acc: 72.287% (9299/12864)
Loss: 1.078 | Acc: 72.555% (13977/19264)
Loss: 1.084 | Acc: 72.421% (18586/25664)
Loss: 1.087 | Acc: 72.374% (23206/32064)
Loss: 1.078 | Acc: 72.554% (27907/38464)
Loss: 1.075 | Acc: 72.640% (32589/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2514, Accuracy: 6711/10000 (67.11%)

Epoch: 27
Loss: 1.266 | Acc: 64.062% (41/64)
Loss: 1.091 | Acc: 71.658% (4632/6464)
Loss: 1.062 | Acc: 72.800% (9365/12864)
Loss: 1.065 | Acc: 72.586% (13983/19264)
Loss: 1.065 | Acc: 72.662% (18648/25664)
Loss: 1.062 | Acc: 72.882% (23369/32064)
Loss: 1.059 | Acc: 72.899% (28040/38464)
Loss: 1.060 | Acc: 72.838% (32678/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4767, Accuracy: 5980/10000 (59.80%)

Epoch: 28
Loss: 1.153 | Acc: 64.062% (41/64)
Loss: 1.055 | Acc: 73.066% (4723/6464)
Loss: 1.062 | Acc: 73.095% (9403/12864)
Loss: 1.046 | Acc: 73.614% (14181/19264)
Loss: 1.048 | Acc: 73.480% (18858/25664)
Loss: 1.044 | Acc: 73.584% (23594/32064)
Loss: 1.049 | Acc: 73.521% (28279/38464)
Loss: 1.050 | Acc: 73.511% (32980/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5140, Accuracy: 5614/10000 (56.14%)

Epoch: 29
Loss: 1.049 | Acc: 75.000% (48/64)
Loss: 1.014 | Acc: 74.783% (4834/6464)
Loss: 1.027 | Acc: 74.238% (9550/12864)
Loss: 1.017 | Acc: 74.481% (14348/19264)
Loss: 1.025 | Acc: 74.303% (19069/25664)
Loss: 1.028 | Acc: 74.083% (23754/32064)
Loss: 1.032 | Acc: 74.035% (28477/38464)
Loss: 1.027 | Acc: 74.137% (33261/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2496, Accuracy: 6721/10000 (67.21%)

Epoch: 30
Loss: 1.304 | Acc: 64.062% (41/64)
Loss: 0.994 | Acc: 75.139% (4857/6464)
Loss: 1.010 | Acc: 74.705% (9610/12864)
Loss: 1.010 | Acc: 74.673% (14385/19264)
Loss: 1.009 | Acc: 74.630% (19153/25664)
Loss: 1.017 | Acc: 74.423% (23863/32064)
Loss: 1.020 | Acc: 74.311% (28583/38464)
Loss: 1.020 | Acc: 74.325% (33345/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2056, Accuracy: 6933/10000 (69.33%)

Epoch: 31
Loss: 0.659 | Acc: 81.250% (52/64)
Loss: 0.980 | Acc: 75.294% (4867/6464)
Loss: 0.995 | Acc: 74.907% (9636/12864)
Loss: 0.996 | Acc: 75.042% (14456/19264)
Loss: 0.997 | Acc: 75.023% (19254/25664)
Loss: 1.001 | Acc: 74.910% (24019/32064)
Loss: 0.998 | Acc: 75.000% (28848/38464)
Loss: 1.002 | Acc: 74.913% (33609/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1762, Accuracy: 7067/10000 (70.67%)

Epoch: 32
Loss: 0.916 | Acc: 75.000% (48/64)
Loss: 0.973 | Acc: 75.959% (4910/6464)
Loss: 0.979 | Acc: 75.637% (9730/12864)
Loss: 0.987 | Acc: 75.483% (14541/19264)
Loss: 0.986 | Acc: 75.409% (19353/25664)
Loss: 0.985 | Acc: 75.533% (24219/32064)
Loss: 0.986 | Acc: 75.530% (29052/38464)
Loss: 0.986 | Acc: 75.568% (33903/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3009, Accuracy: 6550/10000 (65.50%)

Epoch: 33
Loss: 0.941 | Acc: 75.000% (48/64)
Loss: 0.928 | Acc: 77.367% (5001/6464)
Loss: 0.948 | Acc: 76.679% (9864/12864)
Loss: 0.944 | Acc: 76.760% (14787/19264)
Loss: 0.954 | Acc: 76.446% (19619/25664)
Loss: 0.954 | Acc: 76.481% (24523/32064)
Loss: 0.961 | Acc: 76.230% (29321/38464)
Loss: 0.964 | Acc: 76.181% (34178/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2306, Accuracy: 6804/10000 (68.04%)

Epoch: 34
Loss: 1.001 | Acc: 76.562% (49/64)
Loss: 0.933 | Acc: 77.058% (4981/6464)
Loss: 0.927 | Acc: 77.449% (9963/12864)
Loss: 0.930 | Acc: 77.134% (14859/19264)
Loss: 0.935 | Acc: 76.960% (19751/25664)
Loss: 0.939 | Acc: 76.806% (24627/32064)
Loss: 0.943 | Acc: 76.700% (29502/38464)
Loss: 0.947 | Acc: 76.638% (34383/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2084, Accuracy: 6928/10000 (69.28%)

Epoch: 35
Loss: 0.860 | Acc: 79.688% (51/64)
Loss: 0.872 | Acc: 78.140% (5051/6464)
Loss: 0.901 | Acc: 77.760% (10003/12864)
Loss: 0.907 | Acc: 77.705% (14969/19264)
Loss: 0.908 | Acc: 77.603% (19916/25664)
Loss: 0.912 | Acc: 77.526% (24858/32064)
Loss: 0.917 | Acc: 77.374% (29761/38464)
Loss: 0.920 | Acc: 77.352% (34703/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3531, Accuracy: 6473/10000 (64.73%)

Epoch: 36
Loss: 0.981 | Acc: 70.312% (45/64)
Loss: 0.899 | Acc: 77.212% (4991/6464)
Loss: 0.902 | Acc: 77.324% (9947/12864)
Loss: 0.899 | Acc: 77.616% (14952/19264)
Loss: 0.901 | Acc: 77.544% (19901/25664)
Loss: 0.906 | Acc: 77.436% (24829/32064)
Loss: 0.906 | Acc: 77.527% (29820/38464)
Loss: 0.907 | Acc: 77.550% (34792/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2237, Accuracy: 6987/10000 (69.87%)

Epoch: 37
Loss: 0.682 | Acc: 84.375% (54/64)
Loss: 0.867 | Acc: 78.589% (5080/6464)
Loss: 0.865 | Acc: 78.809% (10138/12864)
Loss: 0.861 | Acc: 78.862% (15192/19264)
Loss: 0.857 | Acc: 78.908% (20251/25664)
Loss: 0.864 | Acc: 78.714% (25239/32064)
Loss: 0.871 | Acc: 78.546% (30212/38464)
Loss: 0.874 | Acc: 78.475% (35207/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2035, Accuracy: 7059/10000 (70.59%)

Epoch: 38
Loss: 0.865 | Acc: 78.125% (50/64)
Loss: 0.839 | Acc: 79.301% (5126/6464)
Loss: 0.828 | Acc: 79.524% (10230/12864)
Loss: 0.829 | Acc: 79.459% (15307/19264)
Loss: 0.839 | Acc: 79.095% (20299/25664)
Loss: 0.841 | Acc: 79.082% (25357/32064)
Loss: 0.841 | Acc: 79.131% (30437/38464)
Loss: 0.842 | Acc: 79.161% (35515/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2405, Accuracy: 6934/10000 (69.34%)

Epoch: 39
Loss: 0.938 | Acc: 73.438% (47/64)
Loss: 0.787 | Acc: 80.260% (5188/6464)
Loss: 0.789 | Acc: 80.340% (10335/12864)
Loss: 0.794 | Acc: 80.149% (15440/19264)
Loss: 0.797 | Acc: 80.198% (20582/25664)
Loss: 0.804 | Acc: 80.043% (25665/32064)
Loss: 0.807 | Acc: 79.981% (30764/38464)
Loss: 0.813 | Acc: 79.850% (35824/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2152, Accuracy: 7040/10000 (70.40%)

Epoch: 40
Loss: 0.749 | Acc: 76.562% (49/64)
Loss: 0.770 | Acc: 80.724% (5218/6464)
Loss: 0.768 | Acc: 80.799% (10394/12864)
Loss: 0.770 | Acc: 80.845% (15574/19264)
Loss: 0.775 | Acc: 80.763% (20727/25664)
Loss: 0.777 | Acc: 80.676% (25868/32064)
Loss: 0.780 | Acc: 80.501% (30964/38464)
Loss: 0.778 | Acc: 80.532% (36130/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2406, Accuracy: 7109/10000 (71.09%)

Epoch: 41
Loss: 0.877 | Acc: 73.438% (47/64)
Loss: 0.731 | Acc: 81.312% (5256/6464)
Loss: 0.733 | Acc: 81.421% (10474/12864)
Loss: 0.728 | Acc: 81.593% (15718/19264)
Loss: 0.732 | Acc: 81.488% (20913/25664)
Loss: 0.734 | Acc: 81.475% (26124/32064)
Loss: 0.737 | Acc: 81.372% (31299/38464)
Loss: 0.738 | Acc: 81.319% (36483/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2850, Accuracy: 7021/10000 (70.21%)

Epoch: 42
Loss: 0.532 | Acc: 87.500% (56/64)
Loss: 0.690 | Acc: 82.426% (5328/6464)
Loss: 0.691 | Acc: 82.463% (10608/12864)
Loss: 0.690 | Acc: 82.402% (15874/19264)
Loss: 0.694 | Acc: 82.232% (21104/25664)
Loss: 0.695 | Acc: 82.229% (26366/32064)
Loss: 0.694 | Acc: 82.321% (31664/38464)
Loss: 0.690 | Acc: 82.436% (36984/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3043, Accuracy: 7114/10000 (71.14%)

Epoch: 43
Loss: 0.556 | Acc: 87.500% (56/64)
Loss: 0.629 | Acc: 83.756% (5414/6464)
Loss: 0.639 | Acc: 83.652% (10761/12864)
Loss: 0.640 | Acc: 83.586% (16102/19264)
Loss: 0.638 | Acc: 83.662% (21471/25664)
Loss: 0.637 | Acc: 83.642% (26819/32064)
Loss: 0.642 | Acc: 83.504% (32119/38464)
Loss: 0.644 | Acc: 83.488% (37456/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3320, Accuracy: 7006/10000 (70.06%)

Epoch: 44
Loss: 0.435 | Acc: 90.625% (58/64)
Loss: 0.599 | Acc: 84.390% (5455/6464)
Loss: 0.597 | Acc: 84.375% (10854/12864)
Loss: 0.595 | Acc: 84.401% (16259/19264)
Loss: 0.594 | Acc: 84.437% (21670/25664)
Loss: 0.597 | Acc: 84.256% (27016/32064)
Loss: 0.593 | Acc: 84.393% (32461/38464)
Loss: 0.593 | Acc: 84.404% (37867/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3297, Accuracy: 7118/10000 (71.18%)

Epoch: 45
Loss: 0.474 | Acc: 85.938% (55/64)
Loss: 0.538 | Acc: 85.953% (5556/6464)
Loss: 0.546 | Acc: 85.673% (11021/12864)
Loss: 0.557 | Acc: 85.372% (16446/19264)
Loss: 0.564 | Acc: 85.139% (21850/25664)
Loss: 0.567 | Acc: 85.061% (27274/32064)
Loss: 0.567 | Acc: 85.100% (32733/38464)
Loss: 0.570 | Acc: 85.106% (38182/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3050, Accuracy: 7088/10000 (70.88%)

Epoch: 46
Loss: 0.416 | Acc: 89.062% (57/64)
Loss: 0.563 | Acc: 85.164% (5505/6464)
Loss: 0.565 | Acc: 85.308% (10974/12864)
Loss: 0.565 | Acc: 85.076% (16389/19264)
Loss: 0.570 | Acc: 85.018% (21819/25664)
Loss: 0.572 | Acc: 84.949% (27238/32064)
Loss: 0.574 | Acc: 84.859% (32640/38464)
Loss: 0.577 | Acc: 84.756% (38025/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2751, Accuracy: 7130/10000 (71.30%)

Epoch: 47
Loss: 0.214 | Acc: 96.875% (62/64)
Loss: 0.574 | Acc: 84.777% (5480/6464)
Loss: 0.568 | Acc: 84.865% (10917/12864)
Loss: 0.570 | Acc: 84.956% (16366/19264)
Loss: 0.569 | Acc: 84.963% (21805/25664)
Loss: 0.572 | Acc: 84.855% (27208/32064)
Loss: 0.571 | Acc: 84.869% (32644/38464)
Loss: 0.571 | Acc: 84.861% (38072/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2872, Accuracy: 7107/10000 (71.07%)
torch.Size([100, 10])
Test set: Average loss: 1.2872, Accuracy: 7107/10000 (71.07%)

Epoch: 48
Loss: 0.688 | Acc: 85.938% (55/64)
Loss: 0.541 | Acc: 85.675% (5538/6464)
Loss: 0.554 | Acc: 85.386% (10984/12864)
Loss: 0.563 | Acc: 85.076% (16389/19264)
Loss: 0.564 | Acc: 85.100% (21840/25664)
Loss: 0.561 | Acc: 85.180% (27312/32064)
Loss: 0.563 | Acc: 85.171% (32760/38464)
Loss: 0.562 | Acc: 85.226% (38236/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2815, Accuracy: 7135/10000 (71.35%)
torch.Size([100, 10])
Test set: Average loss: 1.2815, Accuracy: 7135/10000 (71.35%)

Epoch: 49
Loss: 0.567 | Acc: 82.812% (53/64)
Loss: 0.571 | Acc: 85.179% (5506/6464)
Loss: 0.572 | Acc: 84.997% (10934/12864)
Loss: 0.574 | Acc: 84.842% (16344/19264)
Loss: 0.564 | Acc: 85.096% (21839/25664)
Loss: 0.565 | Acc: 85.064% (27275/32064)
Loss: 0.560 | Acc: 85.254% (32792/38464)
Loss: 0.560 | Acc: 85.226% (38236/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2841, Accuracy: 7148/10000 (71.48%)
torch.Size([100, 10])
Test set: Average loss: 1.2841, Accuracy: 7148/10000 (71.48%)

Epoch: 50
Loss: 0.405 | Acc: 90.625% (58/64)
Loss: 1.966 | Acc: 30.136% (1948/6464)
Loss: 1.754 | Acc: 41.255% (5307/12864)
Loss: 1.632 | Acc: 47.285% (9109/19264)
Loss: 1.559 | Acc: 50.939% (13073/25664)
Loss: 1.507 | Acc: 53.549% (17170/32064)
Loss: 1.469 | Acc: 55.322% (21279/38464)
Loss: 1.441 | Acc: 56.691% (25434/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8119, Accuracy: 4514/10000 (45.14%)

Epoch: 51
Loss: 1.317 | Acc: 59.375% (38/64)
Loss: 1.233 | Acc: 65.687% (4246/6464)
Loss: 1.224 | Acc: 66.216% (8518/12864)
Loss: 1.229 | Acc: 66.212% (12755/19264)
Loss: 1.226 | Acc: 66.447% (17053/25664)
Loss: 1.223 | Acc: 66.620% (21361/32064)
Loss: 1.217 | Acc: 66.902% (25733/38464)
Loss: 1.213 | Acc: 67.116% (30111/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3616, Accuracy: 6266/10000 (62.66%)

Epoch: 52
Loss: 1.016 | Acc: 71.875% (46/64)
Loss: 1.180 | Acc: 68.673% (4439/6464)
Loss: 1.182 | Acc: 68.431% (8803/12864)
Loss: 1.176 | Acc: 68.527% (13201/19264)
Loss: 1.177 | Acc: 68.419% (17559/25664)
Loss: 1.180 | Acc: 68.426% (21940/32064)
Loss: 1.178 | Acc: 68.503% (26349/38464)
Loss: 1.180 | Acc: 68.442% (30706/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4215, Accuracy: 6096/10000 (60.96%)

Epoch: 53
Loss: 1.418 | Acc: 54.688% (35/64)
Loss: 1.163 | Acc: 68.874% (4452/6464)
Loss: 1.165 | Acc: 68.874% (8860/12864)
Loss: 1.170 | Acc: 68.651% (13225/19264)
Loss: 1.173 | Acc: 68.676% (17625/25664)
Loss: 1.175 | Acc: 68.697% (22027/32064)
Loss: 1.168 | Acc: 68.885% (26496/38464)
Loss: 1.172 | Acc: 68.770% (30853/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5937, Accuracy: 5445/10000 (54.45%)

Epoch: 54
Loss: 1.091 | Acc: 68.750% (44/64)
Loss: 1.156 | Acc: 69.152% (4470/6464)
Loss: 1.168 | Acc: 68.929% (8867/12864)
Loss: 1.166 | Acc: 69.041% (13300/19264)
Loss: 1.161 | Acc: 69.108% (17736/25664)
Loss: 1.162 | Acc: 69.062% (22144/32064)
Loss: 1.165 | Acc: 68.955% (26523/38464)
Loss: 1.164 | Acc: 69.017% (30964/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7908, Accuracy: 4473/10000 (44.73%)

Epoch: 55
Loss: 1.531 | Acc: 56.250% (36/64)
Loss: 1.150 | Acc: 69.508% (4493/6464)
Loss: 1.158 | Acc: 69.279% (8912/12864)
Loss: 1.160 | Acc: 69.363% (13362/19264)
Loss: 1.163 | Acc: 69.264% (17776/25664)
Loss: 1.160 | Acc: 69.380% (22246/32064)
Loss: 1.159 | Acc: 69.374% (26684/38464)
Loss: 1.160 | Acc: 69.365% (31120/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5121, Accuracy: 5656/10000 (56.56%)

Epoch: 56
Loss: 1.427 | Acc: 64.062% (41/64)
Loss: 1.151 | Acc: 69.787% (4511/6464)
Loss: 1.157 | Acc: 69.395% (8927/12864)
Loss: 1.151 | Acc: 69.643% (13416/19264)
Loss: 1.151 | Acc: 69.646% (17874/25664)
Loss: 1.154 | Acc: 69.589% (22313/32064)
Loss: 1.155 | Acc: 69.548% (26751/38464)
Loss: 1.154 | Acc: 69.517% (31188/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5693, Accuracy: 5627/10000 (56.27%)

Epoch: 57
Loss: 1.398 | Acc: 67.188% (43/64)
Loss: 1.138 | Acc: 69.524% (4494/6464)
Loss: 1.148 | Acc: 69.636% (8958/12864)
Loss: 1.152 | Acc: 69.669% (13421/19264)
Loss: 1.151 | Acc: 69.705% (17889/25664)
Loss: 1.147 | Acc: 69.764% (22369/32064)
Loss: 1.151 | Acc: 69.733% (26822/38464)
Loss: 1.147 | Acc: 69.889% (31355/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7541, Accuracy: 4910/10000 (49.10%)

Epoch: 58
Loss: 1.351 | Acc: 62.500% (40/64)
Loss: 1.148 | Acc: 69.895% (4518/6464)
Loss: 1.156 | Acc: 69.706% (8967/12864)
Loss: 1.145 | Acc: 70.011% (13487/19264)
Loss: 1.144 | Acc: 70.028% (17972/25664)
Loss: 1.149 | Acc: 69.848% (22396/32064)
Loss: 1.147 | Acc: 69.891% (26883/38464)
Loss: 1.145 | Acc: 69.949% (31382/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6996, Accuracy: 5160/10000 (51.60%)

Epoch: 59
Loss: 0.882 | Acc: 78.125% (50/64)
Loss: 1.145 | Acc: 70.436% (4553/6464)
Loss: 1.138 | Acc: 70.344% (9049/12864)
Loss: 1.139 | Acc: 70.219% (13527/19264)
Loss: 1.135 | Acc: 70.277% (18036/25664)
Loss: 1.136 | Acc: 70.213% (22513/32064)
Loss: 1.138 | Acc: 70.175% (26992/38464)
Loss: 1.143 | Acc: 70.099% (31449/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3411, Accuracy: 6328/10000 (63.28%)

Epoch: 60
Loss: 1.023 | Acc: 73.438% (47/64)
Loss: 1.131 | Acc: 70.622% (4565/6464)
Loss: 1.126 | Acc: 70.693% (9094/12864)
Loss: 1.139 | Acc: 70.271% (13537/19264)
Loss: 1.140 | Acc: 70.242% (18027/25664)
Loss: 1.139 | Acc: 70.347% (22556/32064)
Loss: 1.137 | Acc: 70.375% (27069/38464)
Loss: 1.138 | Acc: 70.290% (31535/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3446, Accuracy: 6415/10000 (64.15%)

Epoch: 61
Loss: 1.232 | Acc: 70.312% (45/64)
Loss: 1.117 | Acc: 71.179% (4601/6464)
Loss: 1.114 | Acc: 71.292% (9171/12864)
Loss: 1.122 | Acc: 70.972% (13672/19264)
Loss: 1.129 | Acc: 70.698% (18144/25664)
Loss: 1.129 | Acc: 70.578% (22630/32064)
Loss: 1.131 | Acc: 70.546% (27135/38464)
Loss: 1.129 | Acc: 70.584% (31667/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5145, Accuracy: 5794/10000 (57.94%)

Epoch: 62
Loss: 1.316 | Acc: 64.062% (41/64)
Loss: 1.114 | Acc: 71.473% (4620/6464)
Loss: 1.110 | Acc: 71.580% (9208/12864)
Loss: 1.127 | Acc: 70.972% (13672/19264)
Loss: 1.120 | Acc: 71.072% (18240/25664)
Loss: 1.124 | Acc: 71.036% (22777/32064)
Loss: 1.125 | Acc: 70.973% (27299/38464)
Loss: 1.128 | Acc: 70.805% (31766/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6220, Accuracy: 5514/10000 (55.14%)

Epoch: 63
Loss: 0.957 | Acc: 71.875% (46/64)
Loss: 1.106 | Acc: 71.504% (4622/6464)
Loss: 1.109 | Acc: 71.424% (9188/12864)
Loss: 1.103 | Acc: 71.673% (13807/19264)
Loss: 1.109 | Acc: 71.400% (18324/25664)
Loss: 1.110 | Acc: 71.311% (22865/32064)
Loss: 1.114 | Acc: 71.196% (27385/38464)
Loss: 1.118 | Acc: 71.104% (31900/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5541, Accuracy: 5519/10000 (55.19%)

Epoch: 64
Loss: 1.116 | Acc: 70.312% (45/64)
Loss: 1.123 | Acc: 70.869% (4581/6464)
Loss: 1.115 | Acc: 71.090% (9145/12864)
Loss: 1.106 | Acc: 71.387% (13752/19264)
Loss: 1.109 | Acc: 71.368% (18316/25664)
Loss: 1.113 | Acc: 71.286% (22857/32064)
Loss: 1.110 | Acc: 71.376% (27454/38464)
Loss: 1.114 | Acc: 71.197% (31942/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4119, Accuracy: 6004/10000 (60.04%)

Epoch: 65
Loss: 0.961 | Acc: 71.875% (46/64)
Loss: 1.089 | Acc: 72.061% (4658/6464)
Loss: 1.092 | Acc: 71.852% (9243/12864)
Loss: 1.110 | Acc: 71.346% (13744/19264)
Loss: 1.107 | Acc: 71.337% (18308/25664)
Loss: 1.111 | Acc: 71.242% (22843/32064)
Loss: 1.111 | Acc: 71.261% (27410/38464)
Loss: 1.110 | Acc: 71.300% (31988/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4251, Accuracy: 5933/10000 (59.33%)

Epoch: 66
Loss: 0.961 | Acc: 78.125% (50/64)
Loss: 1.053 | Acc: 73.391% (4744/6464)
Loss: 1.082 | Acc: 72.435% (9318/12864)
Loss: 1.091 | Acc: 72.103% (13890/19264)
Loss: 1.098 | Acc: 71.801% (18427/25664)
Loss: 1.100 | Acc: 71.691% (22987/32064)
Loss: 1.102 | Acc: 71.633% (27553/38464)
Loss: 1.101 | Acc: 71.679% (32158/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6845, Accuracy: 5106/10000 (51.06%)

Epoch: 67
Loss: 1.586 | Acc: 57.812% (37/64)
Loss: 1.113 | Acc: 71.426% (4617/6464)
Loss: 1.092 | Acc: 71.945% (9255/12864)
Loss: 1.092 | Acc: 72.109% (13891/19264)
Loss: 1.098 | Acc: 71.941% (18463/25664)
Loss: 1.095 | Acc: 71.925% (23062/32064)
Loss: 1.096 | Acc: 71.909% (27659/38464)
Loss: 1.097 | Acc: 71.806% (32215/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4212, Accuracy: 6035/10000 (60.35%)

Epoch: 68
Loss: 1.036 | Acc: 70.312% (45/64)
Loss: 1.106 | Acc: 71.380% (4614/6464)
Loss: 1.079 | Acc: 72.069% (9271/12864)
Loss: 1.085 | Acc: 71.948% (13860/19264)
Loss: 1.085 | Acc: 72.035% (18487/25664)
Loss: 1.088 | Acc: 72.031% (23096/32064)
Loss: 1.091 | Acc: 71.974% (27684/38464)
Loss: 1.088 | Acc: 72.015% (32309/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5718, Accuracy: 5419/10000 (54.19%)

Epoch: 69
Loss: 1.182 | Acc: 65.625% (42/64)
Loss: 1.044 | Acc: 73.376% (4743/6464)
Loss: 1.057 | Acc: 73.088% (9402/12864)
Loss: 1.070 | Acc: 72.669% (13999/19264)
Loss: 1.077 | Acc: 72.506% (18608/25664)
Loss: 1.077 | Acc: 72.514% (23251/32064)
Loss: 1.074 | Acc: 72.637% (27939/38464)
Loss: 1.075 | Acc: 72.648% (32593/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3243, Accuracy: 6429/10000 (64.29%)

Epoch: 70
Loss: 1.037 | Acc: 75.000% (48/64)
Loss: 1.021 | Acc: 74.180% (4795/6464)
Loss: 1.033 | Acc: 73.577% (9465/12864)
Loss: 1.046 | Acc: 73.412% (14142/19264)
Loss: 1.048 | Acc: 73.473% (18856/25664)
Loss: 1.059 | Acc: 73.172% (23462/32064)
Loss: 1.064 | Acc: 72.933% (28053/38464)
Loss: 1.069 | Acc: 72.811% (32666/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3281, Accuracy: 6365/10000 (63.65%)

Epoch: 71
Loss: 1.112 | Acc: 73.438% (47/64)
Loss: 1.035 | Acc: 73.639% (4760/6464)
Loss: 1.040 | Acc: 73.422% (9445/12864)
Loss: 1.051 | Acc: 73.251% (14111/19264)
Loss: 1.054 | Acc: 73.289% (18809/25664)
Loss: 1.056 | Acc: 73.291% (23500/32064)
Loss: 1.059 | Acc: 73.094% (28115/38464)
Loss: 1.060 | Acc: 73.043% (32770/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8653, Accuracy: 4575/10000 (45.75%)

Epoch: 72
Loss: 1.100 | Acc: 71.875% (46/64)
Loss: 1.040 | Acc: 73.438% (4747/6464)
Loss: 1.049 | Acc: 73.500% (9455/12864)
Loss: 1.059 | Acc: 73.240% (14109/19264)
Loss: 1.057 | Acc: 73.188% (18783/25664)
Loss: 1.056 | Acc: 73.325% (23511/32064)
Loss: 1.053 | Acc: 73.399% (28232/38464)
Loss: 1.056 | Acc: 73.366% (32915/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3531, Accuracy: 6334/10000 (63.34%)

Epoch: 73
Loss: 1.058 | Acc: 76.562% (49/64)
Loss: 1.042 | Acc: 73.639% (4760/6464)
Loss: 1.042 | Acc: 73.943% (9512/12864)
Loss: 1.047 | Acc: 73.692% (14196/19264)
Loss: 1.049 | Acc: 73.695% (18913/25664)
Loss: 1.049 | Acc: 73.690% (23628/32064)
Loss: 1.044 | Acc: 73.786% (28381/38464)
Loss: 1.046 | Acc: 73.765% (33094/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3253, Accuracy: 6452/10000 (64.52%)

Epoch: 74
Loss: 1.097 | Acc: 68.750% (44/64)
Loss: 1.020 | Acc: 74.087% (4789/6464)
Loss: 1.025 | Acc: 74.145% (9538/12864)
Loss: 1.029 | Acc: 74.086% (14272/19264)
Loss: 1.032 | Acc: 73.999% (18991/25664)
Loss: 1.030 | Acc: 74.102% (23760/32064)
Loss: 1.037 | Acc: 73.892% (28422/38464)
Loss: 1.037 | Acc: 73.899% (33154/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5370, Accuracy: 5767/10000 (57.67%)

Epoch: 75
Loss: 1.016 | Acc: 73.438% (47/64)
Loss: 1.015 | Acc: 74.520% (4817/6464)
Loss: 1.019 | Acc: 74.619% (9599/12864)
Loss: 1.022 | Acc: 74.429% (14338/19264)
Loss: 1.020 | Acc: 74.501% (19120/25664)
Loss: 1.018 | Acc: 74.432% (23866/32064)
Loss: 1.022 | Acc: 74.379% (28609/38464)
Loss: 1.022 | Acc: 74.345% (33354/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2395, Accuracy: 6724/10000 (67.24%)

Epoch: 76
Loss: 0.816 | Acc: 82.812% (53/64)
Loss: 0.984 | Acc: 75.758% (4897/6464)
Loss: 0.984 | Acc: 75.816% (9753/12864)
Loss: 0.996 | Acc: 75.452% (14535/19264)
Loss: 1.004 | Acc: 75.164% (19290/25664)
Loss: 1.012 | Acc: 74.832% (23994/32064)
Loss: 1.013 | Acc: 74.860% (28794/38464)
Loss: 1.010 | Acc: 74.909% (33607/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2228, Accuracy: 6798/10000 (67.98%)

Epoch: 77
Loss: 0.896 | Acc: 79.688% (51/64)
Loss: 0.989 | Acc: 75.278% (4866/6464)
Loss: 0.998 | Acc: 75.101% (9661/12864)
Loss: 0.994 | Acc: 75.286% (14503/19264)
Loss: 1.000 | Acc: 75.043% (19259/25664)
Loss: 1.002 | Acc: 75.003% (24049/32064)
Loss: 1.000 | Acc: 75.081% (28879/38464)
Loss: 1.000 | Acc: 75.049% (33670/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2412, Accuracy: 6751/10000 (67.51%)

Epoch: 78
Loss: 0.848 | Acc: 75.000% (48/64)
Loss: 0.968 | Acc: 76.253% (4929/6464)
Loss: 0.980 | Acc: 75.894% (9763/12864)
Loss: 0.990 | Acc: 75.638% (14571/19264)
Loss: 0.992 | Acc: 75.569% (19394/25664)
Loss: 0.992 | Acc: 75.518% (24214/32064)
Loss: 0.987 | Acc: 75.637% (29093/38464)
Loss: 0.989 | Acc: 75.564% (33901/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5344, Accuracy: 5609/10000 (56.09%)

Epoch: 79
Loss: 1.244 | Acc: 65.625% (42/64)
Loss: 0.952 | Acc: 76.887% (4970/6464)
Loss: 0.956 | Acc: 76.539% (9846/12864)
Loss: 0.962 | Acc: 76.329% (14704/19264)
Loss: 0.970 | Acc: 76.165% (19547/25664)
Loss: 0.973 | Acc: 76.017% (24374/32064)
Loss: 0.971 | Acc: 76.076% (29262/38464)
Loss: 0.968 | Acc: 76.197% (34185/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3547, Accuracy: 6225/10000 (62.25%)

Epoch: 80
Loss: 1.217 | Acc: 67.188% (43/64)
Loss: 0.981 | Acc: 75.464% (4878/6464)
Loss: 0.968 | Acc: 75.902% (9764/12864)
Loss: 0.965 | Acc: 76.132% (14666/19264)
Loss: 0.960 | Acc: 76.294% (19580/25664)
Loss: 0.957 | Acc: 76.332% (24475/32064)
Loss: 0.959 | Acc: 76.292% (29345/38464)
Loss: 0.960 | Acc: 76.320% (34240/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1899, Accuracy: 7006/10000 (70.06%)

Epoch: 81
Loss: 0.884 | Acc: 75.000% (48/64)
Loss: 0.928 | Acc: 77.738% (5025/6464)
Loss: 0.940 | Acc: 77.044% (9911/12864)
Loss: 0.942 | Acc: 76.812% (14797/19264)
Loss: 0.948 | Acc: 76.660% (19674/25664)
Loss: 0.945 | Acc: 76.859% (24644/32064)
Loss: 0.943 | Acc: 76.916% (29585/38464)
Loss: 0.947 | Acc: 76.854% (34480/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2289, Accuracy: 6846/10000 (68.46%)

Epoch: 82
Loss: 0.869 | Acc: 75.000% (48/64)
Loss: 0.937 | Acc: 76.825% (4966/6464)
Loss: 0.934 | Acc: 76.951% (9899/12864)
Loss: 0.920 | Acc: 77.549% (14939/19264)
Loss: 0.917 | Acc: 77.673% (19934/25664)
Loss: 0.921 | Acc: 77.464% (24838/32064)
Loss: 0.925 | Acc: 77.457% (29793/38464)
Loss: 0.925 | Acc: 77.488% (34764/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1572, Accuracy: 7139/10000 (71.39%)

Epoch: 83
Loss: 1.101 | Acc: 76.562% (49/64)
Loss: 0.872 | Acc: 79.007% (5107/6464)
Loss: 0.890 | Acc: 78.335% (10077/12864)
Loss: 0.890 | Acc: 78.172% (15059/19264)
Loss: 0.902 | Acc: 77.922% (19998/25664)
Loss: 0.902 | Acc: 77.897% (24977/32064)
Loss: 0.905 | Acc: 77.862% (29949/38464)
Loss: 0.907 | Acc: 77.797% (34903/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2004, Accuracy: 6988/10000 (69.88%)

Epoch: 84
Loss: 0.786 | Acc: 81.250% (52/64)
Loss: 0.874 | Acc: 78.713% (5088/6464)
Loss: 0.884 | Acc: 78.249% (10066/12864)
Loss: 0.891 | Acc: 78.135% (15052/19264)
Loss: 0.895 | Acc: 78.117% (20048/25664)
Loss: 0.886 | Acc: 78.281% (25100/32064)
Loss: 0.885 | Acc: 78.362% (30141/38464)
Loss: 0.887 | Acc: 78.294% (35126/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1444, Accuracy: 7246/10000 (72.46%)

Epoch: 85
Loss: 0.922 | Acc: 78.125% (50/64)
Loss: 0.860 | Acc: 78.775% (5092/6464)
Loss: 0.862 | Acc: 78.832% (10141/12864)
Loss: 0.861 | Acc: 78.950% (15209/19264)
Loss: 0.855 | Acc: 79.091% (20298/25664)
Loss: 0.854 | Acc: 79.170% (25385/32064)
Loss: 0.859 | Acc: 79.110% (30429/38464)
Loss: 0.864 | Acc: 79.046% (35463/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2149, Accuracy: 7034/10000 (70.34%)

Epoch: 86
Loss: 0.882 | Acc: 78.125% (50/64)
Loss: 0.817 | Acc: 79.997% (5171/6464)
Loss: 0.810 | Acc: 80.185% (10315/12864)
Loss: 0.807 | Acc: 80.207% (15451/19264)
Loss: 0.823 | Acc: 79.812% (20483/25664)
Loss: 0.830 | Acc: 79.634% (25534/32064)
Loss: 0.835 | Acc: 79.508% (30582/38464)
Loss: 0.838 | Acc: 79.429% (35635/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1877, Accuracy: 7160/10000 (71.60%)

Epoch: 87
Loss: 0.633 | Acc: 84.375% (54/64)
Loss: 0.809 | Acc: 80.213% (5185/6464)
Loss: 0.788 | Acc: 80.729% (10385/12864)
Loss: 0.805 | Acc: 80.134% (15437/19264)
Loss: 0.811 | Acc: 79.999% (20531/25664)
Loss: 0.813 | Acc: 79.953% (25636/32064)
Loss: 0.812 | Acc: 79.947% (30751/38464)
Loss: 0.807 | Acc: 80.120% (35945/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2344, Accuracy: 7029/10000 (70.29%)

Epoch: 88
Loss: 0.524 | Acc: 84.375% (54/64)
Loss: 0.764 | Acc: 80.879% (5228/6464)
Loss: 0.766 | Acc: 81.017% (10422/12864)
Loss: 0.769 | Acc: 80.871% (15579/19264)
Loss: 0.773 | Acc: 80.767% (20728/25664)
Loss: 0.775 | Acc: 80.773% (25899/32064)
Loss: 0.775 | Acc: 80.795% (31077/38464)
Loss: 0.777 | Acc: 80.748% (36227/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2321, Accuracy: 7120/10000 (71.20%)

Epoch: 89
Loss: 0.542 | Acc: 89.062% (57/64)
Loss: 0.723 | Acc: 81.822% (5289/6464)
Loss: 0.732 | Acc: 81.856% (10530/12864)
Loss: 0.735 | Acc: 81.702% (15739/19264)
Loss: 0.738 | Acc: 81.531% (20924/25664)
Loss: 0.738 | Acc: 81.568% (26154/32064)
Loss: 0.738 | Acc: 81.562% (31372/38464)
Loss: 0.742 | Acc: 81.495% (36562/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2658, Accuracy: 7178/10000 (71.78%)

Epoch: 90
Loss: 0.750 | Acc: 79.688% (51/64)
Loss: 0.679 | Acc: 83.106% (5372/6464)
Loss: 0.693 | Acc: 82.743% (10644/12864)
Loss: 0.692 | Acc: 82.761% (15943/19264)
Loss: 0.688 | Acc: 82.781% (21245/25664)
Loss: 0.694 | Acc: 82.594% (26483/32064)
Loss: 0.699 | Acc: 82.472% (31722/38464)
Loss: 0.698 | Acc: 82.489% (37008/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2636, Accuracy: 7156/10000 (71.56%)

Epoch: 91
Loss: 0.528 | Acc: 84.375% (54/64)
Loss: 0.647 | Acc: 83.168% (5376/6464)
Loss: 0.644 | Acc: 83.287% (10714/12864)
Loss: 0.652 | Acc: 83.197% (16027/19264)
Loss: 0.651 | Acc: 83.366% (21395/25664)
Loss: 0.652 | Acc: 83.336% (26721/32064)
Loss: 0.653 | Acc: 83.377% (32070/38464)
Loss: 0.651 | Acc: 83.345% (37392/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2800, Accuracy: 7188/10000 (71.88%)

Epoch: 92
Loss: 0.666 | Acc: 82.812% (53/64)
Loss: 0.590 | Acc: 84.561% (5466/6464)
Loss: 0.590 | Acc: 84.577% (10880/12864)
Loss: 0.592 | Acc: 84.588% (16295/19264)
Loss: 0.600 | Acc: 84.406% (21662/25664)
Loss: 0.611 | Acc: 84.104% (26967/32064)
Loss: 0.609 | Acc: 84.144% (32365/38464)
Loss: 0.609 | Acc: 84.130% (37744/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3355, Accuracy: 7098/10000 (70.98%)

Epoch: 93
Loss: 0.488 | Acc: 87.500% (56/64)
Loss: 0.544 | Acc: 85.566% (5531/6464)
Loss: 0.542 | Acc: 85.782% (11035/12864)
Loss: 0.542 | Acc: 85.673% (16504/19264)
Loss: 0.549 | Acc: 85.474% (21936/25664)
Loss: 0.548 | Acc: 85.432% (27393/32064)
Loss: 0.550 | Acc: 85.303% (32811/38464)
Loss: 0.552 | Acc: 85.304% (38271/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3892, Accuracy: 7116/10000 (71.16%)

Epoch: 94
Loss: 0.308 | Acc: 92.188% (59/64)
Loss: 0.491 | Acc: 86.726% (5606/6464)
Loss: 0.501 | Acc: 86.489% (11126/12864)
Loss: 0.500 | Acc: 86.472% (16658/19264)
Loss: 0.500 | Acc: 86.522% (22205/25664)
Loss: 0.504 | Acc: 86.449% (27719/32064)
Loss: 0.500 | Acc: 86.582% (33303/38464)
Loss: 0.498 | Acc: 86.635% (38868/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4324, Accuracy: 7126/10000 (71.26%)

Epoch: 95
Loss: 0.397 | Acc: 89.062% (57/64)
Loss: 0.456 | Acc: 87.423% (5651/6464)
Loss: 0.461 | Acc: 87.298% (11230/12864)
Loss: 0.468 | Acc: 87.178% (16794/19264)
Loss: 0.468 | Acc: 87.184% (22375/25664)
Loss: 0.475 | Acc: 86.985% (27891/32064)
Loss: 0.480 | Acc: 86.915% (33431/38464)
Loss: 0.481 | Acc: 86.914% (38993/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3720, Accuracy: 7136/10000 (71.36%)

Epoch: 96
Loss: 0.421 | Acc: 89.062% (57/64)
Loss: 0.483 | Acc: 86.541% (5594/6464)
Loss: 0.482 | Acc: 86.723% (11156/12864)
Loss: 0.488 | Acc: 86.545% (16672/19264)
Loss: 0.486 | Acc: 86.732% (22259/25664)
Loss: 0.484 | Acc: 86.836% (27843/32064)
Loss: 0.484 | Acc: 86.871% (33414/38464)
Loss: 0.483 | Acc: 86.912% (38992/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3651, Accuracy: 7118/10000 (71.18%)

Epoch: 97
Loss: 0.519 | Acc: 82.812% (53/64)
Loss: 0.484 | Acc: 86.788% (5610/6464)
Loss: 0.487 | Acc: 86.793% (11165/12864)
Loss: 0.484 | Acc: 86.898% (16740/19264)
Loss: 0.480 | Acc: 87.017% (22332/25664)
Loss: 0.479 | Acc: 87.013% (27900/32064)
Loss: 0.474 | Acc: 87.139% (33517/38464)
Loss: 0.477 | Acc: 87.070% (39063/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3683, Accuracy: 7137/10000 (71.37%)
torch.Size([100, 10])
Test set: Average loss: 1.3683, Accuracy: 7137/10000 (71.37%)

Epoch: 98
Loss: 0.430 | Acc: 87.500% (56/64)
Loss: 0.479 | Acc: 86.850% (5614/6464)
Loss: 0.483 | Acc: 86.762% (11161/12864)
Loss: 0.478 | Acc: 87.022% (16764/19264)
Loss: 0.478 | Acc: 87.040% (22338/25664)
Loss: 0.475 | Acc: 87.123% (27935/32064)
Loss: 0.476 | Acc: 87.157% (33524/38464)
Loss: 0.475 | Acc: 87.166% (39106/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3643, Accuracy: 7143/10000 (71.43%)
torch.Size([100, 10])
Test set: Average loss: 1.3643, Accuracy: 7143/10000 (71.43%)

Epoch: 99
Loss: 0.285 | Acc: 93.750% (60/64)
Loss: 0.461 | Acc: 87.237% (5639/6464)
Loss: 0.467 | Acc: 87.197% (11217/12864)
Loss: 0.464 | Acc: 87.266% (16811/19264)
Loss: 0.464 | Acc: 87.180% (22374/25664)
Loss: 0.468 | Acc: 87.144% (27942/32064)
Loss: 0.466 | Acc: 87.191% (33537/38464)
Loss: 0.466 | Acc: 87.199% (39121/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3602, Accuracy: 7136/10000 (71.36%)
torch.Size([100, 10])
Test set: Average loss: 1.3602, Accuracy: 7136/10000 (71.36%)

Epoch: 100
Loss: 0.438 | Acc: 89.062% (57/64)
Loss: 1.768 | Acc: 42.744% (2763/6464)
Loss: 1.568 | Acc: 51.640% (6643/12864)
Loss: 1.459 | Acc: 56.390% (10863/19264)
Loss: 1.404 | Acc: 58.752% (15078/25664)
Loss: 1.365 | Acc: 60.364% (19355/32064)
Loss: 1.338 | Acc: 61.600% (23694/38464)
Loss: 1.319 | Acc: 62.460% (28022/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0570, Accuracy: 4108/10000 (41.08%)

Epoch: 101
Loss: 1.449 | Acc: 59.375% (38/64)
Loss: 1.165 | Acc: 68.843% (4450/6464)
Loss: 1.169 | Acc: 68.571% (8821/12864)
Loss: 1.161 | Acc: 68.984% (13289/19264)
Loss: 1.161 | Acc: 69.132% (17742/25664)
Loss: 1.160 | Acc: 69.143% (22170/32064)
Loss: 1.156 | Acc: 69.338% (26670/38464)
Loss: 1.158 | Acc: 69.316% (31098/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3561, Accuracy: 6232/10000 (62.32%)

Epoch: 102
Loss: 0.806 | Acc: 79.688% (51/64)
Loss: 1.134 | Acc: 70.096% (4531/6464)
Loss: 1.132 | Acc: 70.351% (9050/12864)
Loss: 1.134 | Acc: 70.281% (13539/19264)
Loss: 1.137 | Acc: 70.137% (18000/25664)
Loss: 1.136 | Acc: 70.259% (22528/32064)
Loss: 1.140 | Acc: 70.164% (26988/38464)
Loss: 1.138 | Acc: 70.270% (31526/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7345, Accuracy: 4950/10000 (49.50%)

Epoch: 103
Loss: 1.138 | Acc: 68.750% (44/64)
Loss: 1.142 | Acc: 70.282% (4543/6464)
Loss: 1.139 | Acc: 70.476% (9066/12864)
Loss: 1.135 | Acc: 70.499% (13581/19264)
Loss: 1.129 | Acc: 70.764% (18161/25664)
Loss: 1.130 | Acc: 70.833% (22712/32064)
Loss: 1.133 | Acc: 70.731% (27206/38464)
Loss: 1.133 | Acc: 70.631% (31688/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1836, Accuracy: 4126/10000 (41.26%)

Epoch: 104
Loss: 1.309 | Acc: 67.188% (43/64)
Loss: 1.103 | Acc: 70.978% (4588/6464)
Loss: 1.117 | Acc: 70.779% (9105/12864)
Loss: 1.116 | Acc: 70.982% (13674/19264)
Loss: 1.123 | Acc: 70.768% (18162/25664)
Loss: 1.125 | Acc: 70.721% (22676/32064)
Loss: 1.130 | Acc: 70.552% (27137/38464)
Loss: 1.131 | Acc: 70.511% (31634/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6628, Accuracy: 5124/10000 (51.24%)

Epoch: 105
Loss: 1.647 | Acc: 53.125% (34/64)
Loss: 1.138 | Acc: 70.514% (4558/6464)
Loss: 1.121 | Acc: 70.880% (9118/12864)
Loss: 1.122 | Acc: 70.894% (13657/19264)
Loss: 1.117 | Acc: 70.924% (18202/25664)
Loss: 1.119 | Acc: 70.880% (22727/32064)
Loss: 1.122 | Acc: 70.814% (27238/38464)
Loss: 1.124 | Acc: 70.827% (31776/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6510, Accuracy: 5180/10000 (51.80%)

Epoch: 106
Loss: 1.283 | Acc: 64.062% (41/64)
Loss: 1.116 | Acc: 71.318% (4610/6464)
Loss: 1.130 | Acc: 71.074% (9143/12864)
Loss: 1.121 | Acc: 71.382% (13751/19264)
Loss: 1.122 | Acc: 71.396% (18323/25664)
Loss: 1.121 | Acc: 71.357% (22880/32064)
Loss: 1.124 | Acc: 71.225% (27396/38464)
Loss: 1.125 | Acc: 71.148% (31920/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5440, Accuracy: 5666/10000 (56.66%)

Epoch: 107
Loss: 1.041 | Acc: 68.750% (44/64)
Loss: 1.065 | Acc: 72.865% (4710/6464)
Loss: 1.090 | Acc: 71.859% (9244/12864)
Loss: 1.102 | Acc: 71.621% (13797/19264)
Loss: 1.112 | Acc: 71.298% (18298/25664)
Loss: 1.113 | Acc: 71.286% (22857/32064)
Loss: 1.117 | Acc: 71.181% (27379/38464)
Loss: 1.118 | Acc: 71.220% (31952/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2367, Accuracy: 3898/10000 (38.98%)

Epoch: 108
Loss: 1.574 | Acc: 59.375% (38/64)
Loss: 1.114 | Acc: 71.411% (4616/6464)
Loss: 1.107 | Acc: 71.618% (9213/12864)
Loss: 1.112 | Acc: 71.548% (13783/19264)
Loss: 1.112 | Acc: 71.458% (18339/25664)
Loss: 1.114 | Acc: 71.326% (22870/32064)
Loss: 1.119 | Acc: 71.134% (27361/38464)
Loss: 1.119 | Acc: 71.162% (31926/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2440, Accuracy: 3645/10000 (36.45%)

Epoch: 109
Loss: 1.373 | Acc: 60.938% (39/64)
Loss: 1.130 | Acc: 70.653% (4567/6464)
Loss: 1.111 | Acc: 71.339% (9177/12864)
Loss: 1.110 | Acc: 71.382% (13751/19264)
Loss: 1.111 | Acc: 71.232% (18281/25664)
Loss: 1.114 | Acc: 71.180% (22823/32064)
Loss: 1.116 | Acc: 71.027% (27320/38464)
Loss: 1.115 | Acc: 71.041% (31872/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7107, Accuracy: 5067/10000 (50.67%)

Epoch: 110
Loss: 1.551 | Acc: 62.500% (40/64)
Loss: 1.100 | Acc: 71.875% (4646/6464)
Loss: 1.097 | Acc: 71.766% (9232/12864)
Loss: 1.096 | Acc: 71.911% (13853/19264)
Loss: 1.100 | Acc: 71.894% (18451/25664)
Loss: 1.104 | Acc: 71.735% (23001/32064)
Loss: 1.108 | Acc: 71.628% (27551/38464)
Loss: 1.108 | Acc: 71.605% (32125/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4196, Accuracy: 5985/10000 (59.85%)

Epoch: 111
Loss: 1.159 | Acc: 65.625% (42/64)
Loss: 1.092 | Acc: 71.767% (4639/6464)
Loss: 1.102 | Acc: 71.409% (9186/12864)
Loss: 1.101 | Acc: 71.558% (13785/19264)
Loss: 1.096 | Acc: 71.680% (18396/25664)
Loss: 1.105 | Acc: 71.526% (22934/32064)
Loss: 1.106 | Acc: 71.527% (27512/38464)
Loss: 1.107 | Acc: 71.590% (32118/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6710, Accuracy: 5036/10000 (50.36%)

Epoch: 112
Loss: 1.335 | Acc: 59.375% (38/64)
Loss: 1.091 | Acc: 72.679% (4698/6464)
Loss: 1.078 | Acc: 72.567% (9335/12864)
Loss: 1.086 | Acc: 72.337% (13935/19264)
Loss: 1.089 | Acc: 72.292% (18553/25664)
Loss: 1.090 | Acc: 72.146% (23133/32064)
Loss: 1.096 | Acc: 71.937% (27670/38464)
Loss: 1.099 | Acc: 71.830% (32226/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4431, Accuracy: 5949/10000 (59.49%)

Epoch: 113
Loss: 1.210 | Acc: 67.188% (43/64)
Loss: 1.073 | Acc: 73.066% (4723/6464)
Loss: 1.086 | Acc: 72.139% (9280/12864)
Loss: 1.085 | Acc: 72.202% (13909/19264)
Loss: 1.085 | Acc: 72.132% (18512/25664)
Loss: 1.084 | Acc: 72.206% (23152/32064)
Loss: 1.089 | Acc: 72.125% (27742/38464)
Loss: 1.093 | Acc: 71.995% (32300/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0359, Accuracy: 4289/10000 (42.89%)

Epoch: 114
Loss: 1.209 | Acc: 65.625% (42/64)
Loss: 1.077 | Acc: 72.494% (4686/6464)
Loss: 1.079 | Acc: 72.435% (9318/12864)
Loss: 1.085 | Acc: 72.083% (13886/19264)
Loss: 1.086 | Acc: 72.167% (18521/25664)
Loss: 1.088 | Acc: 72.215% (23155/32064)
Loss: 1.094 | Acc: 72.067% (27720/38464)
Loss: 1.094 | Acc: 72.056% (32327/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4702, Accuracy: 5878/10000 (58.78%)

Epoch: 115
Loss: 1.029 | Acc: 71.875% (46/64)
Loss: 1.056 | Acc: 73.190% (4731/6464)
Loss: 1.070 | Acc: 72.901% (9378/12864)
Loss: 1.082 | Acc: 72.462% (13959/19264)
Loss: 1.087 | Acc: 72.343% (18566/25664)
Loss: 1.085 | Acc: 72.439% (23227/32064)
Loss: 1.083 | Acc: 72.465% (27873/38464)
Loss: 1.083 | Acc: 72.439% (32499/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3213, Accuracy: 6487/10000 (64.87%)

Epoch: 116
Loss: 0.932 | Acc: 76.562% (49/64)
Loss: 1.063 | Acc: 73.267% (4736/6464)
Loss: 1.072 | Acc: 72.761% (9360/12864)
Loss: 1.077 | Acc: 72.623% (13990/19264)
Loss: 1.082 | Acc: 72.502% (18607/25664)
Loss: 1.085 | Acc: 72.477% (23239/32064)
Loss: 1.083 | Acc: 72.546% (27904/38464)
Loss: 1.084 | Acc: 72.432% (32496/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4610, Accuracy: 5868/10000 (58.68%)

Epoch: 117
Loss: 1.001 | Acc: 71.875% (46/64)
Loss: 1.088 | Acc: 72.757% (4703/6464)
Loss: 1.091 | Acc: 72.512% (9328/12864)
Loss: 1.078 | Acc: 72.877% (14039/19264)
Loss: 1.079 | Acc: 72.795% (18682/25664)
Loss: 1.086 | Acc: 72.496% (23245/32064)
Loss: 1.081 | Acc: 72.590% (27921/38464)
Loss: 1.075 | Acc: 72.733% (32631/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2385, Accuracy: 6734/10000 (67.34%)

Epoch: 118
Loss: 1.333 | Acc: 67.188% (43/64)
Loss: 1.036 | Acc: 73.577% (4756/6464)
Loss: 1.052 | Acc: 73.321% (9432/12864)
Loss: 1.058 | Acc: 73.183% (14098/19264)
Loss: 1.058 | Acc: 73.180% (18781/25664)
Loss: 1.063 | Acc: 73.035% (23418/32064)
Loss: 1.064 | Acc: 72.996% (28077/38464)
Loss: 1.065 | Acc: 73.005% (32753/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5735, Accuracy: 5384/10000 (53.84%)

Epoch: 119
Loss: 0.899 | Acc: 78.125% (50/64)
Loss: 1.047 | Acc: 73.762% (4768/6464)
Loss: 1.047 | Acc: 73.842% (9499/12864)
Loss: 1.050 | Acc: 73.661% (14190/19264)
Loss: 1.058 | Acc: 73.434% (18846/25664)
Loss: 1.061 | Acc: 73.369% (23525/32064)
Loss: 1.060 | Acc: 73.370% (28221/38464)
Loss: 1.059 | Acc: 73.351% (32908/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5107, Accuracy: 5899/10000 (58.99%)

Epoch: 120
Loss: 0.900 | Acc: 76.562% (49/64)
Loss: 1.062 | Acc: 73.175% (4730/6464)
Loss: 1.058 | Acc: 73.539% (9460/12864)
Loss: 1.052 | Acc: 73.723% (14202/19264)
Loss: 1.050 | Acc: 73.699% (18914/25664)
Loss: 1.048 | Acc: 73.781% (23657/32064)
Loss: 1.050 | Acc: 73.666% (28335/38464)
Loss: 1.052 | Acc: 73.649% (33042/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3656, Accuracy: 6273/10000 (62.73%)

Epoch: 121
Loss: 1.279 | Acc: 65.625% (42/64)
Loss: 1.006 | Acc: 74.861% (4839/6464)
Loss: 1.027 | Acc: 74.378% (9568/12864)
Loss: 1.037 | Acc: 74.009% (14257/19264)
Loss: 1.042 | Acc: 73.831% (18948/25664)
Loss: 1.037 | Acc: 73.986% (23723/32064)
Loss: 1.043 | Acc: 73.817% (28393/38464)
Loss: 1.045 | Acc: 73.787% (33104/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3132, Accuracy: 6452/10000 (64.52%)

Epoch: 122
Loss: 1.024 | Acc: 75.000% (48/64)
Loss: 1.028 | Acc: 74.025% (4785/6464)
Loss: 1.023 | Acc: 74.246% (9551/12864)
Loss: 1.023 | Acc: 74.346% (14322/19264)
Loss: 1.021 | Acc: 74.451% (19107/25664)
Loss: 1.027 | Acc: 74.354% (23841/32064)
Loss: 1.028 | Acc: 74.262% (28564/38464)
Loss: 1.032 | Acc: 74.088% (33239/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4037, Accuracy: 6163/10000 (61.63%)

Epoch: 123
Loss: 1.002 | Acc: 71.875% (46/64)
Loss: 1.003 | Acc: 75.046% (4851/6464)
Loss: 1.016 | Acc: 74.689% (9608/12864)
Loss: 1.017 | Acc: 74.585% (14368/19264)
Loss: 1.017 | Acc: 74.653% (19159/25664)
Loss: 1.020 | Acc: 74.545% (23902/32064)
Loss: 1.024 | Acc: 74.441% (28633/38464)
Loss: 1.025 | Acc: 74.412% (33384/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2220, Accuracy: 6851/10000 (68.51%)

Epoch: 124
Loss: 0.904 | Acc: 81.250% (52/64)
Loss: 1.005 | Acc: 75.511% (4881/6464)
Loss: 1.001 | Acc: 75.443% (9705/12864)
Loss: 1.009 | Acc: 75.197% (14486/19264)
Loss: 1.008 | Acc: 75.168% (19291/25664)
Loss: 1.011 | Acc: 75.065% (24069/32064)
Loss: 1.010 | Acc: 75.091% (28883/38464)
Loss: 1.018 | Acc: 74.790% (33554/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4038, Accuracy: 6159/10000 (61.59%)

Epoch: 125
Loss: 1.117 | Acc: 71.875% (46/64)
Loss: 0.988 | Acc: 75.681% (4892/6464)
Loss: 0.985 | Acc: 75.552% (9719/12864)
Loss: 1.002 | Acc: 75.067% (14461/19264)
Loss: 1.001 | Acc: 75.152% (19287/25664)
Loss: 1.005 | Acc: 75.112% (24084/32064)
Loss: 1.004 | Acc: 75.117% (28893/38464)
Loss: 1.007 | Acc: 75.042% (33667/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2633, Accuracy: 6658/10000 (66.58%)

Epoch: 126
Loss: 0.913 | Acc: 71.875% (46/64)
Loss: 0.960 | Acc: 76.346% (4935/6464)
Loss: 0.968 | Acc: 76.337% (9820/12864)
Loss: 0.982 | Acc: 75.857% (14613/19264)
Loss: 0.988 | Acc: 75.549% (19389/25664)
Loss: 0.992 | Acc: 75.437% (24188/32064)
Loss: 0.992 | Acc: 75.465% (29027/38464)
Loss: 0.994 | Acc: 75.459% (33854/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2104, Accuracy: 6933/10000 (69.33%)

Epoch: 127
Loss: 0.883 | Acc: 81.250% (52/64)
Loss: 0.951 | Acc: 76.779% (4963/6464)
Loss: 0.972 | Acc: 76.112% (9791/12864)
Loss: 0.979 | Acc: 76.002% (14641/19264)
Loss: 0.983 | Acc: 75.795% (19452/25664)
Loss: 0.989 | Acc: 75.605% (24242/32064)
Loss: 0.984 | Acc: 75.775% (29146/38464)
Loss: 0.981 | Acc: 75.856% (34032/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2497, Accuracy: 6726/10000 (67.26%)

Epoch: 128
Loss: 1.261 | Acc: 70.312% (45/64)
Loss: 0.938 | Acc: 77.398% (5003/6464)
Loss: 0.956 | Acc: 76.594% (9853/12864)
Loss: 0.956 | Acc: 76.469% (14731/19264)
Loss: 0.959 | Acc: 76.434% (19616/25664)
Loss: 0.965 | Acc: 76.338% (24477/32064)
Loss: 0.968 | Acc: 76.284% (29342/38464)
Loss: 0.971 | Acc: 76.190% (34182/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3424, Accuracy: 6371/10000 (63.71%)

Epoch: 129
Loss: 0.936 | Acc: 75.000% (48/64)
Loss: 0.940 | Acc: 77.027% (4979/6464)
Loss: 0.948 | Acc: 77.013% (9907/12864)
Loss: 0.940 | Acc: 77.056% (14844/19264)
Loss: 0.943 | Acc: 76.905% (19737/25664)
Loss: 0.956 | Acc: 76.541% (24542/32064)
Loss: 0.959 | Acc: 76.534% (29438/38464)
Loss: 0.960 | Acc: 76.576% (34355/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4242, Accuracy: 6232/10000 (62.32%)

Epoch: 130
Loss: 1.159 | Acc: 70.312% (45/64)
Loss: 0.950 | Acc: 76.578% (4950/6464)
Loss: 0.961 | Acc: 76.407% (9829/12864)
Loss: 0.950 | Acc: 76.749% (14785/19264)
Loss: 0.948 | Acc: 76.866% (19727/25664)
Loss: 0.944 | Acc: 77.015% (24694/32064)
Loss: 0.943 | Acc: 76.986% (29612/38464)
Loss: 0.943 | Acc: 76.975% (34534/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2708, Accuracy: 6705/10000 (67.05%)

Epoch: 131
Loss: 0.913 | Acc: 78.125% (50/64)
Loss: 0.907 | Acc: 77.723% (5024/6464)
Loss: 0.910 | Acc: 77.713% (9997/12864)
Loss: 0.915 | Acc: 77.658% (14960/19264)
Loss: 0.918 | Acc: 77.626% (19922/25664)
Loss: 0.923 | Acc: 77.520% (24856/32064)
Loss: 0.925 | Acc: 77.493% (29807/38464)
Loss: 0.929 | Acc: 77.398% (34724/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1920, Accuracy: 7022/10000 (70.22%)

Epoch: 132
Loss: 1.087 | Acc: 71.875% (46/64)
Loss: 0.905 | Acc: 77.877% (5034/6464)
Loss: 0.910 | Acc: 77.760% (10003/12864)
Loss: 0.907 | Acc: 77.860% (14999/19264)
Loss: 0.908 | Acc: 77.782% (19962/25664)
Loss: 0.912 | Acc: 77.763% (24934/32064)
Loss: 0.911 | Acc: 77.823% (29934/38464)
Loss: 0.912 | Acc: 77.802% (34905/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1787, Accuracy: 7129/10000 (71.29%)

Epoch: 133
Loss: 0.862 | Acc: 81.250% (52/64)
Loss: 0.851 | Acc: 79.162% (5117/6464)
Loss: 0.878 | Acc: 78.514% (10100/12864)
Loss: 0.888 | Acc: 78.286% (15081/19264)
Loss: 0.891 | Acc: 78.269% (20087/25664)
Loss: 0.897 | Acc: 78.094% (25040/32064)
Loss: 0.895 | Acc: 78.206% (30081/38464)
Loss: 0.891 | Acc: 78.355% (35153/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2061, Accuracy: 7023/10000 (70.23%)

Epoch: 134
Loss: 0.877 | Acc: 79.688% (51/64)
Loss: 0.857 | Acc: 79.038% (5109/6464)
Loss: 0.858 | Acc: 79.050% (10169/12864)
Loss: 0.859 | Acc: 79.132% (15244/19264)
Loss: 0.859 | Acc: 79.037% (20284/25664)
Loss: 0.865 | Acc: 78.911% (25302/32064)
Loss: 0.866 | Acc: 78.866% (30335/38464)
Loss: 0.865 | Acc: 78.956% (35423/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1945, Accuracy: 7064/10000 (70.64%)

Epoch: 135
Loss: 0.911 | Acc: 76.562% (49/64)
Loss: 0.808 | Acc: 80.322% (5192/6464)
Loss: 0.817 | Acc: 80.084% (10302/12864)
Loss: 0.831 | Acc: 79.677% (15349/19264)
Loss: 0.838 | Acc: 79.578% (20423/25664)
Loss: 0.838 | Acc: 79.575% (25515/32064)
Loss: 0.845 | Acc: 79.394% (30538/38464)
Loss: 0.843 | Acc: 79.514% (35673/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2159, Accuracy: 7046/10000 (70.46%)

Epoch: 136
Loss: 1.163 | Acc: 71.875% (46/64)
Loss: 0.803 | Acc: 80.415% (5198/6464)
Loss: 0.809 | Acc: 80.037% (10296/12864)
Loss: 0.802 | Acc: 80.451% (15498/19264)
Loss: 0.811 | Acc: 80.311% (20611/25664)
Loss: 0.813 | Acc: 80.227% (25724/32064)
Loss: 0.819 | Acc: 80.028% (30782/38464)
Loss: 0.819 | Acc: 80.062% (35919/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2242, Accuracy: 7095/10000 (70.95%)

Epoch: 137
Loss: 0.721 | Acc: 84.375% (54/64)
Loss: 0.776 | Acc: 80.879% (5228/6464)
Loss: 0.771 | Acc: 81.141% (10438/12864)
Loss: 0.779 | Acc: 80.907% (15586/19264)
Loss: 0.775 | Acc: 81.040% (20798/25664)
Loss: 0.781 | Acc: 80.907% (25942/32064)
Loss: 0.787 | Acc: 80.720% (31048/38464)
Loss: 0.788 | Acc: 80.713% (36211/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2879, Accuracy: 6869/10000 (68.69%)

Epoch: 138
Loss: 0.808 | Acc: 73.438% (47/64)
Loss: 0.750 | Acc: 81.142% (5245/6464)
Loss: 0.750 | Acc: 81.266% (10454/12864)
Loss: 0.750 | Acc: 81.255% (15653/19264)
Loss: 0.746 | Acc: 81.410% (20893/25664)
Loss: 0.752 | Acc: 81.294% (26066/32064)
Loss: 0.748 | Acc: 81.427% (31320/38464)
Loss: 0.750 | Acc: 81.375% (36508/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2315, Accuracy: 7117/10000 (71.17%)

Epoch: 139
Loss: 0.675 | Acc: 82.812% (53/64)
Loss: 0.708 | Acc: 82.271% (5318/6464)
Loss: 0.711 | Acc: 82.198% (10574/12864)
Loss: 0.710 | Acc: 82.205% (15836/19264)
Loss: 0.718 | Acc: 81.971% (21037/25664)
Loss: 0.721 | Acc: 81.945% (26275/32064)
Loss: 0.722 | Acc: 81.996% (31539/38464)
Loss: 0.725 | Acc: 81.945% (36764/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2373, Accuracy: 7176/10000 (71.76%)

Epoch: 140
Loss: 0.542 | Acc: 81.250% (52/64)
Loss: 0.658 | Acc: 83.308% (5385/6464)
Loss: 0.669 | Acc: 82.945% (10670/12864)
Loss: 0.672 | Acc: 82.890% (15968/19264)
Loss: 0.677 | Acc: 82.762% (21240/25664)
Loss: 0.672 | Acc: 82.915% (26586/32064)
Loss: 0.677 | Acc: 82.823% (31857/38464)
Loss: 0.678 | Acc: 82.781% (37139/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2807, Accuracy: 7186/10000 (71.86%)

Epoch: 141
Loss: 0.553 | Acc: 85.938% (55/64)
Loss: 0.613 | Acc: 84.545% (5465/6464)
Loss: 0.622 | Acc: 84.126% (10822/12864)
Loss: 0.628 | Acc: 84.105% (16202/19264)
Loss: 0.632 | Acc: 83.923% (21538/25664)
Loss: 0.631 | Acc: 83.926% (26910/32064)
Loss: 0.629 | Acc: 84.001% (32310/38464)
Loss: 0.635 | Acc: 83.838% (37613/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3310, Accuracy: 7179/10000 (71.79%)

Epoch: 142
Loss: 0.629 | Acc: 85.938% (55/64)
Loss: 0.596 | Acc: 84.700% (5475/6464)
Loss: 0.590 | Acc: 84.639% (10888/12864)
Loss: 0.590 | Acc: 84.526% (16283/19264)
Loss: 0.584 | Acc: 84.757% (21752/25664)
Loss: 0.583 | Acc: 84.812% (27194/32064)
Loss: 0.584 | Acc: 84.838% (32632/38464)
Loss: 0.586 | Acc: 84.758% (38026/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4074, Accuracy: 7062/10000 (70.62%)

Epoch: 143
Loss: 0.446 | Acc: 90.625% (58/64)
Loss: 0.528 | Acc: 85.845% (5549/6464)
Loss: 0.533 | Acc: 85.821% (11040/12864)
Loss: 0.531 | Acc: 85.891% (16546/19264)
Loss: 0.534 | Acc: 85.789% (22017/25664)
Loss: 0.534 | Acc: 85.825% (27519/32064)
Loss: 0.533 | Acc: 85.813% (33007/38464)
Loss: 0.535 | Acc: 85.744% (38468/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4008, Accuracy: 7116/10000 (71.16%)

Epoch: 144
Loss: 0.510 | Acc: 89.062% (57/64)
Loss: 0.490 | Acc: 86.665% (5602/6464)
Loss: 0.490 | Acc: 86.583% (11138/12864)
Loss: 0.486 | Acc: 86.862% (16733/19264)
Loss: 0.486 | Acc: 86.806% (22278/25664)
Loss: 0.483 | Acc: 86.970% (27886/32064)
Loss: 0.484 | Acc: 86.912% (33430/38464)
Loss: 0.484 | Acc: 86.916% (38994/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4385, Accuracy: 7087/10000 (70.87%)

Epoch: 145
Loss: 0.449 | Acc: 89.062% (57/64)
Loss: 0.422 | Acc: 88.258% (5705/6464)
Loss: 0.431 | Acc: 88.075% (11330/12864)
Loss: 0.436 | Acc: 88.009% (16954/19264)
Loss: 0.442 | Acc: 87.773% (22526/25664)
Loss: 0.445 | Acc: 87.750% (28136/32064)
Loss: 0.452 | Acc: 87.594% (33692/38464)
Loss: 0.456 | Acc: 87.531% (39270/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4095, Accuracy: 7065/10000 (70.65%)

Epoch: 146
Loss: 0.630 | Acc: 81.250% (52/64)
Loss: 0.445 | Acc: 88.119% (5696/6464)
Loss: 0.454 | Acc: 87.881% (11305/12864)
Loss: 0.459 | Acc: 87.682% (16891/19264)
Loss: 0.458 | Acc: 87.695% (22506/25664)
Loss: 0.461 | Acc: 87.565% (28077/32064)
Loss: 0.466 | Acc: 87.367% (33605/38464)
Loss: 0.468 | Acc: 87.324% (39177/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4044, Accuracy: 7129/10000 (71.29%)

Epoch: 147
Loss: 0.455 | Acc: 85.938% (55/64)
Loss: 0.435 | Acc: 88.227% (5703/6464)
Loss: 0.434 | Acc: 88.308% (11360/12864)
Loss: 0.449 | Acc: 87.708% (16896/19264)
Loss: 0.446 | Acc: 87.812% (22536/25664)
Loss: 0.450 | Acc: 87.675% (28112/32064)
Loss: 0.456 | Acc: 87.495% (33654/38464)
Loss: 0.459 | Acc: 87.442% (39230/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3889, Accuracy: 7135/10000 (71.35%)
torch.Size([100, 10])
Test set: Average loss: 1.3889, Accuracy: 7135/10000 (71.35%)

Epoch: 148
Loss: 0.276 | Acc: 92.188% (59/64)
Loss: 0.432 | Acc: 88.026% (5690/6464)
Loss: 0.437 | Acc: 87.858% (11302/12864)
Loss: 0.443 | Acc: 87.791% (16912/19264)
Loss: 0.444 | Acc: 87.823% (22539/25664)
Loss: 0.444 | Acc: 87.821% (28159/32064)
Loss: 0.449 | Acc: 87.695% (33731/38464)
Loss: 0.451 | Acc: 87.596% (39299/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3950, Accuracy: 7141/10000 (71.41%)
torch.Size([100, 10])
Test set: Average loss: 1.3950, Accuracy: 7141/10000 (71.41%)

Epoch: 149
Loss: 0.390 | Acc: 92.188% (59/64)
Loss: 0.449 | Acc: 87.918% (5683/6464)
Loss: 0.440 | Acc: 88.130% (11337/12864)
Loss: 0.442 | Acc: 87.988% (16950/19264)
Loss: 0.441 | Acc: 87.936% (22568/25664)
Loss: 0.440 | Acc: 87.971% (28207/32064)
Loss: 0.446 | Acc: 87.755% (33754/38464)
Loss: 0.444 | Acc: 87.868% (39421/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3987, Accuracy: 7142/10000 (71.42%)
torch.Size([100, 10])
Test set: Average loss: 1.3987, Accuracy: 7142/10000 (71.42%)

Epoch: 150
Loss: 0.391 | Acc: 89.062% (57/64)
Loss: 1.626 | Acc: 49.118% (3175/6464)
Loss: 1.463 | Acc: 56.413% (7257/12864)
Loss: 1.396 | Acc: 59.380% (11439/19264)
Loss: 1.352 | Acc: 61.378% (15752/25664)
Loss: 1.317 | Acc: 62.859% (20155/32064)
Loss: 1.293 | Acc: 63.823% (24549/38464)
Loss: 1.276 | Acc: 64.533% (28952/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4530, Accuracy: 5811/10000 (58.11%)

Epoch: 151
Loss: 0.904 | Acc: 76.562% (49/64)
Loss: 1.143 | Acc: 69.972% (4523/6464)
Loss: 1.143 | Acc: 69.792% (8978/12864)
Loss: 1.151 | Acc: 69.617% (13411/19264)
Loss: 1.149 | Acc: 69.673% (17881/25664)
Loss: 1.145 | Acc: 69.882% (22407/32064)
Loss: 1.142 | Acc: 70.019% (26932/38464)
Loss: 1.141 | Acc: 70.036% (31421/44864)
torch.Size([100, 10])
Test set: Average loss: 2.8174, Accuracy: 2948/10000 (29.48%)

Epoch: 152
Loss: 1.392 | Acc: 57.812% (37/64)
Loss: 1.115 | Acc: 71.442% (4618/6464)
Loss: 1.098 | Acc: 71.836% (9241/12864)
Loss: 1.119 | Acc: 71.148% (13706/19264)
Loss: 1.123 | Acc: 70.979% (18216/25664)
Loss: 1.128 | Acc: 70.833% (22712/32064)
Loss: 1.130 | Acc: 70.806% (27235/38464)
Loss: 1.125 | Acc: 70.903% (31810/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5590, Accuracy: 5497/10000 (54.97%)

Epoch: 153
Loss: 1.074 | Acc: 65.625% (42/64)
Loss: 1.119 | Acc: 70.560% (4561/6464)
Loss: 1.093 | Acc: 71.751% (9230/12864)
Loss: 1.111 | Acc: 71.262% (13728/19264)
Loss: 1.109 | Acc: 71.454% (18338/25664)
Loss: 1.111 | Acc: 71.454% (22911/32064)
Loss: 1.114 | Acc: 71.339% (27440/38464)
Loss: 1.116 | Acc: 71.302% (31989/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2844, Accuracy: 6519/10000 (65.19%)

Epoch: 154
Loss: 1.151 | Acc: 73.438% (47/64)
Loss: 1.088 | Acc: 71.241% (4605/6464)
Loss: 1.103 | Acc: 70.802% (9108/12864)
Loss: 1.111 | Acc: 70.707% (13621/19264)
Loss: 1.114 | Acc: 70.687% (18141/25664)
Loss: 1.118 | Acc: 70.705% (22671/32064)
Loss: 1.119 | Acc: 70.739% (27209/38464)
Loss: 1.119 | Acc: 70.823% (31774/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4225, Accuracy: 5938/10000 (59.38%)

Epoch: 155
Loss: 1.141 | Acc: 71.875% (46/64)
Loss: 1.111 | Acc: 71.751% (4638/6464)
Loss: 1.116 | Acc: 71.409% (9186/12864)
Loss: 1.101 | Acc: 71.678% (13808/19264)
Loss: 1.106 | Acc: 71.602% (18376/25664)
Loss: 1.106 | Acc: 71.582% (22952/32064)
Loss: 1.110 | Acc: 71.493% (27499/38464)
Loss: 1.111 | Acc: 71.503% (32079/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4769, Accuracy: 5834/10000 (58.34%)

Epoch: 156
Loss: 0.941 | Acc: 73.438% (47/64)
Loss: 1.109 | Acc: 71.241% (4605/6464)
Loss: 1.093 | Acc: 71.673% (9220/12864)
Loss: 1.085 | Acc: 71.948% (13860/19264)
Loss: 1.090 | Acc: 71.836% (18436/25664)
Loss: 1.097 | Acc: 71.585% (22953/32064)
Loss: 1.103 | Acc: 71.488% (27497/38464)
Loss: 1.107 | Acc: 71.414% (32039/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4811, Accuracy: 5721/10000 (57.21%)

Epoch: 157
Loss: 0.940 | Acc: 75.000% (48/64)
Loss: 1.103 | Acc: 71.241% (4605/6464)
Loss: 1.091 | Acc: 71.852% (9243/12864)
Loss: 1.100 | Acc: 71.678% (13808/19264)
Loss: 1.104 | Acc: 71.517% (18354/25664)
Loss: 1.106 | Acc: 71.463% (22914/32064)
Loss: 1.107 | Acc: 71.451% (27483/38464)
Loss: 1.105 | Acc: 71.476% (32067/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3523, Accuracy: 6364/10000 (63.64%)

Epoch: 158
Loss: 1.432 | Acc: 62.500% (40/64)
Loss: 1.109 | Acc: 71.194% (4602/6464)
Loss: 1.107 | Acc: 71.432% (9189/12864)
Loss: 1.102 | Acc: 71.699% (13812/19264)
Loss: 1.099 | Acc: 71.933% (18461/25664)
Loss: 1.101 | Acc: 71.881% (23048/32064)
Loss: 1.102 | Acc: 71.792% (27614/38464)
Loss: 1.106 | Acc: 71.688% (32162/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2431, Accuracy: 6716/10000 (67.16%)

Epoch: 159
Loss: 1.031 | Acc: 73.438% (47/64)
Loss: 1.084 | Acc: 72.525% (4688/6464)
Loss: 1.084 | Acc: 72.388% (9312/12864)
Loss: 1.084 | Acc: 72.384% (13944/19264)
Loss: 1.089 | Acc: 72.222% (18535/25664)
Loss: 1.090 | Acc: 72.159% (23137/32064)
Loss: 1.095 | Acc: 72.013% (27699/38464)
Loss: 1.097 | Acc: 71.904% (32259/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5285, Accuracy: 5876/10000 (58.76%)

Epoch: 160
Loss: 1.184 | Acc: 65.625% (42/64)
Loss: 1.098 | Acc: 71.983% (4653/6464)
Loss: 1.096 | Acc: 72.046% (9268/12864)
Loss: 1.091 | Acc: 72.192% (13907/19264)
Loss: 1.092 | Acc: 72.082% (18499/25664)
Loss: 1.090 | Acc: 72.171% (23141/32064)
Loss: 1.095 | Acc: 72.044% (27711/38464)
Loss: 1.098 | Acc: 71.864% (32241/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5567, Accuracy: 5581/10000 (55.81%)

Epoch: 161
Loss: 1.551 | Acc: 57.812% (37/64)
Loss: 1.103 | Acc: 71.705% (4635/6464)
Loss: 1.094 | Acc: 72.240% (9293/12864)
Loss: 1.105 | Acc: 71.854% (13842/19264)
Loss: 1.105 | Acc: 71.805% (18428/25664)
Loss: 1.103 | Acc: 71.925% (23062/32064)
Loss: 1.104 | Acc: 71.852% (27637/38464)
Loss: 1.102 | Acc: 71.906% (32260/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3991, Accuracy: 6117/10000 (61.17%)

Epoch: 162
Loss: 1.135 | Acc: 70.312% (45/64)
Loss: 1.074 | Acc: 72.308% (4674/6464)
Loss: 1.075 | Acc: 72.613% (9341/12864)
Loss: 1.075 | Acc: 72.539% (13974/19264)
Loss: 1.085 | Acc: 72.257% (18544/25664)
Loss: 1.090 | Acc: 72.012% (23090/32064)
Loss: 1.092 | Acc: 72.015% (27700/38464)
Loss: 1.094 | Acc: 71.908% (32261/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4630, Accuracy: 6016/10000 (60.16%)

Epoch: 163
Loss: 0.947 | Acc: 76.562% (49/64)
Loss: 1.042 | Acc: 73.577% (4756/6464)
Loss: 1.058 | Acc: 73.158% (9411/12864)
Loss: 1.066 | Acc: 72.898% (14043/19264)
Loss: 1.075 | Acc: 72.569% (18624/25664)
Loss: 1.080 | Acc: 72.464% (23235/32064)
Loss: 1.085 | Acc: 72.309% (27813/38464)
Loss: 1.087 | Acc: 72.261% (32419/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3068, Accuracy: 6518/10000 (65.18%)

Epoch: 164
Loss: 1.115 | Acc: 70.312% (45/64)
Loss: 1.072 | Acc: 72.772% (4704/6464)
Loss: 1.046 | Acc: 73.609% (9469/12864)
Loss: 1.065 | Acc: 73.090% (14080/19264)
Loss: 1.071 | Acc: 72.771% (18676/25664)
Loss: 1.072 | Acc: 72.817% (23348/32064)
Loss: 1.077 | Acc: 72.655% (27946/38464)
Loss: 1.080 | Acc: 72.593% (32568/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3786, Accuracy: 6198/10000 (61.98%)

Epoch: 165
Loss: 1.216 | Acc: 70.312% (45/64)
Loss: 1.090 | Acc: 71.860% (4645/6464)
Loss: 1.083 | Acc: 72.069% (9271/12864)
Loss: 1.075 | Acc: 72.508% (13968/19264)
Loss: 1.075 | Acc: 72.409% (18583/25664)
Loss: 1.079 | Acc: 72.399% (23214/32064)
Loss: 1.076 | Acc: 72.569% (27913/38464)
Loss: 1.076 | Acc: 72.617% (32579/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2190, Accuracy: 6873/10000 (68.73%)

Epoch: 166
Loss: 1.241 | Acc: 67.188% (43/64)
Loss: 1.051 | Acc: 73.314% (4739/6464)
Loss: 1.055 | Acc: 73.422% (9445/12864)
Loss: 1.055 | Acc: 73.349% (14130/19264)
Loss: 1.062 | Acc: 73.169% (18778/25664)
Loss: 1.067 | Acc: 73.016% (23412/32064)
Loss: 1.071 | Acc: 72.842% (28018/38464)
Loss: 1.073 | Acc: 72.780% (32652/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5217, Accuracy: 5578/10000 (55.78%)

Epoch: 167
Loss: 0.896 | Acc: 81.250% (52/64)
Loss: 1.071 | Acc: 72.726% (4701/6464)
Loss: 1.077 | Acc: 72.559% (9334/12864)
Loss: 1.071 | Acc: 72.950% (14053/19264)
Loss: 1.068 | Acc: 72.962% (18725/25664)
Loss: 1.067 | Acc: 72.967% (23396/32064)
Loss: 1.066 | Acc: 73.032% (28091/38464)
Loss: 1.069 | Acc: 72.900% (32706/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5261, Accuracy: 6058/10000 (60.58%)

Epoch: 168
Loss: 0.697 | Acc: 81.250% (52/64)
Loss: 1.044 | Acc: 73.577% (4756/6464)
Loss: 1.054 | Acc: 73.352% (9436/12864)
Loss: 1.054 | Acc: 73.313% (14123/19264)
Loss: 1.053 | Acc: 73.352% (18825/25664)
Loss: 1.058 | Acc: 73.204% (23472/32064)
Loss: 1.059 | Acc: 73.165% (28142/38464)
Loss: 1.059 | Acc: 73.208% (32844/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4521, Accuracy: 5963/10000 (59.63%)

Epoch: 169
Loss: 1.008 | Acc: 70.312% (45/64)
Loss: 1.041 | Acc: 73.654% (4761/6464)
Loss: 1.050 | Acc: 73.461% (9450/12864)
Loss: 1.059 | Acc: 73.235% (14108/19264)
Loss: 1.052 | Acc: 73.535% (18872/25664)
Loss: 1.057 | Acc: 73.431% (23545/32064)
Loss: 1.054 | Acc: 73.479% (28263/38464)
Loss: 1.056 | Acc: 73.351% (32908/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4045, Accuracy: 6092/10000 (60.92%)

Epoch: 170
Loss: 1.377 | Acc: 65.625% (42/64)
Loss: 1.031 | Acc: 74.134% (4792/6464)
Loss: 1.036 | Acc: 73.850% (9500/12864)
Loss: 1.043 | Acc: 73.790% (14215/19264)
Loss: 1.044 | Acc: 73.804% (18941/25664)
Loss: 1.043 | Acc: 73.883% (23690/32064)
Loss: 1.041 | Acc: 73.963% (28449/38464)
Loss: 1.046 | Acc: 73.819% (33118/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0167, Accuracy: 4357/10000 (43.57%)

Epoch: 171
Loss: 1.150 | Acc: 67.188% (43/64)
Loss: 1.017 | Acc: 74.830% (4837/6464)
Loss: 1.023 | Acc: 74.464% (9579/12864)
Loss: 1.024 | Acc: 74.232% (14300/19264)
Loss: 1.031 | Acc: 74.147% (19029/25664)
Loss: 1.036 | Acc: 73.933% (23706/32064)
Loss: 1.038 | Acc: 73.898% (28424/38464)
Loss: 1.040 | Acc: 73.897% (33153/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4604, Accuracy: 5938/10000 (59.38%)

Epoch: 172
Loss: 1.457 | Acc: 60.938% (39/64)
Loss: 1.016 | Acc: 74.459% (4813/6464)
Loss: 1.017 | Acc: 74.697% (9609/12864)
Loss: 1.017 | Acc: 74.792% (14408/19264)
Loss: 1.021 | Acc: 74.673% (19164/25664)
Loss: 1.022 | Acc: 74.648% (23935/32064)
Loss: 1.025 | Acc: 74.509% (28659/38464)
Loss: 1.028 | Acc: 74.436% (33395/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3403, Accuracy: 6361/10000 (63.61%)

Epoch: 173
Loss: 0.825 | Acc: 81.250% (52/64)
Loss: 1.020 | Acc: 74.675% (4827/6464)
Loss: 1.017 | Acc: 74.806% (9623/12864)
Loss: 1.019 | Acc: 74.714% (14393/19264)
Loss: 1.021 | Acc: 74.649% (19158/25664)
Loss: 1.024 | Acc: 74.604% (23921/32064)
Loss: 1.024 | Acc: 74.615% (28700/38464)
Loss: 1.023 | Acc: 74.663% (33497/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3523, Accuracy: 6420/10000 (64.20%)

Epoch: 174
Loss: 1.236 | Acc: 68.750% (44/64)
Loss: 1.004 | Acc: 74.691% (4828/6464)
Loss: 1.006 | Acc: 74.697% (9609/12864)
Loss: 0.995 | Acc: 75.062% (14460/19264)
Loss: 1.003 | Acc: 74.926% (19229/25664)
Loss: 1.006 | Acc: 74.844% (23998/32064)
Loss: 1.004 | Acc: 75.034% (28861/38464)
Loss: 1.006 | Acc: 74.931% (33617/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4635, Accuracy: 5950/10000 (59.50%)

Epoch: 175
Loss: 1.290 | Acc: 70.312% (45/64)
Loss: 0.986 | Acc: 75.789% (4899/6464)
Loss: 0.974 | Acc: 76.065% (9785/12864)
Loss: 0.983 | Acc: 75.815% (14605/19264)
Loss: 0.990 | Acc: 75.697% (19427/25664)
Loss: 0.987 | Acc: 75.642% (24254/32064)
Loss: 0.990 | Acc: 75.543% (29057/38464)
Loss: 0.996 | Acc: 75.399% (33827/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1999, Accuracy: 6917/10000 (69.17%)

Epoch: 176
Loss: 1.127 | Acc: 71.875% (46/64)
Loss: 0.991 | Acc: 75.526% (4882/6464)
Loss: 0.995 | Acc: 75.326% (9690/12864)
Loss: 0.989 | Acc: 75.436% (14532/19264)
Loss: 0.991 | Acc: 75.390% (19348/25664)
Loss: 0.991 | Acc: 75.390% (24173/32064)
Loss: 0.987 | Acc: 75.588% (29074/38464)
Loss: 0.986 | Acc: 75.591% (33913/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2954, Accuracy: 6579/10000 (65.79%)

Epoch: 177
Loss: 0.926 | Acc: 79.688% (51/64)
Loss: 0.987 | Acc: 75.774% (4898/6464)
Loss: 0.972 | Acc: 75.995% (9776/12864)
Loss: 0.976 | Acc: 75.955% (14632/19264)
Loss: 0.978 | Acc: 75.885% (19475/25664)
Loss: 0.983 | Acc: 75.702% (24273/32064)
Loss: 0.986 | Acc: 75.679% (29109/38464)
Loss: 0.981 | Acc: 75.822% (34017/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6728, Accuracy: 5360/10000 (53.60%)

Epoch: 178
Loss: 0.817 | Acc: 76.562% (49/64)
Loss: 0.922 | Acc: 77.553% (5013/6464)
Loss: 0.941 | Acc: 76.967% (9901/12864)
Loss: 0.950 | Acc: 76.734% (14782/19264)
Loss: 0.954 | Acc: 76.586% (19655/25664)
Loss: 0.957 | Acc: 76.519% (24535/32064)
Loss: 0.957 | Acc: 76.594% (29461/38464)
Loss: 0.962 | Acc: 76.447% (34297/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4102, Accuracy: 6178/10000 (61.78%)

Epoch: 179
Loss: 0.984 | Acc: 76.562% (49/64)
Loss: 0.964 | Acc: 76.315% (4933/6464)
Loss: 0.951 | Acc: 76.570% (9850/12864)
Loss: 0.944 | Acc: 76.739% (14783/19264)
Loss: 0.947 | Acc: 76.691% (19682/25664)
Loss: 0.944 | Acc: 76.834% (24636/32064)
Loss: 0.940 | Acc: 76.973% (29607/38464)
Loss: 0.944 | Acc: 76.886% (34494/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2427, Accuracy: 6794/10000 (67.94%)

Epoch: 180
Loss: 0.694 | Acc: 81.250% (52/64)
Loss: 0.922 | Acc: 77.398% (5003/6464)
Loss: 0.930 | Acc: 77.169% (9927/12864)
Loss: 0.921 | Acc: 77.367% (14904/19264)
Loss: 0.921 | Acc: 77.459% (19879/25664)
Loss: 0.926 | Acc: 77.308% (24788/32064)
Loss: 0.930 | Acc: 77.251% (29714/38464)
Loss: 0.932 | Acc: 77.225% (34646/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1725, Accuracy: 7057/10000 (70.57%)

Epoch: 181
Loss: 0.990 | Acc: 71.875% (46/64)
Loss: 0.899 | Acc: 77.986% (5041/6464)
Loss: 0.891 | Acc: 78.234% (10064/12864)
Loss: 0.898 | Acc: 78.073% (15040/19264)
Loss: 0.905 | Acc: 77.954% (20006/25664)
Loss: 0.905 | Acc: 78.003% (25011/32064)
Loss: 0.912 | Acc: 77.831% (29937/38464)
Loss: 0.917 | Acc: 77.742% (34878/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3137, Accuracy: 6519/10000 (65.19%)

Epoch: 182
Loss: 1.187 | Acc: 64.062% (41/64)
Loss: 0.897 | Acc: 77.769% (5027/6464)
Loss: 0.871 | Acc: 78.553% (10105/12864)
Loss: 0.884 | Acc: 78.218% (15068/19264)
Loss: 0.889 | Acc: 78.121% (20049/25664)
Loss: 0.896 | Acc: 78.013% (25014/32064)
Loss: 0.898 | Acc: 77.982% (29995/38464)
Loss: 0.900 | Acc: 78.018% (35002/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2362, Accuracy: 6926/10000 (69.26%)

Epoch: 183
Loss: 0.913 | Acc: 79.688% (51/64)
Loss: 0.856 | Acc: 78.960% (5104/6464)
Loss: 0.863 | Acc: 79.058% (10170/12864)
Loss: 0.873 | Acc: 78.769% (15174/19264)
Loss: 0.876 | Acc: 78.745% (20209/25664)
Loss: 0.877 | Acc: 78.668% (25224/32064)
Loss: 0.881 | Acc: 78.546% (30212/38464)
Loss: 0.883 | Acc: 78.531% (35232/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1766, Accuracy: 7129/10000 (71.29%)

Epoch: 184
Loss: 0.798 | Acc: 81.250% (52/64)
Loss: 0.844 | Acc: 79.502% (5139/6464)
Loss: 0.853 | Acc: 79.198% (10188/12864)
Loss: 0.862 | Acc: 78.945% (15208/19264)
Loss: 0.858 | Acc: 79.084% (20296/25664)
Loss: 0.855 | Acc: 79.139% (25375/32064)
Loss: 0.856 | Acc: 79.103% (30426/38464)
Loss: 0.856 | Acc: 79.130% (35501/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1806, Accuracy: 7157/10000 (71.57%)

Epoch: 185
Loss: 0.895 | Acc: 76.562% (49/64)
Loss: 0.797 | Acc: 80.337% (5193/6464)
Loss: 0.806 | Acc: 80.208% (10318/12864)
Loss: 0.806 | Acc: 80.264% (15462/19264)
Loss: 0.820 | Acc: 79.902% (20506/25664)
Loss: 0.826 | Acc: 79.697% (25554/32064)
Loss: 0.827 | Acc: 79.760% (30679/38464)
Loss: 0.832 | Acc: 79.627% (35724/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2694, Accuracy: 6816/10000 (68.16%)

Epoch: 186
Loss: 0.464 | Acc: 90.625% (58/64)
Loss: 0.778 | Acc: 80.832% (5225/6464)
Loss: 0.791 | Acc: 80.644% (10374/12864)
Loss: 0.802 | Acc: 80.502% (15508/19264)
Loss: 0.807 | Acc: 80.354% (20622/25664)
Loss: 0.810 | Acc: 80.286% (25743/32064)
Loss: 0.808 | Acc: 80.278% (30878/38464)
Loss: 0.808 | Acc: 80.274% (36014/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2306, Accuracy: 7086/10000 (70.86%)

Epoch: 187
Loss: 0.635 | Acc: 84.375% (54/64)
Loss: 0.776 | Acc: 80.863% (5227/6464)
Loss: 0.776 | Acc: 80.947% (10413/12864)
Loss: 0.771 | Acc: 80.939% (15592/19264)
Loss: 0.776 | Acc: 80.821% (20742/25664)
Loss: 0.777 | Acc: 80.832% (25918/32064)
Loss: 0.781 | Acc: 80.818% (31086/38464)
Loss: 0.783 | Acc: 80.782% (36242/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2411, Accuracy: 7131/10000 (71.31%)

Epoch: 188
Loss: 0.599 | Acc: 87.500% (56/64)
Loss: 0.750 | Acc: 81.343% (5258/6464)
Loss: 0.742 | Acc: 81.576% (10494/12864)
Loss: 0.747 | Acc: 81.307% (15663/19264)
Loss: 0.746 | Acc: 81.453% (20904/25664)
Loss: 0.747 | Acc: 81.534% (26143/32064)
Loss: 0.744 | Acc: 81.570% (31375/38464)
Loss: 0.747 | Acc: 81.491% (36560/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2237, Accuracy: 7242/10000 (72.42%)

Epoch: 189
Loss: 0.579 | Acc: 84.375% (54/64)
Loss: 0.679 | Acc: 82.936% (5361/6464)
Loss: 0.685 | Acc: 82.758% (10646/12864)
Loss: 0.692 | Acc: 82.698% (15931/19264)
Loss: 0.697 | Acc: 82.637% (21208/25664)
Loss: 0.700 | Acc: 82.473% (26444/32064)
Loss: 0.704 | Acc: 82.342% (31672/38464)
Loss: 0.709 | Acc: 82.177% (36868/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2522, Accuracy: 7285/10000 (72.85%)

Epoch: 190
Loss: 0.798 | Acc: 75.000% (48/64)
Loss: 0.643 | Acc: 83.571% (5402/6464)
Loss: 0.645 | Acc: 83.644% (10760/12864)
Loss: 0.653 | Acc: 83.435% (16073/19264)
Loss: 0.657 | Acc: 83.327% (21385/25664)
Loss: 0.653 | Acc: 83.474% (26765/32064)
Loss: 0.657 | Acc: 83.322% (32049/38464)
Loss: 0.661 | Acc: 83.254% (37351/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3112, Accuracy: 7046/10000 (70.46%)

Epoch: 191
Loss: 0.808 | Acc: 78.125% (50/64)
Loss: 0.604 | Acc: 84.390% (5455/6464)
Loss: 0.599 | Acc: 84.515% (10872/12864)
Loss: 0.604 | Acc: 84.401% (16259/19264)
Loss: 0.608 | Acc: 84.332% (21643/25664)
Loss: 0.610 | Acc: 84.344% (27044/32064)
Loss: 0.618 | Acc: 84.105% (32350/38464)
Loss: 0.619 | Acc: 84.058% (37712/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3252, Accuracy: 7095/10000 (70.95%)

Epoch: 192
Loss: 0.691 | Acc: 82.812% (53/64)
Loss: 0.573 | Acc: 85.118% (5502/6464)
Loss: 0.563 | Acc: 85.168% (10956/12864)
Loss: 0.565 | Acc: 85.071% (16388/19264)
Loss: 0.568 | Acc: 85.010% (21817/25664)
Loss: 0.571 | Acc: 84.927% (27231/32064)
Loss: 0.569 | Acc: 85.012% (32699/38464)
Loss: 0.571 | Acc: 84.923% (38100/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3835, Accuracy: 7146/10000 (71.46%)

Epoch: 193
Loss: 0.488 | Acc: 87.500% (56/64)
Loss: 0.510 | Acc: 86.231% (5574/6464)
Loss: 0.520 | Acc: 86.046% (11069/12864)
Loss: 0.520 | Acc: 85.979% (16563/19264)
Loss: 0.524 | Acc: 85.891% (22043/25664)
Loss: 0.523 | Acc: 85.903% (27544/32064)
Loss: 0.519 | Acc: 85.997% (33078/38464)
Loss: 0.519 | Acc: 86.044% (38603/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4168, Accuracy: 7097/10000 (70.97%)

Epoch: 194
Loss: 0.462 | Acc: 84.375% (54/64)
Loss: 0.467 | Acc: 87.005% (5624/6464)
Loss: 0.461 | Acc: 87.142% (11210/12864)
Loss: 0.459 | Acc: 87.370% (16831/19264)
Loss: 0.463 | Acc: 87.282% (22400/25664)
Loss: 0.461 | Acc: 87.338% (28004/32064)
Loss: 0.464 | Acc: 87.300% (33579/38464)
Loss: 0.465 | Acc: 87.328% (39179/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4403, Accuracy: 7117/10000 (71.17%)

Epoch: 195
Loss: 0.367 | Acc: 87.500% (56/64)
Loss: 0.411 | Acc: 88.552% (5724/6464)
Loss: 0.419 | Acc: 88.511% (11386/12864)
Loss: 0.430 | Acc: 88.242% (16999/19264)
Loss: 0.434 | Acc: 88.127% (22617/25664)
Loss: 0.440 | Acc: 87.971% (28207/32064)
Loss: 0.443 | Acc: 87.835% (33785/38464)
Loss: 0.447 | Acc: 87.734% (39361/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4016, Accuracy: 7187/10000 (71.87%)

Epoch: 196
Loss: 0.680 | Acc: 76.562% (49/64)
Loss: 0.424 | Acc: 88.382% (5713/6464)
Loss: 0.432 | Acc: 88.052% (11327/12864)
Loss: 0.448 | Acc: 87.666% (16888/19264)
Loss: 0.449 | Acc: 87.738% (22517/25664)
Loss: 0.448 | Acc: 87.746% (28135/32064)
Loss: 0.449 | Acc: 87.711% (33737/38464)
Loss: 0.449 | Acc: 87.712% (39351/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4004, Accuracy: 7108/10000 (71.08%)

Epoch: 197
Loss: 0.509 | Acc: 82.812% (53/64)
Loss: 0.423 | Acc: 88.397% (5714/6464)
Loss: 0.427 | Acc: 88.332% (11363/12864)
Loss: 0.430 | Acc: 88.268% (17004/19264)
Loss: 0.438 | Acc: 88.010% (22587/25664)
Loss: 0.439 | Acc: 87.915% (28189/32064)
Loss: 0.440 | Acc: 87.913% (33815/38464)
Loss: 0.441 | Acc: 87.910% (39440/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3939, Accuracy: 7109/10000 (71.09%)
torch.Size([100, 10])
Test set: Average loss: 1.3939, Accuracy: 7109/10000 (71.09%)

Epoch: 198
Loss: 0.414 | Acc: 87.500% (56/64)
Loss: 0.445 | Acc: 87.840% (5678/6464)
Loss: 0.437 | Acc: 88.060% (11328/12864)
Loss: 0.433 | Acc: 88.035% (16959/19264)
Loss: 0.435 | Acc: 87.964% (22575/25664)
Loss: 0.435 | Acc: 87.958% (28203/32064)
Loss: 0.436 | Acc: 87.913% (33815/38464)
Loss: 0.434 | Acc: 87.950% (39458/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3932, Accuracy: 7110/10000 (71.10%)
torch.Size([100, 10])
Test set: Average loss: 1.3932, Accuracy: 7110/10000 (71.10%)

Epoch: 199
Loss: 0.293 | Acc: 92.188% (59/64)
Loss: 0.440 | Acc: 87.717% (5670/6464)
Loss: 0.428 | Acc: 88.005% (11321/12864)
Loss: 0.432 | Acc: 87.910% (16935/19264)
Loss: 0.428 | Acc: 88.057% (22599/25664)
Loss: 0.431 | Acc: 87.968% (28206/32064)
Loss: 0.426 | Acc: 88.166% (33912/38464)
Loss: 0.427 | Acc: 88.142% (39544/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4015, Accuracy: 7108/10000 (71.08%)
torch.Size([100, 10])
Test set: Average loss: 1.4015, Accuracy: 7108/10000 (71.08%)
7475
10000
-1.1728447675704956
