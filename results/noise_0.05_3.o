==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.355 | Acc: 15.625% (10/64)
Loss: 2.891 | Acc: 16.708% (1080/6464)
Loss: 2.479 | Acc: 20.204% (2599/12864)
Loss: 2.312 | Acc: 22.316% (4299/19264)
Loss: 2.210 | Acc: 24.092% (6183/25664)
Loss: 2.135 | Acc: 25.724% (8248/32064)
Loss: 2.077 | Acc: 27.134% (10437/38464)
Loss: 2.028 | Acc: 28.546% (12807/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3188, Accuracy: 2631/10000 (26.31%)

Epoch: 1
Loss: 2.173 | Acc: 29.688% (19/64)
Loss: 1.677 | Acc: 39.295% (2540/6464)
Loss: 1.658 | Acc: 39.988% (5144/12864)
Loss: 1.640 | Acc: 40.615% (7824/19264)
Loss: 1.628 | Acc: 41.081% (10543/25664)
Loss: 1.609 | Acc: 41.969% (13457/32064)
Loss: 1.594 | Acc: 42.684% (16418/38464)
Loss: 1.581 | Acc: 43.380% (19462/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6034, Accuracy: 4221/10000 (42.21%)

Epoch: 2
Loss: 1.395 | Acc: 54.688% (35/64)
Loss: 1.430 | Acc: 50.031% (3234/6464)
Loss: 1.434 | Acc: 49.992% (6431/12864)
Loss: 1.416 | Acc: 50.893% (9804/19264)
Loss: 1.395 | Acc: 51.718% (13273/25664)
Loss: 1.380 | Acc: 52.554% (16851/32064)
Loss: 1.368 | Acc: 53.052% (20406/38464)
Loss: 1.360 | Acc: 53.395% (23955/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3393, Accuracy: 5544/10000 (55.44%)

Epoch: 3
Loss: 1.153 | Acc: 62.500% (40/64)
Loss: 1.252 | Acc: 58.942% (3810/6464)
Loss: 1.248 | Acc: 58.901% (7577/12864)
Loss: 1.226 | Acc: 59.505% (11463/19264)
Loss: 1.211 | Acc: 60.030% (15406/25664)
Loss: 1.201 | Acc: 60.339% (19347/32064)
Loss: 1.191 | Acc: 60.727% (23358/38464)
Loss: 1.182 | Acc: 61.138% (27429/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9814, Accuracy: 3942/10000 (39.42%)

Epoch: 4
Loss: 1.388 | Acc: 50.000% (32/64)
Loss: 1.102 | Acc: 64.155% (4147/6464)
Loss: 1.087 | Acc: 64.723% (8326/12864)
Loss: 1.078 | Acc: 65.158% (12552/19264)
Loss: 1.072 | Acc: 65.395% (16783/25664)
Loss: 1.064 | Acc: 65.800% (21098/32064)
Loss: 1.054 | Acc: 66.119% (25432/38464)
Loss: 1.047 | Acc: 66.425% (29801/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2820, Accuracy: 5796/10000 (57.96%)

Epoch: 5
Loss: 1.457 | Acc: 50.000% (32/64)
Loss: 0.952 | Acc: 69.524% (4494/6464)
Loss: 0.962 | Acc: 69.543% (8946/12864)
Loss: 0.956 | Acc: 70.084% (13501/19264)
Loss: 0.953 | Acc: 70.402% (18068/25664)
Loss: 0.944 | Acc: 70.631% (22647/32064)
Loss: 0.941 | Acc: 70.866% (27258/38464)
Loss: 0.937 | Acc: 70.992% (31850/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2006, Accuracy: 6337/10000 (63.37%)

Epoch: 6
Loss: 0.910 | Acc: 76.562% (49/64)
Loss: 0.876 | Acc: 73.639% (4760/6464)
Loss: 0.883 | Acc: 73.259% (9424/12864)
Loss: 0.878 | Acc: 73.277% (14116/19264)
Loss: 0.877 | Acc: 73.348% (18824/25664)
Loss: 0.870 | Acc: 73.503% (23568/32064)
Loss: 0.870 | Acc: 73.586% (28304/38464)
Loss: 0.869 | Acc: 73.672% (33052/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3314, Accuracy: 5866/10000 (58.66%)

Epoch: 7
Loss: 1.153 | Acc: 65.625% (42/64)
Loss: 0.832 | Acc: 75.093% (4854/6464)
Loss: 0.831 | Acc: 75.039% (9653/12864)
Loss: 0.836 | Acc: 75.109% (14469/19264)
Loss: 0.834 | Acc: 75.327% (19332/25664)
Loss: 0.828 | Acc: 75.443% (24190/32064)
Loss: 0.829 | Acc: 75.320% (28971/38464)
Loss: 0.823 | Acc: 75.437% (33844/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1527, Accuracy: 6519/10000 (65.19%)

Epoch: 8
Loss: 1.110 | Acc: 68.750% (44/64)
Loss: 0.812 | Acc: 76.439% (4941/6464)
Loss: 0.799 | Acc: 76.500% (9841/12864)
Loss: 0.790 | Acc: 76.723% (14780/19264)
Loss: 0.790 | Acc: 76.707% (19686/25664)
Loss: 0.789 | Acc: 76.631% (24571/32064)
Loss: 0.792 | Acc: 76.573% (29453/38464)
Loss: 0.787 | Acc: 76.759% (34437/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0892, Accuracy: 6782/10000 (67.82%)

Epoch: 9
Loss: 0.861 | Acc: 75.000% (48/64)
Loss: 0.763 | Acc: 77.707% (5023/6464)
Loss: 0.771 | Acc: 77.596% (9982/12864)
Loss: 0.776 | Acc: 77.258% (14883/19264)
Loss: 0.772 | Acc: 77.307% (19840/25664)
Loss: 0.773 | Acc: 77.333% (24796/32064)
Loss: 0.771 | Acc: 77.342% (29749/38464)
Loss: 0.765 | Acc: 77.570% (34801/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1718, Accuracy: 6360/10000 (63.60%)

Epoch: 10
Loss: 0.781 | Acc: 78.125% (50/64)
Loss: 0.750 | Acc: 78.048% (5045/6464)
Loss: 0.732 | Acc: 78.654% (10118/12864)
Loss: 0.742 | Acc: 78.187% (15062/19264)
Loss: 0.738 | Acc: 78.335% (20104/25664)
Loss: 0.741 | Acc: 78.328% (25115/32064)
Loss: 0.743 | Acc: 78.315% (30123/38464)
Loss: 0.743 | Acc: 78.363% (35157/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0133, Accuracy: 7071/10000 (70.71%)

Epoch: 11
Loss: 1.104 | Acc: 64.062% (41/64)
Loss: 0.716 | Acc: 78.960% (5104/6464)
Loss: 0.724 | Acc: 78.840% (10142/12864)
Loss: 0.719 | Acc: 79.142% (15246/19264)
Loss: 0.724 | Acc: 78.947% (20261/25664)
Loss: 0.721 | Acc: 79.067% (25352/32064)
Loss: 0.720 | Acc: 79.084% (30419/38464)
Loss: 0.722 | Acc: 79.066% (35472/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8926, Accuracy: 7388/10000 (73.88%)

Epoch: 12
Loss: 0.688 | Acc: 81.250% (52/64)
Loss: 0.691 | Acc: 80.368% (5195/6464)
Loss: 0.696 | Acc: 80.379% (10340/12864)
Loss: 0.694 | Acc: 80.362% (15481/19264)
Loss: 0.698 | Acc: 80.030% (20539/25664)
Loss: 0.701 | Acc: 80.018% (25657/32064)
Loss: 0.700 | Acc: 80.033% (30784/38464)
Loss: 0.703 | Acc: 79.951% (35869/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6115, Accuracy: 5344/10000 (53.44%)

Epoch: 13
Loss: 0.791 | Acc: 71.875% (46/64)
Loss: 0.689 | Acc: 80.848% (5226/6464)
Loss: 0.688 | Acc: 80.807% (10395/12864)
Loss: 0.687 | Acc: 80.663% (15539/19264)
Loss: 0.690 | Acc: 80.510% (20662/25664)
Loss: 0.684 | Acc: 80.695% (25874/32064)
Loss: 0.685 | Acc: 80.657% (31024/38464)
Loss: 0.686 | Acc: 80.657% (36186/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1717, Accuracy: 6502/10000 (65.02%)

Epoch: 14
Loss: 0.685 | Acc: 79.688% (51/64)
Loss: 0.705 | Acc: 79.734% (5154/6464)
Loss: 0.696 | Acc: 80.107% (10305/12864)
Loss: 0.682 | Acc: 80.580% (15523/19264)
Loss: 0.676 | Acc: 80.751% (20724/25664)
Loss: 0.673 | Acc: 80.957% (25958/32064)
Loss: 0.669 | Acc: 81.003% (31157/38464)
Loss: 0.671 | Acc: 81.009% (36344/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0205, Accuracy: 5186/10000 (51.86%)

Epoch: 15
Loss: 1.229 | Acc: 60.938% (39/64)
Loss: 0.665 | Acc: 81.498% (5268/6464)
Loss: 0.654 | Acc: 81.670% (10506/12864)
Loss: 0.664 | Acc: 81.229% (15648/19264)
Loss: 0.657 | Acc: 81.577% (20936/25664)
Loss: 0.658 | Acc: 81.571% (26155/32064)
Loss: 0.658 | Acc: 81.554% (31369/38464)
Loss: 0.656 | Acc: 81.609% (36613/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7986, Accuracy: 7735/10000 (77.35%)

Epoch: 16
Loss: 0.749 | Acc: 82.812% (53/64)
Loss: 0.619 | Acc: 82.890% (5358/6464)
Loss: 0.616 | Acc: 82.812% (10653/12864)
Loss: 0.627 | Acc: 82.636% (15919/19264)
Loss: 0.633 | Acc: 82.407% (21149/25664)
Loss: 0.631 | Acc: 82.635% (26496/32064)
Loss: 0.633 | Acc: 82.625% (31781/38464)
Loss: 0.635 | Acc: 82.572% (37045/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4244, Accuracy: 6041/10000 (60.41%)

Epoch: 17
Loss: 0.676 | Acc: 76.562% (49/64)
Loss: 0.598 | Acc: 83.710% (5411/6464)
Loss: 0.625 | Acc: 82.789% (10650/12864)
Loss: 0.629 | Acc: 82.631% (15918/19264)
Loss: 0.628 | Acc: 82.575% (21192/25664)
Loss: 0.627 | Acc: 82.650% (26501/32064)
Loss: 0.626 | Acc: 82.693% (31807/38464)
Loss: 0.626 | Acc: 82.665% (37087/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9079, Accuracy: 7361/10000 (73.61%)

Epoch: 18
Loss: 0.674 | Acc: 79.688% (51/64)
Loss: 0.596 | Acc: 83.895% (5423/6464)
Loss: 0.601 | Acc: 83.590% (10753/12864)
Loss: 0.607 | Acc: 83.378% (16062/19264)
Loss: 0.609 | Acc: 83.323% (21384/25664)
Loss: 0.612 | Acc: 83.212% (26681/32064)
Loss: 0.614 | Acc: 83.130% (31975/38464)
Loss: 0.613 | Acc: 83.125% (37293/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8146, Accuracy: 7737/10000 (77.37%)

Epoch: 19
Loss: 0.593 | Acc: 87.500% (56/64)
Loss: 0.592 | Acc: 83.756% (5414/6464)
Loss: 0.584 | Acc: 83.963% (10801/12864)
Loss: 0.578 | Acc: 84.235% (16227/19264)
Loss: 0.582 | Acc: 84.079% (21578/25664)
Loss: 0.590 | Acc: 83.882% (26896/32064)
Loss: 0.595 | Acc: 83.725% (32204/38464)
Loss: 0.596 | Acc: 83.626% (37518/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0998, Accuracy: 6947/10000 (69.47%)

Epoch: 20
Loss: 0.547 | Acc: 87.500% (56/64)
Loss: 0.580 | Acc: 83.973% (5428/6464)
Loss: 0.586 | Acc: 83.738% (10772/12864)
Loss: 0.584 | Acc: 83.788% (16141/19264)
Loss: 0.582 | Acc: 83.935% (21541/25664)
Loss: 0.580 | Acc: 83.938% (26914/32064)
Loss: 0.582 | Acc: 83.995% (32308/38464)
Loss: 0.584 | Acc: 84.034% (37701/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6840, Accuracy: 5370/10000 (53.70%)

Epoch: 21
Loss: 0.568 | Acc: 85.938% (55/64)
Loss: 0.586 | Acc: 84.127% (5438/6464)
Loss: 0.581 | Acc: 84.235% (10836/12864)
Loss: 0.576 | Acc: 84.546% (16287/19264)
Loss: 0.575 | Acc: 84.593% (21710/25664)
Loss: 0.576 | Acc: 84.587% (27122/32064)
Loss: 0.576 | Acc: 84.518% (32509/38464)
Loss: 0.575 | Acc: 84.562% (37938/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4312, Accuracy: 4522/10000 (45.22%)

Epoch: 22
Loss: 0.702 | Acc: 79.688% (51/64)
Loss: 0.551 | Acc: 85.179% (5506/6464)
Loss: 0.569 | Acc: 84.857% (10916/12864)
Loss: 0.564 | Acc: 84.894% (16354/19264)
Loss: 0.567 | Acc: 84.765% (21754/25664)
Loss: 0.562 | Acc: 84.840% (27203/32064)
Loss: 0.562 | Acc: 84.885% (32650/38464)
Loss: 0.561 | Acc: 84.928% (38102/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2520, Accuracy: 6500/10000 (65.00%)

Epoch: 23
Loss: 0.756 | Acc: 79.688% (51/64)
Loss: 0.519 | Acc: 86.262% (5576/6464)
Loss: 0.537 | Acc: 85.782% (11035/12864)
Loss: 0.541 | Acc: 85.610% (16492/19264)
Loss: 0.543 | Acc: 85.563% (21959/25664)
Loss: 0.548 | Acc: 85.423% (27390/32064)
Loss: 0.545 | Acc: 85.553% (32907/38464)
Loss: 0.545 | Acc: 85.530% (38372/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9656, Accuracy: 7103/10000 (71.03%)

Epoch: 24
Loss: 0.696 | Acc: 79.688% (51/64)
Loss: 0.519 | Acc: 86.092% (5565/6464)
Loss: 0.529 | Acc: 85.774% (11034/12864)
Loss: 0.533 | Acc: 85.943% (16556/19264)
Loss: 0.539 | Acc: 85.786% (22016/25664)
Loss: 0.535 | Acc: 85.822% (27518/32064)
Loss: 0.536 | Acc: 85.818% (33009/38464)
Loss: 0.538 | Acc: 85.815% (38500/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2140, Accuracy: 6728/10000 (67.28%)

Epoch: 25
Loss: 0.738 | Acc: 79.688% (51/64)
Loss: 0.521 | Acc: 86.200% (5572/6464)
Loss: 0.525 | Acc: 86.140% (11081/12864)
Loss: 0.524 | Acc: 86.213% (16608/19264)
Loss: 0.521 | Acc: 86.382% (22169/25664)
Loss: 0.519 | Acc: 86.477% (27728/32064)
Loss: 0.522 | Acc: 86.398% (33232/38464)
Loss: 0.524 | Acc: 86.343% (38737/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6087, Accuracy: 5865/10000 (58.65%)

Epoch: 26
Loss: 0.493 | Acc: 84.375% (54/64)
Loss: 0.502 | Acc: 87.144% (5633/6464)
Loss: 0.503 | Acc: 87.189% (11216/12864)
Loss: 0.498 | Acc: 87.246% (16807/19264)
Loss: 0.509 | Acc: 86.919% (22307/25664)
Loss: 0.508 | Acc: 86.911% (27867/32064)
Loss: 0.505 | Acc: 87.029% (33475/38464)
Loss: 0.503 | Acc: 87.023% (39042/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7490, Accuracy: 7937/10000 (79.37%)

Epoch: 27
Loss: 0.437 | Acc: 82.812% (53/64)
Loss: 0.507 | Acc: 87.438% (5652/6464)
Loss: 0.493 | Acc: 87.414% (11245/12864)
Loss: 0.497 | Acc: 87.334% (16824/19264)
Loss: 0.497 | Acc: 87.188% (22376/25664)
Loss: 0.495 | Acc: 87.272% (27983/32064)
Loss: 0.497 | Acc: 87.180% (33533/38464)
Loss: 0.498 | Acc: 87.215% (39128/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0359, Accuracy: 7178/10000 (71.78%)

Epoch: 28
Loss: 0.795 | Acc: 76.562% (49/64)
Loss: 0.462 | Acc: 88.057% (5692/6464)
Loss: 0.477 | Acc: 87.648% (11275/12864)
Loss: 0.472 | Acc: 87.806% (16915/19264)
Loss: 0.478 | Acc: 87.609% (22484/25664)
Loss: 0.479 | Acc: 87.612% (28092/32064)
Loss: 0.481 | Acc: 87.614% (33700/38464)
Loss: 0.480 | Acc: 87.710% (39350/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0026, Accuracy: 7271/10000 (72.71%)

Epoch: 29
Loss: 0.379 | Acc: 90.625% (58/64)
Loss: 0.459 | Acc: 88.475% (5719/6464)
Loss: 0.467 | Acc: 88.386% (11370/12864)
Loss: 0.458 | Acc: 88.549% (17058/19264)
Loss: 0.461 | Acc: 88.385% (22683/25664)
Loss: 0.463 | Acc: 88.286% (28308/32064)
Loss: 0.465 | Acc: 88.244% (33942/38464)
Loss: 0.465 | Acc: 88.236% (39586/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6691, Accuracy: 8222/10000 (82.22%)

Epoch: 30
Loss: 0.409 | Acc: 87.500% (56/64)
Loss: 0.433 | Acc: 89.341% (5775/6464)
Loss: 0.435 | Acc: 89.265% (11483/12864)
Loss: 0.439 | Acc: 89.151% (17174/19264)
Loss: 0.440 | Acc: 89.043% (22852/25664)
Loss: 0.449 | Acc: 88.797% (28472/32064)
Loss: 0.451 | Acc: 88.761% (34141/38464)
Loss: 0.451 | Acc: 88.799% (39839/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7491, Accuracy: 8002/10000 (80.02%)

Epoch: 31
Loss: 0.369 | Acc: 92.188% (59/64)
Loss: 0.435 | Acc: 89.140% (5762/6464)
Loss: 0.437 | Acc: 88.993% (11448/12864)
Loss: 0.435 | Acc: 89.177% (17179/19264)
Loss: 0.435 | Acc: 89.175% (22886/25664)
Loss: 0.437 | Acc: 89.144% (28583/32064)
Loss: 0.433 | Acc: 89.286% (34343/38464)
Loss: 0.435 | Acc: 89.161% (40001/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7649, Accuracy: 8015/10000 (80.15%)

Epoch: 32
Loss: 0.538 | Acc: 85.938% (55/64)
Loss: 0.407 | Acc: 89.743% (5801/6464)
Loss: 0.416 | Acc: 89.529% (11517/12864)
Loss: 0.412 | Acc: 89.763% (17292/19264)
Loss: 0.408 | Acc: 89.861% (23062/25664)
Loss: 0.408 | Acc: 89.858% (28812/32064)
Loss: 0.412 | Acc: 89.814% (34546/38464)
Loss: 0.411 | Acc: 89.869% (40319/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7992, Accuracy: 7858/10000 (78.58%)

Epoch: 33
Loss: 0.370 | Acc: 92.188% (59/64)
Loss: 0.377 | Acc: 90.347% (5840/6464)
Loss: 0.398 | Acc: 90.197% (11603/12864)
Loss: 0.403 | Acc: 90.106% (17358/19264)
Loss: 0.403 | Acc: 90.044% (23109/25664)
Loss: 0.398 | Acc: 90.148% (28905/32064)
Loss: 0.399 | Acc: 90.087% (34651/38464)
Loss: 0.398 | Acc: 90.115% (40429/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7669, Accuracy: 7907/10000 (79.07%)

Epoch: 34
Loss: 0.433 | Acc: 92.188% (59/64)
Loss: 0.382 | Acc: 90.424% (5845/6464)
Loss: 0.373 | Acc: 90.812% (11682/12864)
Loss: 0.372 | Acc: 90.905% (17512/19264)
Loss: 0.373 | Acc: 90.855% (23317/25664)
Loss: 0.376 | Acc: 90.818% (29120/32064)
Loss: 0.376 | Acc: 90.859% (34948/38464)
Loss: 0.378 | Acc: 90.857% (40762/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5751, Accuracy: 8582/10000 (85.82%)

Epoch: 35
Loss: 0.280 | Acc: 92.188% (59/64)
Loss: 0.332 | Acc: 91.631% (5923/6464)
Loss: 0.351 | Acc: 91.457% (11765/12864)
Loss: 0.353 | Acc: 91.476% (17622/19264)
Loss: 0.353 | Acc: 91.474% (23476/25664)
Loss: 0.353 | Acc: 91.495% (29337/32064)
Loss: 0.359 | Acc: 91.392% (35153/38464)
Loss: 0.361 | Acc: 91.343% (40980/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5506, Accuracy: 8640/10000 (86.40%)

Epoch: 36
Loss: 0.317 | Acc: 92.188% (59/64)
Loss: 0.337 | Acc: 92.048% (5950/6464)
Loss: 0.334 | Acc: 92.032% (11839/12864)
Loss: 0.335 | Acc: 92.001% (17723/19264)
Loss: 0.338 | Acc: 91.860% (23575/25664)
Loss: 0.340 | Acc: 91.857% (29453/32064)
Loss: 0.340 | Acc: 91.904% (35350/38464)
Loss: 0.341 | Acc: 91.891% (41226/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7116, Accuracy: 8147/10000 (81.47%)

Epoch: 37
Loss: 0.443 | Acc: 87.500% (56/64)
Loss: 0.309 | Acc: 92.775% (5997/6464)
Loss: 0.313 | Acc: 92.716% (11927/12864)
Loss: 0.311 | Acc: 92.743% (17866/19264)
Loss: 0.305 | Acc: 92.865% (23833/25664)
Loss: 0.314 | Acc: 92.605% (29693/32064)
Loss: 0.317 | Acc: 92.554% (35600/38464)
Loss: 0.320 | Acc: 92.451% (41477/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7134, Accuracy: 8243/10000 (82.43%)

Epoch: 38
Loss: 0.716 | Acc: 82.812% (53/64)
Loss: 0.294 | Acc: 92.961% (6009/6464)
Loss: 0.293 | Acc: 93.089% (11975/12864)
Loss: 0.293 | Acc: 93.127% (17940/19264)
Loss: 0.293 | Acc: 93.068% (23885/25664)
Loss: 0.297 | Acc: 92.980% (29813/32064)
Loss: 0.297 | Acc: 92.962% (35757/38464)
Loss: 0.296 | Acc: 93.008% (41727/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6234, Accuracy: 8502/10000 (85.02%)

Epoch: 39
Loss: 0.203 | Acc: 95.312% (61/64)
Loss: 0.268 | Acc: 93.781% (6062/6464)
Loss: 0.266 | Acc: 93.820% (12069/12864)
Loss: 0.263 | Acc: 93.968% (18102/19264)
Loss: 0.264 | Acc: 93.918% (24103/25664)
Loss: 0.267 | Acc: 93.828% (30085/32064)
Loss: 0.267 | Acc: 93.799% (36079/38464)
Loss: 0.270 | Acc: 93.750% (42060/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7045, Accuracy: 8258/10000 (82.58%)

Epoch: 40
Loss: 0.172 | Acc: 96.875% (62/64)
Loss: 0.255 | Acc: 94.183% (6088/6464)
Loss: 0.250 | Acc: 94.178% (12115/12864)
Loss: 0.250 | Acc: 94.222% (18151/19264)
Loss: 0.253 | Acc: 94.128% (24157/25664)
Loss: 0.249 | Acc: 94.224% (30212/32064)
Loss: 0.249 | Acc: 94.197% (36232/38464)
Loss: 0.249 | Acc: 94.196% (42260/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6244, Accuracy: 8641/10000 (86.41%)

Epoch: 41
Loss: 0.436 | Acc: 89.062% (57/64)
Loss: 0.223 | Acc: 94.616% (6116/6464)
Loss: 0.226 | Acc: 94.660% (12177/12864)
Loss: 0.222 | Acc: 94.783% (18259/19264)
Loss: 0.225 | Acc: 94.763% (24320/25664)
Loss: 0.223 | Acc: 94.776% (30389/32064)
Loss: 0.224 | Acc: 94.764% (36450/38464)
Loss: 0.223 | Acc: 94.782% (42523/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6151, Accuracy: 8692/10000 (86.92%)

Epoch: 42
Loss: 0.127 | Acc: 98.438% (63/64)
Loss: 0.191 | Acc: 95.591% (6179/6464)
Loss: 0.199 | Acc: 95.375% (12269/12864)
Loss: 0.203 | Acc: 95.297% (18358/19264)
Loss: 0.202 | Acc: 95.285% (24454/25664)
Loss: 0.199 | Acc: 95.350% (30573/32064)
Loss: 0.202 | Acc: 95.299% (36656/38464)
Loss: 0.201 | Acc: 95.324% (42766/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6109, Accuracy: 8748/10000 (87.48%)

Epoch: 43
Loss: 0.224 | Acc: 93.750% (60/64)
Loss: 0.171 | Acc: 95.808% (6193/6464)
Loss: 0.177 | Acc: 95.693% (12310/12864)
Loss: 0.177 | Acc: 95.728% (18441/19264)
Loss: 0.177 | Acc: 95.733% (24569/25664)
Loss: 0.178 | Acc: 95.721% (30692/32064)
Loss: 0.181 | Acc: 95.656% (36793/38464)
Loss: 0.178 | Acc: 95.725% (42946/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6068, Accuracy: 8775/10000 (87.75%)

Epoch: 44
Loss: 0.140 | Acc: 98.438% (63/64)
Loss: 0.142 | Acc: 96.535% (6240/6464)
Loss: 0.154 | Acc: 96.238% (12380/12864)
Loss: 0.151 | Acc: 96.356% (18562/19264)
Loss: 0.152 | Acc: 96.345% (24726/25664)
Loss: 0.154 | Acc: 96.301% (30878/32064)
Loss: 0.155 | Acc: 96.293% (37038/38464)
Loss: 0.153 | Acc: 96.349% (43226/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5943, Accuracy: 8804/10000 (88.04%)

Epoch: 45
Loss: 0.117 | Acc: 98.438% (63/64)
Loss: 0.134 | Acc: 96.627% (6246/6464)
Loss: 0.152 | Acc: 96.362% (12396/12864)
Loss: 0.155 | Acc: 96.309% (18553/19264)
Loss: 0.166 | Acc: 96.072% (24656/25664)
Loss: 0.170 | Acc: 96.002% (30782/32064)
Loss: 0.178 | Acc: 95.825% (36858/38464)
Loss: 0.184 | Acc: 95.745% (42955/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5426, Accuracy: 8751/10000 (87.51%)

Epoch: 46
Loss: 0.209 | Acc: 95.312% (61/64)
Loss: 0.229 | Acc: 94.864% (6132/6464)
Loss: 0.233 | Acc: 94.815% (12197/12864)
Loss: 0.233 | Acc: 94.845% (18271/19264)
Loss: 0.236 | Acc: 94.666% (24295/25664)
Loss: 0.239 | Acc: 94.595% (30331/32064)
Loss: 0.241 | Acc: 94.626% (36397/38464)
Loss: 0.244 | Acc: 94.548% (42418/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5374, Accuracy: 8733/10000 (87.33%)

Epoch: 47
Loss: 0.106 | Acc: 98.438% (63/64)
Loss: 0.255 | Acc: 94.431% (6104/6464)
Loss: 0.258 | Acc: 94.185% (12116/12864)
Loss: 0.260 | Acc: 94.124% (18132/19264)
Loss: 0.262 | Acc: 94.089% (24147/25664)
Loss: 0.267 | Acc: 93.940% (30121/32064)
Loss: 0.268 | Acc: 93.932% (36130/38464)
Loss: 0.269 | Acc: 93.946% (42148/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5371, Accuracy: 8720/10000 (87.20%)
torch.Size([100, 10])
Test set: Average loss: 0.5371, Accuracy: 8720/10000 (87.20%)

Epoch: 48
Loss: 0.179 | Acc: 96.875% (62/64)
Loss: 0.266 | Acc: 94.075% (6081/6464)
Loss: 0.267 | Acc: 94.255% (12125/12864)
Loss: 0.271 | Acc: 94.103% (18128/19264)
Loss: 0.273 | Acc: 94.023% (24130/25664)
Loss: 0.275 | Acc: 93.937% (30120/32064)
Loss: 0.277 | Acc: 93.867% (36105/38464)
Loss: 0.276 | Acc: 93.875% (42116/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5365, Accuracy: 8726/10000 (87.26%)
torch.Size([100, 10])
Test set: Average loss: 0.5365, Accuracy: 8726/10000 (87.26%)

Epoch: 49
Loss: 0.357 | Acc: 90.625% (58/64)
Loss: 0.280 | Acc: 93.982% (6075/6464)
Loss: 0.281 | Acc: 93.781% (12064/12864)
Loss: 0.275 | Acc: 93.921% (18093/19264)
Loss: 0.274 | Acc: 93.902% (24099/25664)
Loss: 0.273 | Acc: 93.943% (30122/32064)
Loss: 0.273 | Acc: 93.989% (36152/38464)
Loss: 0.275 | Acc: 93.910% (42132/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5380, Accuracy: 8733/10000 (87.33%)
torch.Size([100, 10])
Test set: Average loss: 0.5380, Accuracy: 8733/10000 (87.33%)

Epoch: 50
Loss: 0.205 | Acc: 96.875% (62/64)
Loss: 1.369 | Acc: 54.920% (3550/6464)
Loss: 1.132 | Acc: 63.464% (8164/12864)
Loss: 1.026 | Acc: 67.764% (13054/19264)
Loss: 0.968 | Acc: 70.207% (18018/25664)
Loss: 0.925 | Acc: 71.863% (23042/32064)
Loss: 0.894 | Acc: 73.009% (28082/38464)
Loss: 0.868 | Acc: 74.001% (33200/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1589, Accuracy: 4376/10000 (43.76%)

Epoch: 51
Loss: 0.803 | Acc: 75.000% (48/64)
Loss: 0.681 | Acc: 79.780% (5157/6464)
Loss: 0.679 | Acc: 80.333% (10334/12864)
Loss: 0.683 | Acc: 80.342% (15477/19264)
Loss: 0.685 | Acc: 80.272% (20601/25664)
Loss: 0.677 | Acc: 80.664% (25864/32064)
Loss: 0.674 | Acc: 80.759% (31063/38464)
Loss: 0.672 | Acc: 80.860% (36277/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3485, Accuracy: 6181/10000 (61.81%)

Epoch: 52
Loss: 0.838 | Acc: 75.000% (48/64)
Loss: 0.648 | Acc: 81.683% (5280/6464)
Loss: 0.638 | Acc: 81.810% (10524/12864)
Loss: 0.637 | Acc: 81.831% (15764/19264)
Loss: 0.637 | Acc: 82.049% (21057/25664)
Loss: 0.638 | Acc: 82.070% (26315/32064)
Loss: 0.638 | Acc: 82.152% (31599/38464)
Loss: 0.639 | Acc: 82.148% (36855/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8140, Accuracy: 7689/10000 (76.89%)

Epoch: 53
Loss: 0.851 | Acc: 75.000% (48/64)
Loss: 0.604 | Acc: 83.493% (5397/6464)
Loss: 0.608 | Acc: 83.411% (10730/12864)
Loss: 0.614 | Acc: 83.171% (16022/19264)
Loss: 0.619 | Acc: 83.050% (21314/25664)
Loss: 0.623 | Acc: 82.900% (26581/32064)
Loss: 0.625 | Acc: 82.784% (31842/38464)
Loss: 0.623 | Acc: 82.864% (37176/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2039, Accuracy: 6544/10000 (65.44%)

Epoch: 54
Loss: 0.864 | Acc: 73.438% (47/64)
Loss: 0.603 | Acc: 82.890% (5358/6464)
Loss: 0.604 | Acc: 83.131% (10694/12864)
Loss: 0.601 | Acc: 83.217% (16031/19264)
Loss: 0.608 | Acc: 82.968% (21293/25664)
Loss: 0.616 | Acc: 82.725% (26525/32064)
Loss: 0.620 | Acc: 82.690% (31806/38464)
Loss: 0.621 | Acc: 82.743% (37122/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7974, Accuracy: 7772/10000 (77.72%)

Epoch: 55
Loss: 0.666 | Acc: 85.938% (55/64)
Loss: 0.605 | Acc: 83.292% (5384/6464)
Loss: 0.608 | Acc: 83.248% (10709/12864)
Loss: 0.609 | Acc: 83.181% (16024/19264)
Loss: 0.613 | Acc: 83.198% (21352/25664)
Loss: 0.608 | Acc: 83.330% (26719/32064)
Loss: 0.609 | Acc: 83.241% (32018/38464)
Loss: 0.611 | Acc: 83.183% (37319/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4605, Accuracy: 6049/10000 (60.49%)

Epoch: 56
Loss: 0.522 | Acc: 84.375% (54/64)
Loss: 0.603 | Acc: 84.174% (5441/6464)
Loss: 0.616 | Acc: 83.318% (10718/12864)
Loss: 0.607 | Acc: 83.560% (16097/19264)
Loss: 0.602 | Acc: 83.557% (21444/25664)
Loss: 0.606 | Acc: 83.511% (26777/32064)
Loss: 0.606 | Acc: 83.465% (32104/38464)
Loss: 0.610 | Acc: 83.339% (37389/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9644, Accuracy: 7225/10000 (72.25%)

Epoch: 57
Loss: 0.775 | Acc: 78.125% (50/64)
Loss: 0.610 | Acc: 83.184% (5377/6464)
Loss: 0.603 | Acc: 83.411% (10730/12864)
Loss: 0.602 | Acc: 83.602% (16105/19264)
Loss: 0.602 | Acc: 83.627% (21462/25664)
Loss: 0.601 | Acc: 83.598% (26805/32064)
Loss: 0.605 | Acc: 83.520% (32125/38464)
Loss: 0.605 | Acc: 83.581% (37498/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0202, Accuracy: 7133/10000 (71.33%)

Epoch: 58
Loss: 0.914 | Acc: 73.438% (47/64)
Loss: 0.593 | Acc: 83.864% (5421/6464)
Loss: 0.600 | Acc: 83.979% (10803/12864)
Loss: 0.595 | Acc: 84.089% (16199/19264)
Loss: 0.596 | Acc: 84.036% (21567/25664)
Loss: 0.592 | Acc: 84.063% (26954/32064)
Loss: 0.595 | Acc: 83.925% (32281/38464)
Loss: 0.597 | Acc: 83.842% (37615/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9575, Accuracy: 7334/10000 (73.34%)

Epoch: 59
Loss: 0.455 | Acc: 87.500% (56/64)
Loss: 0.596 | Acc: 83.942% (5426/6464)
Loss: 0.585 | Acc: 84.282% (10842/12864)
Loss: 0.590 | Acc: 84.115% (16204/19264)
Loss: 0.593 | Acc: 83.919% (21537/25664)
Loss: 0.592 | Acc: 83.935% (26913/32064)
Loss: 0.593 | Acc: 83.962% (32295/38464)
Loss: 0.595 | Acc: 83.887% (37635/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8308, Accuracy: 7583/10000 (75.83%)

Epoch: 60
Loss: 0.650 | Acc: 85.938% (55/64)
Loss: 0.573 | Acc: 84.731% (5477/6464)
Loss: 0.576 | Acc: 84.546% (10876/12864)
Loss: 0.590 | Acc: 84.089% (16199/19264)
Loss: 0.590 | Acc: 84.149% (21596/25664)
Loss: 0.588 | Acc: 84.203% (26999/32064)
Loss: 0.588 | Acc: 84.219% (32394/38464)
Loss: 0.589 | Acc: 84.223% (37786/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8668, Accuracy: 7577/10000 (75.77%)

Epoch: 61
Loss: 0.741 | Acc: 79.688% (51/64)
Loss: 0.553 | Acc: 85.303% (5514/6464)
Loss: 0.569 | Acc: 84.733% (10900/12864)
Loss: 0.578 | Acc: 84.417% (16262/19264)
Loss: 0.583 | Acc: 84.391% (21658/25664)
Loss: 0.582 | Acc: 84.366% (27051/32064)
Loss: 0.583 | Acc: 84.352% (32445/38464)
Loss: 0.583 | Acc: 84.319% (37829/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3873, Accuracy: 6427/10000 (64.27%)

Epoch: 62
Loss: 0.688 | Acc: 85.938% (55/64)
Loss: 0.555 | Acc: 84.994% (5494/6464)
Loss: 0.564 | Acc: 84.919% (10924/12864)
Loss: 0.575 | Acc: 84.728% (16322/19264)
Loss: 0.576 | Acc: 84.597% (21711/25664)
Loss: 0.580 | Acc: 84.406% (27064/32064)
Loss: 0.579 | Acc: 84.375% (32454/38464)
Loss: 0.580 | Acc: 84.243% (37795/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7224, Accuracy: 7994/10000 (79.94%)

Epoch: 63
Loss: 0.389 | Acc: 90.625% (58/64)
Loss: 0.542 | Acc: 85.922% (5554/6464)
Loss: 0.561 | Acc: 85.176% (10957/12864)
Loss: 0.558 | Acc: 85.206% (16414/19264)
Loss: 0.555 | Acc: 85.275% (21885/25664)
Loss: 0.561 | Acc: 85.108% (27289/32064)
Loss: 0.566 | Acc: 84.905% (32658/38464)
Loss: 0.567 | Acc: 84.946% (38110/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9616, Accuracy: 7313/10000 (73.13%)

Epoch: 64
Loss: 0.873 | Acc: 73.438% (47/64)
Loss: 0.575 | Acc: 84.607% (5469/6464)
Loss: 0.554 | Acc: 85.222% (10963/12864)
Loss: 0.556 | Acc: 84.988% (16372/19264)
Loss: 0.558 | Acc: 84.963% (21805/25664)
Loss: 0.559 | Acc: 84.974% (27246/32064)
Loss: 0.560 | Acc: 84.968% (32682/38464)
Loss: 0.566 | Acc: 84.816% (38052/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6513, Accuracy: 5331/10000 (53.31%)

Epoch: 65
Loss: 0.664 | Acc: 78.125% (50/64)
Loss: 0.562 | Acc: 84.653% (5472/6464)
Loss: 0.548 | Acc: 85.518% (11001/12864)
Loss: 0.553 | Acc: 85.278% (16428/19264)
Loss: 0.561 | Acc: 84.963% (21805/25664)
Loss: 0.563 | Acc: 84.936% (27234/32064)
Loss: 0.558 | Acc: 84.994% (32692/38464)
Loss: 0.561 | Acc: 84.968% (38120/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3569, Accuracy: 5969/10000 (59.69%)

Epoch: 66
Loss: 0.586 | Acc: 87.500% (56/64)
Loss: 0.525 | Acc: 86.216% (5573/6464)
Loss: 0.541 | Acc: 85.728% (11028/12864)
Loss: 0.547 | Acc: 85.626% (16495/19264)
Loss: 0.554 | Acc: 85.427% (21924/25664)
Loss: 0.549 | Acc: 85.435% (27394/32064)
Loss: 0.550 | Acc: 85.379% (32840/38464)
Loss: 0.550 | Acc: 85.365% (38298/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5400, Accuracy: 5464/10000 (54.64%)

Epoch: 67
Loss: 0.542 | Acc: 87.500% (56/64)
Loss: 0.549 | Acc: 85.241% (5510/6464)
Loss: 0.542 | Acc: 85.347% (10979/12864)
Loss: 0.543 | Acc: 85.501% (16471/19264)
Loss: 0.543 | Acc: 85.579% (21963/25664)
Loss: 0.543 | Acc: 85.526% (27423/32064)
Loss: 0.545 | Acc: 85.431% (32860/38464)
Loss: 0.548 | Acc: 85.316% (38276/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2615, Accuracy: 6506/10000 (65.06%)

Epoch: 68
Loss: 0.408 | Acc: 87.500% (56/64)
Loss: 0.546 | Acc: 85.210% (5508/6464)
Loss: 0.540 | Acc: 85.759% (11032/12864)
Loss: 0.543 | Acc: 85.704% (16510/19264)
Loss: 0.542 | Acc: 85.618% (21973/25664)
Loss: 0.541 | Acc: 85.663% (27467/32064)
Loss: 0.541 | Acc: 85.688% (32959/38464)
Loss: 0.537 | Acc: 85.677% (38438/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8317, Accuracy: 7722/10000 (77.22%)

Epoch: 69
Loss: 0.831 | Acc: 79.688% (51/64)
Loss: 0.516 | Acc: 86.108% (5566/6464)
Loss: 0.519 | Acc: 86.326% (11105/12864)
Loss: 0.530 | Acc: 86.015% (16570/19264)
Loss: 0.531 | Acc: 85.969% (22063/25664)
Loss: 0.533 | Acc: 85.947% (27558/32064)
Loss: 0.529 | Acc: 86.119% (33125/38464)
Loss: 0.528 | Acc: 86.136% (38644/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8772, Accuracy: 7588/10000 (75.88%)

Epoch: 70
Loss: 0.518 | Acc: 84.375% (54/64)
Loss: 0.508 | Acc: 86.959% (5621/6464)
Loss: 0.501 | Acc: 87.135% (11209/12864)
Loss: 0.503 | Acc: 86.887% (16738/19264)
Loss: 0.504 | Acc: 86.826% (22283/25664)
Loss: 0.510 | Acc: 86.683% (27794/32064)
Loss: 0.514 | Acc: 86.572% (33299/38464)
Loss: 0.519 | Acc: 86.452% (38786/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9821, Accuracy: 7145/10000 (71.45%)

Epoch: 71
Loss: 0.746 | Acc: 79.688% (51/64)
Loss: 0.503 | Acc: 87.098% (5630/6464)
Loss: 0.504 | Acc: 86.793% (11165/12864)
Loss: 0.501 | Acc: 86.929% (16746/19264)
Loss: 0.504 | Acc: 86.931% (22310/25664)
Loss: 0.511 | Acc: 86.848% (27847/32064)
Loss: 0.512 | Acc: 86.762% (33372/38464)
Loss: 0.511 | Acc: 86.809% (38946/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9179, Accuracy: 7450/10000 (74.50%)

Epoch: 72
Loss: 0.650 | Acc: 79.688% (51/64)
Loss: 0.489 | Acc: 87.268% (5641/6464)
Loss: 0.503 | Acc: 87.127% (11208/12864)
Loss: 0.503 | Acc: 86.903% (16741/19264)
Loss: 0.499 | Acc: 87.064% (22344/25664)
Loss: 0.501 | Acc: 87.042% (27909/32064)
Loss: 0.497 | Acc: 87.128% (33513/38464)
Loss: 0.500 | Acc: 87.108% (39080/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8884, Accuracy: 7609/10000 (76.09%)

Epoch: 73
Loss: 0.315 | Acc: 92.188% (59/64)
Loss: 0.476 | Acc: 87.531% (5658/6464)
Loss: 0.483 | Acc: 87.469% (11252/12864)
Loss: 0.490 | Acc: 87.246% (16807/19264)
Loss: 0.494 | Acc: 87.278% (22399/25664)
Loss: 0.495 | Acc: 87.191% (27957/32064)
Loss: 0.491 | Acc: 87.263% (33565/38464)
Loss: 0.493 | Acc: 87.228% (39134/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8176, Accuracy: 7764/10000 (77.64%)

Epoch: 74
Loss: 0.357 | Acc: 92.188% (59/64)
Loss: 0.450 | Acc: 88.444% (5717/6464)
Loss: 0.463 | Acc: 88.161% (11341/12864)
Loss: 0.473 | Acc: 87.915% (16936/19264)
Loss: 0.474 | Acc: 87.901% (22559/25664)
Loss: 0.478 | Acc: 87.784% (28147/32064)
Loss: 0.484 | Acc: 87.666% (33720/38464)
Loss: 0.481 | Acc: 87.663% (39329/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7212, Accuracy: 8104/10000 (81.04%)

Epoch: 75
Loss: 0.435 | Acc: 90.625% (58/64)
Loss: 0.437 | Acc: 89.047% (5756/6464)
Loss: 0.456 | Acc: 88.347% (11365/12864)
Loss: 0.458 | Acc: 88.325% (17015/19264)
Loss: 0.460 | Acc: 88.318% (22666/25664)
Loss: 0.465 | Acc: 88.195% (28279/32064)
Loss: 0.472 | Acc: 88.012% (33853/38464)
Loss: 0.469 | Acc: 88.135% (39541/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6054, Accuracy: 8437/10000 (84.37%)

Epoch: 76
Loss: 0.509 | Acc: 90.625% (58/64)
Loss: 0.453 | Acc: 88.753% (5737/6464)
Loss: 0.453 | Acc: 88.806% (11424/12864)
Loss: 0.459 | Acc: 88.601% (17068/19264)
Loss: 0.462 | Acc: 88.478% (22707/25664)
Loss: 0.461 | Acc: 88.408% (28347/32064)
Loss: 0.461 | Acc: 88.428% (34013/38464)
Loss: 0.458 | Acc: 88.454% (39684/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6583, Accuracy: 8255/10000 (82.55%)

Epoch: 77
Loss: 0.779 | Acc: 82.812% (53/64)
Loss: 0.452 | Acc: 88.366% (5712/6464)
Loss: 0.452 | Acc: 88.417% (11374/12864)
Loss: 0.445 | Acc: 88.730% (17093/19264)
Loss: 0.448 | Acc: 88.626% (22745/25664)
Loss: 0.447 | Acc: 88.719% (28447/32064)
Loss: 0.446 | Acc: 88.717% (34124/38464)
Loss: 0.443 | Acc: 88.777% (39829/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6559, Accuracy: 8329/10000 (83.29%)

Epoch: 78
Loss: 0.455 | Acc: 89.062% (57/64)
Loss: 0.422 | Acc: 89.821% (5806/6464)
Loss: 0.414 | Acc: 89.832% (11556/12864)
Loss: 0.427 | Acc: 89.457% (17233/19264)
Loss: 0.434 | Acc: 89.327% (22925/25664)
Loss: 0.438 | Acc: 89.147% (28584/32064)
Loss: 0.436 | Acc: 89.125% (34281/38464)
Loss: 0.434 | Acc: 89.178% (40009/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5745, Accuracy: 8574/10000 (85.74%)

Epoch: 79
Loss: 0.409 | Acc: 93.750% (60/64)
Loss: 0.395 | Acc: 90.362% (5841/6464)
Loss: 0.394 | Acc: 90.306% (11617/12864)
Loss: 0.401 | Acc: 90.101% (17357/19264)
Loss: 0.412 | Acc: 89.892% (23070/25664)
Loss: 0.414 | Acc: 89.842% (28807/32064)
Loss: 0.414 | Acc: 89.952% (34599/38464)
Loss: 0.415 | Acc: 89.905% (40335/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9167, Accuracy: 7510/10000 (75.10%)

Epoch: 80
Loss: 0.670 | Acc: 84.375% (54/64)
Loss: 0.429 | Acc: 89.387% (5778/6464)
Loss: 0.410 | Acc: 89.894% (11564/12864)
Loss: 0.408 | Acc: 90.090% (17355/19264)
Loss: 0.409 | Acc: 90.009% (23100/25664)
Loss: 0.410 | Acc: 89.926% (28834/32064)
Loss: 0.407 | Acc: 90.045% (34635/38464)
Loss: 0.405 | Acc: 90.144% (40442/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7830, Accuracy: 7903/10000 (79.03%)

Epoch: 81
Loss: 0.193 | Acc: 93.750% (60/64)
Loss: 0.374 | Acc: 90.764% (5867/6464)
Loss: 0.395 | Acc: 90.143% (11596/12864)
Loss: 0.397 | Acc: 90.179% (17372/19264)
Loss: 0.396 | Acc: 90.317% (23179/25664)
Loss: 0.392 | Acc: 90.488% (29014/32064)
Loss: 0.395 | Acc: 90.443% (34788/38464)
Loss: 0.395 | Acc: 90.424% (40568/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6301, Accuracy: 8404/10000 (84.04%)

Epoch: 82
Loss: 0.352 | Acc: 90.625% (58/64)
Loss: 0.385 | Acc: 90.702% (5863/6464)
Loss: 0.371 | Acc: 91.014% (11708/12864)
Loss: 0.361 | Acc: 91.206% (17570/19264)
Loss: 0.367 | Acc: 91.085% (23376/25664)
Loss: 0.371 | Acc: 91.015% (29183/32064)
Loss: 0.372 | Acc: 91.046% (35020/38464)
Loss: 0.374 | Acc: 91.026% (40838/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6049, Accuracy: 8539/10000 (85.39%)

Epoch: 83
Loss: 0.467 | Acc: 85.938% (55/64)
Loss: 0.336 | Acc: 91.971% (5945/6464)
Loss: 0.344 | Acc: 91.682% (11794/12864)
Loss: 0.343 | Acc: 91.674% (17660/19264)
Loss: 0.351 | Acc: 91.412% (23460/25664)
Loss: 0.352 | Acc: 91.395% (29305/32064)
Loss: 0.357 | Acc: 91.348% (35136/38464)
Loss: 0.356 | Acc: 91.419% (41014/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7968, Accuracy: 7911/10000 (79.11%)

Epoch: 84
Loss: 0.203 | Acc: 96.875% (62/64)
Loss: 0.334 | Acc: 92.296% (5966/6464)
Loss: 0.338 | Acc: 92.110% (11849/12864)
Loss: 0.347 | Acc: 91.814% (17687/19264)
Loss: 0.345 | Acc: 91.884% (23581/25664)
Loss: 0.343 | Acc: 91.863% (29455/32064)
Loss: 0.344 | Acc: 91.805% (35312/38464)
Loss: 0.342 | Acc: 91.882% (41222/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6152, Accuracy: 8460/10000 (84.60%)

Epoch: 85
Loss: 0.487 | Acc: 92.188% (59/64)
Loss: 0.326 | Acc: 92.188% (5959/6464)
Loss: 0.318 | Acc: 92.397% (11886/12864)
Loss: 0.317 | Acc: 92.426% (17805/19264)
Loss: 0.317 | Acc: 92.433% (23722/25664)
Loss: 0.317 | Acc: 92.481% (29653/32064)
Loss: 0.319 | Acc: 92.497% (35578/38464)
Loss: 0.321 | Acc: 92.437% (41471/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5600, Accuracy: 8673/10000 (86.73%)

Epoch: 86
Loss: 0.289 | Acc: 93.750% (60/64)
Loss: 0.281 | Acc: 93.363% (6035/6464)
Loss: 0.276 | Acc: 93.525% (12031/12864)
Loss: 0.288 | Acc: 93.215% (17957/19264)
Loss: 0.294 | Acc: 93.103% (23894/25664)
Loss: 0.293 | Acc: 93.079% (29845/32064)
Loss: 0.296 | Acc: 93.038% (35786/38464)
Loss: 0.298 | Acc: 92.994% (41721/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6184, Accuracy: 8531/10000 (85.31%)

Epoch: 87
Loss: 0.333 | Acc: 90.625% (58/64)
Loss: 0.305 | Acc: 92.946% (6008/6464)
Loss: 0.282 | Acc: 93.447% (12021/12864)
Loss: 0.283 | Acc: 93.470% (18006/19264)
Loss: 0.280 | Acc: 93.532% (24004/25664)
Loss: 0.281 | Acc: 93.451% (29964/32064)
Loss: 0.284 | Acc: 93.381% (35918/38464)
Loss: 0.281 | Acc: 93.469% (41934/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5754, Accuracy: 8690/10000 (86.90%)

Epoch: 88
Loss: 0.350 | Acc: 92.188% (59/64)
Loss: 0.254 | Acc: 94.121% (6084/6464)
Loss: 0.253 | Acc: 94.232% (12122/12864)
Loss: 0.257 | Acc: 94.098% (18127/19264)
Loss: 0.257 | Acc: 94.108% (24152/25664)
Loss: 0.257 | Acc: 94.024% (30148/32064)
Loss: 0.256 | Acc: 94.044% (36173/38464)
Loss: 0.260 | Acc: 93.964% (42156/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6207, Accuracy: 8595/10000 (85.95%)

Epoch: 89
Loss: 0.390 | Acc: 90.625% (58/64)
Loss: 0.229 | Acc: 94.384% (6101/6464)
Loss: 0.238 | Acc: 94.286% (12129/12864)
Loss: 0.241 | Acc: 94.254% (18157/19264)
Loss: 0.238 | Acc: 94.350% (24214/25664)
Loss: 0.240 | Acc: 94.333% (30247/32064)
Loss: 0.237 | Acc: 94.423% (36319/38464)
Loss: 0.237 | Acc: 94.425% (42363/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5807, Accuracy: 8744/10000 (87.44%)

Epoch: 90
Loss: 0.109 | Acc: 96.875% (62/64)
Loss: 0.209 | Acc: 95.127% (6149/6464)
Loss: 0.205 | Acc: 95.258% (12254/12864)
Loss: 0.208 | Acc: 95.188% (18337/19264)
Loss: 0.206 | Acc: 95.188% (24429/25664)
Loss: 0.209 | Acc: 95.113% (30497/32064)
Loss: 0.209 | Acc: 95.094% (36577/38464)
Loss: 0.209 | Acc: 95.101% (42666/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5684, Accuracy: 8811/10000 (88.11%)

Epoch: 91
Loss: 0.269 | Acc: 93.750% (60/64)
Loss: 0.190 | Acc: 95.591% (6179/6464)
Loss: 0.187 | Acc: 95.670% (12307/12864)
Loss: 0.184 | Acc: 95.785% (18452/19264)
Loss: 0.182 | Acc: 95.753% (24574/25664)
Loss: 0.186 | Acc: 95.612% (30657/32064)
Loss: 0.188 | Acc: 95.578% (36763/38464)
Loss: 0.188 | Acc: 95.571% (42877/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5855, Accuracy: 8809/10000 (88.09%)

Epoch: 92
Loss: 0.318 | Acc: 93.750% (60/64)
Loss: 0.149 | Acc: 96.442% (6234/6464)
Loss: 0.151 | Acc: 96.471% (12410/12864)
Loss: 0.157 | Acc: 96.273% (18546/19264)
Loss: 0.163 | Acc: 96.072% (24656/25664)
Loss: 0.165 | Acc: 96.039% (30794/32064)
Loss: 0.164 | Acc: 96.035% (36939/38464)
Loss: 0.165 | Acc: 96.010% (43074/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6140, Accuracy: 8761/10000 (87.61%)

Epoch: 93
Loss: 0.162 | Acc: 93.750% (60/64)
Loss: 0.141 | Acc: 96.566% (6242/6464)
Loss: 0.143 | Acc: 96.541% (12419/12864)
Loss: 0.140 | Acc: 96.569% (18603/19264)
Loss: 0.140 | Acc: 96.583% (24787/25664)
Loss: 0.140 | Acc: 96.569% (30964/32064)
Loss: 0.139 | Acc: 96.592% (37153/38464)
Loss: 0.140 | Acc: 96.565% (43323/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6084, Accuracy: 8823/10000 (88.23%)

Epoch: 94
Loss: 0.069 | Acc: 98.438% (63/64)
Loss: 0.128 | Acc: 96.767% (6255/6464)
Loss: 0.130 | Acc: 96.789% (12451/12864)
Loss: 0.128 | Acc: 96.896% (18666/19264)
Loss: 0.129 | Acc: 96.867% (24860/25664)
Loss: 0.127 | Acc: 96.909% (31073/32064)
Loss: 0.126 | Acc: 96.937% (37286/38464)
Loss: 0.124 | Acc: 96.984% (43511/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6101, Accuracy: 8848/10000 (88.48%)

Epoch: 95
Loss: 0.032 | Acc: 100.000% (64/64)
Loss: 0.107 | Acc: 97.370% (6294/6464)
Loss: 0.116 | Acc: 97.046% (12484/12864)
Loss: 0.122 | Acc: 96.937% (18674/19264)
Loss: 0.131 | Acc: 96.813% (24846/25664)
Loss: 0.137 | Acc: 96.688% (31002/32064)
Loss: 0.146 | Acc: 96.521% (37126/38464)
Loss: 0.150 | Acc: 96.425% (43260/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5373, Accuracy: 8821/10000 (88.21%)

Epoch: 96
Loss: 0.191 | Acc: 96.875% (62/64)
Loss: 0.191 | Acc: 95.498% (6173/6464)
Loss: 0.191 | Acc: 95.662% (12306/12864)
Loss: 0.201 | Acc: 95.458% (18389/19264)
Loss: 0.203 | Acc: 95.390% (24481/25664)
Loss: 0.204 | Acc: 95.390% (30586/32064)
Loss: 0.206 | Acc: 95.333% (36669/38464)
Loss: 0.209 | Acc: 95.286% (42749/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5271, Accuracy: 8801/10000 (88.01%)

Epoch: 97
Loss: 0.188 | Acc: 95.312% (61/64)
Loss: 0.221 | Acc: 95.003% (6141/6464)
Loss: 0.224 | Acc: 95.033% (12225/12864)
Loss: 0.224 | Acc: 95.017% (18304/19264)
Loss: 0.225 | Acc: 94.970% (24373/25664)
Loss: 0.228 | Acc: 94.873% (30420/32064)
Loss: 0.228 | Acc: 94.881% (36495/38464)
Loss: 0.230 | Acc: 94.827% (42543/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5290, Accuracy: 8769/10000 (87.69%)
torch.Size([100, 10])
Test set: Average loss: 0.5290, Accuracy: 8769/10000 (87.69%)

Epoch: 98
Loss: 0.185 | Acc: 95.312% (61/64)
Loss: 0.238 | Acc: 94.261% (6093/6464)
Loss: 0.234 | Acc: 94.590% (12168/12864)
Loss: 0.233 | Acc: 94.726% (18248/19264)
Loss: 0.235 | Acc: 94.697% (24303/25664)
Loss: 0.237 | Acc: 94.676% (30357/32064)
Loss: 0.241 | Acc: 94.564% (36373/38464)
Loss: 0.240 | Acc: 94.577% (42431/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5282, Accuracy: 8772/10000 (87.72%)
torch.Size([100, 10])
Test set: Average loss: 0.5282, Accuracy: 8772/10000 (87.72%)

Epoch: 99
Loss: 0.124 | Acc: 95.312% (61/64)
Loss: 0.242 | Acc: 94.276% (6094/6464)
Loss: 0.232 | Acc: 94.691% (12181/12864)
Loss: 0.235 | Acc: 94.700% (18243/19264)
Loss: 0.237 | Acc: 94.693% (24302/25664)
Loss: 0.237 | Acc: 94.654% (30350/32064)
Loss: 0.236 | Acc: 94.696% (36424/38464)
Loss: 0.237 | Acc: 94.691% (42482/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5283, Accuracy: 8771/10000 (87.71%)
torch.Size([100, 10])
Test set: Average loss: 0.5283, Accuracy: 8771/10000 (87.71%)

Epoch: 100
Loss: 0.210 | Acc: 96.875% (62/64)
Loss: 1.933 | Acc: 29.270% (1892/6464)
Loss: 1.560 | Acc: 45.608% (5867/12864)
Loss: 1.332 | Acc: 55.124% (10619/19264)
Loss: 1.200 | Acc: 60.415% (15505/25664)
Loss: 1.112 | Acc: 63.860% (20476/32064)
Loss: 1.050 | Acc: 66.376% (25531/38464)
Loss: 1.003 | Acc: 68.233% (30612/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0139, Accuracy: 7036/10000 (70.36%)

Epoch: 101
Loss: 0.658 | Acc: 78.125% (50/64)
Loss: 0.647 | Acc: 81.327% (5257/6464)
Loss: 0.660 | Acc: 81.312% (10460/12864)
Loss: 0.663 | Acc: 81.343% (15670/19264)
Loss: 0.656 | Acc: 81.523% (20922/25664)
Loss: 0.654 | Acc: 81.590% (26161/32064)
Loss: 0.653 | Acc: 81.721% (31433/38464)
Loss: 0.656 | Acc: 81.729% (36667/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3329, Accuracy: 6386/10000 (63.86%)

Epoch: 102
Loss: 0.607 | Acc: 82.812% (53/64)
Loss: 0.594 | Acc: 83.787% (5416/6464)
Loss: 0.606 | Acc: 83.287% (10714/12864)
Loss: 0.613 | Acc: 83.228% (16033/19264)
Loss: 0.611 | Acc: 83.257% (21367/25664)
Loss: 0.617 | Acc: 83.081% (26639/32064)
Loss: 0.617 | Acc: 83.145% (31981/38464)
Loss: 0.616 | Acc: 83.194% (37324/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3897, Accuracy: 6073/10000 (60.73%)

Epoch: 103
Loss: 0.637 | Acc: 81.250% (52/64)
Loss: 0.605 | Acc: 83.261% (5382/6464)
Loss: 0.602 | Acc: 83.559% (10749/12864)
Loss: 0.603 | Acc: 83.498% (16085/19264)
Loss: 0.605 | Acc: 83.487% (21426/25664)
Loss: 0.604 | Acc: 83.418% (26747/32064)
Loss: 0.603 | Acc: 83.429% (32090/38464)
Loss: 0.601 | Acc: 83.499% (37461/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6866, Accuracy: 6490/10000 (64.90%)

Epoch: 104
Loss: 0.919 | Acc: 78.125% (50/64)
Loss: 0.601 | Acc: 83.555% (5401/6464)
Loss: 0.611 | Acc: 83.396% (10728/12864)
Loss: 0.605 | Acc: 83.690% (16122/19264)
Loss: 0.602 | Acc: 83.740% (21491/25664)
Loss: 0.597 | Acc: 83.913% (26906/32064)
Loss: 0.596 | Acc: 83.891% (32268/38464)
Loss: 0.598 | Acc: 83.813% (37602/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3110, Accuracy: 6123/10000 (61.23%)

Epoch: 105
Loss: 0.937 | Acc: 75.000% (48/64)
Loss: 0.586 | Acc: 84.189% (5442/6464)
Loss: 0.586 | Acc: 84.282% (10842/12864)
Loss: 0.591 | Acc: 84.126% (16206/19264)
Loss: 0.589 | Acc: 84.165% (21600/25664)
Loss: 0.593 | Acc: 83.985% (26929/32064)
Loss: 0.595 | Acc: 83.938% (32286/38464)
Loss: 0.595 | Acc: 83.894% (37638/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4664, Accuracy: 6100/10000 (61.00%)

Epoch: 106
Loss: 0.482 | Acc: 85.938% (55/64)
Loss: 0.582 | Acc: 84.452% (5459/6464)
Loss: 0.580 | Acc: 84.336% (10849/12864)
Loss: 0.577 | Acc: 84.567% (16291/19264)
Loss: 0.581 | Acc: 84.492% (21684/25664)
Loss: 0.587 | Acc: 84.253% (27015/32064)
Loss: 0.589 | Acc: 84.183% (32380/38464)
Loss: 0.590 | Acc: 84.110% (37735/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9575, Accuracy: 7303/10000 (73.03%)

Epoch: 107
Loss: 0.719 | Acc: 79.688% (51/64)
Loss: 0.581 | Acc: 84.638% (5471/6464)
Loss: 0.579 | Acc: 84.429% (10861/12864)
Loss: 0.586 | Acc: 84.463% (16271/19264)
Loss: 0.588 | Acc: 84.375% (21654/25664)
Loss: 0.585 | Acc: 84.319% (27036/32064)
Loss: 0.583 | Acc: 84.331% (32437/38464)
Loss: 0.579 | Acc: 84.484% (37903/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1834, Accuracy: 4313/10000 (43.13%)

Epoch: 108
Loss: 1.020 | Acc: 67.188% (43/64)
Loss: 0.615 | Acc: 82.967% (5363/6464)
Loss: 0.597 | Acc: 83.722% (10770/12864)
Loss: 0.596 | Acc: 83.923% (16167/19264)
Loss: 0.594 | Acc: 83.966% (21549/25664)
Loss: 0.587 | Acc: 84.072% (26957/32064)
Loss: 0.590 | Acc: 84.063% (32334/38464)
Loss: 0.591 | Acc: 83.956% (37666/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6088, Accuracy: 5682/10000 (56.82%)

Epoch: 109
Loss: 0.758 | Acc: 78.125% (50/64)
Loss: 0.576 | Acc: 84.530% (5464/6464)
Loss: 0.581 | Acc: 84.585% (10881/12864)
Loss: 0.579 | Acc: 84.728% (16322/19264)
Loss: 0.572 | Acc: 84.804% (21764/25664)
Loss: 0.576 | Acc: 84.671% (27149/32064)
Loss: 0.579 | Acc: 84.570% (32529/38464)
Loss: 0.581 | Acc: 84.462% (37893/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1936, Accuracy: 4458/10000 (44.58%)

Epoch: 110
Loss: 0.881 | Acc: 71.875% (46/64)
Loss: 0.588 | Acc: 84.483% (5461/6464)
Loss: 0.571 | Acc: 84.779% (10906/12864)
Loss: 0.566 | Acc: 84.967% (16368/19264)
Loss: 0.568 | Acc: 84.811% (21766/25664)
Loss: 0.571 | Acc: 84.737% (27170/32064)
Loss: 0.572 | Acc: 84.645% (32558/38464)
Loss: 0.573 | Acc: 84.663% (37983/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7586, Accuracy: 7924/10000 (79.24%)

Epoch: 111
Loss: 0.804 | Acc: 78.125% (50/64)
Loss: 0.574 | Acc: 84.855% (5485/6464)
Loss: 0.578 | Acc: 84.670% (10892/12864)
Loss: 0.568 | Acc: 84.894% (16354/19264)
Loss: 0.565 | Acc: 84.991% (21812/25664)
Loss: 0.565 | Acc: 85.067% (27276/32064)
Loss: 0.569 | Acc: 84.939% (32671/38464)
Loss: 0.568 | Acc: 84.948% (38111/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9455, Accuracy: 4185/10000 (41.85%)

Epoch: 112
Loss: 1.090 | Acc: 64.062% (41/64)
Loss: 0.568 | Acc: 84.638% (5471/6464)
Loss: 0.557 | Acc: 84.974% (10931/12864)
Loss: 0.562 | Acc: 85.003% (16375/19264)
Loss: 0.560 | Acc: 84.959% (21804/25664)
Loss: 0.563 | Acc: 84.943% (27236/32064)
Loss: 0.568 | Acc: 84.856% (32639/38464)
Loss: 0.568 | Acc: 84.881% (38081/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3722, Accuracy: 6109/10000 (61.09%)

Epoch: 113
Loss: 0.562 | Acc: 82.812% (53/64)
Loss: 0.552 | Acc: 85.149% (5504/6464)
Loss: 0.551 | Acc: 85.253% (10967/12864)
Loss: 0.548 | Acc: 85.382% (16448/19264)
Loss: 0.546 | Acc: 85.373% (21910/25664)
Loss: 0.543 | Acc: 85.520% (27421/32064)
Loss: 0.546 | Acc: 85.423% (32857/38464)
Loss: 0.548 | Acc: 85.394% (38311/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1449, Accuracy: 6712/10000 (67.12%)

Epoch: 114
Loss: 0.507 | Acc: 89.062% (57/64)
Loss: 0.547 | Acc: 85.907% (5553/6464)
Loss: 0.543 | Acc: 85.564% (11007/12864)
Loss: 0.550 | Acc: 85.237% (16420/19264)
Loss: 0.548 | Acc: 85.337% (21901/25664)
Loss: 0.548 | Acc: 85.404% (27384/32064)
Loss: 0.550 | Acc: 85.319% (32817/38464)
Loss: 0.552 | Acc: 85.316% (38276/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8702, Accuracy: 7516/10000 (75.16%)

Epoch: 115
Loss: 0.679 | Acc: 81.250% (52/64)
Loss: 0.510 | Acc: 86.696% (5604/6464)
Loss: 0.514 | Acc: 86.528% (11131/12864)
Loss: 0.527 | Acc: 86.150% (16596/19264)
Loss: 0.531 | Acc: 85.938% (22055/25664)
Loss: 0.534 | Acc: 85.888% (27539/32064)
Loss: 0.536 | Acc: 85.797% (33001/38464)
Loss: 0.540 | Acc: 85.724% (38459/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8783, Accuracy: 7604/10000 (76.04%)

Epoch: 116
Loss: 0.516 | Acc: 85.938% (55/64)
Loss: 0.522 | Acc: 86.649% (5601/6464)
Loss: 0.529 | Acc: 86.334% (11106/12864)
Loss: 0.538 | Acc: 86.015% (16570/19264)
Loss: 0.534 | Acc: 86.136% (22106/25664)
Loss: 0.539 | Acc: 86.056% (27593/32064)
Loss: 0.537 | Acc: 86.036% (33093/38464)
Loss: 0.539 | Acc: 85.911% (38543/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0830, Accuracy: 6904/10000 (69.04%)

Epoch: 117
Loss: 0.692 | Acc: 78.125% (50/64)
Loss: 0.541 | Acc: 85.566% (5531/6464)
Loss: 0.528 | Acc: 85.953% (11057/12864)
Loss: 0.520 | Acc: 86.181% (16602/19264)
Loss: 0.523 | Acc: 86.179% (22117/25664)
Loss: 0.530 | Acc: 86.081% (27601/32064)
Loss: 0.530 | Acc: 86.067% (33105/38464)
Loss: 0.530 | Acc: 86.036% (38599/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8044, Accuracy: 7699/10000 (76.99%)

Epoch: 118
Loss: 0.644 | Acc: 84.375% (54/64)
Loss: 0.514 | Acc: 87.191% (5636/6464)
Loss: 0.516 | Acc: 87.002% (11192/12864)
Loss: 0.508 | Acc: 87.168% (16792/19264)
Loss: 0.513 | Acc: 86.884% (22298/25664)
Loss: 0.516 | Acc: 86.711% (27803/32064)
Loss: 0.519 | Acc: 86.546% (33289/38464)
Loss: 0.521 | Acc: 86.470% (38794/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4504, Accuracy: 6130/10000 (61.30%)

Epoch: 119
Loss: 0.554 | Acc: 87.500% (56/64)
Loss: 0.522 | Acc: 86.231% (5574/6464)
Loss: 0.508 | Acc: 86.800% (11166/12864)
Loss: 0.505 | Acc: 86.887% (16738/19264)
Loss: 0.508 | Acc: 86.845% (22288/25664)
Loss: 0.512 | Acc: 86.783% (27826/32064)
Loss: 0.512 | Acc: 86.717% (33355/38464)
Loss: 0.515 | Acc: 86.611% (38857/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7743, Accuracy: 7901/10000 (79.01%)

Epoch: 120
Loss: 0.513 | Acc: 84.375% (54/64)
Loss: 0.511 | Acc: 86.618% (5599/6464)
Loss: 0.506 | Acc: 86.878% (11176/12864)
Loss: 0.506 | Acc: 86.867% (16734/19264)
Loss: 0.505 | Acc: 86.923% (22308/25664)
Loss: 0.506 | Acc: 86.920% (27870/32064)
Loss: 0.509 | Acc: 86.814% (33392/38464)
Loss: 0.507 | Acc: 86.838% (38959/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8252, Accuracy: 7666/10000 (76.66%)

Epoch: 121
Loss: 0.380 | Acc: 90.625% (58/64)
Loss: 0.474 | Acc: 87.717% (5670/6464)
Loss: 0.483 | Acc: 87.383% (11241/12864)
Loss: 0.492 | Acc: 87.225% (16803/19264)
Loss: 0.499 | Acc: 87.145% (22365/25664)
Loss: 0.495 | Acc: 87.257% (27978/32064)
Loss: 0.498 | Acc: 87.196% (33539/38464)
Loss: 0.501 | Acc: 87.199% (39121/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8683, Accuracy: 7504/10000 (75.04%)

Epoch: 122
Loss: 0.746 | Acc: 78.125% (50/64)
Loss: 0.463 | Acc: 88.351% (5711/6464)
Loss: 0.458 | Acc: 88.433% (11376/12864)
Loss: 0.463 | Acc: 88.154% (16982/19264)
Loss: 0.472 | Acc: 87.948% (22571/25664)
Loss: 0.481 | Acc: 87.737% (28132/32064)
Loss: 0.480 | Acc: 87.705% (33735/38464)
Loss: 0.484 | Acc: 87.549% (39278/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7736, Accuracy: 7858/10000 (78.58%)

Epoch: 123
Loss: 0.404 | Acc: 89.062% (57/64)
Loss: 0.479 | Acc: 88.196% (5701/6464)
Loss: 0.485 | Acc: 87.733% (11286/12864)
Loss: 0.480 | Acc: 87.811% (16916/19264)
Loss: 0.479 | Acc: 87.784% (22529/25664)
Loss: 0.478 | Acc: 87.803% (28153/32064)
Loss: 0.479 | Acc: 87.734% (33746/38464)
Loss: 0.479 | Acc: 87.745% (39366/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9703, Accuracy: 7432/10000 (74.32%)

Epoch: 124
Loss: 0.662 | Acc: 85.938% (55/64)
Loss: 0.453 | Acc: 88.892% (5746/6464)
Loss: 0.454 | Acc: 88.612% (11399/12864)
Loss: 0.457 | Acc: 88.580% (17064/19264)
Loss: 0.459 | Acc: 88.517% (22717/25664)
Loss: 0.464 | Acc: 88.326% (28321/32064)
Loss: 0.464 | Acc: 88.329% (33975/38464)
Loss: 0.467 | Acc: 88.271% (39602/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1876, Accuracy: 6822/10000 (68.22%)

Epoch: 125
Loss: 0.458 | Acc: 87.500% (56/64)
Loss: 0.429 | Acc: 88.939% (5749/6464)
Loss: 0.439 | Acc: 88.790% (11422/12864)
Loss: 0.451 | Acc: 88.637% (17075/19264)
Loss: 0.449 | Acc: 88.704% (22765/25664)
Loss: 0.452 | Acc: 88.641% (28422/32064)
Loss: 0.453 | Acc: 88.667% (34105/38464)
Loss: 0.457 | Acc: 88.565% (39734/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2006, Accuracy: 6789/10000 (67.89%)

Epoch: 126
Loss: 0.424 | Acc: 87.500% (56/64)
Loss: 0.414 | Acc: 89.851% (5808/6464)
Loss: 0.420 | Acc: 89.785% (11550/12864)
Loss: 0.434 | Acc: 89.379% (17218/19264)
Loss: 0.441 | Acc: 89.078% (22861/25664)
Loss: 0.440 | Acc: 89.075% (28561/32064)
Loss: 0.440 | Acc: 89.057% (34255/38464)
Loss: 0.441 | Acc: 89.071% (39961/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6235, Accuracy: 8417/10000 (84.17%)

Epoch: 127
Loss: 0.637 | Acc: 84.375% (54/64)
Loss: 0.430 | Acc: 89.496% (5785/6464)
Loss: 0.437 | Acc: 89.249% (11481/12864)
Loss: 0.437 | Acc: 89.208% (17185/19264)
Loss: 0.439 | Acc: 89.035% (22850/25664)
Loss: 0.437 | Acc: 89.131% (28579/32064)
Loss: 0.434 | Acc: 89.203% (34311/38464)
Loss: 0.432 | Acc: 89.274% (40052/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7732, Accuracy: 7924/10000 (79.24%)

Epoch: 128
Loss: 0.517 | Acc: 84.375% (54/64)
Loss: 0.401 | Acc: 90.192% (5830/6464)
Loss: 0.413 | Acc: 89.739% (11544/12864)
Loss: 0.416 | Acc: 89.462% (17234/19264)
Loss: 0.422 | Acc: 89.335% (22927/25664)
Loss: 0.424 | Acc: 89.312% (28637/32064)
Loss: 0.423 | Acc: 89.419% (34394/38464)
Loss: 0.423 | Acc: 89.404% (40110/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6504, Accuracy: 8359/10000 (83.59%)

Epoch: 129
Loss: 0.449 | Acc: 90.625% (58/64)
Loss: 0.394 | Acc: 90.424% (5845/6464)
Loss: 0.399 | Acc: 90.493% (11641/12864)
Loss: 0.393 | Acc: 90.578% (17449/19264)
Loss: 0.397 | Acc: 90.481% (23221/25664)
Loss: 0.402 | Acc: 90.354% (28971/32064)
Loss: 0.409 | Acc: 90.134% (34669/38464)
Loss: 0.409 | Acc: 90.190% (40463/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7950, Accuracy: 7868/10000 (78.68%)

Epoch: 130
Loss: 0.397 | Acc: 90.625% (58/64)
Loss: 0.403 | Acc: 90.161% (5828/6464)
Loss: 0.405 | Acc: 90.182% (11601/12864)
Loss: 0.394 | Acc: 90.552% (17444/19264)
Loss: 0.396 | Acc: 90.411% (23203/25664)
Loss: 0.394 | Acc: 90.485% (29013/32064)
Loss: 0.394 | Acc: 90.524% (34819/38464)
Loss: 0.397 | Acc: 90.449% (40579/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7182, Accuracy: 8075/10000 (80.75%)

Epoch: 131
Loss: 0.745 | Acc: 79.688% (51/64)
Loss: 0.362 | Acc: 91.414% (5909/6464)
Loss: 0.376 | Acc: 91.045% (11712/12864)
Loss: 0.369 | Acc: 91.243% (17577/19264)
Loss: 0.371 | Acc: 91.139% (23390/25664)
Loss: 0.377 | Acc: 91.018% (29184/32064)
Loss: 0.377 | Acc: 91.007% (35005/38464)
Loss: 0.380 | Acc: 90.966% (40811/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1453, Accuracy: 7066/10000 (70.66%)

Epoch: 132
Loss: 0.484 | Acc: 90.625% (58/64)
Loss: 0.323 | Acc: 92.528% (5981/6464)
Loss: 0.350 | Acc: 91.752% (11803/12864)
Loss: 0.353 | Acc: 91.611% (17648/19264)
Loss: 0.363 | Acc: 91.397% (23456/25664)
Loss: 0.367 | Acc: 91.249% (29258/32064)
Loss: 0.367 | Acc: 91.270% (35106/38464)
Loss: 0.367 | Acc: 91.236% (40932/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7596, Accuracy: 8089/10000 (80.89%)

Epoch: 133
Loss: 0.334 | Acc: 89.062% (57/64)
Loss: 0.312 | Acc: 92.404% (5973/6464)
Loss: 0.333 | Acc: 91.962% (11830/12864)
Loss: 0.341 | Acc: 91.835% (17691/19264)
Loss: 0.343 | Acc: 91.767% (23551/25664)
Loss: 0.346 | Acc: 91.748% (29418/32064)
Loss: 0.347 | Acc: 91.720% (35279/38464)
Loss: 0.349 | Acc: 91.726% (41152/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5811, Accuracy: 8626/10000 (86.26%)

Epoch: 134
Loss: 0.221 | Acc: 93.750% (60/64)
Loss: 0.324 | Acc: 92.621% (5987/6464)
Loss: 0.320 | Acc: 92.600% (11912/12864)
Loss: 0.323 | Acc: 92.463% (17812/19264)
Loss: 0.329 | Acc: 92.312% (23691/25664)
Loss: 0.333 | Acc: 92.265% (29584/32064)
Loss: 0.333 | Acc: 92.265% (35489/38464)
Loss: 0.329 | Acc: 92.337% (41426/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6186, Accuracy: 8491/10000 (84.91%)

Epoch: 135
Loss: 0.273 | Acc: 92.188% (59/64)
Loss: 0.288 | Acc: 93.332% (6033/6464)
Loss: 0.290 | Acc: 93.214% (11991/12864)
Loss: 0.298 | Acc: 93.060% (17927/19264)
Loss: 0.310 | Acc: 92.710% (23793/25664)
Loss: 0.311 | Acc: 92.721% (29730/32064)
Loss: 0.314 | Acc: 92.707% (35659/38464)
Loss: 0.312 | Acc: 92.760% (41616/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5408, Accuracy: 8727/10000 (87.27%)

Epoch: 136
Loss: 0.157 | Acc: 96.875% (62/64)
Loss: 0.290 | Acc: 93.069% (6016/6464)
Loss: 0.285 | Acc: 93.408% (12016/12864)
Loss: 0.280 | Acc: 93.558% (18023/19264)
Loss: 0.285 | Acc: 93.364% (23961/25664)
Loss: 0.290 | Acc: 93.251% (29900/32064)
Loss: 0.292 | Acc: 93.227% (35859/38464)
Loss: 0.291 | Acc: 93.280% (41849/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5881, Accuracy: 8648/10000 (86.48%)

Epoch: 137
Loss: 0.237 | Acc: 93.750% (60/64)
Loss: 0.267 | Acc: 93.951% (6073/6464)
Loss: 0.265 | Acc: 93.960% (12087/12864)
Loss: 0.263 | Acc: 94.025% (18113/19264)
Loss: 0.262 | Acc: 94.034% (24133/25664)
Loss: 0.267 | Acc: 93.946% (30123/32064)
Loss: 0.268 | Acc: 93.937% (36132/38464)
Loss: 0.268 | Acc: 93.910% (42132/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6361, Accuracy: 8538/10000 (85.38%)

Epoch: 138
Loss: 0.273 | Acc: 95.312% (61/64)
Loss: 0.250 | Acc: 94.307% (6096/6464)
Loss: 0.250 | Acc: 94.139% (12110/12864)
Loss: 0.244 | Acc: 94.311% (18168/19264)
Loss: 0.246 | Acc: 94.237% (24185/25664)
Loss: 0.246 | Acc: 94.271% (30227/32064)
Loss: 0.243 | Acc: 94.361% (36295/38464)
Loss: 0.247 | Acc: 94.249% (42284/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6136, Accuracy: 8643/10000 (86.43%)

Epoch: 139
Loss: 0.498 | Acc: 85.938% (55/64)
Loss: 0.233 | Acc: 94.740% (6124/6464)
Loss: 0.232 | Acc: 94.512% (12158/12864)
Loss: 0.228 | Acc: 94.581% (18220/19264)
Loss: 0.232 | Acc: 94.514% (24256/25664)
Loss: 0.231 | Acc: 94.583% (30327/32064)
Loss: 0.231 | Acc: 94.582% (36380/38464)
Loss: 0.229 | Acc: 94.644% (42461/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5947, Accuracy: 8727/10000 (87.27%)

Epoch: 140
Loss: 0.335 | Acc: 90.625% (58/64)
Loss: 0.203 | Acc: 95.282% (6159/6464)
Loss: 0.202 | Acc: 95.351% (12266/12864)
Loss: 0.199 | Acc: 95.422% (18382/19264)
Loss: 0.201 | Acc: 95.351% (24471/25664)
Loss: 0.198 | Acc: 95.378% (30582/32064)
Loss: 0.198 | Acc: 95.393% (36692/38464)
Loss: 0.201 | Acc: 95.341% (42774/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5865, Accuracy: 8793/10000 (87.93%)

Epoch: 141
Loss: 0.237 | Acc: 95.312% (61/64)
Loss: 0.171 | Acc: 95.962% (6203/6464)
Loss: 0.181 | Acc: 95.631% (12302/12864)
Loss: 0.179 | Acc: 95.697% (18435/19264)
Loss: 0.181 | Acc: 95.694% (24559/25664)
Loss: 0.179 | Acc: 95.755% (30703/32064)
Loss: 0.179 | Acc: 95.728% (36821/38464)
Loss: 0.181 | Acc: 95.669% (42921/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5957, Accuracy: 8765/10000 (87.65%)

Epoch: 142
Loss: 0.088 | Acc: 96.875% (62/64)
Loss: 0.154 | Acc: 96.272% (6223/6464)
Loss: 0.155 | Acc: 96.315% (12390/12864)
Loss: 0.158 | Acc: 96.237% (18539/19264)
Loss: 0.156 | Acc: 96.306% (24716/25664)
Loss: 0.152 | Acc: 96.376% (30902/32064)
Loss: 0.155 | Acc: 96.306% (37043/38464)
Loss: 0.155 | Acc: 96.291% (43200/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5825, Accuracy: 8834/10000 (88.34%)

Epoch: 143
Loss: 0.154 | Acc: 96.875% (62/64)
Loss: 0.138 | Acc: 96.535% (6240/6464)
Loss: 0.137 | Acc: 96.510% (12415/12864)
Loss: 0.138 | Acc: 96.543% (18598/19264)
Loss: 0.141 | Acc: 96.493% (24764/25664)
Loss: 0.141 | Acc: 96.485% (30937/32064)
Loss: 0.137 | Acc: 96.592% (37153/38464)
Loss: 0.138 | Acc: 96.590% (43334/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5952, Accuracy: 8867/10000 (88.67%)

Epoch: 144
Loss: 0.122 | Acc: 98.438% (63/64)
Loss: 0.115 | Acc: 96.983% (6269/6464)
Loss: 0.115 | Acc: 96.968% (12474/12864)
Loss: 0.119 | Acc: 96.906% (18668/19264)
Loss: 0.119 | Acc: 96.949% (24881/25664)
Loss: 0.120 | Acc: 96.912% (31074/32064)
Loss: 0.120 | Acc: 96.922% (37280/38464)
Loss: 0.121 | Acc: 96.926% (43485/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6018, Accuracy: 8873/10000 (88.73%)

Epoch: 145
Loss: 0.028 | Acc: 100.000% (64/64)
Loss: 0.113 | Acc: 97.153% (6280/6464)
Loss: 0.119 | Acc: 97.116% (12493/12864)
Loss: 0.124 | Acc: 96.937% (18674/19264)
Loss: 0.130 | Acc: 96.797% (24842/25664)
Loss: 0.134 | Acc: 96.735% (31017/32064)
Loss: 0.141 | Acc: 96.605% (37158/38464)
Loss: 0.145 | Acc: 96.521% (43303/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5393, Accuracy: 8793/10000 (87.93%)

Epoch: 146
Loss: 0.250 | Acc: 93.750% (60/64)
Loss: 0.171 | Acc: 96.256% (6222/6464)
Loss: 0.174 | Acc: 96.020% (12352/12864)
Loss: 0.184 | Acc: 95.821% (18459/19264)
Loss: 0.186 | Acc: 95.780% (24581/25664)
Loss: 0.190 | Acc: 95.646% (30668/32064)
Loss: 0.194 | Acc: 95.562% (36757/38464)
Loss: 0.196 | Acc: 95.513% (42851/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5315, Accuracy: 8797/10000 (87.97%)

Epoch: 147
Loss: 0.210 | Acc: 95.312% (61/64)
Loss: 0.210 | Acc: 95.111% (6148/6464)
Loss: 0.216 | Acc: 94.955% (12215/12864)
Loss: 0.217 | Acc: 95.017% (18304/19264)
Loss: 0.215 | Acc: 95.129% (24414/25664)
Loss: 0.217 | Acc: 95.035% (30472/32064)
Loss: 0.218 | Acc: 95.102% (36580/38464)
Loss: 0.219 | Acc: 95.076% (42655/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5327, Accuracy: 8756/10000 (87.56%)
torch.Size([100, 10])
Test set: Average loss: 0.5327, Accuracy: 8756/10000 (87.56%)

Epoch: 148
Loss: 0.140 | Acc: 96.875% (62/64)
Loss: 0.223 | Acc: 94.709% (6122/6464)
Loss: 0.226 | Acc: 94.768% (12191/12864)
Loss: 0.225 | Acc: 94.851% (18272/19264)
Loss: 0.225 | Acc: 94.892% (24353/25664)
Loss: 0.225 | Acc: 94.973% (30452/32064)
Loss: 0.225 | Acc: 94.972% (36530/38464)
Loss: 0.225 | Acc: 94.960% (42603/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5297, Accuracy: 8759/10000 (87.59%)
torch.Size([100, 10])
Test set: Average loss: 0.5297, Accuracy: 8759/10000 (87.59%)

Epoch: 149
Loss: 0.339 | Acc: 93.750% (60/64)
Loss: 0.228 | Acc: 94.895% (6134/6464)
Loss: 0.225 | Acc: 95.056% (12228/12864)
Loss: 0.228 | Acc: 94.949% (18291/19264)
Loss: 0.229 | Acc: 94.872% (24348/25664)
Loss: 0.228 | Acc: 94.888% (30425/32064)
Loss: 0.230 | Acc: 94.868% (36490/38464)
Loss: 0.229 | Acc: 94.893% (42573/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5327, Accuracy: 8741/10000 (87.41%)
torch.Size([100, 10])
Test set: Average loss: 0.5327, Accuracy: 8741/10000 (87.41%)

Epoch: 150
Loss: 0.234 | Acc: 93.750% (60/64)
Loss: 1.506 | Acc: 49.103% (3174/6464)
Loss: 1.211 | Acc: 60.906% (7835/12864)
Loss: 1.090 | Acc: 65.563% (12630/19264)
Loss: 1.005 | Acc: 68.703% (17632/25664)
Loss: 0.944 | Acc: 70.930% (22743/32064)
Loss: 0.902 | Acc: 72.447% (27866/38464)
Loss: 0.870 | Acc: 73.623% (33030/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8587, Accuracy: 4642/10000 (46.42%)

Epoch: 151
Loss: 0.624 | Acc: 81.250% (52/64)
Loss: 0.637 | Acc: 81.807% (5288/6464)
Loss: 0.633 | Acc: 82.020% (10551/12864)
Loss: 0.643 | Acc: 81.821% (15762/19264)
Loss: 0.639 | Acc: 82.006% (21046/25664)
Loss: 0.636 | Acc: 82.313% (26393/32064)
Loss: 0.636 | Acc: 82.321% (31664/38464)
Loss: 0.634 | Acc: 82.458% (36994/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9246, Accuracy: 4816/10000 (48.16%)

Epoch: 152
Loss: 0.740 | Acc: 78.125% (50/64)
Loss: 0.600 | Acc: 83.400% (5391/6464)
Loss: 0.583 | Acc: 83.940% (10798/12864)
Loss: 0.592 | Acc: 83.814% (16146/19264)
Loss: 0.597 | Acc: 83.537% (21439/25664)
Loss: 0.602 | Acc: 83.452% (26758/32064)
Loss: 0.606 | Acc: 83.361% (32064/38464)
Loss: 0.604 | Acc: 83.497% (37460/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0361, Accuracy: 6866/10000 (68.66%)

Epoch: 153
Loss: 0.709 | Acc: 79.688% (51/64)
Loss: 0.602 | Acc: 83.524% (5399/6464)
Loss: 0.585 | Acc: 84.297% (10844/12864)
Loss: 0.591 | Acc: 84.152% (16211/19264)
Loss: 0.587 | Acc: 84.254% (21623/25664)
Loss: 0.590 | Acc: 84.191% (26995/32064)
Loss: 0.593 | Acc: 84.089% (32344/38464)
Loss: 0.592 | Acc: 84.112% (37736/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9257, Accuracy: 7329/10000 (73.29%)

Epoch: 154
Loss: 0.666 | Acc: 84.375% (54/64)
Loss: 0.578 | Acc: 84.112% (5437/6464)
Loss: 0.591 | Acc: 83.932% (10797/12864)
Loss: 0.591 | Acc: 83.939% (16170/19264)
Loss: 0.587 | Acc: 84.091% (21581/25664)
Loss: 0.589 | Acc: 83.957% (26920/32064)
Loss: 0.589 | Acc: 84.042% (32326/38464)
Loss: 0.586 | Acc: 84.132% (37745/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3167, Accuracy: 3875/10000 (38.75%)

Epoch: 155
Loss: 1.112 | Acc: 65.625% (42/64)
Loss: 0.603 | Acc: 83.926% (5425/6464)
Loss: 0.595 | Acc: 84.157% (10826/12864)
Loss: 0.586 | Acc: 84.417% (16262/19264)
Loss: 0.582 | Acc: 84.476% (21680/25664)
Loss: 0.575 | Acc: 84.603% (27127/32064)
Loss: 0.581 | Acc: 84.440% (32479/38464)
Loss: 0.585 | Acc: 84.326% (37832/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2379, Accuracy: 6771/10000 (67.71%)

Epoch: 156
Loss: 0.640 | Acc: 81.250% (52/64)
Loss: 0.555 | Acc: 84.700% (5475/6464)
Loss: 0.565 | Acc: 84.328% (10848/12864)
Loss: 0.564 | Acc: 84.567% (16291/19264)
Loss: 0.566 | Acc: 84.636% (21721/25664)
Loss: 0.567 | Acc: 84.609% (27129/32064)
Loss: 0.573 | Acc: 84.510% (32506/38464)
Loss: 0.574 | Acc: 84.475% (37899/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0962, Accuracy: 6706/10000 (67.06%)

Epoch: 157
Loss: 0.508 | Acc: 85.938% (55/64)
Loss: 0.570 | Acc: 84.344% (5452/6464)
Loss: 0.559 | Acc: 84.632% (10887/12864)
Loss: 0.572 | Acc: 84.526% (16283/19264)
Loss: 0.572 | Acc: 84.585% (21708/25664)
Loss: 0.575 | Acc: 84.456% (27080/32064)
Loss: 0.574 | Acc: 84.482% (32495/38464)
Loss: 0.577 | Acc: 84.446% (37886/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3684, Accuracy: 6470/10000 (64.70%)

Epoch: 158
Loss: 0.811 | Acc: 81.250% (52/64)
Loss: 0.567 | Acc: 85.040% (5497/6464)
Loss: 0.555 | Acc: 85.121% (10950/12864)
Loss: 0.563 | Acc: 84.863% (16348/19264)
Loss: 0.562 | Acc: 85.002% (21815/25664)
Loss: 0.569 | Acc: 84.880% (27216/32064)
Loss: 0.568 | Acc: 84.840% (32633/38464)
Loss: 0.570 | Acc: 84.812% (38050/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5005, Accuracy: 5842/10000 (58.42%)

Epoch: 159
Loss: 0.616 | Acc: 82.812% (53/64)
Loss: 0.556 | Acc: 85.102% (5501/6464)
Loss: 0.557 | Acc: 85.145% (10953/12864)
Loss: 0.562 | Acc: 85.117% (16397/19264)
Loss: 0.564 | Acc: 85.053% (21828/25664)
Loss: 0.562 | Acc: 85.046% (27269/32064)
Loss: 0.566 | Acc: 84.921% (32664/38464)
Loss: 0.568 | Acc: 84.856% (38070/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4776, Accuracy: 6035/10000 (60.35%)

Epoch: 160
Loss: 0.630 | Acc: 82.812% (53/64)
Loss: 0.568 | Acc: 84.947% (5491/6464)
Loss: 0.570 | Acc: 85.106% (10948/12864)
Loss: 0.561 | Acc: 85.143% (16402/19264)
Loss: 0.565 | Acc: 84.870% (21781/25664)
Loss: 0.558 | Acc: 85.136% (27298/32064)
Loss: 0.565 | Acc: 84.916% (32662/38464)
Loss: 0.562 | Acc: 85.010% (38139/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3675, Accuracy: 6435/10000 (64.35%)

Epoch: 161
Loss: 0.937 | Acc: 76.562% (49/64)
Loss: 0.531 | Acc: 85.891% (5552/6464)
Loss: 0.538 | Acc: 85.697% (11024/12864)
Loss: 0.550 | Acc: 85.268% (16426/19264)
Loss: 0.554 | Acc: 85.084% (21836/25664)
Loss: 0.561 | Acc: 84.993% (27252/32064)
Loss: 0.560 | Acc: 85.067% (32720/38464)
Loss: 0.561 | Acc: 84.997% (38133/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7156, Accuracy: 8054/10000 (80.54%)

Epoch: 162
Loss: 0.535 | Acc: 89.062% (57/64)
Loss: 0.523 | Acc: 86.092% (5565/6464)
Loss: 0.531 | Acc: 85.992% (11062/12864)
Loss: 0.533 | Acc: 85.974% (16562/19264)
Loss: 0.540 | Acc: 85.832% (22028/25664)
Loss: 0.543 | Acc: 85.732% (27489/32064)
Loss: 0.547 | Acc: 85.607% (32928/38464)
Loss: 0.550 | Acc: 85.474% (38347/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7693, Accuracy: 7871/10000 (78.71%)

Epoch: 163
Loss: 0.441 | Acc: 85.938% (55/64)
Loss: 0.537 | Acc: 85.968% (5557/6464)
Loss: 0.542 | Acc: 85.836% (11042/12864)
Loss: 0.540 | Acc: 85.828% (16534/19264)
Loss: 0.548 | Acc: 85.610% (21971/25664)
Loss: 0.551 | Acc: 85.467% (27404/32064)
Loss: 0.548 | Acc: 85.444% (32865/38464)
Loss: 0.551 | Acc: 85.351% (38292/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9160, Accuracy: 7304/10000 (73.04%)

Epoch: 164
Loss: 0.780 | Acc: 81.250% (52/64)
Loss: 0.538 | Acc: 86.046% (5562/6464)
Loss: 0.524 | Acc: 86.427% (11118/12864)
Loss: 0.530 | Acc: 86.249% (16615/19264)
Loss: 0.539 | Acc: 85.867% (22037/25664)
Loss: 0.537 | Acc: 85.894% (27541/32064)
Loss: 0.538 | Acc: 85.873% (33030/38464)
Loss: 0.539 | Acc: 85.848% (38515/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6770, Accuracy: 8114/10000 (81.14%)

Epoch: 165
Loss: 0.391 | Acc: 90.625% (58/64)
Loss: 0.543 | Acc: 85.999% (5559/6464)
Loss: 0.551 | Acc: 85.580% (11009/12864)
Loss: 0.545 | Acc: 85.642% (16498/19264)
Loss: 0.543 | Acc: 85.641% (21979/25664)
Loss: 0.536 | Acc: 85.881% (27537/32064)
Loss: 0.533 | Acc: 85.995% (33077/38464)
Loss: 0.533 | Acc: 86.009% (38587/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1823, Accuracy: 6524/10000 (65.24%)

Epoch: 166
Loss: 1.019 | Acc: 65.625% (42/64)
Loss: 0.513 | Acc: 86.649% (5601/6464)
Loss: 0.519 | Acc: 86.334% (11106/12864)
Loss: 0.523 | Acc: 86.156% (16597/19264)
Loss: 0.525 | Acc: 86.210% (22125/25664)
Loss: 0.525 | Acc: 86.109% (27610/32064)
Loss: 0.527 | Acc: 85.997% (33078/38464)
Loss: 0.528 | Acc: 86.024% (38594/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2709, Accuracy: 4840/10000 (48.40%)

Epoch: 167
Loss: 0.726 | Acc: 79.688% (51/64)
Loss: 0.510 | Acc: 86.541% (5594/6464)
Loss: 0.509 | Acc: 86.645% (11146/12864)
Loss: 0.516 | Acc: 86.503% (16664/19264)
Loss: 0.510 | Acc: 86.662% (22241/25664)
Loss: 0.517 | Acc: 86.443% (27717/32064)
Loss: 0.519 | Acc: 86.356% (33216/38464)
Loss: 0.521 | Acc: 86.323% (38728/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4110, Accuracy: 6945/10000 (69.45%)

Epoch: 168
Loss: 0.559 | Acc: 85.938% (55/64)
Loss: 0.501 | Acc: 86.804% (5611/6464)
Loss: 0.503 | Acc: 86.839% (11171/12864)
Loss: 0.504 | Acc: 86.872% (16735/19264)
Loss: 0.506 | Acc: 86.818% (22281/25664)
Loss: 0.508 | Acc: 86.833% (27842/32064)
Loss: 0.514 | Acc: 86.751% (33368/38464)
Loss: 0.512 | Acc: 86.807% (38945/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0161, Accuracy: 7140/10000 (71.40%)

Epoch: 169
Loss: 0.622 | Acc: 79.688% (51/64)
Loss: 0.497 | Acc: 87.222% (5638/6464)
Loss: 0.499 | Acc: 87.150% (11211/12864)
Loss: 0.505 | Acc: 87.007% (16761/19264)
Loss: 0.504 | Acc: 86.908% (22304/25664)
Loss: 0.508 | Acc: 86.776% (27824/32064)
Loss: 0.512 | Acc: 86.762% (33372/38464)
Loss: 0.510 | Acc: 86.771% (38929/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9510, Accuracy: 7334/10000 (73.34%)

Epoch: 170
Loss: 0.996 | Acc: 73.438% (47/64)
Loss: 0.507 | Acc: 87.036% (5626/6464)
Loss: 0.502 | Acc: 87.142% (11210/12864)
Loss: 0.508 | Acc: 86.872% (16735/19264)
Loss: 0.506 | Acc: 86.943% (22313/25664)
Loss: 0.508 | Acc: 86.836% (27843/32064)
Loss: 0.506 | Acc: 86.884% (33419/38464)
Loss: 0.508 | Acc: 86.820% (38951/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8035, Accuracy: 7805/10000 (78.05%)

Epoch: 171
Loss: 0.860 | Acc: 71.875% (46/64)
Loss: 0.476 | Acc: 87.918% (5683/6464)
Loss: 0.476 | Acc: 87.826% (11298/12864)
Loss: 0.485 | Acc: 87.604% (16876/19264)
Loss: 0.485 | Acc: 87.664% (22498/25664)
Loss: 0.485 | Acc: 87.634% (28099/32064)
Loss: 0.487 | Acc: 87.635% (33708/38464)
Loss: 0.489 | Acc: 87.605% (39303/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7137, Accuracy: 5499/10000 (54.99%)

Epoch: 172
Loss: 1.273 | Acc: 70.312% (45/64)
Loss: 0.490 | Acc: 87.438% (5652/6464)
Loss: 0.486 | Acc: 87.562% (11264/12864)
Loss: 0.485 | Acc: 87.593% (16874/19264)
Loss: 0.486 | Acc: 87.547% (22468/25664)
Loss: 0.483 | Acc: 87.678% (28113/32064)
Loss: 0.483 | Acc: 87.599% (33694/38464)
Loss: 0.485 | Acc: 87.600% (39301/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3833, Accuracy: 6068/10000 (60.68%)

Epoch: 173
Loss: 0.423 | Acc: 90.625% (58/64)
Loss: 0.454 | Acc: 88.583% (5726/6464)
Loss: 0.460 | Acc: 88.425% (11375/12864)
Loss: 0.468 | Acc: 88.055% (16963/19264)
Loss: 0.468 | Acc: 88.053% (22598/25664)
Loss: 0.466 | Acc: 88.180% (28274/32064)
Loss: 0.470 | Acc: 88.145% (33904/38464)
Loss: 0.470 | Acc: 88.135% (39541/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8252, Accuracy: 7757/10000 (77.57%)

Epoch: 174
Loss: 0.619 | Acc: 84.375% (54/64)
Loss: 0.449 | Acc: 88.660% (5731/6464)
Loss: 0.453 | Acc: 88.596% (11397/12864)
Loss: 0.449 | Acc: 88.658% (17079/19264)
Loss: 0.459 | Acc: 88.420% (22692/25664)
Loss: 0.459 | Acc: 88.420% (28351/32064)
Loss: 0.462 | Acc: 88.340% (33979/38464)
Loss: 0.463 | Acc: 88.287% (39609/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6933, Accuracy: 8059/10000 (80.59%)

Epoch: 175
Loss: 0.455 | Acc: 89.062% (57/64)
Loss: 0.442 | Acc: 88.800% (5740/6464)
Loss: 0.439 | Acc: 88.837% (11428/12864)
Loss: 0.448 | Acc: 88.725% (17092/19264)
Loss: 0.452 | Acc: 88.653% (22752/25664)
Loss: 0.447 | Acc: 88.707% (28443/32064)
Loss: 0.451 | Acc: 88.634% (34092/38464)
Loss: 0.451 | Acc: 88.697% (39793/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6353, Accuracy: 8353/10000 (83.53%)

Epoch: 176
Loss: 0.460 | Acc: 90.625% (58/64)
Loss: 0.423 | Acc: 89.511% (5786/6464)
Loss: 0.435 | Acc: 89.249% (11481/12864)
Loss: 0.435 | Acc: 89.192% (17182/19264)
Loss: 0.442 | Acc: 88.996% (22840/25664)
Loss: 0.439 | Acc: 89.159% (28588/32064)
Loss: 0.435 | Acc: 89.257% (34332/38464)
Loss: 0.438 | Acc: 89.178% (40009/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1028, Accuracy: 7005/10000 (70.05%)

Epoch: 177
Loss: 0.313 | Acc: 87.500% (56/64)
Loss: 0.441 | Acc: 88.815% (5741/6464)
Loss: 0.431 | Acc: 89.280% (11485/12864)
Loss: 0.421 | Acc: 89.509% (17243/19264)
Loss: 0.427 | Acc: 89.413% (22947/25664)
Loss: 0.426 | Acc: 89.484% (28692/32064)
Loss: 0.431 | Acc: 89.317% (34355/38464)
Loss: 0.429 | Acc: 89.361% (40091/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0061, Accuracy: 7163/10000 (71.63%)

Epoch: 178
Loss: 0.508 | Acc: 87.500% (56/64)
Loss: 0.393 | Acc: 90.316% (5838/6464)
Loss: 0.394 | Acc: 90.368% (11625/12864)
Loss: 0.402 | Acc: 90.070% (17351/19264)
Loss: 0.407 | Acc: 89.935% (23081/25664)
Loss: 0.413 | Acc: 89.870% (28816/32064)
Loss: 0.412 | Acc: 89.946% (34597/38464)
Loss: 0.413 | Acc: 89.898% (40332/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0267, Accuracy: 7279/10000 (72.79%)

Epoch: 179
Loss: 0.515 | Acc: 87.500% (56/64)
Loss: 0.414 | Acc: 89.944% (5814/6464)
Loss: 0.408 | Acc: 90.143% (11596/12864)
Loss: 0.407 | Acc: 90.028% (17343/19264)
Loss: 0.406 | Acc: 90.021% (23103/25664)
Loss: 0.407 | Acc: 90.020% (28864/32064)
Loss: 0.407 | Acc: 90.079% (34648/38464)
Loss: 0.405 | Acc: 90.106% (40425/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5822, Accuracy: 8536/10000 (85.36%)

Epoch: 180
Loss: 0.274 | Acc: 90.625% (58/64)
Loss: 0.379 | Acc: 90.950% (5879/6464)
Loss: 0.389 | Acc: 90.578% (11652/12864)
Loss: 0.386 | Acc: 90.744% (17481/19264)
Loss: 0.380 | Acc: 90.972% (23347/25664)
Loss: 0.383 | Acc: 90.890% (29143/32064)
Loss: 0.385 | Acc: 90.823% (34934/38464)
Loss: 0.385 | Acc: 90.848% (40758/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6716, Accuracy: 8230/10000 (82.30%)

Epoch: 181
Loss: 0.408 | Acc: 93.750% (60/64)
Loss: 0.370 | Acc: 91.166% (5893/6464)
Loss: 0.368 | Acc: 91.099% (11719/12864)
Loss: 0.370 | Acc: 91.118% (17553/19264)
Loss: 0.371 | Acc: 91.096% (23379/25664)
Loss: 0.369 | Acc: 91.102% (29211/32064)
Loss: 0.373 | Acc: 91.090% (35037/38464)
Loss: 0.374 | Acc: 91.055% (40851/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6856, Accuracy: 8273/10000 (82.73%)

Epoch: 182
Loss: 0.367 | Acc: 87.500% (56/64)
Loss: 0.375 | Acc: 90.888% (5875/6464)
Loss: 0.359 | Acc: 91.488% (11769/12864)
Loss: 0.360 | Acc: 91.430% (17613/19264)
Loss: 0.358 | Acc: 91.447% (23469/25664)
Loss: 0.361 | Acc: 91.364% (29295/32064)
Loss: 0.359 | Acc: 91.441% (35172/38464)
Loss: 0.358 | Acc: 91.470% (41037/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5490, Accuracy: 8735/10000 (87.35%)

Epoch: 183
Loss: 0.415 | Acc: 93.750% (60/64)
Loss: 0.330 | Acc: 92.218% (5961/6464)
Loss: 0.336 | Acc: 92.055% (11842/12864)
Loss: 0.343 | Acc: 91.803% (17685/19264)
Loss: 0.347 | Acc: 91.673% (23527/25664)
Loss: 0.345 | Acc: 91.742% (29416/32064)
Loss: 0.346 | Acc: 91.730% (35283/38464)
Loss: 0.346 | Acc: 91.813% (41191/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5518, Accuracy: 8673/10000 (86.73%)

Epoch: 184
Loss: 0.309 | Acc: 93.750% (60/64)
Loss: 0.319 | Acc: 92.652% (5989/6464)
Loss: 0.323 | Acc: 92.413% (11888/12864)
Loss: 0.328 | Acc: 92.364% (17793/19264)
Loss: 0.325 | Acc: 92.390% (23711/25664)
Loss: 0.320 | Acc: 92.496% (29658/32064)
Loss: 0.325 | Acc: 92.356% (35524/38464)
Loss: 0.326 | Acc: 92.373% (41442/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5795, Accuracy: 8608/10000 (86.08%)

Epoch: 185
Loss: 0.295 | Acc: 90.625% (58/64)
Loss: 0.282 | Acc: 93.456% (6041/6464)
Loss: 0.292 | Acc: 93.136% (11981/12864)
Loss: 0.292 | Acc: 93.143% (17943/19264)
Loss: 0.303 | Acc: 92.943% (23853/25664)
Loss: 0.304 | Acc: 93.008% (29822/32064)
Loss: 0.308 | Acc: 92.879% (35725/38464)
Loss: 0.308 | Acc: 92.892% (41675/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7477, Accuracy: 8154/10000 (81.54%)

Epoch: 186
Loss: 0.216 | Acc: 95.312% (61/64)
Loss: 0.272 | Acc: 93.827% (6065/6464)
Loss: 0.276 | Acc: 93.563% (12036/12864)
Loss: 0.275 | Acc: 93.683% (18047/19264)
Loss: 0.286 | Acc: 93.532% (24004/25664)
Loss: 0.290 | Acc: 93.423% (29955/32064)
Loss: 0.291 | Acc: 93.347% (35905/38464)
Loss: 0.290 | Acc: 93.315% (41865/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5527, Accuracy: 8718/10000 (87.18%)

Epoch: 187
Loss: 0.261 | Acc: 93.750% (60/64)
Loss: 0.243 | Acc: 94.554% (6112/6464)
Loss: 0.250 | Acc: 94.279% (12128/12864)
Loss: 0.265 | Acc: 93.864% (18082/19264)
Loss: 0.267 | Acc: 93.805% (24074/25664)
Loss: 0.271 | Acc: 93.716% (30049/32064)
Loss: 0.269 | Acc: 93.771% (36068/38464)
Loss: 0.270 | Acc: 93.743% (42057/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5766, Accuracy: 8715/10000 (87.15%)

Epoch: 188
Loss: 0.263 | Acc: 92.188% (59/64)
Loss: 0.254 | Acc: 94.245% (6092/6464)
Loss: 0.247 | Acc: 94.317% (12133/12864)
Loss: 0.245 | Acc: 94.373% (18180/19264)
Loss: 0.247 | Acc: 94.358% (24216/25664)
Loss: 0.244 | Acc: 94.414% (30273/32064)
Loss: 0.242 | Acc: 94.520% (36356/38464)
Loss: 0.241 | Acc: 94.510% (42401/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5772, Accuracy: 8727/10000 (87.27%)

Epoch: 189
Loss: 0.158 | Acc: 96.875% (62/64)
Loss: 0.204 | Acc: 95.282% (6159/6464)
Loss: 0.217 | Acc: 94.978% (12218/12864)
Loss: 0.223 | Acc: 94.825% (18267/19264)
Loss: 0.224 | Acc: 94.872% (24348/25664)
Loss: 0.226 | Acc: 94.813% (30401/32064)
Loss: 0.226 | Acc: 94.811% (36468/38464)
Loss: 0.226 | Acc: 94.815% (42538/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5643, Accuracy: 8815/10000 (88.15%)

Epoch: 190
Loss: 0.252 | Acc: 93.750% (60/64)
Loss: 0.190 | Acc: 95.498% (6173/6464)
Loss: 0.190 | Acc: 95.771% (12320/12864)
Loss: 0.192 | Acc: 95.665% (18429/19264)
Loss: 0.194 | Acc: 95.609% (24537/25664)
Loss: 0.194 | Acc: 95.574% (30645/32064)
Loss: 0.197 | Acc: 95.546% (36751/38464)
Loss: 0.197 | Acc: 95.515% (42852/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6138, Accuracy: 8716/10000 (87.16%)

Epoch: 191
Loss: 0.355 | Acc: 90.625% (58/64)
Loss: 0.175 | Acc: 95.823% (6194/6464)
Loss: 0.174 | Acc: 95.911% (12338/12864)
Loss: 0.171 | Acc: 95.967% (18487/19264)
Loss: 0.172 | Acc: 95.924% (24618/25664)
Loss: 0.171 | Acc: 95.946% (30764/32064)
Loss: 0.174 | Acc: 95.887% (36882/38464)
Loss: 0.175 | Acc: 95.874% (43013/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6080, Accuracy: 8738/10000 (87.38%)

Epoch: 192
Loss: 0.127 | Acc: 95.312% (61/64)
Loss: 0.151 | Acc: 96.395% (6231/6464)
Loss: 0.147 | Acc: 96.401% (12401/12864)
Loss: 0.149 | Acc: 96.413% (18573/19264)
Loss: 0.150 | Acc: 96.423% (24746/25664)
Loss: 0.152 | Acc: 96.357% (30896/32064)
Loss: 0.154 | Acc: 96.326% (37051/38464)
Loss: 0.156 | Acc: 96.271% (43191/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5949, Accuracy: 8805/10000 (88.05%)

Epoch: 193
Loss: 0.108 | Acc: 98.438% (63/64)
Loss: 0.140 | Acc: 96.844% (6260/6464)
Loss: 0.144 | Acc: 96.696% (12439/12864)
Loss: 0.144 | Acc: 96.615% (18612/19264)
Loss: 0.142 | Acc: 96.649% (24804/25664)
Loss: 0.140 | Acc: 96.638% (30986/32064)
Loss: 0.139 | Acc: 96.693% (37192/38464)
Loss: 0.138 | Acc: 96.706% (43386/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6027, Accuracy: 8818/10000 (88.18%)

Epoch: 194
Loss: 0.111 | Acc: 96.875% (62/64)
Loss: 0.116 | Acc: 97.107% (6277/6464)
Loss: 0.119 | Acc: 97.046% (12484/12864)
Loss: 0.118 | Acc: 97.031% (18692/19264)
Loss: 0.121 | Acc: 96.933% (24877/25664)
Loss: 0.118 | Acc: 97.015% (31107/32064)
Loss: 0.117 | Acc: 97.031% (37322/38464)
Loss: 0.116 | Acc: 97.073% (43551/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6115, Accuracy: 8846/10000 (88.46%)

Epoch: 195
Loss: 0.225 | Acc: 96.875% (62/64)
Loss: 0.109 | Acc: 97.215% (6284/6464)
Loss: 0.118 | Acc: 97.069% (12487/12864)
Loss: 0.125 | Acc: 96.927% (18672/19264)
Loss: 0.127 | Acc: 96.918% (24873/25664)
Loss: 0.130 | Acc: 96.866% (31059/32064)
Loss: 0.137 | Acc: 96.719% (37202/38464)
Loss: 0.142 | Acc: 96.599% (43338/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5568, Accuracy: 8785/10000 (87.85%)

Epoch: 196
Loss: 0.199 | Acc: 93.750% (60/64)
Loss: 0.168 | Acc: 95.978% (6204/6464)
Loss: 0.169 | Acc: 96.012% (12351/12864)
Loss: 0.180 | Acc: 95.769% (18449/19264)
Loss: 0.184 | Acc: 95.702% (24561/25664)
Loss: 0.184 | Acc: 95.721% (30692/32064)
Loss: 0.187 | Acc: 95.674% (36800/38464)
Loss: 0.187 | Acc: 95.660% (42917/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5426, Accuracy: 8777/10000 (87.77%)

Epoch: 197
Loss: 0.100 | Acc: 98.438% (63/64)
Loss: 0.200 | Acc: 95.838% (6195/6464)
Loss: 0.206 | Acc: 95.406% (12273/12864)
Loss: 0.204 | Acc: 95.385% (18375/19264)
Loss: 0.205 | Acc: 95.312% (24461/25664)
Loss: 0.208 | Acc: 95.281% (30551/32064)
Loss: 0.208 | Acc: 95.279% (36648/38464)
Loss: 0.210 | Acc: 95.239% (42728/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5429, Accuracy: 8768/10000 (87.68%)
torch.Size([100, 10])
Test set: Average loss: 0.5429, Accuracy: 8768/10000 (87.68%)

Epoch: 198
Loss: 0.174 | Acc: 96.875% (62/64)
Loss: 0.217 | Acc: 94.833% (6130/6464)
Loss: 0.219 | Acc: 94.963% (12216/12864)
Loss: 0.212 | Acc: 95.152% (18330/19264)
Loss: 0.216 | Acc: 95.059% (24396/25664)
Loss: 0.218 | Acc: 94.998% (30460/32064)
Loss: 0.219 | Acc: 94.969% (36529/38464)
Loss: 0.217 | Acc: 95.038% (42638/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5394, Accuracy: 8780/10000 (87.80%)
torch.Size([100, 10])
Test set: Average loss: 0.5394, Accuracy: 8780/10000 (87.80%)

Epoch: 199
Loss: 0.136 | Acc: 96.875% (62/64)
Loss: 0.217 | Acc: 95.266% (6158/6464)
Loss: 0.220 | Acc: 95.025% (12224/12864)
Loss: 0.223 | Acc: 94.804% (18263/19264)
Loss: 0.218 | Acc: 94.962% (24371/25664)
Loss: 0.221 | Acc: 94.867% (30418/32064)
Loss: 0.217 | Acc: 94.964% (36527/38464)
Loss: 0.216 | Acc: 94.994% (42618/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5424, Accuracy: 8785/10000 (87.85%)
torch.Size([100, 10])
Test set: Average loss: 0.5424, Accuracy: 8785/10000 (87.85%)
8992
10000
-0.4627741575241089
