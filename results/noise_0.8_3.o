==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.466 | Acc: 10.938% (7/64)
Loss: 3.110 | Acc: 9.870% (638/6464)
Loss: 2.711 | Acc: 10.106% (1300/12864)
Loss: 2.576 | Acc: 10.102% (1946/19264)
Loss: 2.509 | Acc: 10.123% (2598/25664)
Loss: 2.468 | Acc: 10.292% (3300/32064)
Loss: 2.441 | Acc: 10.259% (3946/38464)
Loss: 2.421 | Acc: 10.215% (4583/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3029, Accuracy: 1106/10000 (11.06%)

Epoch: 1
Loss: 2.308 | Acc: 12.500% (8/64)
Loss: 2.305 | Acc: 10.056% (650/6464)
Loss: 2.304 | Acc: 10.121% (1302/12864)
Loss: 2.304 | Acc: 10.325% (1989/19264)
Loss: 2.304 | Acc: 10.373% (2662/25664)
Loss: 2.303 | Acc: 10.414% (3339/32064)
Loss: 2.303 | Acc: 10.412% (4005/38464)
Loss: 2.303 | Acc: 10.608% (4759/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3047, Accuracy: 1197/10000 (11.97%)

Epoch: 2
Loss: 2.284 | Acc: 10.938% (7/64)
Loss: 2.300 | Acc: 11.866% (767/6464)
Loss: 2.299 | Acc: 11.692% (1504/12864)
Loss: 2.299 | Acc: 11.654% (2245/19264)
Loss: 2.299 | Acc: 11.658% (2992/25664)
Loss: 2.299 | Acc: 11.717% (3757/32064)
Loss: 2.298 | Acc: 11.860% (4562/38464)
Loss: 2.298 | Acc: 11.878% (5329/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2979, Accuracy: 1183/10000 (11.83%)

Epoch: 3
Loss: 2.360 | Acc: 6.250% (4/64)
Loss: 2.298 | Acc: 11.726% (758/6464)
Loss: 2.296 | Acc: 12.142% (1562/12864)
Loss: 2.295 | Acc: 12.334% (2376/19264)
Loss: 2.296 | Acc: 12.173% (3124/25664)
Loss: 2.296 | Acc: 12.110% (3883/32064)
Loss: 2.296 | Acc: 12.102% (4655/38464)
Loss: 2.296 | Acc: 12.159% (5455/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2943, Accuracy: 1192/10000 (11.92%)

Epoch: 4
Loss: 2.289 | Acc: 20.312% (13/64)
Loss: 2.296 | Acc: 12.376% (800/6464)
Loss: 2.295 | Acc: 12.057% (1551/12864)
Loss: 2.295 | Acc: 12.256% (2361/19264)
Loss: 2.295 | Acc: 12.157% (3120/25664)
Loss: 2.295 | Acc: 12.232% (3922/32064)
Loss: 2.295 | Acc: 12.175% (4683/38464)
Loss: 2.294 | Acc: 12.224% (5484/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2961, Accuracy: 1247/10000 (12.47%)

Epoch: 5
Loss: 2.299 | Acc: 12.500% (8/64)
Loss: 2.291 | Acc: 12.531% (810/6464)
Loss: 2.292 | Acc: 12.407% (1596/12864)
Loss: 2.294 | Acc: 12.355% (2380/19264)
Loss: 2.293 | Acc: 12.375% (3176/25664)
Loss: 2.293 | Acc: 12.378% (3969/32064)
Loss: 2.293 | Acc: 12.445% (4787/38464)
Loss: 2.293 | Acc: 12.478% (5598/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3188, Accuracy: 1226/10000 (12.26%)

Epoch: 6
Loss: 2.308 | Acc: 12.500% (8/64)
Loss: 2.290 | Acc: 13.459% (870/6464)
Loss: 2.290 | Acc: 13.511% (1738/12864)
Loss: 2.290 | Acc: 13.372% (2576/19264)
Loss: 2.290 | Acc: 13.392% (3437/25664)
Loss: 2.291 | Acc: 13.302% (4265/32064)
Loss: 2.291 | Acc: 13.192% (5074/38464)
Loss: 2.292 | Acc: 13.129% (5890/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2918, Accuracy: 1202/10000 (12.02%)

Epoch: 7
Loss: 2.306 | Acc: 9.375% (6/64)
Loss: 2.289 | Acc: 12.933% (836/6464)
Loss: 2.289 | Acc: 12.990% (1671/12864)
Loss: 2.289 | Acc: 13.201% (2543/19264)
Loss: 2.289 | Acc: 13.307% (3415/25664)
Loss: 2.290 | Acc: 13.383% (4291/32064)
Loss: 2.290 | Acc: 13.410% (5158/38464)
Loss: 2.289 | Acc: 13.483% (6049/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2869, Accuracy: 1322/10000 (13.22%)

Epoch: 8
Loss: 2.314 | Acc: 10.938% (7/64)
Loss: 2.285 | Acc: 14.248% (921/6464)
Loss: 2.286 | Acc: 14.078% (1811/12864)
Loss: 2.287 | Acc: 13.922% (2682/19264)
Loss: 2.288 | Acc: 13.599% (3490/25664)
Loss: 2.288 | Acc: 13.557% (4347/32064)
Loss: 2.288 | Acc: 13.543% (5209/38464)
Loss: 2.288 | Acc: 13.554% (6081/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3131, Accuracy: 1409/10000 (14.09%)

Epoch: 9
Loss: 2.257 | Acc: 12.500% (8/64)
Loss: 2.288 | Acc: 13.614% (880/6464)
Loss: 2.287 | Acc: 13.868% (1784/12864)
Loss: 2.287 | Acc: 14.005% (2698/19264)
Loss: 2.286 | Acc: 13.922% (3573/25664)
Loss: 2.287 | Acc: 13.819% (4431/32064)
Loss: 2.287 | Acc: 13.743% (5286/38464)
Loss: 2.287 | Acc: 13.726% (6158/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2952, Accuracy: 1329/10000 (13.29%)

Epoch: 10
Loss: 2.256 | Acc: 15.625% (10/64)
Loss: 2.286 | Acc: 14.325% (926/6464)
Loss: 2.286 | Acc: 14.000% (1801/12864)
Loss: 2.285 | Acc: 14.068% (2710/19264)
Loss: 2.285 | Acc: 14.012% (3596/25664)
Loss: 2.285 | Acc: 14.215% (4558/32064)
Loss: 2.286 | Acc: 14.096% (5422/38464)
Loss: 2.286 | Acc: 13.922% (6246/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3111, Accuracy: 1398/10000 (13.98%)

Epoch: 11
Loss: 2.302 | Acc: 14.062% (9/64)
Loss: 2.282 | Acc: 14.295% (924/6464)
Loss: 2.284 | Acc: 14.171% (1823/12864)
Loss: 2.284 | Acc: 14.031% (2703/19264)
Loss: 2.285 | Acc: 13.844% (3553/25664)
Loss: 2.285 | Acc: 13.829% (4434/32064)
Loss: 2.285 | Acc: 13.974% (5375/38464)
Loss: 2.285 | Acc: 14.011% (6286/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2868, Accuracy: 1465/10000 (14.65%)

Epoch: 12
Loss: 2.291 | Acc: 15.625% (10/64)
Loss: 2.286 | Acc: 14.743% (953/6464)
Loss: 2.281 | Acc: 15.011% (1931/12864)
Loss: 2.282 | Acc: 14.789% (2849/19264)
Loss: 2.282 | Acc: 14.799% (3798/25664)
Loss: 2.283 | Acc: 14.671% (4704/32064)
Loss: 2.283 | Acc: 14.705% (5656/38464)
Loss: 2.283 | Acc: 14.684% (6588/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2815, Accuracy: 1449/10000 (14.49%)

Epoch: 13
Loss: 2.289 | Acc: 12.500% (8/64)
Loss: 2.284 | Acc: 15.099% (976/6464)
Loss: 2.279 | Acc: 15.470% (1990/12864)
Loss: 2.281 | Acc: 15.158% (2920/19264)
Loss: 2.282 | Acc: 15.044% (3861/25664)
Loss: 2.281 | Acc: 15.051% (4826/32064)
Loss: 2.281 | Acc: 15.017% (5776/38464)
Loss: 2.281 | Acc: 14.981% (6721/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2892, Accuracy: 1428/10000 (14.28%)

Epoch: 14
Loss: 2.268 | Acc: 15.625% (10/64)
Loss: 2.278 | Acc: 15.099% (976/6464)
Loss: 2.279 | Acc: 15.322% (1971/12864)
Loss: 2.279 | Acc: 15.329% (2953/19264)
Loss: 2.280 | Acc: 15.294% (3925/25664)
Loss: 2.280 | Acc: 15.282% (4900/32064)
Loss: 2.280 | Acc: 15.183% (5840/38464)
Loss: 2.280 | Acc: 15.248% (6841/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2816, Accuracy: 1448/10000 (14.48%)

Epoch: 15
Loss: 2.287 | Acc: 12.500% (8/64)
Loss: 2.280 | Acc: 14.821% (958/6464)
Loss: 2.281 | Acc: 14.793% (1903/12864)
Loss: 2.280 | Acc: 14.945% (2879/19264)
Loss: 2.280 | Acc: 15.044% (3861/25664)
Loss: 2.280 | Acc: 15.054% (4827/32064)
Loss: 2.279 | Acc: 15.225% (5856/38464)
Loss: 2.279 | Acc: 15.255% (6844/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2783, Accuracy: 1568/10000 (15.68%)

Epoch: 16
Loss: 2.299 | Acc: 12.500% (8/64)
Loss: 2.274 | Acc: 16.012% (1035/6464)
Loss: 2.276 | Acc: 15.695% (2019/12864)
Loss: 2.277 | Acc: 15.615% (3008/19264)
Loss: 2.278 | Acc: 15.465% (3969/25664)
Loss: 2.278 | Acc: 15.488% (4966/32064)
Loss: 2.278 | Acc: 15.485% (5956/38464)
Loss: 2.278 | Acc: 15.545% (6974/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2772, Accuracy: 1553/10000 (15.53%)

Epoch: 17
Loss: 2.256 | Acc: 20.312% (13/64)
Loss: 2.277 | Acc: 15.873% (1026/6464)
Loss: 2.276 | Acc: 15.695% (2019/12864)
Loss: 2.277 | Acc: 15.713% (3027/19264)
Loss: 2.277 | Acc: 15.855% (4069/25664)
Loss: 2.276 | Acc: 15.909% (5101/32064)
Loss: 2.276 | Acc: 16.044% (6171/38464)
Loss: 2.276 | Acc: 15.921% (7143/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2950, Accuracy: 1406/10000 (14.06%)

Epoch: 18
Loss: 2.231 | Acc: 28.125% (18/64)
Loss: 2.271 | Acc: 16.646% (1076/6464)
Loss: 2.275 | Acc: 16.208% (2085/12864)
Loss: 2.274 | Acc: 16.321% (3144/19264)
Loss: 2.273 | Acc: 16.439% (4219/25664)
Loss: 2.272 | Acc: 16.517% (5296/32064)
Loss: 2.274 | Acc: 16.262% (6255/38464)
Loss: 2.274 | Acc: 16.307% (7316/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2871, Accuracy: 1509/10000 (15.09%)

Epoch: 19
Loss: 2.294 | Acc: 15.625% (10/64)
Loss: 2.272 | Acc: 16.909% (1093/6464)
Loss: 2.272 | Acc: 16.845% (2167/12864)
Loss: 2.273 | Acc: 16.596% (3197/19264)
Loss: 2.273 | Acc: 16.595% (4259/25664)
Loss: 2.274 | Acc: 16.395% (5257/32064)
Loss: 2.274 | Acc: 16.324% (6279/38464)
Loss: 2.273 | Acc: 16.416% (7365/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2849, Accuracy: 1482/10000 (14.82%)

Epoch: 20
Loss: 2.277 | Acc: 17.188% (11/64)
Loss: 2.275 | Acc: 16.321% (1055/6464)
Loss: 2.274 | Acc: 16.457% (2117/12864)
Loss: 2.272 | Acc: 16.549% (3188/19264)
Loss: 2.271 | Acc: 16.525% (4241/25664)
Loss: 2.271 | Acc: 16.592% (5320/32064)
Loss: 2.270 | Acc: 16.647% (6403/38464)
Loss: 2.270 | Acc: 16.688% (7487/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2702, Accuracy: 1680/10000 (16.80%)

Epoch: 21
Loss: 2.280 | Acc: 14.062% (9/64)
Loss: 2.267 | Acc: 16.785% (1085/6464)
Loss: 2.266 | Acc: 17.016% (2189/12864)
Loss: 2.266 | Acc: 17.068% (3288/19264)
Loss: 2.267 | Acc: 17.016% (4367/25664)
Loss: 2.268 | Acc: 16.950% (5435/32064)
Loss: 2.267 | Acc: 16.964% (6525/38464)
Loss: 2.267 | Acc: 17.056% (7652/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2889, Accuracy: 1583/10000 (15.83%)

Epoch: 22
Loss: 2.287 | Acc: 14.062% (9/64)
Loss: 2.264 | Acc: 17.791% (1150/6464)
Loss: 2.266 | Acc: 17.343% (2231/12864)
Loss: 2.267 | Acc: 17.027% (3280/19264)
Loss: 2.268 | Acc: 16.845% (4323/25664)
Loss: 2.268 | Acc: 16.988% (5447/32064)
Loss: 2.267 | Acc: 17.016% (6545/38464)
Loss: 2.267 | Acc: 17.067% (7657/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2959, Accuracy: 1635/10000 (16.35%)

Epoch: 23
Loss: 2.286 | Acc: 14.062% (9/64)
Loss: 2.262 | Acc: 18.209% (1177/6464)
Loss: 2.265 | Acc: 17.576% (2261/12864)
Loss: 2.263 | Acc: 17.816% (3432/19264)
Loss: 2.264 | Acc: 17.721% (4548/25664)
Loss: 2.265 | Acc: 17.643% (5657/32064)
Loss: 2.265 | Acc: 17.778% (6838/38464)
Loss: 2.264 | Acc: 17.751% (7964/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2829, Accuracy: 1540/10000 (15.40%)

Epoch: 24
Loss: 2.326 | Acc: 7.812% (5/64)
Loss: 2.265 | Acc: 17.543% (1134/6464)
Loss: 2.262 | Acc: 17.872% (2299/12864)
Loss: 2.262 | Acc: 17.914% (3451/19264)
Loss: 2.263 | Acc: 17.838% (4578/25664)
Loss: 2.262 | Acc: 17.830% (5717/32064)
Loss: 2.261 | Acc: 17.897% (6884/38464)
Loss: 2.262 | Acc: 17.825% (7997/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2681, Accuracy: 1689/10000 (16.89%)

Epoch: 25
Loss: 2.305 | Acc: 9.375% (6/64)
Loss: 2.259 | Acc: 18.209% (1177/6464)
Loss: 2.259 | Acc: 18.338% (2359/12864)
Loss: 2.259 | Acc: 18.148% (3496/19264)
Loss: 2.261 | Acc: 18.084% (4641/25664)
Loss: 2.259 | Acc: 18.207% (5838/32064)
Loss: 2.259 | Acc: 18.105% (6964/38464)
Loss: 2.260 | Acc: 18.079% (8111/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2736, Accuracy: 1754/10000 (17.54%)

Epoch: 26
Loss: 2.316 | Acc: 12.500% (8/64)
Loss: 2.254 | Acc: 18.626% (1204/6464)
Loss: 2.257 | Acc: 18.424% (2370/12864)
Loss: 2.257 | Acc: 18.480% (3560/19264)
Loss: 2.258 | Acc: 18.353% (4710/25664)
Loss: 2.258 | Acc: 18.373% (5891/32064)
Loss: 2.257 | Acc: 18.391% (7074/38464)
Loss: 2.257 | Acc: 18.527% (8312/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2710, Accuracy: 1806/10000 (18.06%)

Epoch: 27
Loss: 2.222 | Acc: 20.312% (13/64)
Loss: 2.259 | Acc: 18.967% (1226/6464)
Loss: 2.256 | Acc: 18.501% (2380/12864)
Loss: 2.256 | Acc: 18.568% (3577/19264)
Loss: 2.256 | Acc: 18.664% (4790/25664)
Loss: 2.256 | Acc: 18.762% (6016/32064)
Loss: 2.255 | Acc: 18.823% (7240/38464)
Loss: 2.254 | Acc: 18.884% (8472/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2731, Accuracy: 1755/10000 (17.55%)

Epoch: 28
Loss: 2.282 | Acc: 17.188% (11/64)
Loss: 2.244 | Acc: 19.864% (1284/6464)
Loss: 2.254 | Acc: 18.820% (2421/12864)
Loss: 2.252 | Acc: 19.093% (3678/19264)
Loss: 2.252 | Acc: 19.054% (4890/25664)
Loss: 2.253 | Acc: 19.059% (6111/32064)
Loss: 2.251 | Acc: 19.197% (7384/38464)
Loss: 2.251 | Acc: 19.256% (8639/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2632, Accuracy: 1775/10000 (17.75%)

Epoch: 29
Loss: 2.286 | Acc: 15.625% (10/64)
Loss: 2.251 | Acc: 19.168% (1239/6464)
Loss: 2.248 | Acc: 19.442% (2501/12864)
Loss: 2.248 | Acc: 19.378% (3733/19264)
Loss: 2.249 | Acc: 19.323% (4959/25664)
Loss: 2.248 | Acc: 19.421% (6227/32064)
Loss: 2.249 | Acc: 19.397% (7461/38464)
Loss: 2.249 | Acc: 19.350% (8681/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2605, Accuracy: 1825/10000 (18.25%)

Epoch: 30
Loss: 2.335 | Acc: 10.938% (7/64)
Loss: 2.246 | Acc: 19.508% (1261/6464)
Loss: 2.244 | Acc: 19.597% (2521/12864)
Loss: 2.244 | Acc: 19.627% (3781/19264)
Loss: 2.246 | Acc: 19.584% (5026/25664)
Loss: 2.246 | Acc: 19.530% (6262/32064)
Loss: 2.246 | Acc: 19.611% (7543/38464)
Loss: 2.247 | Acc: 19.595% (8791/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2554, Accuracy: 1952/10000 (19.52%)

Epoch: 31
Loss: 2.264 | Acc: 18.750% (12/64)
Loss: 2.244 | Acc: 19.632% (1269/6464)
Loss: 2.244 | Acc: 19.846% (2553/12864)
Loss: 2.242 | Acc: 20.089% (3870/19264)
Loss: 2.244 | Acc: 19.962% (5123/25664)
Loss: 2.244 | Acc: 20.044% (6427/32064)
Loss: 2.243 | Acc: 20.107% (7734/38464)
Loss: 2.243 | Acc: 20.036% (8989/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2650, Accuracy: 1921/10000 (19.21%)

Epoch: 32
Loss: 2.131 | Acc: 26.562% (17/64)
Loss: 2.240 | Acc: 20.823% (1346/6464)
Loss: 2.244 | Acc: 20.188% (2597/12864)
Loss: 2.245 | Acc: 19.954% (3844/19264)
Loss: 2.242 | Acc: 20.207% (5186/25664)
Loss: 2.241 | Acc: 20.275% (6501/32064)
Loss: 2.241 | Acc: 20.289% (7804/38464)
Loss: 2.241 | Acc: 20.290% (9103/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2632, Accuracy: 1896/10000 (18.96%)

Epoch: 33
Loss: 2.171 | Acc: 25.000% (16/64)
Loss: 2.232 | Acc: 20.498% (1325/6464)
Loss: 2.235 | Acc: 20.833% (2680/12864)
Loss: 2.233 | Acc: 21.153% (4075/19264)
Loss: 2.235 | Acc: 20.944% (5375/25664)
Loss: 2.234 | Acc: 20.964% (6722/32064)
Loss: 2.236 | Acc: 20.783% (7994/38464)
Loss: 2.237 | Acc: 20.667% (9272/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2569, Accuracy: 1901/10000 (19.01%)

Epoch: 34
Loss: 2.184 | Acc: 25.000% (16/64)
Loss: 2.243 | Acc: 20.359% (1316/6464)
Loss: 2.239 | Acc: 20.693% (2662/12864)
Loss: 2.236 | Acc: 20.904% (4027/19264)
Loss: 2.237 | Acc: 20.803% (5339/25664)
Loss: 2.238 | Acc: 20.787% (6665/32064)
Loss: 2.236 | Acc: 20.853% (8021/38464)
Loss: 2.236 | Acc: 20.850% (9354/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2570, Accuracy: 1934/10000 (19.34%)

Epoch: 35
Loss: 2.172 | Acc: 25.000% (16/64)
Loss: 2.222 | Acc: 21.860% (1413/6464)
Loss: 2.225 | Acc: 21.556% (2773/12864)
Loss: 2.228 | Acc: 21.382% (4119/19264)
Loss: 2.229 | Acc: 21.376% (5486/25664)
Loss: 2.231 | Acc: 21.236% (6809/32064)
Loss: 2.231 | Acc: 21.178% (8146/38464)
Loss: 2.232 | Acc: 21.077% (9456/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2543, Accuracy: 1910/10000 (19.10%)

Epoch: 36
Loss: 2.246 | Acc: 25.000% (16/64)
Loss: 2.232 | Acc: 21.566% (1394/6464)
Loss: 2.233 | Acc: 21.331% (2744/12864)
Loss: 2.231 | Acc: 21.512% (4144/19264)
Loss: 2.228 | Acc: 21.750% (5582/25664)
Loss: 2.229 | Acc: 21.654% (6943/32064)
Loss: 2.228 | Acc: 21.896% (8422/38464)
Loss: 2.228 | Acc: 21.850% (9803/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2499, Accuracy: 2006/10000 (20.06%)

Epoch: 37
Loss: 2.244 | Acc: 21.875% (14/64)
Loss: 2.223 | Acc: 21.767% (1407/6464)
Loss: 2.224 | Acc: 21.828% (2808/12864)
Loss: 2.222 | Acc: 22.067% (4251/19264)
Loss: 2.224 | Acc: 21.926% (5627/25664)
Loss: 2.226 | Acc: 21.891% (7019/32064)
Loss: 2.227 | Acc: 21.732% (8359/38464)
Loss: 2.227 | Acc: 21.786% (9774/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2531, Accuracy: 1996/10000 (19.96%)

Epoch: 38
Loss: 2.265 | Acc: 20.312% (13/64)
Loss: 2.220 | Acc: 22.540% (1457/6464)
Loss: 2.223 | Acc: 22.240% (2861/12864)
Loss: 2.225 | Acc: 21.968% (4232/19264)
Loss: 2.227 | Acc: 21.739% (5579/25664)
Loss: 2.224 | Acc: 21.947% (7037/32064)
Loss: 2.223 | Acc: 22.054% (8483/38464)
Loss: 2.223 | Acc: 21.993% (9867/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2436, Accuracy: 2086/10000 (20.86%)

Epoch: 39
Loss: 2.262 | Acc: 18.750% (12/64)
Loss: 2.225 | Acc: 22.123% (1430/6464)
Loss: 2.222 | Acc: 21.953% (2824/12864)
Loss: 2.223 | Acc: 21.958% (4230/19264)
Loss: 2.219 | Acc: 22.296% (5722/25664)
Loss: 2.219 | Acc: 22.318% (7156/32064)
Loss: 2.220 | Acc: 22.317% (8584/38464)
Loss: 2.221 | Acc: 22.200% (9960/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2460, Accuracy: 2067/10000 (20.67%)

Epoch: 40
Loss: 2.222 | Acc: 23.438% (15/64)
Loss: 2.216 | Acc: 22.308% (1442/6464)
Loss: 2.214 | Acc: 22.800% (2933/12864)
Loss: 2.216 | Acc: 22.711% (4375/19264)
Loss: 2.217 | Acc: 22.674% (5819/25664)
Loss: 2.216 | Acc: 22.714% (7283/32064)
Loss: 2.217 | Acc: 22.613% (8698/38464)
Loss: 2.216 | Acc: 22.704% (10186/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2475, Accuracy: 2069/10000 (20.69%)

Epoch: 41
Loss: 2.255 | Acc: 18.750% (12/64)
Loss: 2.206 | Acc: 23.546% (1522/6464)
Loss: 2.211 | Acc: 22.917% (2948/12864)
Loss: 2.213 | Acc: 22.794% (4391/19264)
Loss: 2.213 | Acc: 22.756% (5840/25664)
Loss: 2.213 | Acc: 22.683% (7273/32064)
Loss: 2.214 | Acc: 22.723% (8740/38464)
Loss: 2.213 | Acc: 22.735% (10200/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2493, Accuracy: 2053/10000 (20.53%)

Epoch: 42
Loss: 2.199 | Acc: 25.000% (16/64)
Loss: 2.209 | Acc: 23.175% (1498/6464)
Loss: 2.204 | Acc: 23.492% (3022/12864)
Loss: 2.208 | Acc: 23.017% (4434/19264)
Loss: 2.209 | Acc: 23.044% (5914/25664)
Loss: 2.208 | Acc: 23.110% (7410/32064)
Loss: 2.206 | Acc: 23.302% (8963/38464)
Loss: 2.206 | Acc: 23.277% (10443/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2474, Accuracy: 2116/10000 (21.16%)

Epoch: 43
Loss: 2.127 | Acc: 32.812% (21/64)
Loss: 2.190 | Acc: 24.892% (1609/6464)
Loss: 2.195 | Acc: 24.254% (3120/12864)
Loss: 2.197 | Acc: 24.055% (4634/19264)
Loss: 2.197 | Acc: 24.135% (6194/25664)
Loss: 2.197 | Acc: 24.064% (7716/32064)
Loss: 2.198 | Acc: 24.072% (9259/38464)
Loss: 2.200 | Acc: 23.859% (10704/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2437, Accuracy: 2131/10000 (21.31%)

Epoch: 44
Loss: 2.168 | Acc: 31.250% (20/64)
Loss: 2.194 | Acc: 24.180% (1563/6464)
Loss: 2.198 | Acc: 23.834% (3066/12864)
Loss: 2.195 | Acc: 24.009% (4625/19264)
Loss: 2.196 | Acc: 23.889% (6131/25664)
Loss: 2.196 | Acc: 23.887% (7659/32064)
Loss: 2.196 | Acc: 23.773% (9144/38464)
Loss: 2.197 | Acc: 23.754% (10657/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2464, Accuracy: 2156/10000 (21.56%)

Epoch: 45
Loss: 2.143 | Acc: 28.125% (18/64)
Loss: 2.192 | Acc: 24.118% (1559/6464)
Loss: 2.196 | Acc: 23.904% (3075/12864)
Loss: 2.200 | Acc: 23.733% (4572/19264)
Loss: 2.201 | Acc: 23.663% (6073/25664)
Loss: 2.203 | Acc: 23.540% (7548/32064)
Loss: 2.204 | Acc: 23.528% (9050/38464)
Loss: 2.205 | Acc: 23.536% (10559/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2395, Accuracy: 2124/10000 (21.24%)

Epoch: 46
Loss: 2.161 | Acc: 28.125% (18/64)
Loss: 2.217 | Acc: 22.710% (1468/6464)
Loss: 2.215 | Acc: 22.948% (2952/12864)
Loss: 2.217 | Acc: 22.757% (4384/19264)
Loss: 2.219 | Acc: 22.623% (5806/25664)
Loss: 2.219 | Acc: 22.652% (7263/32064)
Loss: 2.220 | Acc: 22.585% (8687/38464)
Loss: 2.220 | Acc: 22.533% (10109/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2444, Accuracy: 2065/10000 (20.65%)

Epoch: 47
Loss: 2.196 | Acc: 31.250% (20/64)
Loss: 2.223 | Acc: 23.066% (1491/6464)
Loss: 2.222 | Acc: 22.847% (2939/12864)
Loss: 2.223 | Acc: 22.648% (4363/19264)
Loss: 2.223 | Acc: 22.658% (5815/25664)
Loss: 2.223 | Acc: 22.673% (7270/32064)
Loss: 2.225 | Acc: 22.486% (8649/38464)
Loss: 2.225 | Acc: 22.352% (10028/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2412, Accuracy: 2105/10000 (21.05%)
torch.Size([100, 10])
Test set: Average loss: 2.2412, Accuracy: 2105/10000 (21.05%)

Epoch: 48
Loss: 2.234 | Acc: 20.312% (13/64)
Loss: 2.225 | Acc: 21.875% (1414/6464)
Loss: 2.226 | Acc: 21.898% (2817/12864)
Loss: 2.227 | Acc: 22.036% (4245/19264)
Loss: 2.229 | Acc: 21.887% (5617/25664)
Loss: 2.227 | Acc: 22.171% (7109/32064)
Loss: 2.227 | Acc: 22.242% (8555/38464)
Loss: 2.226 | Acc: 22.296% (10003/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2414, Accuracy: 2082/10000 (20.82%)
torch.Size([100, 10])
Test set: Average loss: 2.2414, Accuracy: 2082/10000 (20.82%)

Epoch: 49
Loss: 2.212 | Acc: 25.000% (16/64)
Loss: 2.223 | Acc: 22.556% (1458/6464)
Loss: 2.223 | Acc: 22.598% (2907/12864)
Loss: 2.227 | Acc: 22.114% (4260/19264)
Loss: 2.227 | Acc: 22.163% (5688/25664)
Loss: 2.227 | Acc: 22.115% (7091/32064)
Loss: 2.227 | Acc: 22.104% (8502/38464)
Loss: 2.226 | Acc: 22.140% (9933/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2412, Accuracy: 2065/10000 (20.65%)
torch.Size([100, 10])
Test set: Average loss: 2.2412, Accuracy: 2065/10000 (20.65%)

Epoch: 50
Loss: 2.240 | Acc: 20.312% (13/64)
Loss: 2.300 | Acc: 12.361% (799/6464)
Loss: 2.294 | Acc: 12.928% (1663/12864)
Loss: 2.289 | Acc: 14.026% (2702/19264)
Loss: 2.284 | Acc: 14.776% (3792/25664)
Loss: 2.283 | Acc: 15.095% (4840/32064)
Loss: 2.281 | Acc: 15.331% (5897/38464)
Loss: 2.280 | Acc: 15.636% (7015/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2759, Accuracy: 1605/10000 (16.05%)

Epoch: 51
Loss: 2.277 | Acc: 15.625% (10/64)
Loss: 2.267 | Acc: 17.652% (1141/6464)
Loss: 2.267 | Acc: 17.444% (2244/12864)
Loss: 2.266 | Acc: 17.598% (3390/19264)
Loss: 2.266 | Acc: 17.538% (4501/25664)
Loss: 2.266 | Acc: 17.584% (5638/32064)
Loss: 2.266 | Acc: 17.684% (6802/38464)
Loss: 2.265 | Acc: 17.809% (7990/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2972, Accuracy: 1692/10000 (16.92%)

Epoch: 52
Loss: 2.214 | Acc: 21.875% (14/64)
Loss: 2.264 | Acc: 18.178% (1175/6464)
Loss: 2.261 | Acc: 18.548% (2386/12864)
Loss: 2.261 | Acc: 18.511% (3566/19264)
Loss: 2.261 | Acc: 18.434% (4731/25664)
Loss: 2.261 | Acc: 18.366% (5889/32064)
Loss: 2.261 | Acc: 18.339% (7054/38464)
Loss: 2.261 | Acc: 18.208% (8169/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2780, Accuracy: 1790/10000 (17.90%)

Epoch: 53
Loss: 2.268 | Acc: 17.188% (11/64)
Loss: 2.259 | Acc: 18.688% (1208/6464)
Loss: 2.261 | Acc: 18.455% (2374/12864)
Loss: 2.261 | Acc: 18.522% (3568/19264)
Loss: 2.260 | Acc: 18.485% (4744/25664)
Loss: 2.260 | Acc: 18.519% (5938/32064)
Loss: 2.261 | Acc: 18.430% (7089/38464)
Loss: 2.261 | Acc: 18.485% (8293/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3266, Accuracy: 1457/10000 (14.57%)

Epoch: 54
Loss: 2.258 | Acc: 18.750% (12/64)
Loss: 2.258 | Acc: 18.518% (1197/6464)
Loss: 2.259 | Acc: 18.649% (2399/12864)
Loss: 2.257 | Acc: 18.792% (3620/19264)
Loss: 2.258 | Acc: 18.879% (4845/25664)
Loss: 2.258 | Acc: 18.825% (6036/32064)
Loss: 2.258 | Acc: 18.768% (7219/38464)
Loss: 2.258 | Acc: 18.861% (8462/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2690, Accuracy: 1824/10000 (18.24%)

Epoch: 55
Loss: 2.265 | Acc: 17.188% (11/64)
Loss: 2.259 | Acc: 18.379% (1188/6464)
Loss: 2.258 | Acc: 18.400% (2367/12864)
Loss: 2.256 | Acc: 18.859% (3633/19264)
Loss: 2.257 | Acc: 18.769% (4817/25664)
Loss: 2.258 | Acc: 18.800% (6028/32064)
Loss: 2.257 | Acc: 18.903% (7271/38464)
Loss: 2.258 | Acc: 18.873% (8467/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2712, Accuracy: 1743/10000 (17.43%)

Epoch: 56
Loss: 2.275 | Acc: 10.938% (7/64)
Loss: 2.257 | Acc: 18.735% (1211/6464)
Loss: 2.255 | Acc: 18.867% (2427/12864)
Loss: 2.257 | Acc: 18.911% (3643/19264)
Loss: 2.258 | Acc: 18.754% (4813/25664)
Loss: 2.258 | Acc: 18.635% (5975/32064)
Loss: 2.258 | Acc: 18.638% (7169/38464)
Loss: 2.258 | Acc: 18.752% (8413/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2944, Accuracy: 1697/10000 (16.97%)

Epoch: 57
Loss: 2.259 | Acc: 21.875% (14/64)
Loss: 2.254 | Acc: 19.245% (1244/6464)
Loss: 2.258 | Acc: 18.905% (2432/12864)
Loss: 2.258 | Acc: 18.786% (3619/19264)
Loss: 2.259 | Acc: 18.793% (4823/25664)
Loss: 2.257 | Acc: 18.884% (6055/32064)
Loss: 2.256 | Acc: 19.049% (7327/38464)
Loss: 2.256 | Acc: 19.046% (8545/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2649, Accuracy: 1858/10000 (18.58%)

Epoch: 58
Loss: 2.269 | Acc: 17.188% (11/64)
Loss: 2.251 | Acc: 19.833% (1282/6464)
Loss: 2.254 | Acc: 19.271% (2479/12864)
Loss: 2.253 | Acc: 19.254% (3709/19264)
Loss: 2.252 | Acc: 19.475% (4998/25664)
Loss: 2.252 | Acc: 19.514% (6257/32064)
Loss: 2.253 | Acc: 19.486% (7495/38464)
Loss: 2.254 | Acc: 19.356% (8684/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2816, Accuracy: 1712/10000 (17.12%)

Epoch: 59
Loss: 2.239 | Acc: 25.000% (16/64)
Loss: 2.252 | Acc: 19.446% (1257/6464)
Loss: 2.253 | Acc: 19.419% (2498/12864)
Loss: 2.254 | Acc: 19.316% (3721/19264)
Loss: 2.254 | Acc: 19.522% (5010/25664)
Loss: 2.253 | Acc: 19.489% (6249/32064)
Loss: 2.253 | Acc: 19.522% (7509/38464)
Loss: 2.254 | Acc: 19.356% (8684/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3161, Accuracy: 1487/10000 (14.87%)

Epoch: 60
Loss: 2.271 | Acc: 12.500% (8/64)
Loss: 2.248 | Acc: 19.601% (1267/6464)
Loss: 2.250 | Acc: 19.543% (2514/12864)
Loss: 2.249 | Acc: 19.591% (3774/19264)
Loss: 2.248 | Acc: 19.712% (5059/25664)
Loss: 2.250 | Acc: 19.548% (6268/32064)
Loss: 2.251 | Acc: 19.462% (7486/38464)
Loss: 2.252 | Acc: 19.463% (8732/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3483, Accuracy: 1649/10000 (16.49%)

Epoch: 61
Loss: 2.326 | Acc: 15.625% (10/64)
Loss: 2.253 | Acc: 19.694% (1273/6464)
Loss: 2.249 | Acc: 19.745% (2540/12864)
Loss: 2.250 | Acc: 19.643% (3784/19264)
Loss: 2.252 | Acc: 19.557% (5019/25664)
Loss: 2.251 | Acc: 19.452% (6237/32064)
Loss: 2.252 | Acc: 19.431% (7474/38464)
Loss: 2.252 | Acc: 19.483% (8741/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2787, Accuracy: 1789/10000 (17.89%)

Epoch: 62
Loss: 2.208 | Acc: 28.125% (18/64)
Loss: 2.252 | Acc: 19.168% (1239/6464)
Loss: 2.253 | Acc: 19.248% (2476/12864)
Loss: 2.252 | Acc: 19.186% (3696/19264)
Loss: 2.250 | Acc: 19.592% (5028/25664)
Loss: 2.250 | Acc: 19.689% (6313/32064)
Loss: 2.250 | Acc: 19.764% (7602/38464)
Loss: 2.250 | Acc: 19.720% (8847/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2777, Accuracy: 1680/10000 (16.80%)

Epoch: 63
Loss: 2.240 | Acc: 21.875% (14/64)
Loss: 2.252 | Acc: 19.075% (1233/6464)
Loss: 2.248 | Acc: 20.009% (2574/12864)
Loss: 2.246 | Acc: 20.157% (3883/19264)
Loss: 2.246 | Acc: 20.176% (5178/25664)
Loss: 2.249 | Acc: 19.873% (6372/32064)
Loss: 2.249 | Acc: 19.928% (7665/38464)
Loss: 2.250 | Acc: 19.789% (8878/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3087, Accuracy: 1609/10000 (16.09%)

Epoch: 64
Loss: 2.261 | Acc: 15.625% (10/64)
Loss: 2.253 | Acc: 19.756% (1277/6464)
Loss: 2.249 | Acc: 19.939% (2565/12864)
Loss: 2.249 | Acc: 20.094% (3871/19264)
Loss: 2.250 | Acc: 20.040% (5143/25664)
Loss: 2.249 | Acc: 20.051% (6429/32064)
Loss: 2.248 | Acc: 20.120% (7739/38464)
Loss: 2.248 | Acc: 20.076% (9007/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2768, Accuracy: 1720/10000 (17.20%)

Epoch: 65
Loss: 2.216 | Acc: 17.188% (11/64)
Loss: 2.250 | Acc: 19.957% (1290/6464)
Loss: 2.246 | Acc: 20.274% (2608/12864)
Loss: 2.248 | Acc: 19.928% (3839/19264)
Loss: 2.250 | Acc: 19.748% (5068/25664)
Loss: 2.250 | Acc: 19.795% (6347/32064)
Loss: 2.249 | Acc: 19.959% (7677/38464)
Loss: 2.248 | Acc: 20.016% (8980/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3123, Accuracy: 1614/10000 (16.14%)

Epoch: 66
Loss: 2.207 | Acc: 23.438% (15/64)
Loss: 2.247 | Acc: 19.910% (1287/6464)
Loss: 2.246 | Acc: 20.196% (2598/12864)
Loss: 2.246 | Acc: 20.079% (3868/19264)
Loss: 2.246 | Acc: 20.024% (5139/25664)
Loss: 2.246 | Acc: 20.200% (6477/32064)
Loss: 2.246 | Acc: 20.201% (7770/38464)
Loss: 2.245 | Acc: 20.243% (9082/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2736, Accuracy: 1745/10000 (17.45%)

Epoch: 67
Loss: 2.236 | Acc: 29.688% (19/64)
Loss: 2.247 | Acc: 20.173% (1304/6464)
Loss: 2.249 | Acc: 19.947% (2566/12864)
Loss: 2.247 | Acc: 20.074% (3867/19264)
Loss: 2.246 | Acc: 20.219% (5189/25664)
Loss: 2.245 | Acc: 20.194% (6475/32064)
Loss: 2.245 | Acc: 20.154% (7752/38464)
Loss: 2.245 | Acc: 20.259% (9089/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2782, Accuracy: 1760/10000 (17.60%)

Epoch: 68
Loss: 2.244 | Acc: 18.750% (12/64)
Loss: 2.238 | Acc: 20.978% (1356/6464)
Loss: 2.239 | Acc: 20.771% (2672/12864)
Loss: 2.241 | Acc: 20.686% (3985/19264)
Loss: 2.241 | Acc: 20.726% (5319/25664)
Loss: 2.242 | Acc: 20.621% (6612/32064)
Loss: 2.243 | Acc: 20.518% (7892/38464)
Loss: 2.243 | Acc: 20.531% (9211/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2553, Accuracy: 1991/10000 (19.91%)

Epoch: 69
Loss: 2.297 | Acc: 18.750% (12/64)
Loss: 2.237 | Acc: 21.086% (1363/6464)
Loss: 2.235 | Acc: 21.199% (2727/12864)
Loss: 2.240 | Acc: 20.977% (4041/19264)
Loss: 2.240 | Acc: 20.846% (5350/25664)
Loss: 2.241 | Acc: 20.880% (6695/32064)
Loss: 2.241 | Acc: 20.843% (8017/38464)
Loss: 2.241 | Acc: 20.921% (9386/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2746, Accuracy: 1843/10000 (18.43%)

Epoch: 70
Loss: 2.286 | Acc: 15.625% (10/64)
Loss: 2.238 | Acc: 20.761% (1342/6464)
Loss: 2.239 | Acc: 21.059% (2709/12864)
Loss: 2.244 | Acc: 20.645% (3977/19264)
Loss: 2.242 | Acc: 20.729% (5320/25664)
Loss: 2.241 | Acc: 20.690% (6634/32064)
Loss: 2.242 | Acc: 20.658% (7946/38464)
Loss: 2.241 | Acc: 20.718% (9295/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2859, Accuracy: 1884/10000 (18.84%)

Epoch: 71
Loss: 2.257 | Acc: 14.062% (9/64)
Loss: 2.240 | Acc: 21.101% (1364/6464)
Loss: 2.237 | Acc: 21.354% (2747/12864)
Loss: 2.239 | Acc: 21.273% (4098/19264)
Loss: 2.240 | Acc: 21.072% (5408/25664)
Loss: 2.239 | Acc: 21.070% (6756/32064)
Loss: 2.238 | Acc: 21.134% (8129/38464)
Loss: 2.238 | Acc: 21.110% (9471/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2789, Accuracy: 1825/10000 (18.25%)

Epoch: 72
Loss: 2.252 | Acc: 17.188% (11/64)
Loss: 2.233 | Acc: 21.040% (1360/6464)
Loss: 2.236 | Acc: 20.965% (2697/12864)
Loss: 2.236 | Acc: 21.050% (4055/19264)
Loss: 2.236 | Acc: 21.096% (5414/25664)
Loss: 2.237 | Acc: 21.002% (6734/32064)
Loss: 2.234 | Acc: 21.243% (8171/38464)
Loss: 2.235 | Acc: 21.217% (9519/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3042, Accuracy: 1742/10000 (17.42%)

Epoch: 73
Loss: 2.207 | Acc: 21.875% (14/64)
Loss: 2.229 | Acc: 21.442% (1386/6464)
Loss: 2.234 | Acc: 21.105% (2715/12864)
Loss: 2.236 | Acc: 21.044% (4054/19264)
Loss: 2.234 | Acc: 21.244% (5452/25664)
Loss: 2.236 | Acc: 21.142% (6779/32064)
Loss: 2.235 | Acc: 21.191% (8151/38464)
Loss: 2.235 | Acc: 21.193% (9508/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2740, Accuracy: 1788/10000 (17.88%)

Epoch: 74
Loss: 2.260 | Acc: 18.750% (12/64)
Loss: 2.233 | Acc: 21.488% (1389/6464)
Loss: 2.232 | Acc: 21.852% (2811/12864)
Loss: 2.232 | Acc: 21.699% (4180/19264)
Loss: 2.233 | Acc: 21.606% (5545/25664)
Loss: 2.233 | Acc: 21.569% (6916/32064)
Loss: 2.234 | Acc: 21.402% (8232/38464)
Loss: 2.234 | Acc: 21.456% (9626/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2726, Accuracy: 1858/10000 (18.58%)

Epoch: 75
Loss: 2.174 | Acc: 23.438% (15/64)
Loss: 2.220 | Acc: 22.123% (1430/6464)
Loss: 2.227 | Acc: 21.922% (2820/12864)
Loss: 2.231 | Acc: 21.543% (4150/19264)
Loss: 2.232 | Acc: 21.493% (5516/25664)
Loss: 2.231 | Acc: 21.597% (6925/32064)
Loss: 2.230 | Acc: 21.766% (8372/38464)
Loss: 2.232 | Acc: 21.601% (9691/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2596, Accuracy: 1904/10000 (19.04%)

Epoch: 76
Loss: 2.239 | Acc: 21.875% (14/64)
Loss: 2.225 | Acc: 22.339% (1444/6464)
Loss: 2.224 | Acc: 22.186% (2854/12864)
Loss: 2.228 | Acc: 21.906% (4220/19264)
Loss: 2.230 | Acc: 21.665% (5560/25664)
Loss: 2.230 | Acc: 21.700% (6958/32064)
Loss: 2.231 | Acc: 21.768% (8373/38464)
Loss: 2.230 | Acc: 21.761% (9763/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2524, Accuracy: 2045/10000 (20.45%)

Epoch: 77
Loss: 2.110 | Acc: 32.812% (21/64)
Loss: 2.220 | Acc: 22.556% (1458/6464)
Loss: 2.221 | Acc: 22.924% (2949/12864)
Loss: 2.223 | Acc: 22.664% (4366/19264)
Loss: 2.228 | Acc: 22.113% (5675/25664)
Loss: 2.227 | Acc: 22.193% (7116/32064)
Loss: 2.225 | Acc: 22.265% (8564/38464)
Loss: 2.227 | Acc: 22.187% (9954/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2510, Accuracy: 2014/10000 (20.14%)

Epoch: 78
Loss: 2.225 | Acc: 20.312% (13/64)
Loss: 2.229 | Acc: 21.736% (1405/6464)
Loss: 2.231 | Acc: 21.782% (2802/12864)
Loss: 2.231 | Acc: 21.704% (4181/19264)
Loss: 2.229 | Acc: 21.906% (5622/25664)
Loss: 2.228 | Acc: 22.034% (7065/32064)
Loss: 2.226 | Acc: 22.086% (8495/38464)
Loss: 2.225 | Acc: 22.156% (9940/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2447, Accuracy: 2095/10000 (20.95%)

Epoch: 79
Loss: 2.208 | Acc: 25.000% (16/64)
Loss: 2.220 | Acc: 22.772% (1472/6464)
Loss: 2.223 | Acc: 22.373% (2878/12864)
Loss: 2.222 | Acc: 22.638% (4361/19264)
Loss: 2.223 | Acc: 22.557% (5789/25664)
Loss: 2.224 | Acc: 22.418% (7188/32064)
Loss: 2.224 | Acc: 22.429% (8627/38464)
Loss: 2.223 | Acc: 22.468% (10080/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2818, Accuracy: 1832/10000 (18.32%)

Epoch: 80
Loss: 2.332 | Acc: 10.938% (7/64)
Loss: 2.225 | Acc: 22.030% (1424/6464)
Loss: 2.222 | Acc: 22.637% (2912/12864)
Loss: 2.221 | Acc: 22.555% (4345/19264)
Loss: 2.221 | Acc: 22.604% (5801/25664)
Loss: 2.222 | Acc: 22.499% (7214/32064)
Loss: 2.222 | Acc: 22.522% (8663/38464)
Loss: 2.222 | Acc: 22.570% (10126/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2506, Accuracy: 2067/10000 (20.67%)

Epoch: 81
Loss: 2.272 | Acc: 21.875% (14/64)
Loss: 2.213 | Acc: 22.587% (1460/6464)
Loss: 2.221 | Acc: 22.155% (2850/12864)
Loss: 2.221 | Acc: 22.311% (4298/19264)
Loss: 2.221 | Acc: 22.393% (5747/25664)
Loss: 2.219 | Acc: 22.564% (7235/32064)
Loss: 2.220 | Acc: 22.593% (8690/38464)
Loss: 2.219 | Acc: 22.617% (10147/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2528, Accuracy: 2027/10000 (20.27%)

Epoch: 82
Loss: 2.259 | Acc: 20.312% (13/64)
Loss: 2.227 | Acc: 21.983% (1421/6464)
Loss: 2.220 | Acc: 22.606% (2908/12864)
Loss: 2.220 | Acc: 22.695% (4372/19264)
Loss: 2.218 | Acc: 22.806% (5853/25664)
Loss: 2.216 | Acc: 22.942% (7356/32064)
Loss: 2.217 | Acc: 22.915% (8814/38464)
Loss: 2.217 | Acc: 22.927% (10286/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2540, Accuracy: 2109/10000 (21.09%)

Epoch: 83
Loss: 2.187 | Acc: 23.438% (15/64)
Loss: 2.211 | Acc: 23.252% (1503/6464)
Loss: 2.209 | Acc: 23.507% (3024/12864)
Loss: 2.210 | Acc: 23.458% (4519/19264)
Loss: 2.210 | Acc: 23.531% (6039/25664)
Loss: 2.212 | Acc: 23.369% (7493/32064)
Loss: 2.211 | Acc: 23.318% (8969/38464)
Loss: 2.212 | Acc: 23.346% (10474/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2565, Accuracy: 1905/10000 (19.05%)

Epoch: 84
Loss: 2.283 | Acc: 15.625% (10/64)
Loss: 2.217 | Acc: 22.571% (1459/6464)
Loss: 2.211 | Acc: 23.095% (2971/12864)
Loss: 2.213 | Acc: 23.085% (4447/19264)
Loss: 2.215 | Acc: 22.939% (5887/25664)
Loss: 2.214 | Acc: 23.045% (7389/32064)
Loss: 2.212 | Acc: 23.172% (8913/38464)
Loss: 2.211 | Acc: 23.344% (10473/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2418, Accuracy: 2148/10000 (21.48%)

Epoch: 85
Loss: 2.242 | Acc: 20.312% (13/64)
Loss: 2.204 | Acc: 23.933% (1547/6464)
Loss: 2.207 | Acc: 23.492% (3022/12864)
Loss: 2.206 | Acc: 23.630% (4552/19264)
Loss: 2.203 | Acc: 23.913% (6137/25664)
Loss: 2.204 | Acc: 23.883% (7658/32064)
Loss: 2.207 | Acc: 23.614% (9083/38464)
Loss: 2.208 | Acc: 23.627% (10600/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2400, Accuracy: 2170/10000 (21.70%)

Epoch: 86
Loss: 2.086 | Acc: 34.375% (22/64)
Loss: 2.195 | Acc: 24.551% (1587/6464)
Loss: 2.195 | Acc: 24.518% (3154/12864)
Loss: 2.196 | Acc: 24.502% (4720/19264)
Loss: 2.198 | Acc: 24.361% (6252/25664)
Loss: 2.200 | Acc: 24.083% (7722/32064)
Loss: 2.202 | Acc: 23.973% (9221/38464)
Loss: 2.203 | Acc: 23.941% (10741/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2500, Accuracy: 2121/10000 (21.21%)

Epoch: 87
Loss: 2.127 | Acc: 29.688% (19/64)
Loss: 2.197 | Acc: 23.871% (1543/6464)
Loss: 2.198 | Acc: 23.935% (3079/12864)
Loss: 2.201 | Acc: 23.728% (4571/19264)
Loss: 2.199 | Acc: 23.979% (6154/25664)
Loss: 2.199 | Acc: 23.958% (7682/32064)
Loss: 2.199 | Acc: 24.020% (9239/38464)
Loss: 2.198 | Acc: 24.128% (10825/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2481, Accuracy: 2117/10000 (21.17%)

Epoch: 88
Loss: 2.202 | Acc: 23.438% (15/64)
Loss: 2.196 | Acc: 24.165% (1562/6464)
Loss: 2.193 | Acc: 24.425% (3142/12864)
Loss: 2.193 | Acc: 24.372% (4695/19264)
Loss: 2.193 | Acc: 24.431% (6270/25664)
Loss: 2.193 | Acc: 24.420% (7830/32064)
Loss: 2.192 | Acc: 24.527% (9434/38464)
Loss: 2.191 | Acc: 24.621% (11046/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2526, Accuracy: 2106/10000 (21.06%)

Epoch: 89
Loss: 2.152 | Acc: 28.125% (18/64)
Loss: 2.194 | Acc: 24.335% (1573/6464)
Loss: 2.186 | Acc: 24.860% (3198/12864)
Loss: 2.187 | Acc: 24.777% (4773/19264)
Loss: 2.187 | Acc: 24.793% (6363/25664)
Loss: 2.188 | Acc: 24.775% (7944/32064)
Loss: 2.188 | Acc: 24.873% (9567/38464)
Loss: 2.187 | Acc: 24.960% (11198/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2483, Accuracy: 2108/10000 (21.08%)

Epoch: 90
Loss: 2.234 | Acc: 20.312% (13/64)
Loss: 2.179 | Acc: 25.511% (1649/6464)
Loss: 2.183 | Acc: 25.109% (3230/12864)
Loss: 2.184 | Acc: 25.031% (4822/19264)
Loss: 2.182 | Acc: 25.066% (6433/25664)
Loss: 2.181 | Acc: 25.125% (8056/32064)
Loss: 2.182 | Acc: 25.138% (9669/38464)
Loss: 2.182 | Acc: 25.087% (11255/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2530, Accuracy: 2165/10000 (21.65%)

Epoch: 91
Loss: 2.219 | Acc: 18.750% (12/64)
Loss: 2.176 | Acc: 25.031% (1618/6464)
Loss: 2.173 | Acc: 25.428% (3271/12864)
Loss: 2.173 | Acc: 25.415% (4896/19264)
Loss: 2.172 | Acc: 25.577% (6564/25664)
Loss: 2.173 | Acc: 25.443% (8158/32064)
Loss: 2.173 | Acc: 25.463% (9794/38464)
Loss: 2.174 | Acc: 25.495% (11438/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2473, Accuracy: 2183/10000 (21.83%)

Epoch: 92
Loss: 2.128 | Acc: 28.125% (18/64)
Loss: 2.161 | Acc: 25.944% (1677/6464)
Loss: 2.158 | Acc: 26.446% (3402/12864)
Loss: 2.160 | Acc: 26.386% (5083/19264)
Loss: 2.162 | Acc: 26.227% (6731/25664)
Loss: 2.166 | Acc: 25.964% (8325/32064)
Loss: 2.166 | Acc: 25.931% (9974/38464)
Loss: 2.167 | Acc: 25.849% (11597/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2548, Accuracy: 2164/10000 (21.64%)

Epoch: 93
Loss: 2.107 | Acc: 34.375% (22/64)
Loss: 2.146 | Acc: 27.166% (1756/6464)
Loss: 2.148 | Acc: 26.975% (3470/12864)
Loss: 2.148 | Acc: 26.957% (5193/19264)
Loss: 2.149 | Acc: 26.901% (6904/25664)
Loss: 2.152 | Acc: 26.690% (8558/32064)
Loss: 2.154 | Acc: 26.542% (10209/38464)
Loss: 2.154 | Acc: 26.540% (11907/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2596, Accuracy: 2164/10000 (21.64%)

Epoch: 94
Loss: 2.150 | Acc: 23.438% (15/64)
Loss: 2.135 | Acc: 27.351% (1768/6464)
Loss: 2.143 | Acc: 27.177% (3496/12864)
Loss: 2.140 | Acc: 27.320% (5263/19264)
Loss: 2.141 | Acc: 27.244% (6992/25664)
Loss: 2.144 | Acc: 27.083% (8684/32064)
Loss: 2.144 | Acc: 27.064% (10410/38464)
Loss: 2.144 | Acc: 26.957% (12094/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2672, Accuracy: 2138/10000 (21.38%)

Epoch: 95
Loss: 2.051 | Acc: 31.250% (20/64)
Loss: 2.131 | Acc: 27.769% (1795/6464)
Loss: 2.135 | Acc: 27.488% (3536/12864)
Loss: 2.141 | Acc: 27.082% (5217/19264)
Loss: 2.148 | Acc: 26.777% (6872/25664)
Loss: 2.152 | Acc: 26.541% (8510/32064)
Loss: 2.154 | Acc: 26.503% (10194/38464)
Loss: 2.155 | Acc: 26.576% (11923/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2489, Accuracy: 2168/10000 (21.68%)

Epoch: 96
Loss: 2.147 | Acc: 28.125% (18/64)
Loss: 2.171 | Acc: 25.511% (1649/6464)
Loss: 2.170 | Acc: 25.933% (3336/12864)
Loss: 2.174 | Acc: 25.607% (4933/19264)
Loss: 2.174 | Acc: 25.623% (6576/25664)
Loss: 2.174 | Acc: 25.661% (8228/32064)
Loss: 2.174 | Acc: 25.738% (9900/38464)
Loss: 2.176 | Acc: 25.642% (11504/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2405, Accuracy: 2168/10000 (21.68%)

Epoch: 97
Loss: 2.175 | Acc: 25.000% (16/64)
Loss: 2.170 | Acc: 25.665% (1659/6464)
Loss: 2.173 | Acc: 25.692% (3305/12864)
Loss: 2.177 | Acc: 25.472% (4907/19264)
Loss: 2.178 | Acc: 25.370% (6511/25664)
Loss: 2.179 | Acc: 25.409% (8147/32064)
Loss: 2.180 | Acc: 25.341% (9747/38464)
Loss: 2.181 | Acc: 25.232% (11320/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2422, Accuracy: 2177/10000 (21.77%)
torch.Size([100, 10])
Test set: Average loss: 2.2422, Accuracy: 2177/10000 (21.77%)

Epoch: 98
Loss: 2.084 | Acc: 26.562% (17/64)
Loss: 2.181 | Acc: 25.603% (1655/6464)
Loss: 2.181 | Acc: 25.599% (3293/12864)
Loss: 2.179 | Acc: 25.571% (4926/19264)
Loss: 2.181 | Acc: 25.487% (6541/25664)
Loss: 2.183 | Acc: 25.281% (8106/32064)
Loss: 2.182 | Acc: 25.216% (9699/38464)
Loss: 2.183 | Acc: 25.225% (11317/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2409, Accuracy: 2160/10000 (21.60%)
torch.Size([100, 10])
Test set: Average loss: 2.2409, Accuracy: 2160/10000 (21.60%)

Epoch: 99
Loss: 2.085 | Acc: 29.688% (19/64)
Loss: 2.179 | Acc: 25.603% (1655/6464)
Loss: 2.184 | Acc: 24.984% (3214/12864)
Loss: 2.182 | Acc: 25.213% (4857/19264)
Loss: 2.183 | Acc: 25.183% (6463/25664)
Loss: 2.182 | Acc: 25.337% (8124/32064)
Loss: 2.182 | Acc: 25.400% (9770/38464)
Loss: 2.182 | Acc: 25.424% (11406/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2410, Accuracy: 2175/10000 (21.75%)
torch.Size([100, 10])
Test set: Average loss: 2.2410, Accuracy: 2175/10000 (21.75%)

Epoch: 100
Loss: 2.123 | Acc: 26.562% (17/64)
Loss: 2.304 | Acc: 12.314% (796/6464)
Loss: 2.299 | Acc: 12.679% (1631/12864)
Loss: 2.296 | Acc: 13.196% (2542/19264)
Loss: 2.291 | Acc: 13.992% (3591/25664)
Loss: 2.286 | Acc: 14.686% (4709/32064)
Loss: 2.282 | Acc: 15.214% (5852/38464)
Loss: 2.278 | Acc: 15.696% (7042/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3016, Accuracy: 1581/10000 (15.81%)

Epoch: 101
Loss: 2.273 | Acc: 18.750% (12/64)
Loss: 2.257 | Acc: 19.338% (1250/6464)
Loss: 2.256 | Acc: 19.481% (2506/12864)
Loss: 2.254 | Acc: 19.601% (3776/19264)
Loss: 2.255 | Acc: 19.350% (4966/25664)
Loss: 2.255 | Acc: 19.361% (6208/32064)
Loss: 2.255 | Acc: 19.475% (7491/38464)
Loss: 2.255 | Acc: 19.472% (8736/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2670, Accuracy: 1826/10000 (18.26%)

Epoch: 102
Loss: 2.259 | Acc: 17.188% (11/64)
Loss: 2.246 | Acc: 19.972% (1291/6464)
Loss: 2.248 | Acc: 19.652% (2528/12864)
Loss: 2.248 | Acc: 19.664% (3788/19264)
Loss: 2.250 | Acc: 19.599% (5030/25664)
Loss: 2.250 | Acc: 19.711% (6320/32064)
Loss: 2.251 | Acc: 19.704% (7579/38464)
Loss: 2.251 | Acc: 19.782% (8875/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3037, Accuracy: 1672/10000 (16.72%)

Epoch: 103
Loss: 2.271 | Acc: 12.500% (8/64)
Loss: 2.248 | Acc: 19.910% (1287/6464)
Loss: 2.252 | Acc: 19.535% (2513/12864)
Loss: 2.250 | Acc: 19.710% (3797/19264)
Loss: 2.250 | Acc: 19.642% (5041/25664)
Loss: 2.250 | Acc: 19.748% (6332/32064)
Loss: 2.249 | Acc: 19.834% (7629/38464)
Loss: 2.250 | Acc: 19.851% (8906/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3893, Accuracy: 1472/10000 (14.72%)

Epoch: 104
Loss: 2.210 | Acc: 23.438% (15/64)
Loss: 2.243 | Acc: 20.483% (1324/6464)
Loss: 2.249 | Acc: 19.978% (2570/12864)
Loss: 2.246 | Acc: 20.136% (3879/19264)
Loss: 2.247 | Acc: 20.145% (5170/25664)
Loss: 2.248 | Acc: 20.206% (6479/32064)
Loss: 2.249 | Acc: 20.079% (7723/38464)
Loss: 2.248 | Acc: 20.119% (9026/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2789, Accuracy: 1756/10000 (17.56%)

Epoch: 105
Loss: 2.275 | Acc: 17.188% (11/64)
Loss: 2.245 | Acc: 20.684% (1337/6464)
Loss: 2.243 | Acc: 20.709% (2664/12864)
Loss: 2.244 | Acc: 20.603% (3969/19264)
Loss: 2.245 | Acc: 20.371% (5228/25664)
Loss: 2.246 | Acc: 20.272% (6500/32064)
Loss: 2.247 | Acc: 20.237% (7784/38464)
Loss: 2.247 | Acc: 20.219% (9071/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2652, Accuracy: 1789/10000 (17.89%)

Epoch: 106
Loss: 2.284 | Acc: 15.625% (10/64)
Loss: 2.247 | Acc: 20.637% (1334/6464)
Loss: 2.246 | Acc: 20.522% (2640/12864)
Loss: 2.248 | Acc: 20.115% (3875/19264)
Loss: 2.249 | Acc: 20.161% (5174/25664)
Loss: 2.249 | Acc: 20.241% (6490/32064)
Loss: 2.248 | Acc: 20.183% (7763/38464)
Loss: 2.247 | Acc: 20.310% (9112/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3025, Accuracy: 1708/10000 (17.08%)

Epoch: 107
Loss: 2.333 | Acc: 10.938% (7/64)
Loss: 2.238 | Acc: 20.885% (1350/6464)
Loss: 2.245 | Acc: 20.546% (2643/12864)
Loss: 2.244 | Acc: 20.489% (3947/19264)
Loss: 2.245 | Acc: 20.488% (5258/25664)
Loss: 2.245 | Acc: 20.475% (6565/32064)
Loss: 2.245 | Acc: 20.466% (7872/38464)
Loss: 2.246 | Acc: 20.413% (9158/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2594, Accuracy: 1844/10000 (18.44%)

Epoch: 108
Loss: 2.238 | Acc: 18.750% (12/64)
Loss: 2.250 | Acc: 19.353% (1251/6464)
Loss: 2.248 | Acc: 19.722% (2537/12864)
Loss: 2.247 | Acc: 19.850% (3824/19264)
Loss: 2.248 | Acc: 19.938% (5117/25664)
Loss: 2.247 | Acc: 20.013% (6417/32064)
Loss: 2.247 | Acc: 19.917% (7661/38464)
Loss: 2.246 | Acc: 20.056% (8998/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2850, Accuracy: 1664/10000 (16.64%)

Epoch: 109
Loss: 2.205 | Acc: 23.438% (15/64)
Loss: 2.241 | Acc: 21.303% (1377/6464)
Loss: 2.241 | Acc: 21.175% (2724/12864)
Loss: 2.242 | Acc: 21.081% (4061/19264)
Loss: 2.242 | Acc: 20.952% (5377/25664)
Loss: 2.242 | Acc: 20.855% (6687/32064)
Loss: 2.243 | Acc: 20.775% (7991/38464)
Loss: 2.244 | Acc: 20.665% (9271/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2736, Accuracy: 1796/10000 (17.96%)

Epoch: 110
Loss: 2.262 | Acc: 17.188% (11/64)
Loss: 2.247 | Acc: 20.034% (1295/6464)
Loss: 2.245 | Acc: 20.429% (2628/12864)
Loss: 2.246 | Acc: 20.406% (3931/19264)
Loss: 2.245 | Acc: 20.429% (5243/25664)
Loss: 2.245 | Acc: 20.440% (6554/32064)
Loss: 2.245 | Acc: 20.409% (7850/38464)
Loss: 2.244 | Acc: 20.453% (9176/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2715, Accuracy: 1726/10000 (17.26%)

Epoch: 111
Loss: 2.307 | Acc: 18.750% (12/64)
Loss: 2.242 | Acc: 21.101% (1364/6464)
Loss: 2.244 | Acc: 20.553% (2644/12864)
Loss: 2.245 | Acc: 20.396% (3929/19264)
Loss: 2.243 | Acc: 20.593% (5285/25664)
Loss: 2.242 | Acc: 20.659% (6624/32064)
Loss: 2.243 | Acc: 20.494% (7883/38464)
Loss: 2.244 | Acc: 20.359% (9134/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2931, Accuracy: 1796/10000 (17.96%)

Epoch: 112
Loss: 2.215 | Acc: 21.875% (14/64)
Loss: 2.237 | Acc: 20.916% (1352/6464)
Loss: 2.244 | Acc: 20.258% (2606/12864)
Loss: 2.243 | Acc: 20.546% (3958/19264)
Loss: 2.243 | Acc: 20.640% (5297/25664)
Loss: 2.242 | Acc: 20.702% (6638/32064)
Loss: 2.243 | Acc: 20.632% (7936/38464)
Loss: 2.242 | Acc: 20.734% (9302/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2782, Accuracy: 1879/10000 (18.79%)

Epoch: 113
Loss: 2.199 | Acc: 25.000% (16/64)
Loss: 2.240 | Acc: 20.838% (1347/6464)
Loss: 2.241 | Acc: 20.794% (2675/12864)
Loss: 2.238 | Acc: 21.044% (4054/19264)
Loss: 2.238 | Acc: 21.154% (5429/25664)
Loss: 2.239 | Acc: 21.105% (6767/32064)
Loss: 2.240 | Acc: 21.004% (8079/38464)
Loss: 2.241 | Acc: 20.963% (9405/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2971, Accuracy: 1640/10000 (16.40%)

Epoch: 114
Loss: 2.279 | Acc: 23.438% (15/64)
Loss: 2.238 | Acc: 20.885% (1350/6464)
Loss: 2.236 | Acc: 21.051% (2708/12864)
Loss: 2.237 | Acc: 21.070% (4059/19264)
Loss: 2.237 | Acc: 21.150% (5428/25664)
Loss: 2.239 | Acc: 21.027% (6742/32064)
Loss: 2.240 | Acc: 20.910% (8043/38464)
Loss: 2.240 | Acc: 20.852% (9355/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3266, Accuracy: 1637/10000 (16.37%)

Epoch: 115
Loss: 2.256 | Acc: 20.312% (13/64)
Loss: 2.225 | Acc: 22.370% (1446/6464)
Loss: 2.232 | Acc: 21.727% (2795/12864)
Loss: 2.236 | Acc: 21.278% (4099/19264)
Loss: 2.236 | Acc: 21.252% (5454/25664)
Loss: 2.237 | Acc: 21.120% (6772/32064)
Loss: 2.238 | Acc: 21.225% (8164/38464)
Loss: 2.239 | Acc: 21.113% (9472/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2533, Accuracy: 1984/10000 (19.84%)

Epoch: 116
Loss: 2.144 | Acc: 28.125% (18/64)
Loss: 2.239 | Acc: 20.606% (1332/6464)
Loss: 2.237 | Acc: 21.074% (2711/12864)
Loss: 2.240 | Acc: 20.811% (4009/19264)
Loss: 2.239 | Acc: 21.041% (5400/25664)
Loss: 2.238 | Acc: 20.930% (6711/32064)
Loss: 2.238 | Acc: 21.020% (8085/38464)
Loss: 2.238 | Acc: 21.037% (9438/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2563, Accuracy: 1937/10000 (19.37%)

Epoch: 117
Loss: 2.176 | Acc: 28.125% (18/64)
Loss: 2.237 | Acc: 21.101% (1364/6464)
Loss: 2.237 | Acc: 21.168% (2723/12864)
Loss: 2.237 | Acc: 21.070% (4059/19264)
Loss: 2.239 | Acc: 20.905% (5365/25664)
Loss: 2.239 | Acc: 20.961% (6721/32064)
Loss: 2.238 | Acc: 21.077% (8107/38464)
Loss: 2.238 | Acc: 21.104% (9468/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3039, Accuracy: 1664/10000 (16.64%)

Epoch: 118
Loss: 2.293 | Acc: 17.188% (11/64)
Loss: 2.225 | Acc: 22.788% (1473/6464)
Loss: 2.232 | Acc: 21.922% (2820/12864)
Loss: 2.237 | Acc: 21.434% (4129/19264)
Loss: 2.237 | Acc: 21.513% (5521/25664)
Loss: 2.237 | Acc: 21.423% (6869/32064)
Loss: 2.237 | Acc: 21.259% (8177/38464)
Loss: 2.236 | Acc: 21.356% (9581/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2649, Accuracy: 1929/10000 (19.29%)

Epoch: 119
Loss: 2.224 | Acc: 25.000% (16/64)
Loss: 2.240 | Acc: 21.132% (1366/6464)
Loss: 2.236 | Acc: 21.455% (2760/12864)
Loss: 2.234 | Acc: 21.693% (4179/19264)
Loss: 2.234 | Acc: 21.598% (5543/25664)
Loss: 2.236 | Acc: 21.507% (6896/32064)
Loss: 2.235 | Acc: 21.605% (8310/38464)
Loss: 2.235 | Acc: 21.590% (9686/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3028, Accuracy: 1795/10000 (17.95%)

Epoch: 120
Loss: 2.164 | Acc: 26.562% (17/64)
Loss: 2.235 | Acc: 21.844% (1412/6464)
Loss: 2.233 | Acc: 21.751% (2798/12864)
Loss: 2.233 | Acc: 21.828% (4205/19264)
Loss: 2.231 | Acc: 21.883% (5616/25664)
Loss: 2.233 | Acc: 21.685% (6953/32064)
Loss: 2.233 | Acc: 21.651% (8328/38464)
Loss: 2.234 | Acc: 21.541% (9664/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2633, Accuracy: 1914/10000 (19.14%)

Epoch: 121
Loss: 2.237 | Acc: 18.750% (12/64)
Loss: 2.229 | Acc: 21.782% (1408/6464)
Loss: 2.229 | Acc: 21.992% (2829/12864)
Loss: 2.230 | Acc: 21.849% (4209/19264)
Loss: 2.231 | Acc: 21.700% (5569/25664)
Loss: 2.230 | Acc: 21.825% (6998/32064)
Loss: 2.231 | Acc: 21.745% (8364/38464)
Loss: 2.232 | Acc: 21.728% (9748/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3060, Accuracy: 1682/10000 (16.82%)

Epoch: 122
Loss: 2.217 | Acc: 18.750% (12/64)
Loss: 2.232 | Acc: 21.674% (1401/6464)
Loss: 2.232 | Acc: 21.696% (2791/12864)
Loss: 2.232 | Acc: 21.740% (4188/19264)
Loss: 2.230 | Acc: 21.937% (5630/25664)
Loss: 2.231 | Acc: 21.819% (6996/32064)
Loss: 2.232 | Acc: 21.781% (8378/38464)
Loss: 2.232 | Acc: 21.786% (9774/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2609, Accuracy: 1927/10000 (19.27%)

Epoch: 123
Loss: 2.269 | Acc: 14.062% (9/64)
Loss: 2.226 | Acc: 21.782% (1408/6464)
Loss: 2.230 | Acc: 21.720% (2794/12864)
Loss: 2.229 | Acc: 22.010% (4240/19264)
Loss: 2.227 | Acc: 22.140% (5682/25664)
Loss: 2.226 | Acc: 22.165% (7107/32064)
Loss: 2.228 | Acc: 22.080% (8493/38464)
Loss: 2.229 | Acc: 21.991% (9866/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2587, Accuracy: 1938/10000 (19.38%)

Epoch: 124
Loss: 2.176 | Acc: 29.688% (19/64)
Loss: 2.226 | Acc: 22.153% (1432/6464)
Loss: 2.224 | Acc: 22.520% (2897/12864)
Loss: 2.225 | Acc: 22.363% (4308/19264)
Loss: 2.227 | Acc: 22.222% (5703/25664)
Loss: 2.227 | Acc: 22.231% (7128/32064)
Loss: 2.227 | Acc: 22.221% (8547/38464)
Loss: 2.227 | Acc: 22.185% (9953/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2487, Accuracy: 2038/10000 (20.38%)

Epoch: 125
Loss: 2.320 | Acc: 17.188% (11/64)
Loss: 2.230 | Acc: 22.293% (1441/6464)
Loss: 2.226 | Acc: 22.163% (2851/12864)
Loss: 2.226 | Acc: 22.233% (4283/19264)
Loss: 2.225 | Acc: 22.319% (5728/25664)
Loss: 2.225 | Acc: 22.187% (7114/32064)
Loss: 2.225 | Acc: 22.236% (8553/38464)
Loss: 2.226 | Acc: 22.281% (9996/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2536, Accuracy: 1968/10000 (19.68%)

Epoch: 126
Loss: 2.240 | Acc: 20.312% (13/64)
Loss: 2.221 | Acc: 22.509% (1455/6464)
Loss: 2.225 | Acc: 22.170% (2852/12864)
Loss: 2.226 | Acc: 22.135% (4264/19264)
Loss: 2.226 | Acc: 22.276% (5717/25664)
Loss: 2.227 | Acc: 22.174% (7110/32064)
Loss: 2.224 | Acc: 22.366% (8603/38464)
Loss: 2.224 | Acc: 22.356% (10030/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2666, Accuracy: 1930/10000 (19.30%)

Epoch: 127
Loss: 2.222 | Acc: 21.875% (14/64)
Loss: 2.221 | Acc: 22.587% (1460/6464)
Loss: 2.222 | Acc: 22.528% (2898/12864)
Loss: 2.224 | Acc: 22.430% (4321/19264)
Loss: 2.221 | Acc: 22.689% (5823/25664)
Loss: 2.222 | Acc: 22.627% (7255/32064)
Loss: 2.220 | Acc: 22.720% (8739/38464)
Loss: 2.221 | Acc: 22.644% (10159/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2433, Accuracy: 2109/10000 (21.09%)

Epoch: 128
Loss: 2.278 | Acc: 21.875% (14/64)
Loss: 2.212 | Acc: 22.664% (1465/6464)
Loss: 2.213 | Acc: 22.823% (2936/12864)
Loss: 2.216 | Acc: 22.623% (4358/19264)
Loss: 2.215 | Acc: 22.841% (5862/25664)
Loss: 2.218 | Acc: 22.773% (7302/32064)
Loss: 2.218 | Acc: 22.793% (8767/38464)
Loss: 2.218 | Acc: 22.762% (10212/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2583, Accuracy: 1977/10000 (19.77%)

Epoch: 129
Loss: 2.165 | Acc: 21.875% (14/64)
Loss: 2.209 | Acc: 23.778% (1537/6464)
Loss: 2.210 | Acc: 23.593% (3035/12864)
Loss: 2.215 | Acc: 23.131% (4456/19264)
Loss: 2.215 | Acc: 23.083% (5924/25664)
Loss: 2.216 | Acc: 22.992% (7372/32064)
Loss: 2.216 | Acc: 23.050% (8866/38464)
Loss: 2.217 | Acc: 23.016% (10326/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2504, Accuracy: 2055/10000 (20.55%)

Epoch: 130
Loss: 2.184 | Acc: 23.438% (15/64)
Loss: 2.206 | Acc: 23.345% (1509/6464)
Loss: 2.209 | Acc: 23.220% (2987/12864)
Loss: 2.214 | Acc: 23.074% (4445/19264)
Loss: 2.214 | Acc: 23.095% (5927/25664)
Loss: 2.214 | Acc: 23.182% (7433/32064)
Loss: 2.215 | Acc: 23.133% (8898/38464)
Loss: 2.214 | Acc: 23.188% (10403/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2469, Accuracy: 2131/10000 (21.31%)

Epoch: 131
Loss: 2.291 | Acc: 15.625% (10/64)
Loss: 2.208 | Acc: 23.391% (1512/6464)
Loss: 2.209 | Acc: 23.414% (3012/12864)
Loss: 2.207 | Acc: 23.598% (4546/19264)
Loss: 2.207 | Acc: 23.656% (6071/25664)
Loss: 2.208 | Acc: 23.643% (7581/32064)
Loss: 2.209 | Acc: 23.562% (9063/38464)
Loss: 2.212 | Acc: 23.375% (10487/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2574, Accuracy: 2038/10000 (20.38%)

Epoch: 132
Loss: 2.314 | Acc: 14.062% (9/64)
Loss: 2.205 | Acc: 24.087% (1557/6464)
Loss: 2.208 | Acc: 23.873% (3071/12864)
Loss: 2.209 | Acc: 23.578% (4542/19264)
Loss: 2.209 | Acc: 23.496% (6030/25664)
Loss: 2.209 | Acc: 23.537% (7547/32064)
Loss: 2.210 | Acc: 23.466% (9026/38464)
Loss: 2.210 | Acc: 23.489% (10538/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2438, Accuracy: 2098/10000 (20.98%)

Epoch: 133
Loss: 2.235 | Acc: 21.875% (14/64)
Loss: 2.201 | Acc: 24.304% (1571/6464)
Loss: 2.203 | Acc: 23.927% (3078/12864)
Loss: 2.205 | Acc: 23.780% (4581/19264)
Loss: 2.206 | Acc: 23.683% (6078/25664)
Loss: 2.205 | Acc: 23.880% (7657/32064)
Loss: 2.204 | Acc: 23.957% (9215/38464)
Loss: 2.204 | Acc: 23.890% (10718/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2430, Accuracy: 2151/10000 (21.51%)

Epoch: 134
Loss: 2.244 | Acc: 23.438% (15/64)
Loss: 2.196 | Acc: 24.257% (1568/6464)
Loss: 2.199 | Acc: 24.106% (3101/12864)
Loss: 2.199 | Acc: 24.092% (4641/19264)
Loss: 2.201 | Acc: 23.745% (6094/25664)
Loss: 2.202 | Acc: 23.696% (7598/32064)
Loss: 2.202 | Acc: 23.749% (9135/38464)
Loss: 2.203 | Acc: 23.752% (10656/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2548, Accuracy: 2142/10000 (21.42%)

Epoch: 135
Loss: 2.210 | Acc: 20.312% (13/64)
Loss: 2.183 | Acc: 25.433% (1644/6464)
Loss: 2.187 | Acc: 24.845% (3196/12864)
Loss: 2.189 | Acc: 24.621% (4743/19264)
Loss: 2.192 | Acc: 24.458% (6277/25664)
Loss: 2.195 | Acc: 24.339% (7804/32064)
Loss: 2.196 | Acc: 24.272% (9336/38464)
Loss: 2.197 | Acc: 24.204% (10859/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2473, Accuracy: 2144/10000 (21.44%)

Epoch: 136
Loss: 2.318 | Acc: 18.750% (12/64)
Loss: 2.200 | Acc: 24.087% (1557/6464)
Loss: 2.195 | Acc: 24.572% (3161/12864)
Loss: 2.190 | Acc: 24.818% (4781/19264)
Loss: 2.192 | Acc: 24.700% (6339/25664)
Loss: 2.193 | Acc: 24.716% (7925/32064)
Loss: 2.193 | Acc: 24.688% (9496/38464)
Loss: 2.192 | Acc: 24.762% (11109/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2447, Accuracy: 2180/10000 (21.80%)

Epoch: 137
Loss: 2.262 | Acc: 18.750% (12/64)
Loss: 2.192 | Acc: 24.211% (1565/6464)
Loss: 2.190 | Acc: 24.487% (3150/12864)
Loss: 2.187 | Acc: 24.844% (4786/19264)
Loss: 2.187 | Acc: 24.953% (6404/25664)
Loss: 2.185 | Acc: 25.147% (8063/32064)
Loss: 2.187 | Acc: 25.036% (9630/38464)
Loss: 2.188 | Acc: 24.967% (11201/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2411, Accuracy: 2223/10000 (22.23%)

Epoch: 138
Loss: 2.216 | Acc: 23.438% (15/64)
Loss: 2.174 | Acc: 25.913% (1675/6464)
Loss: 2.180 | Acc: 25.373% (3264/12864)
Loss: 2.180 | Acc: 25.415% (4896/19264)
Loss: 2.184 | Acc: 25.039% (6426/25664)
Loss: 2.183 | Acc: 25.156% (8066/32064)
Loss: 2.183 | Acc: 25.122% (9663/38464)
Loss: 2.183 | Acc: 25.198% (11305/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2483, Accuracy: 2151/10000 (21.51%)

Epoch: 139
Loss: 2.235 | Acc: 20.312% (13/64)
Loss: 2.175 | Acc: 25.402% (1642/6464)
Loss: 2.176 | Acc: 25.614% (3295/12864)
Loss: 2.174 | Acc: 25.815% (4973/19264)
Loss: 2.176 | Acc: 25.620% (6575/25664)
Loss: 2.176 | Acc: 25.599% (8208/32064)
Loss: 2.175 | Acc: 25.634% (9860/38464)
Loss: 2.175 | Acc: 25.684% (11523/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2570, Accuracy: 2125/10000 (21.25%)

Epoch: 140
Loss: 2.255 | Acc: 26.562% (17/64)
Loss: 2.159 | Acc: 26.810% (1733/6464)
Loss: 2.162 | Acc: 26.322% (3386/12864)
Loss: 2.162 | Acc: 26.324% (5071/19264)
Loss: 2.165 | Acc: 26.146% (6710/25664)
Loss: 2.166 | Acc: 26.123% (8376/32064)
Loss: 2.169 | Acc: 25.772% (9913/38464)
Loss: 2.169 | Acc: 25.791% (11571/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2585, Accuracy: 2135/10000 (21.35%)

Epoch: 141
Loss: 2.164 | Acc: 26.562% (17/64)
Loss: 2.147 | Acc: 27.630% (1786/6464)
Loss: 2.151 | Acc: 27.239% (3504/12864)
Loss: 2.153 | Acc: 27.056% (5212/19264)
Loss: 2.156 | Acc: 26.792% (6876/25664)
Loss: 2.157 | Acc: 26.690% (8558/32064)
Loss: 2.158 | Acc: 26.578% (10223/38464)
Loss: 2.158 | Acc: 26.518% (11897/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2552, Accuracy: 2147/10000 (21.47%)

Epoch: 142
Loss: 2.031 | Acc: 31.250% (20/64)
Loss: 2.154 | Acc: 26.501% (1713/6464)
Loss: 2.154 | Acc: 26.718% (3437/12864)
Loss: 2.155 | Acc: 26.625% (5129/19264)
Loss: 2.153 | Acc: 26.753% (6866/25664)
Loss: 2.152 | Acc: 26.750% (8577/32064)
Loss: 2.150 | Acc: 26.885% (10341/38464)
Loss: 2.150 | Acc: 26.955% (12093/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2664, Accuracy: 2143/10000 (21.43%)

Epoch: 143
Loss: 2.059 | Acc: 35.938% (23/64)
Loss: 2.123 | Acc: 28.357% (1833/6464)
Loss: 2.131 | Acc: 27.713% (3565/12864)
Loss: 2.132 | Acc: 27.663% (5329/19264)
Loss: 2.135 | Acc: 27.466% (7049/25664)
Loss: 2.136 | Acc: 27.517% (8823/32064)
Loss: 2.137 | Acc: 27.441% (10555/38464)
Loss: 2.138 | Acc: 27.403% (12294/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2676, Accuracy: 2117/10000 (21.17%)

Epoch: 144
Loss: 2.150 | Acc: 29.688% (19/64)
Loss: 2.124 | Acc: 28.171% (1821/6464)
Loss: 2.125 | Acc: 28.001% (3602/12864)
Loss: 2.123 | Acc: 28.073% (5408/19264)
Loss: 2.124 | Acc: 28.117% (7216/25664)
Loss: 2.122 | Acc: 28.150% (9026/32064)
Loss: 2.122 | Acc: 28.083% (10802/38464)
Loss: 2.124 | Acc: 28.011% (12567/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2856, Accuracy: 2109/10000 (21.09%)

Epoch: 145
Loss: 2.089 | Acc: 31.250% (20/64)
Loss: 2.112 | Acc: 28.682% (1854/6464)
Loss: 2.113 | Acc: 28.762% (3700/12864)
Loss: 2.117 | Acc: 28.426% (5476/19264)
Loss: 2.120 | Acc: 28.289% (7260/25664)
Loss: 2.125 | Acc: 28.063% (8998/32064)
Loss: 2.128 | Acc: 27.909% (10735/38464)
Loss: 2.131 | Acc: 27.757% (12453/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2574, Accuracy: 2128/10000 (21.28%)

Epoch: 146
Loss: 2.197 | Acc: 17.188% (11/64)
Loss: 2.143 | Acc: 27.305% (1765/6464)
Loss: 2.146 | Acc: 27.285% (3510/12864)
Loss: 2.151 | Acc: 27.102% (5221/19264)
Loss: 2.151 | Acc: 27.042% (6940/25664)
Loss: 2.153 | Acc: 26.909% (8628/32064)
Loss: 2.154 | Acc: 26.872% (10336/38464)
Loss: 2.156 | Acc: 26.719% (11987/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2539, Accuracy: 2132/10000 (21.32%)

Epoch: 147
Loss: 2.115 | Acc: 29.688% (19/64)
Loss: 2.149 | Acc: 27.351% (1768/6464)
Loss: 2.155 | Acc: 26.788% (3446/12864)
Loss: 2.158 | Acc: 26.640% (5132/19264)
Loss: 2.159 | Acc: 26.598% (6826/25664)
Loss: 2.161 | Acc: 26.463% (8485/32064)
Loss: 2.161 | Acc: 26.446% (10172/38464)
Loss: 2.161 | Acc: 26.447% (11865/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2551, Accuracy: 2152/10000 (21.52%)
torch.Size([100, 10])
Test set: Average loss: 2.2551, Accuracy: 2152/10000 (21.52%)

Epoch: 148
Loss: 2.040 | Acc: 37.500% (24/64)
Loss: 2.157 | Acc: 26.330% (1702/6464)
Loss: 2.162 | Acc: 26.267% (3379/12864)
Loss: 2.158 | Acc: 26.552% (5115/19264)
Loss: 2.161 | Acc: 26.387% (6772/25664)
Loss: 2.161 | Acc: 26.335% (8444/32064)
Loss: 2.162 | Acc: 26.334% (10129/38464)
Loss: 2.162 | Acc: 26.382% (11836/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2562, Accuracy: 2133/10000 (21.33%)
torch.Size([100, 10])
Test set: Average loss: 2.2562, Accuracy: 2133/10000 (21.33%)

Epoch: 149
Loss: 2.061 | Acc: 37.500% (24/64)
Loss: 2.150 | Acc: 27.645% (1787/6464)
Loss: 2.155 | Acc: 27.013% (3475/12864)
Loss: 2.156 | Acc: 26.931% (5188/19264)
Loss: 2.157 | Acc: 26.820% (6883/25664)
Loss: 2.157 | Acc: 26.709% (8564/32064)
Loss: 2.161 | Acc: 26.487% (10188/38464)
Loss: 2.160 | Acc: 26.516% (11896/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2546, Accuracy: 2142/10000 (21.42%)
torch.Size([100, 10])
Test set: Average loss: 2.2546, Accuracy: 2142/10000 (21.42%)

Epoch: 150
Loss: 2.178 | Acc: 26.562% (17/64)
Loss: 2.306 | Acc: 11.866% (767/6464)
Loss: 2.300 | Acc: 12.873% (1656/12864)
Loss: 2.296 | Acc: 13.066% (2517/19264)
Loss: 2.292 | Acc: 13.688% (3513/25664)
Loss: 2.289 | Acc: 14.231% (4563/32064)
Loss: 2.284 | Acc: 14.764% (5679/38464)
Loss: 2.282 | Acc: 15.230% (6833/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2885, Accuracy: 1671/10000 (16.71%)

Epoch: 151
Loss: 2.255 | Acc: 20.312% (13/64)
Loss: 2.256 | Acc: 18.765% (1213/6464)
Loss: 2.258 | Acc: 18.750% (2412/12864)
Loss: 2.256 | Acc: 19.093% (3678/19264)
Loss: 2.256 | Acc: 19.307% (4955/25664)
Loss: 2.255 | Acc: 19.358% (6207/32064)
Loss: 2.254 | Acc: 19.499% (7500/38464)
Loss: 2.253 | Acc: 19.490% (8744/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2934, Accuracy: 1672/10000 (16.72%)

Epoch: 152
Loss: 2.308 | Acc: 14.062% (9/64)
Loss: 2.252 | Acc: 19.663% (1271/6464)
Loss: 2.251 | Acc: 19.737% (2539/12864)
Loss: 2.251 | Acc: 19.741% (3803/19264)
Loss: 2.250 | Acc: 19.923% (5113/25664)
Loss: 2.249 | Acc: 19.957% (6399/32064)
Loss: 2.249 | Acc: 20.058% (7715/38464)
Loss: 2.248 | Acc: 20.190% (9058/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2787, Accuracy: 1797/10000 (17.97%)

Epoch: 153
Loss: 2.310 | Acc: 17.188% (11/64)
Loss: 2.236 | Acc: 21.334% (1379/6464)
Loss: 2.243 | Acc: 20.421% (2627/12864)
Loss: 2.245 | Acc: 20.328% (3916/19264)
Loss: 2.245 | Acc: 20.305% (5211/25664)
Loss: 2.245 | Acc: 20.316% (6514/32064)
Loss: 2.245 | Acc: 20.237% (7784/38464)
Loss: 2.246 | Acc: 20.214% (9069/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2817, Accuracy: 1608/10000 (16.08%)

Epoch: 154
Loss: 2.366 | Acc: 10.938% (7/64)
Loss: 2.246 | Acc: 20.251% (1309/6464)
Loss: 2.244 | Acc: 20.623% (2653/12864)
Loss: 2.245 | Acc: 20.551% (3959/19264)
Loss: 2.245 | Acc: 20.441% (5246/25664)
Loss: 2.243 | Acc: 20.537% (6585/32064)
Loss: 2.243 | Acc: 20.713% (7967/38464)
Loss: 2.243 | Acc: 20.725% (9298/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3196, Accuracy: 1669/10000 (16.69%)

Epoch: 155
Loss: 2.282 | Acc: 20.312% (13/64)
Loss: 2.241 | Acc: 21.071% (1362/6464)
Loss: 2.245 | Acc: 20.670% (2659/12864)
Loss: 2.243 | Acc: 20.858% (4018/19264)
Loss: 2.244 | Acc: 20.733% (5321/25664)
Loss: 2.244 | Acc: 20.674% (6629/32064)
Loss: 2.244 | Acc: 20.684% (7956/38464)
Loss: 2.244 | Acc: 20.756% (9312/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3323, Accuracy: 1445/10000 (14.45%)

Epoch: 156
Loss: 2.175 | Acc: 25.000% (16/64)
Loss: 2.236 | Acc: 21.179% (1369/6464)
Loss: 2.242 | Acc: 20.965% (2697/12864)
Loss: 2.241 | Acc: 20.816% (4010/19264)
Loss: 2.241 | Acc: 20.971% (5382/25664)
Loss: 2.243 | Acc: 20.833% (6680/32064)
Loss: 2.242 | Acc: 20.947% (8057/38464)
Loss: 2.243 | Acc: 20.854% (9356/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3253, Accuracy: 1542/10000 (15.42%)

Epoch: 157
Loss: 2.290 | Acc: 18.750% (12/64)
Loss: 2.238 | Acc: 20.838% (1347/6464)
Loss: 2.239 | Acc: 20.896% (2688/12864)
Loss: 2.244 | Acc: 20.447% (3939/19264)
Loss: 2.246 | Acc: 20.351% (5223/25664)
Loss: 2.244 | Acc: 20.425% (6549/32064)
Loss: 2.245 | Acc: 20.398% (7846/38464)
Loss: 2.245 | Acc: 20.504% (9199/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2502, Accuracy: 2039/10000 (20.39%)

Epoch: 158
Loss: 2.289 | Acc: 15.625% (10/64)
Loss: 2.233 | Acc: 21.426% (1385/6464)
Loss: 2.238 | Acc: 20.997% (2701/12864)
Loss: 2.240 | Acc: 21.013% (4048/19264)
Loss: 2.240 | Acc: 21.088% (5412/25664)
Loss: 2.241 | Acc: 20.914% (6706/32064)
Loss: 2.242 | Acc: 20.806% (8003/38464)
Loss: 2.242 | Acc: 20.756% (9312/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2928, Accuracy: 1831/10000 (18.31%)

Epoch: 159
Loss: 2.288 | Acc: 14.062% (9/64)
Loss: 2.238 | Acc: 21.395% (1383/6464)
Loss: 2.243 | Acc: 20.919% (2691/12864)
Loss: 2.242 | Acc: 21.039% (4053/19264)
Loss: 2.241 | Acc: 21.045% (5401/25664)
Loss: 2.240 | Acc: 21.173% (6789/32064)
Loss: 2.241 | Acc: 21.079% (8108/38464)
Loss: 2.243 | Acc: 20.948% (9398/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2563, Accuracy: 2015/10000 (20.15%)

Epoch: 160
Loss: 2.160 | Acc: 31.250% (20/64)
Loss: 2.239 | Acc: 21.256% (1374/6464)
Loss: 2.237 | Acc: 21.354% (2747/12864)
Loss: 2.237 | Acc: 21.408% (4124/19264)
Loss: 2.238 | Acc: 21.306% (5468/25664)
Loss: 2.239 | Acc: 21.254% (6815/32064)
Loss: 2.240 | Acc: 21.157% (8138/38464)
Loss: 2.242 | Acc: 20.977% (9411/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2515, Accuracy: 1994/10000 (19.94%)

Epoch: 161
Loss: 2.252 | Acc: 18.750% (12/64)
Loss: 2.240 | Acc: 21.241% (1373/6464)
Loss: 2.237 | Acc: 21.300% (2740/12864)
Loss: 2.240 | Acc: 20.868% (4020/19264)
Loss: 2.240 | Acc: 20.990% (5387/25664)
Loss: 2.240 | Acc: 20.918% (6707/32064)
Loss: 2.240 | Acc: 21.025% (8087/38464)
Loss: 2.240 | Acc: 21.064% (9450/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2838, Accuracy: 1685/10000 (16.85%)

Epoch: 162
Loss: 2.242 | Acc: 21.875% (14/64)
Loss: 2.236 | Acc: 21.395% (1383/6464)
Loss: 2.240 | Acc: 21.144% (2720/12864)
Loss: 2.239 | Acc: 21.195% (4083/19264)
Loss: 2.240 | Acc: 21.181% (5436/25664)
Loss: 2.241 | Acc: 20.914% (6706/32064)
Loss: 2.241 | Acc: 21.027% (8088/38464)
Loss: 2.241 | Acc: 20.950% (9399/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2894, Accuracy: 1763/10000 (17.63%)

Epoch: 163
Loss: 2.249 | Acc: 17.188% (11/64)
Loss: 2.230 | Acc: 21.875% (1414/6464)
Loss: 2.237 | Acc: 21.447% (2759/12864)
Loss: 2.238 | Acc: 21.143% (4073/19264)
Loss: 2.238 | Acc: 21.181% (5436/25664)
Loss: 2.237 | Acc: 21.198% (6797/32064)
Loss: 2.239 | Acc: 21.025% (8087/38464)
Loss: 2.239 | Acc: 20.990% (9417/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3036, Accuracy: 1639/10000 (16.39%)

Epoch: 164
Loss: 2.251 | Acc: 23.438% (15/64)
Loss: 2.233 | Acc: 21.705% (1403/6464)
Loss: 2.234 | Acc: 21.805% (2805/12864)
Loss: 2.237 | Acc: 21.475% (4137/19264)
Loss: 2.238 | Acc: 21.291% (5464/25664)
Loss: 2.239 | Acc: 21.192% (6795/32064)
Loss: 2.238 | Acc: 21.345% (8210/38464)
Loss: 2.239 | Acc: 21.253% (9535/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2561, Accuracy: 1989/10000 (19.89%)

Epoch: 165
Loss: 2.246 | Acc: 20.312% (13/64)
Loss: 2.239 | Acc: 21.071% (1362/6464)
Loss: 2.238 | Acc: 21.020% (2704/12864)
Loss: 2.238 | Acc: 21.070% (4059/19264)
Loss: 2.239 | Acc: 20.959% (5379/25664)
Loss: 2.238 | Acc: 21.117% (6771/32064)
Loss: 2.236 | Acc: 21.238% (8169/38464)
Loss: 2.237 | Acc: 21.184% (9504/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2893, Accuracy: 1674/10000 (16.74%)

Epoch: 166
Loss: 2.342 | Acc: 12.500% (8/64)
Loss: 2.232 | Acc: 21.720% (1404/6464)
Loss: 2.235 | Acc: 21.580% (2776/12864)
Loss: 2.233 | Acc: 21.636% (4168/19264)
Loss: 2.234 | Acc: 21.559% (5533/25664)
Loss: 2.234 | Acc: 21.532% (6904/32064)
Loss: 2.235 | Acc: 21.451% (8251/38464)
Loss: 2.235 | Acc: 21.440% (9619/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2617, Accuracy: 1934/10000 (19.34%)

Epoch: 167
Loss: 2.320 | Acc: 15.625% (10/64)
Loss: 2.232 | Acc: 21.983% (1421/6464)
Loss: 2.236 | Acc: 21.463% (2761/12864)
Loss: 2.237 | Acc: 21.444% (4131/19264)
Loss: 2.235 | Acc: 21.614% (5547/25664)
Loss: 2.235 | Acc: 21.541% (6907/32064)
Loss: 2.235 | Acc: 21.519% (8277/38464)
Loss: 2.235 | Acc: 21.552% (9669/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2613, Accuracy: 1994/10000 (19.94%)

Epoch: 168
Loss: 2.203 | Acc: 21.875% (14/64)
Loss: 2.236 | Acc: 21.086% (1363/6464)
Loss: 2.235 | Acc: 21.261% (2735/12864)
Loss: 2.234 | Acc: 21.309% (4105/19264)
Loss: 2.236 | Acc: 21.232% (5449/25664)
Loss: 2.234 | Acc: 21.326% (6838/32064)
Loss: 2.234 | Acc: 21.303% (8194/38464)
Loss: 2.234 | Acc: 21.293% (9553/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2601, Accuracy: 1893/10000 (18.93%)

Epoch: 169
Loss: 2.319 | Acc: 14.062% (9/64)
Loss: 2.240 | Acc: 21.287% (1376/6464)
Loss: 2.239 | Acc: 21.238% (2732/12864)
Loss: 2.237 | Acc: 21.475% (4137/19264)
Loss: 2.237 | Acc: 21.501% (5518/25664)
Loss: 2.237 | Acc: 21.495% (6892/32064)
Loss: 2.235 | Acc: 21.623% (8317/38464)
Loss: 2.234 | Acc: 21.686% (9729/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2963, Accuracy: 1779/10000 (17.79%)

Epoch: 170
Loss: 2.256 | Acc: 21.875% (14/64)
Loss: 2.229 | Acc: 21.844% (1412/6464)
Loss: 2.229 | Acc: 22.007% (2831/12864)
Loss: 2.230 | Acc: 21.963% (4231/19264)
Loss: 2.230 | Acc: 22.027% (5653/25664)
Loss: 2.232 | Acc: 21.841% (7003/32064)
Loss: 2.232 | Acc: 21.883% (8417/38464)
Loss: 2.232 | Acc: 21.817% (9788/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2733, Accuracy: 1833/10000 (18.33%)

Epoch: 171
Loss: 2.312 | Acc: 10.938% (7/64)
Loss: 2.229 | Acc: 21.983% (1421/6464)
Loss: 2.228 | Acc: 22.124% (2846/12864)
Loss: 2.228 | Acc: 22.026% (4243/19264)
Loss: 2.227 | Acc: 22.191% (5695/25664)
Loss: 2.227 | Acc: 22.193% (7116/32064)
Loss: 2.228 | Acc: 22.112% (8505/38464)
Loss: 2.229 | Acc: 22.018% (9878/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2617, Accuracy: 1926/10000 (19.26%)

Epoch: 172
Loss: 2.213 | Acc: 25.000% (16/64)
Loss: 2.233 | Acc: 21.767% (1407/6464)
Loss: 2.231 | Acc: 21.984% (2828/12864)
Loss: 2.230 | Acc: 22.171% (4271/19264)
Loss: 2.229 | Acc: 22.311% (5726/25664)
Loss: 2.229 | Acc: 22.202% (7119/32064)
Loss: 2.230 | Acc: 22.052% (8482/38464)
Loss: 2.230 | Acc: 22.018% (9878/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2644, Accuracy: 1908/10000 (19.08%)

Epoch: 173
Loss: 2.195 | Acc: 23.438% (15/64)
Loss: 2.226 | Acc: 22.277% (1440/6464)
Loss: 2.229 | Acc: 21.953% (2824/12864)
Loss: 2.230 | Acc: 22.015% (4241/19264)
Loss: 2.228 | Acc: 22.128% (5679/25664)
Loss: 2.227 | Acc: 22.330% (7160/32064)
Loss: 2.227 | Acc: 22.270% (8566/38464)
Loss: 2.227 | Acc: 22.296% (10003/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2612, Accuracy: 1951/10000 (19.51%)

Epoch: 174
Loss: 2.266 | Acc: 18.750% (12/64)
Loss: 2.223 | Acc: 21.767% (1407/6464)
Loss: 2.220 | Acc: 22.233% (2860/12864)
Loss: 2.220 | Acc: 22.446% (4324/19264)
Loss: 2.221 | Acc: 22.421% (5754/25664)
Loss: 2.224 | Acc: 22.249% (7134/32064)
Loss: 2.225 | Acc: 22.270% (8566/38464)
Loss: 2.225 | Acc: 22.305% (10007/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3105, Accuracy: 1732/10000 (17.32%)

Epoch: 175
Loss: 2.239 | Acc: 23.438% (15/64)
Loss: 2.228 | Acc: 22.153% (1432/6464)
Loss: 2.223 | Acc: 22.629% (2911/12864)
Loss: 2.225 | Acc: 22.337% (4303/19264)
Loss: 2.225 | Acc: 22.257% (5712/25664)
Loss: 2.223 | Acc: 22.549% (7230/32064)
Loss: 2.223 | Acc: 22.538% (8669/38464)
Loss: 2.224 | Acc: 22.450% (10072/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2481, Accuracy: 2036/10000 (20.36%)

Epoch: 176
Loss: 2.306 | Acc: 15.625% (10/64)
Loss: 2.229 | Acc: 22.355% (1445/6464)
Loss: 2.226 | Acc: 22.310% (2870/12864)
Loss: 2.223 | Acc: 22.607% (4355/19264)
Loss: 2.222 | Acc: 22.553% (5788/25664)
Loss: 2.224 | Acc: 22.443% (7196/32064)
Loss: 2.223 | Acc: 22.483% (8648/38464)
Loss: 2.223 | Acc: 22.570% (10126/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2556, Accuracy: 1978/10000 (19.78%)

Epoch: 177
Loss: 2.137 | Acc: 31.250% (20/64)
Loss: 2.219 | Acc: 22.293% (1441/6464)
Loss: 2.216 | Acc: 22.792% (2932/12864)
Loss: 2.212 | Acc: 23.162% (4462/19264)
Loss: 2.216 | Acc: 22.888% (5874/25664)
Loss: 2.218 | Acc: 22.701% (7279/32064)
Loss: 2.219 | Acc: 22.616% (8699/38464)
Loss: 2.219 | Acc: 22.700% (10184/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2559, Accuracy: 2014/10000 (20.14%)

Epoch: 178
Loss: 2.168 | Acc: 26.562% (17/64)
Loss: 2.210 | Acc: 23.499% (1519/6464)
Loss: 2.217 | Acc: 23.025% (2962/12864)
Loss: 2.218 | Acc: 22.778% (4388/19264)
Loss: 2.217 | Acc: 22.904% (5878/25664)
Loss: 2.217 | Acc: 22.895% (7341/32064)
Loss: 2.215 | Acc: 23.042% (8863/38464)
Loss: 2.216 | Acc: 22.952% (10297/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2406, Accuracy: 2166/10000 (21.66%)

Epoch: 179
Loss: 2.172 | Acc: 28.125% (18/64)
Loss: 2.219 | Acc: 23.128% (1495/6464)
Loss: 2.211 | Acc: 23.585% (3034/12864)
Loss: 2.212 | Acc: 23.412% (4510/19264)
Loss: 2.213 | Acc: 23.219% (5959/25664)
Loss: 2.213 | Acc: 23.172% (7430/32064)
Loss: 2.213 | Acc: 23.162% (8909/38464)
Loss: 2.214 | Acc: 23.056% (10344/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2465, Accuracy: 2083/10000 (20.83%)

Epoch: 180
Loss: 2.270 | Acc: 20.312% (13/64)
Loss: 2.208 | Acc: 23.639% (1528/6464)
Loss: 2.209 | Acc: 23.686% (3047/12864)
Loss: 2.207 | Acc: 23.681% (4562/19264)
Loss: 2.207 | Acc: 23.683% (6078/25664)
Loss: 2.210 | Acc: 23.475% (7527/32064)
Loss: 2.211 | Acc: 23.349% (8981/38464)
Loss: 2.212 | Acc: 23.281% (10445/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2518, Accuracy: 2097/10000 (20.97%)

Epoch: 181
Loss: 2.261 | Acc: 18.750% (12/64)
Loss: 2.206 | Acc: 23.515% (1520/6464)
Loss: 2.207 | Acc: 23.507% (3024/12864)
Loss: 2.204 | Acc: 23.785% (4582/19264)
Loss: 2.202 | Acc: 24.049% (6172/25664)
Loss: 2.206 | Acc: 23.659% (7586/32064)
Loss: 2.209 | Acc: 23.435% (9014/38464)
Loss: 2.209 | Acc: 23.424% (10509/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2440, Accuracy: 2092/10000 (20.92%)

Epoch: 182
Loss: 2.240 | Acc: 20.312% (13/64)
Loss: 2.207 | Acc: 23.561% (1523/6464)
Loss: 2.201 | Acc: 24.098% (3100/12864)
Loss: 2.201 | Acc: 24.190% (4660/19264)
Loss: 2.201 | Acc: 24.162% (6201/25664)
Loss: 2.203 | Acc: 24.111% (7731/32064)
Loss: 2.203 | Acc: 24.033% (9244/38464)
Loss: 2.205 | Acc: 23.886% (10716/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2390, Accuracy: 2181/10000 (21.81%)

Epoch: 183
Loss: 2.144 | Acc: 28.125% (18/64)
Loss: 2.205 | Acc: 23.623% (1527/6464)
Loss: 2.203 | Acc: 23.686% (3047/12864)
Loss: 2.202 | Acc: 23.801% (4585/19264)
Loss: 2.204 | Acc: 23.617% (6061/25664)
Loss: 2.205 | Acc: 23.575% (7559/32064)
Loss: 2.205 | Acc: 23.609% (9081/38464)
Loss: 2.205 | Acc: 23.674% (10621/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2435, Accuracy: 2152/10000 (21.52%)

Epoch: 184
Loss: 2.186 | Acc: 25.000% (16/64)
Loss: 2.191 | Acc: 25.232% (1631/6464)
Loss: 2.189 | Acc: 25.148% (3235/12864)
Loss: 2.192 | Acc: 24.813% (4780/19264)
Loss: 2.194 | Acc: 24.700% (6339/25664)
Loss: 2.196 | Acc: 24.576% (7880/32064)
Loss: 2.198 | Acc: 24.345% (9364/38464)
Loss: 2.200 | Acc: 24.269% (10888/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2668, Accuracy: 2009/10000 (20.09%)

Epoch: 185
Loss: 2.224 | Acc: 25.000% (16/64)
Loss: 2.195 | Acc: 24.799% (1603/6464)
Loss: 2.192 | Acc: 24.813% (3192/12864)
Loss: 2.194 | Acc: 24.657% (4750/19264)
Loss: 2.195 | Acc: 24.622% (6319/25664)
Loss: 2.196 | Acc: 24.442% (7837/32064)
Loss: 2.195 | Acc: 24.496% (9422/38464)
Loss: 2.195 | Acc: 24.519% (11000/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2550, Accuracy: 2103/10000 (21.03%)

Epoch: 186
Loss: 2.217 | Acc: 20.312% (13/64)
Loss: 2.182 | Acc: 25.402% (1642/6464)
Loss: 2.184 | Acc: 25.117% (3231/12864)
Loss: 2.186 | Acc: 24.948% (4806/19264)
Loss: 2.188 | Acc: 24.871% (6383/25664)
Loss: 2.189 | Acc: 24.903% (7985/32064)
Loss: 2.190 | Acc: 24.745% (9518/38464)
Loss: 2.190 | Acc: 24.688% (11076/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2430, Accuracy: 2163/10000 (21.63%)

Epoch: 187
Loss: 2.080 | Acc: 32.812% (21/64)
Loss: 2.192 | Acc: 24.350% (1574/6464)
Loss: 2.185 | Acc: 24.845% (3196/12864)
Loss: 2.186 | Acc: 24.927% (4802/19264)
Loss: 2.187 | Acc: 24.801% (6365/25664)
Loss: 2.186 | Acc: 24.935% (7995/32064)
Loss: 2.186 | Acc: 24.893% (9575/38464)
Loss: 2.186 | Acc: 24.902% (11172/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2399, Accuracy: 2208/10000 (22.08%)

Epoch: 188
Loss: 2.184 | Acc: 29.688% (19/64)
Loss: 2.180 | Acc: 25.495% (1648/6464)
Loss: 2.181 | Acc: 25.428% (3271/12864)
Loss: 2.180 | Acc: 25.441% (4901/19264)
Loss: 2.180 | Acc: 25.522% (6550/25664)
Loss: 2.179 | Acc: 25.530% (8186/32064)
Loss: 2.179 | Acc: 25.556% (9830/38464)
Loss: 2.179 | Acc: 25.539% (11458/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2504, Accuracy: 2183/10000 (21.83%)

Epoch: 189
Loss: 2.099 | Acc: 29.688% (19/64)
Loss: 2.159 | Acc: 26.764% (1730/6464)
Loss: 2.169 | Acc: 26.065% (3353/12864)
Loss: 2.169 | Acc: 25.960% (5001/19264)
Loss: 2.169 | Acc: 25.966% (6664/25664)
Loss: 2.172 | Acc: 25.705% (8242/32064)
Loss: 2.171 | Acc: 25.788% (9919/38464)
Loss: 2.172 | Acc: 25.644% (11505/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2530, Accuracy: 2184/10000 (21.84%)

Epoch: 190
Loss: 2.124 | Acc: 28.125% (18/64)
Loss: 2.167 | Acc: 25.619% (1656/6464)
Loss: 2.165 | Acc: 25.886% (3330/12864)
Loss: 2.162 | Acc: 26.064% (5021/19264)
Loss: 2.160 | Acc: 26.383% (6771/25664)
Loss: 2.161 | Acc: 26.329% (8442/32064)
Loss: 2.161 | Acc: 26.303% (10117/38464)
Loss: 2.161 | Acc: 26.342% (11818/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2511, Accuracy: 2178/10000 (21.78%)

Epoch: 191
Loss: 2.309 | Acc: 18.750% (12/64)
Loss: 2.147 | Acc: 27.135% (1754/6464)
Loss: 2.151 | Acc: 26.897% (3460/12864)
Loss: 2.152 | Acc: 26.791% (5161/19264)
Loss: 2.153 | Acc: 26.788% (6875/25664)
Loss: 2.152 | Acc: 26.806% (8595/32064)
Loss: 2.153 | Acc: 26.731% (10282/38464)
Loss: 2.155 | Acc: 26.554% (11913/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2695, Accuracy: 2125/10000 (21.25%)

Epoch: 192
Loss: 2.138 | Acc: 32.812% (21/64)
Loss: 2.151 | Acc: 27.104% (1752/6464)
Loss: 2.144 | Acc: 27.348% (3518/12864)
Loss: 2.147 | Acc: 26.978% (5197/19264)
Loss: 2.145 | Acc: 27.092% (6953/25664)
Loss: 2.147 | Acc: 26.881% (8619/32064)
Loss: 2.146 | Acc: 26.937% (10361/38464)
Loss: 2.146 | Acc: 26.970% (12100/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2697, Accuracy: 2165/10000 (21.65%)

Epoch: 193
Loss: 2.044 | Acc: 29.688% (19/64)
Loss: 2.119 | Acc: 28.079% (1815/6464)
Loss: 2.116 | Acc: 28.646% (3685/12864)
Loss: 2.120 | Acc: 28.369% (5465/19264)
Loss: 2.125 | Acc: 28.063% (7202/25664)
Loss: 2.125 | Acc: 28.019% (8984/32064)
Loss: 2.129 | Acc: 27.745% (10672/38464)
Loss: 2.130 | Acc: 27.739% (12445/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2784, Accuracy: 2103/10000 (21.03%)

Epoch: 194
Loss: 2.058 | Acc: 31.250% (20/64)
Loss: 2.113 | Acc: 28.403% (1836/6464)
Loss: 2.108 | Acc: 28.801% (3705/12864)
Loss: 2.113 | Acc: 28.457% (5482/19264)
Loss: 2.115 | Acc: 28.316% (7267/25664)
Loss: 2.113 | Acc: 28.418% (9112/32064)
Loss: 2.114 | Acc: 28.362% (10909/38464)
Loss: 2.115 | Acc: 28.346% (12717/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2848, Accuracy: 2076/10000 (20.76%)

Epoch: 195
Loss: 2.069 | Acc: 28.125% (18/64)
Loss: 2.086 | Acc: 29.796% (1926/6464)
Loss: 2.099 | Acc: 29.275% (3766/12864)
Loss: 2.110 | Acc: 28.670% (5523/19264)
Loss: 2.115 | Acc: 28.398% (7288/25664)
Loss: 2.120 | Acc: 28.225% (9050/32064)
Loss: 2.124 | Acc: 28.044% (10787/38464)
Loss: 2.128 | Acc: 27.829% (12485/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2602, Accuracy: 2171/10000 (21.71%)

Epoch: 196
Loss: 2.173 | Acc: 25.000% (16/64)
Loss: 2.143 | Acc: 27.104% (1752/6464)
Loss: 2.144 | Acc: 27.083% (3484/12864)
Loss: 2.150 | Acc: 26.651% (5134/19264)
Loss: 2.145 | Acc: 27.011% (6932/25664)
Loss: 2.143 | Acc: 27.217% (8727/32064)
Loss: 2.144 | Acc: 27.207% (10465/38464)
Loss: 2.146 | Acc: 27.144% (12178/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2516, Accuracy: 2195/10000 (21.95%)

Epoch: 197
Loss: 2.071 | Acc: 34.375% (22/64)
Loss: 2.155 | Acc: 26.423% (1708/6464)
Loss: 2.153 | Acc: 26.586% (3420/12864)
Loss: 2.152 | Acc: 26.651% (5134/19264)
Loss: 2.153 | Acc: 26.742% (6863/25664)
Loss: 2.153 | Acc: 26.765% (8582/32064)
Loss: 2.152 | Acc: 26.963% (10371/38464)
Loss: 2.153 | Acc: 26.948% (12090/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2508, Accuracy: 2183/10000 (21.83%)
torch.Size([100, 10])
Test set: Average loss: 2.2508, Accuracy: 2183/10000 (21.83%)

Epoch: 198
Loss: 2.145 | Acc: 25.000% (16/64)
Loss: 2.138 | Acc: 27.800% (1797/6464)
Loss: 2.145 | Acc: 27.200% (3499/12864)
Loss: 2.147 | Acc: 26.947% (5191/19264)
Loss: 2.146 | Acc: 26.968% (6921/25664)
Loss: 2.146 | Acc: 27.005% (8659/32064)
Loss: 2.148 | Acc: 26.926% (10357/38464)
Loss: 2.149 | Acc: 26.854% (12048/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2509, Accuracy: 2174/10000 (21.74%)
torch.Size([100, 10])
Test set: Average loss: 2.2509, Accuracy: 2174/10000 (21.74%)

Epoch: 199
Loss: 2.222 | Acc: 28.125% (18/64)
Loss: 2.164 | Acc: 25.588% (1654/6464)
Loss: 2.154 | Acc: 26.469% (3405/12864)
Loss: 2.153 | Acc: 26.417% (5089/19264)
Loss: 2.153 | Acc: 26.407% (6777/25664)
Loss: 2.151 | Acc: 26.547% (8512/32064)
Loss: 2.149 | Acc: 26.760% (10293/38464)
Loss: 2.149 | Acc: 26.799% (12023/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2509, Accuracy: 2186/10000 (21.86%)
torch.Size([100, 10])
Test set: Average loss: 2.2509, Accuracy: 2186/10000 (21.86%)
2284
10000
-2.228311538696289
