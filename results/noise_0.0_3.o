==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.361 | Acc: 15.625% (10/64)
Loss: 2.850 | Acc: 15.749% (1018/6464)
Loss: 2.439 | Acc: 19.310% (2484/12864)
Loss: 2.267 | Acc: 21.631% (4167/19264)
Loss: 2.160 | Acc: 23.944% (6145/25664)
Loss: 2.081 | Acc: 26.076% (8361/32064)
Loss: 2.019 | Acc: 27.727% (10665/38464)
Loss: 1.964 | Acc: 29.282% (13137/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4079, Accuracy: 2549/10000 (25.49%)

Epoch: 1
Loss: 1.900 | Acc: 32.812% (21/64)
Loss: 1.556 | Acc: 42.110% (2722/6464)
Loss: 1.535 | Acc: 42.988% (5530/12864)
Loss: 1.518 | Acc: 43.698% (8418/19264)
Loss: 1.500 | Acc: 44.607% (11448/25664)
Loss: 1.475 | Acc: 45.746% (14668/32064)
Loss: 1.455 | Acc: 46.547% (17904/38464)
Loss: 1.433 | Acc: 47.457% (21291/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9688, Accuracy: 4073/10000 (40.73%)

Epoch: 2
Loss: 1.261 | Acc: 53.125% (34/64)
Loss: 1.221 | Acc: 55.523% (3589/6464)
Loss: 1.214 | Acc: 56.180% (7227/12864)
Loss: 1.184 | Acc: 57.293% (11037/19264)
Loss: 1.160 | Acc: 58.210% (14939/25664)
Loss: 1.143 | Acc: 58.985% (18913/32064)
Loss: 1.127 | Acc: 59.612% (22929/38464)
Loss: 1.113 | Acc: 60.053% (26942/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2402, Accuracy: 5741/10000 (57.41%)

Epoch: 3
Loss: 1.059 | Acc: 64.062% (41/64)
Loss: 0.987 | Acc: 65.053% (4205/6464)
Loss: 0.983 | Acc: 65.081% (8372/12864)
Loss: 0.963 | Acc: 65.568% (12631/19264)
Loss: 0.950 | Acc: 66.139% (16974/25664)
Loss: 0.939 | Acc: 66.657% (21373/32064)
Loss: 0.927 | Acc: 67.115% (25815/38464)
Loss: 0.917 | Acc: 67.508% (30287/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2351, Accuracy: 5998/10000 (59.98%)

Epoch: 4
Loss: 1.308 | Acc: 60.938% (39/64)
Loss: 0.805 | Acc: 71.968% (4652/6464)
Loss: 0.796 | Acc: 72.201% (9288/12864)
Loss: 0.790 | Acc: 72.508% (13968/19264)
Loss: 0.779 | Acc: 72.639% (18642/25664)
Loss: 0.771 | Acc: 73.013% (23411/32064)
Loss: 0.761 | Acc: 73.365% (28219/38464)
Loss: 0.753 | Acc: 73.689% (33060/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9584, Accuracy: 5055/10000 (50.55%)

Epoch: 5
Loss: 1.044 | Acc: 70.312% (45/64)
Loss: 0.682 | Acc: 76.207% (4926/6464)
Loss: 0.678 | Acc: 76.555% (9848/12864)
Loss: 0.670 | Acc: 76.884% (14811/19264)
Loss: 0.673 | Acc: 76.785% (19706/25664)
Loss: 0.667 | Acc: 76.937% (24669/32064)
Loss: 0.664 | Acc: 77.082% (29649/38464)
Loss: 0.662 | Acc: 77.184% (34628/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9794, Accuracy: 6749/10000 (67.49%)

Epoch: 6
Loss: 0.606 | Acc: 79.688% (51/64)
Loss: 0.611 | Acc: 78.914% (5101/6464)
Loss: 0.611 | Acc: 79.042% (10168/12864)
Loss: 0.610 | Acc: 78.987% (15216/19264)
Loss: 0.604 | Acc: 79.142% (20311/25664)
Loss: 0.604 | Acc: 79.079% (25356/32064)
Loss: 0.603 | Acc: 79.136% (30439/38464)
Loss: 0.600 | Acc: 79.235% (35548/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4390, Accuracy: 5834/10000 (58.34%)

Epoch: 7
Loss: 0.580 | Acc: 70.312% (45/64)
Loss: 0.562 | Acc: 80.183% (5183/6464)
Loss: 0.568 | Acc: 80.084% (10302/12864)
Loss: 0.561 | Acc: 80.544% (15516/19264)
Loss: 0.561 | Acc: 80.685% (20707/25664)
Loss: 0.560 | Acc: 80.785% (25903/32064)
Loss: 0.562 | Acc: 80.712% (31045/38464)
Loss: 0.561 | Acc: 80.731% (36219/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9454, Accuracy: 7174/10000 (71.74%)

Epoch: 8
Loss: 0.708 | Acc: 82.812% (53/64)
Loss: 0.537 | Acc: 81.513% (5269/6464)
Loss: 0.526 | Acc: 81.685% (10508/12864)
Loss: 0.522 | Acc: 82.003% (15797/19264)
Loss: 0.523 | Acc: 81.944% (21030/25664)
Loss: 0.522 | Acc: 81.933% (26271/32064)
Loss: 0.527 | Acc: 81.715% (31431/38464)
Loss: 0.525 | Acc: 81.774% (36687/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3766, Accuracy: 6200/10000 (62.00%)

Epoch: 9
Loss: 0.540 | Acc: 78.125% (50/64)
Loss: 0.504 | Acc: 82.874% (5357/6464)
Loss: 0.497 | Acc: 83.077% (10687/12864)
Loss: 0.507 | Acc: 82.807% (15952/19264)
Loss: 0.506 | Acc: 82.774% (21243/25664)
Loss: 0.505 | Acc: 82.775% (26541/32064)
Loss: 0.508 | Acc: 82.664% (31796/38464)
Loss: 0.506 | Acc: 82.759% (37129/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9795, Accuracy: 6820/10000 (68.20%)

Epoch: 10
Loss: 0.629 | Acc: 75.000% (48/64)
Loss: 0.490 | Acc: 82.720% (5347/6464)
Loss: 0.475 | Acc: 83.271% (10712/12864)
Loss: 0.484 | Acc: 82.963% (15982/19264)
Loss: 0.482 | Acc: 83.198% (21352/25664)
Loss: 0.478 | Acc: 83.349% (26725/32064)
Loss: 0.483 | Acc: 83.361% (32064/38464)
Loss: 0.484 | Acc: 83.334% (37387/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5522, Accuracy: 8120/10000 (81.20%)

Epoch: 11
Loss: 0.587 | Acc: 75.000% (48/64)
Loss: 0.457 | Acc: 83.973% (5428/6464)
Loss: 0.462 | Acc: 84.041% (10811/12864)
Loss: 0.461 | Acc: 84.126% (16206/19264)
Loss: 0.467 | Acc: 83.915% (21536/25664)
Loss: 0.466 | Acc: 83.966% (26923/32064)
Loss: 0.464 | Acc: 84.118% (32355/38464)
Loss: 0.463 | Acc: 84.148% (37752/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8393, Accuracy: 7443/10000 (74.43%)

Epoch: 12
Loss: 0.463 | Acc: 89.062% (57/64)
Loss: 0.435 | Acc: 85.226% (5509/6464)
Loss: 0.433 | Acc: 85.362% (10981/12864)
Loss: 0.434 | Acc: 85.216% (16416/19264)
Loss: 0.439 | Acc: 85.104% (21841/25664)
Loss: 0.441 | Acc: 85.033% (27265/32064)
Loss: 0.442 | Acc: 84.991% (32691/38464)
Loss: 0.444 | Acc: 84.883% (38082/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6124, Accuracy: 5692/10000 (56.92%)

Epoch: 13
Loss: 0.679 | Acc: 78.125% (50/64)
Loss: 0.440 | Acc: 85.118% (5502/6464)
Loss: 0.438 | Acc: 85.253% (10967/12864)
Loss: 0.433 | Acc: 85.424% (16456/19264)
Loss: 0.431 | Acc: 85.458% (21932/25664)
Loss: 0.429 | Acc: 85.560% (27434/32064)
Loss: 0.430 | Acc: 85.433% (32861/38464)
Loss: 0.428 | Acc: 85.481% (38350/44864)
torch.Size([100, 10])
Test set: Average loss: 3.7943, Accuracy: 3033/10000 (30.33%)

Epoch: 14
Loss: 0.847 | Acc: 73.438% (47/64)
Loss: 0.426 | Acc: 85.458% (5524/6464)
Loss: 0.422 | Acc: 85.432% (10990/12864)
Loss: 0.422 | Acc: 85.289% (16430/19264)
Loss: 0.420 | Acc: 85.357% (21906/25664)
Loss: 0.414 | Acc: 85.629% (27456/32064)
Loss: 0.415 | Acc: 85.639% (32940/38464)
Loss: 0.415 | Acc: 85.657% (38429/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3839, Accuracy: 6445/10000 (64.45%)

Epoch: 15
Loss: 0.594 | Acc: 81.250% (52/64)
Loss: 0.415 | Acc: 86.293% (5578/6464)
Loss: 0.398 | Acc: 86.489% (11126/12864)
Loss: 0.401 | Acc: 86.394% (16643/19264)
Loss: 0.397 | Acc: 86.530% (22207/25664)
Loss: 0.397 | Acc: 86.539% (27748/32064)
Loss: 0.397 | Acc: 86.489% (33267/38464)
Loss: 0.399 | Acc: 86.428% (38775/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4729, Accuracy: 8416/10000 (84.16%)

Epoch: 16
Loss: 0.388 | Acc: 89.062% (57/64)
Loss: 0.369 | Acc: 87.840% (5678/6464)
Loss: 0.373 | Acc: 87.414% (11245/12864)
Loss: 0.375 | Acc: 87.318% (16821/19264)
Loss: 0.382 | Acc: 87.095% (22352/25664)
Loss: 0.381 | Acc: 87.123% (27935/32064)
Loss: 0.381 | Acc: 87.126% (33512/38464)
Loss: 0.382 | Acc: 87.079% (39067/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4506, Accuracy: 6124/10000 (61.24%)

Epoch: 17
Loss: 0.479 | Acc: 81.250% (52/64)
Loss: 0.352 | Acc: 88.196% (5701/6464)
Loss: 0.372 | Acc: 87.352% (11237/12864)
Loss: 0.370 | Acc: 87.412% (16839/19264)
Loss: 0.368 | Acc: 87.434% (22439/25664)
Loss: 0.367 | Acc: 87.481% (28050/32064)
Loss: 0.368 | Acc: 87.445% (33635/38464)
Loss: 0.368 | Acc: 87.455% (39236/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6450, Accuracy: 7896/10000 (78.96%)

Epoch: 18
Loss: 0.609 | Acc: 81.250% (52/64)
Loss: 0.351 | Acc: 87.717% (5670/6464)
Loss: 0.351 | Acc: 87.733% (11286/12864)
Loss: 0.351 | Acc: 87.926% (16938/19264)
Loss: 0.353 | Acc: 87.870% (22551/25664)
Loss: 0.354 | Acc: 87.937% (28196/32064)
Loss: 0.354 | Acc: 87.913% (33815/38464)
Loss: 0.357 | Acc: 87.792% (39387/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9049, Accuracy: 7334/10000 (73.34%)

Epoch: 19
Loss: 0.357 | Acc: 87.500% (56/64)
Loss: 0.346 | Acc: 88.088% (5694/6464)
Loss: 0.343 | Acc: 88.347% (11365/12864)
Loss: 0.340 | Acc: 88.460% (17041/19264)
Loss: 0.338 | Acc: 88.579% (22733/25664)
Loss: 0.343 | Acc: 88.339% (28325/32064)
Loss: 0.343 | Acc: 88.257% (33947/38464)
Loss: 0.345 | Acc: 88.175% (39559/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5848, Accuracy: 8064/10000 (80.64%)

Epoch: 20
Loss: 0.376 | Acc: 82.812% (53/64)
Loss: 0.322 | Acc: 89.171% (5764/6464)
Loss: 0.314 | Acc: 89.171% (11471/12864)
Loss: 0.323 | Acc: 88.928% (17131/19264)
Loss: 0.323 | Acc: 88.992% (22839/25664)
Loss: 0.325 | Acc: 88.975% (28529/32064)
Loss: 0.327 | Acc: 88.888% (34190/38464)
Loss: 0.326 | Acc: 88.886% (39878/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3258, Accuracy: 4844/10000 (48.44%)

Epoch: 21
Loss: 0.568 | Acc: 75.000% (48/64)
Loss: 0.345 | Acc: 88.134% (5697/6464)
Loss: 0.334 | Acc: 88.511% (11386/12864)
Loss: 0.329 | Acc: 88.782% (17103/19264)
Loss: 0.329 | Acc: 88.751% (22777/25664)
Loss: 0.325 | Acc: 88.935% (28516/32064)
Loss: 0.325 | Acc: 88.878% (34186/38464)
Loss: 0.322 | Acc: 88.976% (39918/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8597, Accuracy: 7326/10000 (73.26%)

Epoch: 22
Loss: 0.404 | Acc: 85.938% (55/64)
Loss: 0.278 | Acc: 90.749% (5866/6464)
Loss: 0.296 | Acc: 90.042% (11583/12864)
Loss: 0.306 | Acc: 89.561% (17253/19264)
Loss: 0.305 | Acc: 89.553% (22983/25664)
Loss: 0.306 | Acc: 89.437% (28677/32064)
Loss: 0.308 | Acc: 89.460% (34410/38464)
Loss: 0.307 | Acc: 89.482% (40145/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8503, Accuracy: 7605/10000 (76.05%)

Epoch: 23
Loss: 0.431 | Acc: 84.375% (54/64)
Loss: 0.265 | Acc: 91.027% (5884/6464)
Loss: 0.280 | Acc: 90.563% (11650/12864)
Loss: 0.282 | Acc: 90.537% (17441/19264)
Loss: 0.287 | Acc: 90.356% (23189/25664)
Loss: 0.289 | Acc: 90.335% (28965/32064)
Loss: 0.289 | Acc: 90.245% (34712/38464)
Loss: 0.289 | Acc: 90.181% (40459/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9962, Accuracy: 6996/10000 (69.96%)

Epoch: 24
Loss: 0.450 | Acc: 78.125% (50/64)
Loss: 0.301 | Acc: 89.403% (5779/6464)
Loss: 0.292 | Acc: 89.739% (11544/12864)
Loss: 0.286 | Acc: 89.987% (17335/19264)
Loss: 0.284 | Acc: 90.115% (23127/25664)
Loss: 0.283 | Acc: 90.129% (28899/32064)
Loss: 0.285 | Acc: 90.110% (34660/38464)
Loss: 0.285 | Acc: 90.135% (40438/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2982, Accuracy: 6688/10000 (66.88%)

Epoch: 25
Loss: 0.583 | Acc: 79.688% (51/64)
Loss: 0.264 | Acc: 90.981% (5881/6464)
Loss: 0.270 | Acc: 90.951% (11700/12864)
Loss: 0.265 | Acc: 91.253% (17579/19264)
Loss: 0.260 | Acc: 91.311% (23434/25664)
Loss: 0.258 | Acc: 91.261% (29262/32064)
Loss: 0.260 | Acc: 91.153% (35061/38464)
Loss: 0.263 | Acc: 91.060% (40853/44864)
torch.Size([100, 10])
Test set: Average loss: 5.5247, Accuracy: 4522/10000 (45.22%)

Epoch: 26
Loss: 0.801 | Acc: 79.688% (51/64)
Loss: 0.258 | Acc: 91.120% (5890/6464)
Loss: 0.249 | Acc: 91.581% (11781/12864)
Loss: 0.244 | Acc: 91.684% (17662/19264)
Loss: 0.247 | Acc: 91.545% (23494/25664)
Loss: 0.249 | Acc: 91.514% (29343/32064)
Loss: 0.249 | Acc: 91.473% (35184/38464)
Loss: 0.248 | Acc: 91.510% (41055/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5726, Accuracy: 8273/10000 (82.73%)

Epoch: 27
Loss: 0.460 | Acc: 84.375% (54/64)
Loss: 0.246 | Acc: 91.476% (5913/6464)
Loss: 0.242 | Acc: 91.682% (11794/12864)
Loss: 0.246 | Acc: 91.523% (17631/19264)
Loss: 0.247 | Acc: 91.506% (23484/25664)
Loss: 0.248 | Acc: 91.470% (29329/32064)
Loss: 0.245 | Acc: 91.613% (35238/38464)
Loss: 0.243 | Acc: 91.695% (41138/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6334, Accuracy: 8082/10000 (80.82%)

Epoch: 28
Loss: 0.480 | Acc: 81.250% (52/64)
Loss: 0.225 | Acc: 91.909% (5941/6464)
Loss: 0.225 | Acc: 92.094% (11847/12864)
Loss: 0.227 | Acc: 92.130% (17748/19264)
Loss: 0.229 | Acc: 92.098% (23636/25664)
Loss: 0.229 | Acc: 92.078% (29524/32064)
Loss: 0.230 | Acc: 92.110% (35429/38464)
Loss: 0.226 | Acc: 92.210% (41369/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3243, Accuracy: 6756/10000 (67.56%)

Epoch: 29
Loss: 0.420 | Acc: 82.812% (53/64)
Loss: 0.214 | Acc: 92.234% (5962/6464)
Loss: 0.208 | Acc: 92.708% (11926/12864)
Loss: 0.207 | Acc: 92.795% (17876/19264)
Loss: 0.208 | Acc: 92.838% (23826/25664)
Loss: 0.211 | Acc: 92.711% (29727/32064)
Loss: 0.212 | Acc: 92.728% (35667/38464)
Loss: 0.213 | Acc: 92.720% (41598/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3805, Accuracy: 8742/10000 (87.42%)

Epoch: 30
Loss: 0.209 | Acc: 90.625% (58/64)
Loss: 0.182 | Acc: 93.905% (6070/6464)
Loss: 0.184 | Acc: 93.742% (12059/12864)
Loss: 0.195 | Acc: 93.433% (17999/19264)
Loss: 0.196 | Acc: 93.415% (23974/25664)
Loss: 0.196 | Acc: 93.382% (29942/32064)
Loss: 0.199 | Acc: 93.272% (35876/38464)
Loss: 0.198 | Acc: 93.264% (41842/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5862, Accuracy: 8300/10000 (83.00%)

Epoch: 31
Loss: 0.250 | Acc: 92.188% (59/64)
Loss: 0.172 | Acc: 94.121% (6084/6464)
Loss: 0.176 | Acc: 93.937% (12084/12864)
Loss: 0.180 | Acc: 93.755% (18061/19264)
Loss: 0.180 | Acc: 93.711% (24050/25664)
Loss: 0.180 | Acc: 93.709% (30047/32064)
Loss: 0.182 | Acc: 93.721% (36049/38464)
Loss: 0.184 | Acc: 93.672% (42025/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3524, Accuracy: 8878/10000 (88.78%)

Epoch: 32
Loss: 0.161 | Acc: 95.312% (61/64)
Loss: 0.145 | Acc: 95.142% (6150/6464)
Loss: 0.154 | Acc: 94.776% (12192/12864)
Loss: 0.158 | Acc: 94.669% (18237/19264)
Loss: 0.162 | Acc: 94.514% (24256/25664)
Loss: 0.165 | Acc: 94.343% (30250/32064)
Loss: 0.167 | Acc: 94.205% (36235/38464)
Loss: 0.166 | Acc: 94.249% (42284/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4547, Accuracy: 8680/10000 (86.80%)

Epoch: 33
Loss: 0.104 | Acc: 96.875% (62/64)
Loss: 0.144 | Acc: 95.235% (6156/6464)
Loss: 0.141 | Acc: 95.180% (12244/12864)
Loss: 0.143 | Acc: 95.203% (18340/19264)
Loss: 0.147 | Acc: 95.102% (24407/25664)
Loss: 0.147 | Acc: 95.019% (30467/32064)
Loss: 0.148 | Acc: 94.946% (36520/38464)
Loss: 0.148 | Acc: 94.889% (42571/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3004, Accuracy: 9067/10000 (90.67%)

Epoch: 34
Loss: 0.063 | Acc: 96.875% (62/64)
Loss: 0.133 | Acc: 95.235% (6156/6464)
Loss: 0.128 | Acc: 95.491% (12284/12864)
Loss: 0.128 | Acc: 95.536% (18404/19264)
Loss: 0.132 | Acc: 95.359% (24473/25664)
Loss: 0.132 | Acc: 95.362% (30577/32064)
Loss: 0.132 | Acc: 95.416% (36701/38464)
Loss: 0.132 | Acc: 95.404% (42802/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2822, Accuracy: 9153/10000 (91.53%)

Epoch: 35
Loss: 0.091 | Acc: 96.875% (62/64)
Loss: 0.121 | Acc: 95.823% (6194/6464)
Loss: 0.117 | Acc: 96.012% (12351/12864)
Loss: 0.112 | Acc: 96.216% (18535/19264)
Loss: 0.114 | Acc: 96.181% (24684/25664)
Loss: 0.113 | Acc: 96.211% (30849/32064)
Loss: 0.114 | Acc: 96.142% (36980/38464)
Loss: 0.116 | Acc: 96.057% (43095/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2868, Accuracy: 9134/10000 (91.34%)

Epoch: 36
Loss: 0.150 | Acc: 93.750% (60/64)
Loss: 0.096 | Acc: 96.597% (6244/6464)
Loss: 0.099 | Acc: 96.611% (12428/12864)
Loss: 0.099 | Acc: 96.589% (18607/19264)
Loss: 0.101 | Acc: 96.536% (24775/25664)
Loss: 0.102 | Acc: 96.501% (30942/32064)
Loss: 0.101 | Acc: 96.558% (37140/38464)
Loss: 0.102 | Acc: 96.509% (43298/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2710, Accuracy: 9170/10000 (91.70%)

Epoch: 37
Loss: 0.083 | Acc: 98.438% (63/64)
Loss: 0.087 | Acc: 96.937% (6266/6464)
Loss: 0.084 | Acc: 97.093% (12490/12864)
Loss: 0.082 | Acc: 97.202% (18725/19264)
Loss: 0.083 | Acc: 97.136% (24929/25664)
Loss: 0.086 | Acc: 97.087% (31130/32064)
Loss: 0.087 | Acc: 97.028% (37321/38464)
Loss: 0.087 | Acc: 96.980% (43509/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2949, Accuracy: 9068/10000 (90.68%)

Epoch: 38
Loss: 0.126 | Acc: 95.312% (61/64)
Loss: 0.087 | Acc: 96.937% (6266/6464)
Loss: 0.076 | Acc: 97.427% (12533/12864)
Loss: 0.072 | Acc: 97.576% (18797/19264)
Loss: 0.071 | Acc: 97.674% (25067/25664)
Loss: 0.071 | Acc: 97.620% (31301/32064)
Loss: 0.072 | Acc: 97.642% (37557/38464)
Loss: 0.071 | Acc: 97.660% (43814/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2567, Accuracy: 9236/10000 (92.36%)

Epoch: 39
Loss: 0.073 | Acc: 95.312% (61/64)
Loss: 0.058 | Acc: 97.989% (6334/6464)
Loss: 0.060 | Acc: 97.963% (12602/12864)
Loss: 0.056 | Acc: 98.105% (18899/19264)
Loss: 0.055 | Acc: 98.169% (25194/25664)
Loss: 0.057 | Acc: 98.094% (31453/32064)
Loss: 0.057 | Acc: 98.074% (37723/38464)
Loss: 0.059 | Acc: 98.030% (43980/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2710, Accuracy: 9217/10000 (92.17%)

Epoch: 40
Loss: 0.027 | Acc: 100.000% (64/64)
Loss: 0.046 | Acc: 98.546% (6370/6464)
Loss: 0.048 | Acc: 98.484% (12669/12864)
Loss: 0.048 | Acc: 98.448% (18965/19264)
Loss: 0.047 | Acc: 98.434% (25262/25664)
Loss: 0.047 | Acc: 98.453% (31568/32064)
Loss: 0.047 | Acc: 98.445% (37866/38464)
Loss: 0.047 | Acc: 98.438% (44163/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2625, Accuracy: 9238/10000 (92.38%)

Epoch: 41
Loss: 0.047 | Acc: 98.438% (63/64)
Loss: 0.037 | Acc: 98.963% (6397/6464)
Loss: 0.035 | Acc: 98.951% (12729/12864)
Loss: 0.035 | Acc: 98.925% (19057/19264)
Loss: 0.035 | Acc: 98.870% (25374/25664)
Loss: 0.035 | Acc: 98.893% (31709/32064)
Loss: 0.036 | Acc: 98.874% (38031/38464)
Loss: 0.035 | Acc: 98.883% (44363/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2191, Accuracy: 9383/10000 (93.83%)

Epoch: 42
Loss: 0.072 | Acc: 96.875% (62/64)
Loss: 0.028 | Acc: 99.103% (6406/6464)
Loss: 0.032 | Acc: 98.943% (12728/12864)
Loss: 0.030 | Acc: 99.066% (19084/19264)
Loss: 0.029 | Acc: 99.127% (25440/25664)
Loss: 0.029 | Acc: 99.111% (31779/32064)
Loss: 0.029 | Acc: 99.093% (38115/38464)
Loss: 0.028 | Acc: 99.128% (44473/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2135, Accuracy: 9394/10000 (93.94%)

Epoch: 43
Loss: 0.013 | Acc: 100.000% (64/64)
Loss: 0.017 | Acc: 99.520% (6433/6464)
Loss: 0.020 | Acc: 99.471% (12796/12864)
Loss: 0.018 | Acc: 99.554% (19178/19264)
Loss: 0.018 | Acc: 99.571% (25554/25664)
Loss: 0.018 | Acc: 99.573% (31927/32064)
Loss: 0.018 | Acc: 99.555% (38293/38464)
Loss: 0.019 | Acc: 99.530% (44653/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2619, Accuracy: 9290/10000 (92.90%)

Epoch: 44
Loss: 0.037 | Acc: 98.438% (63/64)
Loss: 0.016 | Acc: 99.582% (6437/6464)
Loss: 0.016 | Acc: 99.619% (12815/12864)
Loss: 0.016 | Acc: 99.611% (19189/19264)
Loss: 0.016 | Acc: 99.591% (25559/25664)
Loss: 0.016 | Acc: 99.576% (31928/32064)
Loss: 0.016 | Acc: 99.597% (38309/38464)
Loss: 0.016 | Acc: 99.612% (44690/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2066, Accuracy: 9415/10000 (94.15%)

Epoch: 45
Loss: 0.009 | Acc: 100.000% (64/64)
Loss: 0.016 | Acc: 99.598% (6438/6464)
Loss: 0.018 | Acc: 99.572% (12809/12864)
Loss: 0.021 | Acc: 99.528% (19173/19264)
Loss: 0.024 | Acc: 99.412% (25513/25664)
Loss: 0.027 | Acc: 99.411% (31875/32064)
Loss: 0.029 | Acc: 99.342% (38211/38464)
Loss: 0.032 | Acc: 99.307% (44553/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2039, Accuracy: 9344/10000 (93.44%)

Epoch: 46
Loss: 0.060 | Acc: 98.438% (63/64)
Loss: 0.058 | Acc: 98.731% (6382/6464)
Loss: 0.059 | Acc: 98.725% (12700/12864)
Loss: 0.061 | Acc: 98.681% (19010/19264)
Loss: 0.062 | Acc: 98.663% (25321/25664)
Loss: 0.063 | Acc: 98.643% (31629/32064)
Loss: 0.065 | Acc: 98.606% (37928/38464)
Loss: 0.067 | Acc: 98.571% (44223/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2073, Accuracy: 9316/10000 (93.16%)

Epoch: 47
Loss: 0.052 | Acc: 98.438% (63/64)
Loss: 0.076 | Acc: 98.345% (6357/6464)
Loss: 0.077 | Acc: 98.336% (12650/12864)
Loss: 0.077 | Acc: 98.328% (18942/19264)
Loss: 0.078 | Acc: 98.278% (25222/25664)
Loss: 0.079 | Acc: 98.250% (31503/32064)
Loss: 0.081 | Acc: 98.206% (37774/38464)
Loss: 0.081 | Acc: 98.203% (44058/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2150, Accuracy: 9317/10000 (93.17%)
torch.Size([100, 10])
Test set: Average loss: 0.2150, Accuracy: 9317/10000 (93.17%)

Epoch: 48
Loss: 0.085 | Acc: 96.875% (62/64)
Loss: 0.083 | Acc: 98.345% (6357/6464)
Loss: 0.083 | Acc: 98.290% (12644/12864)
Loss: 0.084 | Acc: 98.245% (18926/19264)
Loss: 0.085 | Acc: 98.219% (25207/25664)
Loss: 0.085 | Acc: 98.204% (31488/32064)
Loss: 0.086 | Acc: 98.115% (37739/38464)
Loss: 0.087 | Acc: 98.103% (44013/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2128, Accuracy: 9301/10000 (93.01%)
torch.Size([100, 10])
Test set: Average loss: 0.2128, Accuracy: 9301/10000 (93.01%)

Epoch: 49
Loss: 0.095 | Acc: 98.438% (63/64)
Loss: 0.088 | Acc: 97.927% (6330/6464)
Loss: 0.090 | Acc: 97.924% (12597/12864)
Loss: 0.091 | Acc: 97.851% (18850/19264)
Loss: 0.092 | Acc: 97.810% (25102/25664)
Loss: 0.091 | Acc: 97.885% (31386/32064)
Loss: 0.090 | Acc: 97.967% (37682/38464)
Loss: 0.090 | Acc: 97.934% (43937/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2148, Accuracy: 9282/10000 (92.82%)
torch.Size([100, 10])
Test set: Average loss: 0.2148, Accuracy: 9282/10000 (92.82%)

Epoch: 50
Loss: 0.065 | Acc: 100.000% (64/64)
Loss: 2.070 | Acc: 24.319% (1572/6464)
Loss: 1.867 | Acc: 31.126% (4004/12864)
Loss: 1.662 | Acc: 39.011% (7515/19264)
Loss: 1.464 | Acc: 46.731% (11993/25664)
Loss: 1.315 | Acc: 52.423% (16809/32064)
Loss: 1.206 | Acc: 56.598% (21770/38464)
Loss: 1.120 | Acc: 59.892% (26870/44864)
torch.Size([100, 10])
Test set: Average loss: 3.1981, Accuracy: 4041/10000 (40.41%)

Epoch: 51
Loss: 0.884 | Acc: 73.438% (47/64)
Loss: 0.553 | Acc: 81.405% (5262/6464)
Loss: 0.537 | Acc: 81.755% (10517/12864)
Loss: 0.530 | Acc: 82.091% (15814/19264)
Loss: 0.521 | Acc: 82.325% (21128/25664)
Loss: 0.514 | Acc: 82.522% (26460/32064)
Loss: 0.507 | Acc: 82.779% (31840/38464)
Loss: 0.502 | Acc: 82.931% (37206/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4191, Accuracy: 5014/10000 (50.14%)

Epoch: 52
Loss: 0.782 | Acc: 71.875% (46/64)
Loss: 0.454 | Acc: 84.947% (5491/6464)
Loss: 0.446 | Acc: 84.834% (10913/12864)
Loss: 0.437 | Acc: 85.039% (16382/19264)
Loss: 0.437 | Acc: 85.045% (21826/25664)
Loss: 0.435 | Acc: 85.127% (27295/32064)
Loss: 0.431 | Acc: 85.293% (32807/38464)
Loss: 0.428 | Acc: 85.338% (38286/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5317, Accuracy: 8200/10000 (82.00%)

Epoch: 53
Loss: 0.432 | Acc: 81.250% (52/64)
Loss: 0.383 | Acc: 86.943% (5620/6464)
Loss: 0.390 | Acc: 86.886% (11177/12864)
Loss: 0.396 | Acc: 86.509% (16665/19264)
Loss: 0.394 | Acc: 86.518% (22204/25664)
Loss: 0.398 | Acc: 86.383% (27698/32064)
Loss: 0.397 | Acc: 86.499% (33271/38464)
Loss: 0.398 | Acc: 86.443% (38782/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7682, Accuracy: 7546/10000 (75.46%)

Epoch: 54
Loss: 0.427 | Acc: 84.375% (54/64)
Loss: 0.385 | Acc: 87.051% (5627/6464)
Loss: 0.376 | Acc: 87.135% (11209/12864)
Loss: 0.374 | Acc: 87.235% (16805/19264)
Loss: 0.384 | Acc: 87.017% (22332/25664)
Loss: 0.388 | Acc: 86.826% (27840/32064)
Loss: 0.389 | Acc: 86.785% (33381/38464)
Loss: 0.389 | Acc: 86.791% (38938/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7278, Accuracy: 7699/10000 (76.99%)

Epoch: 55
Loss: 0.283 | Acc: 87.500% (56/64)
Loss: 0.374 | Acc: 87.113% (5631/6464)
Loss: 0.370 | Acc: 87.368% (11239/12864)
Loss: 0.375 | Acc: 87.298% (16817/19264)
Loss: 0.376 | Acc: 87.169% (22371/25664)
Loss: 0.378 | Acc: 87.091% (27925/32064)
Loss: 0.379 | Acc: 87.045% (33481/38464)
Loss: 0.378 | Acc: 87.034% (39047/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8041, Accuracy: 7561/10000 (75.61%)

Epoch: 56
Loss: 0.191 | Acc: 95.312% (61/64)
Loss: 0.359 | Acc: 88.243% (5704/6464)
Loss: 0.366 | Acc: 87.663% (11277/12864)
Loss: 0.364 | Acc: 87.687% (16892/19264)
Loss: 0.360 | Acc: 87.761% (22523/25664)
Loss: 0.364 | Acc: 87.640% (28101/32064)
Loss: 0.368 | Acc: 87.448% (33636/38464)
Loss: 0.370 | Acc: 87.384% (39204/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5025, Accuracy: 8282/10000 (82.82%)

Epoch: 57
Loss: 0.511 | Acc: 76.562% (49/64)
Loss: 0.355 | Acc: 87.763% (5673/6464)
Loss: 0.356 | Acc: 87.920% (11310/12864)
Loss: 0.358 | Acc: 87.957% (16944/19264)
Loss: 0.358 | Acc: 88.053% (22598/25664)
Loss: 0.360 | Acc: 87.893% (28182/32064)
Loss: 0.361 | Acc: 87.854% (33792/38464)
Loss: 0.362 | Acc: 87.810% (39395/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5142, Accuracy: 5844/10000 (58.44%)

Epoch: 58
Loss: 0.397 | Acc: 82.812% (53/64)
Loss: 0.355 | Acc: 87.949% (5685/6464)
Loss: 0.358 | Acc: 87.741% (11287/12864)
Loss: 0.356 | Acc: 87.770% (16908/19264)
Loss: 0.355 | Acc: 87.862% (22549/25664)
Loss: 0.352 | Acc: 87.999% (28216/32064)
Loss: 0.356 | Acc: 87.851% (33791/38464)
Loss: 0.358 | Acc: 87.830% (39404/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9359, Accuracy: 7482/10000 (74.82%)

Epoch: 59
Loss: 0.500 | Acc: 89.062% (57/64)
Loss: 0.349 | Acc: 88.413% (5715/6464)
Loss: 0.349 | Acc: 88.130% (11337/12864)
Loss: 0.350 | Acc: 88.019% (16956/19264)
Loss: 0.353 | Acc: 87.936% (22568/25664)
Loss: 0.355 | Acc: 87.884% (28179/32064)
Loss: 0.355 | Acc: 87.856% (33793/38464)
Loss: 0.355 | Acc: 87.859% (39417/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7304, Accuracy: 7641/10000 (76.41%)

Epoch: 60
Loss: 0.463 | Acc: 84.375% (54/64)
Loss: 0.334 | Acc: 88.691% (5733/6464)
Loss: 0.336 | Acc: 88.783% (11421/12864)
Loss: 0.343 | Acc: 88.357% (17021/19264)
Loss: 0.342 | Acc: 88.381% (22682/25664)
Loss: 0.344 | Acc: 88.308% (28315/32064)
Loss: 0.345 | Acc: 88.277% (33955/38464)
Loss: 0.344 | Acc: 88.220% (39579/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4530, Accuracy: 8466/10000 (84.66%)

Epoch: 61
Loss: 0.292 | Acc: 90.625% (58/64)
Loss: 0.314 | Acc: 89.264% (5770/6464)
Loss: 0.332 | Acc: 88.347% (11365/12864)
Loss: 0.334 | Acc: 88.315% (17013/19264)
Loss: 0.335 | Acc: 88.392% (22685/25664)
Loss: 0.336 | Acc: 88.379% (28338/32064)
Loss: 0.336 | Acc: 88.431% (34014/38464)
Loss: 0.336 | Acc: 88.496% (39703/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3653, Accuracy: 4973/10000 (49.73%)

Epoch: 62
Loss: 0.385 | Acc: 90.625% (58/64)
Loss: 0.322 | Acc: 88.830% (5742/6464)
Loss: 0.319 | Acc: 88.923% (11439/12864)
Loss: 0.318 | Acc: 89.156% (17175/19264)
Loss: 0.321 | Acc: 89.105% (22868/25664)
Loss: 0.326 | Acc: 88.950% (28521/32064)
Loss: 0.329 | Acc: 88.891% (34191/38464)
Loss: 0.331 | Acc: 88.873% (39872/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7472, Accuracy: 6242/10000 (62.42%)

Epoch: 63
Loss: 0.593 | Acc: 85.938% (55/64)
Loss: 0.328 | Acc: 89.078% (5758/6464)
Loss: 0.326 | Acc: 88.993% (11448/12864)
Loss: 0.321 | Acc: 89.088% (17162/19264)
Loss: 0.325 | Acc: 88.930% (22823/25664)
Loss: 0.327 | Acc: 88.860% (28492/32064)
Loss: 0.329 | Acc: 88.730% (34129/38464)
Loss: 0.328 | Acc: 88.730% (39808/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0382, Accuracy: 7361/10000 (73.61%)

Epoch: 64
Loss: 0.489 | Acc: 84.375% (54/64)
Loss: 0.319 | Acc: 89.047% (5756/6464)
Loss: 0.309 | Acc: 89.599% (11526/12864)
Loss: 0.317 | Acc: 89.317% (17206/19264)
Loss: 0.318 | Acc: 89.265% (22909/25664)
Loss: 0.316 | Acc: 89.197% (28600/32064)
Loss: 0.316 | Acc: 89.203% (34311/38464)
Loss: 0.319 | Acc: 89.118% (39982/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2770, Accuracy: 6576/10000 (65.76%)

Epoch: 65
Loss: 0.299 | Acc: 90.625% (58/64)
Loss: 0.328 | Acc: 89.109% (5760/6464)
Loss: 0.315 | Acc: 89.436% (11505/12864)
Loss: 0.308 | Acc: 89.452% (17232/19264)
Loss: 0.309 | Acc: 89.401% (22944/25664)
Loss: 0.308 | Acc: 89.421% (28672/32064)
Loss: 0.310 | Acc: 89.369% (34375/38464)
Loss: 0.311 | Acc: 89.352% (40087/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4787, Accuracy: 8392/10000 (83.92%)

Epoch: 66
Loss: 0.340 | Acc: 90.625% (58/64)
Loss: 0.276 | Acc: 90.532% (5852/6464)
Loss: 0.293 | Acc: 90.096% (11590/12864)
Loss: 0.298 | Acc: 89.950% (17328/19264)
Loss: 0.299 | Acc: 89.931% (23080/25664)
Loss: 0.298 | Acc: 89.945% (28840/32064)
Loss: 0.299 | Acc: 89.889% (34575/38464)
Loss: 0.300 | Acc: 89.809% (40292/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5422, Accuracy: 4704/10000 (47.04%)

Epoch: 67
Loss: 0.476 | Acc: 84.375% (54/64)
Loss: 0.304 | Acc: 89.666% (5796/6464)
Loss: 0.294 | Acc: 89.933% (11569/12864)
Loss: 0.288 | Acc: 90.173% (17371/19264)
Loss: 0.289 | Acc: 90.157% (23138/25664)
Loss: 0.295 | Acc: 90.004% (28859/32064)
Loss: 0.300 | Acc: 89.772% (34530/38464)
Loss: 0.301 | Acc: 89.731% (40257/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7672, Accuracy: 7740/10000 (77.40%)

Epoch: 68
Loss: 0.327 | Acc: 89.062% (57/64)
Loss: 0.290 | Acc: 90.099% (5824/6464)
Loss: 0.287 | Acc: 90.275% (11613/12864)
Loss: 0.291 | Acc: 90.225% (17381/19264)
Loss: 0.294 | Acc: 90.076% (23117/25664)
Loss: 0.290 | Acc: 90.229% (28931/32064)
Loss: 0.289 | Acc: 90.279% (34725/38464)
Loss: 0.290 | Acc: 90.190% (40463/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4532, Accuracy: 8511/10000 (85.11%)

Epoch: 69
Loss: 0.186 | Acc: 89.062% (57/64)
Loss: 0.262 | Acc: 91.120% (5890/6464)
Loss: 0.263 | Acc: 91.099% (11719/12864)
Loss: 0.273 | Acc: 90.791% (17490/19264)
Loss: 0.276 | Acc: 90.664% (23268/25664)
Loss: 0.280 | Acc: 90.572% (29041/32064)
Loss: 0.279 | Acc: 90.615% (34854/38464)
Loss: 0.277 | Acc: 90.714% (40698/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6782, Accuracy: 7967/10000 (79.67%)

Epoch: 70
Loss: 0.204 | Acc: 92.188% (59/64)
Loss: 0.254 | Acc: 91.197% (5895/6464)
Loss: 0.262 | Acc: 91.045% (11712/12864)
Loss: 0.258 | Acc: 91.347% (17597/19264)
Loss: 0.255 | Acc: 91.439% (23467/25664)
Loss: 0.260 | Acc: 91.211% (29246/32064)
Loss: 0.265 | Acc: 91.007% (35005/38464)
Loss: 0.269 | Acc: 90.875% (40770/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6209, Accuracy: 8138/10000 (81.38%)

Epoch: 71
Loss: 0.422 | Acc: 81.250% (52/64)
Loss: 0.236 | Acc: 91.631% (5923/6464)
Loss: 0.255 | Acc: 91.309% (11746/12864)
Loss: 0.251 | Acc: 91.482% (17623/19264)
Loss: 0.256 | Acc: 91.397% (23456/25664)
Loss: 0.258 | Acc: 91.324% (29282/32064)
Loss: 0.262 | Acc: 91.109% (35044/38464)
Loss: 0.260 | Acc: 91.149% (40893/44864)
torch.Size([100, 10])
Test set: Average loss: 2.8027, Accuracy: 4495/10000 (44.95%)

Epoch: 72
Loss: 0.903 | Acc: 70.312% (45/64)
Loss: 0.291 | Acc: 90.207% (5831/6464)
Loss: 0.271 | Acc: 90.757% (11675/12864)
Loss: 0.268 | Acc: 90.713% (17475/19264)
Loss: 0.266 | Acc: 90.773% (23296/25664)
Loss: 0.261 | Acc: 90.940% (29159/32064)
Loss: 0.259 | Acc: 90.953% (34984/38464)
Loss: 0.259 | Acc: 90.991% (40822/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5400, Accuracy: 8362/10000 (83.62%)

Epoch: 73
Loss: 0.230 | Acc: 92.188% (59/64)
Loss: 0.227 | Acc: 92.404% (5973/6464)
Loss: 0.240 | Acc: 92.001% (11835/12864)
Loss: 0.240 | Acc: 91.871% (17698/19264)
Loss: 0.241 | Acc: 91.790% (23557/25664)
Loss: 0.243 | Acc: 91.667% (29392/32064)
Loss: 0.243 | Acc: 91.701% (35272/38464)
Loss: 0.244 | Acc: 91.646% (41116/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4067, Accuracy: 8718/10000 (87.18%)

Epoch: 74
Loss: 0.359 | Acc: 84.375% (54/64)
Loss: 0.215 | Acc: 92.621% (5987/6464)
Loss: 0.210 | Acc: 92.918% (11953/12864)
Loss: 0.217 | Acc: 92.655% (17849/19264)
Loss: 0.222 | Acc: 92.417% (23718/25664)
Loss: 0.223 | Acc: 92.446% (29642/32064)
Loss: 0.227 | Acc: 92.299% (35502/38464)
Loss: 0.227 | Acc: 92.310% (41414/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6562, Accuracy: 7957/10000 (79.57%)

Epoch: 75
Loss: 0.389 | Acc: 87.500% (56/64)
Loss: 0.204 | Acc: 93.023% (6013/6464)
Loss: 0.207 | Acc: 92.864% (11946/12864)
Loss: 0.215 | Acc: 92.608% (17840/19264)
Loss: 0.214 | Acc: 92.659% (23780/25664)
Loss: 0.217 | Acc: 92.543% (29673/32064)
Loss: 0.218 | Acc: 92.505% (35581/38464)
Loss: 0.219 | Acc: 92.482% (41491/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3188, Accuracy: 8923/10000 (89.23%)

Epoch: 76
Loss: 0.206 | Acc: 93.750% (60/64)
Loss: 0.185 | Acc: 93.905% (6070/6464)
Loss: 0.195 | Acc: 93.338% (12007/12864)
Loss: 0.198 | Acc: 93.226% (17959/19264)
Loss: 0.202 | Acc: 93.084% (23889/25664)
Loss: 0.209 | Acc: 92.871% (29778/32064)
Loss: 0.213 | Acc: 92.720% (35664/38464)
Loss: 0.213 | Acc: 92.743% (41608/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3266, Accuracy: 8962/10000 (89.62%)

Epoch: 77
Loss: 0.257 | Acc: 95.312% (61/64)
Loss: 0.189 | Acc: 93.595% (6050/6464)
Loss: 0.189 | Acc: 93.486% (12026/12864)
Loss: 0.196 | Acc: 93.267% (17967/19264)
Loss: 0.198 | Acc: 93.220% (23924/25664)
Loss: 0.197 | Acc: 93.220% (29890/32064)
Loss: 0.197 | Acc: 93.243% (35865/38464)
Loss: 0.197 | Acc: 93.242% (41832/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3195, Accuracy: 8958/10000 (89.58%)

Epoch: 78
Loss: 0.203 | Acc: 92.188% (59/64)
Loss: 0.166 | Acc: 94.524% (6110/6464)
Loss: 0.171 | Acc: 94.317% (12133/12864)
Loss: 0.175 | Acc: 94.181% (18143/19264)
Loss: 0.181 | Acc: 93.879% (24093/25664)
Loss: 0.185 | Acc: 93.713% (30048/32064)
Loss: 0.185 | Acc: 93.677% (36032/38464)
Loss: 0.186 | Acc: 93.656% (42018/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8837, Accuracy: 7522/10000 (75.22%)

Epoch: 79
Loss: 0.125 | Acc: 95.312% (61/64)
Loss: 0.178 | Acc: 93.967% (6074/6464)
Loss: 0.172 | Acc: 94.178% (12115/12864)
Loss: 0.171 | Acc: 94.264% (18159/19264)
Loss: 0.170 | Acc: 94.307% (24203/25664)
Loss: 0.170 | Acc: 94.336% (30248/32064)
Loss: 0.169 | Acc: 94.345% (36289/38464)
Loss: 0.171 | Acc: 94.280% (42298/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4352, Accuracy: 6465/10000 (64.65%)

Epoch: 80
Loss: 0.573 | Acc: 81.250% (52/64)
Loss: 0.185 | Acc: 93.688% (6056/6464)
Loss: 0.169 | Acc: 94.240% (12123/12864)
Loss: 0.167 | Acc: 94.254% (18157/19264)
Loss: 0.170 | Acc: 94.167% (24167/25664)
Loss: 0.169 | Acc: 94.224% (30212/32064)
Loss: 0.167 | Acc: 94.249% (36252/38464)
Loss: 0.165 | Acc: 94.332% (42321/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3374, Accuracy: 8940/10000 (89.40%)

Epoch: 81
Loss: 0.114 | Acc: 95.312% (61/64)
Loss: 0.151 | Acc: 94.725% (6123/6464)
Loss: 0.151 | Acc: 94.722% (12185/12864)
Loss: 0.151 | Acc: 94.825% (18267/19264)
Loss: 0.149 | Acc: 94.837% (24339/25664)
Loss: 0.149 | Acc: 94.826% (30405/32064)
Loss: 0.151 | Acc: 94.772% (36453/38464)
Loss: 0.152 | Acc: 94.764% (42515/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5061, Accuracy: 8542/10000 (85.42%)

Epoch: 82
Loss: 0.204 | Acc: 95.312% (61/64)
Loss: 0.153 | Acc: 94.694% (6121/6464)
Loss: 0.140 | Acc: 94.978% (12218/12864)
Loss: 0.135 | Acc: 95.250% (18349/19264)
Loss: 0.136 | Acc: 95.172% (24425/25664)
Loss: 0.138 | Acc: 95.132% (30503/32064)
Loss: 0.136 | Acc: 95.237% (36632/38464)
Loss: 0.136 | Acc: 95.308% (42759/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3281, Accuracy: 9035/10000 (90.35%)

Epoch: 83
Loss: 0.062 | Acc: 98.438% (63/64)
Loss: 0.109 | Acc: 96.303% (6225/6464)
Loss: 0.107 | Acc: 96.362% (12396/12864)
Loss: 0.111 | Acc: 96.159% (18524/19264)
Loss: 0.114 | Acc: 96.037% (24647/25664)
Loss: 0.116 | Acc: 95.980% (30775/32064)
Loss: 0.116 | Acc: 96.004% (36927/38464)
Loss: 0.119 | Acc: 95.952% (43048/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6450, Accuracy: 7070/10000 (70.70%)

Epoch: 84
Loss: 0.146 | Acc: 95.312% (61/64)
Loss: 0.115 | Acc: 96.318% (6226/6464)
Loss: 0.115 | Acc: 96.245% (12381/12864)
Loss: 0.117 | Acc: 96.127% (18518/19264)
Loss: 0.112 | Acc: 96.306% (24716/25664)
Loss: 0.112 | Acc: 96.286% (30873/32064)
Loss: 0.114 | Acc: 96.212% (37007/38464)
Loss: 0.111 | Acc: 96.318% (43212/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2632, Accuracy: 9203/10000 (92.03%)

Epoch: 85
Loss: 0.124 | Acc: 96.875% (62/64)
Loss: 0.095 | Acc: 96.751% (6254/6464)
Loss: 0.088 | Acc: 96.929% (12469/12864)
Loss: 0.088 | Acc: 96.989% (18684/19264)
Loss: 0.089 | Acc: 96.945% (24880/25664)
Loss: 0.088 | Acc: 96.972% (31093/32064)
Loss: 0.090 | Acc: 96.932% (37284/38464)
Loss: 0.092 | Acc: 96.848% (43450/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3432, Accuracy: 8992/10000 (89.92%)

Epoch: 86
Loss: 0.027 | Acc: 100.000% (64/64)
Loss: 0.081 | Acc: 97.184% (6282/6464)
Loss: 0.081 | Acc: 97.217% (12506/12864)
Loss: 0.082 | Acc: 97.207% (18726/19264)
Loss: 0.082 | Acc: 97.214% (24949/25664)
Loss: 0.080 | Acc: 97.337% (31210/32064)
Loss: 0.079 | Acc: 97.392% (37461/38464)
Loss: 0.078 | Acc: 97.356% (43678/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2527, Accuracy: 9220/10000 (92.20%)

Epoch: 87
Loss: 0.018 | Acc: 100.000% (64/64)
Loss: 0.056 | Acc: 98.113% (6342/6464)
Loss: 0.061 | Acc: 97.971% (12603/12864)
Loss: 0.059 | Acc: 98.105% (18899/19264)
Loss: 0.058 | Acc: 98.122% (25182/25664)
Loss: 0.058 | Acc: 98.107% (31457/32064)
Loss: 0.059 | Acc: 98.081% (37726/38464)
Loss: 0.059 | Acc: 98.047% (43988/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2394, Accuracy: 9280/10000 (92.80%)

Epoch: 88
Loss: 0.071 | Acc: 96.875% (62/64)
Loss: 0.058 | Acc: 98.113% (6342/6464)
Loss: 0.055 | Acc: 98.259% (12640/12864)
Loss: 0.054 | Acc: 98.292% (18935/19264)
Loss: 0.054 | Acc: 98.297% (25227/25664)
Loss: 0.054 | Acc: 98.269% (31509/32064)
Loss: 0.053 | Acc: 98.282% (37803/38464)
Loss: 0.052 | Acc: 98.331% (44115/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2168, Accuracy: 9362/10000 (93.62%)

Epoch: 89
Loss: 0.041 | Acc: 98.438% (63/64)
Loss: 0.034 | Acc: 98.933% (6395/6464)
Loss: 0.034 | Acc: 98.896% (12722/12864)
Loss: 0.036 | Acc: 98.832% (19039/19264)
Loss: 0.038 | Acc: 98.749% (25343/25664)
Loss: 0.038 | Acc: 98.749% (31663/32064)
Loss: 0.037 | Acc: 98.773% (37992/38464)
Loss: 0.037 | Acc: 98.792% (44322/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2218, Accuracy: 9371/10000 (93.71%)

Epoch: 90
Loss: 0.066 | Acc: 98.438% (63/64)
Loss: 0.029 | Acc: 99.165% (6410/6464)
Loss: 0.031 | Acc: 98.989% (12734/12864)
Loss: 0.031 | Acc: 99.029% (19077/19264)
Loss: 0.030 | Acc: 99.084% (25429/25664)
Loss: 0.030 | Acc: 99.083% (31770/32064)
Loss: 0.030 | Acc: 99.064% (38104/38464)
Loss: 0.031 | Acc: 99.050% (44438/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2077, Accuracy: 9415/10000 (94.15%)

Epoch: 91
Loss: 0.015 | Acc: 100.000% (64/64)
Loss: 0.024 | Acc: 99.211% (6413/6464)
Loss: 0.025 | Acc: 99.176% (12758/12864)
Loss: 0.025 | Acc: 99.185% (19107/19264)
Loss: 0.026 | Acc: 99.127% (25440/25664)
Loss: 0.025 | Acc: 99.161% (31795/32064)
Loss: 0.025 | Acc: 99.176% (38147/38464)
Loss: 0.025 | Acc: 99.211% (44510/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1993, Accuracy: 9431/10000 (94.31%)

Epoch: 92
Loss: 0.015 | Acc: 98.438% (63/64)
Loss: 0.019 | Acc: 99.397% (6425/6464)
Loss: 0.020 | Acc: 99.355% (12781/12864)
Loss: 0.020 | Acc: 99.434% (19155/19264)
Loss: 0.019 | Acc: 99.439% (25520/25664)
Loss: 0.019 | Acc: 99.429% (31881/32064)
Loss: 0.019 | Acc: 99.444% (38250/38464)
Loss: 0.018 | Acc: 99.454% (44619/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2063, Accuracy: 9434/10000 (94.34%)

Epoch: 93
Loss: 0.009 | Acc: 100.000% (64/64)
Loss: 0.012 | Acc: 99.691% (6444/6464)
Loss: 0.013 | Acc: 99.697% (12825/12864)
Loss: 0.014 | Acc: 99.673% (19201/19264)
Loss: 0.014 | Acc: 99.634% (25570/25664)
Loss: 0.014 | Acc: 99.648% (31951/32064)
Loss: 0.013 | Acc: 99.659% (38333/38464)
Loss: 0.013 | Acc: 99.672% (44717/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2063, Accuracy: 9441/10000 (94.41%)

Epoch: 94
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.013 | Acc: 99.613% (6439/6464)
Loss: 0.013 | Acc: 99.619% (12815/12864)
Loss: 0.012 | Acc: 99.678% (19202/19264)
Loss: 0.012 | Acc: 99.684% (25583/25664)
Loss: 0.012 | Acc: 99.676% (31960/32064)
Loss: 0.012 | Acc: 99.693% (38346/38464)
Loss: 0.012 | Acc: 99.701% (44730/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2011, Accuracy: 9461/10000 (94.61%)

Epoch: 95
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.814% (6452/6464)
Loss: 0.011 | Acc: 99.829% (12842/12864)
Loss: 0.014 | Acc: 99.782% (19222/19264)
Loss: 0.016 | Acc: 99.735% (25596/25664)
Loss: 0.018 | Acc: 99.691% (31965/32064)
Loss: 0.020 | Acc: 99.644% (38327/38464)
Loss: 0.022 | Acc: 99.603% (44686/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1969, Accuracy: 9371/10000 (93.71%)

Epoch: 96
Loss: 0.021 | Acc: 100.000% (64/64)
Loss: 0.047 | Acc: 99.149% (6409/6464)
Loss: 0.046 | Acc: 99.199% (12761/12864)
Loss: 0.046 | Acc: 99.232% (19116/19264)
Loss: 0.048 | Acc: 99.158% (25448/25664)
Loss: 0.049 | Acc: 99.136% (31787/32064)
Loss: 0.050 | Acc: 99.111% (38122/38464)
Loss: 0.052 | Acc: 99.084% (44453/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2035, Accuracy: 9342/10000 (93.42%)

Epoch: 97
Loss: 0.055 | Acc: 98.438% (63/64)
Loss: 0.064 | Acc: 98.530% (6369/6464)
Loss: 0.062 | Acc: 98.686% (12695/12864)
Loss: 0.063 | Acc: 98.692% (19012/19264)
Loss: 0.065 | Acc: 98.586% (25301/25664)
Loss: 0.066 | Acc: 98.568% (31605/32064)
Loss: 0.066 | Acc: 98.606% (37928/38464)
Loss: 0.067 | Acc: 98.602% (44237/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2078, Accuracy: 9334/10000 (93.34%)
torch.Size([100, 10])
Test set: Average loss: 0.2078, Accuracy: 9334/10000 (93.34%)

Epoch: 98
Loss: 0.055 | Acc: 98.438% (63/64)
Loss: 0.070 | Acc: 98.530% (6369/6464)
Loss: 0.072 | Acc: 98.500% (12671/12864)
Loss: 0.072 | Acc: 98.474% (18970/19264)
Loss: 0.071 | Acc: 98.500% (25279/25664)
Loss: 0.072 | Acc: 98.506% (31585/32064)
Loss: 0.072 | Acc: 98.482% (37880/38464)
Loss: 0.072 | Acc: 98.500% (44191/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2101, Accuracy: 9320/10000 (93.20%)
torch.Size([100, 10])
Test set: Average loss: 0.2101, Accuracy: 9320/10000 (93.20%)

Epoch: 99
Loss: 0.060 | Acc: 100.000% (64/64)
Loss: 0.074 | Acc: 98.438% (6363/6464)
Loss: 0.077 | Acc: 98.313% (12647/12864)
Loss: 0.075 | Acc: 98.412% (18958/19264)
Loss: 0.073 | Acc: 98.496% (25278/25664)
Loss: 0.073 | Acc: 98.515% (31588/32064)
Loss: 0.074 | Acc: 98.471% (37876/38464)
Loss: 0.074 | Acc: 98.462% (44174/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2109, Accuracy: 9314/10000 (93.14%)
torch.Size([100, 10])
Test set: Average loss: 0.2109, Accuracy: 9314/10000 (93.14%)

Epoch: 100
Loss: 0.121 | Acc: 96.875% (62/64)
Loss: 1.876 | Acc: 32.534% (2103/6464)
Loss: 1.459 | Acc: 47.979% (6172/12864)
Loss: 1.208 | Acc: 57.589% (11094/19264)
Loss: 1.056 | Acc: 63.147% (16206/25664)
Loss: 0.955 | Acc: 66.751% (21403/32064)
Loss: 0.883 | Acc: 69.340% (26671/38464)
Loss: 0.829 | Acc: 71.284% (31981/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9401, Accuracy: 3933/10000 (39.33%)

Epoch: 101
Loss: 0.733 | Acc: 78.125% (50/64)
Loss: 0.425 | Acc: 86.092% (5565/6464)
Loss: 0.444 | Acc: 85.075% (10944/12864)
Loss: 0.438 | Acc: 85.117% (16397/19264)
Loss: 0.430 | Acc: 85.419% (21922/25664)
Loss: 0.426 | Acc: 85.569% (27437/32064)
Loss: 0.423 | Acc: 85.568% (32913/38464)
Loss: 0.423 | Acc: 85.621% (38413/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9703, Accuracy: 7220/10000 (72.20%)

Epoch: 102
Loss: 0.291 | Acc: 93.750% (60/64)
Loss: 0.371 | Acc: 87.763% (5673/6464)
Loss: 0.383 | Acc: 87.158% (11212/12864)
Loss: 0.377 | Acc: 87.412% (16839/19264)
Loss: 0.377 | Acc: 87.336% (22414/25664)
Loss: 0.382 | Acc: 87.188% (27956/32064)
Loss: 0.377 | Acc: 87.315% (33585/38464)
Loss: 0.378 | Acc: 87.313% (39172/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3852, Accuracy: 5027/10000 (50.27%)

Epoch: 103
Loss: 0.732 | Acc: 73.438% (47/64)
Loss: 0.392 | Acc: 86.928% (5619/6464)
Loss: 0.371 | Acc: 87.360% (11238/12864)
Loss: 0.372 | Acc: 87.298% (16817/19264)
Loss: 0.368 | Acc: 87.543% (22467/25664)
Loss: 0.364 | Acc: 87.696% (28119/32064)
Loss: 0.365 | Acc: 87.679% (33725/38464)
Loss: 0.367 | Acc: 87.558% (39282/44864)
torch.Size([100, 10])
Test set: Average loss: 2.6862, Accuracy: 5303/10000 (53.03%)

Epoch: 104
Loss: 1.239 | Acc: 71.875% (46/64)
Loss: 0.364 | Acc: 87.639% (5665/6464)
Loss: 0.354 | Acc: 87.974% (11317/12864)
Loss: 0.349 | Acc: 88.133% (16978/19264)
Loss: 0.352 | Acc: 88.026% (22591/25664)
Loss: 0.351 | Acc: 88.093% (28246/32064)
Loss: 0.351 | Acc: 88.041% (33864/38464)
Loss: 0.354 | Acc: 87.930% (39449/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4502, Accuracy: 8463/10000 (84.63%)

Epoch: 105
Loss: 0.396 | Acc: 84.375% (54/64)
Loss: 0.346 | Acc: 88.212% (5702/6464)
Loss: 0.341 | Acc: 88.378% (11369/12864)
Loss: 0.348 | Acc: 88.133% (16978/19264)
Loss: 0.348 | Acc: 88.159% (22625/25664)
Loss: 0.348 | Acc: 88.214% (28285/32064)
Loss: 0.346 | Acc: 88.272% (33953/38464)
Loss: 0.347 | Acc: 88.218% (39578/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5674, Accuracy: 4555/10000 (45.55%)

Epoch: 106
Loss: 0.691 | Acc: 78.125% (50/64)
Loss: 0.368 | Acc: 87.763% (5673/6464)
Loss: 0.342 | Acc: 88.402% (11372/12864)
Loss: 0.337 | Acc: 88.476% (17044/19264)
Loss: 0.345 | Acc: 88.299% (22661/25664)
Loss: 0.345 | Acc: 88.233% (28291/32064)
Loss: 0.346 | Acc: 88.173% (33915/38464)
Loss: 0.348 | Acc: 88.113% (39531/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0702, Accuracy: 7113/10000 (71.13%)

Epoch: 107
Loss: 0.831 | Acc: 70.312% (45/64)
Loss: 0.327 | Acc: 88.753% (5737/6464)
Loss: 0.334 | Acc: 88.487% (11383/12864)
Loss: 0.334 | Acc: 88.549% (17058/19264)
Loss: 0.334 | Acc: 88.521% (22718/25664)
Loss: 0.336 | Acc: 88.454% (28362/32064)
Loss: 0.337 | Acc: 88.465% (34027/38464)
Loss: 0.333 | Acc: 88.619% (39758/44864)
torch.Size([100, 10])
Test set: Average loss: 3.7523, Accuracy: 3297/10000 (32.97%)

Epoch: 108
Loss: 1.209 | Acc: 62.500% (40/64)
Loss: 0.360 | Acc: 87.871% (5680/6464)
Loss: 0.340 | Acc: 88.402% (11372/12864)
Loss: 0.337 | Acc: 88.538% (17056/19264)
Loss: 0.341 | Acc: 88.400% (22687/25664)
Loss: 0.336 | Acc: 88.529% (28386/32064)
Loss: 0.338 | Acc: 88.498% (34040/38464)
Loss: 0.339 | Acc: 88.485% (39698/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4132, Accuracy: 5080/10000 (50.80%)

Epoch: 109
Loss: 0.795 | Acc: 76.562% (49/64)
Loss: 0.342 | Acc: 88.459% (5718/6464)
Loss: 0.332 | Acc: 88.837% (11428/12864)
Loss: 0.334 | Acc: 88.538% (17056/19264)
Loss: 0.330 | Acc: 88.685% (22760/25664)
Loss: 0.331 | Acc: 88.723% (28448/32064)
Loss: 0.330 | Acc: 88.816% (34162/38464)
Loss: 0.328 | Acc: 88.924% (39895/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4882, Accuracy: 5821/10000 (58.21%)

Epoch: 110
Loss: 0.880 | Acc: 68.750% (44/64)
Loss: 0.328 | Acc: 89.047% (5756/6464)
Loss: 0.315 | Acc: 89.451% (11507/12864)
Loss: 0.322 | Acc: 89.125% (17169/19264)
Loss: 0.321 | Acc: 89.035% (22850/25664)
Loss: 0.324 | Acc: 88.919% (28511/32064)
Loss: 0.326 | Acc: 88.891% (34191/38464)
Loss: 0.327 | Acc: 88.842% (39858/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4992, Accuracy: 8379/10000 (83.79%)

Epoch: 111
Loss: 0.332 | Acc: 87.500% (56/64)
Loss: 0.300 | Acc: 89.805% (5805/6464)
Loss: 0.315 | Acc: 89.109% (11463/12864)
Loss: 0.318 | Acc: 88.990% (17143/19264)
Loss: 0.315 | Acc: 89.078% (22861/25664)
Loss: 0.317 | Acc: 89.075% (28561/32064)
Loss: 0.318 | Acc: 89.039% (34248/38464)
Loss: 0.319 | Acc: 89.025% (39940/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0993, Accuracy: 6990/10000 (69.90%)

Epoch: 112
Loss: 0.667 | Acc: 78.125% (50/64)
Loss: 0.289 | Acc: 90.022% (5819/6464)
Loss: 0.290 | Acc: 90.058% (11585/12864)
Loss: 0.298 | Acc: 89.883% (17315/19264)
Loss: 0.300 | Acc: 89.799% (23046/25664)
Loss: 0.302 | Acc: 89.705% (28763/32064)
Loss: 0.305 | Acc: 89.595% (34462/38464)
Loss: 0.306 | Acc: 89.584% (40191/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7898, Accuracy: 7581/10000 (75.81%)

Epoch: 113
Loss: 0.426 | Acc: 87.500% (56/64)
Loss: 0.301 | Acc: 89.635% (5794/6464)
Loss: 0.303 | Acc: 89.708% (11540/12864)
Loss: 0.299 | Acc: 89.836% (17306/19264)
Loss: 0.300 | Acc: 89.877% (23066/25664)
Loss: 0.301 | Acc: 89.867% (28815/32064)
Loss: 0.302 | Acc: 89.868% (34567/38464)
Loss: 0.301 | Acc: 89.901% (40333/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2080, Accuracy: 6834/10000 (68.34%)

Epoch: 114
Loss: 0.261 | Acc: 92.188% (59/64)
Loss: 0.279 | Acc: 90.424% (5845/6464)
Loss: 0.288 | Acc: 90.073% (11587/12864)
Loss: 0.300 | Acc: 89.675% (17275/19264)
Loss: 0.301 | Acc: 89.721% (23026/25664)
Loss: 0.300 | Acc: 89.714% (28766/32064)
Loss: 0.301 | Acc: 89.689% (34498/38464)
Loss: 0.301 | Acc: 89.671% (40230/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0016, Accuracy: 7041/10000 (70.41%)

Epoch: 115
Loss: 0.504 | Acc: 85.938% (55/64)
Loss: 0.265 | Acc: 90.764% (5867/6464)
Loss: 0.272 | Acc: 90.695% (11667/12864)
Loss: 0.279 | Acc: 90.547% (17443/19264)
Loss: 0.282 | Acc: 90.372% (23193/25664)
Loss: 0.286 | Acc: 90.198% (28921/32064)
Loss: 0.290 | Acc: 90.105% (34658/38464)
Loss: 0.293 | Acc: 90.019% (40386/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8265, Accuracy: 7698/10000 (76.98%)

Epoch: 116
Loss: 0.272 | Acc: 89.062% (57/64)
Loss: 0.273 | Acc: 90.470% (5848/6464)
Loss: 0.279 | Acc: 90.361% (11624/12864)
Loss: 0.287 | Acc: 90.267% (17389/19264)
Loss: 0.282 | Acc: 90.454% (23214/25664)
Loss: 0.286 | Acc: 90.248% (28937/32064)
Loss: 0.287 | Acc: 90.147% (34674/38464)
Loss: 0.289 | Acc: 90.077% (40412/44864)
torch.Size([100, 10])
Test set: Average loss: 4.8977, Accuracy: 3165/10000 (31.65%)

Epoch: 117
Loss: 1.150 | Acc: 71.875% (46/64)
Loss: 0.291 | Acc: 90.006% (5818/6464)
Loss: 0.293 | Acc: 89.933% (11569/12864)
Loss: 0.283 | Acc: 90.241% (17384/19264)
Loss: 0.278 | Acc: 90.399% (23200/25664)
Loss: 0.280 | Acc: 90.335% (28965/32064)
Loss: 0.283 | Acc: 90.238% (34709/38464)
Loss: 0.283 | Acc: 90.288% (40507/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8048, Accuracy: 7544/10000 (75.44%)

Epoch: 118
Loss: 0.336 | Acc: 90.625% (58/64)
Loss: 0.273 | Acc: 90.377% (5842/6464)
Loss: 0.267 | Acc: 90.913% (11695/12864)
Loss: 0.265 | Acc: 90.916% (17514/19264)
Loss: 0.270 | Acc: 90.715% (23281/25664)
Loss: 0.270 | Acc: 90.725% (29090/32064)
Loss: 0.272 | Acc: 90.602% (34849/38464)
Loss: 0.272 | Acc: 90.629% (40660/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8204, Accuracy: 7785/10000 (77.85%)

Epoch: 119
Loss: 0.273 | Acc: 93.750% (60/64)
Loss: 0.256 | Acc: 91.368% (5906/6464)
Loss: 0.254 | Acc: 91.356% (11752/12864)
Loss: 0.260 | Acc: 91.186% (17566/19264)
Loss: 0.260 | Acc: 91.100% (23380/25664)
Loss: 0.259 | Acc: 91.202% (29243/32064)
Loss: 0.260 | Acc: 91.189% (35075/38464)
Loss: 0.262 | Acc: 91.100% (40871/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8499, Accuracy: 7352/10000 (73.52%)

Epoch: 120
Loss: 0.257 | Acc: 92.188% (59/64)
Loss: 0.265 | Acc: 91.089% (5888/6464)
Loss: 0.261 | Acc: 90.998% (11706/12864)
Loss: 0.256 | Acc: 91.212% (17571/19264)
Loss: 0.254 | Acc: 91.287% (23428/25664)
Loss: 0.250 | Acc: 91.445% (29321/32064)
Loss: 0.253 | Acc: 91.345% (35135/38464)
Loss: 0.254 | Acc: 91.305% (40963/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1713, Accuracy: 7300/10000 (73.00%)

Epoch: 121
Loss: 0.256 | Acc: 92.188% (59/64)
Loss: 0.236 | Acc: 92.095% (5953/6464)
Loss: 0.238 | Acc: 91.970% (11831/12864)
Loss: 0.245 | Acc: 91.684% (17662/19264)
Loss: 0.247 | Acc: 91.584% (23504/25664)
Loss: 0.247 | Acc: 91.664% (29391/32064)
Loss: 0.244 | Acc: 91.738% (35286/38464)
Loss: 0.244 | Acc: 91.791% (41181/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5522, Accuracy: 8286/10000 (82.86%)

Epoch: 122
Loss: 0.370 | Acc: 87.500% (56/64)
Loss: 0.216 | Acc: 92.652% (5989/6464)
Loss: 0.216 | Acc: 92.600% (11912/12864)
Loss: 0.223 | Acc: 92.343% (17789/19264)
Loss: 0.227 | Acc: 92.250% (23675/25664)
Loss: 0.231 | Acc: 92.209% (29566/32064)
Loss: 0.233 | Acc: 92.047% (35405/38464)
Loss: 0.236 | Acc: 91.967% (41260/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6130, Accuracy: 8166/10000 (81.66%)

Epoch: 123
Loss: 0.296 | Acc: 89.062% (57/64)
Loss: 0.210 | Acc: 92.713% (5993/6464)
Loss: 0.220 | Acc: 92.211% (11862/12864)
Loss: 0.228 | Acc: 91.886% (17701/19264)
Loss: 0.229 | Acc: 92.039% (23621/25664)
Loss: 0.232 | Acc: 91.963% (29487/32064)
Loss: 0.231 | Acc: 91.982% (35380/38464)
Loss: 0.230 | Acc: 92.072% (41307/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3993, Accuracy: 8730/10000 (87.30%)

Epoch: 124
Loss: 0.154 | Acc: 95.312% (61/64)
Loss: 0.200 | Acc: 92.915% (6006/6464)
Loss: 0.211 | Acc: 92.771% (11934/12864)
Loss: 0.208 | Acc: 92.930% (17902/19264)
Loss: 0.212 | Acc: 92.745% (23802/25664)
Loss: 0.216 | Acc: 92.596% (29690/32064)
Loss: 0.215 | Acc: 92.585% (35612/38464)
Loss: 0.216 | Acc: 92.520% (41508/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3849, Accuracy: 8755/10000 (87.55%)

Epoch: 125
Loss: 0.117 | Acc: 96.875% (62/64)
Loss: 0.196 | Acc: 93.224% (6026/6464)
Loss: 0.198 | Acc: 93.136% (11981/12864)
Loss: 0.203 | Acc: 92.904% (17897/19264)
Loss: 0.203 | Acc: 92.982% (23863/25664)
Loss: 0.204 | Acc: 92.927% (29796/32064)
Loss: 0.204 | Acc: 92.910% (35737/38464)
Loss: 0.206 | Acc: 92.805% (41636/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6371, Accuracy: 8051/10000 (80.51%)

Epoch: 126
Loss: 0.365 | Acc: 87.500% (56/64)
Loss: 0.188 | Acc: 93.502% (6044/6464)
Loss: 0.186 | Acc: 93.719% (12056/12864)
Loss: 0.194 | Acc: 93.480% (18008/19264)
Loss: 0.201 | Acc: 93.146% (23905/25664)
Loss: 0.199 | Acc: 93.270% (29906/32064)
Loss: 0.200 | Acc: 93.259% (35871/38464)
Loss: 0.199 | Acc: 93.269% (41844/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3369, Accuracy: 8926/10000 (89.26%)

Epoch: 127
Loss: 0.320 | Acc: 90.625% (58/64)
Loss: 0.189 | Acc: 93.673% (6055/6464)
Loss: 0.189 | Acc: 93.579% (12038/12864)
Loss: 0.188 | Acc: 93.558% (18023/19264)
Loss: 0.186 | Acc: 93.571% (24014/25664)
Loss: 0.186 | Acc: 93.547% (29995/32064)
Loss: 0.187 | Acc: 93.529% (35975/38464)
Loss: 0.186 | Acc: 93.547% (41969/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6114, Accuracy: 8310/10000 (83.10%)

Epoch: 128
Loss: 0.318 | Acc: 92.188% (59/64)
Loss: 0.161 | Acc: 94.168% (6087/6464)
Loss: 0.164 | Acc: 94.294% (12130/12864)
Loss: 0.168 | Acc: 94.150% (18137/19264)
Loss: 0.170 | Acc: 94.171% (24168/25664)
Loss: 0.173 | Acc: 94.062% (30160/32064)
Loss: 0.176 | Acc: 93.927% (36128/38464)
Loss: 0.177 | Acc: 93.893% (42124/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2993, Accuracy: 9016/10000 (90.16%)

Epoch: 129
Loss: 0.088 | Acc: 98.438% (63/64)
Loss: 0.165 | Acc: 94.291% (6095/6464)
Loss: 0.151 | Acc: 94.978% (12218/12864)
Loss: 0.153 | Acc: 94.840% (18270/19264)
Loss: 0.160 | Acc: 94.623% (24284/25664)
Loss: 0.160 | Acc: 94.623% (30340/32064)
Loss: 0.163 | Acc: 94.512% (36353/38464)
Loss: 0.161 | Acc: 94.544% (42416/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5205, Accuracy: 8413/10000 (84.13%)

Epoch: 130
Loss: 0.263 | Acc: 92.188% (59/64)
Loss: 0.162 | Acc: 94.462% (6106/6464)
Loss: 0.150 | Acc: 94.900% (12208/12864)
Loss: 0.151 | Acc: 94.825% (18267/19264)
Loss: 0.151 | Acc: 94.872% (24348/25664)
Loss: 0.147 | Acc: 94.954% (30446/32064)
Loss: 0.150 | Acc: 94.881% (36495/38464)
Loss: 0.152 | Acc: 94.813% (42537/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3171, Accuracy: 9013/10000 (90.13%)

Epoch: 131
Loss: 0.136 | Acc: 93.750% (60/64)
Loss: 0.126 | Acc: 95.637% (6182/6464)
Loss: 0.135 | Acc: 95.406% (12273/12864)
Loss: 0.135 | Acc: 95.271% (18353/19264)
Loss: 0.137 | Acc: 95.211% (24435/25664)
Loss: 0.139 | Acc: 95.166% (30514/32064)
Loss: 0.138 | Acc: 95.203% (36619/38464)
Loss: 0.140 | Acc: 95.107% (42669/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5031, Accuracy: 8597/10000 (85.97%)

Epoch: 132
Loss: 0.221 | Acc: 90.625% (58/64)
Loss: 0.124 | Acc: 95.730% (6188/6464)
Loss: 0.127 | Acc: 95.732% (12315/12864)
Loss: 0.131 | Acc: 95.593% (18415/19264)
Loss: 0.130 | Acc: 95.519% (24514/25664)
Loss: 0.130 | Acc: 95.506% (30623/32064)
Loss: 0.129 | Acc: 95.536% (36747/38464)
Loss: 0.128 | Acc: 95.558% (42871/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3171, Accuracy: 8996/10000 (89.96%)

Epoch: 133
Loss: 0.060 | Acc: 98.438% (63/64)
Loss: 0.106 | Acc: 96.349% (6228/6464)
Loss: 0.109 | Acc: 96.137% (12367/12864)
Loss: 0.108 | Acc: 96.252% (18542/19264)
Loss: 0.107 | Acc: 96.275% (24708/25664)
Loss: 0.109 | Acc: 96.214% (30850/32064)
Loss: 0.110 | Acc: 96.139% (36979/38464)
Loss: 0.111 | Acc: 96.135% (43130/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4753, Accuracy: 8601/10000 (86.01%)

Epoch: 134
Loss: 0.202 | Acc: 93.750% (60/64)
Loss: 0.104 | Acc: 96.380% (6230/6464)
Loss: 0.099 | Acc: 96.642% (12432/12864)
Loss: 0.097 | Acc: 96.667% (18622/19264)
Loss: 0.099 | Acc: 96.653% (24805/25664)
Loss: 0.099 | Acc: 96.641% (30987/32064)
Loss: 0.100 | Acc: 96.620% (37164/38464)
Loss: 0.099 | Acc: 96.637% (43355/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3126, Accuracy: 9018/10000 (90.18%)

Epoch: 135
Loss: 0.101 | Acc: 95.312% (61/64)
Loss: 0.082 | Acc: 97.370% (6294/6464)
Loss: 0.080 | Acc: 97.411% (12531/12864)
Loss: 0.080 | Acc: 97.347% (18753/19264)
Loss: 0.083 | Acc: 97.191% (24943/25664)
Loss: 0.083 | Acc: 97.171% (31157/32064)
Loss: 0.085 | Acc: 97.096% (37347/38464)
Loss: 0.084 | Acc: 97.127% (43575/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2401, Accuracy: 9269/10000 (92.69%)

Epoch: 136
Loss: 0.143 | Acc: 92.188% (59/64)
Loss: 0.077 | Acc: 97.355% (6293/6464)
Loss: 0.075 | Acc: 97.512% (12544/12864)
Loss: 0.070 | Acc: 97.633% (18808/19264)
Loss: 0.071 | Acc: 97.611% (25051/25664)
Loss: 0.070 | Acc: 97.680% (31320/32064)
Loss: 0.070 | Acc: 97.650% (37560/38464)
Loss: 0.068 | Acc: 97.695% (43830/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2290, Accuracy: 9325/10000 (93.25%)

Epoch: 137
Loss: 0.135 | Acc: 92.188% (59/64)
Loss: 0.067 | Acc: 97.788% (6321/6464)
Loss: 0.059 | Acc: 98.064% (12615/12864)
Loss: 0.058 | Acc: 98.095% (18897/19264)
Loss: 0.059 | Acc: 98.056% (25165/25664)
Loss: 0.058 | Acc: 98.079% (31448/32064)
Loss: 0.057 | Acc: 98.087% (37728/38464)
Loss: 0.057 | Acc: 98.081% (44003/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2468, Accuracy: 9279/10000 (92.79%)

Epoch: 138
Loss: 0.040 | Acc: 98.438% (63/64)
Loss: 0.054 | Acc: 98.453% (6364/6464)
Loss: 0.054 | Acc: 98.399% (12658/12864)
Loss: 0.052 | Acc: 98.438% (18963/19264)
Loss: 0.050 | Acc: 98.457% (25268/25664)
Loss: 0.051 | Acc: 98.441% (31564/32064)
Loss: 0.049 | Acc: 98.484% (37881/38464)
Loss: 0.048 | Acc: 98.489% (44186/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2674, Accuracy: 9247/10000 (92.47%)

Epoch: 139
Loss: 0.021 | Acc: 100.000% (64/64)
Loss: 0.038 | Acc: 98.886% (6392/6464)
Loss: 0.039 | Acc: 98.787% (12708/12864)
Loss: 0.036 | Acc: 98.842% (19041/19264)
Loss: 0.035 | Acc: 98.913% (25385/25664)
Loss: 0.036 | Acc: 98.868% (31701/32064)
Loss: 0.035 | Acc: 98.877% (38032/38464)
Loss: 0.035 | Acc: 98.874% (44359/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2069, Accuracy: 9394/10000 (93.94%)

Epoch: 140
Loss: 0.061 | Acc: 98.438% (63/64)
Loss: 0.026 | Acc: 99.257% (6416/6464)
Loss: 0.025 | Acc: 99.293% (12773/12864)
Loss: 0.025 | Acc: 99.320% (19133/19264)
Loss: 0.025 | Acc: 99.264% (25475/25664)
Loss: 0.025 | Acc: 99.267% (31829/32064)
Loss: 0.026 | Acc: 99.233% (38169/38464)
Loss: 0.027 | Acc: 99.193% (44502/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2049, Accuracy: 9417/10000 (94.17%)

Epoch: 141
Loss: 0.012 | Acc: 100.000% (64/64)
Loss: 0.020 | Acc: 99.536% (6434/6464)
Loss: 0.022 | Acc: 99.440% (12792/12864)
Loss: 0.020 | Acc: 99.465% (19161/19264)
Loss: 0.021 | Acc: 99.427% (25517/25664)
Loss: 0.020 | Acc: 99.429% (31881/32064)
Loss: 0.021 | Acc: 99.410% (38237/38464)
Loss: 0.020 | Acc: 99.418% (44603/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2016, Accuracy: 9443/10000 (94.43%)

Epoch: 142
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.012 | Acc: 99.752% (6448/6464)
Loss: 0.015 | Acc: 99.635% (12817/12864)
Loss: 0.016 | Acc: 99.590% (19185/19264)
Loss: 0.016 | Acc: 99.579% (25556/25664)
Loss: 0.016 | Acc: 99.585% (31931/32064)
Loss: 0.015 | Acc: 99.568% (38298/38464)
Loss: 0.015 | Acc: 99.579% (44675/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1982, Accuracy: 9462/10000 (94.62%)

Epoch: 143
Loss: 0.011 | Acc: 100.000% (64/64)
Loss: 0.013 | Acc: 99.706% (6445/6464)
Loss: 0.012 | Acc: 99.697% (12825/12864)
Loss: 0.011 | Acc: 99.725% (19211/19264)
Loss: 0.011 | Acc: 99.743% (25598/25664)
Loss: 0.011 | Acc: 99.744% (31982/32064)
Loss: 0.011 | Acc: 99.737% (38363/38464)
Loss: 0.011 | Acc: 99.737% (44746/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1921, Accuracy: 9465/10000 (94.65%)

Epoch: 144
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.830% (6453/6464)
Loss: 0.011 | Acc: 99.767% (12834/12864)
Loss: 0.010 | Acc: 99.772% (19220/19264)
Loss: 0.010 | Acc: 99.766% (25604/25664)
Loss: 0.010 | Acc: 99.757% (31986/32064)
Loss: 0.010 | Acc: 99.743% (38365/38464)
Loss: 0.010 | Acc: 99.757% (44755/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1895, Accuracy: 9479/10000 (94.79%)

Epoch: 145
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.783% (6450/6464)
Loss: 0.012 | Acc: 99.759% (12833/12864)
Loss: 0.013 | Acc: 99.740% (19214/19264)
Loss: 0.015 | Acc: 99.712% (25590/25664)
Loss: 0.016 | Acc: 99.669% (31958/32064)
Loss: 0.018 | Acc: 99.641% (38326/38464)
Loss: 0.020 | Acc: 99.617% (44692/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1907, Accuracy: 9401/10000 (94.01%)

Epoch: 146
Loss: 0.028 | Acc: 100.000% (64/64)
Loss: 0.035 | Acc: 99.397% (6425/6464)
Loss: 0.038 | Acc: 99.308% (12775/12864)
Loss: 0.038 | Acc: 99.284% (19126/19264)
Loss: 0.041 | Acc: 99.225% (25465/25664)
Loss: 0.043 | Acc: 99.174% (31799/32064)
Loss: 0.044 | Acc: 99.160% (38141/38464)
Loss: 0.047 | Acc: 99.095% (44458/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1952, Accuracy: 9377/10000 (93.77%)

Epoch: 147
Loss: 0.054 | Acc: 100.000% (64/64)
Loss: 0.054 | Acc: 99.056% (6403/6464)
Loss: 0.054 | Acc: 99.028% (12739/12864)
Loss: 0.056 | Acc: 98.972% (19066/19264)
Loss: 0.057 | Acc: 98.936% (25391/25664)
Loss: 0.058 | Acc: 98.890% (31708/32064)
Loss: 0.058 | Acc: 98.846% (38020/38464)
Loss: 0.059 | Acc: 98.799% (44325/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1976, Accuracy: 9375/10000 (93.75%)
torch.Size([100, 10])
Test set: Average loss: 0.1976, Accuracy: 9375/10000 (93.75%)

Epoch: 148
Loss: 0.046 | Acc: 100.000% (64/64)
Loss: 0.061 | Acc: 98.762% (6384/6464)
Loss: 0.062 | Acc: 98.857% (12717/12864)
Loss: 0.062 | Acc: 98.848% (19042/19264)
Loss: 0.062 | Acc: 98.823% (25362/25664)
Loss: 0.062 | Acc: 98.796% (31678/32064)
Loss: 0.062 | Acc: 98.807% (38005/38464)
Loss: 0.063 | Acc: 98.767% (44311/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1991, Accuracy: 9351/10000 (93.51%)
torch.Size([100, 10])
Test set: Average loss: 0.1991, Accuracy: 9351/10000 (93.51%)

Epoch: 149
Loss: 0.082 | Acc: 98.438% (63/64)
Loss: 0.064 | Acc: 98.963% (6397/6464)
Loss: 0.063 | Acc: 98.865% (12718/12864)
Loss: 0.067 | Acc: 98.728% (19019/19264)
Loss: 0.066 | Acc: 98.741% (25341/25664)
Loss: 0.066 | Acc: 98.721% (31654/32064)
Loss: 0.067 | Acc: 98.695% (37962/38464)
Loss: 0.066 | Acc: 98.723% (44291/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1997, Accuracy: 9355/10000 (93.55%)
torch.Size([100, 10])
Test set: Average loss: 0.1997, Accuracy: 9355/10000 (93.55%)

Epoch: 150
Loss: 0.051 | Acc: 100.000% (64/64)
Loss: 1.945 | Acc: 29.363% (1898/6464)
Loss: 1.644 | Acc: 40.213% (5173/12864)
Loss: 1.385 | Acc: 50.176% (9666/19264)
Loss: 1.207 | Acc: 56.932% (14611/25664)
Loss: 1.084 | Acc: 61.580% (19745/32064)
Loss: 0.993 | Acc: 64.983% (24995/38464)
Loss: 0.927 | Acc: 67.430% (30252/44864)
torch.Size([100, 10])
Test set: Average loss: 3.2282, Accuracy: 4233/10000 (42.33%)

Epoch: 151
Loss: 0.678 | Acc: 81.250% (52/64)
Loss: 0.479 | Acc: 84.158% (5440/6464)
Loss: 0.467 | Acc: 84.414% (10859/12864)
Loss: 0.462 | Acc: 84.650% (16307/19264)
Loss: 0.453 | Acc: 84.885% (21785/25664)
Loss: 0.442 | Acc: 85.214% (27323/32064)
Loss: 0.437 | Acc: 85.360% (32833/38464)
Loss: 0.433 | Acc: 85.429% (38327/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9412, Accuracy: 7080/10000 (70.80%)

Epoch: 152
Loss: 0.354 | Acc: 89.062% (57/64)
Loss: 0.371 | Acc: 86.928% (5619/6464)
Loss: 0.374 | Acc: 87.065% (11200/12864)
Loss: 0.377 | Acc: 87.059% (16771/19264)
Loss: 0.383 | Acc: 86.791% (22274/25664)
Loss: 0.384 | Acc: 86.907% (27866/32064)
Loss: 0.381 | Acc: 87.024% (33473/38464)
Loss: 0.381 | Acc: 86.985% (39025/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3170, Accuracy: 6445/10000 (64.45%)

Epoch: 153
Loss: 0.728 | Acc: 76.562% (49/64)
Loss: 0.370 | Acc: 87.624% (5664/6464)
Loss: 0.357 | Acc: 88.161% (11341/12864)
Loss: 0.351 | Acc: 88.175% (16986/19264)
Loss: 0.354 | Acc: 88.159% (22625/25664)
Loss: 0.354 | Acc: 88.174% (28272/32064)
Loss: 0.356 | Acc: 88.046% (33866/38464)
Loss: 0.356 | Acc: 87.997% (39479/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8899, Accuracy: 7352/10000 (73.52%)

Epoch: 154
Loss: 0.372 | Acc: 89.062% (57/64)
Loss: 0.362 | Acc: 87.546% (5659/6464)
Loss: 0.368 | Acc: 87.376% (11240/12864)
Loss: 0.362 | Acc: 87.692% (16893/19264)
Loss: 0.358 | Acc: 87.769% (22525/25664)
Loss: 0.355 | Acc: 87.902% (28185/32064)
Loss: 0.353 | Acc: 88.010% (33852/38464)
Loss: 0.354 | Acc: 87.970% (39467/44864)
torch.Size([100, 10])
Test set: Average loss: 4.9311, Accuracy: 3789/10000 (37.89%)

Epoch: 155
Loss: 1.118 | Acc: 75.000% (48/64)
Loss: 0.346 | Acc: 87.856% (5679/6464)
Loss: 0.351 | Acc: 87.935% (11312/12864)
Loss: 0.342 | Acc: 88.222% (16995/19264)
Loss: 0.345 | Acc: 88.256% (22650/25664)
Loss: 0.343 | Acc: 88.283% (28307/32064)
Loss: 0.343 | Acc: 88.267% (33951/38464)
Loss: 0.345 | Acc: 88.233% (39585/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8203, Accuracy: 7611/10000 (76.11%)

Epoch: 156
Loss: 0.286 | Acc: 89.062% (57/64)
Loss: 0.324 | Acc: 89.387% (5778/6464)
Loss: 0.331 | Acc: 89.047% (11455/12864)
Loss: 0.335 | Acc: 88.725% (17092/19264)
Loss: 0.334 | Acc: 88.774% (22783/25664)
Loss: 0.337 | Acc: 88.598% (28408/32064)
Loss: 0.337 | Acc: 88.522% (34049/38464)
Loss: 0.336 | Acc: 88.614% (39756/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6341, Accuracy: 8031/10000 (80.31%)

Epoch: 157
Loss: 0.183 | Acc: 95.312% (61/64)
Loss: 0.325 | Acc: 88.939% (5749/6464)
Loss: 0.325 | Acc: 88.891% (11435/12864)
Loss: 0.328 | Acc: 88.725% (17092/19264)
Loss: 0.332 | Acc: 88.618% (22743/25664)
Loss: 0.332 | Acc: 88.638% (28421/32064)
Loss: 0.332 | Acc: 88.660% (34102/38464)
Loss: 0.333 | Acc: 88.639% (39767/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2393, Accuracy: 5994/10000 (59.94%)

Epoch: 158
Loss: 0.571 | Acc: 79.688% (51/64)
Loss: 0.326 | Acc: 89.202% (5766/6464)
Loss: 0.323 | Acc: 89.109% (11463/12864)
Loss: 0.321 | Acc: 89.104% (17165/19264)
Loss: 0.321 | Acc: 89.055% (22855/25664)
Loss: 0.327 | Acc: 88.910% (28508/32064)
Loss: 0.329 | Acc: 88.883% (34188/38464)
Loss: 0.331 | Acc: 88.824% (39850/44864)
torch.Size([100, 10])
Test set: Average loss: 2.7377, Accuracy: 5172/10000 (51.72%)

Epoch: 159
Loss: 0.576 | Acc: 84.375% (54/64)
Loss: 0.313 | Acc: 88.877% (5745/6464)
Loss: 0.324 | Acc: 88.495% (11384/12864)
Loss: 0.322 | Acc: 88.710% (17089/19264)
Loss: 0.322 | Acc: 88.708% (22766/25664)
Loss: 0.323 | Acc: 88.748% (28456/32064)
Loss: 0.324 | Acc: 88.704% (34119/38464)
Loss: 0.326 | Acc: 88.657% (39775/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9735, Accuracy: 7071/10000 (70.71%)

Epoch: 160
Loss: 0.537 | Acc: 81.250% (52/64)
Loss: 0.298 | Acc: 90.099% (5824/6464)
Loss: 0.308 | Acc: 89.622% (11529/12864)
Loss: 0.313 | Acc: 89.421% (17226/19264)
Loss: 0.311 | Acc: 89.405% (22945/25664)
Loss: 0.308 | Acc: 89.590% (28726/32064)
Loss: 0.309 | Acc: 89.460% (34410/38464)
Loss: 0.313 | Acc: 89.323% (40074/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7033, Accuracy: 7828/10000 (78.28%)

Epoch: 161
Loss: 0.365 | Acc: 87.500% (56/64)
Loss: 0.295 | Acc: 89.666% (5796/6464)
Loss: 0.302 | Acc: 89.443% (11506/12864)
Loss: 0.308 | Acc: 89.234% (17190/19264)
Loss: 0.309 | Acc: 89.203% (22893/25664)
Loss: 0.311 | Acc: 89.140% (28582/32064)
Loss: 0.311 | Acc: 89.263% (34334/38464)
Loss: 0.314 | Acc: 89.201% (40019/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4620, Accuracy: 6539/10000 (65.39%)

Epoch: 162
Loss: 0.472 | Acc: 85.938% (55/64)
Loss: 0.309 | Acc: 89.496% (5785/6464)
Loss: 0.300 | Acc: 89.887% (11563/12864)
Loss: 0.308 | Acc: 89.405% (17223/19264)
Loss: 0.306 | Acc: 89.577% (22989/25664)
Loss: 0.306 | Acc: 89.571% (28720/32064)
Loss: 0.308 | Acc: 89.533% (34438/38464)
Loss: 0.311 | Acc: 89.401% (40109/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3735, Accuracy: 8722/10000 (87.22%)

Epoch: 163
Loss: 0.309 | Acc: 93.750% (60/64)
Loss: 0.288 | Acc: 90.269% (5835/6464)
Loss: 0.295 | Acc: 90.159% (11598/12864)
Loss: 0.298 | Acc: 90.002% (17338/19264)
Loss: 0.301 | Acc: 89.912% (23075/25664)
Loss: 0.306 | Acc: 89.730% (28771/32064)
Loss: 0.304 | Acc: 89.733% (34515/38464)
Loss: 0.305 | Acc: 89.673% (40231/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7257, Accuracy: 7866/10000 (78.66%)

Epoch: 164
Loss: 0.330 | Acc: 87.500% (56/64)
Loss: 0.274 | Acc: 91.089% (5888/6464)
Loss: 0.272 | Acc: 90.827% (11684/12864)
Loss: 0.283 | Acc: 90.428% (17420/19264)
Loss: 0.289 | Acc: 90.231% (23157/25664)
Loss: 0.295 | Acc: 89.983% (28852/32064)
Loss: 0.293 | Acc: 90.009% (34621/38464)
Loss: 0.296 | Acc: 89.921% (40342/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4443, Accuracy: 8552/10000 (85.52%)

Epoch: 165
Loss: 0.255 | Acc: 89.062% (57/64)
Loss: 0.287 | Acc: 89.991% (5817/6464)
Loss: 0.298 | Acc: 89.731% (11543/12864)
Loss: 0.296 | Acc: 89.841% (17307/19264)
Loss: 0.295 | Acc: 89.861% (23062/25664)
Loss: 0.291 | Acc: 89.989% (28854/32064)
Loss: 0.289 | Acc: 90.063% (34642/38464)
Loss: 0.288 | Acc: 90.072% (40410/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4368, Accuracy: 6366/10000 (63.66%)

Epoch: 166
Loss: 0.918 | Acc: 71.875% (46/64)
Loss: 0.286 | Acc: 90.842% (5872/6464)
Loss: 0.285 | Acc: 90.578% (11652/12864)
Loss: 0.289 | Acc: 90.365% (17408/19264)
Loss: 0.289 | Acc: 90.294% (23173/25664)
Loss: 0.289 | Acc: 90.282% (28948/32064)
Loss: 0.292 | Acc: 90.232% (34707/38464)
Loss: 0.289 | Acc: 90.293% (40509/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8326, Accuracy: 7559/10000 (75.59%)

Epoch: 167
Loss: 0.246 | Acc: 90.625% (58/64)
Loss: 0.277 | Acc: 90.486% (5849/6464)
Loss: 0.273 | Acc: 90.889% (11692/12864)
Loss: 0.272 | Acc: 90.843% (17500/19264)
Loss: 0.270 | Acc: 90.839% (23313/25664)
Loss: 0.274 | Acc: 90.768% (29104/32064)
Loss: 0.278 | Acc: 90.537% (34824/38464)
Loss: 0.278 | Acc: 90.587% (40641/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0794, Accuracy: 7078/10000 (70.78%)

Epoch: 168
Loss: 0.334 | Acc: 85.938% (55/64)
Loss: 0.272 | Acc: 90.764% (5867/6464)
Loss: 0.267 | Acc: 90.928% (11697/12864)
Loss: 0.268 | Acc: 90.890% (17509/19264)
Loss: 0.268 | Acc: 90.886% (23325/25664)
Loss: 0.269 | Acc: 90.903% (29147/32064)
Loss: 0.269 | Acc: 90.916% (34970/38464)
Loss: 0.268 | Acc: 90.968% (40812/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2526, Accuracy: 6966/10000 (69.66%)

Epoch: 169
Loss: 0.489 | Acc: 85.938% (55/64)
Loss: 0.272 | Acc: 90.548% (5853/6464)
Loss: 0.262 | Acc: 90.944% (11699/12864)
Loss: 0.264 | Acc: 90.812% (17494/19264)
Loss: 0.268 | Acc: 90.695% (23276/25664)
Loss: 0.267 | Acc: 90.709% (29085/32064)
Loss: 0.267 | Acc: 90.724% (34896/38464)
Loss: 0.268 | Acc: 90.714% (40698/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3069, Accuracy: 6651/10000 (66.51%)

Epoch: 170
Loss: 0.317 | Acc: 87.500% (56/64)
Loss: 0.251 | Acc: 91.429% (5910/6464)
Loss: 0.247 | Acc: 91.581% (11781/12864)
Loss: 0.251 | Acc: 91.398% (17607/19264)
Loss: 0.249 | Acc: 91.498% (23482/25664)
Loss: 0.252 | Acc: 91.374% (29298/32064)
Loss: 0.253 | Acc: 91.350% (35137/38464)
Loss: 0.256 | Acc: 91.283% (40953/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7045, Accuracy: 6530/10000 (65.30%)

Epoch: 171
Loss: 0.764 | Acc: 79.688% (51/64)
Loss: 0.254 | Acc: 91.058% (5886/6464)
Loss: 0.242 | Acc: 91.651% (11790/12864)
Loss: 0.245 | Acc: 91.674% (17660/19264)
Loss: 0.244 | Acc: 91.677% (23528/25664)
Loss: 0.246 | Acc: 91.611% (29374/32064)
Loss: 0.247 | Acc: 91.551% (35214/38464)
Loss: 0.247 | Acc: 91.577% (41085/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5860, Accuracy: 8252/10000 (82.52%)

Epoch: 172
Loss: 0.208 | Acc: 95.312% (61/64)
Loss: 0.245 | Acc: 91.925% (5942/6464)
Loss: 0.232 | Acc: 92.172% (11857/12864)
Loss: 0.230 | Acc: 92.307% (17782/19264)
Loss: 0.232 | Acc: 92.223% (23668/25664)
Loss: 0.232 | Acc: 92.237% (29575/32064)
Loss: 0.234 | Acc: 92.120% (35433/38464)
Loss: 0.235 | Acc: 92.043% (41294/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8007, Accuracy: 6222/10000 (62.22%)

Epoch: 173
Loss: 0.319 | Acc: 90.625% (58/64)
Loss: 0.245 | Acc: 91.646% (5924/6464)
Loss: 0.232 | Acc: 92.071% (11844/12864)
Loss: 0.233 | Acc: 92.032% (17729/19264)
Loss: 0.233 | Acc: 92.004% (23612/25664)
Loss: 0.230 | Acc: 92.088% (29527/32064)
Loss: 0.230 | Acc: 92.099% (35425/38464)
Loss: 0.231 | Acc: 92.056% (41300/44864)
torch.Size([100, 10])
Test set: Average loss: 4.8691, Accuracy: 3107/10000 (31.07%)

Epoch: 174
Loss: 0.619 | Acc: 82.812% (53/64)
Loss: 0.234 | Acc: 91.909% (5941/6464)
Loss: 0.227 | Acc: 92.250% (11867/12864)
Loss: 0.220 | Acc: 92.494% (17818/19264)
Loss: 0.220 | Acc: 92.433% (23722/25664)
Loss: 0.218 | Acc: 92.574% (29683/32064)
Loss: 0.213 | Acc: 92.715% (35662/38464)
Loss: 0.216 | Acc: 92.642% (41563/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3235, Accuracy: 8947/10000 (89.47%)

Epoch: 175
Loss: 0.122 | Acc: 95.312% (61/64)
Loss: 0.188 | Acc: 93.688% (6056/6464)
Loss: 0.187 | Acc: 93.672% (12050/12864)
Loss: 0.193 | Acc: 93.548% (18021/19264)
Loss: 0.200 | Acc: 93.329% (23952/25664)
Loss: 0.201 | Acc: 93.288% (29912/32064)
Loss: 0.202 | Acc: 93.277% (35878/38464)
Loss: 0.202 | Acc: 93.195% (41811/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6423, Accuracy: 8157/10000 (81.57%)

Epoch: 176
Loss: 0.102 | Acc: 96.875% (62/64)
Loss: 0.186 | Acc: 93.642% (6053/6464)
Loss: 0.203 | Acc: 92.918% (11953/12864)
Loss: 0.199 | Acc: 93.184% (17951/19264)
Loss: 0.200 | Acc: 93.154% (23907/25664)
Loss: 0.201 | Acc: 93.079% (29845/32064)
Loss: 0.197 | Acc: 93.199% (35848/38464)
Loss: 0.198 | Acc: 93.170% (41800/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6768, Accuracy: 8068/10000 (80.68%)

Epoch: 177
Loss: 0.269 | Acc: 87.500% (56/64)
Loss: 0.176 | Acc: 93.920% (6071/6464)
Loss: 0.184 | Acc: 93.734% (12058/12864)
Loss: 0.179 | Acc: 93.880% (18085/19264)
Loss: 0.181 | Acc: 93.805% (24074/25664)
Loss: 0.183 | Acc: 93.781% (30070/32064)
Loss: 0.187 | Acc: 93.662% (36026/38464)
Loss: 0.187 | Acc: 93.694% (42035/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9751, Accuracy: 7597/10000 (75.97%)

Epoch: 178
Loss: 0.091 | Acc: 96.875% (62/64)
Loss: 0.161 | Acc: 94.709% (6122/6464)
Loss: 0.152 | Acc: 94.908% (12209/12864)
Loss: 0.159 | Acc: 94.627% (18229/19264)
Loss: 0.165 | Acc: 94.393% (24225/25664)
Loss: 0.168 | Acc: 94.318% (30242/32064)
Loss: 0.170 | Acc: 94.231% (36245/38464)
Loss: 0.171 | Acc: 94.202% (42263/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6568, Accuracy: 8097/10000 (80.97%)

Epoch: 179
Loss: 0.143 | Acc: 95.312% (61/64)
Loss: 0.152 | Acc: 95.050% (6144/6464)
Loss: 0.160 | Acc: 94.667% (12178/12864)
Loss: 0.161 | Acc: 94.705% (18244/19264)
Loss: 0.161 | Acc: 94.592% (24276/25664)
Loss: 0.158 | Acc: 94.651% (30349/32064)
Loss: 0.159 | Acc: 94.572% (36376/38464)
Loss: 0.160 | Acc: 94.503% (42398/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3969, Accuracy: 8755/10000 (87.55%)

Epoch: 180
Loss: 0.216 | Acc: 93.750% (60/64)
Loss: 0.159 | Acc: 94.663% (6119/6464)
Loss: 0.149 | Acc: 94.916% (12210/12864)
Loss: 0.142 | Acc: 95.172% (18334/19264)
Loss: 0.144 | Acc: 95.083% (24402/25664)
Loss: 0.146 | Acc: 95.010% (30464/32064)
Loss: 0.150 | Acc: 94.891% (36499/38464)
Loss: 0.149 | Acc: 94.920% (42585/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8354, Accuracy: 7762/10000 (77.62%)

Epoch: 181
Loss: 0.164 | Acc: 95.312% (61/64)
Loss: 0.141 | Acc: 95.142% (6150/6464)
Loss: 0.144 | Acc: 95.025% (12224/12864)
Loss: 0.142 | Acc: 95.063% (18313/19264)
Loss: 0.143 | Acc: 95.071% (24399/25664)
Loss: 0.139 | Acc: 95.188% (30521/32064)
Loss: 0.142 | Acc: 95.120% (36587/38464)
Loss: 0.141 | Acc: 95.130% (42679/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3186, Accuracy: 8969/10000 (89.69%)

Epoch: 182
Loss: 0.082 | Acc: 98.438% (63/64)
Loss: 0.115 | Acc: 96.334% (6227/6464)
Loss: 0.113 | Acc: 96.152% (12369/12864)
Loss: 0.115 | Acc: 96.112% (18515/19264)
Loss: 0.119 | Acc: 95.920% (24617/25664)
Loss: 0.119 | Acc: 95.933% (30760/32064)
Loss: 0.121 | Acc: 95.856% (36870/38464)
Loss: 0.122 | Acc: 95.803% (42981/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2673, Accuracy: 9161/10000 (91.61%)

Epoch: 183
Loss: 0.097 | Acc: 95.312% (61/64)
Loss: 0.112 | Acc: 96.318% (6226/6464)
Loss: 0.104 | Acc: 96.549% (12420/12864)
Loss: 0.106 | Acc: 96.475% (18585/19264)
Loss: 0.107 | Acc: 96.442% (24751/25664)
Loss: 0.110 | Acc: 96.332% (30888/32064)
Loss: 0.110 | Acc: 96.329% (37052/38464)
Loss: 0.110 | Acc: 96.311% (43209/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2919, Accuracy: 9094/10000 (90.94%)

Epoch: 184
Loss: 0.174 | Acc: 93.750% (60/64)
Loss: 0.096 | Acc: 96.720% (6252/6464)
Loss: 0.095 | Acc: 96.774% (12449/12864)
Loss: 0.098 | Acc: 96.724% (18633/19264)
Loss: 0.097 | Acc: 96.766% (24834/25664)
Loss: 0.099 | Acc: 96.641% (30987/32064)
Loss: 0.097 | Acc: 96.690% (37191/38464)
Loss: 0.098 | Acc: 96.672% (43371/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3449, Accuracy: 8981/10000 (89.81%)

Epoch: 185
Loss: 0.085 | Acc: 96.875% (62/64)
Loss: 0.085 | Acc: 97.184% (6282/6464)
Loss: 0.080 | Acc: 97.326% (12520/12864)
Loss: 0.081 | Acc: 97.373% (18758/19264)
Loss: 0.082 | Acc: 97.397% (24996/25664)
Loss: 0.084 | Acc: 97.340% (31211/32064)
Loss: 0.082 | Acc: 97.356% (37447/38464)
Loss: 0.083 | Acc: 97.330% (43666/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6404, Accuracy: 8492/10000 (84.92%)

Epoch: 186
Loss: 0.053 | Acc: 98.438% (63/64)
Loss: 0.073 | Acc: 97.556% (6306/6464)
Loss: 0.070 | Acc: 97.769% (12577/12864)
Loss: 0.070 | Acc: 97.716% (18824/19264)
Loss: 0.068 | Acc: 97.767% (25091/25664)
Loss: 0.069 | Acc: 97.723% (31334/32064)
Loss: 0.071 | Acc: 97.650% (37560/38464)
Loss: 0.071 | Acc: 97.671% (43819/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2561, Accuracy: 9240/10000 (92.40%)

Epoch: 187
Loss: 0.048 | Acc: 98.438% (63/64)
Loss: 0.054 | Acc: 98.314% (6355/6464)
Loss: 0.055 | Acc: 98.305% (12646/12864)
Loss: 0.056 | Acc: 98.240% (18925/19264)
Loss: 0.055 | Acc: 98.262% (25218/25664)
Loss: 0.056 | Acc: 98.247% (31502/32064)
Loss: 0.056 | Acc: 98.196% (37770/38464)
Loss: 0.056 | Acc: 98.188% (44051/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2350, Accuracy: 9318/10000 (93.18%)

Epoch: 188
Loss: 0.097 | Acc: 93.750% (60/64)
Loss: 0.054 | Acc: 98.221% (6349/6464)
Loss: 0.054 | Acc: 98.173% (12629/12864)
Loss: 0.053 | Acc: 98.245% (18926/19264)
Loss: 0.052 | Acc: 98.239% (25212/25664)
Loss: 0.051 | Acc: 98.303% (31520/32064)
Loss: 0.050 | Acc: 98.323% (37819/38464)
Loss: 0.049 | Acc: 98.380% (44137/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2244, Accuracy: 9331/10000 (93.31%)

Epoch: 189
Loss: 0.016 | Acc: 100.000% (64/64)
Loss: 0.033 | Acc: 98.809% (6387/6464)
Loss: 0.031 | Acc: 98.927% (12726/12864)
Loss: 0.033 | Acc: 98.931% (19058/19264)
Loss: 0.033 | Acc: 98.905% (25383/25664)
Loss: 0.033 | Acc: 98.915% (31716/32064)
Loss: 0.034 | Acc: 98.879% (38033/38464)
Loss: 0.034 | Acc: 98.888% (44365/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2178, Accuracy: 9371/10000 (93.71%)

Epoch: 190
Loss: 0.014 | Acc: 100.000% (64/64)
Loss: 0.024 | Acc: 99.273% (6417/6464)
Loss: 0.024 | Acc: 99.269% (12770/12864)
Loss: 0.023 | Acc: 99.304% (19130/19264)
Loss: 0.024 | Acc: 99.291% (25482/25664)
Loss: 0.025 | Acc: 99.251% (31824/32064)
Loss: 0.025 | Acc: 99.215% (38162/38464)
Loss: 0.025 | Acc: 99.195% (44503/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2107, Accuracy: 9403/10000 (94.03%)

Epoch: 191
Loss: 0.010 | Acc: 100.000% (64/64)
Loss: 0.023 | Acc: 99.319% (6420/6464)
Loss: 0.021 | Acc: 99.355% (12781/12864)
Loss: 0.020 | Acc: 99.408% (19150/19264)
Loss: 0.020 | Acc: 99.423% (25516/25664)
Loss: 0.021 | Acc: 99.386% (31867/32064)
Loss: 0.021 | Acc: 99.397% (38232/38464)
Loss: 0.020 | Acc: 99.416% (44602/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2108, Accuracy: 9424/10000 (94.24%)

Epoch: 192
Loss: 0.027 | Acc: 98.438% (63/64)
Loss: 0.015 | Acc: 99.613% (6439/6464)
Loss: 0.014 | Acc: 99.635% (12817/12864)
Loss: 0.014 | Acc: 99.605% (19188/19264)
Loss: 0.015 | Acc: 99.564% (25552/25664)
Loss: 0.015 | Acc: 99.566% (31925/32064)
Loss: 0.015 | Acc: 99.587% (38305/38464)
Loss: 0.015 | Acc: 99.570% (44671/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1954, Accuracy: 9463/10000 (94.63%)

Epoch: 193
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.706% (6445/6464)
Loss: 0.011 | Acc: 99.697% (12825/12864)
Loss: 0.011 | Acc: 99.725% (19211/19264)
Loss: 0.011 | Acc: 99.719% (25592/25664)
Loss: 0.012 | Acc: 99.710% (31971/32064)
Loss: 0.011 | Acc: 99.719% (38356/38464)
Loss: 0.011 | Acc: 99.730% (44743/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1946, Accuracy: 9461/10000 (94.61%)

Epoch: 194
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.768% (6449/6464)
Loss: 0.010 | Acc: 99.790% (12837/12864)
Loss: 0.009 | Acc: 99.813% (19228/19264)
Loss: 0.010 | Acc: 99.782% (25608/25664)
Loss: 0.009 | Acc: 99.810% (32003/32064)
Loss: 0.009 | Acc: 99.800% (38387/38464)
Loss: 0.010 | Acc: 99.770% (44761/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1947, Accuracy: 9473/10000 (94.73%)

Epoch: 195
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.752% (6448/6464)
Loss: 0.011 | Acc: 99.720% (12828/12864)
Loss: 0.013 | Acc: 99.694% (19205/19264)
Loss: 0.014 | Acc: 99.677% (25581/25664)
Loss: 0.016 | Acc: 99.638% (31948/32064)
Loss: 0.018 | Acc: 99.620% (38318/38464)
Loss: 0.020 | Acc: 99.588% (44679/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1860, Accuracy: 9431/10000 (94.31%)

Epoch: 196
Loss: 0.018 | Acc: 100.000% (64/64)
Loss: 0.031 | Acc: 99.397% (6425/6464)
Loss: 0.036 | Acc: 99.300% (12774/12864)
Loss: 0.036 | Acc: 99.294% (19128/19264)
Loss: 0.038 | Acc: 99.271% (25477/25664)
Loss: 0.039 | Acc: 99.267% (31829/32064)
Loss: 0.040 | Acc: 99.225% (38166/38464)
Loss: 0.042 | Acc: 99.178% (44495/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1984, Accuracy: 9362/10000 (93.62%)

Epoch: 197
Loss: 0.054 | Acc: 98.438% (63/64)
Loss: 0.052 | Acc: 98.824% (6388/6464)
Loss: 0.054 | Acc: 98.888% (12721/12864)
Loss: 0.054 | Acc: 98.868% (19046/19264)
Loss: 0.055 | Acc: 98.858% (25371/25664)
Loss: 0.056 | Acc: 98.834% (31690/32064)
Loss: 0.057 | Acc: 98.825% (38012/38464)
Loss: 0.057 | Acc: 98.808% (44329/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2015, Accuracy: 9342/10000 (93.42%)
torch.Size([100, 10])
Test set: Average loss: 0.2015, Accuracy: 9342/10000 (93.42%)

Epoch: 198
Loss: 0.045 | Acc: 100.000% (64/64)
Loss: 0.058 | Acc: 98.871% (6391/6464)
Loss: 0.057 | Acc: 98.982% (12733/12864)
Loss: 0.060 | Acc: 98.884% (19049/19264)
Loss: 0.061 | Acc: 98.839% (25366/25664)
Loss: 0.061 | Acc: 98.824% (31687/32064)
Loss: 0.062 | Acc: 98.755% (37985/38464)
Loss: 0.062 | Acc: 98.752% (44304/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2050, Accuracy: 9336/10000 (93.36%)
torch.Size([100, 10])
Test set: Average loss: 0.2050, Accuracy: 9336/10000 (93.36%)

Epoch: 199
Loss: 0.053 | Acc: 100.000% (64/64)
Loss: 0.060 | Acc: 98.762% (6384/6464)
Loss: 0.061 | Acc: 98.795% (12709/12864)
Loss: 0.061 | Acc: 98.827% (19038/19264)
Loss: 0.062 | Acc: 98.815% (25360/25664)
Loss: 0.062 | Acc: 98.787% (31675/32064)
Loss: 0.061 | Acc: 98.817% (38009/38464)
Loss: 0.062 | Acc: 98.790% (44321/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2052, Accuracy: 9329/10000 (93.29%)
torch.Size([100, 10])
Test set: Average loss: 0.2052, Accuracy: 9329/10000 (93.29%)
9495
10000
-0.1645897626876831
