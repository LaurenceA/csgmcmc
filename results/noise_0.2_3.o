==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.403 | Acc: 12.500% (8/64)
Loss: 2.913 | Acc: 14.233% (920/6464)
Loss: 2.540 | Acc: 16.674% (2145/12864)
Loss: 2.405 | Acc: 17.961% (3460/19264)
Loss: 2.319 | Acc: 19.518% (5009/25664)
Loss: 2.262 | Acc: 20.730% (6647/32064)
Loss: 2.221 | Acc: 21.815% (8391/38464)
Loss: 2.182 | Acc: 23.052% (10342/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2725, Accuracy: 2433/10000 (24.33%)

Epoch: 1
Loss: 2.260 | Acc: 17.188% (11/64)
Loss: 1.912 | Acc: 32.843% (2123/6464)
Loss: 1.914 | Acc: 32.797% (4219/12864)
Loss: 1.906 | Acc: 33.233% (6402/19264)
Loss: 1.899 | Acc: 33.716% (8653/25664)
Loss: 1.892 | Acc: 34.129% (10943/32064)
Loss: 1.882 | Acc: 34.534% (13283/38464)
Loss: 1.875 | Acc: 34.986% (15696/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9308, Accuracy: 3522/10000 (35.22%)

Epoch: 2
Loss: 1.598 | Acc: 45.312% (29/64)
Loss: 1.804 | Acc: 38.722% (2503/6464)
Loss: 1.796 | Acc: 38.938% (5009/12864)
Loss: 1.785 | Acc: 39.597% (7628/19264)
Loss: 1.779 | Acc: 39.947% (10252/25664)
Loss: 1.769 | Acc: 40.466% (12975/32064)
Loss: 1.766 | Acc: 40.867% (15719/38464)
Loss: 1.762 | Acc: 40.975% (18383/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8040, Accuracy: 4019/10000 (40.19%)

Epoch: 3
Loss: 2.131 | Acc: 28.125% (18/64)
Loss: 1.700 | Acc: 43.998% (2844/6464)
Loss: 1.716 | Acc: 43.633% (5613/12864)
Loss: 1.697 | Acc: 44.544% (8581/19264)
Loss: 1.691 | Acc: 45.090% (11572/25664)
Loss: 1.685 | Acc: 45.372% (14548/32064)
Loss: 1.675 | Acc: 45.713% (17583/38464)
Loss: 1.665 | Acc: 46.131% (20696/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2326, Accuracy: 2968/10000 (29.68%)

Epoch: 4
Loss: 1.829 | Acc: 43.750% (28/64)
Loss: 1.592 | Acc: 50.263% (3249/6464)
Loss: 1.586 | Acc: 50.342% (6476/12864)
Loss: 1.580 | Acc: 50.613% (9750/19264)
Loss: 1.572 | Acc: 50.783% (13033/25664)
Loss: 1.567 | Acc: 51.045% (16367/32064)
Loss: 1.561 | Acc: 51.245% (19711/38464)
Loss: 1.556 | Acc: 51.366% (23045/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6721, Accuracy: 4905/10000 (49.05%)

Epoch: 5
Loss: 1.809 | Acc: 46.875% (30/64)
Loss: 1.496 | Acc: 54.115% (3498/6464)
Loss: 1.510 | Acc: 53.599% (6895/12864)
Loss: 1.499 | Acc: 54.044% (10411/19264)
Loss: 1.496 | Acc: 54.185% (13906/25664)
Loss: 1.487 | Acc: 54.644% (17521/32064)
Loss: 1.486 | Acc: 54.701% (21040/38464)
Loss: 1.482 | Acc: 54.951% (24653/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0420, Accuracy: 3948/10000 (39.48%)

Epoch: 6
Loss: 1.414 | Acc: 62.500% (40/64)
Loss: 1.442 | Acc: 56.467% (3650/6464)
Loss: 1.441 | Acc: 56.475% (7265/12864)
Loss: 1.439 | Acc: 56.878% (10957/19264)
Loss: 1.429 | Acc: 57.318% (14710/25664)
Loss: 1.423 | Acc: 57.454% (18422/32064)
Loss: 1.422 | Acc: 57.597% (22154/38464)
Loss: 1.420 | Acc: 57.862% (25959/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7296, Accuracy: 4635/10000 (46.35%)

Epoch: 7
Loss: 1.519 | Acc: 48.438% (31/64)
Loss: 1.402 | Acc: 58.926% (3809/6464)
Loss: 1.385 | Acc: 59.523% (7657/12864)
Loss: 1.382 | Acc: 59.821% (11524/19264)
Loss: 1.375 | Acc: 60.006% (15400/25664)
Loss: 1.370 | Acc: 60.336% (19346/32064)
Loss: 1.370 | Acc: 60.402% (23233/38464)
Loss: 1.362 | Acc: 60.612% (27193/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5194, Accuracy: 5488/10000 (54.88%)

Epoch: 8
Loss: 1.301 | Acc: 62.500% (40/64)
Loss: 1.350 | Acc: 60.767% (3928/6464)
Loss: 1.339 | Acc: 61.396% (7898/12864)
Loss: 1.331 | Acc: 61.862% (11917/19264)
Loss: 1.331 | Acc: 61.892% (15884/25664)
Loss: 1.324 | Acc: 62.110% (19915/32064)
Loss: 1.323 | Acc: 62.165% (23911/38464)
Loss: 1.320 | Acc: 62.317% (27958/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5487, Accuracy: 5571/10000 (55.71%)

Epoch: 9
Loss: 1.383 | Acc: 57.812% (37/64)
Loss: 1.273 | Acc: 64.078% (4142/6464)
Loss: 1.288 | Acc: 63.845% (8213/12864)
Loss: 1.300 | Acc: 63.419% (12217/19264)
Loss: 1.297 | Acc: 63.365% (16262/25664)
Loss: 1.298 | Acc: 63.364% (20317/32064)
Loss: 1.296 | Acc: 63.441% (24402/38464)
Loss: 1.291 | Acc: 63.603% (28535/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4831, Accuracy: 5525/10000 (55.25%)

Epoch: 10
Loss: 1.162 | Acc: 70.312% (45/64)
Loss: 1.272 | Acc: 64.836% (4191/6464)
Loss: 1.269 | Acc: 64.614% (8312/12864)
Loss: 1.268 | Acc: 64.571% (12439/19264)
Loss: 1.262 | Acc: 64.830% (16638/25664)
Loss: 1.266 | Acc: 64.848% (20793/32064)
Loss: 1.269 | Acc: 64.788% (24920/38464)
Loss: 1.268 | Acc: 64.800% (29072/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5661, Accuracy: 5371/10000 (53.71%)

Epoch: 11
Loss: 1.331 | Acc: 56.250% (36/64)
Loss: 1.246 | Acc: 65.084% (4207/6464)
Loss: 1.253 | Acc: 65.112% (8376/12864)
Loss: 1.250 | Acc: 65.350% (12589/19264)
Loss: 1.258 | Acc: 65.115% (16711/25664)
Loss: 1.256 | Acc: 65.163% (20894/32064)
Loss: 1.251 | Acc: 65.321% (25125/38464)
Loss: 1.251 | Acc: 65.360% (29323/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4020, Accuracy: 6013/10000 (60.13%)

Epoch: 12
Loss: 1.419 | Acc: 57.812% (37/64)
Loss: 1.232 | Acc: 66.337% (4288/6464)
Loss: 1.234 | Acc: 66.496% (8554/12864)
Loss: 1.233 | Acc: 66.414% (12794/19264)
Loss: 1.235 | Acc: 66.338% (17025/25664)
Loss: 1.237 | Acc: 66.367% (21280/32064)
Loss: 1.235 | Acc: 66.387% (25535/38464)
Loss: 1.237 | Acc: 66.256% (29725/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6370, Accuracy: 5016/10000 (50.16%)

Epoch: 13
Loss: 1.424 | Acc: 57.812% (37/64)
Loss: 1.215 | Acc: 67.342% (4353/6464)
Loss: 1.218 | Acc: 66.915% (8608/12864)
Loss: 1.213 | Acc: 67.130% (12932/19264)
Loss: 1.220 | Acc: 66.993% (17193/25664)
Loss: 1.218 | Acc: 67.122% (21522/32064)
Loss: 1.219 | Acc: 67.060% (25794/38464)
Loss: 1.220 | Acc: 66.947% (30035/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3972, Accuracy: 6138/10000 (61.38%)

Epoch: 14
Loss: 1.260 | Acc: 65.625% (42/64)
Loss: 1.230 | Acc: 66.306% (4286/6464)
Loss: 1.214 | Acc: 66.822% (8596/12864)
Loss: 1.214 | Acc: 66.944% (12896/19264)
Loss: 1.213 | Acc: 67.078% (17215/25664)
Loss: 1.211 | Acc: 67.094% (21513/32064)
Loss: 1.209 | Acc: 67.224% (25857/38464)
Loss: 1.211 | Acc: 67.161% (30131/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5553, Accuracy: 5441/10000 (54.41%)

Epoch: 15
Loss: 1.458 | Acc: 60.938% (39/64)
Loss: 1.194 | Acc: 67.837% (4385/6464)
Loss: 1.195 | Acc: 67.903% (8735/12864)
Loss: 1.200 | Acc: 67.759% (13053/19264)
Loss: 1.198 | Acc: 67.788% (17397/25664)
Loss: 1.192 | Acc: 67.995% (21802/32064)
Loss: 1.196 | Acc: 67.785% (26073/38464)
Loss: 1.196 | Acc: 67.754% (30397/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4678, Accuracy: 5678/10000 (56.78%)

Epoch: 16
Loss: 1.429 | Acc: 64.062% (41/64)
Loss: 1.169 | Acc: 68.595% (4434/6464)
Loss: 1.169 | Acc: 68.556% (8819/12864)
Loss: 1.175 | Acc: 68.439% (13184/19264)
Loss: 1.185 | Acc: 68.091% (17475/25664)
Loss: 1.183 | Acc: 68.214% (21872/32064)
Loss: 1.187 | Acc: 68.240% (26248/38464)
Loss: 1.179 | Acc: 68.405% (30689/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7383, Accuracy: 5052/10000 (50.52%)

Epoch: 17
Loss: 1.224 | Acc: 65.625% (42/64)
Loss: 1.163 | Acc: 69.276% (4478/6464)
Loss: 1.177 | Acc: 68.517% (8814/12864)
Loss: 1.177 | Acc: 68.625% (13220/19264)
Loss: 1.172 | Acc: 68.844% (17668/25664)
Loss: 1.171 | Acc: 68.912% (22096/32064)
Loss: 1.171 | Acc: 68.870% (26490/38464)
Loss: 1.170 | Acc: 68.830% (30880/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5263, Accuracy: 5658/10000 (56.58%)

Epoch: 18
Loss: 1.160 | Acc: 71.875% (46/64)
Loss: 1.126 | Acc: 70.096% (4531/6464)
Loss: 1.133 | Acc: 70.095% (9017/12864)
Loss: 1.147 | Acc: 69.757% (13438/19264)
Loss: 1.153 | Acc: 69.662% (17878/25664)
Loss: 1.153 | Acc: 69.729% (22358/32064)
Loss: 1.158 | Acc: 69.496% (26731/38464)
Loss: 1.158 | Acc: 69.472% (31168/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3490, Accuracy: 6256/10000 (62.56%)

Epoch: 19
Loss: 1.613 | Acc: 57.812% (37/64)
Loss: 1.138 | Acc: 69.756% (4509/6464)
Loss: 1.143 | Acc: 69.737% (8971/12864)
Loss: 1.134 | Acc: 70.084% (13501/19264)
Loss: 1.130 | Acc: 70.258% (18031/25664)
Loss: 1.138 | Acc: 69.979% (22438/32064)
Loss: 1.141 | Acc: 69.985% (26919/38464)
Loss: 1.143 | Acc: 69.896% (31358/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3281, Accuracy: 6350/10000 (63.50%)

Epoch: 20
Loss: 1.100 | Acc: 73.438% (47/64)
Loss: 1.111 | Acc: 71.364% (4613/6464)
Loss: 1.121 | Acc: 70.896% (9120/12864)
Loss: 1.124 | Acc: 70.785% (13636/19264)
Loss: 1.125 | Acc: 70.694% (18143/25664)
Loss: 1.131 | Acc: 70.518% (22611/32064)
Loss: 1.134 | Acc: 70.463% (27103/38464)
Loss: 1.134 | Acc: 70.433% (31599/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4480, Accuracy: 5915/10000 (59.15%)

Epoch: 21
Loss: 1.044 | Acc: 73.438% (47/64)
Loss: 1.109 | Acc: 70.730% (4572/6464)
Loss: 1.114 | Acc: 70.888% (9119/12864)
Loss: 1.112 | Acc: 70.987% (13675/19264)
Loss: 1.121 | Acc: 70.698% (18144/25664)
Loss: 1.120 | Acc: 70.699% (22669/32064)
Loss: 1.123 | Acc: 70.583% (27149/38464)
Loss: 1.122 | Acc: 70.671% (31706/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4581, Accuracy: 5890/10000 (58.90%)

Epoch: 22
Loss: 0.929 | Acc: 79.688% (51/64)
Loss: 1.108 | Acc: 71.782% (4640/6464)
Loss: 1.120 | Acc: 70.981% (9131/12864)
Loss: 1.115 | Acc: 71.195% (13715/19264)
Loss: 1.117 | Acc: 71.065% (18238/25664)
Loss: 1.110 | Acc: 71.114% (22802/32064)
Loss: 1.111 | Acc: 71.061% (27333/38464)
Loss: 1.109 | Acc: 71.142% (31917/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4915, Accuracy: 5674/10000 (56.74%)

Epoch: 23
Loss: 1.018 | Acc: 71.875% (46/64)
Loss: 1.072 | Acc: 72.571% (4691/6464)
Loss: 1.089 | Acc: 71.828% (9240/12864)
Loss: 1.100 | Acc: 71.512% (13776/19264)
Loss: 1.101 | Acc: 71.544% (18361/25664)
Loss: 1.103 | Acc: 71.398% (22893/32064)
Loss: 1.099 | Acc: 71.524% (27511/38464)
Loss: 1.099 | Acc: 71.543% (32097/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3357, Accuracy: 6210/10000 (62.10%)

Epoch: 24
Loss: 1.204 | Acc: 70.312% (45/64)
Loss: 1.090 | Acc: 72.153% (4664/6464)
Loss: 1.101 | Acc: 71.766% (9232/12864)
Loss: 1.092 | Acc: 71.994% (13869/19264)
Loss: 1.098 | Acc: 71.824% (18433/25664)
Loss: 1.093 | Acc: 71.925% (23062/32064)
Loss: 1.091 | Acc: 71.992% (27691/38464)
Loss: 1.091 | Acc: 71.931% (32271/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3277, Accuracy: 6456/10000 (64.56%)

Epoch: 25
Loss: 1.139 | Acc: 71.875% (46/64)
Loss: 1.067 | Acc: 73.051% (4722/6464)
Loss: 1.074 | Acc: 72.481% (9324/12864)
Loss: 1.074 | Acc: 72.472% (13961/19264)
Loss: 1.071 | Acc: 72.592% (18630/25664)
Loss: 1.076 | Acc: 72.468% (23236/32064)
Loss: 1.080 | Acc: 72.343% (27826/38464)
Loss: 1.079 | Acc: 72.325% (32448/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3845, Accuracy: 6133/10000 (61.33%)

Epoch: 26
Loss: 0.993 | Acc: 75.000% (48/64)
Loss: 1.080 | Acc: 72.772% (4704/6464)
Loss: 1.078 | Acc: 72.590% (9338/12864)
Loss: 1.069 | Acc: 72.711% (14007/19264)
Loss: 1.075 | Acc: 72.522% (18612/25664)
Loss: 1.078 | Acc: 72.486% (23242/32064)
Loss: 1.070 | Acc: 72.702% (27964/38464)
Loss: 1.067 | Acc: 72.856% (32686/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3828, Accuracy: 6166/10000 (61.66%)

Epoch: 27
Loss: 1.295 | Acc: 62.500% (40/64)
Loss: 1.085 | Acc: 72.293% (4673/6464)
Loss: 1.050 | Acc: 73.430% (9446/12864)
Loss: 1.053 | Acc: 73.251% (14111/19264)
Loss: 1.053 | Acc: 73.192% (18784/25664)
Loss: 1.051 | Acc: 73.307% (23505/32064)
Loss: 1.048 | Acc: 73.422% (28241/38464)
Loss: 1.051 | Acc: 73.335% (32901/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4536, Accuracy: 6016/10000 (60.16%)

Epoch: 28
Loss: 1.192 | Acc: 67.188% (43/64)
Loss: 1.051 | Acc: 73.190% (4731/6464)
Loss: 1.052 | Acc: 73.453% (9449/12864)
Loss: 1.036 | Acc: 73.837% (14224/19264)
Loss: 1.040 | Acc: 73.644% (18900/25664)
Loss: 1.036 | Acc: 73.721% (23638/32064)
Loss: 1.041 | Acc: 73.534% (28284/38464)
Loss: 1.042 | Acc: 73.589% (33015/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4326, Accuracy: 5865/10000 (58.65%)

Epoch: 29
Loss: 0.942 | Acc: 78.125% (50/64)
Loss: 1.013 | Acc: 74.907% (4842/6464)
Loss: 1.019 | Acc: 74.728% (9613/12864)
Loss: 1.009 | Acc: 74.984% (14445/19264)
Loss: 1.016 | Acc: 74.751% (19184/25664)
Loss: 1.018 | Acc: 74.750% (23968/32064)
Loss: 1.022 | Acc: 74.576% (28685/38464)
Loss: 1.018 | Acc: 74.617% (33476/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2456, Accuracy: 6707/10000 (67.07%)

Epoch: 30
Loss: 1.411 | Acc: 62.500% (40/64)
Loss: 0.989 | Acc: 75.418% (4875/6464)
Loss: 1.003 | Acc: 75.039% (9653/12864)
Loss: 1.000 | Acc: 75.078% (14463/19264)
Loss: 1.000 | Acc: 75.012% (19251/25664)
Loss: 1.007 | Acc: 74.860% (24003/32064)
Loss: 1.012 | Acc: 74.750% (28752/38464)
Loss: 1.011 | Acc: 74.808% (33562/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2368, Accuracy: 6804/10000 (68.04%)

Epoch: 31
Loss: 0.692 | Acc: 82.812% (53/64)
Loss: 0.977 | Acc: 75.526% (4882/6464)
Loss: 0.993 | Acc: 75.171% (9670/12864)
Loss: 0.991 | Acc: 75.270% (14500/19264)
Loss: 0.991 | Acc: 75.277% (19319/25664)
Loss: 0.996 | Acc: 75.131% (24090/32064)
Loss: 0.992 | Acc: 75.247% (28943/38464)
Loss: 0.997 | Acc: 75.174% (33726/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1849, Accuracy: 7027/10000 (70.27%)

Epoch: 32
Loss: 0.891 | Acc: 76.562% (49/64)
Loss: 0.976 | Acc: 76.052% (4916/6464)
Loss: 0.979 | Acc: 75.746% (9744/12864)
Loss: 0.985 | Acc: 75.514% (14547/19264)
Loss: 0.981 | Acc: 75.670% (19420/25664)
Loss: 0.978 | Acc: 75.742% (24286/32064)
Loss: 0.981 | Acc: 75.684% (29111/38464)
Loss: 0.980 | Acc: 75.749% (33984/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2958, Accuracy: 6644/10000 (66.44%)

Epoch: 33
Loss: 1.033 | Acc: 75.000% (48/64)
Loss: 0.925 | Acc: 77.305% (4997/6464)
Loss: 0.943 | Acc: 76.695% (9866/12864)
Loss: 0.938 | Acc: 76.739% (14783/19264)
Loss: 0.947 | Acc: 76.566% (19650/25664)
Loss: 0.949 | Acc: 76.572% (24552/32064)
Loss: 0.954 | Acc: 76.438% (29401/38464)
Loss: 0.957 | Acc: 76.366% (34261/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2464, Accuracy: 6772/10000 (67.72%)

Epoch: 34
Loss: 1.072 | Acc: 73.438% (47/64)
Loss: 0.922 | Acc: 77.429% (5005/6464)
Loss: 0.920 | Acc: 77.534% (9974/12864)
Loss: 0.925 | Acc: 77.191% (14870/19264)
Loss: 0.930 | Acc: 77.077% (19781/25664)
Loss: 0.934 | Acc: 77.024% (24697/32064)
Loss: 0.938 | Acc: 76.833% (29553/38464)
Loss: 0.942 | Acc: 76.788% (34450/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2541, Accuracy: 6781/10000 (67.81%)

Epoch: 35
Loss: 0.893 | Acc: 76.562% (49/64)
Loss: 0.878 | Acc: 78.326% (5063/6464)
Loss: 0.899 | Acc: 77.993% (10033/12864)
Loss: 0.900 | Acc: 78.047% (15035/19264)
Loss: 0.900 | Acc: 78.028% (20025/25664)
Loss: 0.906 | Acc: 77.922% (24985/32064)
Loss: 0.910 | Acc: 77.787% (29920/38464)
Loss: 0.914 | Acc: 77.666% (34844/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2904, Accuracy: 6678/10000 (66.78%)

Epoch: 36
Loss: 1.057 | Acc: 70.312% (45/64)
Loss: 0.885 | Acc: 78.295% (5061/6464)
Loss: 0.890 | Acc: 78.109% (10048/12864)
Loss: 0.889 | Acc: 78.099% (15045/19264)
Loss: 0.891 | Acc: 78.113% (20047/25664)
Loss: 0.896 | Acc: 77.913% (24982/32064)
Loss: 0.896 | Acc: 77.912% (29968/38464)
Loss: 0.896 | Acc: 77.920% (34958/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1759, Accuracy: 7120/10000 (71.20%)

Epoch: 37
Loss: 0.787 | Acc: 79.688% (51/64)
Loss: 0.854 | Acc: 79.363% (5130/6464)
Loss: 0.853 | Acc: 79.190% (10187/12864)
Loss: 0.855 | Acc: 78.997% (15218/19264)
Loss: 0.852 | Acc: 79.084% (20296/25664)
Loss: 0.857 | Acc: 78.889% (25295/32064)
Loss: 0.865 | Acc: 78.720% (30279/38464)
Loss: 0.867 | Acc: 78.651% (35286/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2065, Accuracy: 7066/10000 (70.66%)

Epoch: 38
Loss: 0.910 | Acc: 76.562% (49/64)
Loss: 0.826 | Acc: 79.409% (5133/6464)
Loss: 0.818 | Acc: 79.703% (10253/12864)
Loss: 0.823 | Acc: 79.516% (15318/19264)
Loss: 0.835 | Acc: 79.271% (20344/25664)
Loss: 0.841 | Acc: 79.126% (25371/32064)
Loss: 0.839 | Acc: 79.121% (30433/38464)
Loss: 0.840 | Acc: 79.139% (35505/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1912, Accuracy: 7118/10000 (71.18%)

Epoch: 39
Loss: 0.905 | Acc: 78.125% (50/64)
Loss: 0.786 | Acc: 80.461% (5201/6464)
Loss: 0.786 | Acc: 80.535% (10360/12864)
Loss: 0.792 | Acc: 80.347% (15478/19264)
Loss: 0.793 | Acc: 80.408% (20636/25664)
Loss: 0.798 | Acc: 80.302% (25748/32064)
Loss: 0.800 | Acc: 80.213% (30853/38464)
Loss: 0.807 | Acc: 80.082% (35928/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1913, Accuracy: 7168/10000 (71.68%)

Epoch: 40
Loss: 0.587 | Acc: 87.500% (56/64)
Loss: 0.759 | Acc: 81.281% (5254/6464)
Loss: 0.757 | Acc: 81.242% (10451/12864)
Loss: 0.764 | Acc: 81.115% (15626/19264)
Loss: 0.768 | Acc: 80.954% (20776/25664)
Loss: 0.771 | Acc: 80.876% (25932/32064)
Loss: 0.771 | Acc: 80.860% (31102/38464)
Loss: 0.770 | Acc: 80.907% (36298/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2400, Accuracy: 7081/10000 (70.81%)

Epoch: 41
Loss: 0.920 | Acc: 75.000% (48/64)
Loss: 0.718 | Acc: 81.761% (5285/6464)
Loss: 0.724 | Acc: 81.693% (10509/12864)
Loss: 0.721 | Acc: 81.868% (15771/19264)
Loss: 0.727 | Acc: 81.667% (20959/25664)
Loss: 0.729 | Acc: 81.662% (26184/32064)
Loss: 0.731 | Acc: 81.541% (31364/38464)
Loss: 0.734 | Acc: 81.453% (36543/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2818, Accuracy: 7111/10000 (71.11%)

Epoch: 42
Loss: 0.573 | Acc: 89.062% (57/64)
Loss: 0.690 | Acc: 82.333% (5322/6464)
Loss: 0.681 | Acc: 82.470% (10609/12864)
Loss: 0.684 | Acc: 82.345% (15863/19264)
Loss: 0.687 | Acc: 82.248% (21108/25664)
Loss: 0.688 | Acc: 82.270% (26379/32064)
Loss: 0.688 | Acc: 82.321% (31664/38464)
Loss: 0.684 | Acc: 82.454% (36992/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3130, Accuracy: 7109/10000 (71.09%)

Epoch: 43
Loss: 0.621 | Acc: 84.375% (54/64)
Loss: 0.629 | Acc: 83.617% (5405/6464)
Loss: 0.638 | Acc: 83.388% (10727/12864)
Loss: 0.636 | Acc: 83.581% (16101/19264)
Loss: 0.630 | Acc: 83.755% (21495/25664)
Loss: 0.630 | Acc: 83.720% (26844/32064)
Loss: 0.634 | Acc: 83.650% (32175/38464)
Loss: 0.635 | Acc: 83.666% (37536/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3325, Accuracy: 7057/10000 (70.57%)

Epoch: 44
Loss: 0.576 | Acc: 82.812% (53/64)
Loss: 0.595 | Acc: 84.282% (5448/6464)
Loss: 0.596 | Acc: 84.352% (10851/12864)
Loss: 0.592 | Acc: 84.562% (16290/19264)
Loss: 0.594 | Acc: 84.523% (21692/25664)
Loss: 0.595 | Acc: 84.453% (27079/32064)
Loss: 0.590 | Acc: 84.632% (32553/38464)
Loss: 0.590 | Acc: 84.636% (37971/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3683, Accuracy: 7117/10000 (71.17%)

Epoch: 45
Loss: 0.489 | Acc: 89.062% (57/64)
Loss: 0.548 | Acc: 85.659% (5537/6464)
Loss: 0.569 | Acc: 85.082% (10945/12864)
Loss: 0.593 | Acc: 84.526% (16283/19264)
Loss: 0.610 | Acc: 84.044% (21569/25664)
Loss: 0.620 | Acc: 83.832% (26880/32064)
Loss: 0.629 | Acc: 83.691% (32191/38464)
Loss: 0.638 | Acc: 83.550% (37484/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2229, Accuracy: 7138/10000 (71.38%)

Epoch: 46
Loss: 0.670 | Acc: 82.812% (53/64)
Loss: 0.705 | Acc: 82.317% (5321/6464)
Loss: 0.707 | Acc: 82.346% (10593/12864)
Loss: 0.713 | Acc: 82.122% (15820/19264)
Loss: 0.719 | Acc: 82.022% (21050/25664)
Loss: 0.722 | Acc: 82.011% (26296/32064)
Loss: 0.725 | Acc: 81.916% (31508/38464)
Loss: 0.731 | Acc: 81.772% (36686/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1916, Accuracy: 7225/10000 (72.25%)

Epoch: 47
Loss: 0.376 | Acc: 93.750% (60/64)
Loss: 0.759 | Acc: 80.739% (5219/6464)
Loss: 0.755 | Acc: 80.939% (10412/12864)
Loss: 0.759 | Acc: 81.079% (15619/19264)
Loss: 0.757 | Acc: 81.129% (20821/25664)
Loss: 0.764 | Acc: 81.047% (25987/32064)
Loss: 0.763 | Acc: 81.102% (31195/38464)
Loss: 0.765 | Acc: 81.110% (36389/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1853, Accuracy: 7213/10000 (72.13%)
torch.Size([100, 10])
Test set: Average loss: 1.1853, Accuracy: 7213/10000 (72.13%)

Epoch: 48
Loss: 0.749 | Acc: 82.812% (53/64)
Loss: 0.756 | Acc: 81.451% (5265/6464)
Loss: 0.769 | Acc: 81.180% (10443/12864)
Loss: 0.777 | Acc: 80.824% (15570/19264)
Loss: 0.777 | Acc: 80.817% (20741/25664)
Loss: 0.774 | Acc: 80.966% (25961/32064)
Loss: 0.774 | Acc: 80.990% (31152/38464)
Loss: 0.774 | Acc: 80.933% (36310/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1764, Accuracy: 7214/10000 (72.14%)
torch.Size([100, 10])
Test set: Average loss: 1.1764, Accuracy: 7214/10000 (72.14%)

Epoch: 49
Loss: 0.887 | Acc: 73.438% (47/64)
Loss: 0.774 | Acc: 81.126% (5244/6464)
Loss: 0.786 | Acc: 80.488% (10354/12864)
Loss: 0.788 | Acc: 80.549% (15517/19264)
Loss: 0.783 | Acc: 80.599% (20685/25664)
Loss: 0.783 | Acc: 80.564% (25832/32064)
Loss: 0.778 | Acc: 80.748% (31059/38464)
Loss: 0.778 | Acc: 80.766% (36235/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1792, Accuracy: 7213/10000 (72.13%)
torch.Size([100, 10])
Test set: Average loss: 1.1792, Accuracy: 7213/10000 (72.13%)

Epoch: 50
Loss: 0.613 | Acc: 87.500% (56/64)
Loss: 2.075 | Acc: 24.892% (1609/6464)
Loss: 1.793 | Acc: 39.513% (5083/12864)
Loss: 1.642 | Acc: 47.010% (9056/19264)
Loss: 1.562 | Acc: 50.966% (13080/25664)
Loss: 1.502 | Acc: 53.902% (17283/32064)
Loss: 1.459 | Acc: 55.857% (21485/38464)
Loss: 1.431 | Acc: 57.215% (25669/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9014, Accuracy: 4525/10000 (45.25%)

Epoch: 51
Loss: 1.348 | Acc: 60.938% (39/64)
Loss: 1.218 | Acc: 67.435% (4359/6464)
Loss: 1.210 | Acc: 67.475% (8680/12864)
Loss: 1.211 | Acc: 67.442% (12992/19264)
Loss: 1.209 | Acc: 67.495% (17322/25664)
Loss: 1.205 | Acc: 67.683% (21702/32064)
Loss: 1.200 | Acc: 67.824% (26088/38464)
Loss: 1.197 | Acc: 67.968% (30493/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4010, Accuracy: 6158/10000 (61.58%)

Epoch: 52
Loss: 1.132 | Acc: 68.750% (44/64)
Loss: 1.165 | Acc: 69.168% (4471/6464)
Loss: 1.166 | Acc: 69.209% (8903/12864)
Loss: 1.162 | Acc: 69.477% (13384/19264)
Loss: 1.166 | Acc: 69.198% (17759/25664)
Loss: 1.168 | Acc: 69.184% (22183/32064)
Loss: 1.167 | Acc: 69.171% (26606/38464)
Loss: 1.170 | Acc: 69.124% (31012/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4550, Accuracy: 6068/10000 (60.68%)

Epoch: 53
Loss: 1.408 | Acc: 62.500% (40/64)
Loss: 1.138 | Acc: 69.910% (4519/6464)
Loss: 1.145 | Acc: 69.939% (8997/12864)
Loss: 1.151 | Acc: 69.695% (13426/19264)
Loss: 1.158 | Acc: 69.428% (17818/25664)
Loss: 1.160 | Acc: 69.452% (22269/32064)
Loss: 1.155 | Acc: 69.611% (26775/38464)
Loss: 1.159 | Acc: 69.481% (31172/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8771, Accuracy: 4533/10000 (45.33%)

Epoch: 54
Loss: 1.064 | Acc: 73.438% (47/64)
Loss: 1.150 | Acc: 69.477% (4491/6464)
Loss: 1.155 | Acc: 69.745% (8972/12864)
Loss: 1.150 | Acc: 69.897% (13465/19264)
Loss: 1.148 | Acc: 69.868% (17931/25664)
Loss: 1.151 | Acc: 69.770% (22371/32064)
Loss: 1.153 | Acc: 69.668% (26797/38464)
Loss: 1.154 | Acc: 69.566% (31210/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8979, Accuracy: 4142/10000 (41.42%)

Epoch: 55
Loss: 1.446 | Acc: 59.375% (38/64)
Loss: 1.140 | Acc: 69.910% (4519/6464)
Loss: 1.147 | Acc: 69.823% (8982/12864)
Loss: 1.151 | Acc: 69.679% (13423/19264)
Loss: 1.155 | Acc: 69.479% (17831/25664)
Loss: 1.151 | Acc: 69.639% (22329/32064)
Loss: 1.149 | Acc: 69.678% (26801/38464)
Loss: 1.151 | Acc: 69.659% (31252/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3709, Accuracy: 6122/10000 (61.22%)

Epoch: 56
Loss: 1.409 | Acc: 65.625% (42/64)
Loss: 1.145 | Acc: 69.725% (4507/6464)
Loss: 1.149 | Acc: 69.566% (8949/12864)
Loss: 1.142 | Acc: 69.892% (13464/19264)
Loss: 1.140 | Acc: 70.122% (17996/25664)
Loss: 1.143 | Acc: 70.125% (22485/32064)
Loss: 1.143 | Acc: 70.105% (26965/38464)
Loss: 1.142 | Acc: 70.101% (31450/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4455, Accuracy: 5921/10000 (59.21%)

Epoch: 57
Loss: 1.264 | Acc: 68.750% (44/64)
Loss: 1.130 | Acc: 70.003% (4525/6464)
Loss: 1.139 | Acc: 70.095% (9017/12864)
Loss: 1.144 | Acc: 69.944% (13474/19264)
Loss: 1.142 | Acc: 70.055% (17979/25664)
Loss: 1.139 | Acc: 70.066% (22466/32064)
Loss: 1.145 | Acc: 69.969% (26913/38464)
Loss: 1.139 | Acc: 70.208% (31498/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7745, Accuracy: 4693/10000 (46.93%)

Epoch: 58
Loss: 1.333 | Acc: 65.625% (42/64)
Loss: 1.138 | Acc: 70.359% (4548/6464)
Loss: 1.144 | Acc: 70.320% (9046/12864)
Loss: 1.134 | Acc: 70.640% (13608/19264)
Loss: 1.135 | Acc: 70.605% (18120/25664)
Loss: 1.140 | Acc: 70.453% (22590/32064)
Loss: 1.138 | Acc: 70.440% (27094/38464)
Loss: 1.136 | Acc: 70.502% (31630/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7690, Accuracy: 4995/10000 (49.95%)

Epoch: 59
Loss: 1.031 | Acc: 73.438% (47/64)
Loss: 1.141 | Acc: 70.297% (4544/6464)
Loss: 1.129 | Acc: 70.647% (9088/12864)
Loss: 1.130 | Acc: 70.603% (13601/19264)
Loss: 1.126 | Acc: 70.636% (18128/25664)
Loss: 1.129 | Acc: 70.497% (22604/32064)
Loss: 1.131 | Acc: 70.398% (27078/38464)
Loss: 1.134 | Acc: 70.377% (31574/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3987, Accuracy: 6026/10000 (60.26%)

Epoch: 60
Loss: 1.052 | Acc: 70.312% (45/64)
Loss: 1.128 | Acc: 70.529% (4559/6464)
Loss: 1.126 | Acc: 70.631% (9086/12864)
Loss: 1.139 | Acc: 70.276% (13538/19264)
Loss: 1.138 | Acc: 70.289% (18039/25664)
Loss: 1.135 | Acc: 70.528% (22614/32064)
Loss: 1.132 | Acc: 70.624% (27165/38464)
Loss: 1.133 | Acc: 70.569% (31660/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4502, Accuracy: 5995/10000 (59.95%)

Epoch: 61
Loss: 1.201 | Acc: 65.625% (42/64)
Loss: 1.108 | Acc: 71.395% (4615/6464)
Loss: 1.111 | Acc: 71.362% (9180/12864)
Loss: 1.119 | Acc: 70.972% (13672/19264)
Loss: 1.126 | Acc: 70.772% (18163/25664)
Loss: 1.126 | Acc: 70.752% (22686/32064)
Loss: 1.127 | Acc: 70.765% (27219/38464)
Loss: 1.125 | Acc: 70.836% (31780/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3590, Accuracy: 6203/10000 (62.03%)

Epoch: 62
Loss: 1.283 | Acc: 68.750% (44/64)
Loss: 1.105 | Acc: 71.983% (4653/6464)
Loss: 1.101 | Acc: 72.194% (9287/12864)
Loss: 1.116 | Acc: 71.683% (13809/19264)
Loss: 1.112 | Acc: 71.665% (18392/25664)
Loss: 1.116 | Acc: 71.479% (22919/32064)
Loss: 1.118 | Acc: 71.371% (27452/38464)
Loss: 1.121 | Acc: 71.186% (31937/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3792, Accuracy: 6243/10000 (62.43%)

Epoch: 63
Loss: 0.874 | Acc: 79.688% (51/64)
Loss: 1.102 | Acc: 71.303% (4609/6464)
Loss: 1.104 | Acc: 71.626% (9214/12864)
Loss: 1.098 | Acc: 71.839% (13839/19264)
Loss: 1.106 | Acc: 71.419% (18329/25664)
Loss: 1.106 | Acc: 71.479% (22919/32064)
Loss: 1.111 | Acc: 71.300% (27425/38464)
Loss: 1.114 | Acc: 71.260% (31970/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3535, Accuracy: 6335/10000 (63.35%)

Epoch: 64
Loss: 1.124 | Acc: 78.125% (50/64)
Loss: 1.112 | Acc: 71.689% (4634/6464)
Loss: 1.110 | Acc: 71.510% (9199/12864)
Loss: 1.100 | Acc: 71.792% (13830/19264)
Loss: 1.104 | Acc: 71.680% (18396/25664)
Loss: 1.107 | Acc: 71.641% (22971/32064)
Loss: 1.106 | Acc: 71.693% (27576/38464)
Loss: 1.109 | Acc: 71.530% (32091/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3848, Accuracy: 6078/10000 (60.78%)

Epoch: 65
Loss: 0.918 | Acc: 79.688% (51/64)
Loss: 1.088 | Acc: 71.875% (4646/6464)
Loss: 1.088 | Acc: 72.139% (9280/12864)
Loss: 1.105 | Acc: 71.558% (13785/19264)
Loss: 1.102 | Acc: 71.637% (18385/25664)
Loss: 1.105 | Acc: 71.548% (22941/32064)
Loss: 1.107 | Acc: 71.592% (27537/38464)
Loss: 1.104 | Acc: 71.630% (32136/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3995, Accuracy: 6100/10000 (61.00%)

Epoch: 66
Loss: 1.042 | Acc: 73.438% (47/64)
Loss: 1.059 | Acc: 72.788% (4705/6464)
Loss: 1.086 | Acc: 71.992% (9261/12864)
Loss: 1.092 | Acc: 71.865% (13844/19264)
Loss: 1.095 | Acc: 71.793% (18425/25664)
Loss: 1.097 | Acc: 71.797% (23021/32064)
Loss: 1.097 | Acc: 71.846% (27635/38464)
Loss: 1.096 | Acc: 71.830% (32226/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8630, Accuracy: 4563/10000 (45.63%)

Epoch: 67
Loss: 1.569 | Acc: 54.688% (35/64)
Loss: 1.101 | Acc: 71.999% (4654/6464)
Loss: 1.087 | Acc: 72.349% (9307/12864)
Loss: 1.092 | Acc: 72.103% (13890/19264)
Loss: 1.095 | Acc: 72.031% (18486/25664)
Loss: 1.092 | Acc: 72.100% (23118/32064)
Loss: 1.092 | Acc: 72.008% (27697/38464)
Loss: 1.093 | Acc: 71.984% (32295/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8278, Accuracy: 4707/10000 (47.07%)

Epoch: 68
Loss: 1.030 | Acc: 75.000% (48/64)
Loss: 1.096 | Acc: 72.030% (4656/6464)
Loss: 1.074 | Acc: 72.785% (9363/12864)
Loss: 1.079 | Acc: 72.508% (13968/19264)
Loss: 1.079 | Acc: 72.557% (18621/25664)
Loss: 1.083 | Acc: 72.421% (23221/32064)
Loss: 1.087 | Acc: 72.299% (27809/38464)
Loss: 1.083 | Acc: 72.350% (32459/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5602, Accuracy: 5607/10000 (56.07%)

Epoch: 69
Loss: 1.144 | Acc: 67.188% (43/64)
Loss: 1.046 | Acc: 73.376% (4743/6464)
Loss: 1.058 | Acc: 73.049% (9397/12864)
Loss: 1.069 | Acc: 72.711% (14007/19264)
Loss: 1.075 | Acc: 72.506% (18608/25664)
Loss: 1.071 | Acc: 72.658% (23297/32064)
Loss: 1.069 | Acc: 72.699% (27963/38464)
Loss: 1.071 | Acc: 72.677% (32606/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4349, Accuracy: 6074/10000 (60.74%)

Epoch: 70
Loss: 1.069 | Acc: 73.438% (47/64)
Loss: 1.022 | Acc: 74.428% (4811/6464)
Loss: 1.032 | Acc: 74.168% (9541/12864)
Loss: 1.043 | Acc: 73.739% (14205/19264)
Loss: 1.044 | Acc: 73.788% (18937/25664)
Loss: 1.055 | Acc: 73.425% (23543/32064)
Loss: 1.060 | Acc: 73.214% (28161/38464)
Loss: 1.065 | Acc: 73.052% (32774/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4030, Accuracy: 6048/10000 (60.48%)

Epoch: 71
Loss: 1.128 | Acc: 68.750% (44/64)
Loss: 1.031 | Acc: 73.778% (4769/6464)
Loss: 1.032 | Acc: 73.919% (9509/12864)
Loss: 1.046 | Acc: 73.630% (14184/19264)
Loss: 1.047 | Acc: 73.543% (18874/25664)
Loss: 1.051 | Acc: 73.515% (23572/32064)
Loss: 1.056 | Acc: 73.305% (28196/38464)
Loss: 1.054 | Acc: 73.371% (32917/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4647, Accuracy: 5883/10000 (58.83%)

Epoch: 72
Loss: 1.063 | Acc: 70.312% (45/64)
Loss: 1.026 | Acc: 74.134% (4792/6464)
Loss: 1.038 | Acc: 73.671% (9477/12864)
Loss: 1.052 | Acc: 73.194% (14100/19264)
Loss: 1.050 | Acc: 73.223% (18792/25664)
Loss: 1.049 | Acc: 73.335% (23514/32064)
Loss: 1.047 | Acc: 73.435% (28246/38464)
Loss: 1.049 | Acc: 73.444% (32950/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2595, Accuracy: 6635/10000 (66.35%)

Epoch: 73
Loss: 1.165 | Acc: 70.312% (45/64)
Loss: 1.025 | Acc: 74.505% (4816/6464)
Loss: 1.031 | Acc: 74.518% (9586/12864)
Loss: 1.036 | Acc: 74.278% (14309/19264)
Loss: 1.038 | Acc: 74.295% (19067/25664)
Loss: 1.037 | Acc: 74.239% (23804/32064)
Loss: 1.035 | Acc: 74.275% (28569/38464)
Loss: 1.038 | Acc: 74.160% (33271/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3372, Accuracy: 6357/10000 (63.57%)

Epoch: 74
Loss: 1.145 | Acc: 68.750% (44/64)
Loss: 1.012 | Acc: 74.675% (4827/6464)
Loss: 1.014 | Acc: 74.736% (9614/12864)
Loss: 1.022 | Acc: 74.533% (14358/19264)
Loss: 1.028 | Acc: 74.396% (19093/25664)
Loss: 1.024 | Acc: 74.560% (23907/32064)
Loss: 1.031 | Acc: 74.288% (28574/38464)
Loss: 1.032 | Acc: 74.251% (33312/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2640, Accuracy: 6672/10000 (66.72%)

Epoch: 75
Loss: 0.950 | Acc: 78.125% (50/64)
Loss: 1.006 | Acc: 75.325% (4869/6464)
Loss: 1.011 | Acc: 75.101% (9661/12864)
Loss: 1.016 | Acc: 74.943% (14437/19264)
Loss: 1.016 | Acc: 74.825% (19203/25664)
Loss: 1.015 | Acc: 74.822% (23991/32064)
Loss: 1.021 | Acc: 74.561% (28679/38464)
Loss: 1.021 | Acc: 74.556% (33449/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3721, Accuracy: 6413/10000 (64.13%)

Epoch: 76
Loss: 0.849 | Acc: 79.688% (51/64)
Loss: 0.992 | Acc: 75.294% (4867/6464)
Loss: 0.986 | Acc: 75.645% (9731/12864)
Loss: 0.999 | Acc: 75.265% (14499/19264)
Loss: 1.003 | Acc: 75.117% (19278/25664)
Loss: 1.009 | Acc: 74.935% (24027/32064)
Loss: 1.011 | Acc: 74.857% (28793/38464)
Loss: 1.009 | Acc: 74.931% (33617/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3392, Accuracy: 6412/10000 (64.12%)

Epoch: 77
Loss: 0.955 | Acc: 78.125% (50/64)
Loss: 0.989 | Acc: 75.248% (4864/6464)
Loss: 0.995 | Acc: 75.319% (9689/12864)
Loss: 0.993 | Acc: 75.291% (14504/19264)
Loss: 0.997 | Acc: 75.327% (19332/25664)
Loss: 0.998 | Acc: 75.337% (24156/32064)
Loss: 0.995 | Acc: 75.484% (29034/38464)
Loss: 0.996 | Acc: 75.499% (33872/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1964, Accuracy: 6940/10000 (69.40%)

Epoch: 78
Loss: 0.835 | Acc: 81.250% (52/64)
Loss: 0.969 | Acc: 76.284% (4931/6464)
Loss: 0.982 | Acc: 75.948% (9770/12864)
Loss: 0.991 | Acc: 75.753% (14593/19264)
Loss: 0.990 | Acc: 75.810% (19456/25664)
Loss: 0.990 | Acc: 75.780% (24298/32064)
Loss: 0.986 | Acc: 75.829% (29167/38464)
Loss: 0.987 | Acc: 75.758% (33988/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3836, Accuracy: 6199/10000 (61.99%)

Epoch: 79
Loss: 1.107 | Acc: 75.000% (48/64)
Loss: 0.953 | Acc: 76.253% (4929/6464)
Loss: 0.959 | Acc: 76.073% (9786/12864)
Loss: 0.962 | Acc: 76.194% (14678/19264)
Loss: 0.969 | Acc: 76.146% (19542/25664)
Loss: 0.972 | Acc: 76.045% (24383/32064)
Loss: 0.969 | Acc: 76.144% (29288/38464)
Loss: 0.967 | Acc: 76.233% (34201/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3919, Accuracy: 6115/10000 (61.15%)

Epoch: 80
Loss: 1.199 | Acc: 68.750% (44/64)
Loss: 0.971 | Acc: 75.541% (4883/6464)
Loss: 0.961 | Acc: 76.182% (9800/12864)
Loss: 0.960 | Acc: 76.256% (14690/19264)
Loss: 0.955 | Acc: 76.407% (19609/25664)
Loss: 0.955 | Acc: 76.400% (24497/32064)
Loss: 0.956 | Acc: 76.355% (29369/38464)
Loss: 0.957 | Acc: 76.362% (34259/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2828, Accuracy: 6716/10000 (67.16%)

Epoch: 81
Loss: 0.828 | Acc: 81.250% (52/64)
Loss: 0.933 | Acc: 76.795% (4964/6464)
Loss: 0.940 | Acc: 76.757% (9874/12864)
Loss: 0.938 | Acc: 76.806% (14796/19264)
Loss: 0.943 | Acc: 76.711% (19687/25664)
Loss: 0.939 | Acc: 76.927% (24666/32064)
Loss: 0.939 | Acc: 76.963% (29603/38464)
Loss: 0.942 | Acc: 76.937% (34517/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3602, Accuracy: 6459/10000 (64.59%)

Epoch: 82
Loss: 0.894 | Acc: 75.000% (48/64)
Loss: 0.929 | Acc: 76.810% (4965/6464)
Loss: 0.926 | Acc: 77.192% (9930/12864)
Loss: 0.916 | Acc: 77.653% (14959/19264)
Loss: 0.917 | Acc: 77.669% (19933/25664)
Loss: 0.920 | Acc: 77.592% (24879/32064)
Loss: 0.923 | Acc: 77.569% (29836/38464)
Loss: 0.924 | Acc: 77.541% (34788/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1763, Accuracy: 7099/10000 (70.99%)

Epoch: 83
Loss: 1.130 | Acc: 70.312% (45/64)
Loss: 0.882 | Acc: 78.450% (5071/6464)
Loss: 0.896 | Acc: 78.125% (10050/12864)
Loss: 0.892 | Acc: 78.172% (15059/19264)
Loss: 0.902 | Acc: 77.942% (20003/25664)
Loss: 0.899 | Acc: 78.013% (25014/32064)
Loss: 0.903 | Acc: 77.953% (29984/38464)
Loss: 0.905 | Acc: 77.929% (34962/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2758, Accuracy: 6723/10000 (67.23%)

Epoch: 84
Loss: 0.845 | Acc: 78.125% (50/64)
Loss: 0.883 | Acc: 78.311% (5062/6464)
Loss: 0.886 | Acc: 78.358% (10080/12864)
Loss: 0.888 | Acc: 78.390% (15101/19264)
Loss: 0.890 | Acc: 78.378% (20115/25664)
Loss: 0.883 | Acc: 78.543% (25184/32064)
Loss: 0.882 | Acc: 78.570% (30221/38464)
Loss: 0.885 | Acc: 78.455% (35198/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2436, Accuracy: 6957/10000 (69.57%)

Epoch: 85
Loss: 0.912 | Acc: 78.125% (50/64)
Loss: 0.848 | Acc: 79.425% (5134/6464)
Loss: 0.854 | Acc: 79.167% (10184/12864)
Loss: 0.855 | Acc: 79.148% (15247/19264)
Loss: 0.853 | Acc: 79.282% (20347/25664)
Loss: 0.851 | Acc: 79.432% (25469/32064)
Loss: 0.857 | Acc: 79.308% (30505/38464)
Loss: 0.861 | Acc: 79.179% (35523/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3267, Accuracy: 6589/10000 (65.89%)

Epoch: 86
Loss: 0.786 | Acc: 79.688% (51/64)
Loss: 0.812 | Acc: 80.260% (5188/6464)
Loss: 0.813 | Acc: 80.169% (10313/12864)
Loss: 0.810 | Acc: 80.181% (15446/19264)
Loss: 0.825 | Acc: 79.723% (20460/25664)
Loss: 0.833 | Acc: 79.516% (25496/32064)
Loss: 0.838 | Acc: 79.438% (30555/38464)
Loss: 0.840 | Acc: 79.373% (35610/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2138, Accuracy: 7051/10000 (70.51%)

Epoch: 87
Loss: 0.687 | Acc: 82.812% (53/64)
Loss: 0.809 | Acc: 79.904% (5165/6464)
Loss: 0.792 | Acc: 80.659% (10376/12864)
Loss: 0.809 | Acc: 80.217% (15453/19264)
Loss: 0.813 | Acc: 80.101% (20557/25664)
Loss: 0.815 | Acc: 80.084% (25678/32064)
Loss: 0.812 | Acc: 80.132% (30822/38464)
Loss: 0.807 | Acc: 80.240% (35999/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1920, Accuracy: 7152/10000 (71.52%)

Epoch: 88
Loss: 0.527 | Acc: 87.500% (56/64)
Loss: 0.768 | Acc: 81.219% (5250/6464)
Loss: 0.774 | Acc: 81.032% (10424/12864)
Loss: 0.772 | Acc: 80.923% (15589/19264)
Loss: 0.774 | Acc: 80.911% (20765/25664)
Loss: 0.775 | Acc: 80.876% (25932/32064)
Loss: 0.774 | Acc: 80.894% (31115/38464)
Loss: 0.776 | Acc: 80.891% (36291/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2257, Accuracy: 7140/10000 (71.40%)

Epoch: 89
Loss: 0.513 | Acc: 87.500% (56/64)
Loss: 0.721 | Acc: 82.225% (5315/6464)
Loss: 0.734 | Acc: 81.849% (10529/12864)
Loss: 0.738 | Acc: 81.670% (15733/19264)
Loss: 0.739 | Acc: 81.636% (20951/25664)
Loss: 0.741 | Acc: 81.634% (26175/32064)
Loss: 0.740 | Acc: 81.715% (31431/38464)
Loss: 0.742 | Acc: 81.662% (36637/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2480, Accuracy: 7141/10000 (71.41%)

Epoch: 90
Loss: 0.817 | Acc: 73.438% (47/64)
Loss: 0.674 | Acc: 83.230% (5380/6464)
Loss: 0.696 | Acc: 82.610% (10627/12864)
Loss: 0.697 | Acc: 82.584% (15909/19264)
Loss: 0.697 | Acc: 82.524% (21179/25664)
Loss: 0.702 | Acc: 82.367% (26410/32064)
Loss: 0.706 | Acc: 82.241% (31633/38464)
Loss: 0.706 | Acc: 82.289% (36918/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2826, Accuracy: 7115/10000 (71.15%)

Epoch: 91
Loss: 0.495 | Acc: 85.938% (55/64)
Loss: 0.656 | Acc: 83.122% (5373/6464)
Loss: 0.654 | Acc: 83.178% (10700/12864)
Loss: 0.661 | Acc: 82.968% (15983/19264)
Loss: 0.658 | Acc: 83.128% (21334/25664)
Loss: 0.663 | Acc: 83.025% (26621/32064)
Loss: 0.662 | Acc: 83.075% (31954/38464)
Loss: 0.661 | Acc: 83.120% (37291/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2832, Accuracy: 7170/10000 (71.70%)

Epoch: 92
Loss: 0.800 | Acc: 82.812% (53/64)
Loss: 0.609 | Acc: 84.097% (5436/6464)
Loss: 0.602 | Acc: 84.266% (10840/12864)
Loss: 0.603 | Acc: 84.417% (16262/19264)
Loss: 0.606 | Acc: 84.270% (21627/25664)
Loss: 0.615 | Acc: 84.048% (26949/32064)
Loss: 0.613 | Acc: 84.144% (32365/38464)
Loss: 0.611 | Acc: 84.157% (37756/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3551, Accuracy: 7116/10000 (71.16%)

Epoch: 93
Loss: 0.531 | Acc: 87.500% (56/64)
Loss: 0.551 | Acc: 85.040% (5497/6464)
Loss: 0.546 | Acc: 85.557% (11006/12864)
Loss: 0.545 | Acc: 85.553% (16481/19264)
Loss: 0.549 | Acc: 85.470% (21935/25664)
Loss: 0.549 | Acc: 85.510% (27418/32064)
Loss: 0.554 | Acc: 85.360% (32833/38464)
Loss: 0.555 | Acc: 85.329% (38282/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3718, Accuracy: 7087/10000 (70.87%)

Epoch: 94
Loss: 0.417 | Acc: 90.625% (58/64)
Loss: 0.488 | Acc: 86.788% (5610/6464)
Loss: 0.499 | Acc: 86.536% (11132/12864)
Loss: 0.500 | Acc: 86.524% (16668/19264)
Loss: 0.502 | Acc: 86.440% (22184/25664)
Loss: 0.505 | Acc: 86.383% (27698/32064)
Loss: 0.503 | Acc: 86.437% (33247/38464)
Loss: 0.503 | Acc: 86.468% (38793/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4145, Accuracy: 7096/10000 (70.96%)

Epoch: 95
Loss: 0.441 | Acc: 87.500% (56/64)
Loss: 0.462 | Acc: 87.376% (5648/6464)
Loss: 0.486 | Acc: 86.863% (11174/12864)
Loss: 0.505 | Acc: 86.332% (16631/19264)
Loss: 0.518 | Acc: 86.132% (22105/25664)
Loss: 0.533 | Acc: 85.775% (27503/32064)
Loss: 0.546 | Acc: 85.488% (32882/38464)
Loss: 0.553 | Acc: 85.293% (38266/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2544, Accuracy: 7159/10000 (71.59%)

Epoch: 96
Loss: 0.477 | Acc: 85.938% (55/64)
Loss: 0.644 | Acc: 83.184% (5377/6464)
Loss: 0.636 | Acc: 83.543% (10747/12864)
Loss: 0.643 | Acc: 83.326% (16052/19264)
Loss: 0.644 | Acc: 83.424% (21410/25664)
Loss: 0.641 | Acc: 83.508% (26776/32064)
Loss: 0.642 | Acc: 83.468% (32105/38464)
Loss: 0.647 | Acc: 83.394% (37414/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2203, Accuracy: 7223/10000 (72.23%)

Epoch: 97
Loss: 0.764 | Acc: 78.125% (50/64)
Loss: 0.667 | Acc: 82.843% (5355/6464)
Loss: 0.669 | Acc: 82.844% (10657/12864)
Loss: 0.670 | Acc: 82.823% (15955/19264)
Loss: 0.671 | Acc: 82.781% (21245/25664)
Loss: 0.672 | Acc: 82.738% (26529/32064)
Loss: 0.670 | Acc: 82.859% (31871/38464)
Loss: 0.674 | Acc: 82.750% (37125/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2168, Accuracy: 7240/10000 (72.40%)
torch.Size([100, 10])
Test set: Average loss: 1.2168, Accuracy: 7240/10000 (72.40%)

Epoch: 98
Loss: 0.494 | Acc: 87.500% (56/64)
Loss: 0.688 | Acc: 82.147% (5310/6464)
Loss: 0.693 | Acc: 82.144% (10567/12864)
Loss: 0.690 | Acc: 82.366% (15867/19264)
Loss: 0.692 | Acc: 82.357% (21136/25664)
Loss: 0.691 | Acc: 82.426% (26429/32064)
Loss: 0.691 | Acc: 82.428% (31705/38464)
Loss: 0.690 | Acc: 82.442% (36987/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2109, Accuracy: 7224/10000 (72.24%)
torch.Size([100, 10])
Test set: Average loss: 1.2109, Accuracy: 7224/10000 (72.24%)

Epoch: 99
Loss: 0.448 | Acc: 89.062% (57/64)
Loss: 0.688 | Acc: 82.379% (5325/6464)
Loss: 0.688 | Acc: 82.463% (10608/12864)
Loss: 0.687 | Acc: 82.517% (15896/19264)
Loss: 0.686 | Acc: 82.497% (21172/25664)
Loss: 0.688 | Acc: 82.476% (26445/32064)
Loss: 0.687 | Acc: 82.495% (31731/38464)
Loss: 0.686 | Acc: 82.565% (37042/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2128, Accuracy: 7254/10000 (72.54%)
torch.Size([100, 10])
Test set: Average loss: 1.2128, Accuracy: 7254/10000 (72.54%)

Epoch: 100
Loss: 0.605 | Acc: 84.375% (54/64)
Loss: 1.965 | Acc: 30.832% (1993/6464)
Loss: 1.727 | Acc: 43.144% (5550/12864)
Loss: 1.580 | Acc: 50.062% (9644/19264)
Loss: 1.501 | Acc: 53.768% (13799/25664)
Loss: 1.448 | Acc: 56.241% (18033/32064)
Loss: 1.410 | Acc: 58.018% (22316/38464)
Loss: 1.383 | Acc: 59.308% (26608/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7536, Accuracy: 4851/10000 (48.51%)

Epoch: 101
Loss: 1.445 | Acc: 60.938% (39/64)
Loss: 1.159 | Acc: 68.704% (4441/6464)
Loss: 1.172 | Acc: 68.408% (8800/12864)
Loss: 1.168 | Acc: 68.620% (13219/19264)
Loss: 1.165 | Acc: 68.953% (17696/25664)
Loss: 1.164 | Acc: 69.056% (22142/32064)
Loss: 1.162 | Acc: 69.109% (26582/38464)
Loss: 1.163 | Acc: 69.153% (31025/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5708, Accuracy: 5447/10000 (54.47%)

Epoch: 102
Loss: 0.950 | Acc: 70.312% (45/64)
Loss: 1.145 | Acc: 69.879% (4517/6464)
Loss: 1.142 | Acc: 69.862% (8987/12864)
Loss: 1.145 | Acc: 69.856% (13457/19264)
Loss: 1.143 | Acc: 69.857% (17928/25664)
Loss: 1.143 | Acc: 69.870% (22403/32064)
Loss: 1.146 | Acc: 69.790% (26844/38464)
Loss: 1.142 | Acc: 70.087% (31444/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6491, Accuracy: 5464/10000 (54.64%)

Epoch: 103
Loss: 1.187 | Acc: 67.188% (43/64)
Loss: 1.142 | Acc: 70.127% (4533/6464)
Loss: 1.141 | Acc: 70.211% (9032/12864)
Loss: 1.137 | Acc: 70.229% (13529/19264)
Loss: 1.133 | Acc: 70.418% (18072/25664)
Loss: 1.134 | Acc: 70.422% (22580/32064)
Loss: 1.136 | Acc: 70.450% (27098/38464)
Loss: 1.136 | Acc: 70.375% (31573/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1112, Accuracy: 4395/10000 (43.95%)

Epoch: 104
Loss: 1.354 | Acc: 62.500% (40/64)
Loss: 1.110 | Acc: 70.328% (4546/6464)
Loss: 1.126 | Acc: 70.126% (9021/12864)
Loss: 1.123 | Acc: 70.437% (13569/19264)
Loss: 1.127 | Acc: 70.344% (18053/25664)
Loss: 1.129 | Acc: 70.472% (22596/32064)
Loss: 1.131 | Acc: 70.466% (27104/38464)
Loss: 1.132 | Acc: 70.477% (31619/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5029, Accuracy: 5864/10000 (58.64%)

Epoch: 105
Loss: 1.649 | Acc: 53.125% (34/64)
Loss: 1.136 | Acc: 70.668% (4568/6464)
Loss: 1.118 | Acc: 71.276% (9169/12864)
Loss: 1.123 | Acc: 71.133% (13703/19264)
Loss: 1.114 | Acc: 71.310% (18301/25664)
Loss: 1.117 | Acc: 71.170% (22820/32064)
Loss: 1.121 | Acc: 71.053% (27330/38464)
Loss: 1.123 | Acc: 70.939% (31826/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6289, Accuracy: 5489/10000 (54.89%)

Epoch: 106
Loss: 1.216 | Acc: 65.625% (42/64)
Loss: 1.114 | Acc: 71.689% (4634/6464)
Loss: 1.128 | Acc: 70.981% (9131/12864)
Loss: 1.120 | Acc: 71.221% (13720/19264)
Loss: 1.121 | Acc: 71.100% (18247/25664)
Loss: 1.120 | Acc: 71.254% (22847/32064)
Loss: 1.123 | Acc: 71.092% (27345/38464)
Loss: 1.124 | Acc: 70.999% (31853/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9639, Accuracy: 4369/10000 (43.69%)

Epoch: 107
Loss: 1.217 | Acc: 67.188% (43/64)
Loss: 1.078 | Acc: 72.092% (4660/6464)
Loss: 1.092 | Acc: 71.805% (9237/12864)
Loss: 1.103 | Acc: 71.631% (13799/19264)
Loss: 1.113 | Acc: 71.248% (18285/25664)
Loss: 1.114 | Acc: 71.195% (22828/32064)
Loss: 1.119 | Acc: 71.001% (27310/38464)
Loss: 1.121 | Acc: 71.041% (31872/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6650, Accuracy: 5020/10000 (50.20%)

Epoch: 108
Loss: 1.376 | Acc: 64.062% (41/64)
Loss: 1.111 | Acc: 71.442% (4618/6464)
Loss: 1.105 | Acc: 71.673% (9220/12864)
Loss: 1.114 | Acc: 71.164% (13709/19264)
Loss: 1.113 | Acc: 71.294% (18297/25664)
Loss: 1.113 | Acc: 71.229% (22839/32064)
Loss: 1.118 | Acc: 71.059% (27332/38464)
Loss: 1.119 | Acc: 70.979% (31844/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5672, Accuracy: 5584/10000 (55.84%)

Epoch: 109
Loss: 1.227 | Acc: 68.750% (44/64)
Loss: 1.124 | Acc: 70.900% (4583/6464)
Loss: 1.110 | Acc: 71.377% (9182/12864)
Loss: 1.107 | Acc: 71.486% (13771/19264)
Loss: 1.107 | Acc: 71.485% (18346/25664)
Loss: 1.111 | Acc: 71.404% (22895/32064)
Loss: 1.112 | Acc: 71.381% (27456/38464)
Loss: 1.113 | Acc: 71.322% (31998/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6300, Accuracy: 5298/10000 (52.98%)

Epoch: 110
Loss: 1.560 | Acc: 56.250% (36/64)
Loss: 1.107 | Acc: 71.411% (4616/6464)
Loss: 1.099 | Acc: 71.603% (9211/12864)
Loss: 1.098 | Acc: 71.704% (13813/19264)
Loss: 1.100 | Acc: 71.746% (18413/25664)
Loss: 1.104 | Acc: 71.669% (22980/32064)
Loss: 1.107 | Acc: 71.589% (27536/38464)
Loss: 1.108 | Acc: 71.563% (32106/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4261, Accuracy: 6035/10000 (60.35%)

Epoch: 111
Loss: 0.985 | Acc: 75.000% (48/64)
Loss: 1.096 | Acc: 71.643% (4631/6464)
Loss: 1.103 | Acc: 71.681% (9221/12864)
Loss: 1.099 | Acc: 71.942% (13859/19264)
Loss: 1.094 | Acc: 71.988% (18475/25664)
Loss: 1.101 | Acc: 71.859% (23041/32064)
Loss: 1.103 | Acc: 71.781% (27610/38464)
Loss: 1.104 | Acc: 71.692% (32164/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5272, Accuracy: 5539/10000 (55.39%)

Epoch: 112
Loss: 1.317 | Acc: 60.938% (39/64)
Loss: 1.102 | Acc: 71.395% (4615/6464)
Loss: 1.084 | Acc: 72.077% (9272/12864)
Loss: 1.089 | Acc: 72.031% (13876/19264)
Loss: 1.093 | Acc: 71.848% (18439/25664)
Loss: 1.092 | Acc: 71.825% (23030/32064)
Loss: 1.098 | Acc: 71.703% (27580/38464)
Loss: 1.101 | Acc: 71.581% (32114/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6175, Accuracy: 5117/10000 (51.17%)

Epoch: 113
Loss: 1.125 | Acc: 73.438% (47/64)
Loss: 1.075 | Acc: 72.834% (4708/6464)
Loss: 1.090 | Acc: 71.867% (9245/12864)
Loss: 1.087 | Acc: 72.057% (13881/19264)
Loss: 1.087 | Acc: 72.124% (18510/25664)
Loss: 1.085 | Acc: 72.255% (23168/32064)
Loss: 1.090 | Acc: 72.083% (27726/38464)
Loss: 1.094 | Acc: 71.935% (32273/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8903, Accuracy: 4572/10000 (45.72%)

Epoch: 114
Loss: 1.113 | Acc: 71.875% (46/64)
Loss: 1.073 | Acc: 72.416% (4681/6464)
Loss: 1.078 | Acc: 72.186% (9286/12864)
Loss: 1.082 | Acc: 72.000% (13870/19264)
Loss: 1.085 | Acc: 72.000% (18478/25664)
Loss: 1.089 | Acc: 71.956% (23072/32064)
Loss: 1.095 | Acc: 71.794% (27615/38464)
Loss: 1.096 | Acc: 71.764% (32196/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6990, Accuracy: 5202/10000 (52.02%)

Epoch: 115
Loss: 1.140 | Acc: 64.062% (41/64)
Loss: 1.064 | Acc: 73.035% (4721/6464)
Loss: 1.071 | Acc: 72.808% (9366/12864)
Loss: 1.083 | Acc: 72.524% (13971/19264)
Loss: 1.089 | Acc: 72.424% (18587/25664)
Loss: 1.086 | Acc: 72.424% (23222/32064)
Loss: 1.084 | Acc: 72.377% (27839/38464)
Loss: 1.082 | Acc: 72.450% (32504/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3675, Accuracy: 6348/10000 (63.48%)

Epoch: 116
Loss: 0.962 | Acc: 78.125% (50/64)
Loss: 1.076 | Acc: 72.014% (4655/6464)
Loss: 1.078 | Acc: 72.163% (9283/12864)
Loss: 1.078 | Acc: 72.384% (13944/19264)
Loss: 1.081 | Acc: 72.315% (18559/25664)
Loss: 1.083 | Acc: 72.386% (23210/32064)
Loss: 1.081 | Acc: 72.502% (27887/38464)
Loss: 1.082 | Acc: 72.468% (32512/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5160, Accuracy: 5653/10000 (56.53%)

Epoch: 117
Loss: 0.998 | Acc: 75.000% (48/64)
Loss: 1.083 | Acc: 72.153% (4664/6464)
Loss: 1.090 | Acc: 72.132% (9279/12864)
Loss: 1.079 | Acc: 72.545% (13975/19264)
Loss: 1.077 | Acc: 72.763% (18674/25664)
Loss: 1.085 | Acc: 72.508% (23249/32064)
Loss: 1.080 | Acc: 72.593% (27922/38464)
Loss: 1.074 | Acc: 72.751% (32639/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3570, Accuracy: 6331/10000 (63.31%)

Epoch: 118
Loss: 1.289 | Acc: 73.438% (47/64)
Loss: 1.041 | Acc: 73.314% (4739/6464)
Loss: 1.056 | Acc: 73.111% (9405/12864)
Loss: 1.063 | Acc: 73.053% (14073/19264)
Loss: 1.063 | Acc: 73.157% (18775/25664)
Loss: 1.067 | Acc: 73.029% (23416/32064)
Loss: 1.067 | Acc: 72.957% (28062/38464)
Loss: 1.067 | Acc: 73.018% (32759/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9003, Accuracy: 4360/10000 (43.60%)

Epoch: 119
Loss: 1.076 | Acc: 70.312% (45/64)
Loss: 1.059 | Acc: 73.066% (4723/6464)
Loss: 1.055 | Acc: 73.235% (9421/12864)
Loss: 1.052 | Acc: 73.209% (14103/19264)
Loss: 1.059 | Acc: 73.282% (18807/25664)
Loss: 1.061 | Acc: 73.282% (23497/32064)
Loss: 1.061 | Acc: 73.302% (28195/38464)
Loss: 1.059 | Acc: 73.380% (32921/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5069, Accuracy: 5834/10000 (58.34%)

Epoch: 120
Loss: 0.974 | Acc: 73.438% (47/64)
Loss: 1.063 | Acc: 73.283% (4737/6464)
Loss: 1.059 | Acc: 73.453% (9449/12864)
Loss: 1.049 | Acc: 73.775% (14212/19264)
Loss: 1.048 | Acc: 73.792% (18938/25664)
Loss: 1.047 | Acc: 73.752% (23648/32064)
Loss: 1.049 | Acc: 73.703% (28349/38464)
Loss: 1.052 | Acc: 73.643% (33039/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2841, Accuracy: 6588/10000 (65.88%)

Epoch: 121
Loss: 1.254 | Acc: 67.188% (43/64)
Loss: 1.013 | Acc: 74.722% (4830/6464)
Loss: 1.033 | Acc: 74.230% (9549/12864)
Loss: 1.041 | Acc: 73.977% (14251/19264)
Loss: 1.046 | Acc: 73.874% (18959/25664)
Loss: 1.039 | Acc: 74.077% (23752/32064)
Loss: 1.043 | Acc: 74.004% (28465/38464)
Loss: 1.046 | Acc: 73.950% (33177/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5013, Accuracy: 5855/10000 (58.55%)

Epoch: 122
Loss: 1.119 | Acc: 70.312% (45/64)
Loss: 1.025 | Acc: 74.257% (4800/6464)
Loss: 1.020 | Acc: 74.510% (9585/12864)
Loss: 1.025 | Acc: 74.320% (14317/19264)
Loss: 1.022 | Acc: 74.423% (19100/25664)
Loss: 1.027 | Acc: 74.323% (23831/32064)
Loss: 1.029 | Acc: 74.238% (28555/38464)
Loss: 1.033 | Acc: 74.082% (33236/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3340, Accuracy: 6364/10000 (63.64%)

Epoch: 123
Loss: 0.897 | Acc: 75.000% (48/64)
Loss: 1.008 | Acc: 74.489% (4815/6464)
Loss: 1.017 | Acc: 74.541% (9589/12864)
Loss: 1.018 | Acc: 74.605% (14372/19264)
Loss: 1.016 | Acc: 74.797% (19196/25664)
Loss: 1.021 | Acc: 74.610% (23923/32064)
Loss: 1.025 | Acc: 74.464% (28642/38464)
Loss: 1.027 | Acc: 74.398% (33378/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2200, Accuracy: 6884/10000 (68.84%)

Epoch: 124
Loss: 0.828 | Acc: 84.375% (54/64)
Loss: 1.003 | Acc: 75.464% (4878/6464)
Loss: 0.997 | Acc: 75.272% (9683/12864)
Loss: 1.009 | Acc: 74.964% (14441/19264)
Loss: 1.007 | Acc: 75.051% (19261/25664)
Loss: 1.011 | Acc: 74.847% (23999/32064)
Loss: 1.010 | Acc: 74.927% (28820/38464)
Loss: 1.017 | Acc: 74.784% (33551/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2365, Accuracy: 6821/10000 (68.21%)

Epoch: 125
Loss: 1.037 | Acc: 73.438% (47/64)
Loss: 0.989 | Acc: 75.526% (4882/6464)
Loss: 0.985 | Acc: 75.606% (9726/12864)
Loss: 1.004 | Acc: 75.036% (14455/19264)
Loss: 1.004 | Acc: 75.179% (19294/25664)
Loss: 1.008 | Acc: 75.056% (24066/32064)
Loss: 1.007 | Acc: 75.044% (28865/38464)
Loss: 1.010 | Acc: 74.931% (33617/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5009, Accuracy: 5655/10000 (56.55%)

Epoch: 126
Loss: 0.947 | Acc: 73.438% (47/64)
Loss: 0.964 | Acc: 76.083% (4918/6464)
Loss: 0.967 | Acc: 76.189% (9801/12864)
Loss: 0.982 | Acc: 75.711% (14585/19264)
Loss: 0.985 | Acc: 75.604% (19403/25664)
Loss: 0.990 | Acc: 75.505% (24210/32064)
Loss: 0.991 | Acc: 75.413% (29007/38464)
Loss: 0.994 | Acc: 75.388% (33822/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2280, Accuracy: 6834/10000 (68.34%)

Epoch: 127
Loss: 0.840 | Acc: 82.812% (53/64)
Loss: 0.952 | Acc: 76.439% (4941/6464)
Loss: 0.973 | Acc: 75.785% (9749/12864)
Loss: 0.981 | Acc: 75.659% (14575/19264)
Loss: 0.983 | Acc: 75.686% (19424/25664)
Loss: 0.989 | Acc: 75.543% (24222/32064)
Loss: 0.984 | Acc: 75.645% (29096/38464)
Loss: 0.981 | Acc: 75.814% (34013/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1530, Accuracy: 7117/10000 (71.17%)

Epoch: 128
Loss: 1.255 | Acc: 70.312% (45/64)
Loss: 0.942 | Acc: 76.965% (4975/6464)
Loss: 0.963 | Acc: 76.345% (9821/12864)
Loss: 0.962 | Acc: 76.293% (14697/19264)
Loss: 0.962 | Acc: 76.457% (19622/25664)
Loss: 0.965 | Acc: 76.456% (24515/32064)
Loss: 0.968 | Acc: 76.331% (29360/38464)
Loss: 0.971 | Acc: 76.186% (34180/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3570, Accuracy: 6405/10000 (64.05%)

Epoch: 129
Loss: 1.085 | Acc: 70.312% (45/64)
Loss: 0.943 | Acc: 76.949% (4974/6464)
Loss: 0.946 | Acc: 76.951% (9899/12864)
Loss: 0.937 | Acc: 77.222% (14876/19264)
Loss: 0.942 | Acc: 77.057% (19776/25664)
Loss: 0.955 | Acc: 76.759% (24612/32064)
Loss: 0.959 | Acc: 76.609% (29467/38464)
Loss: 0.959 | Acc: 76.603% (34367/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5011, Accuracy: 6101/10000 (61.01%)

Epoch: 130
Loss: 1.056 | Acc: 75.000% (48/64)
Loss: 0.943 | Acc: 77.135% (4986/6464)
Loss: 0.964 | Acc: 76.570% (9850/12864)
Loss: 0.955 | Acc: 76.786% (14792/19264)
Loss: 0.953 | Acc: 76.847% (19722/25664)
Loss: 0.950 | Acc: 76.902% (24658/32064)
Loss: 0.948 | Acc: 76.971% (29606/38464)
Loss: 0.948 | Acc: 76.999% (34545/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3038, Accuracy: 6514/10000 (65.14%)

Epoch: 131
Loss: 0.841 | Acc: 81.250% (52/64)
Loss: 0.912 | Acc: 77.429% (5005/6464)
Loss: 0.911 | Acc: 77.596% (9982/12864)
Loss: 0.918 | Acc: 77.544% (14938/19264)
Loss: 0.919 | Acc: 77.568% (19907/25664)
Loss: 0.925 | Acc: 77.473% (24841/32064)
Loss: 0.927 | Acc: 77.467% (29797/38464)
Loss: 0.930 | Acc: 77.376% (34714/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2727, Accuracy: 6687/10000 (66.87%)

Epoch: 132
Loss: 1.140 | Acc: 73.438% (47/64)
Loss: 0.908 | Acc: 78.218% (5056/6464)
Loss: 0.909 | Acc: 78.094% (10046/12864)
Loss: 0.906 | Acc: 78.068% (15039/19264)
Loss: 0.911 | Acc: 77.872% (19985/25664)
Loss: 0.914 | Acc: 77.710% (24917/32064)
Loss: 0.913 | Acc: 77.849% (29944/38464)
Loss: 0.913 | Acc: 77.866% (34934/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2321, Accuracy: 6874/10000 (68.74%)

Epoch: 133
Loss: 0.908 | Acc: 78.125% (50/64)
Loss: 0.858 | Acc: 79.162% (5117/6464)
Loss: 0.881 | Acc: 78.584% (10109/12864)
Loss: 0.892 | Acc: 78.379% (15099/19264)
Loss: 0.894 | Acc: 78.285% (20091/25664)
Loss: 0.899 | Acc: 78.150% (25058/32064)
Loss: 0.898 | Acc: 78.177% (30070/38464)
Loss: 0.895 | Acc: 78.301% (35129/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2113, Accuracy: 6995/10000 (69.95%)

Epoch: 134
Loss: 0.913 | Acc: 79.688% (51/64)
Loss: 0.854 | Acc: 79.363% (5130/6464)
Loss: 0.860 | Acc: 79.206% (10189/12864)
Loss: 0.864 | Acc: 79.096% (15237/19264)
Loss: 0.863 | Acc: 79.052% (20288/25664)
Loss: 0.869 | Acc: 78.898% (25298/32064)
Loss: 0.868 | Acc: 78.879% (30340/38464)
Loss: 0.868 | Acc: 78.901% (35398/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1824, Accuracy: 7095/10000 (70.95%)

Epoch: 135
Loss: 0.944 | Acc: 78.125% (50/64)
Loss: 0.809 | Acc: 80.291% (5190/6464)
Loss: 0.823 | Acc: 80.006% (10292/12864)
Loss: 0.832 | Acc: 79.739% (15361/19264)
Loss: 0.840 | Acc: 79.442% (20388/25664)
Loss: 0.843 | Acc: 79.385% (25454/32064)
Loss: 0.849 | Acc: 79.290% (30498/38464)
Loss: 0.847 | Acc: 79.380% (35613/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1666, Accuracy: 7200/10000 (72.00%)

Epoch: 136
Loss: 1.196 | Acc: 71.875% (46/64)
Loss: 0.812 | Acc: 80.074% (5176/6464)
Loss: 0.817 | Acc: 79.998% (10291/12864)
Loss: 0.811 | Acc: 80.191% (15448/19264)
Loss: 0.819 | Acc: 80.034% (20540/25664)
Loss: 0.819 | Acc: 80.074% (25675/32064)
Loss: 0.824 | Acc: 79.979% (30763/38464)
Loss: 0.825 | Acc: 79.962% (35874/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2631, Accuracy: 6866/10000 (68.66%)

Epoch: 137
Loss: 0.711 | Acc: 82.812% (53/64)
Loss: 0.791 | Acc: 80.709% (5217/6464)
Loss: 0.780 | Acc: 80.955% (10414/12864)
Loss: 0.788 | Acc: 80.741% (15554/19264)
Loss: 0.785 | Acc: 80.817% (20741/25664)
Loss: 0.791 | Acc: 80.720% (25882/32064)
Loss: 0.794 | Acc: 80.688% (31036/38464)
Loss: 0.793 | Acc: 80.720% (36214/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2322, Accuracy: 6994/10000 (69.94%)

Epoch: 138
Loss: 0.815 | Acc: 79.688% (51/64)
Loss: 0.755 | Acc: 81.265% (5253/6464)
Loss: 0.758 | Acc: 81.032% (10424/12864)
Loss: 0.761 | Acc: 81.048% (15613/19264)
Loss: 0.753 | Acc: 81.285% (20861/25664)
Loss: 0.759 | Acc: 81.160% (26023/32064)
Loss: 0.755 | Acc: 81.286% (31266/38464)
Loss: 0.758 | Acc: 81.252% (36453/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1911, Accuracy: 7269/10000 (72.69%)

Epoch: 139
Loss: 0.541 | Acc: 85.938% (55/64)
Loss: 0.708 | Acc: 82.132% (5309/6464)
Loss: 0.707 | Acc: 82.331% (10591/12864)
Loss: 0.708 | Acc: 82.330% (15860/19264)
Loss: 0.715 | Acc: 82.209% (21098/25664)
Loss: 0.720 | Acc: 82.042% (26306/32064)
Loss: 0.721 | Acc: 82.048% (31559/38464)
Loss: 0.725 | Acc: 81.981% (36780/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2665, Accuracy: 7031/10000 (70.31%)

Epoch: 140
Loss: 0.511 | Acc: 84.375% (54/64)
Loss: 0.660 | Acc: 83.478% (5396/6464)
Loss: 0.676 | Acc: 83.061% (10685/12864)
Loss: 0.677 | Acc: 82.968% (15983/19264)
Loss: 0.679 | Acc: 82.922% (21281/25664)
Loss: 0.675 | Acc: 83.071% (26636/32064)
Loss: 0.679 | Acc: 83.013% (31930/38464)
Loss: 0.680 | Acc: 82.977% (37227/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2675, Accuracy: 7170/10000 (71.70%)

Epoch: 141
Loss: 0.569 | Acc: 82.812% (53/64)
Loss: 0.616 | Acc: 84.669% (5473/6464)
Loss: 0.630 | Acc: 84.095% (10818/12864)
Loss: 0.636 | Acc: 83.840% (16151/19264)
Loss: 0.643 | Acc: 83.631% (21463/25664)
Loss: 0.640 | Acc: 83.739% (26850/32064)
Loss: 0.637 | Acc: 83.772% (32222/38464)
Loss: 0.642 | Acc: 83.631% (37520/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3013, Accuracy: 7109/10000 (71.09%)

Epoch: 142
Loss: 0.701 | Acc: 81.250% (52/64)
Loss: 0.605 | Acc: 84.421% (5457/6464)
Loss: 0.597 | Acc: 84.453% (10864/12864)
Loss: 0.598 | Acc: 84.344% (16248/19264)
Loss: 0.592 | Acc: 84.539% (21696/25664)
Loss: 0.591 | Acc: 84.606% (27128/32064)
Loss: 0.592 | Acc: 84.596% (32539/38464)
Loss: 0.594 | Acc: 84.551% (37933/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3324, Accuracy: 7134/10000 (71.34%)

Epoch: 143
Loss: 0.480 | Acc: 89.062% (57/64)
Loss: 0.531 | Acc: 86.015% (5560/6464)
Loss: 0.542 | Acc: 85.720% (11027/12864)
Loss: 0.540 | Acc: 85.844% (16537/19264)
Loss: 0.544 | Acc: 85.673% (21987/25664)
Loss: 0.544 | Acc: 85.663% (27467/32064)
Loss: 0.544 | Acc: 85.670% (32952/38464)
Loss: 0.544 | Acc: 85.646% (38424/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3439, Accuracy: 7077/10000 (70.77%)

Epoch: 144
Loss: 0.526 | Acc: 87.500% (56/64)
Loss: 0.490 | Acc: 86.788% (5610/6464)
Loss: 0.501 | Acc: 86.435% (11119/12864)
Loss: 0.499 | Acc: 86.534% (16670/19264)
Loss: 0.496 | Acc: 86.580% (22220/25664)
Loss: 0.492 | Acc: 86.708% (27802/32064)
Loss: 0.492 | Acc: 86.678% (33340/38464)
Loss: 0.493 | Acc: 86.682% (38889/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4223, Accuracy: 7092/10000 (70.92%)

Epoch: 145
Loss: 0.462 | Acc: 85.938% (55/64)
Loss: 0.449 | Acc: 87.717% (5670/6464)
Loss: 0.471 | Acc: 87.197% (11217/12864)
Loss: 0.485 | Acc: 86.908% (16742/19264)
Loss: 0.502 | Acc: 86.514% (22203/25664)
Loss: 0.514 | Acc: 86.318% (27677/32064)
Loss: 0.527 | Acc: 85.984% (33073/38464)
Loss: 0.537 | Acc: 85.828% (38506/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2663, Accuracy: 7128/10000 (71.28%)

Epoch: 146
Loss: 0.776 | Acc: 76.562% (49/64)
Loss: 0.566 | Acc: 85.210% (5508/6464)
Loss: 0.589 | Acc: 84.670% (10892/12864)
Loss: 0.603 | Acc: 84.282% (16236/19264)
Loss: 0.604 | Acc: 84.250% (21622/25664)
Loss: 0.610 | Acc: 84.135% (26977/32064)
Loss: 0.620 | Acc: 83.847% (32251/38464)
Loss: 0.621 | Acc: 83.818% (37604/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2500, Accuracy: 7152/10000 (71.52%)

Epoch: 147
Loss: 0.542 | Acc: 84.375% (54/64)
Loss: 0.616 | Acc: 84.081% (5435/6464)
Loss: 0.621 | Acc: 84.118% (10821/12864)
Loss: 0.641 | Acc: 83.518% (16089/19264)
Loss: 0.637 | Acc: 83.755% (21495/25664)
Loss: 0.644 | Acc: 83.564% (26794/32064)
Loss: 0.649 | Acc: 83.457% (32101/38464)
Loss: 0.651 | Acc: 83.396% (37415/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2485, Accuracy: 7151/10000 (71.51%)
torch.Size([100, 10])
Test set: Average loss: 1.2485, Accuracy: 7151/10000 (71.51%)

Epoch: 148
Loss: 0.465 | Acc: 90.625% (58/64)
Loss: 0.652 | Acc: 82.921% (5360/6464)
Loss: 0.650 | Acc: 83.201% (10703/12864)
Loss: 0.650 | Acc: 83.285% (16044/19264)
Loss: 0.652 | Acc: 83.210% (21355/25664)
Loss: 0.652 | Acc: 83.274% (26701/32064)
Loss: 0.656 | Acc: 83.161% (31987/38464)
Loss: 0.660 | Acc: 83.100% (37282/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2395, Accuracy: 7183/10000 (71.83%)
torch.Size([100, 10])
Test set: Average loss: 1.2395, Accuracy: 7183/10000 (71.83%)

Epoch: 149
Loss: 0.512 | Acc: 90.625% (58/64)
Loss: 0.675 | Acc: 83.014% (5366/6464)
Loss: 0.661 | Acc: 83.294% (10715/12864)
Loss: 0.659 | Acc: 83.332% (16053/19264)
Loss: 0.658 | Acc: 83.284% (21374/25664)
Loss: 0.658 | Acc: 83.293% (26707/32064)
Loss: 0.665 | Acc: 83.057% (31947/38464)
Loss: 0.660 | Acc: 83.196% (37325/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2408, Accuracy: 7161/10000 (71.61%)
torch.Size([100, 10])
Test set: Average loss: 1.2408, Accuracy: 7161/10000 (71.61%)

Epoch: 150
Loss: 0.579 | Acc: 82.812% (53/64)
Loss: 1.856 | Acc: 38.057% (2460/6464)
Loss: 1.610 | Acc: 49.526% (6371/12864)
Loss: 1.501 | Acc: 54.366% (10473/19264)
Loss: 1.438 | Acc: 57.290% (14703/25664)
Loss: 1.390 | Acc: 59.509% (19081/32064)
Loss: 1.354 | Acc: 61.039% (23478/38464)
Loss: 1.329 | Acc: 62.099% (27860/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7836, Accuracy: 4767/10000 (47.67%)

Epoch: 151
Loss: 0.918 | Acc: 76.562% (49/64)
Loss: 1.163 | Acc: 68.998% (4460/6464)
Loss: 1.157 | Acc: 69.349% (8921/12864)
Loss: 1.165 | Acc: 69.160% (13323/19264)
Loss: 1.159 | Acc: 69.373% (17804/25664)
Loss: 1.154 | Acc: 69.570% (22307/32064)
Loss: 1.151 | Acc: 69.730% (26821/38464)
Loss: 1.151 | Acc: 69.700% (31270/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6618, Accuracy: 5337/10000 (53.37%)

Epoch: 152
Loss: 1.101 | Acc: 70.312% (45/64)
Loss: 1.108 | Acc: 71.380% (4614/6464)
Loss: 1.101 | Acc: 71.502% (9198/12864)
Loss: 1.121 | Acc: 70.935% (13665/19264)
Loss: 1.128 | Acc: 70.671% (18137/25664)
Loss: 1.132 | Acc: 70.509% (22608/32064)
Loss: 1.134 | Acc: 70.565% (27142/38464)
Loss: 1.128 | Acc: 70.720% (31728/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5110, Accuracy: 5606/10000 (56.06%)

Epoch: 153
Loss: 1.039 | Acc: 73.438% (47/64)
Loss: 1.125 | Acc: 70.684% (4569/6464)
Loss: 1.096 | Acc: 71.595% (9210/12864)
Loss: 1.114 | Acc: 71.226% (13721/19264)
Loss: 1.109 | Acc: 71.415% (18328/25664)
Loss: 1.113 | Acc: 71.286% (22857/32064)
Loss: 1.116 | Acc: 71.150% (27367/38464)
Loss: 1.118 | Acc: 71.088% (31893/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4939, Accuracy: 5840/10000 (58.40%)

Epoch: 154
Loss: 1.374 | Acc: 65.625% (42/64)
Loss: 1.094 | Acc: 71.241% (4605/6464)
Loss: 1.105 | Acc: 71.090% (9145/12864)
Loss: 1.112 | Acc: 71.174% (13711/19264)
Loss: 1.114 | Acc: 71.205% (18274/25664)
Loss: 1.117 | Acc: 71.161% (22817/32064)
Loss: 1.116 | Acc: 71.191% (27383/38464)
Loss: 1.118 | Acc: 71.193% (31940/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7509, Accuracy: 4829/10000 (48.29%)

Epoch: 155
Loss: 1.362 | Acc: 57.812% (37/64)
Loss: 1.116 | Acc: 70.916% (4584/6464)
Loss: 1.114 | Acc: 71.160% (9154/12864)
Loss: 1.099 | Acc: 71.538% (13781/19264)
Loss: 1.107 | Acc: 71.306% (18300/25664)
Loss: 1.107 | Acc: 71.335% (22873/32064)
Loss: 1.112 | Acc: 71.264% (27411/38464)
Loss: 1.113 | Acc: 71.255% (31968/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4311, Accuracy: 5954/10000 (59.54%)

Epoch: 156
Loss: 0.799 | Acc: 84.375% (54/64)
Loss: 1.113 | Acc: 71.829% (4643/6464)
Loss: 1.100 | Acc: 71.743% (9229/12864)
Loss: 1.093 | Acc: 71.953% (13861/19264)
Loss: 1.095 | Acc: 71.848% (18439/25664)
Loss: 1.101 | Acc: 71.622% (22965/32064)
Loss: 1.107 | Acc: 71.485% (27496/38464)
Loss: 1.111 | Acc: 71.291% (31984/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5645, Accuracy: 5609/10000 (56.09%)

Epoch: 157
Loss: 1.003 | Acc: 70.312% (45/64)
Loss: 1.096 | Acc: 71.720% (4636/6464)
Loss: 1.096 | Acc: 71.867% (9245/12864)
Loss: 1.106 | Acc: 71.480% (13770/19264)
Loss: 1.109 | Acc: 71.392% (18322/25664)
Loss: 1.110 | Acc: 71.410% (22897/32064)
Loss: 1.107 | Acc: 71.490% (27498/38464)
Loss: 1.106 | Acc: 71.587% (32117/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4245, Accuracy: 6090/10000 (60.90%)

Epoch: 158
Loss: 1.418 | Acc: 59.375% (38/64)
Loss: 1.107 | Acc: 71.148% (4599/6464)
Loss: 1.103 | Acc: 71.401% (9185/12864)
Loss: 1.101 | Acc: 71.574% (13788/19264)
Loss: 1.102 | Acc: 71.559% (18365/25664)
Loss: 1.102 | Acc: 71.694% (22988/32064)
Loss: 1.102 | Acc: 71.670% (27567/38464)
Loss: 1.106 | Acc: 71.554% (32102/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4130, Accuracy: 6240/10000 (62.40%)

Epoch: 159
Loss: 1.020 | Acc: 78.125% (50/64)
Loss: 1.090 | Acc: 72.184% (4666/6464)
Loss: 1.092 | Acc: 72.116% (9277/12864)
Loss: 1.091 | Acc: 72.161% (13901/19264)
Loss: 1.096 | Acc: 71.961% (18468/25664)
Loss: 1.094 | Acc: 72.078% (23111/32064)
Loss: 1.098 | Acc: 71.974% (27684/38464)
Loss: 1.102 | Acc: 71.844% (32232/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7904, Accuracy: 4911/10000 (49.11%)

Epoch: 160
Loss: 1.158 | Acc: 67.188% (43/64)
Loss: 1.102 | Acc: 71.643% (4631/6464)
Loss: 1.098 | Acc: 71.751% (9230/12864)
Loss: 1.092 | Acc: 71.979% (13866/19264)
Loss: 1.093 | Acc: 71.945% (18464/25664)
Loss: 1.091 | Acc: 72.115% (23123/32064)
Loss: 1.096 | Acc: 71.909% (27659/38464)
Loss: 1.098 | Acc: 71.882% (32249/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5537, Accuracy: 5455/10000 (54.55%)

Epoch: 161
Loss: 1.620 | Acc: 56.250% (36/64)
Loss: 1.100 | Acc: 71.983% (4653/6464)
Loss: 1.091 | Acc: 72.163% (9283/12864)
Loss: 1.102 | Acc: 71.891% (13849/19264)
Loss: 1.103 | Acc: 71.984% (18474/25664)
Loss: 1.103 | Acc: 71.891% (23051/32064)
Loss: 1.105 | Acc: 71.787% (27612/38464)
Loss: 1.103 | Acc: 71.835% (32228/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4989, Accuracy: 5702/10000 (57.02%)

Epoch: 162
Loss: 1.220 | Acc: 67.188% (43/64)
Loss: 1.086 | Acc: 71.860% (4645/6464)
Loss: 1.080 | Acc: 72.497% (9326/12864)
Loss: 1.075 | Acc: 72.711% (14007/19264)
Loss: 1.083 | Acc: 72.565% (18623/25664)
Loss: 1.089 | Acc: 72.243% (23164/32064)
Loss: 1.091 | Acc: 72.218% (27778/38464)
Loss: 1.093 | Acc: 72.180% (32383/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4898, Accuracy: 5828/10000 (58.28%)

Epoch: 163
Loss: 1.017 | Acc: 75.000% (48/64)
Loss: 1.056 | Acc: 73.035% (4721/6464)
Loss: 1.069 | Acc: 72.683% (9350/12864)
Loss: 1.078 | Acc: 72.379% (13943/19264)
Loss: 1.081 | Acc: 72.350% (18568/25664)
Loss: 1.084 | Acc: 72.321% (23189/32064)
Loss: 1.089 | Acc: 72.223% (27780/38464)
Loss: 1.091 | Acc: 72.140% (32365/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3091, Accuracy: 6446/10000 (64.46%)

Epoch: 164
Loss: 1.091 | Acc: 71.875% (46/64)
Loss: 1.078 | Acc: 72.664% (4697/6464)
Loss: 1.056 | Acc: 73.298% (9429/12864)
Loss: 1.067 | Acc: 73.001% (14063/19264)
Loss: 1.074 | Acc: 72.709% (18660/25664)
Loss: 1.076 | Acc: 72.677% (23303/32064)
Loss: 1.079 | Acc: 72.676% (27954/38464)
Loss: 1.084 | Acc: 72.423% (32492/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2958, Accuracy: 6511/10000 (65.11%)

Epoch: 165
Loss: 1.317 | Acc: 67.188% (43/64)
Loss: 1.102 | Acc: 71.597% (4628/6464)
Loss: 1.086 | Acc: 72.069% (9271/12864)
Loss: 1.077 | Acc: 72.498% (13966/19264)
Loss: 1.077 | Acc: 72.584% (18628/25664)
Loss: 1.081 | Acc: 72.577% (23271/32064)
Loss: 1.077 | Acc: 72.660% (27948/38464)
Loss: 1.078 | Acc: 72.673% (32604/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4671, Accuracy: 5949/10000 (59.49%)

Epoch: 166
Loss: 1.253 | Acc: 65.625% (42/64)
Loss: 1.045 | Acc: 73.824% (4772/6464)
Loss: 1.053 | Acc: 73.609% (9469/12864)
Loss: 1.052 | Acc: 73.521% (14163/19264)
Loss: 1.062 | Acc: 73.212% (18789/25664)
Loss: 1.066 | Acc: 73.063% (23427/32064)
Loss: 1.071 | Acc: 72.837% (28016/38464)
Loss: 1.073 | Acc: 72.831% (32675/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7470, Accuracy: 4958/10000 (49.58%)

Epoch: 167
Loss: 0.836 | Acc: 81.250% (52/64)
Loss: 1.067 | Acc: 72.664% (4697/6464)
Loss: 1.071 | Acc: 72.746% (9358/12864)
Loss: 1.070 | Acc: 72.851% (14034/19264)
Loss: 1.067 | Acc: 72.997% (18734/25664)
Loss: 1.064 | Acc: 73.091% (23436/32064)
Loss: 1.063 | Acc: 73.170% (28144/38464)
Loss: 1.067 | Acc: 73.083% (32788/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5533, Accuracy: 5697/10000 (56.97%)

Epoch: 168
Loss: 0.830 | Acc: 76.562% (49/64)
Loss: 1.046 | Acc: 73.515% (4752/6464)
Loss: 1.057 | Acc: 73.228% (9420/12864)
Loss: 1.057 | Acc: 73.188% (14099/19264)
Loss: 1.058 | Acc: 73.184% (18782/25664)
Loss: 1.059 | Acc: 73.294% (23501/32064)
Loss: 1.061 | Acc: 73.214% (28161/38464)
Loss: 1.060 | Acc: 73.250% (32863/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3883, Accuracy: 6170/10000 (61.70%)

Epoch: 169
Loss: 1.112 | Acc: 67.188% (43/64)
Loss: 1.042 | Acc: 73.530% (4753/6464)
Loss: 1.051 | Acc: 73.476% (9452/12864)
Loss: 1.061 | Acc: 73.297% (14120/19264)
Loss: 1.054 | Acc: 73.535% (18872/25664)
Loss: 1.059 | Acc: 73.500% (23567/32064)
Loss: 1.056 | Acc: 73.583% (28303/38464)
Loss: 1.057 | Acc: 73.553% (32999/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5497, Accuracy: 5586/10000 (55.86%)

Epoch: 170
Loss: 1.443 | Acc: 59.375% (38/64)
Loss: 1.029 | Acc: 74.428% (4811/6464)
Loss: 1.032 | Acc: 74.192% (9544/12864)
Loss: 1.041 | Acc: 73.946% (14245/19264)
Loss: 1.045 | Acc: 73.851% (18953/25664)
Loss: 1.047 | Acc: 73.718% (23637/32064)
Loss: 1.044 | Acc: 73.820% (28394/38464)
Loss: 1.047 | Acc: 73.721% (33074/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4440, Accuracy: 6123/10000 (61.23%)

Epoch: 171
Loss: 1.047 | Acc: 75.000% (48/64)
Loss: 1.010 | Acc: 75.263% (4865/6464)
Loss: 1.019 | Acc: 74.837% (9627/12864)
Loss: 1.020 | Acc: 74.683% (14387/19264)
Loss: 1.028 | Acc: 74.377% (19088/25664)
Loss: 1.033 | Acc: 74.267% (23813/32064)
Loss: 1.036 | Acc: 74.134% (28515/38464)
Loss: 1.038 | Acc: 74.111% (33249/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3342, Accuracy: 6299/10000 (62.99%)

Epoch: 172
Loss: 1.236 | Acc: 67.188% (43/64)
Loss: 1.030 | Acc: 74.010% (4784/6464)
Loss: 1.024 | Acc: 74.339% (9563/12864)
Loss: 1.021 | Acc: 74.564% (14364/19264)
Loss: 1.024 | Acc: 74.400% (19094/25664)
Loss: 1.025 | Acc: 74.373% (23847/32064)
Loss: 1.026 | Acc: 74.371% (28606/38464)
Loss: 1.029 | Acc: 74.302% (33335/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4085, Accuracy: 6122/10000 (61.22%)

Epoch: 173
Loss: 1.009 | Acc: 73.438% (47/64)
Loss: 1.033 | Acc: 74.087% (4789/6464)
Loss: 1.021 | Acc: 74.300% (9558/12864)
Loss: 1.024 | Acc: 74.351% (14323/19264)
Loss: 1.026 | Acc: 74.408% (19096/25664)
Loss: 1.026 | Acc: 74.417% (23861/32064)
Loss: 1.025 | Acc: 74.511% (28660/38464)
Loss: 1.024 | Acc: 74.501% (33424/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3099, Accuracy: 6552/10000 (65.52%)

Epoch: 174
Loss: 1.252 | Acc: 64.062% (41/64)
Loss: 1.004 | Acc: 74.892% (4841/6464)
Loss: 1.003 | Acc: 74.961% (9643/12864)
Loss: 0.994 | Acc: 75.145% (14476/19264)
Loss: 1.002 | Acc: 74.981% (19243/25664)
Loss: 1.006 | Acc: 74.881% (24010/32064)
Loss: 1.005 | Acc: 74.883% (28803/38464)
Loss: 1.008 | Acc: 74.866% (33588/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2067, Accuracy: 6919/10000 (69.19%)

Epoch: 175
Loss: 1.243 | Acc: 67.188% (43/64)
Loss: 0.981 | Acc: 76.176% (4924/6464)
Loss: 0.973 | Acc: 76.228% (9806/12864)
Loss: 0.982 | Acc: 75.867% (14615/19264)
Loss: 0.992 | Acc: 75.608% (19404/25664)
Loss: 0.987 | Acc: 75.630% (24250/32064)
Loss: 0.990 | Acc: 75.463% (29026/38464)
Loss: 0.995 | Acc: 75.312% (33788/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2833, Accuracy: 6542/10000 (65.42%)

Epoch: 176
Loss: 1.044 | Acc: 78.125% (50/64)
Loss: 0.987 | Acc: 76.346% (4935/6464)
Loss: 0.994 | Acc: 75.964% (9772/12864)
Loss: 0.989 | Acc: 75.872% (14616/19264)
Loss: 0.990 | Acc: 75.787% (19450/25664)
Loss: 0.992 | Acc: 75.599% (24240/32064)
Loss: 0.989 | Acc: 75.694% (29115/38464)
Loss: 0.988 | Acc: 75.715% (33969/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3426, Accuracy: 6395/10000 (63.95%)

Epoch: 177
Loss: 0.905 | Acc: 79.688% (51/64)
Loss: 1.003 | Acc: 74.923% (4843/6464)
Loss: 0.979 | Acc: 75.684% (9736/12864)
Loss: 0.979 | Acc: 75.872% (14616/19264)
Loss: 0.980 | Acc: 75.826% (19460/25664)
Loss: 0.983 | Acc: 75.798% (24304/32064)
Loss: 0.986 | Acc: 75.689% (29113/38464)
Loss: 0.982 | Acc: 75.840% (34025/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5895, Accuracy: 5682/10000 (56.82%)

Epoch: 178
Loss: 0.874 | Acc: 76.562% (49/64)
Loss: 0.926 | Acc: 77.027% (4979/6464)
Loss: 0.948 | Acc: 76.687% (9865/12864)
Loss: 0.957 | Acc: 76.490% (14735/19264)
Loss: 0.960 | Acc: 76.414% (19611/25664)
Loss: 0.961 | Acc: 76.438% (24509/32064)
Loss: 0.962 | Acc: 76.412% (29391/38464)
Loss: 0.965 | Acc: 76.360% (34258/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3795, Accuracy: 6306/10000 (63.06%)

Epoch: 179
Loss: 1.017 | Acc: 73.438% (47/64)
Loss: 0.960 | Acc: 76.501% (4945/6464)
Loss: 0.957 | Acc: 76.718% (9869/12864)
Loss: 0.950 | Acc: 76.895% (14813/19264)
Loss: 0.952 | Acc: 76.855% (19724/25664)
Loss: 0.949 | Acc: 76.959% (24676/32064)
Loss: 0.944 | Acc: 77.093% (29653/38464)
Loss: 0.948 | Acc: 76.977% (34535/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2378, Accuracy: 6832/10000 (68.32%)

Epoch: 180
Loss: 0.670 | Acc: 81.250% (52/64)
Loss: 0.929 | Acc: 77.429% (5005/6464)
Loss: 0.934 | Acc: 77.231% (9935/12864)
Loss: 0.926 | Acc: 77.424% (14915/19264)
Loss: 0.924 | Acc: 77.579% (19910/25664)
Loss: 0.930 | Acc: 77.464% (24838/32064)
Loss: 0.934 | Acc: 77.353% (29753/38464)
Loss: 0.938 | Acc: 77.204% (34637/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2583, Accuracy: 6756/10000 (67.56%)

Epoch: 181
Loss: 0.976 | Acc: 76.562% (49/64)
Loss: 0.902 | Acc: 77.893% (5035/6464)
Loss: 0.891 | Acc: 78.242% (10065/12864)
Loss: 0.899 | Acc: 78.021% (15030/19264)
Loss: 0.908 | Acc: 77.844% (19978/25664)
Loss: 0.909 | Acc: 77.832% (24956/32064)
Loss: 0.915 | Acc: 77.722% (29895/38464)
Loss: 0.919 | Acc: 77.583% (34807/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3711, Accuracy: 6362/10000 (63.62%)

Epoch: 182
Loss: 1.134 | Acc: 70.312% (45/64)
Loss: 0.900 | Acc: 77.522% (5011/6464)
Loss: 0.871 | Acc: 78.584% (10109/12864)
Loss: 0.885 | Acc: 78.333% (15090/19264)
Loss: 0.891 | Acc: 78.203% (20070/25664)
Loss: 0.897 | Acc: 78.109% (25045/32064)
Loss: 0.900 | Acc: 78.050% (30021/38464)
Loss: 0.902 | Acc: 78.018% (35002/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2424, Accuracy: 6880/10000 (68.80%)

Epoch: 183
Loss: 0.887 | Acc: 82.812% (53/64)
Loss: 0.859 | Acc: 78.976% (5105/6464)
Loss: 0.868 | Acc: 78.972% (10159/12864)
Loss: 0.877 | Acc: 78.774% (15175/19264)
Loss: 0.879 | Acc: 78.721% (20203/25664)
Loss: 0.881 | Acc: 78.602% (25203/32064)
Loss: 0.883 | Acc: 78.559% (30217/38464)
Loss: 0.884 | Acc: 78.551% (35241/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2540, Accuracy: 6856/10000 (68.56%)

Epoch: 184
Loss: 0.818 | Acc: 78.125% (50/64)
Loss: 0.842 | Acc: 79.270% (5124/6464)
Loss: 0.854 | Acc: 79.112% (10177/12864)
Loss: 0.862 | Acc: 79.044% (15227/19264)
Loss: 0.859 | Acc: 79.169% (20318/25664)
Loss: 0.857 | Acc: 79.235% (25406/32064)
Loss: 0.860 | Acc: 79.144% (30442/38464)
Loss: 0.859 | Acc: 79.195% (35530/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1890, Accuracy: 7096/10000 (70.96%)

Epoch: 185
Loss: 0.987 | Acc: 75.000% (48/64)
Loss: 0.800 | Acc: 80.136% (5180/6464)
Loss: 0.809 | Acc: 80.115% (10306/12864)
Loss: 0.812 | Acc: 80.217% (15453/19264)
Loss: 0.825 | Acc: 79.929% (20513/25664)
Loss: 0.830 | Acc: 79.744% (25569/32064)
Loss: 0.831 | Acc: 79.745% (30673/38464)
Loss: 0.836 | Acc: 79.645% (35732/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1534, Accuracy: 7246/10000 (72.46%)

Epoch: 186
Loss: 0.429 | Acc: 93.750% (60/64)
Loss: 0.790 | Acc: 80.662% (5214/6464)
Loss: 0.802 | Acc: 80.473% (10352/12864)
Loss: 0.812 | Acc: 80.290% (15467/19264)
Loss: 0.815 | Acc: 80.342% (20619/25664)
Loss: 0.819 | Acc: 80.193% (25713/32064)
Loss: 0.815 | Acc: 80.218% (30855/38464)
Loss: 0.815 | Acc: 80.178% (35971/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2052, Accuracy: 7188/10000 (71.88%)

Epoch: 187
Loss: 0.582 | Acc: 87.500% (56/64)
Loss: 0.784 | Acc: 80.476% (5202/6464)
Loss: 0.782 | Acc: 80.822% (10397/12864)
Loss: 0.780 | Acc: 80.809% (15567/19264)
Loss: 0.786 | Acc: 80.697% (20710/25664)
Loss: 0.786 | Acc: 80.698% (25875/32064)
Loss: 0.788 | Acc: 80.668% (31028/38464)
Loss: 0.793 | Acc: 80.552% (36139/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2005, Accuracy: 7187/10000 (71.87%)

Epoch: 188
Loss: 0.643 | Acc: 85.938% (55/64)
Loss: 0.773 | Acc: 80.817% (5224/6464)
Loss: 0.763 | Acc: 81.009% (10421/12864)
Loss: 0.761 | Acc: 81.079% (15619/19264)
Loss: 0.759 | Acc: 81.149% (20826/25664)
Loss: 0.757 | Acc: 81.278% (26061/32064)
Loss: 0.755 | Acc: 81.341% (31287/38464)
Loss: 0.758 | Acc: 81.328% (36487/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2220, Accuracy: 7216/10000 (72.16%)

Epoch: 189
Loss: 0.540 | Acc: 85.938% (55/64)
Loss: 0.683 | Acc: 83.060% (5369/6464)
Loss: 0.696 | Acc: 82.743% (10644/12864)
Loss: 0.700 | Acc: 82.740% (15939/19264)
Loss: 0.706 | Acc: 82.536% (21182/25664)
Loss: 0.710 | Acc: 82.444% (26435/32064)
Loss: 0.712 | Acc: 82.368% (31682/38464)
Loss: 0.718 | Acc: 82.204% (36880/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2373, Accuracy: 7261/10000 (72.61%)

Epoch: 190
Loss: 0.724 | Acc: 81.250% (52/64)
Loss: 0.655 | Acc: 83.338% (5387/6464)
Loss: 0.658 | Acc: 83.326% (10719/12864)
Loss: 0.665 | Acc: 83.124% (16013/19264)
Loss: 0.667 | Acc: 83.206% (21354/25664)
Loss: 0.667 | Acc: 83.283% (26704/32064)
Loss: 0.669 | Acc: 83.210% (32006/38464)
Loss: 0.673 | Acc: 83.136% (37298/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3014, Accuracy: 7097/10000 (70.97%)

Epoch: 191
Loss: 0.817 | Acc: 79.688% (51/64)
Loss: 0.603 | Acc: 84.545% (5465/6464)
Loss: 0.602 | Acc: 84.686% (10894/12864)
Loss: 0.614 | Acc: 84.437% (16266/19264)
Loss: 0.616 | Acc: 84.340% (21645/25664)
Loss: 0.618 | Acc: 84.319% (27036/32064)
Loss: 0.625 | Acc: 84.125% (32358/38464)
Loss: 0.627 | Acc: 84.092% (37727/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3179, Accuracy: 7136/10000 (71.36%)

Epoch: 192
Loss: 0.737 | Acc: 81.250% (52/64)
Loss: 0.590 | Acc: 84.777% (5480/6464)
Loss: 0.574 | Acc: 85.121% (10950/12864)
Loss: 0.576 | Acc: 85.086% (16391/19264)
Loss: 0.579 | Acc: 84.889% (21786/25664)
Loss: 0.587 | Acc: 84.721% (27165/32064)
Loss: 0.586 | Acc: 84.840% (32633/38464)
Loss: 0.587 | Acc: 84.810% (38049/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3538, Accuracy: 7132/10000 (71.32%)

Epoch: 193
Loss: 0.490 | Acc: 85.938% (55/64)
Loss: 0.529 | Acc: 85.922% (5554/6464)
Loss: 0.540 | Acc: 85.619% (11014/12864)
Loss: 0.538 | Acc: 85.725% (16514/19264)
Loss: 0.539 | Acc: 85.657% (21983/25664)
Loss: 0.536 | Acc: 85.813% (27515/32064)
Loss: 0.533 | Acc: 85.896% (33039/38464)
Loss: 0.534 | Acc: 85.851% (38516/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3923, Accuracy: 7045/10000 (70.45%)

Epoch: 194
Loss: 0.502 | Acc: 85.938% (55/64)
Loss: 0.492 | Acc: 86.572% (5596/6464)
Loss: 0.481 | Acc: 86.800% (11166/12864)
Loss: 0.479 | Acc: 86.991% (16758/19264)
Loss: 0.483 | Acc: 86.873% (22295/25664)
Loss: 0.482 | Acc: 86.948% (27879/32064)
Loss: 0.482 | Acc: 86.977% (33455/38464)
Loss: 0.484 | Acc: 86.932% (39001/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4407, Accuracy: 7098/10000 (70.98%)

Epoch: 195
Loss: 0.401 | Acc: 89.062% (57/64)
Loss: 0.440 | Acc: 87.995% (5688/6464)
Loss: 0.460 | Acc: 87.539% (11261/12864)
Loss: 0.480 | Acc: 86.934% (16747/19264)
Loss: 0.492 | Acc: 86.744% (22262/25664)
Loss: 0.503 | Acc: 86.474% (27727/32064)
Loss: 0.514 | Acc: 86.270% (33183/38464)
Loss: 0.525 | Acc: 86.002% (38584/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2945, Accuracy: 7123/10000 (71.23%)

Epoch: 196
Loss: 0.886 | Acc: 73.438% (47/64)
Loss: 0.568 | Acc: 85.241% (5510/6464)
Loss: 0.581 | Acc: 85.067% (10943/12864)
Loss: 0.596 | Acc: 84.551% (16288/19264)
Loss: 0.598 | Acc: 84.539% (21696/25664)
Loss: 0.600 | Acc: 84.450% (27078/32064)
Loss: 0.606 | Acc: 84.318% (32432/38464)
Loss: 0.608 | Acc: 84.293% (37817/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2640, Accuracy: 7157/10000 (71.57%)

Epoch: 197
Loss: 0.548 | Acc: 85.938% (55/64)
Loss: 0.612 | Acc: 84.158% (5440/6464)
Loss: 0.616 | Acc: 83.963% (10801/12864)
Loss: 0.620 | Acc: 83.960% (16174/19264)
Loss: 0.628 | Acc: 83.794% (21505/25664)
Loss: 0.633 | Acc: 83.667% (26827/32064)
Loss: 0.633 | Acc: 83.639% (32171/38464)
Loss: 0.635 | Acc: 83.566% (37491/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2619, Accuracy: 7163/10000 (71.63%)
torch.Size([100, 10])
Test set: Average loss: 1.2619, Accuracy: 7163/10000 (71.63%)

Epoch: 198
Loss: 0.574 | Acc: 85.938% (55/64)
Loss: 0.636 | Acc: 83.864% (5421/6464)
Loss: 0.631 | Acc: 84.002% (10806/12864)
Loss: 0.634 | Acc: 83.975% (16177/19264)
Loss: 0.638 | Acc: 83.833% (21515/25664)
Loss: 0.639 | Acc: 83.776% (26862/32064)
Loss: 0.642 | Acc: 83.665% (32181/38464)
Loss: 0.643 | Acc: 83.613% (37512/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2547, Accuracy: 7124/10000 (71.24%)
torch.Size([100, 10])
Test set: Average loss: 1.2547, Accuracy: 7124/10000 (71.24%)

Epoch: 199
Loss: 0.468 | Acc: 89.062% (57/64)
Loss: 0.644 | Acc: 83.509% (5398/6464)
Loss: 0.637 | Acc: 83.831% (10784/12864)
Loss: 0.644 | Acc: 83.534% (16092/19264)
Loss: 0.641 | Acc: 83.529% (21437/25664)
Loss: 0.644 | Acc: 83.414% (26746/32064)
Loss: 0.637 | Acc: 83.611% (32160/38464)
Loss: 0.637 | Acc: 83.631% (37520/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2620, Accuracy: 7140/10000 (71.40%)
torch.Size([100, 10])
Test set: Average loss: 1.2620, Accuracy: 7140/10000 (71.40%)
7498
10000
-1.103109359741211
