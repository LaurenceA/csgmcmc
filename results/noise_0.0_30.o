==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.361 | Acc: 15.625% (10/64)
Loss: 2.838 | Acc: 16.723% (1081/6464)
Loss: 2.427 | Acc: 19.916% (2562/12864)
Loss: 2.254 | Acc: 22.000% (4238/19264)
Loss: 2.154 | Acc: 23.975% (6153/25664)
Loss: 2.079 | Acc: 25.730% (8250/32064)
Loss: 2.017 | Acc: 27.444% (10556/38464)
Loss: 1.962 | Acc: 29.086% (13049/44864)
torch.Size([100, 10])
Test set: Average loss: 4.4126, Accuracy: 1879/10000 (18.79%)

Epoch: 1
Loss: 2.128 | Acc: 35.938% (23/64)
Loss: 1.566 | Acc: 41.770% (2700/6464)
Loss: 1.540 | Acc: 42.693% (5492/12864)
Loss: 1.524 | Acc: 43.304% (8342/19264)
Loss: 1.506 | Acc: 44.058% (11307/25664)
Loss: 1.485 | Acc: 44.976% (14421/32064)
Loss: 1.468 | Acc: 45.671% (17567/38464)
Loss: 1.448 | Acc: 46.467% (20847/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6661, Accuracy: 4298/10000 (42.98%)

Epoch: 2
Loss: 1.395 | Acc: 51.562% (33/64)
Loss: 1.265 | Acc: 53.914% (3485/6464)
Loss: 1.266 | Acc: 54.377% (6995/12864)
Loss: 1.244 | Acc: 55.227% (10639/19264)
Loss: 1.225 | Acc: 55.958% (14361/25664)
Loss: 1.208 | Acc: 56.659% (18167/32064)
Loss: 1.191 | Acc: 57.243% (22018/38464)
Loss: 1.176 | Acc: 57.739% (25904/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4519, Accuracy: 4969/10000 (49.69%)

Epoch: 3
Loss: 1.032 | Acc: 65.625% (42/64)
Loss: 1.037 | Acc: 63.057% (4076/6464)
Loss: 1.032 | Acc: 63.324% (8146/12864)
Loss: 1.009 | Acc: 63.969% (12323/19264)
Loss: 0.995 | Acc: 64.624% (16585/25664)
Loss: 0.980 | Acc: 65.273% (20929/32064)
Loss: 0.967 | Acc: 65.680% (25263/38464)
Loss: 0.956 | Acc: 66.080% (29646/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7382, Accuracy: 5021/10000 (50.21%)

Epoch: 4
Loss: 1.600 | Acc: 50.000% (32/64)
Loss: 0.841 | Acc: 71.349% (4612/6464)
Loss: 0.829 | Acc: 71.463% (9193/12864)
Loss: 0.821 | Acc: 71.724% (13817/19264)
Loss: 0.810 | Acc: 71.840% (18437/25664)
Loss: 0.800 | Acc: 72.280% (23176/32064)
Loss: 0.788 | Acc: 72.616% (27931/38464)
Loss: 0.781 | Acc: 72.938% (32723/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3253, Accuracy: 5818/10000 (58.18%)

Epoch: 5
Loss: 0.975 | Acc: 67.188% (43/64)
Loss: 0.691 | Acc: 76.145% (4922/6464)
Loss: 0.695 | Acc: 75.964% (9772/12864)
Loss: 0.686 | Acc: 76.329% (14704/19264)
Loss: 0.686 | Acc: 76.301% (19582/25664)
Loss: 0.679 | Acc: 76.578% (24554/32064)
Loss: 0.676 | Acc: 76.648% (29482/38464)
Loss: 0.673 | Acc: 76.866% (34485/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3307, Accuracy: 6191/10000 (61.91%)

Epoch: 6
Loss: 0.595 | Acc: 79.688% (51/64)
Loss: 0.616 | Acc: 78.945% (5103/6464)
Loss: 0.622 | Acc: 78.584% (10109/12864)
Loss: 0.619 | Acc: 78.582% (15138/19264)
Loss: 0.614 | Acc: 78.651% (20185/25664)
Loss: 0.610 | Acc: 78.839% (25279/32064)
Loss: 0.609 | Acc: 78.957% (30370/38464)
Loss: 0.607 | Acc: 79.034% (35458/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3919, Accuracy: 5758/10000 (57.58%)

Epoch: 7
Loss: 0.535 | Acc: 76.562% (49/64)
Loss: 0.564 | Acc: 80.461% (5201/6464)
Loss: 0.573 | Acc: 80.131% (10308/12864)
Loss: 0.564 | Acc: 80.601% (15527/19264)
Loss: 0.564 | Acc: 80.556% (20674/25664)
Loss: 0.559 | Acc: 80.832% (25918/32064)
Loss: 0.561 | Acc: 80.766% (31066/38464)
Loss: 0.562 | Acc: 80.693% (36202/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6544, Accuracy: 7770/10000 (77.70%)

Epoch: 8
Loss: 0.656 | Acc: 82.812% (53/64)
Loss: 0.532 | Acc: 81.776% (5286/6464)
Loss: 0.524 | Acc: 82.113% (10563/12864)
Loss: 0.522 | Acc: 82.184% (15832/19264)
Loss: 0.523 | Acc: 82.119% (21075/25664)
Loss: 0.522 | Acc: 82.117% (26330/32064)
Loss: 0.525 | Acc: 81.968% (31528/38464)
Loss: 0.525 | Acc: 81.921% (36753/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0107, Accuracy: 6755/10000 (67.55%)

Epoch: 9
Loss: 0.471 | Acc: 84.375% (54/64)
Loss: 0.501 | Acc: 82.890% (5358/6464)
Loss: 0.495 | Acc: 82.781% (10649/12864)
Loss: 0.506 | Acc: 82.574% (15907/19264)
Loss: 0.505 | Acc: 82.633% (21207/25664)
Loss: 0.502 | Acc: 82.781% (26543/32064)
Loss: 0.504 | Acc: 82.753% (31830/38464)
Loss: 0.501 | Acc: 82.859% (37174/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9133, Accuracy: 6979/10000 (69.79%)

Epoch: 10
Loss: 0.722 | Acc: 71.875% (46/64)
Loss: 0.488 | Acc: 83.277% (5383/6464)
Loss: 0.476 | Acc: 83.691% (10766/12864)
Loss: 0.489 | Acc: 83.321% (16051/19264)
Loss: 0.485 | Acc: 83.522% (21435/25664)
Loss: 0.483 | Acc: 83.633% (26816/32064)
Loss: 0.484 | Acc: 83.598% (32155/38464)
Loss: 0.484 | Acc: 83.519% (37470/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7030, Accuracy: 7661/10000 (76.61%)

Epoch: 11
Loss: 0.528 | Acc: 76.562% (49/64)
Loss: 0.451 | Acc: 84.452% (5459/6464)
Loss: 0.458 | Acc: 84.243% (10837/12864)
Loss: 0.456 | Acc: 84.536% (16285/19264)
Loss: 0.461 | Acc: 84.352% (21648/25664)
Loss: 0.462 | Acc: 84.328% (27039/32064)
Loss: 0.463 | Acc: 84.287% (32420/38464)
Loss: 0.463 | Acc: 84.208% (37779/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7608, Accuracy: 7633/10000 (76.33%)

Epoch: 12
Loss: 0.591 | Acc: 81.250% (52/64)
Loss: 0.435 | Acc: 84.777% (5480/6464)
Loss: 0.433 | Acc: 85.075% (10944/12864)
Loss: 0.439 | Acc: 84.842% (16344/19264)
Loss: 0.444 | Acc: 84.640% (21722/25664)
Loss: 0.448 | Acc: 84.556% (27112/32064)
Loss: 0.448 | Acc: 84.604% (32542/38464)
Loss: 0.448 | Acc: 84.607% (37958/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7782, Accuracy: 7422/10000 (74.22%)

Epoch: 13
Loss: 0.659 | Acc: 71.875% (46/64)
Loss: 0.428 | Acc: 85.257% (5511/6464)
Loss: 0.429 | Acc: 85.261% (10968/12864)
Loss: 0.428 | Acc: 85.439% (16459/19264)
Loss: 0.427 | Acc: 85.513% (21946/25664)
Loss: 0.423 | Acc: 85.594% (27445/32064)
Loss: 0.424 | Acc: 85.568% (32913/38464)
Loss: 0.424 | Acc: 85.463% (38342/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7401, Accuracy: 5630/10000 (56.30%)

Epoch: 14
Loss: 0.523 | Acc: 82.812% (53/64)
Loss: 0.422 | Acc: 85.504% (5527/6464)
Loss: 0.420 | Acc: 85.533% (11003/12864)
Loss: 0.416 | Acc: 85.595% (16489/19264)
Loss: 0.416 | Acc: 85.653% (21982/25664)
Loss: 0.410 | Acc: 85.875% (27535/32064)
Loss: 0.412 | Acc: 85.854% (33023/38464)
Loss: 0.412 | Acc: 85.799% (38493/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6421, Accuracy: 5778/10000 (57.78%)

Epoch: 15
Loss: 0.669 | Acc: 73.438% (47/64)
Loss: 0.404 | Acc: 86.247% (5575/6464)
Loss: 0.394 | Acc: 86.505% (11128/12864)
Loss: 0.398 | Acc: 86.358% (16636/19264)
Loss: 0.393 | Acc: 86.545% (22211/25664)
Loss: 0.395 | Acc: 86.574% (27759/32064)
Loss: 0.397 | Acc: 86.473% (33261/38464)
Loss: 0.397 | Acc: 86.481% (38799/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9493, Accuracy: 6894/10000 (68.94%)

Epoch: 16
Loss: 0.551 | Acc: 81.250% (52/64)
Loss: 0.369 | Acc: 87.067% (5628/6464)
Loss: 0.369 | Acc: 87.065% (11200/12864)
Loss: 0.368 | Acc: 87.126% (16784/19264)
Loss: 0.376 | Acc: 86.954% (22316/25664)
Loss: 0.375 | Acc: 86.973% (27887/32064)
Loss: 0.377 | Acc: 86.941% (33441/38464)
Loss: 0.376 | Acc: 86.985% (39025/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8929, Accuracy: 7468/10000 (74.68%)

Epoch: 17
Loss: 0.472 | Acc: 85.938% (55/64)
Loss: 0.346 | Acc: 88.413% (5715/6464)
Loss: 0.364 | Acc: 87.617% (11271/12864)
Loss: 0.367 | Acc: 87.469% (16850/19264)
Loss: 0.366 | Acc: 87.484% (22452/25664)
Loss: 0.363 | Acc: 87.640% (28101/32064)
Loss: 0.366 | Acc: 87.477% (33647/38464)
Loss: 0.366 | Acc: 87.455% (39236/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7465, Accuracy: 7710/10000 (77.10%)

Epoch: 18
Loss: 0.577 | Acc: 81.250% (52/64)
Loss: 0.345 | Acc: 88.289% (5707/6464)
Loss: 0.345 | Acc: 88.106% (11334/12864)
Loss: 0.346 | Acc: 88.066% (16965/19264)
Loss: 0.347 | Acc: 88.069% (22602/25664)
Loss: 0.348 | Acc: 88.061% (28236/32064)
Loss: 0.351 | Acc: 87.929% (33821/38464)
Loss: 0.353 | Acc: 87.845% (39411/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6193, Accuracy: 7948/10000 (79.48%)

Epoch: 19
Loss: 0.322 | Acc: 87.500% (56/64)
Loss: 0.336 | Acc: 88.413% (5715/6464)
Loss: 0.335 | Acc: 88.565% (11393/12864)
Loss: 0.334 | Acc: 88.637% (17075/19264)
Loss: 0.336 | Acc: 88.544% (22724/25664)
Loss: 0.337 | Acc: 88.548% (28392/32064)
Loss: 0.339 | Acc: 88.394% (34000/38464)
Loss: 0.340 | Acc: 88.383% (39652/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2847, Accuracy: 6525/10000 (65.25%)

Epoch: 20
Loss: 0.276 | Acc: 89.062% (57/64)
Loss: 0.320 | Acc: 89.093% (5759/6464)
Loss: 0.316 | Acc: 89.109% (11463/12864)
Loss: 0.325 | Acc: 88.715% (17090/19264)
Loss: 0.325 | Acc: 88.755% (22778/25664)
Loss: 0.326 | Acc: 88.751% (28457/32064)
Loss: 0.326 | Acc: 88.761% (34141/38464)
Loss: 0.326 | Acc: 88.788% (39834/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5671, Accuracy: 5756/10000 (57.56%)

Epoch: 21
Loss: 0.324 | Acc: 90.625% (58/64)
Loss: 0.316 | Acc: 89.233% (5768/6464)
Loss: 0.323 | Acc: 89.039% (11454/12864)
Loss: 0.318 | Acc: 89.177% (17179/19264)
Loss: 0.318 | Acc: 89.059% (22856/25664)
Loss: 0.313 | Acc: 89.281% (28627/32064)
Loss: 0.313 | Acc: 89.244% (34327/38464)
Loss: 0.312 | Acc: 89.234% (40034/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4329, Accuracy: 8546/10000 (85.46%)

Epoch: 22
Loss: 0.208 | Acc: 95.312% (61/64)
Loss: 0.285 | Acc: 90.455% (5847/6464)
Loss: 0.295 | Acc: 89.988% (11576/12864)
Loss: 0.301 | Acc: 89.753% (17290/19264)
Loss: 0.298 | Acc: 89.737% (23030/25664)
Loss: 0.300 | Acc: 89.689% (28758/32064)
Loss: 0.301 | Acc: 89.712% (34507/38464)
Loss: 0.302 | Acc: 89.671% (40230/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6521, Accuracy: 7961/10000 (79.61%)

Epoch: 23
Loss: 0.407 | Acc: 82.812% (53/64)
Loss: 0.260 | Acc: 90.965% (5880/6464)
Loss: 0.281 | Acc: 90.322% (11619/12864)
Loss: 0.280 | Acc: 90.428% (17420/19264)
Loss: 0.285 | Acc: 90.192% (23147/25664)
Loss: 0.288 | Acc: 90.148% (28905/32064)
Loss: 0.285 | Acc: 90.248% (34713/38464)
Loss: 0.287 | Acc: 90.208% (40471/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9750, Accuracy: 7349/10000 (73.49%)

Epoch: 24
Loss: 0.484 | Acc: 89.062% (57/64)
Loss: 0.274 | Acc: 90.579% (5855/6464)
Loss: 0.273 | Acc: 90.609% (11656/12864)
Loss: 0.275 | Acc: 90.558% (17445/19264)
Loss: 0.277 | Acc: 90.387% (23197/25664)
Loss: 0.277 | Acc: 90.413% (28990/32064)
Loss: 0.277 | Acc: 90.388% (34767/38464)
Loss: 0.278 | Acc: 90.382% (40549/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8632, Accuracy: 7467/10000 (74.67%)

Epoch: 25
Loss: 0.369 | Acc: 89.062% (57/64)
Loss: 0.270 | Acc: 90.826% (5871/6464)
Loss: 0.277 | Acc: 90.765% (11676/12864)
Loss: 0.273 | Acc: 90.895% (17510/19264)
Loss: 0.266 | Acc: 91.104% (23381/25664)
Loss: 0.265 | Acc: 91.080% (29204/32064)
Loss: 0.267 | Acc: 91.010% (35006/38464)
Loss: 0.268 | Acc: 90.904% (40783/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6637, Accuracy: 6968/10000 (69.68%)

Epoch: 26
Loss: 0.396 | Acc: 90.625% (58/64)
Loss: 0.241 | Acc: 91.754% (5931/6464)
Loss: 0.238 | Acc: 91.721% (11799/12864)
Loss: 0.239 | Acc: 91.777% (17680/19264)
Loss: 0.241 | Acc: 91.677% (23528/25664)
Loss: 0.244 | Acc: 91.604% (29372/32064)
Loss: 0.243 | Acc: 91.657% (35255/38464)
Loss: 0.243 | Acc: 91.704% (41142/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4764, Accuracy: 8501/10000 (85.01%)

Epoch: 27
Loss: 0.371 | Acc: 87.500% (56/64)
Loss: 0.247 | Acc: 91.491% (5914/6464)
Loss: 0.236 | Acc: 91.877% (11819/12864)
Loss: 0.238 | Acc: 91.845% (17693/19264)
Loss: 0.241 | Acc: 91.732% (23542/25664)
Loss: 0.241 | Acc: 91.770% (29425/32064)
Loss: 0.242 | Acc: 91.668% (35259/38464)
Loss: 0.241 | Acc: 91.682% (41132/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6263, Accuracy: 8213/10000 (82.13%)

Epoch: 28
Loss: 0.378 | Acc: 85.938% (55/64)
Loss: 0.213 | Acc: 92.853% (6002/6464)
Loss: 0.210 | Acc: 92.747% (11931/12864)
Loss: 0.211 | Acc: 92.764% (17870/19264)
Loss: 0.217 | Acc: 92.577% (23759/25664)
Loss: 0.218 | Acc: 92.552% (29676/32064)
Loss: 0.219 | Acc: 92.499% (35579/38464)
Loss: 0.219 | Acc: 92.484% (41492/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7940, Accuracy: 7779/10000 (77.79%)

Epoch: 29
Loss: 0.304 | Acc: 92.188% (59/64)
Loss: 0.213 | Acc: 92.760% (5996/6464)
Loss: 0.205 | Acc: 92.980% (11961/12864)
Loss: 0.204 | Acc: 92.847% (17886/19264)
Loss: 0.203 | Acc: 92.943% (23853/25664)
Loss: 0.206 | Acc: 92.861% (29775/32064)
Loss: 0.207 | Acc: 92.848% (35713/38464)
Loss: 0.206 | Acc: 92.865% (41663/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4958, Accuracy: 8393/10000 (83.93%)

Epoch: 30
Loss: 0.311 | Acc: 87.500% (56/64)
Loss: 0.185 | Acc: 93.626% (6052/6464)
Loss: 0.179 | Acc: 93.913% (12081/12864)
Loss: 0.185 | Acc: 93.792% (18068/19264)
Loss: 0.187 | Acc: 93.731% (24055/25664)
Loss: 0.187 | Acc: 93.610% (30015/32064)
Loss: 0.189 | Acc: 93.524% (35973/38464)
Loss: 0.188 | Acc: 93.540% (41966/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8116, Accuracy: 7785/10000 (77.85%)

Epoch: 31
Loss: 0.312 | Acc: 89.062% (57/64)
Loss: 0.180 | Acc: 93.642% (6053/6464)
Loss: 0.180 | Acc: 93.742% (12059/12864)
Loss: 0.183 | Acc: 93.698% (18050/19264)
Loss: 0.182 | Acc: 93.731% (24055/25664)
Loss: 0.181 | Acc: 93.806% (30078/32064)
Loss: 0.181 | Acc: 93.831% (36091/38464)
Loss: 0.184 | Acc: 93.703% (42039/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4191, Accuracy: 8744/10000 (87.44%)

Epoch: 32
Loss: 0.132 | Acc: 96.875% (62/64)
Loss: 0.155 | Acc: 94.601% (6115/6464)
Loss: 0.157 | Acc: 94.566% (12165/12864)
Loss: 0.155 | Acc: 94.632% (18230/19264)
Loss: 0.159 | Acc: 94.455% (24241/25664)
Loss: 0.164 | Acc: 94.299% (30236/32064)
Loss: 0.165 | Acc: 94.241% (36249/38464)
Loss: 0.163 | Acc: 94.280% (42298/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6835, Accuracy: 8146/10000 (81.46%)

Epoch: 33
Loss: 0.122 | Acc: 95.312% (61/64)
Loss: 0.141 | Acc: 95.189% (6153/6464)
Loss: 0.143 | Acc: 95.079% (12231/12864)
Loss: 0.143 | Acc: 95.105% (18321/19264)
Loss: 0.145 | Acc: 95.032% (24389/25664)
Loss: 0.146 | Acc: 94.957% (30447/32064)
Loss: 0.146 | Acc: 94.993% (36538/38464)
Loss: 0.144 | Acc: 95.049% (42643/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3814, Accuracy: 8823/10000 (88.23%)

Epoch: 34
Loss: 0.092 | Acc: 96.875% (62/64)
Loss: 0.137 | Acc: 95.467% (6171/6464)
Loss: 0.129 | Acc: 95.662% (12306/12864)
Loss: 0.128 | Acc: 95.665% (18429/19264)
Loss: 0.132 | Acc: 95.503% (24510/25664)
Loss: 0.131 | Acc: 95.540% (30634/32064)
Loss: 0.130 | Acc: 95.528% (36744/38464)
Loss: 0.132 | Acc: 95.475% (42834/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2937, Accuracy: 9119/10000 (91.19%)

Epoch: 35
Loss: 0.041 | Acc: 100.000% (64/64)
Loss: 0.116 | Acc: 95.916% (6200/6464)
Loss: 0.118 | Acc: 95.849% (12330/12864)
Loss: 0.116 | Acc: 95.956% (18485/19264)
Loss: 0.115 | Acc: 95.998% (24637/25664)
Loss: 0.114 | Acc: 96.020% (30788/32064)
Loss: 0.117 | Acc: 95.978% (36917/38464)
Loss: 0.118 | Acc: 95.917% (43032/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3387, Accuracy: 8901/10000 (89.01%)

Epoch: 36
Loss: 0.199 | Acc: 92.188% (59/64)
Loss: 0.100 | Acc: 96.658% (6248/6464)
Loss: 0.103 | Acc: 96.556% (12421/12864)
Loss: 0.100 | Acc: 96.548% (18599/19264)
Loss: 0.102 | Acc: 96.450% (24753/25664)
Loss: 0.103 | Acc: 96.420% (30916/32064)
Loss: 0.103 | Acc: 96.404% (37081/38464)
Loss: 0.103 | Acc: 96.414% (43255/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3336, Accuracy: 9003/10000 (90.03%)

Epoch: 37
Loss: 0.093 | Acc: 98.438% (63/64)
Loss: 0.080 | Acc: 97.277% (6288/6464)
Loss: 0.079 | Acc: 97.396% (12529/12864)
Loss: 0.081 | Acc: 97.295% (18743/19264)
Loss: 0.082 | Acc: 97.288% (24968/25664)
Loss: 0.084 | Acc: 97.187% (31162/32064)
Loss: 0.085 | Acc: 97.151% (37368/38464)
Loss: 0.086 | Acc: 97.118% (43571/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2803, Accuracy: 9153/10000 (91.53%)

Epoch: 38
Loss: 0.111 | Acc: 95.312% (61/64)
Loss: 0.075 | Acc: 97.664% (6313/6464)
Loss: 0.071 | Acc: 97.668% (12564/12864)
Loss: 0.069 | Acc: 97.669% (18815/19264)
Loss: 0.071 | Acc: 97.576% (25042/25664)
Loss: 0.071 | Acc: 97.574% (31286/32064)
Loss: 0.071 | Acc: 97.561% (37526/38464)
Loss: 0.071 | Acc: 97.570% (43774/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2486, Accuracy: 9262/10000 (92.62%)

Epoch: 39
Loss: 0.114 | Acc: 96.875% (62/64)
Loss: 0.064 | Acc: 97.772% (6320/6464)
Loss: 0.058 | Acc: 98.033% (12611/12864)
Loss: 0.055 | Acc: 98.188% (18915/19264)
Loss: 0.055 | Acc: 98.161% (25192/25664)
Loss: 0.056 | Acc: 98.154% (31472/32064)
Loss: 0.056 | Acc: 98.152% (37753/38464)
Loss: 0.056 | Acc: 98.148% (44033/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2861, Accuracy: 9198/10000 (91.98%)

Epoch: 40
Loss: 0.087 | Acc: 96.875% (62/64)
Loss: 0.048 | Acc: 98.360% (6358/6464)
Loss: 0.046 | Acc: 98.453% (12665/12864)
Loss: 0.045 | Acc: 98.479% (18971/19264)
Loss: 0.045 | Acc: 98.496% (25278/25664)
Loss: 0.046 | Acc: 98.481% (31577/32064)
Loss: 0.045 | Acc: 98.523% (37896/38464)
Loss: 0.045 | Acc: 98.542% (44210/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2258, Accuracy: 9341/10000 (93.41%)

Epoch: 41
Loss: 0.072 | Acc: 96.875% (62/64)
Loss: 0.029 | Acc: 99.056% (6403/6464)
Loss: 0.030 | Acc: 99.028% (12739/12864)
Loss: 0.032 | Acc: 99.024% (19076/19264)
Loss: 0.033 | Acc: 98.995% (25406/25664)
Loss: 0.034 | Acc: 98.965% (31732/32064)
Loss: 0.033 | Acc: 98.965% (38066/38464)
Loss: 0.034 | Acc: 98.955% (44395/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2424, Accuracy: 9329/10000 (93.29%)

Epoch: 42
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 0.025 | Acc: 99.381% (6424/6464)
Loss: 0.024 | Acc: 99.308% (12775/12864)
Loss: 0.025 | Acc: 99.263% (19122/19264)
Loss: 0.026 | Acc: 99.228% (25466/25664)
Loss: 0.026 | Acc: 99.223% (31815/32064)
Loss: 0.026 | Acc: 99.215% (38162/38464)
Loss: 0.025 | Acc: 99.244% (44525/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2221, Accuracy: 9386/10000 (93.86%)

Epoch: 43
Loss: 0.020 | Acc: 100.000% (64/64)
Loss: 0.021 | Acc: 99.474% (6430/6464)
Loss: 0.022 | Acc: 99.409% (12788/12864)
Loss: 0.020 | Acc: 99.460% (19160/19264)
Loss: 0.020 | Acc: 99.443% (25521/25664)
Loss: 0.020 | Acc: 99.429% (31881/32064)
Loss: 0.019 | Acc: 99.457% (38255/38464)
Loss: 0.019 | Acc: 99.461% (44622/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2768, Accuracy: 9255/10000 (92.55%)

Epoch: 44
Loss: 0.030 | Acc: 98.438% (63/64)
Loss: 0.022 | Acc: 99.443% (6428/6464)
Loss: 0.019 | Acc: 99.518% (12802/12864)
Loss: 0.018 | Acc: 99.543% (19176/19264)
Loss: 0.018 | Acc: 99.532% (25544/25664)
Loss: 0.017 | Acc: 99.557% (31922/32064)
Loss: 0.017 | Acc: 99.548% (38290/38464)
Loss: 0.017 | Acc: 99.570% (44671/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2306, Accuracy: 9368/10000 (93.68%)

Epoch: 45
Loss: 0.035 | Acc: 98.438% (63/64)
Loss: 0.013 | Acc: 99.660% (6442/6464)
Loss: 0.013 | Acc: 99.666% (12821/12864)
Loss: 0.014 | Acc: 99.647% (19196/19264)
Loss: 0.014 | Acc: 99.642% (25572/25664)
Loss: 0.014 | Acc: 99.657% (31954/32064)
Loss: 0.014 | Acc: 99.672% (38338/38464)
Loss: 0.014 | Acc: 99.672% (44717/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2146, Accuracy: 9404/10000 (94.04%)

Epoch: 46
Loss: 0.008 | Acc: 100.000% (64/64)
Loss: 0.014 | Acc: 99.737% (6447/6464)
Loss: 0.014 | Acc: 99.658% (12820/12864)
Loss: 0.014 | Acc: 99.699% (19206/19264)
Loss: 0.015 | Acc: 99.669% (25579/25664)
Loss: 0.015 | Acc: 99.660% (31955/32064)
Loss: 0.015 | Acc: 99.659% (38333/38464)
Loss: 0.015 | Acc: 99.661% (44712/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2091, Accuracy: 9395/10000 (93.95%)

Epoch: 47
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.013 | Acc: 99.737% (6447/6464)
Loss: 0.013 | Acc: 99.728% (12829/12864)
Loss: 0.013 | Acc: 99.772% (19220/19264)
Loss: 0.013 | Acc: 99.766% (25604/25664)
Loss: 0.014 | Acc: 99.741% (31981/32064)
Loss: 0.014 | Acc: 99.740% (38364/38464)
Loss: 0.014 | Acc: 99.730% (44743/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2148, Accuracy: 9393/10000 (93.93%)
torch.Size([100, 10])
Test set: Average loss: 0.2148, Accuracy: 9393/10000 (93.93%)

Epoch: 48
Loss: 0.010 | Acc: 100.000% (64/64)
Loss: 0.014 | Acc: 99.752% (6448/6464)
Loss: 0.014 | Acc: 99.689% (12824/12864)
Loss: 0.014 | Acc: 99.699% (19206/19264)
Loss: 0.014 | Acc: 99.692% (25585/25664)
Loss: 0.014 | Acc: 99.673% (31959/32064)
Loss: 0.014 | Acc: 99.693% (38346/38464)
Loss: 0.014 | Acc: 99.695% (44727/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2097, Accuracy: 9402/10000 (94.02%)
torch.Size([100, 10])
Test set: Average loss: 0.2097, Accuracy: 9402/10000 (94.02%)

Epoch: 49
Loss: 0.021 | Acc: 98.438% (63/64)
Loss: 0.013 | Acc: 99.752% (6448/6464)
Loss: 0.014 | Acc: 99.751% (12832/12864)
Loss: 0.014 | Acc: 99.772% (19220/19264)
Loss: 0.014 | Acc: 99.731% (25595/25664)
Loss: 0.014 | Acc: 99.744% (31982/32064)
Loss: 0.014 | Acc: 99.743% (38365/38464)
Loss: 0.014 | Acc: 99.739% (44747/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2117, Accuracy: 9398/10000 (93.98%)
torch.Size([100, 10])
Test set: Average loss: 0.2117, Accuracy: 9398/10000 (93.98%)

Epoch: 50
Loss: 0.019 | Acc: 98.438% (63/64)
Loss: 1.165 | Acc: 60.675% (3922/6464)
Loss: 0.919 | Acc: 69.053% (8883/12864)
Loss: 0.806 | Acc: 72.768% (14018/19264)
Loss: 0.736 | Acc: 75.132% (19282/25664)
Loss: 0.691 | Acc: 76.659% (24580/32064)
Loss: 0.662 | Acc: 77.717% (29893/38464)
Loss: 0.635 | Acc: 78.564% (35247/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7845, Accuracy: 7531/10000 (75.31%)

Epoch: 51
Loss: 0.447 | Acc: 84.375% (54/64)
Loss: 0.447 | Acc: 84.669% (5473/6464)
Loss: 0.444 | Acc: 84.717% (10898/12864)
Loss: 0.441 | Acc: 84.837% (16343/19264)
Loss: 0.439 | Acc: 84.983% (21810/25664)
Loss: 0.437 | Acc: 85.148% (27302/32064)
Loss: 0.431 | Acc: 85.340% (32825/38464)
Loss: 0.430 | Acc: 85.418% (38322/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2581, Accuracy: 6717/10000 (67.17%)

Epoch: 52
Loss: 0.682 | Acc: 75.000% (48/64)
Loss: 0.397 | Acc: 86.324% (5580/6464)
Loss: 0.400 | Acc: 86.085% (11074/12864)
Loss: 0.394 | Acc: 86.316% (16628/19264)
Loss: 0.393 | Acc: 86.448% (22186/25664)
Loss: 0.392 | Acc: 86.543% (27749/32064)
Loss: 0.390 | Acc: 86.632% (33322/38464)
Loss: 0.391 | Acc: 86.698% (38896/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5076, Accuracy: 8303/10000 (83.03%)

Epoch: 53
Loss: 0.394 | Acc: 84.375% (54/64)
Loss: 0.347 | Acc: 88.150% (5698/6464)
Loss: 0.356 | Acc: 87.842% (11300/12864)
Loss: 0.364 | Acc: 87.552% (16866/19264)
Loss: 0.365 | Acc: 87.387% (22427/25664)
Loss: 0.366 | Acc: 87.422% (28031/32064)
Loss: 0.369 | Acc: 87.360% (33602/38464)
Loss: 0.370 | Acc: 87.348% (39188/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1474, Accuracy: 7007/10000 (70.07%)

Epoch: 54
Loss: 0.713 | Acc: 76.562% (49/64)
Loss: 0.369 | Acc: 87.717% (5670/6464)
Loss: 0.360 | Acc: 87.539% (11261/12864)
Loss: 0.361 | Acc: 87.505% (16857/19264)
Loss: 0.365 | Acc: 87.430% (22438/25664)
Loss: 0.369 | Acc: 87.288% (27988/32064)
Loss: 0.372 | Acc: 87.139% (33517/38464)
Loss: 0.373 | Acc: 87.146% (39097/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6823, Accuracy: 7843/10000 (78.43%)

Epoch: 55
Loss: 0.437 | Acc: 82.812% (53/64)
Loss: 0.374 | Acc: 87.314% (5644/6464)
Loss: 0.362 | Acc: 87.632% (11273/12864)
Loss: 0.363 | Acc: 87.651% (16885/19264)
Loss: 0.363 | Acc: 87.668% (22499/25664)
Loss: 0.362 | Acc: 87.721% (28127/32064)
Loss: 0.363 | Acc: 87.737% (33747/38464)
Loss: 0.364 | Acc: 87.732% (39360/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6444, Accuracy: 8040/10000 (80.40%)

Epoch: 56
Loss: 0.254 | Acc: 87.500% (56/64)
Loss: 0.328 | Acc: 89.387% (5778/6464)
Loss: 0.345 | Acc: 88.526% (11388/12864)
Loss: 0.347 | Acc: 88.372% (17024/19264)
Loss: 0.345 | Acc: 88.404% (22688/25664)
Loss: 0.350 | Acc: 88.233% (28291/32064)
Loss: 0.353 | Acc: 88.007% (33851/38464)
Loss: 0.356 | Acc: 87.901% (39436/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5699, Accuracy: 8123/10000 (81.23%)

Epoch: 57
Loss: 0.237 | Acc: 92.188% (59/64)
Loss: 0.353 | Acc: 88.150% (5698/6464)
Loss: 0.342 | Acc: 88.456% (11379/12864)
Loss: 0.344 | Acc: 88.476% (17044/19264)
Loss: 0.346 | Acc: 88.346% (22673/25664)
Loss: 0.350 | Acc: 88.342% (28326/32064)
Loss: 0.352 | Acc: 88.207% (33928/38464)
Loss: 0.349 | Acc: 88.307% (39618/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2349, Accuracy: 5341/10000 (53.41%)

Epoch: 58
Loss: 0.635 | Acc: 79.688% (51/64)
Loss: 0.337 | Acc: 88.475% (5719/6464)
Loss: 0.343 | Acc: 88.246% (11352/12864)
Loss: 0.344 | Acc: 88.289% (17008/19264)
Loss: 0.345 | Acc: 88.186% (22632/25664)
Loss: 0.343 | Acc: 88.308% (28315/32064)
Loss: 0.347 | Acc: 88.207% (33928/38464)
Loss: 0.348 | Acc: 88.204% (39572/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3448, Accuracy: 6827/10000 (68.27%)

Epoch: 59
Loss: 0.493 | Acc: 82.812% (53/64)
Loss: 0.342 | Acc: 88.691% (5733/6464)
Loss: 0.346 | Acc: 88.293% (11358/12864)
Loss: 0.343 | Acc: 88.388% (17027/19264)
Loss: 0.343 | Acc: 88.307% (22663/25664)
Loss: 0.344 | Acc: 88.342% (28326/32064)
Loss: 0.343 | Acc: 88.384% (33996/38464)
Loss: 0.345 | Acc: 88.345% (39635/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5970, Accuracy: 8046/10000 (80.46%)

Epoch: 60
Loss: 0.354 | Acc: 89.062% (57/64)
Loss: 0.326 | Acc: 88.753% (5737/6464)
Loss: 0.328 | Acc: 88.565% (11393/12864)
Loss: 0.334 | Acc: 88.362% (17022/19264)
Loss: 0.334 | Acc: 88.412% (22690/25664)
Loss: 0.334 | Acc: 88.395% (28343/32064)
Loss: 0.334 | Acc: 88.426% (34012/38464)
Loss: 0.334 | Acc: 88.472% (39692/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6455, Accuracy: 8095/10000 (80.95%)

Epoch: 61
Loss: 0.339 | Acc: 89.062% (57/64)
Loss: 0.326 | Acc: 89.032% (5755/6464)
Loss: 0.329 | Acc: 88.588% (11396/12864)
Loss: 0.332 | Acc: 88.497% (17048/19264)
Loss: 0.332 | Acc: 88.622% (22744/25664)
Loss: 0.337 | Acc: 88.401% (28345/32064)
Loss: 0.335 | Acc: 88.498% (34040/38464)
Loss: 0.333 | Acc: 88.583% (39742/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4418, Accuracy: 6636/10000 (66.36%)

Epoch: 62
Loss: 0.422 | Acc: 92.188% (59/64)
Loss: 0.319 | Acc: 88.923% (5748/6464)
Loss: 0.318 | Acc: 89.008% (11450/12864)
Loss: 0.320 | Acc: 88.969% (17139/19264)
Loss: 0.323 | Acc: 88.934% (22824/25664)
Loss: 0.329 | Acc: 88.776% (28465/32064)
Loss: 0.327 | Acc: 88.813% (34161/38464)
Loss: 0.331 | Acc: 88.704% (39796/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4713, Accuracy: 8519/10000 (85.19%)

Epoch: 63
Loss: 0.210 | Acc: 92.188% (59/64)
Loss: 0.298 | Acc: 90.022% (5819/6464)
Loss: 0.305 | Acc: 89.785% (11550/12864)
Loss: 0.307 | Acc: 89.659% (17272/19264)
Loss: 0.313 | Acc: 89.378% (22938/25664)
Loss: 0.316 | Acc: 89.334% (28644/32064)
Loss: 0.319 | Acc: 89.247% (34328/38464)
Loss: 0.319 | Acc: 89.263% (40047/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5497, Accuracy: 8345/10000 (83.45%)

Epoch: 64
Loss: 0.385 | Acc: 92.188% (59/64)
Loss: 0.327 | Acc: 89.001% (5753/6464)
Loss: 0.311 | Acc: 89.661% (11534/12864)
Loss: 0.314 | Acc: 89.499% (17241/19264)
Loss: 0.313 | Acc: 89.530% (22977/25664)
Loss: 0.310 | Acc: 89.630% (28739/32064)
Loss: 0.311 | Acc: 89.603% (34465/38464)
Loss: 0.314 | Acc: 89.453% (40132/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7703, Accuracy: 7529/10000 (75.29%)

Epoch: 65
Loss: 0.274 | Acc: 89.062% (57/64)
Loss: 0.315 | Acc: 89.233% (5768/6464)
Loss: 0.308 | Acc: 89.529% (11517/12864)
Loss: 0.307 | Acc: 89.421% (17226/19264)
Loss: 0.303 | Acc: 89.542% (22980/25664)
Loss: 0.305 | Acc: 89.459% (28684/32064)
Loss: 0.307 | Acc: 89.452% (34407/38464)
Loss: 0.307 | Acc: 89.430% (40122/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5841, Accuracy: 8193/10000 (81.93%)

Epoch: 66
Loss: 0.317 | Acc: 90.625% (58/64)
Loss: 0.267 | Acc: 91.105% (5889/6464)
Loss: 0.283 | Acc: 90.415% (11631/12864)
Loss: 0.292 | Acc: 89.976% (17333/19264)
Loss: 0.294 | Acc: 89.931% (23080/25664)
Loss: 0.293 | Acc: 89.954% (28843/32064)
Loss: 0.295 | Acc: 89.827% (34551/38464)
Loss: 0.295 | Acc: 89.823% (40298/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9827, Accuracy: 7111/10000 (71.11%)

Epoch: 67
Loss: 0.450 | Acc: 82.812% (53/64)
Loss: 0.290 | Acc: 90.006% (5818/6464)
Loss: 0.290 | Acc: 90.050% (11584/12864)
Loss: 0.283 | Acc: 90.345% (17404/19264)
Loss: 0.281 | Acc: 90.337% (23184/25664)
Loss: 0.285 | Acc: 90.173% (28913/32064)
Loss: 0.290 | Acc: 90.037% (34632/38464)
Loss: 0.292 | Acc: 90.010% (40382/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4382, Accuracy: 6629/10000 (66.29%)

Epoch: 68
Loss: 0.384 | Acc: 82.812% (53/64)
Loss: 0.304 | Acc: 89.743% (5801/6464)
Loss: 0.287 | Acc: 90.159% (11598/12864)
Loss: 0.292 | Acc: 90.033% (17344/19264)
Loss: 0.292 | Acc: 90.025% (23104/25664)
Loss: 0.288 | Acc: 90.145% (28904/32064)
Loss: 0.287 | Acc: 90.227% (34705/38464)
Loss: 0.288 | Acc: 90.184% (40460/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8191, Accuracy: 7621/10000 (76.21%)

Epoch: 69
Loss: 0.423 | Acc: 84.375% (54/64)
Loss: 0.266 | Acc: 91.182% (5894/6464)
Loss: 0.264 | Acc: 91.053% (11713/12864)
Loss: 0.268 | Acc: 90.926% (17516/19264)
Loss: 0.272 | Acc: 90.773% (23296/25664)
Loss: 0.275 | Acc: 90.772% (29105/32064)
Loss: 0.275 | Acc: 90.698% (34886/38464)
Loss: 0.271 | Acc: 90.763% (40720/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5906, Accuracy: 8181/10000 (81.81%)

Epoch: 70
Loss: 0.214 | Acc: 93.750% (60/64)
Loss: 0.238 | Acc: 91.940% (5943/6464)
Loss: 0.245 | Acc: 91.690% (11795/12864)
Loss: 0.253 | Acc: 91.544% (17635/19264)
Loss: 0.250 | Acc: 91.584% (23504/25664)
Loss: 0.253 | Acc: 91.358% (29293/32064)
Loss: 0.258 | Acc: 91.205% (35081/38464)
Loss: 0.260 | Acc: 91.147% (40892/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4352, Accuracy: 8595/10000 (85.95%)

Epoch: 71
Loss: 0.490 | Acc: 84.375% (54/64)
Loss: 0.233 | Acc: 91.909% (5941/6464)
Loss: 0.246 | Acc: 91.418% (11760/12864)
Loss: 0.247 | Acc: 91.430% (17613/19264)
Loss: 0.249 | Acc: 91.428% (23464/25664)
Loss: 0.252 | Acc: 91.330% (29284/32064)
Loss: 0.257 | Acc: 91.161% (35064/38464)
Loss: 0.256 | Acc: 91.222% (40926/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3706, Accuracy: 6436/10000 (64.36%)

Epoch: 72
Loss: 0.496 | Acc: 81.250% (52/64)
Loss: 0.262 | Acc: 91.136% (5891/6464)
Loss: 0.254 | Acc: 91.449% (11764/12864)
Loss: 0.257 | Acc: 91.336% (17595/19264)
Loss: 0.258 | Acc: 91.299% (23431/25664)
Loss: 0.254 | Acc: 91.370% (29297/32064)
Loss: 0.252 | Acc: 91.392% (35153/38464)
Loss: 0.253 | Acc: 91.345% (40981/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5187, Accuracy: 8472/10000 (84.72%)

Epoch: 73
Loss: 0.205 | Acc: 93.750% (60/64)
Loss: 0.226 | Acc: 92.048% (5950/6464)
Loss: 0.223 | Acc: 92.203% (11861/12864)
Loss: 0.228 | Acc: 92.120% (17746/19264)
Loss: 0.233 | Acc: 91.852% (23573/25664)
Loss: 0.236 | Acc: 91.813% (29439/32064)
Loss: 0.236 | Acc: 91.795% (35308/38464)
Loss: 0.238 | Acc: 91.791% (41181/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3960, Accuracy: 8730/10000 (87.30%)

Epoch: 74
Loss: 0.286 | Acc: 87.500% (56/64)
Loss: 0.212 | Acc: 92.744% (5995/6464)
Loss: 0.214 | Acc: 92.693% (11924/12864)
Loss: 0.217 | Acc: 92.681% (17854/19264)
Loss: 0.216 | Acc: 92.671% (23783/25664)
Loss: 0.221 | Acc: 92.446% (29642/32064)
Loss: 0.223 | Acc: 92.351% (35522/38464)
Loss: 0.224 | Acc: 92.359% (41436/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8701, Accuracy: 7431/10000 (74.31%)

Epoch: 75
Loss: 0.363 | Acc: 87.500% (56/64)
Loss: 0.226 | Acc: 91.986% (5946/6464)
Loss: 0.218 | Acc: 92.226% (11864/12864)
Loss: 0.223 | Acc: 92.136% (17749/19264)
Loss: 0.225 | Acc: 92.110% (23639/25664)
Loss: 0.220 | Acc: 92.372% (29618/32064)
Loss: 0.221 | Acc: 92.299% (35502/38464)
Loss: 0.222 | Acc: 92.281% (41401/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3278, Accuracy: 8918/10000 (89.18%)

Epoch: 76
Loss: 0.136 | Acc: 96.875% (62/64)
Loss: 0.186 | Acc: 93.889% (6069/6464)
Loss: 0.190 | Acc: 93.727% (12057/12864)
Loss: 0.196 | Acc: 93.387% (17990/19264)
Loss: 0.199 | Acc: 93.337% (23954/25664)
Loss: 0.202 | Acc: 93.214% (29888/32064)
Loss: 0.208 | Acc: 93.012% (35776/38464)
Loss: 0.207 | Acc: 93.048% (41745/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3148, Accuracy: 8953/10000 (89.53%)

Epoch: 77
Loss: 0.168 | Acc: 92.188% (59/64)
Loss: 0.190 | Acc: 93.425% (6039/6464)
Loss: 0.188 | Acc: 93.455% (12022/12864)
Loss: 0.195 | Acc: 93.163% (17947/19264)
Loss: 0.194 | Acc: 93.275% (23938/25664)
Loss: 0.193 | Acc: 93.345% (29930/32064)
Loss: 0.195 | Acc: 93.277% (35878/38464)
Loss: 0.196 | Acc: 93.233% (41828/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3364, Accuracy: 8931/10000 (89.31%)

Epoch: 78
Loss: 0.118 | Acc: 96.875% (62/64)
Loss: 0.167 | Acc: 94.261% (6093/6464)
Loss: 0.169 | Acc: 94.209% (12119/12864)
Loss: 0.174 | Acc: 93.937% (18096/19264)
Loss: 0.180 | Acc: 93.777% (24067/25664)
Loss: 0.181 | Acc: 93.741% (30057/32064)
Loss: 0.181 | Acc: 93.760% (36064/38464)
Loss: 0.182 | Acc: 93.743% (42057/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0072, Accuracy: 7481/10000 (74.81%)

Epoch: 79
Loss: 0.159 | Acc: 95.312% (61/64)
Loss: 0.155 | Acc: 94.694% (6121/6464)
Loss: 0.154 | Acc: 94.714% (12184/12864)
Loss: 0.158 | Acc: 94.596% (18223/19264)
Loss: 0.159 | Acc: 94.576% (24272/25664)
Loss: 0.162 | Acc: 94.474% (30292/32064)
Loss: 0.162 | Acc: 94.462% (36334/38464)
Loss: 0.162 | Acc: 94.461% (42379/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5375, Accuracy: 8329/10000 (83.29%)

Epoch: 80
Loss: 0.459 | Acc: 90.625% (58/64)
Loss: 0.172 | Acc: 94.199% (6089/6464)
Loss: 0.162 | Acc: 94.520% (12159/12864)
Loss: 0.163 | Acc: 94.503% (18205/19264)
Loss: 0.164 | Acc: 94.370% (24219/25664)
Loss: 0.165 | Acc: 94.318% (30242/32064)
Loss: 0.161 | Acc: 94.421% (36318/38464)
Loss: 0.161 | Acc: 94.457% (42377/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4368, Accuracy: 8614/10000 (86.14%)

Epoch: 81
Loss: 0.278 | Acc: 90.625% (58/64)
Loss: 0.156 | Acc: 94.647% (6118/6464)
Loss: 0.151 | Acc: 94.807% (12196/12864)
Loss: 0.151 | Acc: 94.788% (18260/19264)
Loss: 0.146 | Acc: 94.970% (24373/25664)
Loss: 0.149 | Acc: 94.944% (30443/32064)
Loss: 0.149 | Acc: 94.917% (36509/38464)
Loss: 0.151 | Acc: 94.829% (42544/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3759, Accuracy: 8814/10000 (88.14%)

Epoch: 82
Loss: 0.114 | Acc: 98.438% (63/64)
Loss: 0.137 | Acc: 95.668% (6184/6464)
Loss: 0.128 | Acc: 95.849% (12330/12864)
Loss: 0.124 | Acc: 95.915% (18477/19264)
Loss: 0.126 | Acc: 95.807% (24588/25664)
Loss: 0.129 | Acc: 95.684% (30680/32064)
Loss: 0.129 | Acc: 95.697% (36809/38464)
Loss: 0.130 | Acc: 95.667% (42920/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8878, Accuracy: 7694/10000 (76.94%)

Epoch: 83
Loss: 0.093 | Acc: 96.875% (62/64)
Loss: 0.115 | Acc: 96.287% (6224/6464)
Loss: 0.109 | Acc: 96.308% (12389/12864)
Loss: 0.108 | Acc: 96.314% (18554/19264)
Loss: 0.108 | Acc: 96.345% (24726/25664)
Loss: 0.111 | Acc: 96.223% (30853/32064)
Loss: 0.110 | Acc: 96.251% (37022/38464)
Loss: 0.111 | Acc: 96.235% (43175/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4383, Accuracy: 8769/10000 (87.69%)

Epoch: 84
Loss: 0.083 | Acc: 96.875% (62/64)
Loss: 0.109 | Acc: 96.210% (6219/6464)
Loss: 0.111 | Acc: 96.160% (12370/12864)
Loss: 0.115 | Acc: 96.060% (18505/19264)
Loss: 0.111 | Acc: 96.185% (24685/25664)
Loss: 0.109 | Acc: 96.279% (30871/32064)
Loss: 0.109 | Acc: 96.308% (37044/38464)
Loss: 0.108 | Acc: 96.338% (43221/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2590, Accuracy: 9189/10000 (91.89%)

Epoch: 85
Loss: 0.110 | Acc: 95.312% (61/64)
Loss: 0.080 | Acc: 97.308% (6290/6464)
Loss: 0.081 | Acc: 97.209% (12505/12864)
Loss: 0.085 | Acc: 97.192% (18723/19264)
Loss: 0.085 | Acc: 97.128% (24927/25664)
Loss: 0.085 | Acc: 97.128% (31143/32064)
Loss: 0.088 | Acc: 97.013% (37315/38464)
Loss: 0.089 | Acc: 96.955% (43498/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3847, Accuracy: 8918/10000 (89.18%)

Epoch: 86
Loss: 0.124 | Acc: 95.312% (61/64)
Loss: 0.076 | Acc: 97.525% (6304/6464)
Loss: 0.075 | Acc: 97.582% (12553/12864)
Loss: 0.078 | Acc: 97.539% (18790/19264)
Loss: 0.078 | Acc: 97.498% (25022/25664)
Loss: 0.076 | Acc: 97.570% (31285/32064)
Loss: 0.077 | Acc: 97.473% (37492/38464)
Loss: 0.077 | Acc: 97.475% (43731/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2338, Accuracy: 9310/10000 (93.10%)

Epoch: 87
Loss: 0.016 | Acc: 100.000% (64/64)
Loss: 0.055 | Acc: 98.190% (6347/6464)
Loss: 0.057 | Acc: 98.018% (12609/12864)
Loss: 0.057 | Acc: 98.074% (18893/19264)
Loss: 0.057 | Acc: 98.099% (25176/25664)
Loss: 0.059 | Acc: 98.073% (31446/32064)
Loss: 0.060 | Acc: 97.967% (37682/38464)
Loss: 0.060 | Acc: 97.987% (43961/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3108, Accuracy: 9168/10000 (91.68%)

Epoch: 88
Loss: 0.154 | Acc: 95.312% (61/64)
Loss: 0.064 | Acc: 97.958% (6332/6464)
Loss: 0.057 | Acc: 98.158% (12627/12864)
Loss: 0.052 | Acc: 98.297% (18936/19264)
Loss: 0.050 | Acc: 98.340% (25238/25664)
Loss: 0.049 | Acc: 98.366% (31540/32064)
Loss: 0.050 | Acc: 98.308% (37813/38464)
Loss: 0.051 | Acc: 98.275% (44090/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2262, Accuracy: 9314/10000 (93.14%)

Epoch: 89
Loss: 0.026 | Acc: 98.438% (63/64)
Loss: 0.039 | Acc: 98.608% (6374/6464)
Loss: 0.041 | Acc: 98.585% (12682/12864)
Loss: 0.037 | Acc: 98.759% (19025/19264)
Loss: 0.037 | Acc: 98.765% (25347/25664)
Loss: 0.036 | Acc: 98.787% (31675/32064)
Loss: 0.035 | Acc: 98.817% (38009/38464)
Loss: 0.036 | Acc: 98.803% (44327/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2212, Accuracy: 9369/10000 (93.69%)

Epoch: 90
Loss: 0.018 | Acc: 100.000% (64/64)
Loss: 0.025 | Acc: 99.242% (6415/6464)
Loss: 0.027 | Acc: 99.160% (12756/12864)
Loss: 0.028 | Acc: 99.123% (19095/19264)
Loss: 0.028 | Acc: 99.135% (25442/25664)
Loss: 0.028 | Acc: 99.139% (31788/32064)
Loss: 0.028 | Acc: 99.119% (38125/38464)
Loss: 0.028 | Acc: 99.117% (44468/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2163, Accuracy: 9412/10000 (94.12%)

Epoch: 91
Loss: 0.016 | Acc: 100.000% (64/64)
Loss: 0.023 | Acc: 99.335% (6421/6464)
Loss: 0.024 | Acc: 99.254% (12768/12864)
Loss: 0.023 | Acc: 99.273% (19124/19264)
Loss: 0.023 | Acc: 99.275% (25478/25664)
Loss: 0.023 | Acc: 99.258% (31826/32064)
Loss: 0.024 | Acc: 99.251% (38176/38464)
Loss: 0.024 | Acc: 99.253% (44529/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2039, Accuracy: 9425/10000 (94.25%)

Epoch: 92
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 0.018 | Acc: 99.551% (6435/6464)
Loss: 0.016 | Acc: 99.572% (12809/12864)
Loss: 0.017 | Acc: 99.554% (19178/19264)
Loss: 0.017 | Acc: 99.556% (25550/25664)
Loss: 0.017 | Acc: 99.557% (31922/32064)
Loss: 0.016 | Acc: 99.553% (38292/38464)
Loss: 0.016 | Acc: 99.570% (44671/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2207, Accuracy: 9381/10000 (93.81%)

Epoch: 93
Loss: 0.030 | Acc: 98.438% (63/64)
Loss: 0.013 | Acc: 99.629% (6440/6464)
Loss: 0.013 | Acc: 99.642% (12818/12864)
Loss: 0.013 | Acc: 99.673% (19201/19264)
Loss: 0.013 | Acc: 99.661% (25577/25664)
Loss: 0.014 | Acc: 99.648% (31951/32064)
Loss: 0.013 | Acc: 99.659% (38333/38464)
Loss: 0.013 | Acc: 99.663% (44713/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2014, Accuracy: 9450/10000 (94.50%)

Epoch: 94
Loss: 0.019 | Acc: 98.438% (63/64)
Loss: 0.012 | Acc: 99.644% (6441/6464)
Loss: 0.012 | Acc: 99.697% (12825/12864)
Loss: 0.011 | Acc: 99.740% (19214/19264)
Loss: 0.011 | Acc: 99.743% (25598/25664)
Loss: 0.010 | Acc: 99.757% (31986/32064)
Loss: 0.010 | Acc: 99.756% (38370/38464)
Loss: 0.010 | Acc: 99.762% (44757/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2042, Accuracy: 9446/10000 (94.46%)

Epoch: 95
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.830% (6453/6464)
Loss: 0.009 | Acc: 99.829% (12842/12864)
Loss: 0.009 | Acc: 99.834% (19232/19264)
Loss: 0.009 | Acc: 99.832% (25621/25664)
Loss: 0.009 | Acc: 99.832% (32010/32064)
Loss: 0.009 | Acc: 99.841% (38403/38464)
Loss: 0.009 | Acc: 99.831% (44788/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1977, Accuracy: 9446/10000 (94.46%)

Epoch: 96
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 0.012 | Acc: 99.691% (6444/6464)
Loss: 0.011 | Acc: 99.720% (12828/12864)
Loss: 0.011 | Acc: 99.756% (19217/19264)
Loss: 0.011 | Acc: 99.762% (25603/25664)
Loss: 0.011 | Acc: 99.788% (31996/32064)
Loss: 0.011 | Acc: 99.779% (38379/38464)
Loss: 0.011 | Acc: 99.779% (44765/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1971, Accuracy: 9445/10000 (94.45%)

Epoch: 97
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.012 | Acc: 99.691% (6444/6464)
Loss: 0.011 | Acc: 99.751% (12832/12864)
Loss: 0.011 | Acc: 99.756% (19217/19264)
Loss: 0.011 | Acc: 99.766% (25604/25664)
Loss: 0.012 | Acc: 99.729% (31977/32064)
Loss: 0.011 | Acc: 99.748% (38367/38464)
Loss: 0.011 | Acc: 99.759% (44756/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1937, Accuracy: 9449/10000 (94.49%)
torch.Size([100, 10])
Test set: Average loss: 0.1937, Accuracy: 9449/10000 (94.49%)

Epoch: 98
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.892% (6457/6464)
Loss: 0.010 | Acc: 99.845% (12844/12864)
Loss: 0.010 | Acc: 99.849% (19235/19264)
Loss: 0.010 | Acc: 99.844% (25624/25664)
Loss: 0.010 | Acc: 99.819% (32006/32064)
Loss: 0.010 | Acc: 99.823% (38396/38464)
Loss: 0.010 | Acc: 99.824% (44785/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1933, Accuracy: 9448/10000 (94.48%)
torch.Size([100, 10])
Test set: Average loss: 0.1933, Accuracy: 9448/10000 (94.48%)

Epoch: 99
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.783% (6450/6464)
Loss: 0.010 | Acc: 99.806% (12839/12864)
Loss: 0.011 | Acc: 99.792% (19224/19264)
Loss: 0.010 | Acc: 99.801% (25613/25664)
Loss: 0.010 | Acc: 99.816% (32005/32064)
Loss: 0.010 | Acc: 99.818% (38394/38464)
Loss: 0.010 | Acc: 99.826% (44786/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1931, Accuracy: 9448/10000 (94.48%)
torch.Size([100, 10])
Test set: Average loss: 0.1931, Accuracy: 9448/10000 (94.48%)

Epoch: 100
Loss: 0.014 | Acc: 100.000% (64/64)
Loss: 2.026 | Acc: 25.340% (1638/6464)
Loss: 1.843 | Acc: 31.802% (4091/12864)
Loss: 1.575 | Acc: 42.390% (8166/19264)
Loss: 1.365 | Acc: 50.627% (12993/25664)
Loss: 1.217 | Acc: 56.234% (18031/32064)
Loss: 1.110 | Acc: 60.329% (23205/38464)
Loss: 1.028 | Acc: 63.358% (28425/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2312, Accuracy: 5496/10000 (54.96%)

Epoch: 101
Loss: 0.674 | Acc: 81.250% (52/64)
Loss: 0.462 | Acc: 84.112% (5437/6464)
Loss: 0.474 | Acc: 83.979% (10803/12864)
Loss: 0.464 | Acc: 84.406% (16260/19264)
Loss: 0.456 | Acc: 84.632% (21720/25664)
Loss: 0.452 | Acc: 84.784% (27185/32064)
Loss: 0.448 | Acc: 84.916% (32662/38464)
Loss: 0.445 | Acc: 85.064% (38163/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8882, Accuracy: 5867/10000 (58.67%)

Epoch: 102
Loss: 0.377 | Acc: 89.062% (57/64)
Loss: 0.381 | Acc: 87.330% (5645/6464)
Loss: 0.387 | Acc: 86.979% (11189/12864)
Loss: 0.385 | Acc: 86.971% (16754/19264)
Loss: 0.387 | Acc: 86.982% (22323/25664)
Loss: 0.389 | Acc: 86.879% (27857/32064)
Loss: 0.384 | Acc: 87.061% (33487/38464)
Loss: 0.387 | Acc: 86.974% (39020/44864)
torch.Size([100, 10])
Test set: Average loss: 6.0136, Accuracy: 3097/10000 (30.97%)

Epoch: 103
Loss: 0.824 | Acc: 71.875% (46/64)
Loss: 0.392 | Acc: 86.603% (5598/6464)
Loss: 0.372 | Acc: 87.337% (11235/12864)
Loss: 0.372 | Acc: 87.329% (16823/19264)
Loss: 0.368 | Acc: 87.504% (22457/25664)
Loss: 0.368 | Acc: 87.519% (28062/32064)
Loss: 0.367 | Acc: 87.604% (33696/38464)
Loss: 0.368 | Acc: 87.598% (39300/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5052, Accuracy: 6142/10000 (61.42%)

Epoch: 104
Loss: 1.104 | Acc: 68.750% (44/64)
Loss: 0.360 | Acc: 87.809% (5676/6464)
Loss: 0.357 | Acc: 87.687% (11280/12864)
Loss: 0.352 | Acc: 87.905% (16934/19264)
Loss: 0.357 | Acc: 87.699% (22507/25664)
Loss: 0.353 | Acc: 87.874% (28176/32064)
Loss: 0.355 | Acc: 87.828% (33782/38464)
Loss: 0.356 | Acc: 87.832% (39405/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7393, Accuracy: 6153/10000 (61.53%)

Epoch: 105
Loss: 0.674 | Acc: 73.438% (47/64)
Loss: 0.339 | Acc: 88.475% (5719/6464)
Loss: 0.340 | Acc: 88.355% (11366/12864)
Loss: 0.343 | Acc: 88.273% (17005/19264)
Loss: 0.347 | Acc: 88.131% (22618/25664)
Loss: 0.345 | Acc: 88.245% (28295/32064)
Loss: 0.347 | Acc: 88.202% (33926/38464)
Loss: 0.347 | Acc: 88.178% (39560/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9565, Accuracy: 4546/10000 (45.46%)

Epoch: 106
Loss: 0.643 | Acc: 73.438% (47/64)
Loss: 0.363 | Acc: 87.856% (5679/6464)
Loss: 0.343 | Acc: 88.565% (11393/12864)
Loss: 0.333 | Acc: 88.808% (17108/19264)
Loss: 0.340 | Acc: 88.587% (22735/25664)
Loss: 0.340 | Acc: 88.588% (28405/32064)
Loss: 0.340 | Acc: 88.537% (34055/38464)
Loss: 0.343 | Acc: 88.429% (39673/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4159, Accuracy: 6715/10000 (67.15%)

Epoch: 107
Loss: 0.758 | Acc: 85.938% (55/64)
Loss: 0.324 | Acc: 89.233% (5768/6464)
Loss: 0.334 | Acc: 88.837% (11428/12864)
Loss: 0.336 | Acc: 88.793% (17105/19264)
Loss: 0.335 | Acc: 88.716% (22768/25664)
Loss: 0.339 | Acc: 88.635% (28420/32064)
Loss: 0.340 | Acc: 88.608% (34082/38464)
Loss: 0.337 | Acc: 88.635% (39765/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4327, Accuracy: 4291/10000 (42.91%)

Epoch: 108
Loss: 0.803 | Acc: 75.000% (48/64)
Loss: 0.361 | Acc: 87.763% (5673/6464)
Loss: 0.341 | Acc: 88.573% (11394/12864)
Loss: 0.337 | Acc: 88.730% (17093/19264)
Loss: 0.336 | Acc: 88.766% (22781/25664)
Loss: 0.333 | Acc: 88.782% (28467/32064)
Loss: 0.337 | Acc: 88.657% (34101/38464)
Loss: 0.338 | Acc: 88.621% (39759/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1233, Accuracy: 7093/10000 (70.93%)

Epoch: 109
Loss: 0.433 | Acc: 87.500% (56/64)
Loss: 0.334 | Acc: 89.047% (5756/6464)
Loss: 0.331 | Acc: 88.806% (11424/12864)
Loss: 0.332 | Acc: 88.699% (17087/19264)
Loss: 0.326 | Acc: 88.907% (22817/25664)
Loss: 0.327 | Acc: 88.866% (28494/32064)
Loss: 0.328 | Acc: 88.886% (34189/38464)
Loss: 0.328 | Acc: 88.831% (39853/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4325, Accuracy: 6050/10000 (60.50%)

Epoch: 110
Loss: 0.872 | Acc: 71.875% (46/64)
Loss: 0.337 | Acc: 88.444% (5717/6464)
Loss: 0.324 | Acc: 88.899% (11436/12864)
Loss: 0.325 | Acc: 88.943% (17134/19264)
Loss: 0.326 | Acc: 88.950% (22828/25664)
Loss: 0.326 | Acc: 88.941% (28518/32064)
Loss: 0.326 | Acc: 88.870% (34183/38464)
Loss: 0.325 | Acc: 88.846% (39860/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6468, Accuracy: 8011/10000 (80.11%)

Epoch: 111
Loss: 0.393 | Acc: 82.812% (53/64)
Loss: 0.309 | Acc: 89.558% (5789/6464)
Loss: 0.315 | Acc: 89.350% (11494/12864)
Loss: 0.313 | Acc: 89.488% (17239/19264)
Loss: 0.313 | Acc: 89.394% (22942/25664)
Loss: 0.316 | Acc: 89.237% (28613/32064)
Loss: 0.318 | Acc: 89.156% (34293/38464)
Loss: 0.319 | Acc: 89.154% (39998/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3125, Accuracy: 6159/10000 (61.59%)

Epoch: 112
Loss: 0.730 | Acc: 76.562% (49/64)
Loss: 0.302 | Acc: 89.356% (5776/6464)
Loss: 0.313 | Acc: 89.265% (11483/12864)
Loss: 0.314 | Acc: 89.364% (17215/19264)
Loss: 0.312 | Acc: 89.355% (22932/25664)
Loss: 0.314 | Acc: 89.340% (28646/32064)
Loss: 0.316 | Acc: 89.322% (34357/38464)
Loss: 0.316 | Acc: 89.294% (40061/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7574, Accuracy: 7609/10000 (76.09%)

Epoch: 113
Loss: 0.343 | Acc: 90.625% (58/64)
Loss: 0.296 | Acc: 90.145% (5827/6464)
Loss: 0.297 | Acc: 90.058% (11585/12864)
Loss: 0.295 | Acc: 90.070% (17351/19264)
Loss: 0.295 | Acc: 89.994% (23096/25664)
Loss: 0.295 | Acc: 89.954% (28843/32064)
Loss: 0.297 | Acc: 89.806% (34543/38464)
Loss: 0.299 | Acc: 89.787% (40282/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8552, Accuracy: 6093/10000 (60.93%)

Epoch: 114
Loss: 0.322 | Acc: 89.062% (57/64)
Loss: 0.294 | Acc: 89.929% (5813/6464)
Loss: 0.297 | Acc: 89.840% (11557/12864)
Loss: 0.302 | Acc: 89.623% (17265/19264)
Loss: 0.300 | Acc: 89.670% (23013/25664)
Loss: 0.298 | Acc: 89.777% (28786/32064)
Loss: 0.299 | Acc: 89.715% (34508/38464)
Loss: 0.300 | Acc: 89.782% (40280/44864)
torch.Size([100, 10])
Test set: Average loss: 3.0354, Accuracy: 4387/10000 (43.87%)

Epoch: 115
Loss: 0.757 | Acc: 73.438% (47/64)
Loss: 0.294 | Acc: 90.254% (5834/6464)
Loss: 0.288 | Acc: 90.244% (11609/12864)
Loss: 0.285 | Acc: 90.355% (17406/19264)
Loss: 0.287 | Acc: 90.181% (23144/25664)
Loss: 0.291 | Acc: 90.017% (28863/32064)
Loss: 0.293 | Acc: 90.019% (34625/38464)
Loss: 0.295 | Acc: 89.927% (40345/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5308, Accuracy: 8304/10000 (83.04%)

Epoch: 116
Loss: 0.239 | Acc: 89.062% (57/64)
Loss: 0.277 | Acc: 90.811% (5870/6464)
Loss: 0.274 | Acc: 90.617% (11657/12864)
Loss: 0.285 | Acc: 90.246% (17385/19264)
Loss: 0.284 | Acc: 90.286% (23171/25664)
Loss: 0.286 | Acc: 90.307% (28956/32064)
Loss: 0.285 | Acc: 90.336% (34747/38464)
Loss: 0.290 | Acc: 90.186% (40461/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6811, Accuracy: 7973/10000 (79.73%)

Epoch: 117
Loss: 0.396 | Acc: 90.625% (58/64)
Loss: 0.286 | Acc: 90.548% (5853/6464)
Loss: 0.283 | Acc: 90.493% (11641/12864)
Loss: 0.280 | Acc: 90.474% (17429/19264)
Loss: 0.275 | Acc: 90.637% (23261/25664)
Loss: 0.278 | Acc: 90.510% (29021/32064)
Loss: 0.281 | Acc: 90.370% (34760/38464)
Loss: 0.282 | Acc: 90.398% (40556/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6170, Accuracy: 8104/10000 (81.04%)

Epoch: 118
Loss: 0.473 | Acc: 87.500% (56/64)
Loss: 0.264 | Acc: 90.826% (5871/6464)
Loss: 0.268 | Acc: 90.695% (11667/12864)
Loss: 0.265 | Acc: 90.879% (17507/19264)
Loss: 0.270 | Acc: 90.668% (23269/25664)
Loss: 0.269 | Acc: 90.731% (29092/32064)
Loss: 0.270 | Acc: 90.693% (34884/38464)
Loss: 0.270 | Acc: 90.696% (40690/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5431, Accuracy: 6071/10000 (60.71%)

Epoch: 119
Loss: 0.237 | Acc: 89.062% (57/64)
Loss: 0.264 | Acc: 90.873% (5874/6464)
Loss: 0.262 | Acc: 91.161% (11727/12864)
Loss: 0.263 | Acc: 91.020% (17534/19264)
Loss: 0.264 | Acc: 91.073% (23373/25664)
Loss: 0.262 | Acc: 91.221% (29249/32064)
Loss: 0.262 | Acc: 91.220% (35087/38464)
Loss: 0.263 | Acc: 91.184% (40909/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6625, Accuracy: 8015/10000 (80.15%)

Epoch: 120
Loss: 0.223 | Acc: 92.188% (59/64)
Loss: 0.262 | Acc: 91.306% (5902/6464)
Loss: 0.249 | Acc: 91.822% (11812/12864)
Loss: 0.255 | Acc: 91.549% (17636/19264)
Loss: 0.249 | Acc: 91.685% (23530/25664)
Loss: 0.249 | Acc: 91.639% (29383/32064)
Loss: 0.253 | Acc: 91.480% (35187/38464)
Loss: 0.253 | Acc: 91.479% (41041/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7125, Accuracy: 7719/10000 (77.19%)

Epoch: 121
Loss: 0.161 | Acc: 95.312% (61/64)
Loss: 0.222 | Acc: 92.574% (5984/6464)
Loss: 0.241 | Acc: 91.682% (11794/12864)
Loss: 0.245 | Acc: 91.616% (17649/19264)
Loss: 0.246 | Acc: 91.630% (23516/25664)
Loss: 0.247 | Acc: 91.558% (29357/32064)
Loss: 0.247 | Acc: 91.538% (35209/38464)
Loss: 0.247 | Acc: 91.490% (41046/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5005, Accuracy: 8440/10000 (84.40%)

Epoch: 122
Loss: 0.499 | Acc: 84.375% (54/64)
Loss: 0.227 | Acc: 92.064% (5951/6464)
Loss: 0.222 | Acc: 92.421% (11889/12864)
Loss: 0.225 | Acc: 92.317% (17784/19264)
Loss: 0.231 | Acc: 92.102% (23637/25664)
Loss: 0.236 | Acc: 91.944% (29481/32064)
Loss: 0.236 | Acc: 91.912% (35353/38464)
Loss: 0.237 | Acc: 91.882% (41222/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6451, Accuracy: 8054/10000 (80.54%)

Epoch: 123
Loss: 0.305 | Acc: 89.062% (57/64)
Loss: 0.197 | Acc: 93.131% (6020/6464)
Loss: 0.218 | Acc: 92.366% (11882/12864)
Loss: 0.225 | Acc: 92.058% (17734/19264)
Loss: 0.224 | Acc: 92.117% (23641/25664)
Loss: 0.227 | Acc: 92.038% (29511/32064)
Loss: 0.229 | Acc: 91.985% (35381/38464)
Loss: 0.229 | Acc: 92.011% (41280/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3345, Accuracy: 8914/10000 (89.14%)

Epoch: 124
Loss: 0.062 | Acc: 98.438% (63/64)
Loss: 0.200 | Acc: 93.673% (6055/6464)
Loss: 0.206 | Acc: 93.416% (12017/12864)
Loss: 0.205 | Acc: 93.309% (17975/19264)
Loss: 0.208 | Acc: 93.127% (23900/25664)
Loss: 0.213 | Acc: 92.905% (29789/32064)
Loss: 0.214 | Acc: 92.908% (35736/38464)
Loss: 0.214 | Acc: 92.896% (41677/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3828, Accuracy: 8764/10000 (87.64%)

Epoch: 125
Loss: 0.164 | Acc: 93.750% (60/64)
Loss: 0.200 | Acc: 92.791% (5998/6464)
Loss: 0.203 | Acc: 92.739% (11930/12864)
Loss: 0.210 | Acc: 92.551% (17829/19264)
Loss: 0.206 | Acc: 92.807% (23818/25664)
Loss: 0.205 | Acc: 92.914% (29792/32064)
Loss: 0.206 | Acc: 92.876% (35724/38464)
Loss: 0.208 | Acc: 92.825% (41645/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7307, Accuracy: 7832/10000 (78.32%)

Epoch: 126
Loss: 0.341 | Acc: 87.500% (56/64)
Loss: 0.201 | Acc: 92.961% (6009/6464)
Loss: 0.195 | Acc: 93.392% (12014/12864)
Loss: 0.197 | Acc: 93.210% (17956/19264)
Loss: 0.201 | Acc: 93.010% (23870/25664)
Loss: 0.200 | Acc: 93.073% (29843/32064)
Loss: 0.200 | Acc: 93.123% (35819/38464)
Loss: 0.202 | Acc: 92.994% (41721/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3747, Accuracy: 8799/10000 (87.99%)

Epoch: 127
Loss: 0.293 | Acc: 93.750% (60/64)
Loss: 0.179 | Acc: 93.812% (6064/6464)
Loss: 0.181 | Acc: 93.680% (12051/12864)
Loss: 0.181 | Acc: 93.677% (18046/19264)
Loss: 0.184 | Acc: 93.660% (24037/25664)
Loss: 0.185 | Acc: 93.678% (30037/32064)
Loss: 0.187 | Acc: 93.560% (35987/38464)
Loss: 0.186 | Acc: 93.585% (41986/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5087, Accuracy: 8530/10000 (85.30%)

Epoch: 128
Loss: 0.208 | Acc: 89.062% (57/64)
Loss: 0.156 | Acc: 94.524% (6110/6464)
Loss: 0.159 | Acc: 94.465% (12152/12864)
Loss: 0.164 | Acc: 94.264% (18159/19264)
Loss: 0.163 | Acc: 94.334% (24210/25664)
Loss: 0.171 | Acc: 94.031% (30150/32064)
Loss: 0.172 | Acc: 94.013% (36161/38464)
Loss: 0.173 | Acc: 94.002% (42173/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3229, Accuracy: 8958/10000 (89.58%)

Epoch: 129
Loss: 0.073 | Acc: 96.875% (62/64)
Loss: 0.169 | Acc: 94.369% (6100/6464)
Loss: 0.156 | Acc: 94.753% (12189/12864)
Loss: 0.159 | Acc: 94.674% (18238/19264)
Loss: 0.158 | Acc: 94.689% (24301/25664)
Loss: 0.160 | Acc: 94.629% (30342/32064)
Loss: 0.161 | Acc: 94.496% (36347/38464)
Loss: 0.160 | Acc: 94.544% (42416/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2537, Accuracy: 7321/10000 (73.21%)

Epoch: 130
Loss: 0.174 | Acc: 90.625% (58/64)
Loss: 0.155 | Acc: 94.678% (6120/6464)
Loss: 0.150 | Acc: 94.846% (12201/12864)
Loss: 0.145 | Acc: 95.027% (18306/19264)
Loss: 0.148 | Acc: 94.923% (24361/25664)
Loss: 0.148 | Acc: 94.895% (30427/32064)
Loss: 0.151 | Acc: 94.806% (36466/38464)
Loss: 0.152 | Acc: 94.802% (42532/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3233, Accuracy: 8990/10000 (89.90%)

Epoch: 131
Loss: 0.229 | Acc: 89.062% (57/64)
Loss: 0.124 | Acc: 95.761% (6190/6464)
Loss: 0.131 | Acc: 95.499% (12285/12864)
Loss: 0.131 | Acc: 95.572% (18411/19264)
Loss: 0.133 | Acc: 95.519% (24514/25664)
Loss: 0.133 | Acc: 95.497% (30620/32064)
Loss: 0.134 | Acc: 95.479% (36725/38464)
Loss: 0.137 | Acc: 95.346% (42776/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2868, Accuracy: 9095/10000 (90.95%)

Epoch: 132
Loss: 0.081 | Acc: 96.875% (62/64)
Loss: 0.122 | Acc: 95.885% (6198/6464)
Loss: 0.124 | Acc: 95.818% (12326/12864)
Loss: 0.127 | Acc: 95.712% (18438/19264)
Loss: 0.123 | Acc: 95.827% (24593/25664)
Loss: 0.125 | Acc: 95.805% (30719/32064)
Loss: 0.126 | Acc: 95.752% (36830/38464)
Loss: 0.127 | Acc: 95.732% (42949/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4431, Accuracy: 8728/10000 (87.28%)

Epoch: 133
Loss: 0.202 | Acc: 92.188% (59/64)
Loss: 0.107 | Acc: 96.627% (6246/6464)
Loss: 0.106 | Acc: 96.517% (12416/12864)
Loss: 0.106 | Acc: 96.558% (18601/19264)
Loss: 0.106 | Acc: 96.485% (24762/25664)
Loss: 0.110 | Acc: 96.329% (30887/32064)
Loss: 0.112 | Acc: 96.228% (37013/38464)
Loss: 0.110 | Acc: 96.291% (43200/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5812, Accuracy: 8479/10000 (84.79%)

Epoch: 134
Loss: 0.121 | Acc: 95.312% (61/64)
Loss: 0.096 | Acc: 96.689% (6250/6464)
Loss: 0.091 | Acc: 96.821% (12455/12864)
Loss: 0.095 | Acc: 96.662% (18621/19264)
Loss: 0.096 | Acc: 96.665% (24808/25664)
Loss: 0.097 | Acc: 96.669% (30996/32064)
Loss: 0.099 | Acc: 96.610% (37160/38464)
Loss: 0.098 | Acc: 96.628% (43351/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3078, Accuracy: 9093/10000 (90.93%)

Epoch: 135
Loss: 0.029 | Acc: 100.000% (64/64)
Loss: 0.080 | Acc: 97.184% (6282/6464)
Loss: 0.081 | Acc: 97.287% (12515/12864)
Loss: 0.081 | Acc: 97.316% (18747/19264)
Loss: 0.082 | Acc: 97.269% (24963/25664)
Loss: 0.084 | Acc: 97.187% (31162/32064)
Loss: 0.083 | Acc: 97.223% (37396/38464)
Loss: 0.083 | Acc: 97.247% (43629/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2382, Accuracy: 9270/10000 (92.70%)

Epoch: 136
Loss: 0.124 | Acc: 95.312% (61/64)
Loss: 0.073 | Acc: 97.246% (6286/6464)
Loss: 0.068 | Acc: 97.645% (12561/12864)
Loss: 0.068 | Acc: 97.633% (18808/19264)
Loss: 0.070 | Acc: 97.592% (25046/25664)
Loss: 0.070 | Acc: 97.620% (31301/32064)
Loss: 0.070 | Acc: 97.587% (37536/38464)
Loss: 0.070 | Acc: 97.619% (43796/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2534, Accuracy: 9261/10000 (92.61%)

Epoch: 137
Loss: 0.061 | Acc: 96.875% (62/64)
Loss: 0.059 | Acc: 98.051% (6338/6464)
Loss: 0.055 | Acc: 98.212% (12634/12864)
Loss: 0.052 | Acc: 98.261% (18929/19264)
Loss: 0.054 | Acc: 98.247% (25214/25664)
Loss: 0.053 | Acc: 98.263% (31507/32064)
Loss: 0.054 | Acc: 98.256% (37793/38464)
Loss: 0.055 | Acc: 98.206% (44059/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2272, Accuracy: 9336/10000 (93.36%)

Epoch: 138
Loss: 0.037 | Acc: 98.438% (63/64)
Loss: 0.048 | Acc: 98.376% (6359/6464)
Loss: 0.047 | Acc: 98.422% (12661/12864)
Loss: 0.047 | Acc: 98.417% (18959/19264)
Loss: 0.046 | Acc: 98.438% (25263/25664)
Loss: 0.047 | Acc: 98.413% (31555/32064)
Loss: 0.047 | Acc: 98.404% (37850/38464)
Loss: 0.046 | Acc: 98.466% (44176/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3440, Accuracy: 9070/10000 (90.70%)

Epoch: 139
Loss: 0.169 | Acc: 93.750% (60/64)
Loss: 0.040 | Acc: 98.700% (6380/6464)
Loss: 0.038 | Acc: 98.803% (12710/12864)
Loss: 0.038 | Acc: 98.785% (19030/19264)
Loss: 0.037 | Acc: 98.808% (25358/25664)
Loss: 0.037 | Acc: 98.790% (31676/32064)
Loss: 0.037 | Acc: 98.817% (38009/38464)
Loss: 0.036 | Acc: 98.868% (44356/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2296, Accuracy: 9352/10000 (93.52%)

Epoch: 140
Loss: 0.040 | Acc: 96.875% (62/64)
Loss: 0.028 | Acc: 99.149% (6409/6464)
Loss: 0.026 | Acc: 99.215% (12763/12864)
Loss: 0.025 | Acc: 99.268% (19123/19264)
Loss: 0.025 | Acc: 99.244% (25470/25664)
Loss: 0.025 | Acc: 99.242% (31821/32064)
Loss: 0.026 | Acc: 99.225% (38166/38464)
Loss: 0.027 | Acc: 99.202% (44506/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2007, Accuracy: 9448/10000 (94.48%)

Epoch: 141
Loss: 0.013 | Acc: 100.000% (64/64)
Loss: 0.019 | Acc: 99.428% (6427/6464)
Loss: 0.018 | Acc: 99.526% (12803/12864)
Loss: 0.018 | Acc: 99.512% (19170/19264)
Loss: 0.019 | Acc: 99.451% (25523/25664)
Loss: 0.019 | Acc: 99.454% (31889/32064)
Loss: 0.019 | Acc: 99.444% (38250/38464)
Loss: 0.019 | Acc: 99.432% (44609/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2038, Accuracy: 9474/10000 (94.74%)

Epoch: 142
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.018 | Acc: 99.489% (6431/6464)
Loss: 0.017 | Acc: 99.495% (12799/12864)
Loss: 0.017 | Acc: 99.533% (19174/19264)
Loss: 0.017 | Acc: 99.525% (25542/25664)
Loss: 0.016 | Acc: 99.563% (31924/32064)
Loss: 0.016 | Acc: 99.553% (38292/38464)
Loss: 0.016 | Acc: 99.561% (44667/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1927, Accuracy: 9472/10000 (94.72%)

Epoch: 143
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.752% (6448/6464)
Loss: 0.012 | Acc: 99.728% (12829/12864)
Loss: 0.011 | Acc: 99.730% (19212/19264)
Loss: 0.011 | Acc: 99.747% (25599/25664)
Loss: 0.011 | Acc: 99.741% (31981/32064)
Loss: 0.011 | Acc: 99.719% (38356/38464)
Loss: 0.011 | Acc: 99.730% (44743/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1974, Accuracy: 9466/10000 (94.66%)

Epoch: 144
Loss: 0.017 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.768% (6449/6464)
Loss: 0.009 | Acc: 99.790% (12837/12864)
Loss: 0.009 | Acc: 99.772% (19220/19264)
Loss: 0.009 | Acc: 99.762% (25603/25664)
Loss: 0.008 | Acc: 99.785% (31995/32064)
Loss: 0.009 | Acc: 99.776% (38378/38464)
Loss: 0.009 | Acc: 99.766% (44759/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1917, Accuracy: 9499/10000 (94.99%)

Epoch: 145
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.768% (6449/6464)
Loss: 0.008 | Acc: 99.829% (12842/12864)
Loss: 0.009 | Acc: 99.787% (19223/19264)
Loss: 0.009 | Acc: 99.809% (25615/25664)
Loss: 0.009 | Acc: 99.819% (32006/32064)
Loss: 0.009 | Acc: 99.828% (38398/38464)
Loss: 0.009 | Acc: 99.815% (44781/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1870, Accuracy: 9490/10000 (94.90%)

Epoch: 146
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.892% (6457/6464)
Loss: 0.008 | Acc: 99.876% (12848/12864)
Loss: 0.008 | Acc: 99.860% (19237/19264)
Loss: 0.009 | Acc: 99.836% (25622/25664)
Loss: 0.009 | Acc: 99.819% (32006/32064)
Loss: 0.009 | Acc: 99.813% (38392/38464)
Loss: 0.009 | Acc: 99.824% (44785/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1844, Accuracy: 9490/10000 (94.90%)

Epoch: 147
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.876% (6456/6464)
Loss: 0.009 | Acc: 99.806% (12839/12864)
Loss: 0.009 | Acc: 99.829% (19231/19264)
Loss: 0.009 | Acc: 99.836% (25622/25664)
Loss: 0.009 | Acc: 99.838% (32012/32064)
Loss: 0.009 | Acc: 99.839% (38402/38464)
Loss: 0.009 | Acc: 99.842% (44793/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1824, Accuracy: 9481/10000 (94.81%)
torch.Size([100, 10])
Test set: Average loss: 0.1824, Accuracy: 9481/10000 (94.81%)

Epoch: 148
Loss: 0.009 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.876% (6456/6464)
Loss: 0.008 | Acc: 99.876% (12848/12864)
Loss: 0.009 | Acc: 99.855% (19236/19264)
Loss: 0.009 | Acc: 99.860% (25628/25664)
Loss: 0.009 | Acc: 99.838% (32012/32064)
Loss: 0.009 | Acc: 99.847% (38405/38464)
Loss: 0.009 | Acc: 99.851% (44797/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1811, Accuracy: 9485/10000 (94.85%)
torch.Size([100, 10])
Test set: Average loss: 0.1811, Accuracy: 9485/10000 (94.85%)

Epoch: 149
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.907% (6458/6464)
Loss: 0.008 | Acc: 99.899% (12851/12864)
Loss: 0.009 | Acc: 99.886% (19242/19264)
Loss: 0.009 | Acc: 99.860% (25628/25664)
Loss: 0.009 | Acc: 99.844% (32014/32064)
Loss: 0.009 | Acc: 99.847% (38405/38464)
Loss: 0.009 | Acc: 99.837% (44791/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1833, Accuracy: 9480/10000 (94.80%)
torch.Size([100, 10])
Test set: Average loss: 0.1833, Accuracy: 9480/10000 (94.80%)

Epoch: 150
Loss: 0.011 | Acc: 100.000% (64/64)
Loss: 1.927 | Acc: 30.476% (1970/6464)
Loss: 1.502 | Acc: 46.331% (5960/12864)
Loss: 1.236 | Acc: 56.167% (10820/19264)
Loss: 1.073 | Acc: 62.095% (15936/25664)
Loss: 0.963 | Acc: 66.087% (21190/32064)
Loss: 0.885 | Acc: 68.994% (26538/38464)
Loss: 0.828 | Acc: 71.122% (31908/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8270, Accuracy: 5472/10000 (54.72%)

Epoch: 151
Loss: 0.757 | Acc: 79.688% (51/64)
Loss: 0.448 | Acc: 85.102% (5501/6464)
Loss: 0.434 | Acc: 85.362% (10981/12864)
Loss: 0.434 | Acc: 85.398% (16451/19264)
Loss: 0.428 | Acc: 85.563% (21959/25664)
Loss: 0.418 | Acc: 85.822% (27518/32064)
Loss: 0.416 | Acc: 85.964% (33065/38464)
Loss: 0.411 | Acc: 86.073% (38616/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2725, Accuracy: 6237/10000 (62.37%)

Epoch: 152
Loss: 0.802 | Acc: 71.875% (46/64)
Loss: 0.372 | Acc: 87.082% (5629/6464)
Loss: 0.365 | Acc: 87.469% (11252/12864)
Loss: 0.371 | Acc: 87.344% (16826/19264)
Loss: 0.376 | Acc: 87.134% (22362/25664)
Loss: 0.376 | Acc: 87.173% (27951/32064)
Loss: 0.375 | Acc: 87.204% (33542/38464)
Loss: 0.372 | Acc: 87.255% (39146/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0548, Accuracy: 5893/10000 (58.93%)

Epoch: 153
Loss: 1.545 | Acc: 68.750% (44/64)
Loss: 0.363 | Acc: 88.289% (5707/6464)
Loss: 0.348 | Acc: 88.363% (11367/12864)
Loss: 0.350 | Acc: 88.253% (17001/19264)
Loss: 0.346 | Acc: 88.310% (22664/25664)
Loss: 0.346 | Acc: 88.273% (28304/32064)
Loss: 0.349 | Acc: 88.147% (33905/38464)
Loss: 0.349 | Acc: 88.162% (39553/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6006, Accuracy: 8100/10000 (81.00%)

Epoch: 154
Loss: 0.285 | Acc: 90.625% (58/64)
Loss: 0.339 | Acc: 88.598% (5727/6464)
Loss: 0.340 | Acc: 88.604% (11398/12864)
Loss: 0.345 | Acc: 88.549% (17058/19264)
Loss: 0.340 | Acc: 88.614% (22742/25664)
Loss: 0.341 | Acc: 88.651% (28425/32064)
Loss: 0.341 | Acc: 88.636% (34093/38464)
Loss: 0.341 | Acc: 88.666% (39779/44864)
torch.Size([100, 10])
Test set: Average loss: 2.7786, Accuracy: 5226/10000 (52.26%)

Epoch: 155
Loss: 0.734 | Acc: 81.250% (52/64)
Loss: 0.336 | Acc: 88.521% (5722/6464)
Loss: 0.337 | Acc: 88.643% (11403/12864)
Loss: 0.331 | Acc: 88.756% (17098/19264)
Loss: 0.335 | Acc: 88.653% (22752/25664)
Loss: 0.335 | Acc: 88.648% (28424/32064)
Loss: 0.337 | Acc: 88.600% (34079/38464)
Loss: 0.339 | Acc: 88.543% (39724/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8460, Accuracy: 7636/10000 (76.36%)

Epoch: 156
Loss: 0.257 | Acc: 90.625% (58/64)
Loss: 0.329 | Acc: 88.815% (5741/6464)
Loss: 0.324 | Acc: 88.993% (11448/12864)
Loss: 0.326 | Acc: 88.979% (17141/19264)
Loss: 0.326 | Acc: 88.926% (22822/25664)
Loss: 0.331 | Acc: 88.772% (28464/32064)
Loss: 0.330 | Acc: 88.797% (34155/38464)
Loss: 0.330 | Acc: 88.768% (39825/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7238, Accuracy: 6461/10000 (64.61%)

Epoch: 157
Loss: 0.556 | Acc: 76.562% (49/64)
Loss: 0.319 | Acc: 89.124% (5761/6464)
Loss: 0.326 | Acc: 88.969% (11445/12864)
Loss: 0.328 | Acc: 88.953% (17136/19264)
Loss: 0.326 | Acc: 89.012% (22844/25664)
Loss: 0.327 | Acc: 88.963% (28525/32064)
Loss: 0.325 | Acc: 89.031% (34245/38464)
Loss: 0.326 | Acc: 88.967% (39914/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1379, Accuracy: 5935/10000 (59.35%)

Epoch: 158
Loss: 0.694 | Acc: 75.000% (48/64)
Loss: 0.325 | Acc: 89.109% (5760/6464)
Loss: 0.328 | Acc: 88.814% (11425/12864)
Loss: 0.320 | Acc: 89.062% (17157/19264)
Loss: 0.319 | Acc: 89.140% (22877/25664)
Loss: 0.323 | Acc: 89.019% (28543/32064)
Loss: 0.323 | Acc: 89.101% (34272/38464)
Loss: 0.324 | Acc: 89.056% (39954/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3682, Accuracy: 6462/10000 (64.62%)

Epoch: 159
Loss: 0.415 | Acc: 87.500% (56/64)
Loss: 0.304 | Acc: 89.805% (5805/6464)
Loss: 0.312 | Acc: 89.513% (11515/12864)
Loss: 0.313 | Acc: 89.431% (17228/19264)
Loss: 0.316 | Acc: 89.320% (22923/25664)
Loss: 0.316 | Acc: 89.275% (28625/32064)
Loss: 0.316 | Acc: 89.260% (34333/38464)
Loss: 0.321 | Acc: 89.114% (39980/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4853, Accuracy: 5514/10000 (55.14%)

Epoch: 160
Loss: 0.853 | Acc: 79.688% (51/64)
Loss: 0.317 | Acc: 89.372% (5777/6464)
Loss: 0.312 | Acc: 89.576% (11523/12864)
Loss: 0.314 | Acc: 89.530% (17247/19264)
Loss: 0.315 | Acc: 89.343% (22929/25664)
Loss: 0.310 | Acc: 89.508% (28700/32064)
Loss: 0.314 | Acc: 89.291% (34345/38464)
Loss: 0.314 | Acc: 89.263% (40047/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7292, Accuracy: 7699/10000 (76.99%)

Epoch: 161
Loss: 0.358 | Acc: 87.500% (56/64)
Loss: 0.293 | Acc: 89.991% (5817/6464)
Loss: 0.294 | Acc: 90.003% (11578/12864)
Loss: 0.299 | Acc: 89.805% (17300/19264)
Loss: 0.305 | Acc: 89.643% (23006/25664)
Loss: 0.304 | Acc: 89.646% (28744/32064)
Loss: 0.306 | Acc: 89.611% (34468/38464)
Loss: 0.308 | Acc: 89.537% (40170/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6950, Accuracy: 7837/10000 (78.37%)

Epoch: 162
Loss: 0.394 | Acc: 90.625% (58/64)
Loss: 0.293 | Acc: 90.114% (5825/6464)
Loss: 0.297 | Acc: 89.910% (11566/12864)
Loss: 0.302 | Acc: 89.665% (17273/19264)
Loss: 0.302 | Acc: 89.608% (22997/25664)
Loss: 0.304 | Acc: 89.490% (28694/32064)
Loss: 0.303 | Acc: 89.567% (34451/38464)
Loss: 0.306 | Acc: 89.493% (40150/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3459, Accuracy: 8870/10000 (88.70%)

Epoch: 163
Loss: 0.220 | Acc: 92.188% (59/64)
Loss: 0.283 | Acc: 90.610% (5857/6464)
Loss: 0.293 | Acc: 90.236% (11608/12864)
Loss: 0.297 | Acc: 90.080% (17353/19264)
Loss: 0.297 | Acc: 90.115% (23127/25664)
Loss: 0.299 | Acc: 89.995% (28856/32064)
Loss: 0.299 | Acc: 90.017% (34624/38464)
Loss: 0.299 | Acc: 90.010% (40382/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6358, Accuracy: 7999/10000 (79.99%)

Epoch: 164
Loss: 0.195 | Acc: 93.750% (60/64)
Loss: 0.274 | Acc: 90.501% (5850/6464)
Loss: 0.278 | Acc: 90.407% (11630/12864)
Loss: 0.283 | Acc: 90.241% (17384/19264)
Loss: 0.290 | Acc: 90.076% (23117/25664)
Loss: 0.291 | Acc: 90.061% (28877/32064)
Loss: 0.291 | Acc: 90.050% (34637/38464)
Loss: 0.294 | Acc: 89.954% (40357/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5486, Accuracy: 8364/10000 (83.64%)

Epoch: 165
Loss: 0.231 | Acc: 93.750% (60/64)
Loss: 0.272 | Acc: 90.470% (5848/6464)
Loss: 0.282 | Acc: 90.244% (11609/12864)
Loss: 0.281 | Acc: 90.272% (17390/19264)
Loss: 0.280 | Acc: 90.368% (23192/25664)
Loss: 0.281 | Acc: 90.341% (28967/32064)
Loss: 0.279 | Acc: 90.461% (34795/38464)
Loss: 0.281 | Acc: 90.422% (40567/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2805, Accuracy: 6770/10000 (67.70%)

Epoch: 166
Loss: 1.413 | Acc: 67.188% (43/64)
Loss: 0.281 | Acc: 90.919% (5877/6464)
Loss: 0.278 | Acc: 90.625% (11658/12864)
Loss: 0.285 | Acc: 90.173% (17371/19264)
Loss: 0.285 | Acc: 90.282% (23170/25664)
Loss: 0.285 | Acc: 90.251% (28938/32064)
Loss: 0.286 | Acc: 90.266% (34720/38464)
Loss: 0.283 | Acc: 90.371% (40544/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4537, Accuracy: 7060/10000 (70.60%)

Epoch: 167
Loss: 0.657 | Acc: 82.812% (53/64)
Loss: 0.275 | Acc: 90.996% (5882/6464)
Loss: 0.269 | Acc: 90.998% (11706/12864)
Loss: 0.261 | Acc: 91.196% (17568/19264)
Loss: 0.263 | Acc: 91.135% (23389/25664)
Loss: 0.268 | Acc: 90.974% (29170/32064)
Loss: 0.271 | Acc: 90.830% (34937/38464)
Loss: 0.272 | Acc: 90.801% (40737/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3844, Accuracy: 6803/10000 (68.03%)

Epoch: 168
Loss: 0.412 | Acc: 84.375% (54/64)
Loss: 0.269 | Acc: 90.517% (5851/6464)
Loss: 0.263 | Acc: 90.905% (11694/12864)
Loss: 0.267 | Acc: 90.786% (17489/19264)
Loss: 0.267 | Acc: 90.812% (23306/25664)
Loss: 0.267 | Acc: 90.915% (29151/32064)
Loss: 0.268 | Acc: 90.833% (34938/38464)
Loss: 0.266 | Acc: 90.970% (40813/44864)
torch.Size([100, 10])
Test set: Average loss: 9.3656, Accuracy: 2683/10000 (26.83%)

Epoch: 169
Loss: 0.593 | Acc: 81.250% (52/64)
Loss: 0.263 | Acc: 91.151% (5892/6464)
Loss: 0.257 | Acc: 91.379% (11755/12864)
Loss: 0.256 | Acc: 91.373% (17602/19264)
Loss: 0.255 | Acc: 91.369% (23449/25664)
Loss: 0.255 | Acc: 91.355% (29292/32064)
Loss: 0.257 | Acc: 91.262% (35103/38464)
Loss: 0.259 | Acc: 91.220% (40925/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5376, Accuracy: 6212/10000 (62.12%)

Epoch: 170
Loss: 0.538 | Acc: 81.250% (52/64)
Loss: 0.255 | Acc: 91.306% (5902/6464)
Loss: 0.248 | Acc: 91.426% (11761/12864)
Loss: 0.252 | Acc: 91.414% (17610/19264)
Loss: 0.250 | Acc: 91.428% (23464/25664)
Loss: 0.254 | Acc: 91.227% (29251/32064)
Loss: 0.254 | Acc: 91.239% (35094/38464)
Loss: 0.254 | Acc: 91.234% (40931/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9619, Accuracy: 7314/10000 (73.14%)

Epoch: 171
Loss: 0.445 | Acc: 84.375% (54/64)
Loss: 0.230 | Acc: 92.698% (5992/6464)
Loss: 0.227 | Acc: 92.576% (11909/12864)
Loss: 0.237 | Acc: 92.120% (17746/19264)
Loss: 0.238 | Acc: 92.028% (23618/25664)
Loss: 0.241 | Acc: 91.844% (29449/32064)
Loss: 0.240 | Acc: 91.891% (35345/38464)
Loss: 0.241 | Acc: 91.831% (41199/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9520, Accuracy: 7545/10000 (75.45%)

Epoch: 172
Loss: 0.402 | Acc: 87.500% (56/64)
Loss: 0.252 | Acc: 91.538% (5917/6464)
Loss: 0.230 | Acc: 92.055% (11842/12864)
Loss: 0.228 | Acc: 92.219% (17765/19264)
Loss: 0.233 | Acc: 91.977% (23605/25664)
Loss: 0.233 | Acc: 92.010% (29502/32064)
Loss: 0.234 | Acc: 91.948% (35367/38464)
Loss: 0.233 | Acc: 91.987% (41269/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5319, Accuracy: 5041/10000 (50.41%)

Epoch: 173
Loss: 0.302 | Acc: 92.188% (59/64)
Loss: 0.254 | Acc: 91.460% (5912/6464)
Loss: 0.230 | Acc: 92.125% (11851/12864)
Loss: 0.227 | Acc: 92.271% (17775/19264)
Loss: 0.226 | Acc: 92.324% (23694/25664)
Loss: 0.224 | Acc: 92.375% (29619/32064)
Loss: 0.224 | Acc: 92.395% (35539/38464)
Loss: 0.224 | Acc: 92.368% (41440/44864)
torch.Size([100, 10])
Test set: Average loss: 4.5082, Accuracy: 3436/10000 (34.36%)

Epoch: 174
Loss: 0.670 | Acc: 79.688% (51/64)
Loss: 0.236 | Acc: 92.033% (5949/6464)
Loss: 0.228 | Acc: 92.242% (11866/12864)
Loss: 0.223 | Acc: 92.400% (17800/19264)
Loss: 0.220 | Acc: 92.413% (23717/25664)
Loss: 0.218 | Acc: 92.478% (29652/32064)
Loss: 0.215 | Acc: 92.629% (35629/38464)
Loss: 0.216 | Acc: 92.611% (41549/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4373, Accuracy: 8645/10000 (86.45%)

Epoch: 175
Loss: 0.211 | Acc: 92.188% (59/64)
Loss: 0.188 | Acc: 93.719% (6058/6464)
Loss: 0.196 | Acc: 93.315% (12004/12864)
Loss: 0.197 | Acc: 93.397% (17992/19264)
Loss: 0.203 | Acc: 93.138% (23903/25664)
Loss: 0.203 | Acc: 93.120% (29858/32064)
Loss: 0.204 | Acc: 93.139% (35825/38464)
Loss: 0.202 | Acc: 93.166% (41798/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9485, Accuracy: 7667/10000 (76.67%)

Epoch: 176
Loss: 0.183 | Acc: 95.312% (61/64)
Loss: 0.170 | Acc: 94.338% (6098/6464)
Loss: 0.180 | Acc: 94.053% (12099/12864)
Loss: 0.188 | Acc: 93.677% (18046/19264)
Loss: 0.189 | Acc: 93.641% (24032/25664)
Loss: 0.190 | Acc: 93.547% (29995/32064)
Loss: 0.187 | Acc: 93.643% (36019/38464)
Loss: 0.189 | Acc: 93.612% (41998/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5927, Accuracy: 8302/10000 (83.02%)

Epoch: 177
Loss: 0.395 | Acc: 84.375% (54/64)
Loss: 0.186 | Acc: 93.595% (6050/6464)
Loss: 0.182 | Acc: 93.843% (12072/12864)
Loss: 0.178 | Acc: 93.895% (18088/19264)
Loss: 0.182 | Acc: 93.824% (24079/25664)
Loss: 0.183 | Acc: 93.769% (30066/32064)
Loss: 0.187 | Acc: 93.630% (36014/38464)
Loss: 0.186 | Acc: 93.656% (42018/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6686, Accuracy: 8019/10000 (80.19%)

Epoch: 178
Loss: 0.197 | Acc: 93.750% (60/64)
Loss: 0.158 | Acc: 94.616% (6116/6464)
Loss: 0.152 | Acc: 94.900% (12208/12864)
Loss: 0.162 | Acc: 94.570% (18218/19264)
Loss: 0.166 | Acc: 94.479% (24247/25664)
Loss: 0.165 | Acc: 94.449% (30284/32064)
Loss: 0.166 | Acc: 94.429% (36321/38464)
Loss: 0.168 | Acc: 94.381% (42343/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5528, Accuracy: 8309/10000 (83.09%)

Epoch: 179
Loss: 0.124 | Acc: 93.750% (60/64)
Loss: 0.167 | Acc: 94.353% (6099/6464)
Loss: 0.159 | Acc: 94.558% (12164/12864)
Loss: 0.155 | Acc: 94.716% (18246/19264)
Loss: 0.156 | Acc: 94.681% (24299/25664)
Loss: 0.154 | Acc: 94.698% (30364/32064)
Loss: 0.154 | Acc: 94.722% (36434/38464)
Loss: 0.155 | Acc: 94.724% (42497/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4111, Accuracy: 8751/10000 (87.51%)

Epoch: 180
Loss: 0.352 | Acc: 90.625% (58/64)
Loss: 0.145 | Acc: 95.158% (6151/6464)
Loss: 0.136 | Acc: 95.476% (12282/12864)
Loss: 0.137 | Acc: 95.427% (18383/19264)
Loss: 0.138 | Acc: 95.429% (24491/25664)
Loss: 0.139 | Acc: 95.347% (30572/32064)
Loss: 0.142 | Acc: 95.284% (36650/38464)
Loss: 0.144 | Acc: 95.230% (42724/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4870, Accuracy: 8551/10000 (85.51%)

Epoch: 181
Loss: 0.129 | Acc: 93.750% (60/64)
Loss: 0.134 | Acc: 95.312% (6161/6464)
Loss: 0.137 | Acc: 95.398% (12272/12864)
Loss: 0.138 | Acc: 95.338% (18366/19264)
Loss: 0.138 | Acc: 95.289% (24455/25664)
Loss: 0.137 | Acc: 95.312% (30561/32064)
Loss: 0.137 | Acc: 95.307% (36659/38464)
Loss: 0.138 | Acc: 95.243% (42730/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4103, Accuracy: 8772/10000 (87.72%)

Epoch: 182
Loss: 0.039 | Acc: 100.000% (64/64)
Loss: 0.118 | Acc: 96.117% (6213/6464)
Loss: 0.111 | Acc: 96.339% (12393/12864)
Loss: 0.116 | Acc: 96.107% (18514/19264)
Loss: 0.116 | Acc: 96.057% (24652/25664)
Loss: 0.119 | Acc: 95.958% (30768/32064)
Loss: 0.121 | Acc: 95.884% (36881/38464)
Loss: 0.121 | Acc: 95.830% (42993/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2478, Accuracy: 9235/10000 (92.35%)

Epoch: 183
Loss: 0.042 | Acc: 100.000% (64/64)
Loss: 0.105 | Acc: 96.566% (6242/6464)
Loss: 0.101 | Acc: 96.611% (12428/12864)
Loss: 0.101 | Acc: 96.584% (18606/19264)
Loss: 0.103 | Acc: 96.548% (24778/25664)
Loss: 0.104 | Acc: 96.551% (30958/32064)
Loss: 0.104 | Acc: 96.490% (37114/38464)
Loss: 0.105 | Acc: 96.425% (43260/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4109, Accuracy: 8866/10000 (88.66%)

Epoch: 184
Loss: 0.122 | Acc: 93.750% (60/64)
Loss: 0.080 | Acc: 97.463% (6300/6464)
Loss: 0.087 | Acc: 97.279% (12514/12864)
Loss: 0.092 | Acc: 96.979% (18682/19264)
Loss: 0.091 | Acc: 97.011% (24897/25664)
Loss: 0.094 | Acc: 96.863% (31058/32064)
Loss: 0.094 | Acc: 96.852% (37253/38464)
Loss: 0.094 | Acc: 96.799% (43428/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2443, Accuracy: 9222/10000 (92.22%)

Epoch: 185
Loss: 0.096 | Acc: 98.438% (63/64)
Loss: 0.081 | Acc: 97.478% (6301/6464)
Loss: 0.081 | Acc: 97.450% (12536/12864)
Loss: 0.080 | Acc: 97.456% (18774/19264)
Loss: 0.083 | Acc: 97.311% (24974/25664)
Loss: 0.082 | Acc: 97.327% (31207/32064)
Loss: 0.081 | Acc: 97.346% (37443/38464)
Loss: 0.080 | Acc: 97.352% (43676/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2342, Accuracy: 9273/10000 (92.73%)

Epoch: 186
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 0.062 | Acc: 97.881% (6327/6464)
Loss: 0.064 | Acc: 97.777% (12578/12864)
Loss: 0.064 | Acc: 97.768% (18834/19264)
Loss: 0.064 | Acc: 97.810% (25102/25664)
Loss: 0.066 | Acc: 97.730% (31336/32064)
Loss: 0.067 | Acc: 97.707% (37582/38464)
Loss: 0.067 | Acc: 97.720% (43841/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2204, Accuracy: 9352/10000 (93.52%)

Epoch: 187
Loss: 0.044 | Acc: 100.000% (64/64)
Loss: 0.053 | Acc: 98.298% (6354/6464)
Loss: 0.052 | Acc: 98.344% (12651/12864)
Loss: 0.054 | Acc: 98.194% (18916/19264)
Loss: 0.054 | Acc: 98.196% (25201/25664)
Loss: 0.056 | Acc: 98.160% (31474/32064)
Loss: 0.057 | Acc: 98.094% (37731/38464)
Loss: 0.056 | Acc: 98.132% (44026/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5784, Accuracy: 8615/10000 (86.15%)

Epoch: 188
Loss: 0.089 | Acc: 96.875% (62/64)
Loss: 0.053 | Acc: 98.283% (6353/6464)
Loss: 0.051 | Acc: 98.259% (12640/12864)
Loss: 0.050 | Acc: 98.323% (18941/19264)
Loss: 0.048 | Acc: 98.367% (25245/25664)
Loss: 0.048 | Acc: 98.409% (31554/32064)
Loss: 0.046 | Acc: 98.484% (37881/38464)
Loss: 0.045 | Acc: 98.509% (44195/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3091, Accuracy: 9150/10000 (91.50%)

Epoch: 189
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 0.034 | Acc: 98.994% (6399/6464)
Loss: 0.035 | Acc: 98.974% (12732/12864)
Loss: 0.035 | Acc: 98.884% (19049/19264)
Loss: 0.035 | Acc: 98.886% (25378/25664)
Loss: 0.035 | Acc: 98.896% (31710/32064)
Loss: 0.036 | Acc: 98.882% (38034/38464)
Loss: 0.035 | Acc: 98.888% (44365/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2053, Accuracy: 9406/10000 (94.06%)

Epoch: 190
Loss: 0.030 | Acc: 98.438% (63/64)
Loss: 0.026 | Acc: 99.226% (6414/6464)
Loss: 0.026 | Acc: 99.207% (12762/12864)
Loss: 0.026 | Acc: 99.227% (19115/19264)
Loss: 0.024 | Acc: 99.287% (25481/25664)
Loss: 0.024 | Acc: 99.270% (31830/32064)
Loss: 0.024 | Acc: 99.275% (38185/38464)
Loss: 0.024 | Acc: 99.280% (44541/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2172, Accuracy: 9390/10000 (93.90%)

Epoch: 191
Loss: 0.019 | Acc: 100.000% (64/64)
Loss: 0.019 | Acc: 99.366% (6423/6464)
Loss: 0.021 | Acc: 99.339% (12779/12864)
Loss: 0.020 | Acc: 99.351% (19139/19264)
Loss: 0.020 | Acc: 99.353% (25498/25664)
Loss: 0.020 | Acc: 99.364% (31860/32064)
Loss: 0.020 | Acc: 99.384% (38227/38464)
Loss: 0.020 | Acc: 99.371% (44582/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2059, Accuracy: 9433/10000 (94.33%)

Epoch: 192
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 0.013 | Acc: 99.752% (6448/6464)
Loss: 0.014 | Acc: 99.666% (12821/12864)
Loss: 0.014 | Acc: 99.673% (19201/19264)
Loss: 0.013 | Acc: 99.700% (25587/25664)
Loss: 0.013 | Acc: 99.669% (31958/32064)
Loss: 0.013 | Acc: 99.675% (38339/38464)
Loss: 0.014 | Acc: 99.634% (44700/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2036, Accuracy: 9472/10000 (94.72%)

Epoch: 193
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.830% (6453/6464)
Loss: 0.010 | Acc: 99.790% (12837/12864)
Loss: 0.010 | Acc: 99.761% (19218/19264)
Loss: 0.010 | Acc: 99.727% (25594/25664)
Loss: 0.010 | Acc: 99.741% (31981/32064)
Loss: 0.010 | Acc: 99.753% (38369/38464)
Loss: 0.010 | Acc: 99.757% (44755/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1947, Accuracy: 9490/10000 (94.90%)

Epoch: 194
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.752% (6448/6464)
Loss: 0.010 | Acc: 99.743% (12831/12864)
Loss: 0.010 | Acc: 99.730% (19212/19264)
Loss: 0.010 | Acc: 99.755% (25601/25664)
Loss: 0.010 | Acc: 99.744% (31982/32064)
Loss: 0.009 | Acc: 99.763% (38373/38464)
Loss: 0.009 | Acc: 99.755% (44754/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1928, Accuracy: 9488/10000 (94.88%)

Epoch: 195
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.783% (6450/6464)
Loss: 0.008 | Acc: 99.845% (12844/12864)
Loss: 0.008 | Acc: 99.870% (19239/19264)
Loss: 0.008 | Acc: 99.852% (25626/25664)
Loss: 0.008 | Acc: 99.838% (32012/32064)
Loss: 0.008 | Acc: 99.836% (38401/38464)
Loss: 0.008 | Acc: 99.844% (44794/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1872, Accuracy: 9497/10000 (94.97%)

Epoch: 196
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.892% (6457/6464)
Loss: 0.009 | Acc: 99.860% (12846/12864)
Loss: 0.008 | Acc: 99.870% (19239/19264)
Loss: 0.009 | Acc: 99.856% (25627/25664)
Loss: 0.009 | Acc: 99.853% (32017/32064)
Loss: 0.009 | Acc: 99.849% (38406/38464)
Loss: 0.009 | Acc: 99.846% (44795/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1887, Accuracy: 9490/10000 (94.90%)

Epoch: 197
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.722% (6446/6464)
Loss: 0.009 | Acc: 99.798% (12838/12864)
Loss: 0.009 | Acc: 99.824% (19230/19264)
Loss: 0.009 | Acc: 99.821% (25618/25664)
Loss: 0.009 | Acc: 99.813% (32004/32064)
Loss: 0.009 | Acc: 99.818% (38394/38464)
Loss: 0.009 | Acc: 99.828% (44787/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1876, Accuracy: 9490/10000 (94.90%)
torch.Size([100, 10])
Test set: Average loss: 0.1876, Accuracy: 9490/10000 (94.90%)

Epoch: 198
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.799% (6451/6464)
Loss: 0.010 | Acc: 99.813% (12840/12864)
Loss: 0.010 | Acc: 99.808% (19227/19264)
Loss: 0.009 | Acc: 99.813% (25616/25664)
Loss: 0.010 | Acc: 99.797% (31999/32064)
Loss: 0.010 | Acc: 99.797% (38386/38464)
Loss: 0.010 | Acc: 99.808% (44778/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1864, Accuracy: 9491/10000 (94.91%)
torch.Size([100, 10])
Test set: Average loss: 0.1864, Accuracy: 9491/10000 (94.91%)

Epoch: 199
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.799% (6451/6464)
Loss: 0.009 | Acc: 99.798% (12838/12864)
Loss: 0.009 | Acc: 99.818% (19229/19264)
Loss: 0.010 | Acc: 99.821% (25618/25664)
Loss: 0.010 | Acc: 99.810% (32003/32064)
Loss: 0.010 | Acc: 99.815% (38393/38464)
Loss: 0.010 | Acc: 99.822% (44784/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1870, Accuracy: 9483/10000 (94.83%)
torch.Size([100, 10])
Test set: Average loss: 0.1870, Accuracy: 9483/10000 (94.83%)
9545
10000
-0.14134638011455536
