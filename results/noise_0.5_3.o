==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.418 | Acc: 12.500% (8/64)
Loss: 2.896 | Acc: 13.057% (844/6464)
Loss: 2.583 | Acc: 14.078% (1811/12864)
Loss: 2.476 | Acc: 14.114% (2719/19264)
Loss: 2.416 | Acc: 14.635% (3756/25664)
Loss: 2.381 | Acc: 15.064% (4830/32064)
Loss: 2.356 | Acc: 15.511% (5966/38464)
Loss: 2.336 | Acc: 15.921% (7143/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2648, Accuracy: 1638/10000 (16.38%)

Epoch: 1
Loss: 2.293 | Acc: 6.250% (4/64)
Loss: 2.208 | Acc: 20.096% (1299/6464)
Loss: 2.200 | Acc: 20.398% (2624/12864)
Loss: 2.196 | Acc: 20.473% (3944/19264)
Loss: 2.196 | Acc: 20.542% (5272/25664)
Loss: 2.195 | Acc: 20.705% (6639/32064)
Loss: 2.191 | Acc: 21.030% (8089/38464)
Loss: 2.190 | Acc: 21.188% (9506/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3813, Accuracy: 1774/10000 (17.74%)

Epoch: 2
Loss: 2.199 | Acc: 18.750% (12/64)
Loss: 2.159 | Acc: 23.499% (1519/6464)
Loss: 2.161 | Acc: 23.298% (2997/12864)
Loss: 2.158 | Acc: 23.469% (4521/19264)
Loss: 2.156 | Acc: 23.749% (6095/25664)
Loss: 2.156 | Acc: 23.933% (7674/32064)
Loss: 2.154 | Acc: 24.126% (9280/38464)
Loss: 2.152 | Acc: 24.327% (10914/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1318, Accuracy: 2573/10000 (25.73%)

Epoch: 3
Loss: 2.380 | Acc: 10.938% (7/64)
Loss: 2.135 | Acc: 25.557% (1652/6464)
Loss: 2.140 | Acc: 25.482% (3278/12864)
Loss: 2.134 | Acc: 25.789% (4968/19264)
Loss: 2.134 | Acc: 25.912% (6650/25664)
Loss: 2.133 | Acc: 26.060% (8356/32064)
Loss: 2.130 | Acc: 26.157% (10061/38464)
Loss: 2.128 | Acc: 26.337% (11816/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2352, Accuracy: 2247/10000 (22.47%)

Epoch: 4
Loss: 2.062 | Acc: 35.938% (23/64)
Loss: 2.105 | Acc: 28.233% (1825/6464)
Loss: 2.097 | Acc: 28.599% (3679/12864)
Loss: 2.103 | Acc: 28.353% (5462/19264)
Loss: 2.102 | Acc: 28.304% (7264/25664)
Loss: 2.103 | Acc: 28.219% (9048/32064)
Loss: 2.101 | Acc: 28.434% (10937/38464)
Loss: 2.099 | Acc: 28.609% (12835/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1717, Accuracy: 2452/10000 (24.52%)

Epoch: 5
Loss: 2.033 | Acc: 26.562% (17/64)
Loss: 2.073 | Acc: 29.780% (1925/6464)
Loss: 2.083 | Acc: 29.688% (3819/12864)
Loss: 2.081 | Acc: 29.724% (5726/19264)
Loss: 2.077 | Acc: 30.007% (7701/25664)
Loss: 2.075 | Acc: 30.199% (9683/32064)
Loss: 2.075 | Acc: 30.194% (11614/38464)
Loss: 2.073 | Acc: 30.454% (13663/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1740, Accuracy: 2693/10000 (26.93%)

Epoch: 6
Loss: 1.907 | Acc: 42.188% (27/64)
Loss: 2.038 | Acc: 32.689% (2113/6464)
Loss: 2.046 | Acc: 32.299% (4155/12864)
Loss: 2.049 | Acc: 32.511% (6263/19264)
Loss: 2.047 | Acc: 32.489% (8338/25664)
Loss: 2.043 | Acc: 32.650% (10469/32064)
Loss: 2.044 | Acc: 32.698% (12577/38464)
Loss: 2.044 | Acc: 32.790% (14711/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1260, Accuracy: 2778/10000 (27.78%)

Epoch: 7
Loss: 2.058 | Acc: 32.812% (21/64)
Loss: 2.022 | Acc: 34.344% (2220/6464)
Loss: 2.019 | Acc: 34.235% (4404/12864)
Loss: 2.021 | Acc: 34.089% (6567/19264)
Loss: 2.020 | Acc: 34.122% (8757/25664)
Loss: 2.019 | Acc: 34.241% (10979/32064)
Loss: 2.019 | Acc: 34.214% (13160/38464)
Loss: 2.017 | Acc: 34.313% (15394/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0611, Accuracy: 3179/10000 (31.79%)

Epoch: 8
Loss: 2.165 | Acc: 28.125% (18/64)
Loss: 1.999 | Acc: 34.793% (2249/6464)
Loss: 1.995 | Acc: 35.113% (4517/12864)
Loss: 1.993 | Acc: 35.304% (6801/19264)
Loss: 1.999 | Acc: 35.263% (9050/25664)
Loss: 1.995 | Acc: 35.563% (11403/32064)
Loss: 1.997 | Acc: 35.428% (13627/38464)
Loss: 1.996 | Acc: 35.599% (15971/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1509, Accuracy: 3013/10000 (30.13%)

Epoch: 9
Loss: 2.060 | Acc: 32.812% (21/64)
Loss: 1.968 | Acc: 37.361% (2415/6464)
Loss: 1.977 | Acc: 36.933% (4751/12864)
Loss: 1.980 | Acc: 36.773% (7084/19264)
Loss: 1.981 | Acc: 36.760% (9434/25664)
Loss: 1.981 | Acc: 36.801% (11800/32064)
Loss: 1.982 | Acc: 36.840% (14170/38464)
Loss: 1.982 | Acc: 36.891% (16551/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1211, Accuracy: 2864/10000 (28.64%)

Epoch: 10
Loss: 1.904 | Acc: 42.188% (27/64)
Loss: 1.975 | Acc: 37.268% (2409/6464)
Loss: 1.974 | Acc: 37.383% (4809/12864)
Loss: 1.971 | Acc: 37.329% (7191/19264)
Loss: 1.972 | Acc: 37.255% (9561/25664)
Loss: 1.969 | Acc: 37.450% (12008/32064)
Loss: 1.969 | Acc: 37.440% (14401/38464)
Loss: 1.968 | Acc: 37.518% (16832/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0278, Accuracy: 3529/10000 (35.29%)

Epoch: 11
Loss: 1.915 | Acc: 45.312% (29/64)
Loss: 1.946 | Acc: 38.521% (2490/6464)
Loss: 1.953 | Acc: 38.503% (4953/12864)
Loss: 1.955 | Acc: 38.466% (7410/19264)
Loss: 1.956 | Acc: 38.385% (9851/25664)
Loss: 1.957 | Acc: 38.280% (12274/32064)
Loss: 1.956 | Acc: 38.340% (14747/38464)
Loss: 1.953 | Acc: 38.490% (17268/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0934, Accuracy: 2980/10000 (29.80%)

Epoch: 12
Loss: 1.949 | Acc: 37.500% (24/64)
Loss: 1.953 | Acc: 38.753% (2505/6464)
Loss: 1.945 | Acc: 39.513% (5083/12864)
Loss: 1.939 | Acc: 39.696% (7647/19264)
Loss: 1.940 | Acc: 39.705% (10190/25664)
Loss: 1.939 | Acc: 39.671% (12720/32064)
Loss: 1.937 | Acc: 39.710% (15274/38464)
Loss: 1.938 | Acc: 39.638% (17783/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0138, Accuracy: 3517/10000 (35.17%)

Epoch: 13
Loss: 2.152 | Acc: 29.688% (19/64)
Loss: 1.924 | Acc: 40.207% (2599/6464)
Loss: 1.926 | Acc: 40.252% (5178/12864)
Loss: 1.926 | Acc: 40.272% (7758/19264)
Loss: 1.926 | Acc: 40.325% (10349/25664)
Loss: 1.927 | Acc: 40.266% (12911/32064)
Loss: 1.928 | Acc: 40.264% (15487/38464)
Loss: 1.928 | Acc: 40.317% (18088/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0664, Accuracy: 3455/10000 (34.55%)

Epoch: 14
Loss: 1.996 | Acc: 35.938% (23/64)
Loss: 1.920 | Acc: 40.625% (2626/6464)
Loss: 1.917 | Acc: 40.617% (5225/12864)
Loss: 1.916 | Acc: 40.734% (7847/19264)
Loss: 1.916 | Acc: 40.847% (10483/25664)
Loss: 1.916 | Acc: 40.946% (13129/32064)
Loss: 1.916 | Acc: 41.012% (15775/38464)
Loss: 1.913 | Acc: 41.158% (18465/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0673, Accuracy: 3251/10000 (32.51%)

Epoch: 15
Loss: 1.973 | Acc: 40.625% (26/64)
Loss: 1.914 | Acc: 41.306% (2670/6464)
Loss: 1.911 | Acc: 41.628% (5355/12864)
Loss: 1.911 | Acc: 41.575% (8009/19264)
Loss: 1.910 | Acc: 41.564% (10667/25664)
Loss: 1.907 | Acc: 41.726% (13379/32064)
Loss: 1.906 | Acc: 41.748% (16058/38464)
Loss: 1.908 | Acc: 41.697% (18707/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1626, Accuracy: 2839/10000 (28.39%)

Epoch: 16
Loss: 2.165 | Acc: 28.125% (18/64)
Loss: 1.892 | Acc: 42.683% (2759/6464)
Loss: 1.898 | Acc: 42.094% (5415/12864)
Loss: 1.902 | Acc: 41.928% (8077/19264)
Loss: 1.905 | Acc: 41.810% (10730/25664)
Loss: 1.903 | Acc: 41.966% (13456/32064)
Loss: 1.902 | Acc: 42.045% (16172/38464)
Loss: 1.897 | Acc: 42.190% (18928/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1024, Accuracy: 3338/10000 (33.38%)

Epoch: 17
Loss: 1.902 | Acc: 39.062% (25/64)
Loss: 1.887 | Acc: 43.147% (2789/6464)
Loss: 1.897 | Acc: 42.164% (5424/12864)
Loss: 1.899 | Acc: 42.281% (8145/19264)
Loss: 1.894 | Acc: 42.402% (10882/25664)
Loss: 1.897 | Acc: 42.375% (13587/32064)
Loss: 1.894 | Acc: 42.393% (16306/38464)
Loss: 1.892 | Acc: 42.493% (19064/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0615, Accuracy: 3567/10000 (35.67%)

Epoch: 18
Loss: 1.994 | Acc: 34.375% (22/64)
Loss: 1.868 | Acc: 43.472% (2810/6464)
Loss: 1.884 | Acc: 42.809% (5507/12864)
Loss: 1.884 | Acc: 42.784% (8242/19264)
Loss: 1.883 | Acc: 42.850% (10997/25664)
Loss: 1.882 | Acc: 42.989% (13784/32064)
Loss: 1.881 | Acc: 42.892% (16498/38464)
Loss: 1.881 | Acc: 42.972% (19279/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9880, Accuracy: 3852/10000 (38.52%)

Epoch: 19
Loss: 2.173 | Acc: 29.688% (19/64)
Loss: 1.866 | Acc: 43.796% (2831/6464)
Loss: 1.866 | Acc: 43.766% (5630/12864)
Loss: 1.861 | Acc: 44.139% (8503/19264)
Loss: 1.864 | Acc: 44.120% (11323/25664)
Loss: 1.869 | Acc: 43.884% (14071/32064)
Loss: 1.872 | Acc: 43.758% (16831/38464)
Loss: 1.873 | Acc: 43.672% (19593/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9818, Accuracy: 3785/10000 (37.85%)

Epoch: 20
Loss: 1.830 | Acc: 45.312% (29/64)
Loss: 1.865 | Acc: 44.400% (2870/6464)
Loss: 1.858 | Acc: 44.644% (5743/12864)
Loss: 1.861 | Acc: 44.259% (8526/19264)
Loss: 1.864 | Acc: 44.003% (11293/25664)
Loss: 1.864 | Acc: 44.068% (14130/32064)
Loss: 1.866 | Acc: 44.000% (16924/38464)
Loss: 1.867 | Acc: 43.908% (19699/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9903, Accuracy: 3723/10000 (37.23%)

Epoch: 21
Loss: 1.931 | Acc: 40.625% (26/64)
Loss: 1.857 | Acc: 43.982% (2843/6464)
Loss: 1.859 | Acc: 43.983% (5658/12864)
Loss: 1.856 | Acc: 44.274% (8529/19264)
Loss: 1.860 | Acc: 44.190% (11341/25664)
Loss: 1.859 | Acc: 44.277% (14197/32064)
Loss: 1.862 | Acc: 44.065% (16949/38464)
Loss: 1.858 | Acc: 44.205% (19832/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9443, Accuracy: 4043/10000 (40.43%)

Epoch: 22
Loss: 1.695 | Acc: 50.000% (32/64)
Loss: 1.837 | Acc: 45.034% (2911/6464)
Loss: 1.852 | Acc: 44.605% (5738/12864)
Loss: 1.852 | Acc: 44.570% (8586/19264)
Loss: 1.855 | Acc: 44.257% (11358/25664)
Loss: 1.854 | Acc: 44.324% (14212/32064)
Loss: 1.854 | Acc: 44.470% (17105/38464)
Loss: 1.852 | Acc: 44.512% (19970/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9469, Accuracy: 4011/10000 (40.11%)

Epoch: 23
Loss: 1.809 | Acc: 50.000% (32/64)
Loss: 1.835 | Acc: 45.622% (2949/6464)
Loss: 1.846 | Acc: 45.009% (5790/12864)
Loss: 1.848 | Acc: 45.115% (8691/19264)
Loss: 1.851 | Acc: 44.829% (11505/25664)
Loss: 1.850 | Acc: 44.820% (14371/32064)
Loss: 1.852 | Acc: 44.702% (17194/38464)
Loss: 1.848 | Acc: 44.907% (20147/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0263, Accuracy: 3569/10000 (35.69%)

Epoch: 24
Loss: 1.712 | Acc: 54.688% (35/64)
Loss: 1.853 | Acc: 44.415% (2871/6464)
Loss: 1.843 | Acc: 44.869% (5772/12864)
Loss: 1.842 | Acc: 45.032% (8675/19264)
Loss: 1.847 | Acc: 44.950% (11536/25664)
Loss: 1.840 | Acc: 45.144% (14475/32064)
Loss: 1.840 | Acc: 45.092% (17344/38464)
Loss: 1.842 | Acc: 45.027% (20201/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0056, Accuracy: 3650/10000 (36.50%)

Epoch: 25
Loss: 1.911 | Acc: 45.312% (29/64)
Loss: 1.817 | Acc: 46.132% (2982/6464)
Loss: 1.828 | Acc: 45.484% (5851/12864)
Loss: 1.830 | Acc: 45.577% (8780/19264)
Loss: 1.829 | Acc: 45.702% (11729/25664)
Loss: 1.831 | Acc: 45.652% (14638/32064)
Loss: 1.833 | Acc: 45.541% (17517/38464)
Loss: 1.833 | Acc: 45.560% (20440/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9547, Accuracy: 3829/10000 (38.29%)

Epoch: 26
Loss: 2.008 | Acc: 39.062% (25/64)
Loss: 1.846 | Acc: 44.632% (2885/6464)
Loss: 1.843 | Acc: 44.893% (5775/12864)
Loss: 1.834 | Acc: 45.416% (8749/19264)
Loss: 1.832 | Acc: 45.648% (11715/25664)
Loss: 1.832 | Acc: 45.637% (14633/32064)
Loss: 1.829 | Acc: 45.749% (17597/38464)
Loss: 1.827 | Acc: 45.856% (20573/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8949, Accuracy: 4284/10000 (42.84%)

Epoch: 27
Loss: 1.922 | Acc: 39.062% (25/64)
Loss: 1.844 | Acc: 45.266% (2926/6464)
Loss: 1.822 | Acc: 46.129% (5934/12864)
Loss: 1.815 | Acc: 46.262% (8912/19264)
Loss: 1.821 | Acc: 45.885% (11776/25664)
Loss: 1.820 | Acc: 46.064% (14770/32064)
Loss: 1.815 | Acc: 46.287% (17804/38464)
Loss: 1.815 | Acc: 46.367% (20802/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9227, Accuracy: 4091/10000 (40.91%)

Epoch: 28
Loss: 1.870 | Acc: 40.625% (26/64)
Loss: 1.809 | Acc: 46.535% (3008/6464)
Loss: 1.814 | Acc: 46.447% (5975/12864)
Loss: 1.810 | Acc: 46.553% (8968/19264)
Loss: 1.812 | Acc: 46.493% (11932/25664)
Loss: 1.811 | Acc: 46.585% (14937/32064)
Loss: 1.811 | Acc: 46.586% (17919/38464)
Loss: 1.809 | Acc: 46.677% (20941/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9393, Accuracy: 4071/10000 (40.71%)

Epoch: 29
Loss: 1.921 | Acc: 37.500% (24/64)
Loss: 1.794 | Acc: 47.184% (3050/6464)
Loss: 1.790 | Acc: 47.450% (6104/12864)
Loss: 1.790 | Acc: 47.493% (9149/19264)
Loss: 1.795 | Acc: 47.105% (12089/25664)
Loss: 1.794 | Acc: 47.137% (15114/32064)
Loss: 1.799 | Acc: 47.031% (18090/38464)
Loss: 1.798 | Acc: 47.078% (21121/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8943, Accuracy: 4261/10000 (42.61%)

Epoch: 30
Loss: 2.063 | Acc: 34.375% (22/64)
Loss: 1.762 | Acc: 49.025% (3169/6464)
Loss: 1.771 | Acc: 48.523% (6242/12864)
Loss: 1.778 | Acc: 48.178% (9281/19264)
Loss: 1.781 | Acc: 48.095% (12343/25664)
Loss: 1.784 | Acc: 47.960% (15378/32064)
Loss: 1.788 | Acc: 47.840% (18401/38464)
Loss: 1.789 | Acc: 47.769% (21431/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8886, Accuracy: 4316/10000 (43.16%)

Epoch: 31
Loss: 1.690 | Acc: 51.562% (33/64)
Loss: 1.767 | Acc: 48.654% (3145/6464)
Loss: 1.776 | Acc: 48.266% (6209/12864)
Loss: 1.780 | Acc: 48.277% (9300/19264)
Loss: 1.780 | Acc: 48.231% (12378/25664)
Loss: 1.779 | Acc: 48.182% (15449/32064)
Loss: 1.779 | Acc: 48.219% (18547/38464)
Loss: 1.782 | Acc: 48.054% (21559/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8964, Accuracy: 4340/10000 (43.40%)

Epoch: 32
Loss: 1.623 | Acc: 50.000% (32/64)
Loss: 1.765 | Acc: 48.747% (3151/6464)
Loss: 1.768 | Acc: 48.515% (6241/12864)
Loss: 1.774 | Acc: 48.313% (9307/19264)
Loss: 1.772 | Acc: 48.387% (12418/25664)
Loss: 1.770 | Acc: 48.459% (15538/32064)
Loss: 1.771 | Acc: 48.432% (18629/38464)
Loss: 1.772 | Acc: 48.473% (21747/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8705, Accuracy: 4496/10000 (44.96%)

Epoch: 33
Loss: 1.795 | Acc: 43.750% (28/64)
Loss: 1.733 | Acc: 49.737% (3215/6464)
Loss: 1.742 | Acc: 49.417% (6357/12864)
Loss: 1.741 | Acc: 49.403% (9517/19264)
Loss: 1.750 | Acc: 49.053% (12589/25664)
Loss: 1.751 | Acc: 49.071% (15734/32064)
Loss: 1.755 | Acc: 48.989% (18843/38464)
Loss: 1.758 | Acc: 48.872% (21926/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8858, Accuracy: 4357/10000 (43.57%)

Epoch: 34
Loss: 1.737 | Acc: 53.125% (34/64)
Loss: 1.735 | Acc: 49.969% (3230/6464)
Loss: 1.737 | Acc: 49.899% (6419/12864)
Loss: 1.738 | Acc: 49.896% (9612/19264)
Loss: 1.745 | Acc: 49.482% (12699/25664)
Loss: 1.749 | Acc: 49.317% (15813/32064)
Loss: 1.749 | Acc: 49.319% (18970/38464)
Loss: 1.750 | Acc: 49.367% (22148/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8908, Accuracy: 4383/10000 (43.83%)

Epoch: 35
Loss: 1.478 | Acc: 60.938% (39/64)
Loss: 1.680 | Acc: 51.624% (3337/6464)
Loss: 1.704 | Acc: 50.560% (6504/12864)
Loss: 1.720 | Acc: 50.088% (9649/19264)
Loss: 1.721 | Acc: 50.152% (12871/25664)
Loss: 1.725 | Acc: 50.053% (16049/32064)
Loss: 1.727 | Acc: 49.964% (19218/38464)
Loss: 1.733 | Acc: 49.750% (22320/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8876, Accuracy: 4375/10000 (43.75%)

Epoch: 36
Loss: 1.812 | Acc: 45.312% (29/64)
Loss: 1.732 | Acc: 49.722% (3214/6464)
Loss: 1.721 | Acc: 50.311% (6472/12864)
Loss: 1.719 | Acc: 50.524% (9733/19264)
Loss: 1.720 | Acc: 50.444% (12946/25664)
Loss: 1.719 | Acc: 50.474% (16184/32064)
Loss: 1.720 | Acc: 50.411% (19390/38464)
Loss: 1.720 | Acc: 50.406% (22614/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8902, Accuracy: 4369/10000 (43.69%)

Epoch: 37
Loss: 1.644 | Acc: 53.125% (34/64)
Loss: 1.699 | Acc: 50.959% (3294/6464)
Loss: 1.697 | Acc: 51.049% (6567/12864)
Loss: 1.699 | Acc: 50.831% (9792/19264)
Loss: 1.703 | Acc: 50.869% (13055/25664)
Loss: 1.709 | Acc: 50.586% (16220/32064)
Loss: 1.711 | Acc: 50.471% (19413/38464)
Loss: 1.710 | Acc: 50.533% (22671/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8885, Accuracy: 4455/10000 (44.55%)

Epoch: 38
Loss: 1.787 | Acc: 50.000% (32/64)
Loss: 1.678 | Acc: 51.547% (3332/6464)
Loss: 1.681 | Acc: 51.469% (6621/12864)
Loss: 1.687 | Acc: 51.365% (9895/19264)
Loss: 1.693 | Acc: 51.068% (13106/25664)
Loss: 1.691 | Acc: 51.135% (16396/32064)
Loss: 1.687 | Acc: 51.323% (19741/38464)
Loss: 1.689 | Acc: 51.248% (22992/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9062, Accuracy: 4341/10000 (43.41%)

Epoch: 39
Loss: 1.914 | Acc: 39.062% (25/64)
Loss: 1.658 | Acc: 52.444% (3390/6464)
Loss: 1.654 | Acc: 52.550% (6760/12864)
Loss: 1.668 | Acc: 52.045% (10026/19264)
Loss: 1.661 | Acc: 52.233% (13405/25664)
Loss: 1.661 | Acc: 52.333% (16780/32064)
Loss: 1.661 | Acc: 52.314% (20122/38464)
Loss: 1.668 | Acc: 52.022% (23339/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9045, Accuracy: 4446/10000 (44.46%)

Epoch: 40
Loss: 1.614 | Acc: 54.688% (35/64)
Loss: 1.640 | Acc: 52.769% (3411/6464)
Loss: 1.638 | Acc: 52.962% (6813/12864)
Loss: 1.641 | Acc: 52.876% (10186/19264)
Loss: 1.642 | Acc: 52.946% (13588/25664)
Loss: 1.641 | Acc: 52.969% (16984/32064)
Loss: 1.645 | Acc: 52.751% (20290/38464)
Loss: 1.646 | Acc: 52.686% (23637/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8683, Accuracy: 4622/10000 (46.22%)

Epoch: 41
Loss: 1.695 | Acc: 48.438% (31/64)
Loss: 1.605 | Acc: 53.899% (3484/6464)
Loss: 1.618 | Acc: 53.296% (6856/12864)
Loss: 1.614 | Acc: 53.411% (10289/19264)
Loss: 1.617 | Acc: 53.378% (13699/25664)
Loss: 1.619 | Acc: 53.315% (17095/32064)
Loss: 1.624 | Acc: 53.193% (20460/38464)
Loss: 1.622 | Acc: 53.254% (23892/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9072, Accuracy: 4553/10000 (45.53%)

Epoch: 42
Loss: 1.435 | Acc: 59.375% (38/64)
Loss: 1.601 | Acc: 54.084% (3496/6464)
Loss: 1.598 | Acc: 53.840% (6926/12864)
Loss: 1.592 | Acc: 54.013% (10405/19264)
Loss: 1.596 | Acc: 53.912% (13836/25664)
Loss: 1.593 | Acc: 54.048% (17330/32064)
Loss: 1.590 | Acc: 54.160% (20832/38464)
Loss: 1.587 | Acc: 54.248% (24338/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9213, Accuracy: 4517/10000 (45.17%)

Epoch: 43
Loss: 1.435 | Acc: 56.250% (36/64)
Loss: 1.516 | Acc: 56.018% (3621/6464)
Loss: 1.533 | Acc: 55.403% (7127/12864)
Loss: 1.539 | Acc: 55.435% (10679/19264)
Loss: 1.540 | Acc: 55.537% (14253/25664)
Loss: 1.541 | Acc: 55.430% (17773/32064)
Loss: 1.543 | Acc: 55.439% (21324/38464)
Loss: 1.545 | Acc: 55.419% (24863/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9429, Accuracy: 4507/10000 (45.07%)

Epoch: 44
Loss: 1.396 | Acc: 62.500% (40/64)
Loss: 1.478 | Acc: 57.627% (3725/6464)
Loss: 1.484 | Acc: 57.012% (7334/12864)
Loss: 1.488 | Acc: 56.868% (10955/19264)
Loss: 1.494 | Acc: 56.558% (14515/25664)
Loss: 1.503 | Acc: 56.309% (18055/32064)
Loss: 1.503 | Acc: 56.336% (21669/38464)
Loss: 1.505 | Acc: 56.346% (25279/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9718, Accuracy: 4460/10000 (44.60%)

Epoch: 45
Loss: 1.468 | Acc: 51.562% (33/64)
Loss: 1.485 | Acc: 56.513% (3653/6464)
Loss: 1.484 | Acc: 56.887% (7318/12864)
Loss: 1.505 | Acc: 56.292% (10844/19264)
Loss: 1.523 | Acc: 55.806% (14322/25664)
Loss: 1.528 | Acc: 55.692% (17857/32064)
Loss: 1.533 | Acc: 55.652% (21406/38464)
Loss: 1.540 | Acc: 55.521% (24909/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8903, Accuracy: 4531/10000 (45.31%)

Epoch: 46
Loss: 1.441 | Acc: 57.812% (37/64)
Loss: 1.592 | Acc: 54.162% (3501/6464)
Loss: 1.591 | Acc: 54.501% (7011/12864)
Loss: 1.599 | Acc: 54.184% (10438/19264)
Loss: 1.604 | Acc: 53.986% (13855/25664)
Loss: 1.607 | Acc: 54.004% (17316/32064)
Loss: 1.611 | Acc: 53.827% (20704/38464)
Loss: 1.614 | Acc: 53.774% (24125/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8755, Accuracy: 4572/10000 (45.72%)

Epoch: 47
Loss: 1.362 | Acc: 67.188% (43/64)
Loss: 1.624 | Acc: 53.419% (3453/6464)
Loss: 1.633 | Acc: 53.117% (6833/12864)
Loss: 1.629 | Acc: 53.317% (10271/19264)
Loss: 1.625 | Acc: 53.487% (13727/25664)
Loss: 1.634 | Acc: 53.203% (17059/32064)
Loss: 1.636 | Acc: 53.125% (20434/38464)
Loss: 1.638 | Acc: 53.076% (23812/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8677, Accuracy: 4612/10000 (46.12%)
torch.Size([100, 10])
Test set: Average loss: 1.8677, Accuracy: 4612/10000 (46.12%)

Epoch: 48
Loss: 1.581 | Acc: 54.688% (35/64)
Loss: 1.622 | Acc: 53.651% (3468/6464)
Loss: 1.630 | Acc: 53.358% (6864/12864)
Loss: 1.638 | Acc: 53.156% (10240/19264)
Loss: 1.645 | Acc: 52.915% (13580/25664)
Loss: 1.638 | Acc: 53.253% (17075/32064)
Loss: 1.638 | Acc: 53.211% (20467/38464)
Loss: 1.640 | Acc: 53.123% (23833/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8683, Accuracy: 4618/10000 (46.18%)
torch.Size([100, 10])
Test set: Average loss: 1.8683, Accuracy: 4618/10000 (46.18%)

Epoch: 49
Loss: 1.698 | Acc: 48.438% (31/64)
Loss: 1.657 | Acc: 52.290% (3380/6464)
Loss: 1.655 | Acc: 52.464% (6749/12864)
Loss: 1.653 | Acc: 52.414% (10097/19264)
Loss: 1.646 | Acc: 52.728% (13532/25664)
Loss: 1.643 | Acc: 52.872% (16953/32064)
Loss: 1.641 | Acc: 53.016% (20392/38464)
Loss: 1.639 | Acc: 53.105% (23825/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8689, Accuracy: 4647/10000 (46.47%)
torch.Size([100, 10])
Test set: Average loss: 1.8689, Accuracy: 4647/10000 (46.47%)

Epoch: 50
Loss: 1.582 | Acc: 54.688% (35/64)
Loss: 2.153 | Acc: 25.402% (1642/6464)
Loss: 2.065 | Acc: 31.421% (4042/12864)
Loss: 2.022 | Acc: 34.375% (6622/19264)
Loss: 2.003 | Acc: 35.524% (9117/25664)
Loss: 1.988 | Acc: 36.571% (11726/32064)
Loss: 1.974 | Acc: 37.448% (14404/38464)
Loss: 1.964 | Acc: 38.106% (17096/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0912, Accuracy: 3322/10000 (33.22%)

Epoch: 51
Loss: 1.941 | Acc: 35.938% (23/64)
Loss: 1.893 | Acc: 42.095% (2721/6464)
Loss: 1.899 | Acc: 42.133% (5420/12864)
Loss: 1.895 | Acc: 42.307% (8150/19264)
Loss: 1.893 | Acc: 42.437% (10891/25664)
Loss: 1.890 | Acc: 42.630% (13669/32064)
Loss: 1.887 | Acc: 42.772% (16452/38464)
Loss: 1.885 | Acc: 42.885% (19240/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9943, Accuracy: 3928/10000 (39.28%)

Epoch: 52
Loss: 1.685 | Acc: 48.438% (31/64)
Loss: 1.862 | Acc: 44.044% (2847/6464)
Loss: 1.867 | Acc: 43.991% (5659/12864)
Loss: 1.865 | Acc: 43.989% (8474/19264)
Loss: 1.872 | Acc: 43.602% (11190/25664)
Loss: 1.871 | Acc: 43.688% (14008/32064)
Loss: 1.869 | Acc: 43.789% (16843/38464)
Loss: 1.871 | Acc: 43.723% (19616/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0675, Accuracy: 3362/10000 (33.62%)

Epoch: 53
Loss: 1.767 | Acc: 43.750% (28/64)
Loss: 1.851 | Acc: 44.508% (2877/6464)
Loss: 1.856 | Acc: 44.263% (5694/12864)
Loss: 1.864 | Acc: 43.973% (8471/19264)
Loss: 1.867 | Acc: 43.949% (11279/25664)
Loss: 1.870 | Acc: 43.753% (14029/32064)
Loss: 1.871 | Acc: 43.753% (16829/38464)
Loss: 1.872 | Acc: 43.750% (19628/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0824, Accuracy: 3419/10000 (34.19%)

Epoch: 54
Loss: 1.770 | Acc: 48.438% (31/64)
Loss: 1.868 | Acc: 44.307% (2864/6464)
Loss: 1.868 | Acc: 44.030% (5664/12864)
Loss: 1.867 | Acc: 44.150% (8505/19264)
Loss: 1.861 | Acc: 44.397% (11394/25664)
Loss: 1.865 | Acc: 44.196% (14171/32064)
Loss: 1.865 | Acc: 44.213% (17006/38464)
Loss: 1.865 | Acc: 44.202% (19831/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0543, Accuracy: 3389/10000 (33.89%)

Epoch: 55
Loss: 1.798 | Acc: 43.750% (28/64)
Loss: 1.861 | Acc: 44.199% (2857/6464)
Loss: 1.861 | Acc: 44.286% (5697/12864)
Loss: 1.859 | Acc: 44.404% (8554/19264)
Loss: 1.861 | Acc: 44.237% (11353/25664)
Loss: 1.861 | Acc: 44.308% (14207/32064)
Loss: 1.860 | Acc: 44.358% (17062/38464)
Loss: 1.862 | Acc: 44.276% (19864/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9983, Accuracy: 3930/10000 (39.30%)

Epoch: 56
Loss: 2.171 | Acc: 29.688% (19/64)
Loss: 1.864 | Acc: 44.245% (2860/6464)
Loss: 1.858 | Acc: 44.341% (5704/12864)
Loss: 1.858 | Acc: 44.425% (8558/19264)
Loss: 1.866 | Acc: 44.058% (11307/25664)
Loss: 1.863 | Acc: 44.237% (14184/32064)
Loss: 1.861 | Acc: 44.301% (17040/38464)
Loss: 1.862 | Acc: 44.318% (19883/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9910, Accuracy: 3842/10000 (38.42%)

Epoch: 57
Loss: 2.068 | Acc: 34.375% (22/64)
Loss: 1.837 | Acc: 45.436% (2937/6464)
Loss: 1.847 | Acc: 45.173% (5811/12864)
Loss: 1.857 | Acc: 44.627% (8597/19264)
Loss: 1.856 | Acc: 44.670% (11464/25664)
Loss: 1.855 | Acc: 44.673% (14324/32064)
Loss: 1.858 | Acc: 44.553% (17137/38464)
Loss: 1.856 | Acc: 44.633% (20024/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9778, Accuracy: 3754/10000 (37.54%)

Epoch: 58
Loss: 1.747 | Acc: 43.750% (28/64)
Loss: 1.848 | Acc: 44.694% (2889/6464)
Loss: 1.854 | Acc: 44.473% (5721/12864)
Loss: 1.855 | Acc: 44.394% (8552/19264)
Loss: 1.853 | Acc: 44.549% (11433/25664)
Loss: 1.855 | Acc: 44.583% (14295/32064)
Loss: 1.856 | Acc: 44.564% (17141/38464)
Loss: 1.856 | Acc: 44.617% (20017/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9993, Accuracy: 3746/10000 (37.46%)

Epoch: 59
Loss: 1.786 | Acc: 51.562% (33/64)
Loss: 1.855 | Acc: 44.910% (2903/6464)
Loss: 1.843 | Acc: 45.320% (5830/12864)
Loss: 1.848 | Acc: 45.094% (8687/19264)
Loss: 1.846 | Acc: 45.071% (11567/25664)
Loss: 1.849 | Acc: 44.916% (14402/32064)
Loss: 1.850 | Acc: 44.793% (17229/38464)
Loss: 1.853 | Acc: 44.679% (20045/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0563, Accuracy: 3327/10000 (33.27%)

Epoch: 60
Loss: 2.090 | Acc: 32.812% (21/64)
Loss: 1.858 | Acc: 44.245% (2860/6464)
Loss: 1.861 | Acc: 44.053% (5667/12864)
Loss: 1.860 | Acc: 44.150% (8505/19264)
Loss: 1.856 | Acc: 44.549% (11433/25664)
Loss: 1.854 | Acc: 44.645% (14315/32064)
Loss: 1.855 | Acc: 44.631% (17167/38464)
Loss: 1.856 | Acc: 44.628% (20022/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9626, Accuracy: 3985/10000 (39.85%)

Epoch: 61
Loss: 1.798 | Acc: 43.750% (28/64)
Loss: 1.831 | Acc: 45.885% (2966/6464)
Loss: 1.833 | Acc: 45.965% (5913/12864)
Loss: 1.842 | Acc: 45.385% (8743/19264)
Loss: 1.849 | Acc: 45.059% (11564/25664)
Loss: 1.848 | Acc: 45.054% (14446/32064)
Loss: 1.848 | Acc: 45.107% (17350/38464)
Loss: 1.848 | Acc: 45.099% (20233/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0229, Accuracy: 3669/10000 (36.69%)

Epoch: 62
Loss: 1.715 | Acc: 50.000% (32/64)
Loss: 1.840 | Acc: 45.606% (2948/6464)
Loss: 1.842 | Acc: 45.227% (5818/12864)
Loss: 1.841 | Acc: 45.411% (8748/19264)
Loss: 1.841 | Acc: 45.418% (11656/25664)
Loss: 1.847 | Acc: 45.175% (14485/32064)
Loss: 1.847 | Acc: 45.138% (17362/38464)
Loss: 1.847 | Acc: 45.154% (20258/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0880, Accuracy: 3227/10000 (32.27%)

Epoch: 63
Loss: 1.690 | Acc: 54.688% (35/64)
Loss: 1.830 | Acc: 45.838% (2963/6464)
Loss: 1.831 | Acc: 45.802% (5892/12864)
Loss: 1.825 | Acc: 46.102% (8881/19264)
Loss: 1.833 | Acc: 45.675% (11722/25664)
Loss: 1.839 | Acc: 45.353% (14542/32064)
Loss: 1.844 | Acc: 45.123% (17356/38464)
Loss: 1.845 | Acc: 45.132% (20248/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0388, Accuracy: 3382/10000 (33.82%)

Epoch: 64
Loss: 1.987 | Acc: 42.188% (27/64)
Loss: 1.835 | Acc: 45.498% (2941/6464)
Loss: 1.838 | Acc: 45.382% (5838/12864)
Loss: 1.832 | Acc: 45.598% (8784/19264)
Loss: 1.838 | Acc: 45.449% (11664/25664)
Loss: 1.837 | Acc: 45.574% (14613/32064)
Loss: 1.837 | Acc: 45.552% (17521/38464)
Loss: 1.841 | Acc: 45.337% (20340/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9978, Accuracy: 3692/10000 (36.92%)

Epoch: 65
Loss: 1.659 | Acc: 56.250% (36/64)
Loss: 1.827 | Acc: 46.364% (2997/6464)
Loss: 1.823 | Acc: 46.308% (5957/12864)
Loss: 1.836 | Acc: 45.603% (8785/19264)
Loss: 1.840 | Acc: 45.457% (11666/25664)
Loss: 1.842 | Acc: 45.390% (14554/32064)
Loss: 1.843 | Acc: 45.331% (17436/38464)
Loss: 1.839 | Acc: 45.542% (20432/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9854, Accuracy: 3791/10000 (37.91%)

Epoch: 66
Loss: 1.910 | Acc: 43.750% (28/64)
Loss: 1.833 | Acc: 45.622% (2949/6464)
Loss: 1.838 | Acc: 45.398% (5840/12864)
Loss: 1.841 | Acc: 45.287% (8724/19264)
Loss: 1.838 | Acc: 45.340% (11636/25664)
Loss: 1.837 | Acc: 45.412% (14561/32064)
Loss: 1.834 | Acc: 45.541% (17517/38464)
Loss: 1.831 | Acc: 45.714% (20509/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0452, Accuracy: 3444/10000 (34.44%)

Epoch: 67
Loss: 1.642 | Acc: 57.812% (37/64)
Loss: 1.837 | Acc: 45.838% (2963/6464)
Loss: 1.838 | Acc: 45.569% (5862/12864)
Loss: 1.835 | Acc: 45.821% (8827/19264)
Loss: 1.834 | Acc: 45.846% (11766/25664)
Loss: 1.830 | Acc: 46.002% (14750/32064)
Loss: 1.830 | Acc: 45.952% (17675/38464)
Loss: 1.829 | Acc: 46.015% (20644/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1268, Accuracy: 3366/10000 (33.66%)

Epoch: 68
Loss: 1.885 | Acc: 43.750% (28/64)
Loss: 1.832 | Acc: 46.009% (2974/6464)
Loss: 1.818 | Acc: 46.339% (5961/12864)
Loss: 1.826 | Acc: 46.008% (8863/19264)
Loss: 1.816 | Acc: 46.365% (11899/25664)
Loss: 1.817 | Acc: 46.382% (14872/32064)
Loss: 1.822 | Acc: 46.191% (17767/38464)
Loss: 1.822 | Acc: 46.229% (20740/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9319, Accuracy: 4056/10000 (40.56%)

Epoch: 69
Loss: 1.869 | Acc: 43.750% (28/64)
Loss: 1.788 | Acc: 47.834% (3092/6464)
Loss: 1.795 | Acc: 47.528% (6114/12864)
Loss: 1.811 | Acc: 46.839% (9023/19264)
Loss: 1.817 | Acc: 46.575% (11953/25664)
Loss: 1.818 | Acc: 46.588% (14938/32064)
Loss: 1.819 | Acc: 46.508% (17889/38464)
Loss: 1.819 | Acc: 46.503% (20863/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9976, Accuracy: 3747/10000 (37.47%)

Epoch: 70
Loss: 1.909 | Acc: 43.750% (28/64)
Loss: 1.793 | Acc: 47.664% (3081/6464)
Loss: 1.800 | Acc: 47.163% (6067/12864)
Loss: 1.810 | Acc: 46.761% (9008/19264)
Loss: 1.810 | Acc: 46.817% (12015/25664)
Loss: 1.816 | Acc: 46.582% (14936/32064)
Loss: 1.816 | Acc: 46.633% (17937/38464)
Loss: 1.815 | Acc: 46.694% (20949/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9262, Accuracy: 4193/10000 (41.93%)

Epoch: 71
Loss: 1.840 | Acc: 40.625% (26/64)
Loss: 1.785 | Acc: 47.633% (3079/6464)
Loss: 1.795 | Acc: 47.481% (6108/12864)
Loss: 1.801 | Acc: 47.404% (9132/19264)
Loss: 1.805 | Acc: 47.195% (12112/25664)
Loss: 1.807 | Acc: 47.037% (15082/32064)
Loss: 1.808 | Acc: 47.000% (18078/38464)
Loss: 1.809 | Acc: 46.859% (21023/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9110, Accuracy: 4175/10000 (41.75%)

Epoch: 72
Loss: 1.875 | Acc: 45.312% (29/64)
Loss: 1.790 | Acc: 48.097% (3109/6464)
Loss: 1.802 | Acc: 47.442% (6103/12864)
Loss: 1.810 | Acc: 46.885% (9032/19264)
Loss: 1.808 | Acc: 46.992% (12060/25664)
Loss: 1.808 | Acc: 47.009% (15073/32064)
Loss: 1.803 | Acc: 47.226% (18165/38464)
Loss: 1.805 | Acc: 47.203% (21177/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0236, Accuracy: 3682/10000 (36.82%)

Epoch: 73
Loss: 1.642 | Acc: 54.688% (35/64)
Loss: 1.807 | Acc: 46.983% (3037/6464)
Loss: 1.797 | Acc: 47.505% (6111/12864)
Loss: 1.802 | Acc: 47.321% (9116/19264)
Loss: 1.804 | Acc: 47.284% (12135/25664)
Loss: 1.802 | Acc: 47.402% (15199/32064)
Loss: 1.800 | Acc: 47.421% (18240/38464)
Loss: 1.798 | Acc: 47.521% (21320/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9531, Accuracy: 3912/10000 (39.12%)

Epoch: 74
Loss: 1.825 | Acc: 43.750% (28/64)
Loss: 1.794 | Acc: 47.587% (3076/6464)
Loss: 1.791 | Acc: 47.668% (6132/12864)
Loss: 1.792 | Acc: 47.685% (9186/19264)
Loss: 1.795 | Acc: 47.522% (12196/25664)
Loss: 1.789 | Acc: 47.792% (15324/32064)
Loss: 1.794 | Acc: 47.624% (18318/38464)
Loss: 1.794 | Acc: 47.606% (21358/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8846, Accuracy: 4308/10000 (43.08%)

Epoch: 75
Loss: 1.571 | Acc: 57.812% (37/64)
Loss: 1.765 | Acc: 48.128% (3111/6464)
Loss: 1.768 | Acc: 48.235% (6205/12864)
Loss: 1.778 | Acc: 47.918% (9231/19264)
Loss: 1.781 | Acc: 47.865% (12284/25664)
Loss: 1.781 | Acc: 47.945% (15373/32064)
Loss: 1.783 | Acc: 47.873% (18414/38464)
Loss: 1.784 | Acc: 47.918% (21498/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9375, Accuracy: 4132/10000 (41.32%)

Epoch: 76
Loss: 1.679 | Acc: 51.562% (33/64)
Loss: 1.765 | Acc: 48.871% (3159/6464)
Loss: 1.761 | Acc: 48.865% (6286/12864)
Loss: 1.772 | Acc: 48.438% (9331/19264)
Loss: 1.776 | Acc: 48.317% (12400/25664)
Loss: 1.777 | Acc: 48.307% (15489/32064)
Loss: 1.779 | Acc: 48.183% (18533/38464)
Loss: 1.777 | Acc: 48.322% (21679/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8867, Accuracy: 4325/10000 (43.25%)

Epoch: 77
Loss: 1.751 | Acc: 50.000% (32/64)
Loss: 1.780 | Acc: 48.097% (3109/6464)
Loss: 1.773 | Acc: 48.476% (6236/12864)
Loss: 1.773 | Acc: 48.531% (9349/19264)
Loss: 1.779 | Acc: 48.270% (12388/25664)
Loss: 1.776 | Acc: 48.425% (15527/32064)
Loss: 1.773 | Acc: 48.531% (18667/38464)
Loss: 1.773 | Acc: 48.551% (21782/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9358, Accuracy: 4033/10000 (40.33%)

Epoch: 78
Loss: 1.800 | Acc: 45.312% (29/64)
Loss: 1.766 | Acc: 49.149% (3177/6464)
Loss: 1.769 | Acc: 48.826% (6281/12864)
Loss: 1.766 | Acc: 48.920% (9424/19264)
Loss: 1.765 | Acc: 48.956% (12564/25664)
Loss: 1.763 | Acc: 48.946% (15694/32064)
Loss: 1.762 | Acc: 48.924% (18818/38464)
Loss: 1.764 | Acc: 48.859% (21920/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9015, Accuracy: 4314/10000 (43.14%)

Epoch: 79
Loss: 1.578 | Acc: 59.375% (38/64)
Loss: 1.747 | Acc: 49.489% (3199/6464)
Loss: 1.755 | Acc: 49.044% (6309/12864)
Loss: 1.752 | Acc: 49.377% (9512/19264)
Loss: 1.752 | Acc: 49.419% (12683/25664)
Loss: 1.753 | Acc: 49.292% (15805/32064)
Loss: 1.754 | Acc: 49.254% (18945/38464)
Loss: 1.753 | Acc: 49.291% (22114/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8772, Accuracy: 4342/10000 (43.42%)

Epoch: 80
Loss: 1.822 | Acc: 46.875% (30/64)
Loss: 1.764 | Acc: 48.422% (3130/6464)
Loss: 1.747 | Acc: 49.269% (6338/12864)
Loss: 1.742 | Acc: 49.714% (9577/19264)
Loss: 1.743 | Acc: 49.684% (12751/25664)
Loss: 1.746 | Acc: 49.501% (15872/32064)
Loss: 1.747 | Acc: 49.511% (19044/38464)
Loss: 1.749 | Acc: 49.454% (22187/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8952, Accuracy: 4391/10000 (43.91%)

Epoch: 81
Loss: 1.831 | Acc: 43.750% (28/64)
Loss: 1.728 | Acc: 49.876% (3224/6464)
Loss: 1.733 | Acc: 49.852% (6413/12864)
Loss: 1.734 | Acc: 49.958% (9624/19264)
Loss: 1.738 | Acc: 49.825% (12787/25664)
Loss: 1.737 | Acc: 49.913% (16004/32064)
Loss: 1.735 | Acc: 50.049% (19251/38464)
Loss: 1.737 | Acc: 49.949% (22409/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8877, Accuracy: 4381/10000 (43.81%)

Epoch: 82
Loss: 1.738 | Acc: 50.000% (32/64)
Loss: 1.734 | Acc: 49.103% (3174/6464)
Loss: 1.729 | Acc: 49.736% (6398/12864)
Loss: 1.723 | Acc: 50.161% (9663/19264)
Loss: 1.723 | Acc: 50.179% (12878/25664)
Loss: 1.725 | Acc: 50.140% (16077/32064)
Loss: 1.728 | Acc: 50.055% (19253/38464)
Loss: 1.728 | Acc: 50.062% (22460/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9123, Accuracy: 4330/10000 (43.30%)

Epoch: 83
Loss: 1.793 | Acc: 46.875% (30/64)
Loss: 1.685 | Acc: 51.903% (3355/6464)
Loss: 1.690 | Acc: 51.632% (6642/12864)
Loss: 1.696 | Acc: 51.329% (9888/19264)
Loss: 1.707 | Acc: 50.935% (13072/25664)
Loss: 1.706 | Acc: 50.998% (16352/32064)
Loss: 1.709 | Acc: 50.939% (19593/38464)
Loss: 1.709 | Acc: 50.947% (22857/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8680, Accuracy: 4531/10000 (45.31%)

Epoch: 84
Loss: 1.932 | Acc: 42.188% (27/64)
Loss: 1.698 | Acc: 51.021% (3298/6464)
Loss: 1.691 | Acc: 51.267% (6595/12864)
Loss: 1.700 | Acc: 51.054% (9835/19264)
Loss: 1.706 | Acc: 50.826% (13044/25664)
Loss: 1.703 | Acc: 50.967% (16342/32064)
Loss: 1.703 | Acc: 50.936% (19592/38464)
Loss: 1.702 | Acc: 51.086% (22919/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8713, Accuracy: 4498/10000 (44.98%)

Epoch: 85
Loss: 1.614 | Acc: 57.812% (37/64)
Loss: 1.691 | Acc: 51.238% (3312/6464)
Loss: 1.685 | Acc: 51.539% (6630/12864)
Loss: 1.679 | Acc: 51.765% (9972/19264)
Loss: 1.677 | Acc: 51.808% (13296/25664)
Loss: 1.678 | Acc: 51.865% (16630/32064)
Loss: 1.684 | Acc: 51.679% (19878/38464)
Loss: 1.690 | Acc: 51.480% (23096/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8937, Accuracy: 4418/10000 (44.18%)

Epoch: 86
Loss: 1.705 | Acc: 48.438% (31/64)
Loss: 1.662 | Acc: 51.949% (3358/6464)
Loss: 1.659 | Acc: 52.208% (6716/12864)
Loss: 1.654 | Acc: 52.492% (10112/19264)
Loss: 1.660 | Acc: 52.295% (13421/25664)
Loss: 1.666 | Acc: 52.115% (16710/32064)
Loss: 1.672 | Acc: 51.911% (19967/38464)
Loss: 1.669 | Acc: 52.075% (23363/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8805, Accuracy: 4531/10000 (45.31%)

Epoch: 87
Loss: 1.407 | Acc: 62.500% (40/64)
Loss: 1.635 | Acc: 53.094% (3432/6464)
Loss: 1.635 | Acc: 53.148% (6837/12864)
Loss: 1.647 | Acc: 52.684% (10149/19264)
Loss: 1.647 | Acc: 52.700% (13525/25664)
Loss: 1.645 | Acc: 52.720% (16904/32064)
Loss: 1.645 | Acc: 52.782% (20302/38464)
Loss: 1.643 | Acc: 52.936% (23749/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8851, Accuracy: 4528/10000 (45.28%)

Epoch: 88
Loss: 1.705 | Acc: 48.438% (31/64)
Loss: 1.624 | Acc: 53.079% (3431/6464)
Loss: 1.625 | Acc: 53.148% (6837/12864)
Loss: 1.628 | Acc: 53.187% (10246/19264)
Loss: 1.625 | Acc: 53.339% (13689/25664)
Loss: 1.628 | Acc: 53.190% (17055/32064)
Loss: 1.622 | Acc: 53.429% (20551/38464)
Loss: 1.623 | Acc: 53.419% (23966/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9045, Accuracy: 4517/10000 (45.17%)

Epoch: 89
Loss: 1.519 | Acc: 57.812% (37/64)
Loss: 1.600 | Acc: 53.605% (3465/6464)
Loss: 1.575 | Acc: 54.960% (7070/12864)
Loss: 1.583 | Acc: 54.698% (10537/19264)
Loss: 1.588 | Acc: 54.563% (14003/25664)
Loss: 1.588 | Acc: 54.541% (17488/32064)
Loss: 1.592 | Acc: 54.422% (20933/38464)
Loss: 1.594 | Acc: 54.313% (24367/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9230, Accuracy: 4576/10000 (45.76%)

Epoch: 90
Loss: 1.680 | Acc: 53.125% (34/64)
Loss: 1.535 | Acc: 56.204% (3633/6464)
Loss: 1.555 | Acc: 55.395% (7126/12864)
Loss: 1.564 | Acc: 54.999% (10595/19264)
Loss: 1.563 | Acc: 54.968% (14107/25664)
Loss: 1.565 | Acc: 54.946% (17618/32064)
Loss: 1.567 | Acc: 54.908% (21120/38464)
Loss: 1.567 | Acc: 54.937% (24647/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9205, Accuracy: 4561/10000 (45.61%)

Epoch: 91
Loss: 1.524 | Acc: 54.688% (35/64)
Loss: 1.538 | Acc: 55.894% (3613/6464)
Loss: 1.538 | Acc: 55.605% (7153/12864)
Loss: 1.536 | Acc: 55.617% (10714/19264)
Loss: 1.532 | Acc: 55.817% (14325/25664)
Loss: 1.531 | Acc: 55.782% (17886/32064)
Loss: 1.532 | Acc: 55.850% (21482/38464)
Loss: 1.530 | Acc: 55.954% (25103/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9394, Accuracy: 4431/10000 (44.31%)

Epoch: 92
Loss: 1.461 | Acc: 59.375% (38/64)
Loss: 1.482 | Acc: 57.085% (3690/6464)
Loss: 1.466 | Acc: 57.812% (7437/12864)
Loss: 1.476 | Acc: 57.361% (11050/19264)
Loss: 1.481 | Acc: 57.150% (14667/25664)
Loss: 1.489 | Acc: 56.821% (18219/32064)
Loss: 1.485 | Acc: 56.970% (21913/38464)
Loss: 1.487 | Acc: 56.937% (25544/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9651, Accuracy: 4490/10000 (44.90%)

Epoch: 93
Loss: 1.381 | Acc: 62.500% (40/64)
Loss: 1.417 | Acc: 58.524% (3783/6464)
Loss: 1.411 | Acc: 59.056% (7597/12864)
Loss: 1.411 | Acc: 59.089% (11383/19264)
Loss: 1.424 | Acc: 58.685% (15061/25664)
Loss: 1.424 | Acc: 58.692% (18819/32064)
Loss: 1.430 | Acc: 58.509% (22505/38464)
Loss: 1.432 | Acc: 58.437% (26217/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9939, Accuracy: 4392/10000 (43.92%)

Epoch: 94
Loss: 1.362 | Acc: 59.375% (38/64)
Loss: 1.354 | Acc: 60.350% (3901/6464)
Loss: 1.367 | Acc: 59.989% (7717/12864)
Loss: 1.374 | Acc: 59.811% (11522/19264)
Loss: 1.379 | Acc: 59.617% (15300/25664)
Loss: 1.379 | Acc: 59.681% (19136/32064)
Loss: 1.381 | Acc: 59.619% (22932/38464)
Loss: 1.381 | Acc: 59.640% (26757/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0711, Accuracy: 4318/10000 (43.18%)

Epoch: 95
Loss: 1.155 | Acc: 67.188% (43/64)
Loss: 1.321 | Acc: 61.139% (3952/6464)
Loss: 1.355 | Acc: 60.285% (7755/12864)
Loss: 1.372 | Acc: 59.811% (11522/19264)
Loss: 1.385 | Acc: 59.519% (15275/25664)
Loss: 1.401 | Acc: 59.066% (18939/32064)
Loss: 1.410 | Acc: 58.839% (22632/38464)
Loss: 1.418 | Acc: 58.680% (26326/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9705, Accuracy: 4466/10000 (44.66%)

Epoch: 96
Loss: 1.302 | Acc: 67.188% (43/64)
Loss: 1.478 | Acc: 57.132% (3693/6464)
Loss: 1.473 | Acc: 57.548% (7403/12864)
Loss: 1.483 | Acc: 57.086% (10997/19264)
Loss: 1.488 | Acc: 56.998% (14628/25664)
Loss: 1.488 | Acc: 57.098% (18308/32064)
Loss: 1.494 | Acc: 57.004% (21926/38464)
Loss: 1.497 | Acc: 56.896% (25526/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9329, Accuracy: 4463/10000 (44.63%)

Epoch: 97
Loss: 1.569 | Acc: 56.250% (36/64)
Loss: 1.509 | Acc: 56.761% (3669/6464)
Loss: 1.507 | Acc: 57.012% (7334/12864)
Loss: 1.515 | Acc: 56.452% (10875/19264)
Loss: 1.515 | Acc: 56.445% (14486/25664)
Loss: 1.517 | Acc: 56.331% (18062/32064)
Loss: 1.515 | Acc: 56.403% (21695/38464)
Loss: 1.519 | Acc: 56.319% (25267/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9339, Accuracy: 4504/10000 (45.04%)
torch.Size([100, 10])
Test set: Average loss: 1.9339, Accuracy: 4504/10000 (45.04%)

Epoch: 98
Loss: 1.275 | Acc: 65.625% (42/64)
Loss: 1.520 | Acc: 56.126% (3628/6464)
Loss: 1.530 | Acc: 55.807% (7179/12864)
Loss: 1.534 | Acc: 55.793% (10748/19264)
Loss: 1.532 | Acc: 55.856% (14335/25664)
Loss: 1.532 | Acc: 55.888% (17920/32064)
Loss: 1.530 | Acc: 56.016% (21546/38464)
Loss: 1.528 | Acc: 56.029% (25137/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9328, Accuracy: 4500/10000 (45.00%)
torch.Size([100, 10])
Test set: Average loss: 1.9328, Accuracy: 4500/10000 (45.00%)

Epoch: 99
Loss: 1.489 | Acc: 57.812% (37/64)
Loss: 1.507 | Acc: 56.791% (3671/6464)
Loss: 1.520 | Acc: 56.219% (7232/12864)
Loss: 1.520 | Acc: 56.307% (10847/19264)
Loss: 1.522 | Acc: 56.207% (14425/25664)
Loss: 1.521 | Acc: 56.247% (18035/32064)
Loss: 1.520 | Acc: 56.276% (21646/38464)
Loss: 1.521 | Acc: 56.263% (25242/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9337, Accuracy: 4495/10000 (44.95%)
torch.Size([100, 10])
Test set: Average loss: 1.9337, Accuracy: 4495/10000 (44.95%)

Epoch: 100
Loss: 1.668 | Acc: 46.875% (30/64)
Loss: 2.189 | Acc: 22.695% (1467/6464)
Loss: 2.085 | Acc: 29.835% (3838/12864)
Loss: 2.032 | Acc: 33.451% (6444/19264)
Loss: 1.998 | Acc: 35.692% (9160/25664)
Loss: 1.979 | Acc: 37.001% (11864/32064)
Loss: 1.962 | Acc: 37.978% (14608/38464)
Loss: 1.951 | Acc: 38.677% (17352/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0459, Accuracy: 3345/10000 (33.45%)

Epoch: 101
Loss: 2.094 | Acc: 31.250% (20/64)
Loss: 1.851 | Acc: 44.647% (2886/6464)
Loss: 1.854 | Acc: 44.566% (5733/12864)
Loss: 1.850 | Acc: 44.741% (8619/19264)
Loss: 1.856 | Acc: 44.537% (11430/25664)
Loss: 1.856 | Acc: 44.580% (14294/32064)
Loss: 1.854 | Acc: 44.670% (17182/38464)
Loss: 1.857 | Acc: 44.604% (20011/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0484, Accuracy: 3522/10000 (35.22%)

Epoch: 102
Loss: 1.808 | Acc: 42.188% (27/64)
Loss: 1.845 | Acc: 45.312% (2929/6464)
Loss: 1.847 | Acc: 44.807% (5764/12864)
Loss: 1.849 | Acc: 44.721% (8615/19264)
Loss: 1.845 | Acc: 44.950% (11536/25664)
Loss: 1.844 | Acc: 44.988% (14425/32064)
Loss: 1.849 | Acc: 44.821% (17240/38464)
Loss: 1.852 | Acc: 44.686% (20048/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3508, Accuracy: 2885/10000 (28.85%)

Epoch: 103
Loss: 2.059 | Acc: 34.375% (22/64)
Loss: 1.852 | Acc: 45.405% (2935/6464)
Loss: 1.850 | Acc: 45.141% (5807/12864)
Loss: 1.848 | Acc: 45.146% (8697/19264)
Loss: 1.847 | Acc: 45.211% (11603/25664)
Loss: 1.846 | Acc: 45.334% (14536/32064)
Loss: 1.846 | Acc: 45.294% (17422/38464)
Loss: 1.847 | Acc: 45.281% (20315/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1317, Accuracy: 3440/10000 (34.40%)

Epoch: 104
Loss: 1.861 | Acc: 42.188% (27/64)
Loss: 1.831 | Acc: 45.823% (2962/6464)
Loss: 1.836 | Acc: 45.608% (5867/12864)
Loss: 1.833 | Acc: 45.811% (8825/19264)
Loss: 1.838 | Acc: 45.593% (11701/25664)
Loss: 1.841 | Acc: 45.481% (14583/32064)
Loss: 1.847 | Acc: 45.227% (17396/38464)
Loss: 1.846 | Acc: 45.284% (20316/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0807, Accuracy: 3531/10000 (35.31%)

Epoch: 105
Loss: 2.184 | Acc: 29.688% (19/64)
Loss: 1.852 | Acc: 44.895% (2902/6464)
Loss: 1.833 | Acc: 45.756% (5886/12864)
Loss: 1.840 | Acc: 45.411% (8748/19264)
Loss: 1.835 | Acc: 45.535% (11686/25664)
Loss: 1.836 | Acc: 45.440% (14570/32064)
Loss: 1.839 | Acc: 45.336% (17438/38464)
Loss: 1.840 | Acc: 45.315% (20330/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3381, Accuracy: 2417/10000 (24.17%)

Epoch: 106
Loss: 2.147 | Acc: 35.938% (23/64)
Loss: 1.850 | Acc: 45.003% (2909/6464)
Loss: 1.859 | Acc: 44.621% (5740/12864)
Loss: 1.853 | Acc: 45.032% (8675/19264)
Loss: 1.851 | Acc: 45.188% (11597/25664)
Loss: 1.850 | Acc: 45.200% (14493/32064)
Loss: 1.851 | Acc: 45.128% (17358/38464)
Loss: 1.847 | Acc: 45.284% (20316/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9727, Accuracy: 3936/10000 (39.36%)

Epoch: 107
Loss: 2.011 | Acc: 37.500% (24/64)
Loss: 1.819 | Acc: 46.194% (2986/6464)
Loss: 1.831 | Acc: 45.585% (5864/12864)
Loss: 1.827 | Acc: 45.920% (8846/19264)
Loss: 1.833 | Acc: 45.667% (11720/25664)
Loss: 1.833 | Acc: 45.768% (14675/32064)
Loss: 1.837 | Acc: 45.606% (17542/38464)
Loss: 1.839 | Acc: 45.551% (20436/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2030, Accuracy: 2803/10000 (28.03%)

Epoch: 108
Loss: 2.048 | Acc: 37.500% (24/64)
Loss: 1.834 | Acc: 45.668% (2952/6464)
Loss: 1.827 | Acc: 46.090% (5929/12864)
Loss: 1.830 | Acc: 46.013% (8864/19264)
Loss: 1.833 | Acc: 45.944% (11791/25664)
Loss: 1.835 | Acc: 45.734% (14664/32064)
Loss: 1.839 | Acc: 45.567% (17527/38464)
Loss: 1.839 | Acc: 45.580% (20449/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1362, Accuracy: 3142/10000 (31.42%)

Epoch: 109
Loss: 1.754 | Acc: 43.750% (28/64)
Loss: 1.841 | Acc: 45.622% (2949/6464)
Loss: 1.827 | Acc: 46.144% (5936/12864)
Loss: 1.832 | Acc: 45.946% (8851/19264)
Loss: 1.832 | Acc: 45.893% (11778/25664)
Loss: 1.837 | Acc: 45.702% (14654/32064)
Loss: 1.838 | Acc: 45.614% (17545/38464)
Loss: 1.839 | Acc: 45.520% (20422/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0497, Accuracy: 3701/10000 (37.01%)

Epoch: 110
Loss: 1.882 | Acc: 42.188% (27/64)
Loss: 1.850 | Acc: 45.096% (2915/6464)
Loss: 1.839 | Acc: 45.429% (5844/12864)
Loss: 1.836 | Acc: 45.603% (8785/19264)
Loss: 1.835 | Acc: 45.632% (11711/25664)
Loss: 1.836 | Acc: 45.590% (14618/32064)
Loss: 1.837 | Acc: 45.593% (17537/38464)
Loss: 1.835 | Acc: 45.678% (20493/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0685, Accuracy: 3490/10000 (34.90%)

Epoch: 111
Loss: 1.789 | Acc: 48.438% (31/64)
Loss: 1.819 | Acc: 46.101% (2980/6464)
Loss: 1.819 | Acc: 46.323% (5959/12864)
Loss: 1.824 | Acc: 46.008% (8863/19264)
Loss: 1.828 | Acc: 45.963% (11796/25664)
Loss: 1.832 | Acc: 45.883% (14712/32064)
Loss: 1.834 | Acc: 45.812% (17621/38464)
Loss: 1.834 | Acc: 45.839% (20565/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9859, Accuracy: 3894/10000 (38.94%)

Epoch: 112
Loss: 1.888 | Acc: 42.188% (27/64)
Loss: 1.808 | Acc: 47.061% (3042/6464)
Loss: 1.817 | Acc: 46.758% (6015/12864)
Loss: 1.821 | Acc: 46.543% (8966/19264)
Loss: 1.826 | Acc: 46.294% (11881/25664)
Loss: 1.826 | Acc: 46.245% (14828/32064)
Loss: 1.830 | Acc: 46.022% (17702/38464)
Loss: 1.829 | Acc: 46.117% (20690/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9071, Accuracy: 4235/10000 (42.35%)

Epoch: 113
Loss: 1.641 | Acc: 56.250% (36/64)
Loss: 1.805 | Acc: 47.386% (3063/6464)
Loss: 1.815 | Acc: 46.727% (6011/12864)
Loss: 1.819 | Acc: 46.621% (8981/19264)
Loss: 1.821 | Acc: 46.555% (11948/25664)
Loss: 1.824 | Acc: 46.407% (14880/32064)
Loss: 1.829 | Acc: 46.129% (17743/38464)
Loss: 1.828 | Acc: 46.213% (20733/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9649, Accuracy: 3918/10000 (39.18%)

Epoch: 114
Loss: 1.725 | Acc: 53.125% (34/64)
Loss: 1.813 | Acc: 46.720% (3020/6464)
Loss: 1.816 | Acc: 46.642% (6000/12864)
Loss: 1.818 | Acc: 46.475% (8953/19264)
Loss: 1.816 | Acc: 46.587% (11956/25664)
Loss: 1.820 | Acc: 46.460% (14897/32064)
Loss: 1.822 | Acc: 46.300% (17809/38464)
Loss: 1.824 | Acc: 46.240% (20745/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9821, Accuracy: 3909/10000 (39.09%)

Epoch: 115
Loss: 1.757 | Acc: 50.000% (32/64)
Loss: 1.800 | Acc: 47.030% (3040/6464)
Loss: 1.819 | Acc: 46.261% (5951/12864)
Loss: 1.819 | Acc: 46.397% (8938/19264)
Loss: 1.822 | Acc: 46.341% (11893/25664)
Loss: 1.824 | Acc: 46.151% (14798/32064)
Loss: 1.821 | Acc: 46.329% (17820/38464)
Loss: 1.821 | Acc: 46.365% (20801/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8960, Accuracy: 4331/10000 (43.31%)

Epoch: 116
Loss: 1.619 | Acc: 56.250% (36/64)
Loss: 1.802 | Acc: 47.401% (3064/6464)
Loss: 1.806 | Acc: 47.194% (6071/12864)
Loss: 1.812 | Acc: 46.948% (9044/19264)
Loss: 1.814 | Acc: 46.883% (12032/25664)
Loss: 1.812 | Acc: 46.972% (15061/32064)
Loss: 1.812 | Acc: 46.976% (18069/38464)
Loss: 1.815 | Acc: 46.850% (21019/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0571, Accuracy: 3566/10000 (35.66%)

Epoch: 117
Loss: 1.659 | Acc: 48.438% (31/64)
Loss: 1.795 | Acc: 47.339% (3060/6464)
Loss: 1.808 | Acc: 46.992% (6045/12864)
Loss: 1.811 | Acc: 46.932% (9041/19264)
Loss: 1.816 | Acc: 46.715% (11989/25664)
Loss: 1.817 | Acc: 46.644% (14956/32064)
Loss: 1.818 | Acc: 46.683% (17956/38464)
Loss: 1.816 | Acc: 46.737% (20968/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0681, Accuracy: 3547/10000 (35.47%)

Epoch: 118
Loss: 2.011 | Acc: 35.938% (23/64)
Loss: 1.800 | Acc: 47.231% (3053/6464)
Loss: 1.801 | Acc: 47.326% (6088/12864)
Loss: 1.805 | Acc: 47.285% (9109/19264)
Loss: 1.806 | Acc: 47.222% (12119/25664)
Loss: 1.807 | Acc: 47.231% (15144/32064)
Loss: 1.806 | Acc: 47.236% (18169/38464)
Loss: 1.808 | Acc: 47.158% (21157/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9508, Accuracy: 4068/10000 (40.68%)

Epoch: 119
Loss: 1.747 | Acc: 45.312% (29/64)
Loss: 1.820 | Acc: 46.426% (3001/6464)
Loss: 1.810 | Acc: 46.992% (6045/12864)
Loss: 1.799 | Acc: 47.332% (9118/19264)
Loss: 1.802 | Acc: 47.335% (12148/25664)
Loss: 1.804 | Acc: 47.296% (15165/32064)
Loss: 1.806 | Acc: 47.218% (18162/38464)
Loss: 1.807 | Acc: 47.134% (21146/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9503, Accuracy: 4043/10000 (40.43%)

Epoch: 120
Loss: 1.632 | Acc: 53.125% (34/64)
Loss: 1.820 | Acc: 46.643% (3015/6464)
Loss: 1.815 | Acc: 46.875% (6030/12864)
Loss: 1.804 | Acc: 47.275% (9107/19264)
Loss: 1.802 | Acc: 47.405% (12166/25664)
Loss: 1.803 | Acc: 47.452% (15215/32064)
Loss: 1.803 | Acc: 47.457% (18254/38464)
Loss: 1.806 | Acc: 47.290% (21216/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9820, Accuracy: 4041/10000 (40.41%)

Epoch: 121
Loss: 1.782 | Acc: 48.438% (31/64)
Loss: 1.800 | Acc: 47.432% (3066/6464)
Loss: 1.796 | Acc: 47.567% (6119/12864)
Loss: 1.791 | Acc: 47.612% (9172/19264)
Loss: 1.796 | Acc: 47.405% (12166/25664)
Loss: 1.793 | Acc: 47.586% (15258/32064)
Loss: 1.796 | Acc: 47.473% (18260/38464)
Loss: 1.798 | Acc: 47.470% (21297/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8951, Accuracy: 4397/10000 (43.97%)

Epoch: 122
Loss: 1.905 | Acc: 43.750% (28/64)
Loss: 1.789 | Acc: 48.128% (3111/6464)
Loss: 1.794 | Acc: 47.963% (6170/12864)
Loss: 1.793 | Acc: 47.799% (9208/19264)
Loss: 1.789 | Acc: 47.900% (12293/25664)
Loss: 1.792 | Acc: 47.770% (15317/32064)
Loss: 1.791 | Acc: 47.775% (18376/38464)
Loss: 1.793 | Acc: 47.704% (21402/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8946, Accuracy: 4359/10000 (43.59%)

Epoch: 123
Loss: 1.850 | Acc: 43.750% (28/64)
Loss: 1.778 | Acc: 48.097% (3109/6464)
Loss: 1.788 | Acc: 47.746% (6142/12864)
Loss: 1.783 | Acc: 48.074% (9261/19264)
Loss: 1.779 | Acc: 48.317% (12400/25664)
Loss: 1.779 | Acc: 48.247% (15470/32064)
Loss: 1.782 | Acc: 48.136% (18515/38464)
Loss: 1.784 | Acc: 48.025% (21546/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9441, Accuracy: 4028/10000 (40.28%)

Epoch: 124
Loss: 1.787 | Acc: 53.125% (34/64)
Loss: 1.768 | Acc: 48.902% (3161/6464)
Loss: 1.765 | Acc: 49.137% (6321/12864)
Loss: 1.768 | Acc: 49.009% (9441/19264)
Loss: 1.765 | Acc: 49.069% (12593/25664)
Loss: 1.772 | Acc: 48.749% (15631/32064)
Loss: 1.776 | Acc: 48.531% (18667/38464)
Loss: 1.779 | Acc: 48.397% (21713/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9300, Accuracy: 4124/10000 (41.24%)

Epoch: 125
Loss: 1.769 | Acc: 51.562% (33/64)
Loss: 1.781 | Acc: 48.577% (3140/6464)
Loss: 1.767 | Acc: 48.935% (6295/12864)
Loss: 1.769 | Acc: 48.879% (9416/19264)
Loss: 1.764 | Acc: 49.057% (12590/25664)
Loss: 1.770 | Acc: 48.806% (15649/32064)
Loss: 1.771 | Acc: 48.729% (18743/38464)
Loss: 1.771 | Acc: 48.721% (21858/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9704, Accuracy: 3824/10000 (38.24%)

Epoch: 126
Loss: 1.728 | Acc: 45.312% (29/64)
Loss: 1.739 | Acc: 49.923% (3227/6464)
Loss: 1.760 | Acc: 49.246% (6335/12864)
Loss: 1.763 | Acc: 49.081% (9455/19264)
Loss: 1.769 | Acc: 48.745% (12510/25664)
Loss: 1.771 | Acc: 48.646% (15598/32064)
Loss: 1.764 | Acc: 48.965% (18834/38464)
Loss: 1.766 | Acc: 48.836% (21910/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0133, Accuracy: 3878/10000 (38.78%)

Epoch: 127
Loss: 1.699 | Acc: 56.250% (36/64)
Loss: 1.766 | Acc: 48.453% (3132/6464)
Loss: 1.757 | Acc: 49.355% (6349/12864)
Loss: 1.762 | Acc: 49.076% (9454/19264)
Loss: 1.760 | Acc: 49.162% (12617/25664)
Loss: 1.762 | Acc: 49.046% (15726/32064)
Loss: 1.759 | Acc: 49.168% (18912/38464)
Loss: 1.757 | Acc: 49.262% (22101/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9696, Accuracy: 3893/10000 (38.93%)

Epoch: 128
Loss: 2.120 | Acc: 34.375% (22/64)
Loss: 1.734 | Acc: 49.737% (3215/6464)
Loss: 1.744 | Acc: 49.549% (6374/12864)
Loss: 1.741 | Acc: 49.585% (9552/19264)
Loss: 1.745 | Acc: 49.454% (12692/25664)
Loss: 1.746 | Acc: 49.451% (15856/32064)
Loss: 1.747 | Acc: 49.470% (19028/38464)
Loss: 1.748 | Acc: 49.387% (22157/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8905, Accuracy: 4398/10000 (43.98%)

Epoch: 129
Loss: 1.754 | Acc: 51.562% (33/64)
Loss: 1.723 | Acc: 50.619% (3272/6464)
Loss: 1.722 | Acc: 50.567% (6505/12864)
Loss: 1.721 | Acc: 50.457% (9720/19264)
Loss: 1.726 | Acc: 50.230% (12891/25664)
Loss: 1.734 | Acc: 49.928% (16009/32064)
Loss: 1.738 | Acc: 49.886% (19188/38464)
Loss: 1.740 | Acc: 49.840% (22360/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8731, Accuracy: 4483/10000 (44.83%)

Epoch: 130
Loss: 1.800 | Acc: 45.312% (29/64)
Loss: 1.719 | Acc: 50.588% (3270/6464)
Loss: 1.731 | Acc: 50.117% (6447/12864)
Loss: 1.735 | Acc: 50.067% (9645/19264)
Loss: 1.734 | Acc: 50.074% (12851/25664)
Loss: 1.734 | Acc: 50.084% (16059/32064)
Loss: 1.735 | Acc: 50.081% (19263/38464)
Loss: 1.733 | Acc: 50.118% (22485/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8826, Accuracy: 4440/10000 (44.40%)

Epoch: 131
Loss: 1.891 | Acc: 42.188% (27/64)
Loss: 1.699 | Acc: 51.485% (3328/6464)
Loss: 1.712 | Acc: 50.824% (6538/12864)
Loss: 1.710 | Acc: 50.981% (9821/19264)
Loss: 1.710 | Acc: 51.009% (13091/25664)
Loss: 1.714 | Acc: 50.876% (16313/32064)
Loss: 1.718 | Acc: 50.767% (19527/38464)
Loss: 1.721 | Acc: 50.633% (22716/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8794, Accuracy: 4459/10000 (44.59%)

Epoch: 132
Loss: 2.195 | Acc: 29.688% (19/64)
Loss: 1.689 | Acc: 51.547% (3332/6464)
Loss: 1.693 | Acc: 51.353% (6606/12864)
Loss: 1.701 | Acc: 51.116% (9847/19264)
Loss: 1.701 | Acc: 51.212% (13143/25664)
Loss: 1.704 | Acc: 51.179% (16410/32064)
Loss: 1.707 | Acc: 51.071% (19644/38464)
Loss: 1.708 | Acc: 51.016% (22888/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8786, Accuracy: 4455/10000 (44.55%)

Epoch: 133
Loss: 1.699 | Acc: 51.562% (33/64)
Loss: 1.649 | Acc: 53.094% (3432/6464)
Loss: 1.684 | Acc: 51.640% (6643/12864)
Loss: 1.701 | Acc: 50.976% (9820/19264)
Loss: 1.702 | Acc: 51.060% (13104/25664)
Loss: 1.703 | Acc: 51.073% (16376/32064)
Loss: 1.700 | Acc: 51.160% (19678/38464)
Loss: 1.697 | Acc: 51.331% (23029/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8922, Accuracy: 4439/10000 (44.39%)

Epoch: 134
Loss: 1.556 | Acc: 57.812% (37/64)
Loss: 1.669 | Acc: 52.522% (3395/6464)
Loss: 1.679 | Acc: 52.021% (6692/12864)
Loss: 1.681 | Acc: 51.926% (10003/19264)
Loss: 1.682 | Acc: 51.796% (13293/25664)
Loss: 1.685 | Acc: 51.659% (16564/32064)
Loss: 1.682 | Acc: 51.731% (19898/38464)
Loss: 1.680 | Acc: 51.826% (23251/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8802, Accuracy: 4545/10000 (45.45%)

Epoch: 135
Loss: 1.842 | Acc: 43.750% (28/64)
Loss: 1.658 | Acc: 52.243% (3377/6464)
Loss: 1.650 | Acc: 52.721% (6782/12864)
Loss: 1.654 | Acc: 52.554% (10124/19264)
Loss: 1.659 | Acc: 52.494% (13472/25664)
Loss: 1.659 | Acc: 52.511% (16837/32064)
Loss: 1.663 | Acc: 52.342% (20133/38464)
Loss: 1.665 | Acc: 52.298% (23463/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9169, Accuracy: 4350/10000 (43.50%)

Epoch: 136
Loss: 2.033 | Acc: 37.500% (24/64)
Loss: 1.643 | Acc: 52.692% (3406/6464)
Loss: 1.636 | Acc: 53.024% (6821/12864)
Loss: 1.637 | Acc: 53.011% (10212/19264)
Loss: 1.646 | Acc: 52.720% (13530/25664)
Loss: 1.647 | Acc: 52.648% (16881/32064)
Loss: 1.649 | Acc: 52.563% (20218/38464)
Loss: 1.647 | Acc: 52.708% (23647/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9089, Accuracy: 4370/10000 (43.70%)

Epoch: 137
Loss: 1.593 | Acc: 51.562% (33/64)
Loss: 1.606 | Acc: 54.610% (3530/6464)
Loss: 1.608 | Acc: 54.206% (6973/12864)
Loss: 1.620 | Acc: 53.748% (10354/19264)
Loss: 1.617 | Acc: 53.904% (13834/25664)
Loss: 1.615 | Acc: 53.895% (17281/32064)
Loss: 1.618 | Acc: 53.744% (20672/38464)
Loss: 1.621 | Acc: 53.693% (24089/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8934, Accuracy: 4551/10000 (45.51%)

Epoch: 138
Loss: 1.769 | Acc: 45.312% (29/64)
Loss: 1.587 | Acc: 54.688% (3535/6464)
Loss: 1.589 | Acc: 54.548% (7017/12864)
Loss: 1.594 | Acc: 54.480% (10495/19264)
Loss: 1.600 | Acc: 54.193% (13908/25664)
Loss: 1.599 | Acc: 54.226% (17387/32064)
Loss: 1.596 | Acc: 54.337% (20900/38464)
Loss: 1.595 | Acc: 54.451% (24429/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8916, Accuracy: 4505/10000 (45.05%)

Epoch: 139
Loss: 1.445 | Acc: 59.375% (38/64)
Loss: 1.548 | Acc: 55.724% (3602/6464)
Loss: 1.548 | Acc: 55.838% (7183/12864)
Loss: 1.546 | Acc: 55.902% (10769/19264)
Loss: 1.551 | Acc: 55.673% (14288/25664)
Loss: 1.559 | Acc: 55.458% (17782/32064)
Loss: 1.563 | Acc: 55.317% (21277/38464)
Loss: 1.565 | Acc: 55.236% (24781/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9177, Accuracy: 4515/10000 (45.15%)

Epoch: 140
Loss: 1.808 | Acc: 42.188% (27/64)
Loss: 1.514 | Acc: 56.730% (3667/6464)
Loss: 1.524 | Acc: 56.149% (7223/12864)
Loss: 1.524 | Acc: 56.120% (10811/19264)
Loss: 1.527 | Acc: 56.086% (14394/25664)
Loss: 1.527 | Acc: 56.113% (17992/32064)
Loss: 1.532 | Acc: 55.915% (21507/38464)
Loss: 1.533 | Acc: 55.933% (25094/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9542, Accuracy: 4492/10000 (44.92%)

Epoch: 141
Loss: 1.433 | Acc: 57.812% (37/64)
Loss: 1.466 | Acc: 58.091% (3755/6464)
Loss: 1.474 | Acc: 57.548% (7403/12864)
Loss: 1.480 | Acc: 57.408% (11059/19264)
Loss: 1.489 | Acc: 57.018% (14633/25664)
Loss: 1.489 | Acc: 57.070% (18299/32064)
Loss: 1.490 | Acc: 57.009% (21928/38464)
Loss: 1.494 | Acc: 56.914% (25534/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9879, Accuracy: 4423/10000 (44.23%)

Epoch: 142
Loss: 1.246 | Acc: 68.750% (44/64)
Loss: 1.452 | Acc: 57.642% (3726/6464)
Loss: 1.439 | Acc: 58.209% (7488/12864)
Loss: 1.447 | Acc: 57.922% (11158/19264)
Loss: 1.443 | Acc: 58.144% (14922/25664)
Loss: 1.444 | Acc: 58.121% (18636/32064)
Loss: 1.442 | Acc: 58.171% (22375/38464)
Loss: 1.444 | Acc: 58.183% (26103/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0158, Accuracy: 4391/10000 (43.91%)

Epoch: 143
Loss: 1.293 | Acc: 64.062% (41/64)
Loss: 1.382 | Acc: 60.133% (3887/6464)
Loss: 1.394 | Acc: 59.492% (7653/12864)
Loss: 1.388 | Acc: 59.697% (11500/19264)
Loss: 1.391 | Acc: 59.515% (15274/25664)
Loss: 1.391 | Acc: 59.553% (19095/32064)
Loss: 1.393 | Acc: 59.541% (22902/38464)
Loss: 1.395 | Acc: 59.384% (26642/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0450, Accuracy: 4295/10000 (42.95%)

Epoch: 144
Loss: 1.513 | Acc: 50.000% (32/64)
Loss: 1.333 | Acc: 61.015% (3944/6464)
Loss: 1.340 | Acc: 60.487% (7781/12864)
Loss: 1.335 | Acc: 60.803% (11713/19264)
Loss: 1.334 | Acc: 60.934% (15638/25664)
Loss: 1.332 | Acc: 61.050% (19575/32064)
Loss: 1.334 | Acc: 61.008% (23466/38464)
Loss: 1.336 | Acc: 60.969% (27353/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1022, Accuracy: 4390/10000 (43.90%)

Epoch: 145
Loss: 1.177 | Acc: 62.500% (40/64)
Loss: 1.281 | Acc: 62.268% (4025/6464)
Loss: 1.300 | Acc: 61.738% (7942/12864)
Loss: 1.309 | Acc: 61.602% (11867/19264)
Loss: 1.322 | Acc: 61.319% (15737/25664)
Loss: 1.338 | Acc: 60.966% (19548/32064)
Loss: 1.352 | Acc: 60.613% (23314/38464)
Loss: 1.364 | Acc: 60.284% (27046/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0030, Accuracy: 4379/10000 (43.79%)

Epoch: 146
Loss: 1.531 | Acc: 54.688% (35/64)
Loss: 1.407 | Acc: 59.530% (3848/6464)
Loss: 1.402 | Acc: 59.709% (7681/12864)
Loss: 1.419 | Acc: 58.897% (11346/19264)
Loss: 1.421 | Acc: 58.857% (15105/25664)
Loss: 1.427 | Acc: 58.661% (18809/32064)
Loss: 1.438 | Acc: 58.273% (22414/38464)
Loss: 1.446 | Acc: 58.082% (26058/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9808, Accuracy: 4405/10000 (44.05%)

Epoch: 147
Loss: 1.426 | Acc: 60.938% (39/64)
Loss: 1.441 | Acc: 58.679% (3793/6464)
Loss: 1.447 | Acc: 58.427% (7516/12864)
Loss: 1.457 | Acc: 58.025% (11178/19264)
Loss: 1.456 | Acc: 58.046% (14897/25664)
Loss: 1.456 | Acc: 58.040% (18610/32064)
Loss: 1.462 | Acc: 57.774% (22222/38464)
Loss: 1.461 | Acc: 57.835% (25947/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9603, Accuracy: 4465/10000 (44.65%)
torch.Size([100, 10])
Test set: Average loss: 1.9603, Accuracy: 4465/10000 (44.65%)

Epoch: 148
Loss: 1.301 | Acc: 67.188% (43/64)
Loss: 1.455 | Acc: 58.153% (3759/6464)
Loss: 1.465 | Acc: 57.805% (7436/12864)
Loss: 1.464 | Acc: 57.714% (11118/19264)
Loss: 1.461 | Acc: 57.933% (14868/25664)
Loss: 1.463 | Acc: 57.875% (18557/32064)
Loss: 1.467 | Acc: 57.703% (22195/38464)
Loss: 1.468 | Acc: 57.719% (25895/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9638, Accuracy: 4494/10000 (44.94%)
torch.Size([100, 10])
Test set: Average loss: 1.9638, Accuracy: 4494/10000 (44.94%)

Epoch: 149
Loss: 1.322 | Acc: 60.938% (39/64)
Loss: 1.470 | Acc: 58.199% (3762/6464)
Loss: 1.465 | Acc: 58.131% (7478/12864)
Loss: 1.468 | Acc: 57.807% (11136/19264)
Loss: 1.468 | Acc: 57.668% (14800/25664)
Loss: 1.465 | Acc: 57.750% (18517/32064)
Loss: 1.467 | Acc: 57.644% (22172/38464)
Loss: 1.465 | Acc: 57.734% (25902/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9664, Accuracy: 4488/10000 (44.88%)
torch.Size([100, 10])
Test set: Average loss: 1.9664, Accuracy: 4488/10000 (44.88%)

Epoch: 150
Loss: 1.445 | Acc: 56.250% (36/64)
Loss: 2.174 | Acc: 23.639% (1528/6464)
Loss: 2.073 | Acc: 30.784% (3960/12864)
Loss: 2.027 | Acc: 33.882% (6527/19264)
Loss: 1.992 | Acc: 36.160% (9280/25664)
Loss: 1.967 | Acc: 37.715% (12093/32064)
Loss: 1.952 | Acc: 38.667% (14873/38464)
Loss: 1.939 | Acc: 39.557% (17747/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3504, Accuracy: 2282/10000 (22.82%)

Epoch: 151
Loss: 2.032 | Acc: 39.062% (25/64)
Loss: 1.854 | Acc: 44.322% (2865/6464)
Loss: 1.845 | Acc: 44.807% (5764/12864)
Loss: 1.850 | Acc: 44.835% (8637/19264)
Loss: 1.850 | Acc: 44.709% (11474/25664)
Loss: 1.852 | Acc: 44.736% (14344/32064)
Loss: 1.853 | Acc: 44.665% (17180/38464)
Loss: 1.853 | Acc: 44.624% (20020/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1070, Accuracy: 3471/10000 (34.71%)

Epoch: 152
Loss: 1.678 | Acc: 51.562% (33/64)
Loss: 1.824 | Acc: 45.668% (2952/6464)
Loss: 1.832 | Acc: 45.491% (5852/12864)
Loss: 1.837 | Acc: 45.432% (8752/19264)
Loss: 1.843 | Acc: 45.075% (11568/25664)
Loss: 1.844 | Acc: 45.057% (14447/32064)
Loss: 1.844 | Acc: 45.076% (17338/38464)
Loss: 1.843 | Acc: 45.145% (20254/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1492, Accuracy: 3025/10000 (30.25%)

Epoch: 153
Loss: 1.894 | Acc: 34.375% (22/64)
Loss: 1.847 | Acc: 45.173% (2920/6464)
Loss: 1.835 | Acc: 45.950% (5911/12864)
Loss: 1.841 | Acc: 45.515% (8768/19264)
Loss: 1.832 | Acc: 45.948% (11792/25664)
Loss: 1.834 | Acc: 45.846% (14700/32064)
Loss: 1.838 | Acc: 45.643% (17556/38464)
Loss: 1.839 | Acc: 45.631% (20472/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9781, Accuracy: 3832/10000 (38.32%)

Epoch: 154
Loss: 2.103 | Acc: 37.500% (24/64)
Loss: 1.824 | Acc: 45.730% (2956/6464)
Loss: 1.828 | Acc: 45.787% (5890/12864)
Loss: 1.832 | Acc: 45.614% (8787/19264)
Loss: 1.834 | Acc: 45.566% (11694/25664)
Loss: 1.832 | Acc: 45.634% (14632/32064)
Loss: 1.833 | Acc: 45.658% (17562/38464)
Loss: 1.832 | Acc: 45.747% (20524/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9977, Accuracy: 3731/10000 (37.31%)

Epoch: 155
Loss: 1.842 | Acc: 50.000% (32/64)
Loss: 1.837 | Acc: 46.055% (2977/6464)
Loss: 1.843 | Acc: 45.639% (5871/12864)
Loss: 1.833 | Acc: 45.935% (8849/19264)
Loss: 1.832 | Acc: 45.998% (11805/25664)
Loss: 1.832 | Acc: 45.999% (14749/32064)
Loss: 1.833 | Acc: 45.978% (17685/38464)
Loss: 1.834 | Acc: 45.888% (20587/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9738, Accuracy: 3895/10000 (38.95%)

Epoch: 156
Loss: 1.645 | Acc: 54.688% (35/64)
Loss: 1.837 | Acc: 45.684% (2953/6464)
Loss: 1.837 | Acc: 45.756% (5886/12864)
Loss: 1.830 | Acc: 46.050% (8871/19264)
Loss: 1.830 | Acc: 46.100% (11831/25664)
Loss: 1.835 | Acc: 45.833% (14696/32064)
Loss: 1.834 | Acc: 45.780% (17609/38464)
Loss: 1.834 | Acc: 45.841% (20566/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9364, Accuracy: 4039/10000 (40.39%)

Epoch: 157
Loss: 1.922 | Acc: 39.062% (25/64)
Loss: 1.836 | Acc: 45.545% (2944/6464)
Loss: 1.831 | Acc: 45.973% (5914/12864)
Loss: 1.834 | Acc: 45.821% (8827/19264)
Loss: 1.833 | Acc: 45.858% (11769/25664)
Loss: 1.835 | Acc: 45.762% (14673/32064)
Loss: 1.835 | Acc: 45.806% (17619/38464)
Loss: 1.835 | Acc: 45.772% (20535/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0564, Accuracy: 3554/10000 (35.54%)

Epoch: 158
Loss: 1.911 | Acc: 46.875% (30/64)
Loss: 1.832 | Acc: 45.746% (2957/6464)
Loss: 1.830 | Acc: 45.639% (5871/12864)
Loss: 1.833 | Acc: 45.432% (8752/19264)
Loss: 1.834 | Acc: 45.535% (11686/25664)
Loss: 1.833 | Acc: 45.565% (14610/32064)
Loss: 1.831 | Acc: 45.687% (17573/38464)
Loss: 1.832 | Acc: 45.687% (20497/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9715, Accuracy: 4005/10000 (40.05%)

Epoch: 159
Loss: 1.756 | Acc: 45.312% (29/64)
Loss: 1.818 | Acc: 46.349% (2996/6464)
Loss: 1.821 | Acc: 46.533% (5986/12864)
Loss: 1.823 | Acc: 46.252% (8910/19264)
Loss: 1.826 | Acc: 46.061% (11821/25664)
Loss: 1.827 | Acc: 45.974% (14741/32064)
Loss: 1.830 | Acc: 45.884% (17649/38464)
Loss: 1.831 | Acc: 45.908% (20596/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1140, Accuracy: 3237/10000 (32.37%)

Epoch: 160
Loss: 1.919 | Acc: 40.625% (26/64)
Loss: 1.811 | Acc: 47.355% (3061/6464)
Loss: 1.817 | Acc: 46.914% (6035/12864)
Loss: 1.818 | Acc: 46.714% (8999/19264)
Loss: 1.824 | Acc: 46.407% (11910/25664)
Loss: 1.823 | Acc: 46.519% (14916/32064)
Loss: 1.824 | Acc: 46.433% (17860/38464)
Loss: 1.826 | Acc: 46.425% (20828/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0331, Accuracy: 3504/10000 (35.04%)

Epoch: 161
Loss: 2.040 | Acc: 37.500% (24/64)
Loss: 1.832 | Acc: 46.071% (2978/6464)
Loss: 1.821 | Acc: 46.479% (5979/12864)
Loss: 1.828 | Acc: 45.987% (8859/19264)
Loss: 1.832 | Acc: 45.835% (11763/25664)
Loss: 1.832 | Acc: 45.874% (14709/32064)
Loss: 1.831 | Acc: 45.939% (17670/38464)
Loss: 1.830 | Acc: 45.981% (20629/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0179, Accuracy: 3474/10000 (34.74%)

Epoch: 162
Loss: 1.700 | Acc: 51.562% (33/64)
Loss: 1.822 | Acc: 46.272% (2991/6464)
Loss: 1.816 | Acc: 46.673% (6004/12864)
Loss: 1.818 | Acc: 46.465% (8951/19264)
Loss: 1.821 | Acc: 46.368% (11900/25664)
Loss: 1.826 | Acc: 46.126% (14790/32064)
Loss: 1.821 | Acc: 46.397% (17846/38464)
Loss: 1.822 | Acc: 46.318% (20780/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9364, Accuracy: 4133/10000 (41.33%)

Epoch: 163
Loss: 1.779 | Acc: 48.438% (31/64)
Loss: 1.797 | Acc: 47.772% (3088/6464)
Loss: 1.805 | Acc: 47.287% (6083/12864)
Loss: 1.812 | Acc: 46.948% (9044/19264)
Loss: 1.816 | Acc: 46.715% (11989/25664)
Loss: 1.819 | Acc: 46.576% (14934/32064)
Loss: 1.821 | Acc: 46.560% (17909/38464)
Loss: 1.822 | Acc: 46.478% (20852/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1501, Accuracy: 3284/10000 (32.84%)

Epoch: 164
Loss: 1.872 | Acc: 45.312% (29/64)
Loss: 1.823 | Acc: 46.426% (3001/6464)
Loss: 1.813 | Acc: 46.891% (6032/12864)
Loss: 1.815 | Acc: 46.714% (8999/19264)
Loss: 1.820 | Acc: 46.575% (11953/25664)
Loss: 1.820 | Acc: 46.526% (14918/32064)
Loss: 1.821 | Acc: 46.482% (17879/38464)
Loss: 1.822 | Acc: 46.382% (20809/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0242, Accuracy: 3558/10000 (35.58%)

Epoch: 165
Loss: 2.112 | Acc: 37.500% (24/64)
Loss: 1.829 | Acc: 45.978% (2972/6464)
Loss: 1.822 | Acc: 46.261% (5951/12864)
Loss: 1.820 | Acc: 46.325% (8924/19264)
Loss: 1.817 | Acc: 46.435% (11917/25664)
Loss: 1.814 | Acc: 46.697% (14973/32064)
Loss: 1.815 | Acc: 46.761% (17986/38464)
Loss: 1.814 | Acc: 46.768% (20982/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9871, Accuracy: 3824/10000 (38.24%)

Epoch: 166
Loss: 1.996 | Acc: 37.500% (24/64)
Loss: 1.799 | Acc: 47.571% (3075/6464)
Loss: 1.801 | Acc: 47.512% (6112/12864)
Loss: 1.800 | Acc: 47.368% (9125/19264)
Loss: 1.809 | Acc: 46.914% (12040/25664)
Loss: 1.811 | Acc: 46.872% (15029/32064)
Loss: 1.812 | Acc: 46.859% (18024/38464)
Loss: 1.813 | Acc: 46.928% (21054/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9028, Accuracy: 4322/10000 (43.22%)

Epoch: 167
Loss: 2.037 | Acc: 39.062% (25/64)
Loss: 1.798 | Acc: 47.432% (3066/6464)
Loss: 1.803 | Acc: 47.209% (6073/12864)
Loss: 1.805 | Acc: 47.228% (9098/19264)
Loss: 1.800 | Acc: 47.483% (12186/25664)
Loss: 1.804 | Acc: 47.271% (15157/32064)
Loss: 1.806 | Acc: 47.153% (18137/38464)
Loss: 1.808 | Acc: 47.100% (21131/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9096, Accuracy: 4265/10000 (42.65%)

Epoch: 168
Loss: 1.756 | Acc: 51.562% (33/64)
Loss: 1.807 | Acc: 46.890% (3031/6464)
Loss: 1.810 | Acc: 46.906% (6034/12864)
Loss: 1.807 | Acc: 47.119% (9077/19264)
Loss: 1.802 | Acc: 47.339% (12149/25664)
Loss: 1.803 | Acc: 47.365% (15187/32064)
Loss: 1.801 | Acc: 47.377% (18223/38464)
Loss: 1.805 | Acc: 47.205% (21178/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9692, Accuracy: 3854/10000 (38.54%)

Epoch: 169
Loss: 1.976 | Acc: 37.500% (24/64)
Loss: 1.804 | Acc: 47.401% (3064/6464)
Loss: 1.805 | Acc: 47.093% (6058/12864)
Loss: 1.803 | Acc: 47.285% (9109/19264)
Loss: 1.804 | Acc: 47.245% (12125/25664)
Loss: 1.805 | Acc: 47.243% (15148/32064)
Loss: 1.803 | Acc: 47.291% (18190/38464)
Loss: 1.804 | Acc: 47.316% (21228/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9818, Accuracy: 3759/10000 (37.59%)

Epoch: 170
Loss: 1.843 | Acc: 50.000% (32/64)
Loss: 1.788 | Acc: 47.912% (3097/6464)
Loss: 1.793 | Acc: 47.598% (6123/12864)
Loss: 1.795 | Acc: 47.555% (9161/19264)
Loss: 1.796 | Acc: 47.518% (12195/25664)
Loss: 1.796 | Acc: 47.586% (15258/32064)
Loss: 1.796 | Acc: 47.626% (18319/38464)
Loss: 1.798 | Acc: 47.521% (21320/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9686, Accuracy: 3955/10000 (39.55%)

Epoch: 171
Loss: 1.794 | Acc: 46.875% (30/64)
Loss: 1.771 | Acc: 48.608% (3142/6464)
Loss: 1.779 | Acc: 48.321% (6216/12864)
Loss: 1.782 | Acc: 48.131% (9272/19264)
Loss: 1.786 | Acc: 48.102% (12345/25664)
Loss: 1.785 | Acc: 48.144% (15437/32064)
Loss: 1.787 | Acc: 48.055% (18484/38464)
Loss: 1.792 | Acc: 47.860% (21472/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9506, Accuracy: 4052/10000 (40.52%)

Epoch: 172
Loss: 1.854 | Acc: 45.312% (29/64)
Loss: 1.789 | Acc: 47.339% (3060/6464)
Loss: 1.779 | Acc: 48.088% (6186/12864)
Loss: 1.776 | Acc: 48.370% (9318/19264)
Loss: 1.777 | Acc: 48.395% (12420/25664)
Loss: 1.782 | Acc: 48.282% (15481/32064)
Loss: 1.785 | Acc: 48.162% (18525/38464)
Loss: 1.786 | Acc: 48.141% (21598/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9032, Accuracy: 4315/10000 (43.15%)

Epoch: 173
Loss: 1.737 | Acc: 48.438% (31/64)
Loss: 1.802 | Acc: 47.076% (3043/6464)
Loss: 1.788 | Acc: 47.660% (6131/12864)
Loss: 1.783 | Acc: 48.121% (9270/19264)
Loss: 1.784 | Acc: 48.079% (12339/25664)
Loss: 1.780 | Acc: 48.253% (15472/32064)
Loss: 1.782 | Acc: 48.240% (18555/38464)
Loss: 1.779 | Acc: 48.297% (21668/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9292, Accuracy: 4109/10000 (41.09%)

Epoch: 174
Loss: 1.868 | Acc: 43.750% (28/64)
Loss: 1.761 | Acc: 48.855% (3158/6464)
Loss: 1.771 | Acc: 48.375% (6223/12864)
Loss: 1.760 | Acc: 49.040% (9447/19264)
Loss: 1.765 | Acc: 48.847% (12536/25664)
Loss: 1.771 | Acc: 48.634% (15594/32064)
Loss: 1.773 | Acc: 48.593% (18691/38464)
Loss: 1.774 | Acc: 48.520% (21768/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9538, Accuracy: 4100/10000 (41.00%)

Epoch: 175
Loss: 1.649 | Acc: 51.562% (33/64)
Loss: 1.761 | Acc: 49.025% (3169/6464)
Loss: 1.765 | Acc: 48.850% (6284/12864)
Loss: 1.760 | Acc: 49.071% (9453/19264)
Loss: 1.760 | Acc: 49.112% (12604/25664)
Loss: 1.756 | Acc: 49.392% (15837/32064)
Loss: 1.759 | Acc: 49.217% (18931/38464)
Loss: 1.763 | Acc: 49.093% (22025/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9218, Accuracy: 4105/10000 (41.05%)

Epoch: 176
Loss: 1.892 | Acc: 39.062% (25/64)
Loss: 1.766 | Acc: 48.515% (3136/6464)
Loss: 1.766 | Acc: 48.360% (6221/12864)
Loss: 1.763 | Acc: 48.526% (9348/19264)
Loss: 1.767 | Acc: 48.613% (12476/25664)
Loss: 1.767 | Acc: 48.631% (15593/32064)
Loss: 1.762 | Acc: 48.908% (18812/38464)
Loss: 1.759 | Acc: 49.095% (22026/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8860, Accuracy: 4397/10000 (43.97%)

Epoch: 177
Loss: 1.737 | Acc: 46.875% (30/64)
Loss: 1.762 | Acc: 49.257% (3184/6464)
Loss: 1.742 | Acc: 50.008% (6433/12864)
Loss: 1.745 | Acc: 49.922% (9617/19264)
Loss: 1.751 | Acc: 49.497% (12703/25664)
Loss: 1.753 | Acc: 49.414% (15844/32064)
Loss: 1.752 | Acc: 49.428% (19012/38464)
Loss: 1.751 | Acc: 49.427% (22175/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8733, Accuracy: 4465/10000 (44.65%)

Epoch: 178
Loss: 1.764 | Acc: 46.875% (30/64)
Loss: 1.716 | Acc: 50.480% (3263/6464)
Loss: 1.745 | Acc: 49.215% (6331/12864)
Loss: 1.739 | Acc: 49.590% (9553/19264)
Loss: 1.742 | Acc: 49.630% (12737/25664)
Loss: 1.742 | Acc: 49.697% (15935/32064)
Loss: 1.740 | Acc: 49.792% (19152/38464)
Loss: 1.742 | Acc: 49.724% (22308/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8749, Accuracy: 4471/10000 (44.71%)

Epoch: 179
Loss: 1.636 | Acc: 54.688% (35/64)
Loss: 1.737 | Acc: 49.907% (3226/6464)
Loss: 1.723 | Acc: 50.482% (6494/12864)
Loss: 1.726 | Acc: 50.197% (9670/19264)
Loss: 1.728 | Acc: 50.199% (12883/25664)
Loss: 1.726 | Acc: 50.427% (16169/32064)
Loss: 1.725 | Acc: 50.465% (19411/38464)
Loss: 1.730 | Acc: 50.272% (22554/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9205, Accuracy: 4222/10000 (42.22%)

Epoch: 180
Loss: 1.850 | Acc: 43.750% (28/64)
Loss: 1.708 | Acc: 50.866% (3288/6464)
Loss: 1.712 | Acc: 50.793% (6534/12864)
Loss: 1.711 | Acc: 50.955% (9816/19264)
Loss: 1.712 | Acc: 50.927% (13070/25664)
Loss: 1.720 | Acc: 50.611% (16228/32064)
Loss: 1.721 | Acc: 50.577% (19454/38464)
Loss: 1.722 | Acc: 50.528% (22669/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8677, Accuracy: 4575/10000 (45.75%)

Epoch: 181
Loss: 1.569 | Acc: 53.125% (34/64)
Loss: 1.693 | Acc: 51.640% (3338/6464)
Loss: 1.693 | Acc: 51.702% (6651/12864)
Loss: 1.692 | Acc: 51.682% (9956/19264)
Loss: 1.697 | Acc: 51.438% (13201/25664)
Loss: 1.702 | Acc: 51.254% (16434/32064)
Loss: 1.708 | Acc: 50.988% (19612/38464)
Loss: 1.711 | Acc: 50.845% (22811/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8918, Accuracy: 4368/10000 (43.68%)

Epoch: 182
Loss: 1.997 | Acc: 35.938% (23/64)
Loss: 1.700 | Acc: 50.882% (3289/6464)
Loss: 1.683 | Acc: 51.632% (6642/12864)
Loss: 1.683 | Acc: 51.687% (9957/19264)
Loss: 1.686 | Acc: 51.613% (13246/25664)
Loss: 1.691 | Acc: 51.413% (16485/32064)
Loss: 1.692 | Acc: 51.407% (19773/38464)
Loss: 1.696 | Acc: 51.257% (22996/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8835, Accuracy: 4500/10000 (45.00%)

Epoch: 183
Loss: 1.630 | Acc: 57.812% (37/64)
Loss: 1.667 | Acc: 52.785% (3412/6464)
Loss: 1.675 | Acc: 52.153% (6709/12864)
Loss: 1.681 | Acc: 51.973% (10012/19264)
Loss: 1.688 | Acc: 51.726% (13275/25664)
Loss: 1.692 | Acc: 51.491% (16510/32064)
Loss: 1.691 | Acc: 51.573% (19837/38464)
Loss: 1.690 | Acc: 51.647% (23171/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8999, Accuracy: 4498/10000 (44.98%)

Epoch: 184
Loss: 1.556 | Acc: 51.562% (33/64)
Loss: 1.653 | Acc: 53.311% (3446/6464)
Loss: 1.658 | Acc: 52.526% (6757/12864)
Loss: 1.662 | Acc: 52.336% (10082/19264)
Loss: 1.660 | Acc: 52.389% (13445/25664)
Loss: 1.662 | Acc: 52.439% (16814/32064)
Loss: 1.666 | Acc: 52.457% (20177/38464)
Loss: 1.670 | Acc: 52.334% (23479/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9173, Accuracy: 4408/10000 (44.08%)

Epoch: 185
Loss: 1.771 | Acc: 43.750% (28/64)
Loss: 1.626 | Acc: 53.728% (3473/6464)
Loss: 1.635 | Acc: 53.296% (6856/12864)
Loss: 1.639 | Acc: 53.364% (10280/19264)
Loss: 1.645 | Acc: 53.086% (13624/25664)
Loss: 1.648 | Acc: 53.022% (17001/32064)
Loss: 1.645 | Acc: 53.133% (20437/38464)
Loss: 1.649 | Acc: 53.027% (23790/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8842, Accuracy: 4515/10000 (45.15%)

Epoch: 186
Loss: 1.562 | Acc: 56.250% (36/64)
Loss: 1.612 | Acc: 53.929% (3486/6464)
Loss: 1.618 | Acc: 53.786% (6919/12864)
Loss: 1.625 | Acc: 53.556% (10317/19264)
Loss: 1.628 | Acc: 53.503% (13731/25664)
Loss: 1.627 | Acc: 53.509% (17157/32064)
Loss: 1.631 | Acc: 53.411% (20544/38464)
Loss: 1.632 | Acc: 53.384% (23950/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9009, Accuracy: 4474/10000 (44.74%)

Epoch: 187
Loss: 1.507 | Acc: 57.812% (37/64)
Loss: 1.623 | Acc: 53.295% (3445/6464)
Loss: 1.611 | Acc: 53.762% (6916/12864)
Loss: 1.606 | Acc: 53.950% (10393/19264)
Loss: 1.610 | Acc: 53.745% (13793/25664)
Loss: 1.609 | Acc: 53.833% (17261/32064)
Loss: 1.611 | Acc: 53.770% (20682/38464)
Loss: 1.610 | Acc: 53.845% (24157/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9562, Accuracy: 4235/10000 (42.35%)

Epoch: 188
Loss: 1.545 | Acc: 56.250% (36/64)
Loss: 1.570 | Acc: 54.595% (3529/6464)
Loss: 1.578 | Acc: 54.656% (7031/12864)
Loss: 1.578 | Acc: 54.656% (10529/19264)
Loss: 1.577 | Acc: 54.723% (14044/25664)
Loss: 1.580 | Acc: 54.606% (17509/32064)
Loss: 1.576 | Acc: 54.828% (21089/38464)
Loss: 1.581 | Acc: 54.634% (24511/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9161, Accuracy: 4513/10000 (45.13%)

Epoch: 189
Loss: 1.549 | Acc: 53.125% (34/64)
Loss: 1.542 | Acc: 55.461% (3585/6464)
Loss: 1.543 | Acc: 55.721% (7168/12864)
Loss: 1.540 | Acc: 55.918% (10772/19264)
Loss: 1.543 | Acc: 55.806% (14322/25664)
Loss: 1.547 | Acc: 55.695% (17858/32064)
Loss: 1.550 | Acc: 55.569% (21374/38464)
Loss: 1.554 | Acc: 55.376% (24844/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9728, Accuracy: 4430/10000 (44.30%)

Epoch: 190
Loss: 1.610 | Acc: 53.125% (34/64)
Loss: 1.494 | Acc: 57.116% (3692/6464)
Loss: 1.506 | Acc: 56.771% (7303/12864)
Loss: 1.506 | Acc: 56.691% (10921/19264)
Loss: 1.506 | Acc: 56.796% (14576/25664)
Loss: 1.508 | Acc: 56.740% (18193/32064)
Loss: 1.511 | Acc: 56.588% (21766/38464)
Loss: 1.511 | Acc: 56.616% (25400/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9707, Accuracy: 4354/10000 (43.54%)

Epoch: 191
Loss: 1.717 | Acc: 48.438% (31/64)
Loss: 1.458 | Acc: 58.199% (3762/6464)
Loss: 1.456 | Acc: 58.053% (7468/12864)
Loss: 1.467 | Acc: 57.724% (11120/19264)
Loss: 1.472 | Acc: 57.396% (14730/25664)
Loss: 1.470 | Acc: 57.448% (18420/32064)
Loss: 1.471 | Acc: 57.498% (22116/38464)
Loss: 1.473 | Acc: 57.440% (25770/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0208, Accuracy: 4321/10000 (43.21%)

Epoch: 192
Loss: 1.509 | Acc: 53.125% (34/64)
Loss: 1.443 | Acc: 58.029% (3751/6464)
Loss: 1.428 | Acc: 58.512% (7527/12864)
Loss: 1.419 | Acc: 58.965% (11359/19264)
Loss: 1.423 | Acc: 58.896% (15115/25664)
Loss: 1.432 | Acc: 58.611% (18793/32064)
Loss: 1.431 | Acc: 58.774% (22607/38464)
Loss: 1.429 | Acc: 58.789% (26375/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0343, Accuracy: 4411/10000 (44.11%)

Epoch: 193
Loss: 1.083 | Acc: 70.312% (45/64)
Loss: 1.341 | Acc: 60.814% (3931/6464)
Loss: 1.359 | Acc: 60.627% (7799/12864)
Loss: 1.355 | Acc: 60.709% (11695/19264)
Loss: 1.364 | Acc: 60.489% (15524/25664)
Loss: 1.364 | Acc: 60.435% (19378/32064)
Loss: 1.366 | Acc: 60.355% (23215/38464)
Loss: 1.367 | Acc: 60.327% (27065/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0809, Accuracy: 4322/10000 (43.22%)

Epoch: 194
Loss: 1.149 | Acc: 70.312% (45/64)
Loss: 1.300 | Acc: 62.608% (4047/6464)
Loss: 1.293 | Acc: 62.469% (8036/12864)
Loss: 1.296 | Acc: 62.324% (12006/19264)
Loss: 1.305 | Acc: 62.071% (15930/25664)
Loss: 1.308 | Acc: 61.936% (19859/32064)
Loss: 1.311 | Acc: 61.785% (23765/38464)
Loss: 1.311 | Acc: 61.771% (27713/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1121, Accuracy: 4281/10000 (42.81%)

Epoch: 195
Loss: 1.200 | Acc: 62.500% (40/64)
Loss: 1.260 | Acc: 63.119% (4080/6464)
Loss: 1.281 | Acc: 62.586% (8051/12864)
Loss: 1.295 | Acc: 61.996% (11943/19264)
Loss: 1.306 | Acc: 61.682% (15830/25664)
Loss: 1.317 | Acc: 61.458% (19706/32064)
Loss: 1.328 | Acc: 61.031% (23475/38464)
Loss: 1.339 | Acc: 60.728% (27245/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0122, Accuracy: 4360/10000 (43.60%)

Epoch: 196
Loss: 1.428 | Acc: 59.375% (38/64)
Loss: 1.387 | Acc: 59.762% (3863/6464)
Loss: 1.376 | Acc: 60.090% (7730/12864)
Loss: 1.399 | Acc: 59.178% (11400/19264)
Loss: 1.396 | Acc: 59.437% (15254/25664)
Loss: 1.400 | Acc: 59.387% (19042/32064)
Loss: 1.408 | Acc: 59.144% (22749/38464)
Loss: 1.412 | Acc: 59.092% (26511/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9924, Accuracy: 4408/10000 (44.08%)

Epoch: 197
Loss: 1.426 | Acc: 60.938% (39/64)
Loss: 1.425 | Acc: 58.787% (3800/6464)
Loss: 1.431 | Acc: 58.528% (7529/12864)
Loss: 1.426 | Acc: 58.752% (11318/19264)
Loss: 1.430 | Acc: 58.572% (15032/25664)
Loss: 1.431 | Acc: 58.499% (18757/32064)
Loss: 1.430 | Acc: 58.512% (22506/38464)
Loss: 1.434 | Acc: 58.381% (26192/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9950, Accuracy: 4408/10000 (44.08%)
torch.Size([100, 10])
Test set: Average loss: 1.9950, Accuracy: 4408/10000 (44.08%)

Epoch: 198
Loss: 1.195 | Acc: 68.750% (44/64)
Loss: 1.411 | Acc: 59.298% (3833/6464)
Loss: 1.423 | Acc: 58.940% (7582/12864)
Loss: 1.424 | Acc: 58.965% (11359/19264)
Loss: 1.425 | Acc: 58.806% (15092/25664)
Loss: 1.434 | Acc: 58.427% (18734/32064)
Loss: 1.432 | Acc: 58.530% (22513/38464)
Loss: 1.433 | Acc: 58.475% (26234/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9884, Accuracy: 4415/10000 (44.15%)
torch.Size([100, 10])
Test set: Average loss: 1.9884, Accuracy: 4415/10000 (44.15%)

Epoch: 199
Loss: 1.530 | Acc: 54.688% (35/64)
Loss: 1.444 | Acc: 58.509% (3782/6464)
Loss: 1.434 | Acc: 58.955% (7584/12864)
Loss: 1.436 | Acc: 58.726% (11313/19264)
Loss: 1.432 | Acc: 58.716% (15069/25664)
Loss: 1.434 | Acc: 58.555% (18775/32064)
Loss: 1.434 | Acc: 58.540% (22517/38464)
Loss: 1.435 | Acc: 58.546% (26266/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9914, Accuracy: 4407/10000 (44.07%)
torch.Size([100, 10])
Test set: Average loss: 1.9914, Accuracy: 4407/10000 (44.07%)
4820
10000
-1.839516043663025
