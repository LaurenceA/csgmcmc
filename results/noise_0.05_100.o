==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.355 | Acc: 15.625% (10/64)
Loss: 2.955 | Acc: 16.166% (1045/6464)
Loss: 2.509 | Acc: 19.434% (2500/12864)
Loss: 2.327 | Acc: 22.020% (4242/19264)
Loss: 2.219 | Acc: 23.967% (6151/25664)
Loss: 2.142 | Acc: 25.686% (8236/32064)
Loss: 2.084 | Acc: 27.004% (10387/38464)
Loss: 2.034 | Acc: 28.390% (12737/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9482, Accuracy: 3408/10000 (34.08%)

Epoch: 1
Loss: 1.901 | Acc: 29.688% (19/64)
Loss: 1.672 | Acc: 39.202% (2534/6464)
Loss: 1.657 | Acc: 40.089% (5157/12864)
Loss: 1.642 | Acc: 40.635% (7828/19264)
Loss: 1.631 | Acc: 41.135% (10557/25664)
Loss: 1.616 | Acc: 41.723% (13378/32064)
Loss: 1.601 | Acc: 42.263% (16256/38464)
Loss: 1.589 | Acc: 42.963% (19275/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8411, Accuracy: 3794/10000 (37.94%)

Epoch: 2
Loss: 1.429 | Acc: 53.125% (34/64)
Loss: 1.444 | Acc: 49.350% (3190/6464)
Loss: 1.445 | Acc: 49.425% (6358/12864)
Loss: 1.427 | Acc: 50.249% (9680/19264)
Loss: 1.404 | Acc: 51.114% (13118/25664)
Loss: 1.388 | Acc: 51.915% (16646/32064)
Loss: 1.378 | Acc: 52.449% (20174/38464)
Loss: 1.370 | Acc: 52.842% (23707/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5402, Accuracy: 4870/10000 (48.70%)

Epoch: 3
Loss: 1.200 | Acc: 59.375% (38/64)
Loss: 1.269 | Acc: 57.580% (3722/6464)
Loss: 1.265 | Acc: 57.797% (7435/12864)
Loss: 1.244 | Acc: 58.352% (11241/19264)
Loss: 1.229 | Acc: 58.868% (15108/25664)
Loss: 1.219 | Acc: 59.228% (18991/32064)
Loss: 1.210 | Acc: 59.614% (22930/38464)
Loss: 1.202 | Acc: 60.015% (26925/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0555, Accuracy: 3821/10000 (38.21%)

Epoch: 4
Loss: 1.322 | Acc: 57.812% (37/64)
Loss: 1.127 | Acc: 62.732% (4055/6464)
Loss: 1.121 | Acc: 63.332% (8147/12864)
Loss: 1.115 | Acc: 63.549% (12242/19264)
Loss: 1.111 | Acc: 63.798% (16373/25664)
Loss: 1.105 | Acc: 64.215% (20590/32064)
Loss: 1.095 | Acc: 64.549% (24828/38464)
Loss: 1.088 | Acc: 64.883% (29109/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2007, Accuracy: 6112/10000 (61.12%)

Epoch: 5
Loss: 1.386 | Acc: 54.688% (35/64)
Loss: 0.999 | Acc: 67.543% (4366/6464)
Loss: 1.010 | Acc: 67.794% (8721/12864)
Loss: 1.007 | Acc: 68.096% (13118/19264)
Loss: 1.003 | Acc: 68.173% (17496/25664)
Loss: 0.994 | Acc: 68.451% (21948/32064)
Loss: 0.990 | Acc: 68.568% (26374/38464)
Loss: 0.985 | Acc: 68.857% (30892/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8428, Accuracy: 4711/10000 (47.11%)

Epoch: 6
Loss: 0.976 | Acc: 75.000% (48/64)
Loss: 0.925 | Acc: 71.627% (4630/6464)
Loss: 0.926 | Acc: 71.564% (9206/12864)
Loss: 0.917 | Acc: 71.828% (13837/19264)
Loss: 0.915 | Acc: 71.961% (18468/25664)
Loss: 0.906 | Acc: 72.184% (23145/32064)
Loss: 0.905 | Acc: 72.247% (27789/38464)
Loss: 0.903 | Acc: 72.361% (32464/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7869, Accuracy: 4366/10000 (43.66%)

Epoch: 7
Loss: 1.143 | Acc: 60.938% (39/64)
Loss: 0.859 | Acc: 73.933% (4779/6464)
Loss: 0.863 | Acc: 74.044% (9525/12864)
Loss: 0.864 | Acc: 74.159% (14286/19264)
Loss: 0.860 | Acc: 74.392% (19092/25664)
Loss: 0.854 | Acc: 74.570% (23910/32064)
Loss: 0.854 | Acc: 74.475% (28646/38464)
Loss: 0.848 | Acc: 74.568% (33454/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3082, Accuracy: 6112/10000 (61.12%)

Epoch: 8
Loss: 1.074 | Acc: 70.312% (45/64)
Loss: 0.826 | Acc: 75.526% (4882/6464)
Loss: 0.816 | Acc: 75.653% (9732/12864)
Loss: 0.810 | Acc: 75.929% (14627/19264)
Loss: 0.809 | Acc: 75.916% (19483/25664)
Loss: 0.808 | Acc: 75.986% (24364/32064)
Loss: 0.810 | Acc: 75.827% (29166/38464)
Loss: 0.806 | Acc: 75.954% (34076/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5222, Accuracy: 5399/10000 (53.99%)

Epoch: 9
Loss: 1.047 | Acc: 67.188% (43/64)
Loss: 0.780 | Acc: 77.228% (4992/6464)
Loss: 0.785 | Acc: 76.990% (9904/12864)
Loss: 0.787 | Acc: 76.796% (14794/19264)
Loss: 0.783 | Acc: 76.855% (19724/25664)
Loss: 0.784 | Acc: 76.943% (24671/32064)
Loss: 0.781 | Acc: 76.950% (29598/38464)
Loss: 0.775 | Acc: 77.113% (34596/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1185, Accuracy: 6443/10000 (64.43%)

Epoch: 10
Loss: 0.793 | Acc: 76.562% (49/64)
Loss: 0.760 | Acc: 77.676% (5021/6464)
Loss: 0.741 | Acc: 78.475% (10095/12864)
Loss: 0.749 | Acc: 78.218% (15068/19264)
Loss: 0.745 | Acc: 78.109% (20046/25664)
Loss: 0.749 | Acc: 78.100% (25042/32064)
Loss: 0.750 | Acc: 78.130% (30052/38464)
Loss: 0.751 | Acc: 78.109% (35043/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3032, Accuracy: 6200/10000 (62.00%)

Epoch: 11
Loss: 1.063 | Acc: 64.062% (41/64)
Loss: 0.733 | Acc: 78.001% (5042/6464)
Loss: 0.739 | Acc: 78.350% (10079/12864)
Loss: 0.733 | Acc: 78.696% (15160/19264)
Loss: 0.735 | Acc: 78.651% (20185/25664)
Loss: 0.733 | Acc: 78.661% (25222/32064)
Loss: 0.732 | Acc: 78.713% (30276/38464)
Loss: 0.734 | Acc: 78.754% (35332/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0704, Accuracy: 6831/10000 (68.31%)

Epoch: 12
Loss: 0.700 | Acc: 84.375% (54/64)
Loss: 0.698 | Acc: 80.183% (5183/6464)
Loss: 0.702 | Acc: 80.053% (10298/12864)
Loss: 0.702 | Acc: 79.989% (15409/19264)
Loss: 0.706 | Acc: 79.960% (20521/25664)
Loss: 0.708 | Acc: 79.881% (25613/32064)
Loss: 0.708 | Acc: 79.872% (30722/38464)
Loss: 0.712 | Acc: 79.743% (35776/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4994, Accuracy: 5464/10000 (54.64%)

Epoch: 13
Loss: 0.766 | Acc: 73.438% (47/64)
Loss: 0.690 | Acc: 80.755% (5220/6464)
Loss: 0.692 | Acc: 80.519% (10358/12864)
Loss: 0.691 | Acc: 80.456% (15499/19264)
Loss: 0.695 | Acc: 80.338% (20618/25664)
Loss: 0.690 | Acc: 80.614% (25848/32064)
Loss: 0.693 | Acc: 80.499% (30963/38464)
Loss: 0.694 | Acc: 80.465% (36100/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1204, Accuracy: 6735/10000 (67.35%)

Epoch: 14
Loss: 0.907 | Acc: 70.312% (45/64)
Loss: 0.706 | Acc: 80.105% (5178/6464)
Loss: 0.698 | Acc: 80.356% (10337/12864)
Loss: 0.687 | Acc: 80.554% (15518/19264)
Loss: 0.682 | Acc: 80.650% (20698/25664)
Loss: 0.679 | Acc: 80.667% (25865/32064)
Loss: 0.675 | Acc: 80.821% (31087/38464)
Loss: 0.678 | Acc: 80.798% (36249/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3437, Accuracy: 4308/10000 (43.08%)

Epoch: 15
Loss: 0.995 | Acc: 65.625% (42/64)
Loss: 0.664 | Acc: 81.637% (5277/6464)
Loss: 0.660 | Acc: 81.359% (10466/12864)
Loss: 0.669 | Acc: 81.042% (15612/19264)
Loss: 0.664 | Acc: 81.215% (20843/25664)
Loss: 0.666 | Acc: 81.197% (26035/32064)
Loss: 0.664 | Acc: 81.289% (31267/38464)
Loss: 0.662 | Acc: 81.286% (36468/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7947, Accuracy: 7747/10000 (77.47%)

Epoch: 16
Loss: 0.824 | Acc: 78.125% (50/64)
Loss: 0.614 | Acc: 83.385% (5390/6464)
Loss: 0.621 | Acc: 82.945% (10670/12864)
Loss: 0.630 | Acc: 82.605% (15913/19264)
Loss: 0.639 | Acc: 82.251% (21109/25664)
Loss: 0.640 | Acc: 82.282% (26383/32064)
Loss: 0.642 | Acc: 82.241% (31633/38464)
Loss: 0.643 | Acc: 82.260% (36905/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0187, Accuracy: 7046/10000 (70.46%)

Epoch: 17
Loss: 0.495 | Acc: 87.500% (56/64)
Loss: 0.600 | Acc: 83.091% (5371/6464)
Loss: 0.628 | Acc: 82.587% (10624/12864)
Loss: 0.635 | Acc: 82.402% (15874/19264)
Loss: 0.635 | Acc: 82.368% (21139/25664)
Loss: 0.633 | Acc: 82.423% (26428/32064)
Loss: 0.633 | Acc: 82.371% (31683/38464)
Loss: 0.632 | Acc: 82.389% (36963/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8819, Accuracy: 7488/10000 (74.88%)

Epoch: 18
Loss: 0.649 | Acc: 82.812% (53/64)
Loss: 0.605 | Acc: 83.137% (5374/6464)
Loss: 0.605 | Acc: 83.232% (10707/12864)
Loss: 0.609 | Acc: 83.129% (16014/19264)
Loss: 0.615 | Acc: 83.015% (21305/25664)
Loss: 0.619 | Acc: 82.909% (26584/32064)
Loss: 0.621 | Acc: 82.922% (31895/38464)
Loss: 0.619 | Acc: 82.944% (37212/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7776, Accuracy: 7802/10000 (78.02%)

Epoch: 19
Loss: 0.639 | Acc: 85.938% (55/64)
Loss: 0.595 | Acc: 83.540% (5400/6464)
Loss: 0.589 | Acc: 83.815% (10782/12864)
Loss: 0.584 | Acc: 84.079% (16197/19264)
Loss: 0.587 | Acc: 84.013% (21561/25664)
Loss: 0.595 | Acc: 83.907% (26904/32064)
Loss: 0.600 | Acc: 83.824% (32242/38464)
Loss: 0.600 | Acc: 83.735% (37567/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4315, Accuracy: 5897/10000 (58.97%)

Epoch: 20
Loss: 0.596 | Acc: 85.938% (55/64)
Loss: 0.591 | Acc: 84.143% (5439/6464)
Loss: 0.594 | Acc: 83.901% (10793/12864)
Loss: 0.592 | Acc: 83.830% (16149/19264)
Loss: 0.590 | Acc: 83.900% (21532/25664)
Loss: 0.587 | Acc: 84.054% (26951/32064)
Loss: 0.589 | Acc: 84.042% (32326/38464)
Loss: 0.591 | Acc: 83.972% (37673/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4302, Accuracy: 6072/10000 (60.72%)

Epoch: 21
Loss: 0.521 | Acc: 85.938% (55/64)
Loss: 0.591 | Acc: 83.632% (5406/6464)
Loss: 0.587 | Acc: 83.784% (10778/12864)
Loss: 0.581 | Acc: 83.986% (16179/19264)
Loss: 0.582 | Acc: 83.950% (21545/25664)
Loss: 0.582 | Acc: 84.001% (26934/32064)
Loss: 0.580 | Acc: 84.125% (32358/38464)
Loss: 0.579 | Acc: 84.179% (37766/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9261, Accuracy: 7346/10000 (73.46%)

Epoch: 22
Loss: 0.575 | Acc: 82.812% (53/64)
Loss: 0.548 | Acc: 85.520% (5528/6464)
Loss: 0.565 | Acc: 85.168% (10956/12864)
Loss: 0.561 | Acc: 85.071% (16388/19264)
Loss: 0.566 | Acc: 84.909% (21791/25664)
Loss: 0.564 | Acc: 84.908% (27225/32064)
Loss: 0.564 | Acc: 84.916% (32662/38464)
Loss: 0.563 | Acc: 84.943% (38109/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2011, Accuracy: 6680/10000 (66.80%)

Epoch: 23
Loss: 0.470 | Acc: 90.625% (58/64)
Loss: 0.517 | Acc: 86.448% (5588/6464)
Loss: 0.536 | Acc: 85.697% (11024/12864)
Loss: 0.542 | Acc: 85.408% (16453/19264)
Loss: 0.544 | Acc: 85.380% (21912/25664)
Loss: 0.549 | Acc: 85.239% (27331/32064)
Loss: 0.548 | Acc: 85.301% (32810/38464)
Loss: 0.548 | Acc: 85.291% (38265/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9665, Accuracy: 7124/10000 (71.24%)

Epoch: 24
Loss: 0.762 | Acc: 76.562% (49/64)
Loss: 0.522 | Acc: 85.999% (5559/6464)
Loss: 0.533 | Acc: 85.813% (11039/12864)
Loss: 0.534 | Acc: 85.912% (16550/19264)
Loss: 0.540 | Acc: 85.797% (22019/25664)
Loss: 0.538 | Acc: 85.725% (27487/32064)
Loss: 0.539 | Acc: 85.696% (32962/38464)
Loss: 0.541 | Acc: 85.663% (38432/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1446, Accuracy: 6864/10000 (68.64%)

Epoch: 25
Loss: 0.576 | Acc: 84.375% (54/64)
Loss: 0.514 | Acc: 86.649% (5601/6464)
Loss: 0.530 | Acc: 86.000% (11063/12864)
Loss: 0.526 | Acc: 86.171% (16600/19264)
Loss: 0.526 | Acc: 86.210% (22125/25664)
Loss: 0.521 | Acc: 86.368% (27693/32064)
Loss: 0.523 | Acc: 86.307% (33197/38464)
Loss: 0.526 | Acc: 86.214% (38679/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8518, Accuracy: 7679/10000 (76.79%)

Epoch: 26
Loss: 0.512 | Acc: 84.375% (54/64)
Loss: 0.520 | Acc: 86.046% (5562/6464)
Loss: 0.513 | Acc: 86.567% (11136/12864)
Loss: 0.507 | Acc: 86.851% (16731/19264)
Loss: 0.515 | Acc: 86.627% (22232/25664)
Loss: 0.516 | Acc: 86.574% (27759/32064)
Loss: 0.513 | Acc: 86.652% (33330/38464)
Loss: 0.510 | Acc: 86.733% (38912/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7355, Accuracy: 7948/10000 (79.48%)

Epoch: 27
Loss: 0.544 | Acc: 79.688% (51/64)
Loss: 0.509 | Acc: 86.649% (5601/6464)
Loss: 0.497 | Acc: 86.987% (11190/12864)
Loss: 0.498 | Acc: 86.851% (16731/19264)
Loss: 0.498 | Acc: 86.744% (22262/25664)
Loss: 0.497 | Acc: 86.901% (27864/32064)
Loss: 0.499 | Acc: 86.949% (33444/38464)
Loss: 0.501 | Acc: 86.945% (39007/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1205, Accuracy: 6756/10000 (67.56%)

Epoch: 28
Loss: 0.723 | Acc: 73.438% (47/64)
Loss: 0.472 | Acc: 87.330% (5645/6464)
Loss: 0.481 | Acc: 87.306% (11231/12864)
Loss: 0.479 | Acc: 87.474% (16851/19264)
Loss: 0.484 | Acc: 87.325% (22411/25664)
Loss: 0.484 | Acc: 87.353% (28009/32064)
Loss: 0.487 | Acc: 87.313% (33584/38464)
Loss: 0.486 | Acc: 87.420% (39220/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1148, Accuracy: 6987/10000 (69.87%)

Epoch: 29
Loss: 0.328 | Acc: 93.750% (60/64)
Loss: 0.460 | Acc: 88.258% (5705/6464)
Loss: 0.468 | Acc: 88.052% (11327/12864)
Loss: 0.460 | Acc: 88.279% (17006/19264)
Loss: 0.462 | Acc: 88.225% (22642/25664)
Loss: 0.463 | Acc: 88.186% (28276/32064)
Loss: 0.466 | Acc: 88.064% (33873/38464)
Loss: 0.466 | Acc: 88.095% (39523/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7332, Accuracy: 7951/10000 (79.51%)

Epoch: 30
Loss: 0.450 | Acc: 87.500% (56/64)
Loss: 0.437 | Acc: 89.124% (5761/6464)
Loss: 0.438 | Acc: 89.062% (11457/12864)
Loss: 0.441 | Acc: 88.917% (17129/19264)
Loss: 0.445 | Acc: 88.751% (22777/25664)
Loss: 0.452 | Acc: 88.632% (28419/32064)
Loss: 0.453 | Acc: 88.615% (34085/38464)
Loss: 0.453 | Acc: 88.643% (39769/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8522, Accuracy: 7692/10000 (76.92%)

Epoch: 31
Loss: 0.402 | Acc: 92.188% (59/64)
Loss: 0.428 | Acc: 89.496% (5785/6464)
Loss: 0.436 | Acc: 89.241% (11480/12864)
Loss: 0.438 | Acc: 89.182% (17180/19264)
Loss: 0.438 | Acc: 89.094% (22865/25664)
Loss: 0.440 | Acc: 89.059% (28556/32064)
Loss: 0.435 | Acc: 89.205% (34312/38464)
Loss: 0.436 | Acc: 89.105% (39976/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7173, Accuracy: 8064/10000 (80.64%)

Epoch: 32
Loss: 0.587 | Acc: 85.938% (55/64)
Loss: 0.402 | Acc: 89.975% (5816/6464)
Loss: 0.419 | Acc: 89.661% (11534/12864)
Loss: 0.413 | Acc: 89.836% (17306/19264)
Loss: 0.409 | Acc: 89.904% (23073/25664)
Loss: 0.407 | Acc: 89.973% (28849/32064)
Loss: 0.412 | Acc: 89.871% (34568/38464)
Loss: 0.413 | Acc: 89.892% (40329/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8682, Accuracy: 7697/10000 (76.97%)

Epoch: 33
Loss: 0.405 | Acc: 90.625% (58/64)
Loss: 0.375 | Acc: 90.501% (5850/6464)
Loss: 0.400 | Acc: 90.213% (11605/12864)
Loss: 0.404 | Acc: 90.153% (17367/19264)
Loss: 0.404 | Acc: 90.107% (23125/25664)
Loss: 0.396 | Acc: 90.338% (28966/32064)
Loss: 0.398 | Acc: 90.253% (34715/38464)
Loss: 0.399 | Acc: 90.190% (40463/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6354, Accuracy: 8386/10000 (83.86%)

Epoch: 34
Loss: 0.459 | Acc: 92.188% (59/64)
Loss: 0.386 | Acc: 90.486% (5849/6464)
Loss: 0.379 | Acc: 90.679% (11665/12864)
Loss: 0.374 | Acc: 90.848% (17501/19264)
Loss: 0.376 | Acc: 90.835% (23312/25664)
Loss: 0.380 | Acc: 90.762% (29102/32064)
Loss: 0.381 | Acc: 90.799% (34925/38464)
Loss: 0.383 | Acc: 90.785% (40730/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5608, Accuracy: 8639/10000 (86.39%)

Epoch: 35
Loss: 0.344 | Acc: 90.625% (58/64)
Loss: 0.332 | Acc: 91.723% (5929/6464)
Loss: 0.350 | Acc: 91.511% (11772/12864)
Loss: 0.354 | Acc: 91.456% (17618/19264)
Loss: 0.352 | Acc: 91.603% (23509/25664)
Loss: 0.352 | Acc: 91.614% (29375/32064)
Loss: 0.357 | Acc: 91.478% (35186/38464)
Loss: 0.361 | Acc: 91.365% (40990/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6090, Accuracy: 8472/10000 (84.72%)

Epoch: 36
Loss: 0.195 | Acc: 95.312% (61/64)
Loss: 0.337 | Acc: 91.832% (5936/6464)
Loss: 0.337 | Acc: 91.931% (11826/12864)
Loss: 0.338 | Acc: 91.980% (17719/19264)
Loss: 0.339 | Acc: 91.849% (23572/25664)
Loss: 0.341 | Acc: 91.922% (29474/32064)
Loss: 0.340 | Acc: 91.987% (35382/38464)
Loss: 0.340 | Acc: 91.974% (41263/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6408, Accuracy: 8383/10000 (83.83%)

Epoch: 37
Loss: 0.388 | Acc: 92.188% (59/64)
Loss: 0.309 | Acc: 92.976% (6010/6464)
Loss: 0.311 | Acc: 92.755% (11932/12864)
Loss: 0.313 | Acc: 92.629% (17844/19264)
Loss: 0.307 | Acc: 92.776% (23810/25664)
Loss: 0.316 | Acc: 92.574% (29683/32064)
Loss: 0.321 | Acc: 92.401% (35541/38464)
Loss: 0.324 | Acc: 92.317% (41417/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6104, Accuracy: 8516/10000 (85.16%)

Epoch: 38
Loss: 0.461 | Acc: 87.500% (56/64)
Loss: 0.288 | Acc: 93.255% (6028/6464)
Loss: 0.291 | Acc: 93.268% (11998/12864)
Loss: 0.293 | Acc: 93.117% (17938/19264)
Loss: 0.291 | Acc: 93.212% (23922/25664)
Loss: 0.295 | Acc: 93.142% (29865/32064)
Loss: 0.296 | Acc: 93.043% (35788/38464)
Loss: 0.296 | Acc: 93.026% (41735/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6085, Accuracy: 8570/10000 (85.70%)

Epoch: 39
Loss: 0.174 | Acc: 96.875% (62/64)
Loss: 0.274 | Acc: 93.209% (6025/6464)
Loss: 0.267 | Acc: 93.493% (12027/12864)
Loss: 0.265 | Acc: 93.672% (18045/19264)
Loss: 0.269 | Acc: 93.598% (24021/25664)
Loss: 0.269 | Acc: 93.619% (30018/32064)
Loss: 0.268 | Acc: 93.667% (36028/38464)
Loss: 0.271 | Acc: 93.607% (41996/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5965, Accuracy: 8615/10000 (86.15%)

Epoch: 40
Loss: 0.134 | Acc: 98.438% (63/64)
Loss: 0.240 | Acc: 94.307% (6096/6464)
Loss: 0.242 | Acc: 94.084% (12103/12864)
Loss: 0.247 | Acc: 94.067% (18121/19264)
Loss: 0.250 | Acc: 94.003% (24125/25664)
Loss: 0.248 | Acc: 94.081% (30166/32064)
Loss: 0.248 | Acc: 94.052% (36176/38464)
Loss: 0.249 | Acc: 94.040% (42190/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5859, Accuracy: 8718/10000 (87.18%)

Epoch: 41
Loss: 0.295 | Acc: 92.188% (59/64)
Loss: 0.220 | Acc: 94.663% (6119/6464)
Loss: 0.224 | Acc: 94.729% (12186/12864)
Loss: 0.220 | Acc: 94.799% (18262/19264)
Loss: 0.222 | Acc: 94.720% (24309/25664)
Loss: 0.221 | Acc: 94.707% (30367/32064)
Loss: 0.220 | Acc: 94.743% (36442/38464)
Loss: 0.221 | Acc: 94.744% (42506/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6444, Accuracy: 8541/10000 (85.41%)

Epoch: 42
Loss: 0.172 | Acc: 95.312% (61/64)
Loss: 0.197 | Acc: 95.266% (6158/6464)
Loss: 0.198 | Acc: 95.204% (12247/12864)
Loss: 0.202 | Acc: 95.105% (18321/19264)
Loss: 0.202 | Acc: 95.079% (24401/25664)
Loss: 0.199 | Acc: 95.144% (30507/32064)
Loss: 0.200 | Acc: 95.216% (36624/38464)
Loss: 0.199 | Acc: 95.239% (42728/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5901, Accuracy: 8762/10000 (87.62%)

Epoch: 43
Loss: 0.180 | Acc: 95.312% (61/64)
Loss: 0.160 | Acc: 96.040% (6208/6464)
Loss: 0.168 | Acc: 95.903% (12337/12864)
Loss: 0.170 | Acc: 95.858% (18466/19264)
Loss: 0.171 | Acc: 95.889% (24609/25664)
Loss: 0.171 | Acc: 95.911% (30753/32064)
Loss: 0.172 | Acc: 95.882% (36880/38464)
Loss: 0.170 | Acc: 95.919% (43033/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6310, Accuracy: 8680/10000 (86.80%)

Epoch: 44
Loss: 0.264 | Acc: 92.188% (59/64)
Loss: 0.143 | Acc: 96.504% (6238/6464)
Loss: 0.152 | Acc: 96.230% (12379/12864)
Loss: 0.149 | Acc: 96.325% (18556/19264)
Loss: 0.151 | Acc: 96.314% (24718/25664)
Loss: 0.152 | Acc: 96.273% (30869/32064)
Loss: 0.152 | Acc: 96.303% (37042/38464)
Loss: 0.151 | Acc: 96.360% (43231/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6010, Accuracy: 8774/10000 (87.74%)

Epoch: 45
Loss: 0.116 | Acc: 98.438% (63/64)
Loss: 0.125 | Acc: 96.952% (6267/6464)
Loss: 0.133 | Acc: 96.844% (12458/12864)
Loss: 0.130 | Acc: 96.854% (18658/19264)
Loss: 0.131 | Acc: 96.820% (24848/25664)
Loss: 0.131 | Acc: 96.819% (31044/32064)
Loss: 0.131 | Acc: 96.784% (37227/38464)
Loss: 0.132 | Acc: 96.795% (43426/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5982, Accuracy: 8739/10000 (87.39%)

Epoch: 46
Loss: 0.111 | Acc: 96.875% (62/64)
Loss: 0.126 | Acc: 96.767% (6255/6464)
Loss: 0.124 | Acc: 96.953% (12472/12864)
Loss: 0.123 | Acc: 96.937% (18674/19264)
Loss: 0.121 | Acc: 96.969% (24886/25664)
Loss: 0.122 | Acc: 96.972% (31093/32064)
Loss: 0.121 | Acc: 97.008% (37313/38464)
Loss: 0.120 | Acc: 97.047% (43539/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6043, Accuracy: 8743/10000 (87.43%)

Epoch: 47
Loss: 0.022 | Acc: 100.000% (64/64)
Loss: 0.113 | Acc: 97.184% (6282/6464)
Loss: 0.113 | Acc: 97.163% (12499/12864)
Loss: 0.113 | Acc: 97.207% (18726/19264)
Loss: 0.111 | Acc: 97.265% (24962/25664)
Loss: 0.114 | Acc: 97.193% (31164/32064)
Loss: 0.114 | Acc: 97.192% (37384/38464)
Loss: 0.114 | Acc: 97.207% (43611/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6016, Accuracy: 8768/10000 (87.68%)
torch.Size([100, 10])
Test set: Average loss: 0.6016, Accuracy: 8768/10000 (87.68%)

Epoch: 48
Loss: 0.051 | Acc: 98.438% (63/64)
Loss: 0.107 | Acc: 97.540% (6305/6464)
Loss: 0.108 | Acc: 97.365% (12525/12864)
Loss: 0.109 | Acc: 97.316% (18747/19264)
Loss: 0.109 | Acc: 97.343% (24982/25664)
Loss: 0.110 | Acc: 97.293% (31196/32064)
Loss: 0.110 | Acc: 97.257% (37409/38464)
Loss: 0.109 | Acc: 97.278% (43643/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6039, Accuracy: 8751/10000 (87.51%)
torch.Size([100, 10])
Test set: Average loss: 0.6039, Accuracy: 8751/10000 (87.51%)

Epoch: 49
Loss: 0.136 | Acc: 95.312% (61/64)
Loss: 0.110 | Acc: 97.153% (6280/6464)
Loss: 0.110 | Acc: 97.155% (12498/12864)
Loss: 0.108 | Acc: 97.254% (18735/19264)
Loss: 0.106 | Acc: 97.300% (24971/25664)
Loss: 0.106 | Acc: 97.333% (31209/32064)
Loss: 0.108 | Acc: 97.296% (37424/38464)
Loss: 0.109 | Acc: 97.265% (43637/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6007, Accuracy: 8770/10000 (87.70%)
torch.Size([100, 10])
Test set: Average loss: 0.6007, Accuracy: 8770/10000 (87.70%)

Epoch: 50
Loss: 0.031 | Acc: 100.000% (64/64)
Loss: 1.885 | Acc: 31.699% (2049/6464)
Loss: 1.494 | Acc: 48.228% (6204/12864)
Loss: 1.278 | Acc: 57.003% (10981/19264)
Loss: 1.164 | Acc: 61.795% (15859/25664)
Loss: 1.086 | Acc: 64.958% (20828/32064)
Loss: 1.031 | Acc: 67.123% (25818/38464)
Loss: 0.988 | Acc: 68.841% (30885/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1864, Accuracy: 6548/10000 (65.48%)

Epoch: 51
Loss: 0.606 | Acc: 87.500% (56/64)
Loss: 0.679 | Acc: 80.894% (5229/6464)
Loss: 0.685 | Acc: 80.620% (10371/12864)
Loss: 0.691 | Acc: 80.560% (15519/19264)
Loss: 0.690 | Acc: 80.556% (20674/25664)
Loss: 0.686 | Acc: 80.667% (25865/32064)
Loss: 0.681 | Acc: 80.782% (31072/38464)
Loss: 0.680 | Acc: 80.771% (36237/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4550, Accuracy: 5818/10000 (58.18%)

Epoch: 52
Loss: 0.792 | Acc: 71.875% (46/64)
Loss: 0.646 | Acc: 81.637% (5277/6464)
Loss: 0.640 | Acc: 81.817% (10525/12864)
Loss: 0.638 | Acc: 81.972% (15791/19264)
Loss: 0.641 | Acc: 81.909% (21021/25664)
Loss: 0.640 | Acc: 82.027% (26301/32064)
Loss: 0.641 | Acc: 81.968% (31528/38464)
Loss: 0.643 | Acc: 81.977% (36778/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1929, Accuracy: 6444/10000 (64.44%)

Epoch: 53
Loss: 0.821 | Acc: 75.000% (48/64)
Loss: 0.599 | Acc: 83.663% (5408/6464)
Loss: 0.615 | Acc: 83.015% (10679/12864)
Loss: 0.621 | Acc: 82.885% (15967/19264)
Loss: 0.622 | Acc: 82.922% (21281/25664)
Loss: 0.627 | Acc: 82.759% (26536/32064)
Loss: 0.626 | Acc: 82.737% (31824/38464)
Loss: 0.626 | Acc: 82.701% (37103/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3612, Accuracy: 6162/10000 (61.62%)

Epoch: 54
Loss: 0.747 | Acc: 76.562% (49/64)
Loss: 0.606 | Acc: 83.075% (5370/6464)
Loss: 0.606 | Acc: 83.302% (10716/12864)
Loss: 0.602 | Acc: 83.503% (16086/19264)
Loss: 0.609 | Acc: 83.335% (21387/25664)
Loss: 0.615 | Acc: 83.099% (26645/32064)
Loss: 0.620 | Acc: 82.937% (31901/38464)
Loss: 0.623 | Acc: 82.913% (37198/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2415, Accuracy: 6334/10000 (63.34%)

Epoch: 55
Loss: 0.717 | Acc: 76.562% (49/64)
Loss: 0.619 | Acc: 82.611% (5340/6464)
Loss: 0.614 | Acc: 83.030% (10681/12864)
Loss: 0.613 | Acc: 83.134% (16015/19264)
Loss: 0.617 | Acc: 83.128% (21334/25664)
Loss: 0.612 | Acc: 83.215% (26682/32064)
Loss: 0.614 | Acc: 83.098% (31963/38464)
Loss: 0.616 | Acc: 83.062% (37265/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1146, Accuracy: 6786/10000 (67.86%)

Epoch: 56
Loss: 0.506 | Acc: 89.062% (57/64)
Loss: 0.602 | Acc: 83.725% (5412/6464)
Loss: 0.611 | Acc: 83.333% (10720/12864)
Loss: 0.603 | Acc: 83.581% (16101/19264)
Loss: 0.600 | Acc: 83.646% (21467/25664)
Loss: 0.605 | Acc: 83.471% (26764/32064)
Loss: 0.606 | Acc: 83.408% (32082/38464)
Loss: 0.608 | Acc: 83.307% (37375/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8985, Accuracy: 7456/10000 (74.56%)

Epoch: 57
Loss: 0.790 | Acc: 81.250% (52/64)
Loss: 0.599 | Acc: 83.478% (5396/6464)
Loss: 0.596 | Acc: 83.543% (10747/12864)
Loss: 0.598 | Acc: 83.467% (16079/19264)
Loss: 0.598 | Acc: 83.603% (21456/25664)
Loss: 0.598 | Acc: 83.520% (26780/32064)
Loss: 0.602 | Acc: 83.418% (32086/38464)
Loss: 0.601 | Acc: 83.414% (37423/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4536, Accuracy: 5943/10000 (59.43%)

Epoch: 58
Loss: 0.948 | Acc: 68.750% (44/64)
Loss: 0.603 | Acc: 83.014% (5366/6464)
Loss: 0.611 | Acc: 83.155% (10697/12864)
Loss: 0.601 | Acc: 83.695% (16123/19264)
Loss: 0.600 | Acc: 83.681% (21476/25664)
Loss: 0.598 | Acc: 83.782% (26864/32064)
Loss: 0.600 | Acc: 83.712% (32199/38464)
Loss: 0.602 | Acc: 83.731% (37565/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0025, Accuracy: 7116/10000 (71.16%)

Epoch: 59
Loss: 0.436 | Acc: 89.062% (57/64)
Loss: 0.595 | Acc: 83.957% (5427/6464)
Loss: 0.582 | Acc: 84.282% (10842/12864)
Loss: 0.589 | Acc: 84.012% (16184/19264)
Loss: 0.592 | Acc: 83.892% (21530/25664)
Loss: 0.591 | Acc: 83.885% (26897/32064)
Loss: 0.593 | Acc: 83.756% (32216/38464)
Loss: 0.596 | Acc: 83.704% (37553/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7311, Accuracy: 7939/10000 (79.39%)

Epoch: 60
Loss: 0.660 | Acc: 81.250% (52/64)
Loss: 0.573 | Acc: 84.375% (5454/6464)
Loss: 0.575 | Acc: 84.422% (10860/12864)
Loss: 0.588 | Acc: 84.038% (16189/19264)
Loss: 0.590 | Acc: 83.974% (21551/25664)
Loss: 0.588 | Acc: 84.044% (26948/32064)
Loss: 0.590 | Acc: 84.003% (32311/38464)
Loss: 0.591 | Acc: 84.018% (37694/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8503, Accuracy: 7587/10000 (75.87%)

Epoch: 61
Loss: 0.728 | Acc: 79.688% (51/64)
Loss: 0.559 | Acc: 85.025% (5496/6464)
Loss: 0.565 | Acc: 84.904% (10922/12864)
Loss: 0.578 | Acc: 84.458% (16270/19264)
Loss: 0.583 | Acc: 84.363% (21651/25664)
Loss: 0.585 | Acc: 84.244% (27012/32064)
Loss: 0.585 | Acc: 84.279% (32417/38464)
Loss: 0.585 | Acc: 84.277% (37810/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8489, Accuracy: 7555/10000 (75.55%)

Epoch: 62
Loss: 0.592 | Acc: 81.250% (52/64)
Loss: 0.541 | Acc: 85.907% (5553/6464)
Loss: 0.556 | Acc: 85.300% (10973/12864)
Loss: 0.567 | Acc: 84.988% (16372/19264)
Loss: 0.570 | Acc: 84.753% (21751/25664)
Loss: 0.574 | Acc: 84.540% (27107/32064)
Loss: 0.573 | Acc: 84.606% (32543/38464)
Loss: 0.574 | Acc: 84.515% (37917/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7544, Accuracy: 7896/10000 (78.96%)

Epoch: 63
Loss: 0.407 | Acc: 85.938% (55/64)
Loss: 0.564 | Acc: 84.762% (5479/6464)
Loss: 0.566 | Acc: 85.028% (10938/12864)
Loss: 0.563 | Acc: 84.956% (16366/19264)
Loss: 0.562 | Acc: 84.854% (21777/25664)
Loss: 0.564 | Acc: 84.943% (27236/32064)
Loss: 0.568 | Acc: 84.846% (32635/38464)
Loss: 0.567 | Acc: 84.897% (38088/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8322, Accuracy: 5218/10000 (52.18%)

Epoch: 64
Loss: 0.813 | Acc: 78.125% (50/64)
Loss: 0.568 | Acc: 84.700% (5475/6464)
Loss: 0.551 | Acc: 85.230% (10964/12864)
Loss: 0.552 | Acc: 85.133% (16400/19264)
Loss: 0.554 | Acc: 85.006% (21816/25664)
Loss: 0.555 | Acc: 84.943% (27236/32064)
Loss: 0.558 | Acc: 84.885% (32650/38464)
Loss: 0.563 | Acc: 84.830% (38058/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1330, Accuracy: 6688/10000 (66.88%)

Epoch: 65
Loss: 0.651 | Acc: 79.688% (51/64)
Loss: 0.549 | Acc: 85.381% (5519/6464)
Loss: 0.551 | Acc: 85.393% (10985/12864)
Loss: 0.553 | Acc: 85.361% (16444/19264)
Loss: 0.557 | Acc: 85.318% (21896/25664)
Loss: 0.561 | Acc: 85.142% (27300/32064)
Loss: 0.558 | Acc: 85.191% (32768/38464)
Loss: 0.561 | Acc: 85.090% (38175/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9484, Accuracy: 7265/10000 (72.65%)

Epoch: 66
Loss: 0.619 | Acc: 84.375% (54/64)
Loss: 0.519 | Acc: 86.402% (5585/6464)
Loss: 0.538 | Acc: 85.658% (11019/12864)
Loss: 0.545 | Acc: 85.434% (16458/19264)
Loss: 0.554 | Acc: 85.217% (21870/25664)
Loss: 0.549 | Acc: 85.301% (27351/32064)
Loss: 0.551 | Acc: 85.212% (32776/38464)
Loss: 0.550 | Acc: 85.224% (38235/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8529, Accuracy: 7543/10000 (75.43%)

Epoch: 67
Loss: 0.508 | Acc: 87.500% (56/64)
Loss: 0.552 | Acc: 85.458% (5524/6464)
Loss: 0.541 | Acc: 85.634% (11016/12864)
Loss: 0.536 | Acc: 85.922% (16552/19264)
Loss: 0.539 | Acc: 85.844% (22031/25664)
Loss: 0.540 | Acc: 85.782% (27505/32064)
Loss: 0.542 | Acc: 85.680% (32956/38464)
Loss: 0.548 | Acc: 85.547% (38380/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0146, Accuracy: 7077/10000 (70.77%)

Epoch: 68
Loss: 0.521 | Acc: 84.375% (54/64)
Loss: 0.545 | Acc: 85.087% (5500/6464)
Loss: 0.535 | Acc: 85.875% (11047/12864)
Loss: 0.539 | Acc: 85.704% (16510/19264)
Loss: 0.538 | Acc: 85.786% (22016/25664)
Loss: 0.536 | Acc: 85.844% (27525/32064)
Loss: 0.538 | Acc: 85.836% (33016/38464)
Loss: 0.533 | Acc: 85.857% (38519/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8843, Accuracy: 7503/10000 (75.03%)

Epoch: 69
Loss: 0.772 | Acc: 78.125% (50/64)
Loss: 0.514 | Acc: 86.433% (5587/6464)
Loss: 0.513 | Acc: 86.746% (11159/12864)
Loss: 0.527 | Acc: 86.233% (16612/19264)
Loss: 0.527 | Acc: 86.202% (22123/25664)
Loss: 0.530 | Acc: 86.159% (27626/32064)
Loss: 0.526 | Acc: 86.242% (33172/38464)
Loss: 0.526 | Acc: 86.299% (38717/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4806, Accuracy: 6212/10000 (62.12%)

Epoch: 70
Loss: 0.621 | Acc: 82.812% (53/64)
Loss: 0.507 | Acc: 87.067% (5628/6464)
Loss: 0.505 | Acc: 86.987% (11190/12864)
Loss: 0.505 | Acc: 86.919% (16744/19264)
Loss: 0.505 | Acc: 86.966% (22319/25664)
Loss: 0.512 | Acc: 86.761% (27819/32064)
Loss: 0.515 | Acc: 86.673% (33338/38464)
Loss: 0.521 | Acc: 86.519% (38816/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8158, Accuracy: 7613/10000 (76.13%)

Epoch: 71
Loss: 0.654 | Acc: 81.250% (52/64)
Loss: 0.488 | Acc: 87.794% (5675/6464)
Loss: 0.500 | Acc: 87.065% (11200/12864)
Loss: 0.500 | Acc: 87.064% (16772/19264)
Loss: 0.504 | Acc: 86.951% (22315/25664)
Loss: 0.512 | Acc: 86.789% (27828/32064)
Loss: 0.512 | Acc: 86.699% (33348/38464)
Loss: 0.510 | Acc: 86.704% (38899/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2167, Accuracy: 6557/10000 (65.57%)

Epoch: 72
Loss: 0.556 | Acc: 79.688% (51/64)
Loss: 0.491 | Acc: 87.531% (5658/6464)
Loss: 0.501 | Acc: 87.306% (11231/12864)
Loss: 0.502 | Acc: 87.116% (16782/19264)
Loss: 0.499 | Acc: 87.145% (22365/25664)
Loss: 0.499 | Acc: 87.160% (27947/32064)
Loss: 0.497 | Acc: 87.120% (33510/38464)
Loss: 0.500 | Acc: 87.114% (39083/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9226, Accuracy: 7476/10000 (74.76%)

Epoch: 73
Loss: 0.430 | Acc: 89.062% (57/64)
Loss: 0.482 | Acc: 87.330% (5645/6464)
Loss: 0.491 | Acc: 87.142% (11210/12864)
Loss: 0.493 | Acc: 87.152% (16789/19264)
Loss: 0.496 | Acc: 87.270% (22397/25664)
Loss: 0.496 | Acc: 87.235% (27971/32064)
Loss: 0.493 | Acc: 87.315% (33585/38464)
Loss: 0.496 | Acc: 87.159% (39103/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7852, Accuracy: 7836/10000 (78.36%)

Epoch: 74
Loss: 0.443 | Acc: 85.938% (55/64)
Loss: 0.454 | Acc: 88.258% (5705/6464)
Loss: 0.469 | Acc: 87.826% (11298/12864)
Loss: 0.473 | Acc: 87.827% (16919/19264)
Loss: 0.474 | Acc: 87.722% (22513/25664)
Loss: 0.477 | Acc: 87.700% (28120/32064)
Loss: 0.482 | Acc: 87.594% (33692/38464)
Loss: 0.479 | Acc: 87.689% (39341/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8878, Accuracy: 7387/10000 (73.87%)

Epoch: 75
Loss: 0.535 | Acc: 82.812% (53/64)
Loss: 0.442 | Acc: 88.567% (5725/6464)
Loss: 0.460 | Acc: 88.184% (11344/12864)
Loss: 0.460 | Acc: 88.279% (17006/19264)
Loss: 0.460 | Acc: 88.326% (22668/25664)
Loss: 0.464 | Acc: 88.236% (28292/32064)
Loss: 0.470 | Acc: 88.103% (33888/38464)
Loss: 0.469 | Acc: 88.133% (39540/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7704, Accuracy: 7893/10000 (78.93%)

Epoch: 76
Loss: 0.638 | Acc: 82.812% (53/64)
Loss: 0.448 | Acc: 88.908% (5747/6464)
Loss: 0.446 | Acc: 89.062% (11457/12864)
Loss: 0.458 | Acc: 88.647% (17077/19264)
Loss: 0.461 | Acc: 88.474% (22706/25664)
Loss: 0.459 | Acc: 88.507% (28379/32064)
Loss: 0.462 | Acc: 88.371% (33991/38464)
Loss: 0.458 | Acc: 88.425% (39671/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6525, Accuracy: 8244/10000 (82.44%)

Epoch: 77
Loss: 0.815 | Acc: 79.688% (51/64)
Loss: 0.452 | Acc: 88.428% (5716/6464)
Loss: 0.453 | Acc: 88.565% (11393/12864)
Loss: 0.449 | Acc: 88.725% (17092/19264)
Loss: 0.453 | Acc: 88.657% (22753/25664)
Loss: 0.452 | Acc: 88.688% (28437/32064)
Loss: 0.450 | Acc: 88.673% (34107/38464)
Loss: 0.446 | Acc: 88.721% (39804/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9450, Accuracy: 7385/10000 (73.85%)

Epoch: 78
Loss: 0.519 | Acc: 85.938% (55/64)
Loss: 0.415 | Acc: 89.991% (5817/6464)
Loss: 0.411 | Acc: 89.995% (11577/12864)
Loss: 0.422 | Acc: 89.748% (17289/19264)
Loss: 0.431 | Acc: 89.460% (22959/25664)
Loss: 0.437 | Acc: 89.222% (28608/32064)
Loss: 0.435 | Acc: 89.265% (34335/38464)
Loss: 0.433 | Acc: 89.268% (40049/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7159, Accuracy: 8106/10000 (81.06%)

Epoch: 79
Loss: 0.439 | Acc: 90.625% (58/64)
Loss: 0.399 | Acc: 90.486% (5849/6464)
Loss: 0.395 | Acc: 90.291% (11615/12864)
Loss: 0.401 | Acc: 90.116% (17360/19264)
Loss: 0.406 | Acc: 90.087% (23120/25664)
Loss: 0.409 | Acc: 89.983% (28852/32064)
Loss: 0.408 | Acc: 90.022% (34626/38464)
Loss: 0.410 | Acc: 89.954% (40357/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6172, Accuracy: 8394/10000 (83.94%)

Epoch: 80
Loss: 0.557 | Acc: 87.500% (56/64)
Loss: 0.419 | Acc: 89.511% (5786/6464)
Loss: 0.413 | Acc: 89.436% (11505/12864)
Loss: 0.413 | Acc: 89.576% (17256/19264)
Loss: 0.411 | Acc: 89.721% (23026/25664)
Loss: 0.411 | Acc: 89.783% (28788/32064)
Loss: 0.408 | Acc: 89.894% (34577/38464)
Loss: 0.409 | Acc: 89.881% (40324/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6372, Accuracy: 8400/10000 (84.00%)

Epoch: 81
Loss: 0.231 | Acc: 92.188% (59/64)
Loss: 0.368 | Acc: 90.842% (5872/6464)
Loss: 0.393 | Acc: 90.330% (11620/12864)
Loss: 0.394 | Acc: 90.417% (17418/19264)
Loss: 0.392 | Acc: 90.512% (23229/25664)
Loss: 0.386 | Acc: 90.694% (29080/32064)
Loss: 0.390 | Acc: 90.542% (34826/38464)
Loss: 0.392 | Acc: 90.453% (40581/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7584, Accuracy: 8048/10000 (80.48%)

Epoch: 82
Loss: 0.411 | Acc: 90.625% (58/64)
Loss: 0.386 | Acc: 90.842% (5872/6464)
Loss: 0.371 | Acc: 91.169% (11728/12864)
Loss: 0.360 | Acc: 91.310% (17590/19264)
Loss: 0.366 | Acc: 91.198% (23405/25664)
Loss: 0.369 | Acc: 91.146% (29225/32064)
Loss: 0.371 | Acc: 91.116% (35047/38464)
Loss: 0.372 | Acc: 91.102% (40872/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6076, Accuracy: 8500/10000 (85.00%)

Epoch: 83
Loss: 0.469 | Acc: 87.500% (56/64)
Loss: 0.326 | Acc: 92.389% (5972/6464)
Loss: 0.340 | Acc: 91.947% (11828/12864)
Loss: 0.338 | Acc: 92.001% (17723/19264)
Loss: 0.345 | Acc: 91.868% (23577/25664)
Loss: 0.347 | Acc: 91.698% (29402/32064)
Loss: 0.354 | Acc: 91.584% (35227/38464)
Loss: 0.354 | Acc: 91.646% (41116/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7851, Accuracy: 7901/10000 (79.01%)

Epoch: 84
Loss: 0.190 | Acc: 96.875% (62/64)
Loss: 0.340 | Acc: 92.033% (5949/6464)
Loss: 0.336 | Acc: 92.141% (11853/12864)
Loss: 0.346 | Acc: 91.850% (17694/19264)
Loss: 0.347 | Acc: 91.767% (23551/25664)
Loss: 0.342 | Acc: 91.901% (29467/32064)
Loss: 0.343 | Acc: 91.839% (35325/38464)
Loss: 0.342 | Acc: 91.800% (41185/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5986, Accuracy: 8549/10000 (85.49%)

Epoch: 85
Loss: 0.423 | Acc: 89.062% (57/64)
Loss: 0.319 | Acc: 92.713% (5993/6464)
Loss: 0.313 | Acc: 92.918% (11953/12864)
Loss: 0.312 | Acc: 92.847% (17886/19264)
Loss: 0.313 | Acc: 92.717% (23795/25664)
Loss: 0.313 | Acc: 92.690% (29720/32064)
Loss: 0.316 | Acc: 92.614% (35623/38464)
Loss: 0.318 | Acc: 92.582% (41536/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6569, Accuracy: 8363/10000 (83.63%)

Epoch: 86
Loss: 0.191 | Acc: 95.312% (61/64)
Loss: 0.285 | Acc: 93.363% (6035/6464)
Loss: 0.279 | Acc: 93.548% (12034/12864)
Loss: 0.291 | Acc: 93.252% (17964/19264)
Loss: 0.296 | Acc: 93.080% (23888/25664)
Loss: 0.295 | Acc: 93.067% (29841/32064)
Loss: 0.297 | Acc: 93.027% (35782/38464)
Loss: 0.300 | Acc: 92.963% (41707/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9560, Accuracy: 7535/10000 (75.35%)

Epoch: 87
Loss: 0.259 | Acc: 95.312% (61/64)
Loss: 0.308 | Acc: 93.054% (6015/6464)
Loss: 0.286 | Acc: 93.462% (12023/12864)
Loss: 0.283 | Acc: 93.480% (18008/19264)
Loss: 0.281 | Acc: 93.505% (23997/25664)
Loss: 0.282 | Acc: 93.513% (29984/32064)
Loss: 0.286 | Acc: 93.425% (35935/38464)
Loss: 0.282 | Acc: 93.498% (41947/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5620, Accuracy: 8770/10000 (87.70%)

Epoch: 88
Loss: 0.274 | Acc: 95.312% (61/64)
Loss: 0.243 | Acc: 94.415% (6103/6464)
Loss: 0.248 | Acc: 94.193% (12117/12864)
Loss: 0.248 | Acc: 94.248% (18156/19264)
Loss: 0.249 | Acc: 94.241% (24186/25664)
Loss: 0.249 | Acc: 94.190% (30201/32064)
Loss: 0.249 | Acc: 94.150% (36214/38464)
Loss: 0.254 | Acc: 94.062% (42200/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5503, Accuracy: 8787/10000 (87.87%)

Epoch: 89
Loss: 0.329 | Acc: 92.188% (59/64)
Loss: 0.223 | Acc: 94.802% (6128/6464)
Loss: 0.227 | Acc: 94.683% (12180/12864)
Loss: 0.232 | Acc: 94.601% (18224/19264)
Loss: 0.229 | Acc: 94.650% (24291/25664)
Loss: 0.232 | Acc: 94.633% (30343/32064)
Loss: 0.229 | Acc: 94.696% (36424/38464)
Loss: 0.228 | Acc: 94.708% (42490/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5730, Accuracy: 8761/10000 (87.61%)

Epoch: 90
Loss: 0.090 | Acc: 98.438% (63/64)
Loss: 0.201 | Acc: 95.467% (6171/6464)
Loss: 0.198 | Acc: 95.406% (12273/12864)
Loss: 0.202 | Acc: 95.323% (18363/19264)
Loss: 0.200 | Acc: 95.383% (24479/25664)
Loss: 0.204 | Acc: 95.263% (30545/32064)
Loss: 0.204 | Acc: 95.268% (36644/38464)
Loss: 0.204 | Acc: 95.248% (42732/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5761, Accuracy: 8818/10000 (88.18%)

Epoch: 91
Loss: 0.248 | Acc: 93.750% (60/64)
Loss: 0.186 | Acc: 95.808% (6193/6464)
Loss: 0.185 | Acc: 95.717% (12313/12864)
Loss: 0.180 | Acc: 95.837% (18462/19264)
Loss: 0.179 | Acc: 95.761% (24576/25664)
Loss: 0.182 | Acc: 95.684% (30680/32064)
Loss: 0.185 | Acc: 95.643% (36788/38464)
Loss: 0.185 | Acc: 95.629% (42903/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5679, Accuracy: 8841/10000 (88.41%)

Epoch: 92
Loss: 0.294 | Acc: 92.188% (59/64)
Loss: 0.142 | Acc: 96.426% (6233/6464)
Loss: 0.145 | Acc: 96.517% (12416/12864)
Loss: 0.151 | Acc: 96.294% (18550/19264)
Loss: 0.157 | Acc: 96.127% (24670/25664)
Loss: 0.160 | Acc: 96.064% (30802/32064)
Loss: 0.161 | Acc: 96.017% (36932/38464)
Loss: 0.161 | Acc: 96.008% (43073/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5771, Accuracy: 8850/10000 (88.50%)

Epoch: 93
Loss: 0.163 | Acc: 93.750% (60/64)
Loss: 0.132 | Acc: 96.689% (6250/6464)
Loss: 0.135 | Acc: 96.642% (12432/12864)
Loss: 0.133 | Acc: 96.667% (18622/19264)
Loss: 0.136 | Acc: 96.649% (24804/25664)
Loss: 0.135 | Acc: 96.619% (30980/32064)
Loss: 0.134 | Acc: 96.688% (37190/38464)
Loss: 0.135 | Acc: 96.677% (43373/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5998, Accuracy: 8803/10000 (88.03%)

Epoch: 94
Loss: 0.060 | Acc: 96.875% (62/64)
Loss: 0.124 | Acc: 96.736% (6253/6464)
Loss: 0.124 | Acc: 96.883% (12463/12864)
Loss: 0.122 | Acc: 96.974% (18681/19264)
Loss: 0.121 | Acc: 97.004% (24895/25664)
Loss: 0.121 | Acc: 97.037% (31114/32064)
Loss: 0.121 | Acc: 97.049% (37329/38464)
Loss: 0.119 | Acc: 97.069% (43549/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5946, Accuracy: 8862/10000 (88.62%)

Epoch: 95
Loss: 0.060 | Acc: 100.000% (64/64)
Loss: 0.098 | Acc: 97.432% (6298/6464)
Loss: 0.097 | Acc: 97.512% (12544/12864)
Loss: 0.098 | Acc: 97.488% (18780/19264)
Loss: 0.101 | Acc: 97.444% (25008/25664)
Loss: 0.102 | Acc: 97.411% (31234/32064)
Loss: 0.104 | Acc: 97.351% (37445/38464)
Loss: 0.103 | Acc: 97.370% (43684/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6074, Accuracy: 8886/10000 (88.86%)

Epoch: 96
Loss: 0.095 | Acc: 98.438% (63/64)
Loss: 0.092 | Acc: 97.618% (6310/6464)
Loss: 0.092 | Acc: 97.699% (12568/12864)
Loss: 0.096 | Acc: 97.498% (18782/19264)
Loss: 0.096 | Acc: 97.502% (25023/25664)
Loss: 0.095 | Acc: 97.552% (31279/32064)
Loss: 0.094 | Acc: 97.528% (37513/38464)
Loss: 0.094 | Acc: 97.541% (43761/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5971, Accuracy: 8891/10000 (88.91%)

Epoch: 97
Loss: 0.088 | Acc: 98.438% (63/64)
Loss: 0.090 | Acc: 97.556% (6306/6464)
Loss: 0.090 | Acc: 97.582% (12553/12864)
Loss: 0.088 | Acc: 97.638% (18809/19264)
Loss: 0.089 | Acc: 97.619% (25053/25664)
Loss: 0.089 | Acc: 97.611% (31298/32064)
Loss: 0.090 | Acc: 97.603% (37542/38464)
Loss: 0.090 | Acc: 97.604% (43789/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5986, Accuracy: 8903/10000 (89.03%)
torch.Size([100, 10])
Test set: Average loss: 0.5986, Accuracy: 8903/10000 (89.03%)

Epoch: 98
Loss: 0.113 | Acc: 95.312% (61/64)
Loss: 0.089 | Acc: 97.788% (6321/6464)
Loss: 0.086 | Acc: 97.839% (12586/12864)
Loss: 0.085 | Acc: 97.815% (18843/19264)
Loss: 0.084 | Acc: 97.787% (25096/25664)
Loss: 0.085 | Acc: 97.786% (31354/32064)
Loss: 0.087 | Acc: 97.723% (37588/38464)
Loss: 0.086 | Acc: 97.762% (43860/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5986, Accuracy: 8894/10000 (88.94%)
torch.Size([100, 10])
Test set: Average loss: 0.5986, Accuracy: 8894/10000 (88.94%)

Epoch: 99
Loss: 0.025 | Acc: 100.000% (64/64)
Loss: 0.087 | Acc: 97.726% (6317/6464)
Loss: 0.079 | Acc: 98.002% (12607/12864)
Loss: 0.081 | Acc: 97.856% (18851/19264)
Loss: 0.084 | Acc: 97.822% (25105/25664)
Loss: 0.084 | Acc: 97.836% (31370/32064)
Loss: 0.083 | Acc: 97.855% (37639/38464)
Loss: 0.083 | Acc: 97.833% (43892/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6005, Accuracy: 8893/10000 (88.93%)
torch.Size([100, 10])
Test set: Average loss: 0.6005, Accuracy: 8893/10000 (88.93%)

Epoch: 100
Loss: 0.053 | Acc: 98.438% (63/64)
Loss: 2.013 | Acc: 26.098% (1687/6464)
Loss: 1.573 | Acc: 44.714% (5752/12864)
Loss: 1.331 | Acc: 54.713% (10540/19264)
Loss: 1.194 | Acc: 60.295% (15474/25664)
Loss: 1.102 | Acc: 64.038% (20533/32064)
Loss: 1.040 | Acc: 66.629% (25628/38464)
Loss: 0.991 | Acc: 68.532% (30746/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6590, Accuracy: 5541/10000 (55.41%)

Epoch: 101
Loss: 0.913 | Acc: 73.438% (47/64)
Loss: 0.644 | Acc: 81.838% (5290/6464)
Loss: 0.658 | Acc: 81.227% (10449/12864)
Loss: 0.659 | Acc: 81.157% (15634/19264)
Loss: 0.651 | Acc: 81.429% (20898/25664)
Loss: 0.650 | Acc: 81.546% (26147/32064)
Loss: 0.647 | Acc: 81.697% (31424/38464)
Loss: 0.650 | Acc: 81.716% (36661/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9175, Accuracy: 7342/10000 (73.42%)

Epoch: 102
Loss: 0.391 | Acc: 92.188% (59/64)
Loss: 0.586 | Acc: 84.174% (5441/6464)
Loss: 0.602 | Acc: 83.364% (10724/12864)
Loss: 0.605 | Acc: 83.456% (16077/19264)
Loss: 0.608 | Acc: 83.307% (21380/25664)
Loss: 0.612 | Acc: 83.205% (26679/32064)
Loss: 0.613 | Acc: 83.283% (32034/38464)
Loss: 0.612 | Acc: 83.341% (37390/44864)
torch.Size([100, 10])
Test set: Average loss: 4.4350, Accuracy: 2551/10000 (25.51%)

Epoch: 103
Loss: 0.981 | Acc: 71.875% (46/64)
Loss: 0.609 | Acc: 83.168% (5376/6464)
Loss: 0.612 | Acc: 83.372% (10725/12864)
Loss: 0.606 | Acc: 83.493% (16084/19264)
Loss: 0.607 | Acc: 83.572% (21448/25664)
Loss: 0.606 | Acc: 83.552% (26790/32064)
Loss: 0.605 | Acc: 83.556% (32139/38464)
Loss: 0.603 | Acc: 83.535% (37477/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9332, Accuracy: 5562/10000 (55.62%)

Epoch: 104
Loss: 0.947 | Acc: 75.000% (48/64)
Loss: 0.598 | Acc: 83.988% (5429/6464)
Loss: 0.605 | Acc: 83.862% (10788/12864)
Loss: 0.600 | Acc: 83.970% (16176/19264)
Loss: 0.599 | Acc: 83.841% (21517/25664)
Loss: 0.596 | Acc: 83.907% (26904/32064)
Loss: 0.597 | Acc: 83.837% (32247/38464)
Loss: 0.596 | Acc: 83.849% (37618/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4221, Accuracy: 5984/10000 (59.84%)

Epoch: 105
Loss: 0.820 | Acc: 70.312% (45/64)
Loss: 0.581 | Acc: 84.127% (5438/6464)
Loss: 0.584 | Acc: 84.087% (10817/12864)
Loss: 0.586 | Acc: 84.183% (16217/19264)
Loss: 0.585 | Acc: 84.153% (21597/25664)
Loss: 0.588 | Acc: 84.147% (26981/32064)
Loss: 0.590 | Acc: 84.125% (32358/38464)
Loss: 0.591 | Acc: 84.061% (37713/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6895, Accuracy: 5219/10000 (52.19%)

Epoch: 106
Loss: 0.616 | Acc: 82.812% (53/64)
Loss: 0.595 | Acc: 83.679% (5409/6464)
Loss: 0.580 | Acc: 84.227% (10835/12864)
Loss: 0.576 | Acc: 84.531% (16284/19264)
Loss: 0.581 | Acc: 84.394% (21659/25664)
Loss: 0.586 | Acc: 84.313% (27034/32064)
Loss: 0.586 | Acc: 84.294% (32423/38464)
Loss: 0.589 | Acc: 84.161% (37758/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9797, Accuracy: 7322/10000 (73.22%)

Epoch: 107
Loss: 0.561 | Acc: 84.375% (54/64)
Loss: 0.557 | Acc: 85.257% (5511/6464)
Loss: 0.567 | Acc: 84.608% (10884/12864)
Loss: 0.579 | Acc: 84.406% (16260/19264)
Loss: 0.581 | Acc: 84.414% (21664/25664)
Loss: 0.580 | Acc: 84.422% (27069/32064)
Loss: 0.582 | Acc: 84.320% (32433/38464)
Loss: 0.578 | Acc: 84.469% (37896/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0942, Accuracy: 4367/10000 (43.67%)

Epoch: 108
Loss: 0.841 | Acc: 71.875% (46/64)
Loss: 0.576 | Acc: 84.576% (5467/6464)
Loss: 0.576 | Acc: 84.639% (10888/12864)
Loss: 0.577 | Acc: 84.645% (16306/19264)
Loss: 0.576 | Acc: 84.726% (21744/25664)
Loss: 0.570 | Acc: 84.812% (27194/32064)
Loss: 0.578 | Acc: 84.609% (32544/38464)
Loss: 0.582 | Acc: 84.428% (37878/44864)
torch.Size([100, 10])
Test set: Average loss: 3.0977, Accuracy: 4077/10000 (40.77%)

Epoch: 109
Loss: 0.759 | Acc: 78.125% (50/64)
Loss: 0.570 | Acc: 84.112% (5437/6464)
Loss: 0.577 | Acc: 84.562% (10878/12864)
Loss: 0.580 | Acc: 84.463% (16271/19264)
Loss: 0.569 | Acc: 84.757% (21752/25664)
Loss: 0.572 | Acc: 84.621% (27133/32064)
Loss: 0.575 | Acc: 84.599% (32540/38464)
Loss: 0.576 | Acc: 84.540% (37928/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4778, Accuracy: 5849/10000 (58.49%)

Epoch: 110
Loss: 0.814 | Acc: 73.438% (47/64)
Loss: 0.575 | Acc: 84.700% (5475/6464)
Loss: 0.565 | Acc: 84.756% (10903/12864)
Loss: 0.565 | Acc: 84.946% (16364/19264)
Loss: 0.565 | Acc: 84.917% (21793/25664)
Loss: 0.569 | Acc: 84.799% (27190/32064)
Loss: 0.570 | Acc: 84.791% (32614/38464)
Loss: 0.569 | Acc: 84.843% (38064/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2614, Accuracy: 6405/10000 (64.05%)

Epoch: 111
Loss: 0.884 | Acc: 70.312% (45/64)
Loss: 0.571 | Acc: 84.638% (5471/6464)
Loss: 0.573 | Acc: 84.748% (10902/12864)
Loss: 0.568 | Acc: 84.930% (16361/19264)
Loss: 0.562 | Acc: 85.002% (21815/25664)
Loss: 0.564 | Acc: 84.993% (27252/32064)
Loss: 0.569 | Acc: 84.869% (32644/38464)
Loss: 0.568 | Acc: 84.856% (38070/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4188, Accuracy: 6047/10000 (60.47%)

Epoch: 112
Loss: 0.952 | Acc: 70.312% (45/64)
Loss: 0.553 | Acc: 85.102% (5501/6464)
Loss: 0.549 | Acc: 85.215% (10962/12864)
Loss: 0.558 | Acc: 85.071% (16388/19264)
Loss: 0.556 | Acc: 85.154% (21854/25664)
Loss: 0.559 | Acc: 85.049% (27270/32064)
Loss: 0.562 | Acc: 84.952% (32676/38464)
Loss: 0.563 | Acc: 84.957% (38115/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8768, Accuracy: 7469/10000 (74.69%)

Epoch: 113
Loss: 0.624 | Acc: 85.938% (55/64)
Loss: 0.550 | Acc: 85.040% (5497/6464)
Loss: 0.553 | Acc: 84.927% (10925/12864)
Loss: 0.548 | Acc: 85.133% (16400/19264)
Loss: 0.546 | Acc: 85.260% (21881/25664)
Loss: 0.544 | Acc: 85.279% (27344/32064)
Loss: 0.548 | Acc: 85.314% (32815/38464)
Loss: 0.551 | Acc: 85.278% (38259/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2380, Accuracy: 6603/10000 (66.03%)

Epoch: 114
Loss: 0.517 | Acc: 82.812% (53/64)
Loss: 0.561 | Acc: 84.947% (5491/6464)
Loss: 0.545 | Acc: 85.409% (10987/12864)
Loss: 0.550 | Acc: 85.206% (16414/19264)
Loss: 0.545 | Acc: 85.408% (21919/25664)
Loss: 0.546 | Acc: 85.448% (27398/32064)
Loss: 0.548 | Acc: 85.345% (32827/38464)
Loss: 0.551 | Acc: 85.311% (38274/44864)
torch.Size([100, 10])
Test set: Average loss: 2.2108, Accuracy: 4741/10000 (47.41%)

Epoch: 115
Loss: 0.844 | Acc: 76.562% (49/64)
Loss: 0.515 | Acc: 86.603% (5598/6464)
Loss: 0.513 | Acc: 86.583% (11138/12864)
Loss: 0.527 | Acc: 86.197% (16605/19264)
Loss: 0.532 | Acc: 86.031% (22079/25664)
Loss: 0.535 | Acc: 85.875% (27535/32064)
Loss: 0.535 | Acc: 85.854% (33023/38464)
Loss: 0.539 | Acc: 85.775% (38482/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8565, Accuracy: 7685/10000 (76.85%)

Epoch: 116
Loss: 0.504 | Acc: 85.938% (55/64)
Loss: 0.515 | Acc: 86.371% (5583/6464)
Loss: 0.525 | Acc: 86.023% (11066/12864)
Loss: 0.531 | Acc: 86.021% (16571/19264)
Loss: 0.530 | Acc: 86.043% (22082/25664)
Loss: 0.536 | Acc: 85.869% (27533/32064)
Loss: 0.532 | Acc: 86.039% (33094/38464)
Loss: 0.536 | Acc: 85.855% (38518/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8014, Accuracy: 7792/10000 (77.92%)

Epoch: 117
Loss: 0.531 | Acc: 82.812% (53/64)
Loss: 0.539 | Acc: 85.597% (5533/6464)
Loss: 0.528 | Acc: 85.938% (11055/12864)
Loss: 0.518 | Acc: 86.327% (16630/19264)
Loss: 0.519 | Acc: 86.374% (22167/25664)
Loss: 0.527 | Acc: 86.221% (27646/32064)
Loss: 0.525 | Acc: 86.262% (33180/38464)
Loss: 0.525 | Acc: 86.294% (38715/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7709, Accuracy: 7906/10000 (79.06%)

Epoch: 118
Loss: 0.714 | Acc: 85.938% (55/64)
Loss: 0.519 | Acc: 86.696% (5604/6464)
Loss: 0.527 | Acc: 86.396% (11114/12864)
Loss: 0.517 | Acc: 86.581% (16679/19264)
Loss: 0.518 | Acc: 86.506% (22201/25664)
Loss: 0.521 | Acc: 86.446% (27718/32064)
Loss: 0.522 | Acc: 86.426% (33243/38464)
Loss: 0.522 | Acc: 86.475% (38796/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6541, Accuracy: 5646/10000 (56.46%)

Epoch: 119
Loss: 0.473 | Acc: 89.062% (57/64)
Loss: 0.516 | Acc: 86.386% (5584/6464)
Loss: 0.508 | Acc: 86.622% (11143/12864)
Loss: 0.505 | Acc: 86.804% (16722/19264)
Loss: 0.509 | Acc: 86.705% (22252/25664)
Loss: 0.511 | Acc: 86.751% (27816/32064)
Loss: 0.510 | Acc: 86.663% (33334/38464)
Loss: 0.515 | Acc: 86.564% (38836/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8415, Accuracy: 7681/10000 (76.81%)

Epoch: 120
Loss: 0.422 | Acc: 90.625% (58/64)
Loss: 0.516 | Acc: 86.773% (5609/6464)
Loss: 0.512 | Acc: 86.653% (11147/12864)
Loss: 0.513 | Acc: 86.597% (16682/19264)
Loss: 0.511 | Acc: 86.631% (22233/25664)
Loss: 0.509 | Acc: 86.652% (27784/32064)
Loss: 0.510 | Acc: 86.650% (33329/38464)
Loss: 0.508 | Acc: 86.718% (38905/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5145, Accuracy: 6204/10000 (62.04%)

Epoch: 121
Loss: 0.505 | Acc: 85.938% (55/64)
Loss: 0.470 | Acc: 87.717% (5670/6464)
Loss: 0.477 | Acc: 87.547% (11262/12864)
Loss: 0.488 | Acc: 87.339% (16825/19264)
Loss: 0.494 | Acc: 87.157% (22368/25664)
Loss: 0.491 | Acc: 87.307% (27994/32064)
Loss: 0.494 | Acc: 87.250% (33560/38464)
Loss: 0.496 | Acc: 87.241% (39140/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7035, Accuracy: 8081/10000 (80.81%)

Epoch: 122
Loss: 0.645 | Acc: 79.688% (51/64)
Loss: 0.463 | Acc: 88.320% (5709/6464)
Loss: 0.458 | Acc: 88.410% (11373/12864)
Loss: 0.464 | Acc: 88.113% (16974/19264)
Loss: 0.473 | Acc: 87.866% (22550/25664)
Loss: 0.479 | Acc: 87.712% (28124/32064)
Loss: 0.477 | Acc: 87.752% (33753/38464)
Loss: 0.481 | Acc: 87.596% (39299/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7555, Accuracy: 8000/10000 (80.00%)

Epoch: 123
Loss: 0.439 | Acc: 87.500% (56/64)
Loss: 0.475 | Acc: 88.335% (5710/6464)
Loss: 0.473 | Acc: 88.029% (11324/12864)
Loss: 0.474 | Acc: 88.024% (16957/19264)
Loss: 0.472 | Acc: 88.084% (22606/25664)
Loss: 0.474 | Acc: 88.036% (28228/32064)
Loss: 0.476 | Acc: 87.958% (33832/38464)
Loss: 0.475 | Acc: 87.997% (39479/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8455, Accuracy: 7724/10000 (77.24%)

Epoch: 124
Loss: 0.479 | Acc: 85.938% (55/64)
Loss: 0.454 | Acc: 88.413% (5715/6464)
Loss: 0.456 | Acc: 88.347% (11365/12864)
Loss: 0.457 | Acc: 88.440% (17037/19264)
Loss: 0.458 | Acc: 88.307% (22663/25664)
Loss: 0.464 | Acc: 88.142% (28262/32064)
Loss: 0.463 | Acc: 88.199% (33925/38464)
Loss: 0.468 | Acc: 88.111% (39530/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7138, Accuracy: 8095/10000 (80.95%)

Epoch: 125
Loss: 0.337 | Acc: 89.062% (57/64)
Loss: 0.420 | Acc: 89.403% (5779/6464)
Loss: 0.435 | Acc: 88.915% (11438/12864)
Loss: 0.446 | Acc: 88.678% (17083/19264)
Loss: 0.443 | Acc: 88.801% (22790/25664)
Loss: 0.448 | Acc: 88.732% (28451/32064)
Loss: 0.449 | Acc: 88.628% (34090/38464)
Loss: 0.455 | Acc: 88.519% (39713/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9494, Accuracy: 7286/10000 (72.86%)

Epoch: 126
Loss: 0.640 | Acc: 81.250% (52/64)
Loss: 0.416 | Acc: 89.635% (5794/6464)
Loss: 0.423 | Acc: 89.529% (11517/12864)
Loss: 0.435 | Acc: 89.161% (17176/19264)
Loss: 0.440 | Acc: 88.969% (22833/25664)
Loss: 0.439 | Acc: 88.972% (28528/32064)
Loss: 0.440 | Acc: 88.951% (34214/38464)
Loss: 0.442 | Acc: 88.915% (39891/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6417, Accuracy: 8332/10000 (83.32%)

Epoch: 127
Loss: 0.563 | Acc: 82.812% (53/64)
Loss: 0.418 | Acc: 90.192% (5830/6464)
Loss: 0.429 | Acc: 89.708% (11540/12864)
Loss: 0.434 | Acc: 89.436% (17229/19264)
Loss: 0.435 | Acc: 89.242% (22903/25664)
Loss: 0.436 | Acc: 89.175% (28593/32064)
Loss: 0.433 | Acc: 89.268% (34336/38464)
Loss: 0.433 | Acc: 89.292% (40060/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0273, Accuracy: 7170/10000 (71.70%)

Epoch: 128
Loss: 0.543 | Acc: 82.812% (53/64)
Loss: 0.402 | Acc: 89.666% (5796/6464)
Loss: 0.408 | Acc: 89.576% (11523/12864)
Loss: 0.410 | Acc: 89.618% (17264/19264)
Loss: 0.415 | Acc: 89.698% (23020/25664)
Loss: 0.418 | Acc: 89.655% (28747/32064)
Loss: 0.419 | Acc: 89.616% (34470/38464)
Loss: 0.419 | Acc: 89.629% (40211/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5976, Accuracy: 8481/10000 (84.81%)

Epoch: 129
Loss: 0.493 | Acc: 87.500% (56/64)
Loss: 0.388 | Acc: 90.687% (5862/6464)
Loss: 0.399 | Acc: 90.415% (11631/12864)
Loss: 0.390 | Acc: 90.672% (17467/19264)
Loss: 0.394 | Acc: 90.446% (23212/25664)
Loss: 0.400 | Acc: 90.285% (28949/32064)
Loss: 0.408 | Acc: 90.126% (34666/38464)
Loss: 0.409 | Acc: 90.110% (40427/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9340, Accuracy: 7543/10000 (75.43%)

Epoch: 130
Loss: 0.399 | Acc: 89.062% (57/64)
Loss: 0.394 | Acc: 90.424% (5845/6464)
Loss: 0.403 | Acc: 90.244% (11609/12864)
Loss: 0.393 | Acc: 90.547% (17443/19264)
Loss: 0.395 | Acc: 90.446% (23212/25664)
Loss: 0.392 | Acc: 90.516% (29023/32064)
Loss: 0.393 | Acc: 90.552% (34830/38464)
Loss: 0.395 | Acc: 90.511% (40607/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7449, Accuracy: 8028/10000 (80.28%)

Epoch: 131
Loss: 0.707 | Acc: 82.812% (53/64)
Loss: 0.359 | Acc: 91.429% (5910/6464)
Loss: 0.369 | Acc: 91.224% (11735/12864)
Loss: 0.364 | Acc: 91.315% (17591/19264)
Loss: 0.366 | Acc: 91.217% (23410/25664)
Loss: 0.370 | Acc: 91.146% (29225/32064)
Loss: 0.372 | Acc: 91.111% (35045/38464)
Loss: 0.376 | Acc: 91.002% (40827/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0250, Accuracy: 7258/10000 (72.58%)

Epoch: 132
Loss: 0.383 | Acc: 87.500% (56/64)
Loss: 0.326 | Acc: 92.311% (5967/6464)
Loss: 0.348 | Acc: 91.869% (11818/12864)
Loss: 0.348 | Acc: 91.814% (17687/19264)
Loss: 0.359 | Acc: 91.521% (23488/25664)
Loss: 0.363 | Acc: 91.439% (29319/32064)
Loss: 0.364 | Acc: 91.395% (35154/38464)
Loss: 0.364 | Acc: 91.398% (41005/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6282, Accuracy: 8447/10000 (84.47%)

Epoch: 133
Loss: 0.347 | Acc: 93.750% (60/64)
Loss: 0.307 | Acc: 92.853% (6002/6464)
Loss: 0.332 | Acc: 92.102% (11848/12864)
Loss: 0.338 | Acc: 92.016% (17726/19264)
Loss: 0.341 | Acc: 91.930% (23593/25664)
Loss: 0.344 | Acc: 91.816% (29440/32064)
Loss: 0.345 | Acc: 91.795% (35308/38464)
Loss: 0.347 | Acc: 91.802% (41186/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5959, Accuracy: 8619/10000 (86.19%)

Epoch: 134
Loss: 0.282 | Acc: 89.062% (57/64)
Loss: 0.308 | Acc: 92.946% (6008/6464)
Loss: 0.311 | Acc: 92.724% (11928/12864)
Loss: 0.312 | Acc: 92.790% (17875/19264)
Loss: 0.318 | Acc: 92.628% (23772/25664)
Loss: 0.321 | Acc: 92.596% (29690/32064)
Loss: 0.323 | Acc: 92.468% (35567/38464)
Loss: 0.320 | Acc: 92.533% (41514/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5997, Accuracy: 8551/10000 (85.51%)

Epoch: 135
Loss: 0.216 | Acc: 95.312% (61/64)
Loss: 0.276 | Acc: 93.796% (6063/6464)
Loss: 0.284 | Acc: 93.424% (12018/12864)
Loss: 0.292 | Acc: 93.158% (17946/19264)
Loss: 0.304 | Acc: 92.889% (23839/25664)
Loss: 0.304 | Acc: 92.933% (29798/32064)
Loss: 0.307 | Acc: 92.832% (35707/38464)
Loss: 0.306 | Acc: 92.874% (41667/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6188, Accuracy: 8525/10000 (85.25%)

Epoch: 136
Loss: 0.202 | Acc: 95.312% (61/64)
Loss: 0.293 | Acc: 93.038% (6014/6464)
Loss: 0.287 | Acc: 93.276% (11999/12864)
Loss: 0.279 | Acc: 93.511% (18014/19264)
Loss: 0.281 | Acc: 93.419% (23975/25664)
Loss: 0.287 | Acc: 93.260% (29903/32064)
Loss: 0.288 | Acc: 93.269% (35875/38464)
Loss: 0.286 | Acc: 93.309% (41862/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7638, Accuracy: 8134/10000 (81.34%)

Epoch: 137
Loss: 0.298 | Acc: 93.750% (60/64)
Loss: 0.268 | Acc: 93.719% (6058/6464)
Loss: 0.263 | Acc: 93.804% (12067/12864)
Loss: 0.259 | Acc: 93.958% (18100/19264)
Loss: 0.258 | Acc: 94.038% (24134/25664)
Loss: 0.263 | Acc: 93.922% (30115/32064)
Loss: 0.265 | Acc: 93.893% (36115/38464)
Loss: 0.264 | Acc: 93.906% (42130/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5856, Accuracy: 8645/10000 (86.45%)

Epoch: 138
Loss: 0.316 | Acc: 90.625% (58/64)
Loss: 0.248 | Acc: 94.028% (6078/6464)
Loss: 0.252 | Acc: 93.859% (12074/12864)
Loss: 0.244 | Acc: 94.191% (18145/19264)
Loss: 0.244 | Acc: 94.296% (24200/25664)
Loss: 0.242 | Acc: 94.311% (30240/32064)
Loss: 0.238 | Acc: 94.371% (36299/38464)
Loss: 0.243 | Acc: 94.301% (42307/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6509, Accuracy: 8532/10000 (85.32%)

Epoch: 139
Loss: 0.502 | Acc: 87.500% (56/64)
Loss: 0.221 | Acc: 95.189% (6153/6464)
Loss: 0.217 | Acc: 95.048% (12227/12864)
Loss: 0.216 | Acc: 95.126% (18325/19264)
Loss: 0.218 | Acc: 95.040% (24391/25664)
Loss: 0.219 | Acc: 95.016% (30466/32064)
Loss: 0.219 | Acc: 94.975% (36531/38464)
Loss: 0.218 | Acc: 95.005% (42623/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6050, Accuracy: 8723/10000 (87.23%)

Epoch: 140
Loss: 0.348 | Acc: 90.625% (58/64)
Loss: 0.191 | Acc: 95.498% (6173/6464)
Loss: 0.188 | Acc: 95.522% (12288/12864)
Loss: 0.190 | Acc: 95.520% (18401/19264)
Loss: 0.191 | Acc: 95.461% (24499/25664)
Loss: 0.189 | Acc: 95.481% (30615/32064)
Loss: 0.191 | Acc: 95.474% (36723/38464)
Loss: 0.194 | Acc: 95.411% (42805/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6599, Accuracy: 8648/10000 (86.48%)

Epoch: 141
Loss: 0.224 | Acc: 93.750% (60/64)
Loss: 0.162 | Acc: 96.071% (6210/6464)
Loss: 0.171 | Acc: 95.833% (12328/12864)
Loss: 0.169 | Acc: 95.878% (18470/19264)
Loss: 0.174 | Acc: 95.776% (24580/25664)
Loss: 0.171 | Acc: 95.871% (30740/32064)
Loss: 0.170 | Acc: 95.879% (36879/38464)
Loss: 0.173 | Acc: 95.823% (42990/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6039, Accuracy: 8776/10000 (87.76%)

Epoch: 142
Loss: 0.036 | Acc: 100.000% (64/64)
Loss: 0.147 | Acc: 96.194% (6218/6464)
Loss: 0.146 | Acc: 96.370% (12397/12864)
Loss: 0.148 | Acc: 96.278% (18547/19264)
Loss: 0.147 | Acc: 96.318% (24719/25664)
Loss: 0.144 | Acc: 96.435% (30921/32064)
Loss: 0.145 | Acc: 96.412% (37084/38464)
Loss: 0.147 | Acc: 96.371% (43236/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6250, Accuracy: 8765/10000 (87.65%)

Epoch: 143
Loss: 0.098 | Acc: 96.875% (62/64)
Loss: 0.138 | Acc: 96.457% (6235/6464)
Loss: 0.132 | Acc: 96.634% (12431/12864)
Loss: 0.133 | Acc: 96.678% (18624/19264)
Loss: 0.136 | Acc: 96.622% (24797/25664)
Loss: 0.134 | Acc: 96.647% (30989/32064)
Loss: 0.132 | Acc: 96.748% (37213/38464)
Loss: 0.132 | Acc: 96.721% (43393/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6111, Accuracy: 8838/10000 (88.38%)

Epoch: 144
Loss: 0.097 | Acc: 98.438% (63/64)
Loss: 0.115 | Acc: 97.014% (6271/6464)
Loss: 0.110 | Acc: 97.225% (12507/12864)
Loss: 0.114 | Acc: 97.135% (18712/19264)
Loss: 0.113 | Acc: 97.159% (24935/25664)
Loss: 0.113 | Acc: 97.174% (31158/32064)
Loss: 0.112 | Acc: 97.208% (37390/38464)
Loss: 0.112 | Acc: 97.192% (43604/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6120, Accuracy: 8848/10000 (88.48%)

Epoch: 145
Loss: 0.020 | Acc: 100.000% (64/64)
Loss: 0.103 | Acc: 97.277% (6288/6464)
Loss: 0.096 | Acc: 97.466% (12538/12864)
Loss: 0.095 | Acc: 97.451% (18773/19264)
Loss: 0.096 | Acc: 97.448% (25009/25664)
Loss: 0.096 | Acc: 97.464% (31251/32064)
Loss: 0.097 | Acc: 97.455% (37485/38464)
Loss: 0.098 | Acc: 97.461% (43725/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6194, Accuracy: 8809/10000 (88.09%)

Epoch: 146
Loss: 0.211 | Acc: 93.750% (60/64)
Loss: 0.086 | Acc: 97.865% (6326/6464)
Loss: 0.086 | Acc: 97.823% (12584/12864)
Loss: 0.091 | Acc: 97.602% (18802/19264)
Loss: 0.089 | Acc: 97.682% (25069/25664)
Loss: 0.091 | Acc: 97.661% (31314/32064)
Loss: 0.091 | Acc: 97.676% (37570/38464)
Loss: 0.091 | Acc: 97.689% (43827/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6134, Accuracy: 8841/10000 (88.41%)

Epoch: 147
Loss: 0.073 | Acc: 98.438% (63/64)
Loss: 0.086 | Acc: 97.772% (6320/6464)
Loss: 0.085 | Acc: 97.777% (12578/12864)
Loss: 0.085 | Acc: 97.809% (18842/19264)
Loss: 0.084 | Acc: 97.853% (25113/25664)
Loss: 0.083 | Acc: 97.867% (31380/32064)
Loss: 0.084 | Acc: 97.853% (37638/38464)
Loss: 0.084 | Acc: 97.845% (43897/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6155, Accuracy: 8845/10000 (88.45%)
torch.Size([100, 10])
Test set: Average loss: 0.6155, Accuracy: 8845/10000 (88.45%)

Epoch: 148
Loss: 0.033 | Acc: 100.000% (64/64)
Loss: 0.077 | Acc: 97.912% (6329/6464)
Loss: 0.081 | Acc: 97.847% (12587/12864)
Loss: 0.081 | Acc: 97.830% (18846/19264)
Loss: 0.080 | Acc: 97.911% (25128/25664)
Loss: 0.079 | Acc: 97.879% (31384/32064)
Loss: 0.079 | Acc: 97.897% (37655/38464)
Loss: 0.080 | Acc: 97.887% (43916/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6149, Accuracy: 8825/10000 (88.25%)
torch.Size([100, 10])
Test set: Average loss: 0.6149, Accuracy: 8825/10000 (88.25%)

Epoch: 149
Loss: 0.157 | Acc: 95.312% (61/64)
Loss: 0.080 | Acc: 97.896% (6328/6464)
Loss: 0.078 | Acc: 97.994% (12606/12864)
Loss: 0.079 | Acc: 97.965% (18872/19264)
Loss: 0.079 | Acc: 97.947% (25137/25664)
Loss: 0.079 | Acc: 97.938% (31403/32064)
Loss: 0.079 | Acc: 97.925% (37666/38464)
Loss: 0.079 | Acc: 97.958% (43948/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6148, Accuracy: 8837/10000 (88.37%)
torch.Size([100, 10])
Test set: Average loss: 0.6148, Accuracy: 8837/10000 (88.37%)

Epoch: 150
Loss: 0.056 | Acc: 98.438% (63/64)
Loss: 1.575 | Acc: 46.844% (3028/6464)
Loss: 1.228 | Acc: 60.191% (7743/12864)
Loss: 1.090 | Acc: 65.480% (12614/19264)
Loss: 0.999 | Acc: 68.773% (17650/25664)
Loss: 0.936 | Acc: 71.130% (22807/32064)
Loss: 0.893 | Acc: 72.736% (27977/38464)
Loss: 0.861 | Acc: 73.923% (33165/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5268, Accuracy: 5255/10000 (52.55%)

Epoch: 151
Loss: 0.581 | Acc: 79.688% (51/64)
Loss: 0.632 | Acc: 81.931% (5296/6464)
Loss: 0.624 | Acc: 82.315% (10589/12864)
Loss: 0.636 | Acc: 82.132% (15822/19264)
Loss: 0.633 | Acc: 82.255% (21110/25664)
Loss: 0.630 | Acc: 82.466% (26442/32064)
Loss: 0.627 | Acc: 82.641% (31787/38464)
Loss: 0.626 | Acc: 82.770% (37134/44864)
torch.Size([100, 10])
Test set: Average loss: 3.2284, Accuracy: 2689/10000 (26.89%)

Epoch: 152
Loss: 0.870 | Acc: 73.438% (47/64)
Loss: 0.608 | Acc: 83.385% (5390/6464)
Loss: 0.587 | Acc: 83.979% (10803/12864)
Loss: 0.597 | Acc: 83.773% (16138/19264)
Loss: 0.601 | Acc: 83.518% (21434/25664)
Loss: 0.603 | Acc: 83.508% (26776/32064)
Loss: 0.605 | Acc: 83.517% (32124/38464)
Loss: 0.602 | Acc: 83.666% (37536/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0512, Accuracy: 6915/10000 (69.15%)

Epoch: 153
Loss: 0.760 | Acc: 78.125% (50/64)
Loss: 0.605 | Acc: 83.400% (5391/6464)
Loss: 0.585 | Acc: 83.955% (10800/12864)
Loss: 0.587 | Acc: 83.944% (16171/19264)
Loss: 0.584 | Acc: 84.153% (21597/25664)
Loss: 0.586 | Acc: 84.163% (26986/32064)
Loss: 0.589 | Acc: 84.040% (32325/38464)
Loss: 0.588 | Acc: 84.090% (37726/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1627, Accuracy: 6533/10000 (65.33%)

Epoch: 154
Loss: 0.821 | Acc: 78.125% (50/64)
Loss: 0.594 | Acc: 83.663% (5408/6464)
Loss: 0.588 | Acc: 84.103% (10819/12864)
Loss: 0.588 | Acc: 84.048% (16191/19264)
Loss: 0.585 | Acc: 84.161% (21599/25664)
Loss: 0.584 | Acc: 84.232% (27008/32064)
Loss: 0.585 | Acc: 84.154% (32369/38464)
Loss: 0.583 | Acc: 84.221% (37785/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4376, Accuracy: 5786/10000 (57.86%)

Epoch: 155
Loss: 0.918 | Acc: 75.000% (48/64)
Loss: 0.594 | Acc: 84.251% (5446/6464)
Loss: 0.594 | Acc: 84.134% (10823/12864)
Loss: 0.584 | Acc: 84.422% (16263/19264)
Loss: 0.579 | Acc: 84.449% (21673/25664)
Loss: 0.574 | Acc: 84.628% (27135/32064)
Loss: 0.577 | Acc: 84.536% (32516/38464)
Loss: 0.583 | Acc: 84.344% (37840/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1394, Accuracy: 6607/10000 (66.07%)

Epoch: 156
Loss: 0.585 | Acc: 84.375% (54/64)
Loss: 0.556 | Acc: 84.592% (5468/6464)
Loss: 0.556 | Acc: 84.810% (10910/12864)
Loss: 0.559 | Acc: 84.712% (16319/19264)
Loss: 0.564 | Acc: 84.620% (21717/25664)
Loss: 0.563 | Acc: 84.640% (27139/32064)
Loss: 0.569 | Acc: 84.541% (32518/38464)
Loss: 0.571 | Acc: 84.475% (37899/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3387, Accuracy: 6217/10000 (62.17%)

Epoch: 157
Loss: 0.752 | Acc: 78.125% (50/64)
Loss: 0.562 | Acc: 84.855% (5485/6464)
Loss: 0.546 | Acc: 85.238% (10965/12864)
Loss: 0.562 | Acc: 84.759% (16328/19264)
Loss: 0.567 | Acc: 84.710% (21740/25664)
Loss: 0.568 | Acc: 84.662% (27146/32064)
Loss: 0.568 | Acc: 84.729% (32590/38464)
Loss: 0.570 | Acc: 84.642% (37974/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7993, Accuracy: 7752/10000 (77.52%)

Epoch: 158
Loss: 0.598 | Acc: 84.375% (54/64)
Loss: 0.563 | Acc: 85.365% (5518/6464)
Loss: 0.548 | Acc: 85.650% (11018/12864)
Loss: 0.559 | Acc: 85.232% (16419/19264)
Loss: 0.560 | Acc: 85.260% (21881/25664)
Loss: 0.566 | Acc: 85.011% (27258/32064)
Loss: 0.564 | Acc: 85.048% (32713/38464)
Loss: 0.565 | Acc: 85.030% (38148/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9828, Accuracy: 7168/10000 (71.68%)

Epoch: 159
Loss: 0.438 | Acc: 87.500% (56/64)
Loss: 0.553 | Acc: 85.118% (5502/6464)
Loss: 0.553 | Acc: 85.075% (10944/12864)
Loss: 0.553 | Acc: 85.195% (16412/19264)
Loss: 0.556 | Acc: 85.104% (21841/25664)
Loss: 0.554 | Acc: 85.189% (27315/32064)
Loss: 0.558 | Acc: 85.069% (32721/38464)
Loss: 0.562 | Acc: 84.941% (38108/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6560, Accuracy: 5669/10000 (56.69%)

Epoch: 160
Loss: 0.813 | Acc: 75.000% (48/64)
Loss: 0.570 | Acc: 84.963% (5492/6464)
Loss: 0.580 | Acc: 84.663% (10891/12864)
Loss: 0.565 | Acc: 84.941% (16363/19264)
Loss: 0.563 | Acc: 84.998% (21814/25664)
Loss: 0.557 | Acc: 85.205% (27320/32064)
Loss: 0.561 | Acc: 85.069% (32721/38464)
Loss: 0.561 | Acc: 85.037% (38151/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8252, Accuracy: 5387/10000 (53.87%)

Epoch: 161
Loss: 1.137 | Acc: 70.312% (45/64)
Loss: 0.539 | Acc: 85.829% (5548/6464)
Loss: 0.543 | Acc: 85.759% (11032/12864)
Loss: 0.547 | Acc: 85.777% (16524/19264)
Loss: 0.549 | Acc: 85.626% (21975/25664)
Loss: 0.557 | Acc: 85.463% (27403/32064)
Loss: 0.558 | Acc: 85.425% (32858/38464)
Loss: 0.560 | Acc: 85.345% (38289/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0761, Accuracy: 6968/10000 (69.68%)

Epoch: 162
Loss: 0.655 | Acc: 87.500% (56/64)
Loss: 0.533 | Acc: 85.659% (5537/6464)
Loss: 0.536 | Acc: 85.759% (11032/12864)
Loss: 0.538 | Acc: 85.745% (16518/19264)
Loss: 0.543 | Acc: 85.599% (21968/25664)
Loss: 0.547 | Acc: 85.504% (27416/32064)
Loss: 0.548 | Acc: 85.472% (32876/38464)
Loss: 0.550 | Acc: 85.356% (38294/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7026, Accuracy: 8125/10000 (81.25%)

Epoch: 163
Loss: 0.453 | Acc: 84.375% (54/64)
Loss: 0.518 | Acc: 86.231% (5574/6464)
Loss: 0.538 | Acc: 85.510% (11000/12864)
Loss: 0.545 | Acc: 85.361% (16444/19264)
Loss: 0.549 | Acc: 85.353% (21905/25664)
Loss: 0.549 | Acc: 85.348% (27366/32064)
Loss: 0.547 | Acc: 85.431% (32860/38464)
Loss: 0.549 | Acc: 85.436% (38330/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1902, Accuracy: 6632/10000 (66.32%)

Epoch: 164
Loss: 0.598 | Acc: 89.062% (57/64)
Loss: 0.538 | Acc: 85.829% (5548/6464)
Loss: 0.524 | Acc: 86.015% (11065/12864)
Loss: 0.533 | Acc: 85.797% (16528/19264)
Loss: 0.543 | Acc: 85.486% (21939/25664)
Loss: 0.541 | Acc: 85.579% (27440/32064)
Loss: 0.541 | Acc: 85.613% (32930/38464)
Loss: 0.542 | Acc: 85.619% (38412/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8339, Accuracy: 7723/10000 (77.23%)

Epoch: 165
Loss: 0.417 | Acc: 90.625% (58/64)
Loss: 0.533 | Acc: 86.278% (5577/6464)
Loss: 0.537 | Acc: 86.109% (11077/12864)
Loss: 0.532 | Acc: 86.296% (16624/19264)
Loss: 0.532 | Acc: 86.280% (22143/25664)
Loss: 0.529 | Acc: 86.327% (27680/32064)
Loss: 0.528 | Acc: 86.281% (33187/38464)
Loss: 0.528 | Acc: 86.290% (38713/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1516, Accuracy: 4706/10000 (47.06%)

Epoch: 166
Loss: 1.188 | Acc: 71.875% (46/64)
Loss: 0.519 | Acc: 86.433% (5587/6464)
Loss: 0.516 | Acc: 86.419% (11117/12864)
Loss: 0.521 | Acc: 86.244% (16614/19264)
Loss: 0.524 | Acc: 86.199% (22122/25664)
Loss: 0.523 | Acc: 86.134% (27618/32064)
Loss: 0.528 | Acc: 85.974% (33069/38464)
Loss: 0.530 | Acc: 85.958% (38564/44864)
torch.Size([100, 10])
Test set: Average loss: 3.2987, Accuracy: 3716/10000 (37.16%)

Epoch: 167
Loss: 0.689 | Acc: 82.812% (53/64)
Loss: 0.514 | Acc: 86.525% (5593/6464)
Loss: 0.510 | Acc: 86.676% (11150/12864)
Loss: 0.514 | Acc: 86.711% (16704/19264)
Loss: 0.509 | Acc: 86.892% (22300/25664)
Loss: 0.514 | Acc: 86.714% (27804/32064)
Loss: 0.517 | Acc: 86.632% (33322/38464)
Loss: 0.518 | Acc: 86.664% (38881/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9873, Accuracy: 7215/10000 (72.15%)

Epoch: 168
Loss: 0.386 | Acc: 89.062% (57/64)
Loss: 0.493 | Acc: 87.067% (5628/6464)
Loss: 0.502 | Acc: 86.777% (11163/12864)
Loss: 0.507 | Acc: 86.597% (16682/19264)
Loss: 0.512 | Acc: 86.417% (22178/25664)
Loss: 0.512 | Acc: 86.477% (27728/32064)
Loss: 0.517 | Acc: 86.392% (33230/38464)
Loss: 0.517 | Acc: 86.392% (38759/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6199, Accuracy: 8353/10000 (83.53%)

Epoch: 169
Loss: 0.446 | Acc: 85.938% (55/64)
Loss: 0.486 | Acc: 87.345% (5646/6464)
Loss: 0.492 | Acc: 87.220% (11220/12864)
Loss: 0.499 | Acc: 87.137% (16786/19264)
Loss: 0.499 | Acc: 87.161% (22369/25664)
Loss: 0.503 | Acc: 87.029% (27905/32064)
Loss: 0.506 | Acc: 86.985% (33458/38464)
Loss: 0.506 | Acc: 86.929% (39000/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6747, Accuracy: 5417/10000 (54.17%)

Epoch: 170
Loss: 0.934 | Acc: 76.562% (49/64)
Loss: 0.499 | Acc: 87.485% (5655/6464)
Loss: 0.499 | Acc: 87.313% (11232/12864)
Loss: 0.503 | Acc: 87.131% (16785/19264)
Loss: 0.504 | Acc: 87.157% (22368/25664)
Loss: 0.505 | Acc: 87.048% (27911/32064)
Loss: 0.502 | Acc: 87.118% (33509/38464)
Loss: 0.504 | Acc: 86.990% (39027/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1620, Accuracy: 6887/10000 (68.87%)

Epoch: 171
Loss: 0.764 | Acc: 81.250% (52/64)
Loss: 0.472 | Acc: 88.212% (5702/6464)
Loss: 0.469 | Acc: 88.044% (11326/12864)
Loss: 0.483 | Acc: 87.692% (16893/19264)
Loss: 0.485 | Acc: 87.648% (22494/25664)
Loss: 0.484 | Acc: 87.622% (28095/32064)
Loss: 0.485 | Acc: 87.588% (33690/38464)
Loss: 0.487 | Acc: 87.569% (39287/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2300, Accuracy: 6612/10000 (66.12%)

Epoch: 172
Loss: 1.142 | Acc: 71.875% (46/64)
Loss: 0.495 | Acc: 87.098% (5630/6464)
Loss: 0.484 | Acc: 87.655% (11276/12864)
Loss: 0.482 | Acc: 87.728% (16900/19264)
Loss: 0.479 | Acc: 87.742% (22518/25664)
Loss: 0.477 | Acc: 87.874% (28176/32064)
Loss: 0.476 | Acc: 87.825% (33781/38464)
Loss: 0.479 | Acc: 87.781% (39382/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5372, Accuracy: 5760/10000 (57.60%)

Epoch: 173
Loss: 0.447 | Acc: 92.188% (59/64)
Loss: 0.457 | Acc: 88.691% (5733/6464)
Loss: 0.462 | Acc: 88.308% (11360/12864)
Loss: 0.468 | Acc: 88.248% (17000/19264)
Loss: 0.467 | Acc: 88.155% (22624/25664)
Loss: 0.464 | Acc: 88.242% (28294/32064)
Loss: 0.467 | Acc: 88.166% (33912/38464)
Loss: 0.468 | Acc: 88.155% (39550/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3166, Accuracy: 4482/10000 (44.82%)

Epoch: 174
Loss: 0.644 | Acc: 85.938% (55/64)
Loss: 0.456 | Acc: 88.676% (5732/6464)
Loss: 0.457 | Acc: 88.441% (11377/12864)
Loss: 0.453 | Acc: 88.580% (17064/19264)
Loss: 0.461 | Acc: 88.431% (22695/25664)
Loss: 0.459 | Acc: 88.423% (28352/32064)
Loss: 0.460 | Acc: 88.350% (33983/38464)
Loss: 0.461 | Acc: 88.307% (39618/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8251, Accuracy: 7684/10000 (76.84%)

Epoch: 175
Loss: 0.431 | Acc: 84.375% (54/64)
Loss: 0.443 | Acc: 88.722% (5735/6464)
Loss: 0.435 | Acc: 89.086% (11460/12864)
Loss: 0.444 | Acc: 89.057% (17156/19264)
Loss: 0.449 | Acc: 88.848% (22802/25664)
Loss: 0.445 | Acc: 88.875% (28497/32064)
Loss: 0.451 | Acc: 88.745% (34135/38464)
Loss: 0.453 | Acc: 88.655% (39774/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7618, Accuracy: 7995/10000 (79.95%)

Epoch: 176
Loss: 0.474 | Acc: 92.188% (59/64)
Loss: 0.420 | Acc: 89.434% (5781/6464)
Loss: 0.434 | Acc: 89.226% (11478/12864)
Loss: 0.434 | Acc: 89.151% (17174/19264)
Loss: 0.442 | Acc: 89.000% (22841/25664)
Loss: 0.439 | Acc: 89.125% (28577/32064)
Loss: 0.435 | Acc: 89.260% (34333/38464)
Loss: 0.438 | Acc: 89.163% (40002/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9015, Accuracy: 7490/10000 (74.90%)

Epoch: 177
Loss: 0.379 | Acc: 90.625% (58/64)
Loss: 0.431 | Acc: 89.124% (5761/6464)
Loss: 0.432 | Acc: 89.164% (11470/12864)
Loss: 0.420 | Acc: 89.608% (17262/19264)
Loss: 0.426 | Acc: 89.503% (22970/25664)
Loss: 0.426 | Acc: 89.496% (28696/32064)
Loss: 0.428 | Acc: 89.395% (34385/38464)
Loss: 0.426 | Acc: 89.457% (40134/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9103, Accuracy: 5321/10000 (53.21%)

Epoch: 178
Loss: 0.494 | Acc: 84.375% (54/64)
Loss: 0.390 | Acc: 90.145% (5827/6464)
Loss: 0.392 | Acc: 90.392% (11628/12864)
Loss: 0.398 | Acc: 90.142% (17365/19264)
Loss: 0.403 | Acc: 90.064% (23114/25664)
Loss: 0.409 | Acc: 89.920% (28832/32064)
Loss: 0.408 | Acc: 89.965% (34604/38464)
Loss: 0.407 | Acc: 90.023% (40388/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7870, Accuracy: 7811/10000 (78.11%)

Epoch: 179
Loss: 0.467 | Acc: 89.062% (57/64)
Loss: 0.405 | Acc: 90.176% (5829/6464)
Loss: 0.402 | Acc: 90.127% (11594/12864)
Loss: 0.393 | Acc: 90.438% (17422/19264)
Loss: 0.394 | Acc: 90.418% (23205/25664)
Loss: 0.395 | Acc: 90.379% (28979/32064)
Loss: 0.397 | Acc: 90.326% (34743/38464)
Loss: 0.397 | Acc: 90.326% (40524/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6360, Accuracy: 8373/10000 (83.73%)

Epoch: 180
Loss: 0.313 | Acc: 89.062% (57/64)
Loss: 0.382 | Acc: 90.532% (5852/6464)
Loss: 0.386 | Acc: 90.617% (11657/12864)
Loss: 0.384 | Acc: 90.744% (17481/19264)
Loss: 0.378 | Acc: 90.886% (23325/25664)
Loss: 0.382 | Acc: 90.828% (29123/32064)
Loss: 0.383 | Acc: 90.817% (34932/38464)
Loss: 0.383 | Acc: 90.812% (40742/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5515, Accuracy: 8636/10000 (86.36%)

Epoch: 181
Loss: 0.376 | Acc: 90.625% (58/64)
Loss: 0.362 | Acc: 91.491% (5914/6464)
Loss: 0.361 | Acc: 91.379% (11755/12864)
Loss: 0.365 | Acc: 91.284% (17585/19264)
Loss: 0.365 | Acc: 91.252% (23419/25664)
Loss: 0.362 | Acc: 91.358% (29293/32064)
Loss: 0.366 | Acc: 91.296% (35116/38464)
Loss: 0.367 | Acc: 91.276% (40950/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8293, Accuracy: 7884/10000 (78.84%)

Epoch: 182
Loss: 0.382 | Acc: 90.625% (58/64)
Loss: 0.368 | Acc: 90.996% (5882/6464)
Loss: 0.352 | Acc: 91.480% (11768/12864)
Loss: 0.355 | Acc: 91.440% (17615/19264)
Loss: 0.354 | Acc: 91.482% (23478/25664)
Loss: 0.356 | Acc: 91.461% (29326/32064)
Loss: 0.355 | Acc: 91.434% (35169/38464)
Loss: 0.354 | Acc: 91.483% (41043/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6038, Accuracy: 8493/10000 (84.93%)

Epoch: 183
Loss: 0.407 | Acc: 90.625% (58/64)
Loss: 0.326 | Acc: 92.218% (5961/6464)
Loss: 0.336 | Acc: 91.915% (11824/12864)
Loss: 0.337 | Acc: 91.933% (17710/19264)
Loss: 0.341 | Acc: 91.891% (23583/25664)
Loss: 0.340 | Acc: 91.929% (29476/32064)
Loss: 0.340 | Acc: 91.881% (35341/38464)
Loss: 0.339 | Acc: 91.924% (41241/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5558, Accuracy: 8652/10000 (86.52%)

Epoch: 184
Loss: 0.386 | Acc: 89.062% (57/64)
Loss: 0.315 | Acc: 92.760% (5996/6464)
Loss: 0.313 | Acc: 92.537% (11904/12864)
Loss: 0.323 | Acc: 92.354% (17791/19264)
Loss: 0.321 | Acc: 92.413% (23717/25664)
Loss: 0.317 | Acc: 92.456% (29645/32064)
Loss: 0.323 | Acc: 92.323% (35511/38464)
Loss: 0.323 | Acc: 92.359% (41436/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5910, Accuracy: 8595/10000 (85.95%)

Epoch: 185
Loss: 0.219 | Acc: 93.750% (60/64)
Loss: 0.280 | Acc: 93.394% (6037/6464)
Loss: 0.291 | Acc: 93.128% (11980/12864)
Loss: 0.287 | Acc: 93.205% (17955/19264)
Loss: 0.299 | Acc: 92.881% (23837/25664)
Loss: 0.301 | Acc: 92.861% (29775/32064)
Loss: 0.301 | Acc: 92.856% (35716/38464)
Loss: 0.303 | Acc: 92.825% (41645/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5839, Accuracy: 8630/10000 (86.30%)

Epoch: 186
Loss: 0.160 | Acc: 95.312% (61/64)
Loss: 0.269 | Acc: 93.796% (6063/6464)
Loss: 0.266 | Acc: 93.742% (12059/12864)
Loss: 0.264 | Acc: 93.817% (18073/19264)
Loss: 0.274 | Acc: 93.618% (24026/25664)
Loss: 0.279 | Acc: 93.494% (29978/32064)
Loss: 0.283 | Acc: 93.360% (35910/38464)
Loss: 0.281 | Acc: 93.362% (41886/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5611, Accuracy: 8722/10000 (87.22%)

Epoch: 187
Loss: 0.237 | Acc: 93.750% (60/64)
Loss: 0.251 | Acc: 94.059% (6080/6464)
Loss: 0.249 | Acc: 94.201% (12118/12864)
Loss: 0.260 | Acc: 93.906% (18090/19264)
Loss: 0.260 | Acc: 93.960% (24114/25664)
Loss: 0.263 | Acc: 93.903% (30109/32064)
Loss: 0.261 | Acc: 93.927% (36128/38464)
Loss: 0.261 | Acc: 93.919% (42136/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6018, Accuracy: 8644/10000 (86.44%)

Epoch: 188
Loss: 0.311 | Acc: 93.750% (60/64)
Loss: 0.247 | Acc: 94.261% (6093/6464)
Loss: 0.246 | Acc: 94.248% (12124/12864)
Loss: 0.244 | Acc: 94.311% (18168/19264)
Loss: 0.243 | Acc: 94.366% (24218/25664)
Loss: 0.241 | Acc: 94.392% (30266/32064)
Loss: 0.239 | Acc: 94.423% (36319/38464)
Loss: 0.238 | Acc: 94.450% (42374/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5607, Accuracy: 8791/10000 (87.91%)

Epoch: 189
Loss: 0.174 | Acc: 98.438% (63/64)
Loss: 0.195 | Acc: 95.529% (6175/6464)
Loss: 0.201 | Acc: 95.414% (12274/12864)
Loss: 0.207 | Acc: 95.188% (18337/19264)
Loss: 0.210 | Acc: 95.141% (24417/25664)
Loss: 0.214 | Acc: 95.022% (30468/32064)
Loss: 0.216 | Acc: 94.930% (36514/38464)
Loss: 0.217 | Acc: 94.925% (42587/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6261, Accuracy: 8654/10000 (86.54%)

Epoch: 190
Loss: 0.255 | Acc: 92.188% (59/64)
Loss: 0.184 | Acc: 95.730% (6188/6464)
Loss: 0.184 | Acc: 95.686% (12309/12864)
Loss: 0.188 | Acc: 95.546% (18406/19264)
Loss: 0.190 | Acc: 95.492% (24507/25664)
Loss: 0.188 | Acc: 95.521% (30628/32064)
Loss: 0.190 | Acc: 95.502% (36734/38464)
Loss: 0.190 | Acc: 95.511% (42850/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6229, Accuracy: 8704/10000 (87.04%)

Epoch: 191
Loss: 0.260 | Acc: 93.750% (60/64)
Loss: 0.162 | Acc: 96.225% (6220/6464)
Loss: 0.160 | Acc: 96.331% (12392/12864)
Loss: 0.161 | Acc: 96.252% (18542/19264)
Loss: 0.162 | Acc: 96.189% (24686/25664)
Loss: 0.164 | Acc: 96.111% (30817/32064)
Loss: 0.167 | Acc: 95.999% (36925/38464)
Loss: 0.168 | Acc: 95.972% (43057/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5918, Accuracy: 8753/10000 (87.53%)

Epoch: 192
Loss: 0.129 | Acc: 95.312% (61/64)
Loss: 0.143 | Acc: 96.550% (6241/6464)
Loss: 0.140 | Acc: 96.510% (12415/12864)
Loss: 0.141 | Acc: 96.460% (18582/19264)
Loss: 0.141 | Acc: 96.474% (24759/25664)
Loss: 0.142 | Acc: 96.466% (30931/32064)
Loss: 0.142 | Acc: 96.469% (37106/38464)
Loss: 0.146 | Acc: 96.407% (43252/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6012, Accuracy: 8800/10000 (88.00%)

Epoch: 193
Loss: 0.094 | Acc: 98.438% (63/64)
Loss: 0.129 | Acc: 96.983% (6269/6464)
Loss: 0.128 | Acc: 96.961% (12473/12864)
Loss: 0.130 | Acc: 96.917% (18670/19264)
Loss: 0.129 | Acc: 96.891% (24866/25664)
Loss: 0.127 | Acc: 96.947% (31085/32064)
Loss: 0.125 | Acc: 96.992% (37307/38464)
Loss: 0.124 | Acc: 97.011% (43523/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6014, Accuracy: 8833/10000 (88.33%)

Epoch: 194
Loss: 0.074 | Acc: 98.438% (63/64)
Loss: 0.105 | Acc: 97.107% (6277/6464)
Loss: 0.108 | Acc: 97.155% (12498/12864)
Loss: 0.107 | Acc: 97.249% (18734/19264)
Loss: 0.110 | Acc: 97.128% (24927/25664)
Loss: 0.109 | Acc: 97.202% (31167/32064)
Loss: 0.109 | Acc: 97.203% (37388/38464)
Loss: 0.107 | Acc: 97.276% (43642/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6185, Accuracy: 8821/10000 (88.21%)

Epoch: 195
Loss: 0.174 | Acc: 96.875% (62/64)
Loss: 0.099 | Acc: 97.571% (6307/6464)
Loss: 0.099 | Acc: 97.520% (12545/12864)
Loss: 0.101 | Acc: 97.462% (18775/19264)
Loss: 0.100 | Acc: 97.487% (25019/25664)
Loss: 0.098 | Acc: 97.542% (31276/32064)
Loss: 0.098 | Acc: 97.535% (37516/38464)
Loss: 0.099 | Acc: 97.533% (43757/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6157, Accuracy: 8846/10000 (88.46%)

Epoch: 196
Loss: 0.102 | Acc: 96.875% (62/64)
Loss: 0.085 | Acc: 97.881% (6327/6464)
Loss: 0.083 | Acc: 97.870% (12590/12864)
Loss: 0.088 | Acc: 97.711% (18823/19264)
Loss: 0.090 | Acc: 97.662% (25064/25664)
Loss: 0.087 | Acc: 97.748% (31342/32064)
Loss: 0.088 | Acc: 97.702% (37580/38464)
Loss: 0.087 | Acc: 97.726% (43844/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6199, Accuracy: 8822/10000 (88.22%)

Epoch: 197
Loss: 0.035 | Acc: 100.000% (64/64)
Loss: 0.081 | Acc: 97.973% (6333/6464)
Loss: 0.084 | Acc: 97.854% (12588/12864)
Loss: 0.084 | Acc: 97.830% (18846/19264)
Loss: 0.082 | Acc: 97.869% (25117/25664)
Loss: 0.083 | Acc: 97.842% (31372/32064)
Loss: 0.083 | Acc: 97.860% (37641/38464)
Loss: 0.082 | Acc: 97.882% (43914/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6165, Accuracy: 8836/10000 (88.36%)
torch.Size([100, 10])
Test set: Average loss: 0.6165, Accuracy: 8836/10000 (88.36%)

Epoch: 198
Loss: 0.023 | Acc: 100.000% (64/64)
Loss: 0.082 | Acc: 97.865% (6326/6464)
Loss: 0.080 | Acc: 97.862% (12589/12864)
Loss: 0.077 | Acc: 97.924% (18864/19264)
Loss: 0.079 | Acc: 97.892% (25123/25664)
Loss: 0.079 | Acc: 97.895% (31389/32064)
Loss: 0.080 | Acc: 97.899% (37656/38464)
Loss: 0.078 | Acc: 97.938% (43939/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6188, Accuracy: 8841/10000 (88.41%)
torch.Size([100, 10])
Test set: Average loss: 0.6188, Accuracy: 8841/10000 (88.41%)

Epoch: 199
Loss: 0.019 | Acc: 100.000% (64/64)
Loss: 0.079 | Acc: 97.958% (6332/6464)
Loss: 0.078 | Acc: 97.971% (12603/12864)
Loss: 0.078 | Acc: 97.939% (18867/19264)
Loss: 0.075 | Acc: 97.993% (25149/25664)
Loss: 0.075 | Acc: 97.988% (31419/32064)
Loss: 0.075 | Acc: 98.024% (37704/38464)
Loss: 0.075 | Acc: 98.014% (43973/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6217, Accuracy: 8845/10000 (88.45%)
torch.Size([100, 10])
Test set: Average loss: 0.6217, Accuracy: 8845/10000 (88.45%)
9024
10000
-0.49250131845474243
