==> Preparing data..
Files already downloaded and verified
Files already downloaded and verified
==> Building model..

Epoch: 0
Loss: 2.361 | Acc: 15.625% (10/64)
Loss: 2.908 | Acc: 16.832% (1088/6464)
Loss: 2.472 | Acc: 19.846% (2553/12864)
Loss: 2.293 | Acc: 21.911% (4221/19264)
Loss: 2.190 | Acc: 23.773% (6101/25664)
Loss: 2.116 | Acc: 25.306% (8114/32064)
Loss: 2.058 | Acc: 26.830% (10320/38464)
Loss: 2.004 | Acc: 28.308% (12700/44864)
torch.Size([100, 10])
Test set: Average loss: 2.9226, Accuracy: 2390/10000 (23.90%)

Epoch: 1
Loss: 2.071 | Acc: 40.625% (26/64)
Loss: 1.599 | Acc: 40.377% (2610/6464)
Loss: 1.582 | Acc: 41.169% (5296/12864)
Loss: 1.569 | Acc: 41.632% (8020/19264)
Loss: 1.553 | Acc: 42.413% (10885/25664)
Loss: 1.533 | Acc: 43.263% (13872/32064)
Loss: 1.516 | Acc: 43.844% (16864/38464)
Loss: 1.496 | Acc: 44.650% (20032/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3513, Accuracy: 3123/10000 (31.23%)

Epoch: 2
Loss: 1.579 | Acc: 53.125% (34/64)
Loss: 1.304 | Acc: 51.748% (3345/6464)
Loss: 1.304 | Acc: 52.114% (6704/12864)
Loss: 1.278 | Acc: 53.135% (10236/19264)
Loss: 1.255 | Acc: 54.259% (13925/25664)
Loss: 1.237 | Acc: 55.155% (17685/32064)
Loss: 1.221 | Acc: 55.824% (21472/38464)
Loss: 1.205 | Acc: 56.451% (25326/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2931, Accuracy: 5473/10000 (54.73%)

Epoch: 3
Loss: 1.063 | Acc: 62.500% (40/64)
Loss: 1.059 | Acc: 61.711% (3989/6464)
Loss: 1.056 | Acc: 62.034% (7980/12864)
Loss: 1.038 | Acc: 62.630% (12065/19264)
Loss: 1.025 | Acc: 63.116% (16198/25664)
Loss: 1.014 | Acc: 63.523% (20368/32064)
Loss: 1.003 | Acc: 63.992% (24614/38464)
Loss: 0.994 | Acc: 64.366% (28877/44864)
torch.Size([100, 10])
Test set: Average loss: 1.8215, Accuracy: 4685/10000 (46.85%)

Epoch: 4
Loss: 1.418 | Acc: 57.812% (37/64)
Loss: 0.903 | Acc: 68.007% (4396/6464)
Loss: 0.892 | Acc: 68.455% (8806/12864)
Loss: 0.884 | Acc: 68.968% (13286/19264)
Loss: 0.872 | Acc: 69.420% (17816/25664)
Loss: 0.863 | Acc: 69.770% (22371/32064)
Loss: 0.852 | Acc: 70.125% (26973/38464)
Loss: 0.844 | Acc: 70.480% (31620/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4139, Accuracy: 5540/10000 (55.40%)

Epoch: 5
Loss: 1.045 | Acc: 68.750% (44/64)
Loss: 0.746 | Acc: 73.391% (4744/6464)
Loss: 0.742 | Acc: 73.881% (9504/12864)
Loss: 0.735 | Acc: 74.310% (14315/19264)
Loss: 0.735 | Acc: 74.341% (19079/25664)
Loss: 0.727 | Acc: 74.644% (23934/32064)
Loss: 0.724 | Acc: 74.810% (28775/38464)
Loss: 0.719 | Acc: 74.922% (33613/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0576, Accuracy: 6627/10000 (66.27%)

Epoch: 6
Loss: 0.758 | Acc: 78.125% (50/64)
Loss: 0.648 | Acc: 77.135% (4986/6464)
Loss: 0.652 | Acc: 77.060% (9913/12864)
Loss: 0.650 | Acc: 77.030% (14839/19264)
Loss: 0.643 | Acc: 77.260% (19828/25664)
Loss: 0.641 | Acc: 77.392% (24815/32064)
Loss: 0.640 | Acc: 77.488% (29805/38464)
Loss: 0.638 | Acc: 77.690% (34855/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1023, Accuracy: 6611/10000 (66.11%)

Epoch: 7
Loss: 0.639 | Acc: 70.312% (45/64)
Loss: 0.582 | Acc: 79.672% (5150/6464)
Loss: 0.590 | Acc: 79.415% (10216/12864)
Loss: 0.582 | Acc: 79.682% (15350/19264)
Loss: 0.581 | Acc: 79.719% (20459/25664)
Loss: 0.579 | Acc: 79.906% (25621/32064)
Loss: 0.581 | Acc: 79.924% (30742/38464)
Loss: 0.581 | Acc: 79.922% (35856/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3633, Accuracy: 6648/10000 (66.48%)

Epoch: 8
Loss: 0.931 | Acc: 76.562% (49/64)
Loss: 0.558 | Acc: 81.018% (5237/6464)
Loss: 0.543 | Acc: 81.242% (10451/12864)
Loss: 0.540 | Acc: 81.478% (15696/19264)
Loss: 0.539 | Acc: 81.538% (20926/25664)
Loss: 0.539 | Acc: 81.556% (26150/32064)
Loss: 0.542 | Acc: 81.411% (31314/38464)
Loss: 0.541 | Acc: 81.373% (36507/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9764, Accuracy: 6848/10000 (68.48%)

Epoch: 9
Loss: 0.550 | Acc: 79.688% (51/64)
Loss: 0.512 | Acc: 82.410% (5327/6464)
Loss: 0.508 | Acc: 82.649% (10632/12864)
Loss: 0.519 | Acc: 82.164% (15828/19264)
Loss: 0.517 | Acc: 82.193% (21094/25664)
Loss: 0.514 | Acc: 82.401% (26421/32064)
Loss: 0.517 | Acc: 82.267% (31643/38464)
Loss: 0.513 | Acc: 82.445% (36988/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8141, Accuracy: 7269/10000 (72.69%)

Epoch: 10
Loss: 0.627 | Acc: 73.438% (47/64)
Loss: 0.490 | Acc: 83.014% (5366/6464)
Loss: 0.482 | Acc: 83.318% (10718/12864)
Loss: 0.491 | Acc: 83.072% (16003/19264)
Loss: 0.489 | Acc: 83.105% (21328/25664)
Loss: 0.485 | Acc: 83.283% (26704/32064)
Loss: 0.488 | Acc: 83.262% (32026/38464)
Loss: 0.488 | Acc: 83.225% (37338/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6804, Accuracy: 7752/10000 (77.52%)

Epoch: 11
Loss: 0.675 | Acc: 79.688% (51/64)
Loss: 0.456 | Acc: 84.251% (5446/6464)
Loss: 0.465 | Acc: 84.017% (10808/12864)
Loss: 0.460 | Acc: 84.147% (16210/19264)
Loss: 0.466 | Acc: 83.954% (21546/25664)
Loss: 0.466 | Acc: 83.998% (26933/32064)
Loss: 0.466 | Acc: 84.027% (32320/38464)
Loss: 0.466 | Acc: 84.074% (37719/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7545, Accuracy: 7685/10000 (76.85%)

Epoch: 12
Loss: 0.497 | Acc: 87.500% (56/64)
Loss: 0.436 | Acc: 85.365% (5518/6464)
Loss: 0.432 | Acc: 85.518% (11001/12864)
Loss: 0.436 | Acc: 85.216% (16416/19264)
Loss: 0.440 | Acc: 85.069% (21832/25664)
Loss: 0.441 | Acc: 84.993% (27252/32064)
Loss: 0.442 | Acc: 84.970% (32683/38464)
Loss: 0.444 | Acc: 84.903% (38091/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4816, Accuracy: 5745/10000 (57.45%)

Epoch: 13
Loss: 0.836 | Acc: 70.312% (45/64)
Loss: 0.443 | Acc: 85.133% (5503/6464)
Loss: 0.436 | Acc: 85.409% (10987/12864)
Loss: 0.436 | Acc: 85.346% (16441/19264)
Loss: 0.435 | Acc: 85.279% (21886/25664)
Loss: 0.428 | Acc: 85.442% (27396/32064)
Loss: 0.426 | Acc: 85.493% (32884/38464)
Loss: 0.424 | Acc: 85.570% (38390/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5465, Accuracy: 5685/10000 (56.85%)

Epoch: 14
Loss: 0.570 | Acc: 81.250% (52/64)
Loss: 0.433 | Acc: 85.582% (5532/6464)
Loss: 0.420 | Acc: 85.712% (11026/12864)
Loss: 0.418 | Acc: 85.642% (16498/19264)
Loss: 0.416 | Acc: 85.669% (21986/25664)
Loss: 0.411 | Acc: 85.828% (27520/32064)
Loss: 0.413 | Acc: 85.776% (32993/38464)
Loss: 0.414 | Acc: 85.706% (38451/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0164, Accuracy: 6911/10000 (69.11%)

Epoch: 15
Loss: 0.800 | Acc: 75.000% (48/64)
Loss: 0.391 | Acc: 87.191% (5636/6464)
Loss: 0.386 | Acc: 86.925% (11182/12864)
Loss: 0.394 | Acc: 86.519% (16667/19264)
Loss: 0.390 | Acc: 86.674% (22244/25664)
Loss: 0.392 | Acc: 86.596% (27766/32064)
Loss: 0.392 | Acc: 86.590% (33306/38464)
Loss: 0.392 | Acc: 86.506% (38810/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5225, Accuracy: 8211/10000 (82.11%)

Epoch: 16
Loss: 0.397 | Acc: 82.812% (53/64)
Loss: 0.365 | Acc: 87.562% (5660/6464)
Loss: 0.369 | Acc: 87.251% (11224/12864)
Loss: 0.369 | Acc: 87.381% (16833/19264)
Loss: 0.379 | Acc: 87.032% (22336/25664)
Loss: 0.378 | Acc: 87.085% (27923/32064)
Loss: 0.379 | Acc: 87.133% (33515/38464)
Loss: 0.380 | Acc: 87.019% (39040/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1282, Accuracy: 6827/10000 (68.27%)

Epoch: 17
Loss: 0.391 | Acc: 87.500% (56/64)
Loss: 0.356 | Acc: 87.639% (5665/6464)
Loss: 0.370 | Acc: 87.088% (11203/12864)
Loss: 0.369 | Acc: 87.085% (16776/19264)
Loss: 0.369 | Acc: 87.087% (22350/25664)
Loss: 0.366 | Acc: 87.269% (27982/32064)
Loss: 0.367 | Acc: 87.230% (33552/38464)
Loss: 0.367 | Acc: 87.233% (39136/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5643, Accuracy: 8224/10000 (82.24%)

Epoch: 18
Loss: 0.671 | Acc: 81.250% (52/64)
Loss: 0.345 | Acc: 88.103% (5695/6464)
Loss: 0.350 | Acc: 87.920% (11310/12864)
Loss: 0.344 | Acc: 88.196% (16990/19264)
Loss: 0.344 | Acc: 88.166% (22627/25664)
Loss: 0.348 | Acc: 87.990% (28213/32064)
Loss: 0.350 | Acc: 87.877% (33801/38464)
Loss: 0.352 | Acc: 87.845% (39411/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6478, Accuracy: 7988/10000 (79.88%)

Epoch: 19
Loss: 0.289 | Acc: 90.625% (58/64)
Loss: 0.320 | Acc: 89.047% (5756/6464)
Loss: 0.331 | Acc: 88.798% (11423/12864)
Loss: 0.330 | Acc: 88.767% (17100/19264)
Loss: 0.332 | Acc: 88.653% (22752/25664)
Loss: 0.333 | Acc: 88.666% (28430/32064)
Loss: 0.334 | Acc: 88.584% (34073/38464)
Loss: 0.337 | Acc: 88.503% (39706/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7495, Accuracy: 7692/10000 (76.92%)

Epoch: 20
Loss: 0.311 | Acc: 87.500% (56/64)
Loss: 0.311 | Acc: 89.511% (5786/6464)
Loss: 0.315 | Acc: 89.187% (11473/12864)
Loss: 0.322 | Acc: 89.005% (17146/19264)
Loss: 0.324 | Acc: 88.930% (22823/25664)
Loss: 0.325 | Acc: 88.878% (28498/32064)
Loss: 0.325 | Acc: 88.844% (34173/38464)
Loss: 0.322 | Acc: 88.971% (39916/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4091, Accuracy: 5254/10000 (52.54%)

Epoch: 21
Loss: 0.688 | Acc: 78.125% (50/64)
Loss: 0.339 | Acc: 88.459% (5718/6464)
Loss: 0.329 | Acc: 88.588% (11396/12864)
Loss: 0.320 | Acc: 88.969% (17139/19264)
Loss: 0.321 | Acc: 88.942% (22826/25664)
Loss: 0.318 | Acc: 89.097% (28568/32064)
Loss: 0.317 | Acc: 89.117% (34278/38464)
Loss: 0.315 | Acc: 89.203% (40020/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0001, Accuracy: 7104/10000 (71.04%)

Epoch: 22
Loss: 0.513 | Acc: 82.812% (53/64)
Loss: 0.281 | Acc: 90.362% (5841/6464)
Loss: 0.299 | Acc: 89.715% (11541/12864)
Loss: 0.303 | Acc: 89.592% (17259/19264)
Loss: 0.300 | Acc: 89.670% (23013/25664)
Loss: 0.304 | Acc: 89.537% (28709/32064)
Loss: 0.303 | Acc: 89.666% (34489/38464)
Loss: 0.302 | Acc: 89.682% (40235/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6192, Accuracy: 8095/10000 (80.95%)

Epoch: 23
Loss: 0.438 | Acc: 84.375% (54/64)
Loss: 0.269 | Acc: 91.027% (5884/6464)
Loss: 0.278 | Acc: 90.625% (11658/12864)
Loss: 0.284 | Acc: 90.381% (17411/19264)
Loss: 0.288 | Acc: 90.317% (23179/25664)
Loss: 0.289 | Acc: 90.319% (28960/32064)
Loss: 0.288 | Acc: 90.331% (34745/38464)
Loss: 0.289 | Acc: 90.235% (40483/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0768, Accuracy: 6945/10000 (69.45%)

Epoch: 24
Loss: 0.357 | Acc: 87.500% (56/64)
Loss: 0.285 | Acc: 90.145% (5827/6464)
Loss: 0.281 | Acc: 90.345% (11622/12864)
Loss: 0.280 | Acc: 90.360% (17407/19264)
Loss: 0.279 | Acc: 90.376% (23194/25664)
Loss: 0.279 | Acc: 90.366% (28975/32064)
Loss: 0.279 | Acc: 90.308% (34736/38464)
Loss: 0.281 | Acc: 90.297% (40511/44864)
torch.Size([100, 10])
Test set: Average loss: 2.3637, Accuracy: 5389/10000 (53.89%)

Epoch: 25
Loss: 0.544 | Acc: 82.812% (53/64)
Loss: 0.266 | Acc: 90.934% (5878/6464)
Loss: 0.270 | Acc: 90.804% (11681/12864)
Loss: 0.270 | Acc: 90.791% (17490/19264)
Loss: 0.263 | Acc: 91.042% (23365/25664)
Loss: 0.260 | Acc: 91.105% (29212/32064)
Loss: 0.262 | Acc: 90.999% (35002/38464)
Loss: 0.265 | Acc: 90.859% (40763/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3163, Accuracy: 6862/10000 (68.62%)

Epoch: 26
Loss: 0.468 | Acc: 81.250% (52/64)
Loss: 0.266 | Acc: 90.811% (5870/6464)
Loss: 0.250 | Acc: 91.317% (11747/12864)
Loss: 0.245 | Acc: 91.445% (17616/19264)
Loss: 0.245 | Acc: 91.412% (23460/25664)
Loss: 0.249 | Acc: 91.383% (29301/32064)
Loss: 0.248 | Acc: 91.418% (35163/38464)
Loss: 0.248 | Acc: 91.490% (41046/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4643, Accuracy: 8487/10000 (84.87%)

Epoch: 27
Loss: 0.538 | Acc: 82.812% (53/64)
Loss: 0.243 | Acc: 91.801% (5934/6464)
Loss: 0.236 | Acc: 91.861% (11817/12864)
Loss: 0.239 | Acc: 91.866% (17697/19264)
Loss: 0.241 | Acc: 91.751% (23547/25664)
Loss: 0.242 | Acc: 91.710% (29406/32064)
Loss: 0.242 | Acc: 91.821% (35318/38464)
Loss: 0.239 | Acc: 91.853% (41209/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5913, Accuracy: 8277/10000 (82.77%)

Epoch: 28
Loss: 0.391 | Acc: 82.812% (53/64)
Loss: 0.227 | Acc: 92.079% (5952/6464)
Loss: 0.224 | Acc: 92.250% (11867/12864)
Loss: 0.224 | Acc: 92.286% (17778/19264)
Loss: 0.224 | Acc: 92.394% (23712/25664)
Loss: 0.221 | Acc: 92.496% (29658/32064)
Loss: 0.221 | Acc: 92.484% (35573/38464)
Loss: 0.220 | Acc: 92.491% (41495/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7534, Accuracy: 7802/10000 (78.02%)

Epoch: 29
Loss: 0.172 | Acc: 95.312% (61/64)
Loss: 0.211 | Acc: 93.162% (6022/6464)
Loss: 0.204 | Acc: 93.237% (11994/12864)
Loss: 0.200 | Acc: 93.200% (17954/19264)
Loss: 0.203 | Acc: 93.142% (23904/25664)
Loss: 0.204 | Acc: 93.061% (29839/32064)
Loss: 0.205 | Acc: 93.001% (35772/38464)
Loss: 0.206 | Acc: 92.968% (41709/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3408, Accuracy: 8856/10000 (88.56%)

Epoch: 30
Loss: 0.271 | Acc: 89.062% (57/64)
Loss: 0.187 | Acc: 93.472% (6042/6464)
Loss: 0.183 | Acc: 93.742% (12059/12864)
Loss: 0.192 | Acc: 93.397% (17992/19264)
Loss: 0.195 | Acc: 93.317% (23949/25664)
Loss: 0.197 | Acc: 93.217% (29889/32064)
Loss: 0.199 | Acc: 93.186% (35843/38464)
Loss: 0.198 | Acc: 93.213% (41819/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1129, Accuracy: 7251/10000 (72.51%)

Epoch: 31
Loss: 0.304 | Acc: 90.625% (58/64)
Loss: 0.168 | Acc: 94.446% (6105/6464)
Loss: 0.170 | Acc: 94.271% (12127/12864)
Loss: 0.175 | Acc: 94.056% (18119/19264)
Loss: 0.175 | Acc: 94.003% (24125/25664)
Loss: 0.176 | Acc: 94.024% (30148/32064)
Loss: 0.177 | Acc: 94.039% (36171/38464)
Loss: 0.178 | Acc: 93.975% (42161/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3472, Accuracy: 8894/10000 (88.94%)

Epoch: 32
Loss: 0.190 | Acc: 90.625% (58/64)
Loss: 0.145 | Acc: 95.019% (6142/6464)
Loss: 0.154 | Acc: 94.644% (12175/12864)
Loss: 0.159 | Acc: 94.378% (18181/19264)
Loss: 0.159 | Acc: 94.440% (24237/25664)
Loss: 0.161 | Acc: 94.371% (30259/32064)
Loss: 0.162 | Acc: 94.348% (36290/38464)
Loss: 0.162 | Acc: 94.381% (42343/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3350, Accuracy: 8927/10000 (89.27%)

Epoch: 33
Loss: 0.136 | Acc: 93.750% (60/64)
Loss: 0.136 | Acc: 95.405% (6167/6464)
Loss: 0.140 | Acc: 95.204% (12247/12864)
Loss: 0.139 | Acc: 95.261% (18351/19264)
Loss: 0.140 | Acc: 95.309% (24460/25664)
Loss: 0.140 | Acc: 95.322% (30564/32064)
Loss: 0.141 | Acc: 95.253% (36638/38464)
Loss: 0.144 | Acc: 95.136% (42682/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4136, Accuracy: 8776/10000 (87.76%)

Epoch: 34
Loss: 0.145 | Acc: 95.312% (61/64)
Loss: 0.133 | Acc: 95.637% (6182/6464)
Loss: 0.132 | Acc: 95.600% (12298/12864)
Loss: 0.129 | Acc: 95.598% (18416/19264)
Loss: 0.133 | Acc: 95.480% (24504/25664)
Loss: 0.131 | Acc: 95.546% (30636/32064)
Loss: 0.131 | Acc: 95.539% (36748/38464)
Loss: 0.132 | Acc: 95.464% (42829/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2811, Accuracy: 9105/10000 (91.05%)

Epoch: 35
Loss: 0.060 | Acc: 98.438% (63/64)
Loss: 0.119 | Acc: 95.715% (6187/6464)
Loss: 0.113 | Acc: 96.043% (12355/12864)
Loss: 0.107 | Acc: 96.247% (18541/19264)
Loss: 0.107 | Acc: 96.244% (24700/25664)
Loss: 0.108 | Acc: 96.189% (30842/32064)
Loss: 0.114 | Acc: 95.983% (36919/38464)
Loss: 0.115 | Acc: 95.952% (43048/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2922, Accuracy: 9095/10000 (90.95%)

Epoch: 36
Loss: 0.182 | Acc: 92.188% (59/64)
Loss: 0.100 | Acc: 96.736% (6253/6464)
Loss: 0.101 | Acc: 96.650% (12433/12864)
Loss: 0.099 | Acc: 96.693% (18627/19264)
Loss: 0.102 | Acc: 96.598% (24791/25664)
Loss: 0.102 | Acc: 96.557% (30960/32064)
Loss: 0.101 | Acc: 96.589% (37152/38464)
Loss: 0.101 | Acc: 96.567% (43324/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2809, Accuracy: 9160/10000 (91.60%)

Epoch: 37
Loss: 0.079 | Acc: 96.875% (62/64)
Loss: 0.076 | Acc: 97.478% (6301/6464)
Loss: 0.075 | Acc: 97.419% (12532/12864)
Loss: 0.077 | Acc: 97.327% (18749/19264)
Loss: 0.079 | Acc: 97.233% (24954/25664)
Loss: 0.084 | Acc: 97.078% (31127/32064)
Loss: 0.088 | Acc: 96.961% (37295/38464)
Loss: 0.087 | Acc: 96.991% (43514/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2793, Accuracy: 9171/10000 (91.71%)

Epoch: 38
Loss: 0.090 | Acc: 96.875% (62/64)
Loss: 0.070 | Acc: 97.819% (6323/6464)
Loss: 0.067 | Acc: 97.816% (12583/12864)
Loss: 0.065 | Acc: 97.872% (18854/19264)
Loss: 0.064 | Acc: 97.892% (25123/25664)
Loss: 0.068 | Acc: 97.773% (31350/32064)
Loss: 0.069 | Acc: 97.723% (37588/38464)
Loss: 0.069 | Acc: 97.695% (43830/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2647, Accuracy: 9226/10000 (92.26%)

Epoch: 39
Loss: 0.084 | Acc: 96.875% (62/64)
Loss: 0.057 | Acc: 98.004% (6335/6464)
Loss: 0.055 | Acc: 98.134% (12624/12864)
Loss: 0.055 | Acc: 98.178% (18913/19264)
Loss: 0.055 | Acc: 98.149% (25189/25664)
Loss: 0.058 | Acc: 98.101% (31455/32064)
Loss: 0.058 | Acc: 98.126% (37743/38464)
Loss: 0.057 | Acc: 98.114% (44018/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3648, Accuracy: 8931/10000 (89.31%)

Epoch: 40
Loss: 0.123 | Acc: 90.625% (58/64)
Loss: 0.047 | Acc: 98.515% (6368/6464)
Loss: 0.049 | Acc: 98.406% (12659/12864)
Loss: 0.048 | Acc: 98.484% (18972/19264)
Loss: 0.047 | Acc: 98.457% (25268/25664)
Loss: 0.047 | Acc: 98.456% (31569/32064)
Loss: 0.047 | Acc: 98.500% (37887/38464)
Loss: 0.047 | Acc: 98.504% (44193/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2295, Accuracy: 9337/10000 (93.37%)

Epoch: 41
Loss: 0.020 | Acc: 100.000% (64/64)
Loss: 0.033 | Acc: 99.041% (6402/6464)
Loss: 0.032 | Acc: 99.036% (12740/12864)
Loss: 0.032 | Acc: 99.029% (19077/19264)
Loss: 0.033 | Acc: 98.983% (25403/25664)
Loss: 0.033 | Acc: 98.933% (31722/32064)
Loss: 0.033 | Acc: 98.926% (38051/38464)
Loss: 0.034 | Acc: 98.908% (44374/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2405, Accuracy: 9318/10000 (93.18%)

Epoch: 42
Loss: 0.038 | Acc: 98.438% (63/64)
Loss: 0.025 | Acc: 99.335% (6421/6464)
Loss: 0.028 | Acc: 99.145% (12754/12864)
Loss: 0.028 | Acc: 99.123% (19095/19264)
Loss: 0.027 | Acc: 99.154% (25447/25664)
Loss: 0.027 | Acc: 99.167% (31797/32064)
Loss: 0.026 | Acc: 99.163% (38142/38464)
Loss: 0.025 | Acc: 99.206% (44508/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2325, Accuracy: 9337/10000 (93.37%)

Epoch: 43
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 0.022 | Acc: 99.412% (6426/6464)
Loss: 0.021 | Acc: 99.370% (12783/12864)
Loss: 0.019 | Acc: 99.439% (19156/19264)
Loss: 0.019 | Acc: 99.478% (25530/25664)
Loss: 0.018 | Acc: 99.482% (31898/32064)
Loss: 0.018 | Acc: 99.470% (38260/38464)
Loss: 0.018 | Acc: 99.470% (44626/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2354, Accuracy: 9358/10000 (93.58%)

Epoch: 44
Loss: 0.010 | Acc: 100.000% (64/64)
Loss: 0.015 | Acc: 99.675% (6443/6464)
Loss: 0.014 | Acc: 99.720% (12828/12864)
Loss: 0.014 | Acc: 99.678% (19202/19264)
Loss: 0.014 | Acc: 99.677% (25581/25664)
Loss: 0.015 | Acc: 99.641% (31949/32064)
Loss: 0.015 | Acc: 99.633% (38323/38464)
Loss: 0.015 | Acc: 99.641% (44703/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2163, Accuracy: 9418/10000 (94.18%)

Epoch: 45
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.012 | Acc: 99.629% (6440/6464)
Loss: 0.012 | Acc: 99.642% (12818/12864)
Loss: 0.012 | Acc: 99.657% (19198/19264)
Loss: 0.012 | Acc: 99.669% (25579/25664)
Loss: 0.012 | Acc: 99.685% (31963/32064)
Loss: 0.012 | Acc: 99.683% (38342/38464)
Loss: 0.012 | Acc: 99.701% (44730/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2134, Accuracy: 9428/10000 (94.28%)

Epoch: 46
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.783% (6450/6464)
Loss: 0.010 | Acc: 99.743% (12831/12864)
Loss: 0.011 | Acc: 99.725% (19211/19264)
Loss: 0.011 | Acc: 99.739% (25597/25664)
Loss: 0.011 | Acc: 99.744% (31982/32064)
Loss: 0.011 | Acc: 99.740% (38364/38464)
Loss: 0.011 | Acc: 99.741% (44748/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2045, Accuracy: 9430/10000 (94.30%)

Epoch: 47
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.814% (6452/6464)
Loss: 0.009 | Acc: 99.813% (12840/12864)
Loss: 0.009 | Acc: 99.818% (19229/19264)
Loss: 0.009 | Acc: 99.821% (25618/25664)
Loss: 0.009 | Acc: 99.835% (32011/32064)
Loss: 0.009 | Acc: 99.815% (38393/38464)
Loss: 0.009 | Acc: 99.815% (44781/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2099, Accuracy: 9423/10000 (94.23%)
torch.Size([100, 10])
Test set: Average loss: 0.2099, Accuracy: 9423/10000 (94.23%)

Epoch: 48
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.969% (6462/6464)
Loss: 0.009 | Acc: 99.837% (12843/12864)
Loss: 0.009 | Acc: 99.824% (19230/19264)
Loss: 0.009 | Acc: 99.821% (25618/25664)
Loss: 0.010 | Acc: 99.816% (32005/32064)
Loss: 0.010 | Acc: 99.810% (38391/38464)
Loss: 0.010 | Acc: 99.808% (44778/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2041, Accuracy: 9440/10000 (94.40%)
torch.Size([100, 10])
Test set: Average loss: 0.2041, Accuracy: 9440/10000 (94.40%)

Epoch: 49
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.907% (6458/6464)
Loss: 0.010 | Acc: 99.852% (12845/12864)
Loss: 0.011 | Acc: 99.772% (19220/19264)
Loss: 0.010 | Acc: 99.793% (25611/25664)
Loss: 0.010 | Acc: 99.810% (32003/32064)
Loss: 0.010 | Acc: 99.813% (38392/38464)
Loss: 0.010 | Acc: 99.802% (44775/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2068, Accuracy: 9425/10000 (94.25%)
torch.Size([100, 10])
Test set: Average loss: 0.2068, Accuracy: 9425/10000 (94.25%)

Epoch: 50
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 1.953 | Acc: 29.100% (1881/6464)
Loss: 1.725 | Acc: 36.886% (4745/12864)
Loss: 1.510 | Acc: 45.328% (8732/19264)
Loss: 1.314 | Acc: 52.743% (13536/25664)
Loss: 1.178 | Acc: 57.990% (18594/32064)
Loss: 1.082 | Acc: 61.572% (23683/38464)
Loss: 1.007 | Acc: 64.359% (28874/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0073, Accuracy: 6870/10000 (68.70%)

Epoch: 51
Loss: 0.527 | Acc: 85.938% (55/64)
Loss: 0.506 | Acc: 82.642% (5342/6464)
Loss: 0.500 | Acc: 82.680% (10636/12864)
Loss: 0.492 | Acc: 83.025% (15994/19264)
Loss: 0.486 | Acc: 83.315% (21382/25664)
Loss: 0.477 | Acc: 83.586% (26801/32064)
Loss: 0.470 | Acc: 83.785% (32227/38464)
Loss: 0.468 | Acc: 83.925% (37652/44864)
torch.Size([100, 10])
Test set: Average loss: 2.1468, Accuracy: 5625/10000 (56.25%)

Epoch: 52
Loss: 0.547 | Acc: 79.688% (51/64)
Loss: 0.425 | Acc: 85.381% (5519/6464)
Loss: 0.415 | Acc: 85.580% (11009/12864)
Loss: 0.410 | Acc: 85.745% (16518/19264)
Loss: 0.412 | Acc: 85.719% (21999/25664)
Loss: 0.409 | Acc: 85.844% (27525/32064)
Loss: 0.409 | Acc: 85.875% (33031/38464)
Loss: 0.408 | Acc: 85.953% (38562/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6823, Accuracy: 7978/10000 (79.78%)

Epoch: 53
Loss: 0.468 | Acc: 79.688% (51/64)
Loss: 0.376 | Acc: 87.252% (5640/6464)
Loss: 0.375 | Acc: 87.220% (11220/12864)
Loss: 0.380 | Acc: 87.100% (16779/19264)
Loss: 0.380 | Acc: 87.001% (22328/25664)
Loss: 0.383 | Acc: 86.829% (27841/32064)
Loss: 0.386 | Acc: 86.759% (33371/38464)
Loss: 0.387 | Acc: 86.813% (38948/44864)
torch.Size([100, 10])
Test set: Average loss: 0.9655, Accuracy: 7049/10000 (70.49%)

Epoch: 54
Loss: 0.680 | Acc: 78.125% (50/64)
Loss: 0.360 | Acc: 87.902% (5682/6464)
Loss: 0.355 | Acc: 87.889% (11306/12864)
Loss: 0.359 | Acc: 87.676% (16890/19264)
Loss: 0.367 | Acc: 87.500% (22456/25664)
Loss: 0.372 | Acc: 87.282% (27986/32064)
Loss: 0.373 | Acc: 87.227% (33551/38464)
Loss: 0.374 | Acc: 87.244% (39141/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6296, Accuracy: 8015/10000 (80.15%)

Epoch: 55
Loss: 0.428 | Acc: 84.375% (54/64)
Loss: 0.377 | Acc: 87.175% (5635/6464)
Loss: 0.361 | Acc: 87.679% (11279/12864)
Loss: 0.362 | Acc: 87.692% (16893/19264)
Loss: 0.365 | Acc: 87.484% (22452/25664)
Loss: 0.364 | Acc: 87.565% (28077/32064)
Loss: 0.365 | Acc: 87.552% (33676/38464)
Loss: 0.367 | Acc: 87.458% (39237/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5769, Accuracy: 5837/10000 (58.37%)

Epoch: 56
Loss: 0.185 | Acc: 93.750% (60/64)
Loss: 0.349 | Acc: 88.072% (5693/6464)
Loss: 0.353 | Acc: 87.935% (11312/12864)
Loss: 0.351 | Acc: 88.029% (16958/19264)
Loss: 0.349 | Acc: 87.987% (22581/25664)
Loss: 0.353 | Acc: 87.915% (28189/32064)
Loss: 0.353 | Acc: 87.952% (33830/38464)
Loss: 0.357 | Acc: 87.870% (39422/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6464, Accuracy: 7892/10000 (78.92%)

Epoch: 57
Loss: 0.457 | Acc: 85.938% (55/64)
Loss: 0.350 | Acc: 87.995% (5688/6464)
Loss: 0.343 | Acc: 88.487% (11383/12864)
Loss: 0.347 | Acc: 88.211% (16993/19264)
Loss: 0.348 | Acc: 88.104% (22611/25664)
Loss: 0.351 | Acc: 88.068% (28238/32064)
Loss: 0.352 | Acc: 88.077% (33878/38464)
Loss: 0.352 | Acc: 88.053% (39504/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8775, Accuracy: 7333/10000 (73.33%)

Epoch: 58
Loss: 0.623 | Acc: 78.125% (50/64)
Loss: 0.347 | Acc: 88.274% (5706/6464)
Loss: 0.351 | Acc: 88.013% (11322/12864)
Loss: 0.345 | Acc: 88.180% (16987/19264)
Loss: 0.347 | Acc: 88.081% (22605/25664)
Loss: 0.344 | Acc: 88.146% (28263/32064)
Loss: 0.347 | Acc: 88.051% (33868/38464)
Loss: 0.346 | Acc: 88.073% (39513/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2738, Accuracy: 6926/10000 (69.26%)

Epoch: 59
Loss: 0.436 | Acc: 82.812% (53/64)
Loss: 0.348 | Acc: 88.165% (5699/6464)
Loss: 0.346 | Acc: 88.153% (11340/12864)
Loss: 0.345 | Acc: 88.107% (16973/19264)
Loss: 0.342 | Acc: 88.256% (22650/25664)
Loss: 0.345 | Acc: 88.093% (28246/32064)
Loss: 0.345 | Acc: 88.145% (33904/38464)
Loss: 0.345 | Acc: 88.142% (39544/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4742, Accuracy: 8441/10000 (84.41%)

Epoch: 60
Loss: 0.206 | Acc: 92.188% (59/64)
Loss: 0.318 | Acc: 88.908% (5747/6464)
Loss: 0.324 | Acc: 88.744% (11416/12864)
Loss: 0.333 | Acc: 88.377% (17025/19264)
Loss: 0.332 | Acc: 88.525% (22719/25664)
Loss: 0.332 | Acc: 88.548% (28392/32064)
Loss: 0.330 | Acc: 88.592% (34076/38464)
Loss: 0.331 | Acc: 88.583% (39742/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5449, Accuracy: 8229/10000 (82.29%)

Epoch: 61
Loss: 0.404 | Acc: 85.938% (55/64)
Loss: 0.333 | Acc: 88.877% (5745/6464)
Loss: 0.327 | Acc: 88.993% (11448/12864)
Loss: 0.333 | Acc: 88.673% (17082/19264)
Loss: 0.332 | Acc: 88.747% (22776/25664)
Loss: 0.331 | Acc: 88.673% (28432/32064)
Loss: 0.331 | Acc: 88.696% (34116/38464)
Loss: 0.330 | Acc: 88.733% (39809/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6084, Accuracy: 6400/10000 (64.00%)

Epoch: 62
Loss: 0.541 | Acc: 87.500% (56/64)
Loss: 0.312 | Acc: 89.465% (5783/6464)
Loss: 0.307 | Acc: 89.638% (11531/12864)
Loss: 0.310 | Acc: 89.576% (17256/19264)
Loss: 0.315 | Acc: 89.257% (22907/25664)
Loss: 0.319 | Acc: 89.066% (28558/32064)
Loss: 0.320 | Acc: 89.057% (34255/38464)
Loss: 0.322 | Acc: 89.042% (39948/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5843, Accuracy: 8137/10000 (81.37%)

Epoch: 63
Loss: 0.237 | Acc: 90.625% (58/64)
Loss: 0.293 | Acc: 89.898% (5811/6464)
Loss: 0.310 | Acc: 89.490% (11512/12864)
Loss: 0.306 | Acc: 89.608% (17262/19264)
Loss: 0.312 | Acc: 89.265% (22909/25664)
Loss: 0.314 | Acc: 89.234% (28612/32064)
Loss: 0.315 | Acc: 89.221% (34318/38464)
Loss: 0.315 | Acc: 89.259% (40045/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4426, Accuracy: 8567/10000 (85.67%)

Epoch: 64
Loss: 0.394 | Acc: 84.375% (54/64)
Loss: 0.309 | Acc: 89.341% (5775/6464)
Loss: 0.300 | Acc: 89.949% (11571/12864)
Loss: 0.304 | Acc: 89.743% (17288/19264)
Loss: 0.304 | Acc: 89.729% (23028/25664)
Loss: 0.303 | Acc: 89.727% (28770/32064)
Loss: 0.306 | Acc: 89.637% (34478/38464)
Loss: 0.310 | Acc: 89.477% (40143/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3108, Accuracy: 6804/10000 (68.04%)

Epoch: 65
Loss: 0.314 | Acc: 87.500% (56/64)
Loss: 0.312 | Acc: 89.681% (5797/6464)
Loss: 0.306 | Acc: 89.855% (11559/12864)
Loss: 0.304 | Acc: 89.831% (17305/19264)
Loss: 0.302 | Acc: 89.729% (23028/25664)
Loss: 0.305 | Acc: 89.540% (28710/32064)
Loss: 0.309 | Acc: 89.502% (34426/38464)
Loss: 0.308 | Acc: 89.573% (40186/44864)
torch.Size([100, 10])
Test set: Average loss: 1.6116, Accuracy: 6288/10000 (62.88%)

Epoch: 66
Loss: 0.461 | Acc: 84.375% (54/64)
Loss: 0.279 | Acc: 90.826% (5871/6464)
Loss: 0.284 | Acc: 90.462% (11637/12864)
Loss: 0.290 | Acc: 90.205% (17377/19264)
Loss: 0.295 | Acc: 90.037% (23107/25664)
Loss: 0.291 | Acc: 90.070% (28880/32064)
Loss: 0.293 | Acc: 90.009% (34621/38464)
Loss: 0.294 | Acc: 89.930% (40346/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1683, Accuracy: 6790/10000 (67.90%)

Epoch: 67
Loss: 0.344 | Acc: 85.938% (55/64)
Loss: 0.290 | Acc: 90.053% (5821/6464)
Loss: 0.288 | Acc: 90.213% (11605/12864)
Loss: 0.283 | Acc: 90.402% (17415/19264)
Loss: 0.284 | Acc: 90.356% (23189/25664)
Loss: 0.289 | Acc: 90.145% (28904/32064)
Loss: 0.291 | Acc: 90.087% (34651/38464)
Loss: 0.291 | Acc: 90.086% (40416/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6306, Accuracy: 8022/10000 (80.22%)

Epoch: 68
Loss: 0.244 | Acc: 90.625% (58/64)
Loss: 0.279 | Acc: 90.548% (5853/6464)
Loss: 0.278 | Acc: 90.532% (11646/12864)
Loss: 0.280 | Acc: 90.500% (17434/19264)
Loss: 0.283 | Acc: 90.337% (23184/25664)
Loss: 0.282 | Acc: 90.429% (28995/32064)
Loss: 0.281 | Acc: 90.495% (34808/38464)
Loss: 0.282 | Acc: 90.411% (40562/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5254, Accuracy: 8300/10000 (83.00%)

Epoch: 69
Loss: 0.319 | Acc: 89.062% (57/64)
Loss: 0.258 | Acc: 90.826% (5871/6464)
Loss: 0.259 | Acc: 91.029% (11710/12864)
Loss: 0.265 | Acc: 90.859% (17503/19264)
Loss: 0.269 | Acc: 90.726% (23284/25664)
Loss: 0.270 | Acc: 90.740% (29095/32064)
Loss: 0.268 | Acc: 90.802% (34926/38464)
Loss: 0.267 | Acc: 90.832% (40751/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5396, Accuracy: 8290/10000 (82.90%)

Epoch: 70
Loss: 0.268 | Acc: 93.750% (60/64)
Loss: 0.241 | Acc: 91.878% (5939/6464)
Loss: 0.245 | Acc: 91.659% (11791/12864)
Loss: 0.253 | Acc: 91.430% (17613/19264)
Loss: 0.248 | Acc: 91.619% (23513/25664)
Loss: 0.254 | Acc: 91.317% (29280/32064)
Loss: 0.258 | Acc: 91.223% (35088/38464)
Loss: 0.259 | Acc: 91.162% (40899/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5040, Accuracy: 8371/10000 (83.71%)

Epoch: 71
Loss: 0.453 | Acc: 84.375% (54/64)
Loss: 0.233 | Acc: 91.770% (5932/6464)
Loss: 0.242 | Acc: 91.768% (11805/12864)
Loss: 0.248 | Acc: 91.450% (17617/19264)
Loss: 0.252 | Acc: 91.385% (23453/25664)
Loss: 0.251 | Acc: 91.495% (29337/32064)
Loss: 0.256 | Acc: 91.249% (35098/38464)
Loss: 0.257 | Acc: 91.238% (40933/44864)
torch.Size([100, 10])
Test set: Average loss: 3.4684, Accuracy: 4718/10000 (47.18%)

Epoch: 72
Loss: 0.625 | Acc: 78.125% (50/64)
Loss: 0.261 | Acc: 91.089% (5888/6464)
Loss: 0.248 | Acc: 91.449% (11764/12864)
Loss: 0.255 | Acc: 91.232% (17575/19264)
Loss: 0.255 | Acc: 91.213% (23409/25664)
Loss: 0.252 | Acc: 91.342% (29288/32064)
Loss: 0.249 | Acc: 91.434% (35169/38464)
Loss: 0.247 | Acc: 91.534% (41066/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2373, Accuracy: 7027/10000 (70.27%)

Epoch: 73
Loss: 0.258 | Acc: 89.062% (57/64)
Loss: 0.225 | Acc: 92.172% (5958/6464)
Loss: 0.233 | Acc: 91.962% (11830/12864)
Loss: 0.237 | Acc: 91.731% (17671/19264)
Loss: 0.236 | Acc: 91.743% (23545/25664)
Loss: 0.237 | Acc: 91.707% (29405/32064)
Loss: 0.234 | Acc: 91.863% (35334/38464)
Loss: 0.235 | Acc: 91.840% (41203/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5256, Accuracy: 8372/10000 (83.72%)

Epoch: 74
Loss: 0.330 | Acc: 84.375% (54/64)
Loss: 0.205 | Acc: 93.348% (6034/6464)
Loss: 0.209 | Acc: 93.105% (11977/12864)
Loss: 0.215 | Acc: 92.784% (17874/19264)
Loss: 0.219 | Acc: 92.554% (23753/25664)
Loss: 0.220 | Acc: 92.537% (29671/32064)
Loss: 0.223 | Acc: 92.424% (35550/38464)
Loss: 0.223 | Acc: 92.384% (41447/44864)
torch.Size([100, 10])
Test set: Average loss: 1.9534, Accuracy: 5794/10000 (57.94%)

Epoch: 75
Loss: 0.549 | Acc: 79.688% (51/64)
Loss: 0.209 | Acc: 92.853% (6002/6464)
Loss: 0.206 | Acc: 93.043% (11969/12864)
Loss: 0.210 | Acc: 92.868% (17890/19264)
Loss: 0.214 | Acc: 92.639% (23775/25664)
Loss: 0.215 | Acc: 92.574% (29683/32064)
Loss: 0.218 | Acc: 92.445% (35558/38464)
Loss: 0.220 | Acc: 92.350% (41432/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4960, Accuracy: 8493/10000 (84.93%)

Epoch: 76
Loss: 0.249 | Acc: 92.188% (59/64)
Loss: 0.190 | Acc: 93.719% (6058/6464)
Loss: 0.189 | Acc: 93.734% (12058/12864)
Loss: 0.192 | Acc: 93.646% (18040/19264)
Loss: 0.195 | Acc: 93.462% (23986/25664)
Loss: 0.200 | Acc: 93.248% (29899/32064)
Loss: 0.205 | Acc: 93.066% (35797/38464)
Loss: 0.203 | Acc: 93.119% (41777/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5614, Accuracy: 8326/10000 (83.26%)

Epoch: 77
Loss: 0.248 | Acc: 87.500% (56/64)
Loss: 0.193 | Acc: 93.379% (6036/6464)
Loss: 0.191 | Acc: 93.587% (12039/12864)
Loss: 0.190 | Acc: 93.433% (17999/19264)
Loss: 0.191 | Acc: 93.403% (23971/25664)
Loss: 0.190 | Acc: 93.441% (29961/32064)
Loss: 0.194 | Acc: 93.313% (35892/38464)
Loss: 0.192 | Acc: 93.389% (41898/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5301, Accuracy: 8447/10000 (84.47%)

Epoch: 78
Loss: 0.168 | Acc: 95.312% (61/64)
Loss: 0.163 | Acc: 94.338% (6098/6464)
Loss: 0.170 | Acc: 94.131% (12109/12864)
Loss: 0.179 | Acc: 93.880% (18085/19264)
Loss: 0.183 | Acc: 93.680% (24042/25664)
Loss: 0.184 | Acc: 93.622% (30019/32064)
Loss: 0.185 | Acc: 93.636% (36016/38464)
Loss: 0.186 | Acc: 93.583% (41985/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3964, Accuracy: 8762/10000 (87.62%)

Epoch: 79
Loss: 0.125 | Acc: 95.312% (61/64)
Loss: 0.156 | Acc: 94.833% (6130/6464)
Loss: 0.156 | Acc: 94.698% (12182/12864)
Loss: 0.156 | Acc: 94.690% (18241/19264)
Loss: 0.156 | Acc: 94.740% (24314/25664)
Loss: 0.159 | Acc: 94.642% (30346/32064)
Loss: 0.160 | Acc: 94.561% (36372/38464)
Loss: 0.162 | Acc: 94.468% (42382/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8263, Accuracy: 7754/10000 (77.54%)

Epoch: 80
Loss: 0.712 | Acc: 82.812% (53/64)
Loss: 0.172 | Acc: 94.601% (6115/6464)
Loss: 0.162 | Acc: 94.660% (12177/12864)
Loss: 0.160 | Acc: 94.607% (18225/19264)
Loss: 0.160 | Acc: 94.603% (24279/25664)
Loss: 0.160 | Acc: 94.592% (30330/32064)
Loss: 0.158 | Acc: 94.618% (36394/38464)
Loss: 0.158 | Acc: 94.642% (42460/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3970, Accuracy: 8742/10000 (87.42%)

Epoch: 81
Loss: 0.138 | Acc: 93.750% (60/64)
Loss: 0.141 | Acc: 95.467% (6171/6464)
Loss: 0.146 | Acc: 95.126% (12237/12864)
Loss: 0.149 | Acc: 94.944% (18290/19264)
Loss: 0.145 | Acc: 95.024% (24387/25664)
Loss: 0.145 | Acc: 94.948% (30444/32064)
Loss: 0.146 | Acc: 94.941% (36518/38464)
Loss: 0.148 | Acc: 94.925% (42587/44864)
torch.Size([100, 10])
Test set: Average loss: 1.4215, Accuracy: 7106/10000 (71.06%)

Epoch: 82
Loss: 0.240 | Acc: 92.188% (59/64)
Loss: 0.142 | Acc: 95.374% (6165/6464)
Loss: 0.131 | Acc: 95.631% (12302/12864)
Loss: 0.130 | Acc: 95.582% (18413/19264)
Loss: 0.128 | Acc: 95.601% (24535/25664)
Loss: 0.128 | Acc: 95.559% (30640/32064)
Loss: 0.129 | Acc: 95.494% (36731/38464)
Loss: 0.129 | Acc: 95.540% (42863/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4062, Accuracy: 8849/10000 (88.49%)

Epoch: 83
Loss: 0.074 | Acc: 98.438% (63/64)
Loss: 0.102 | Acc: 96.658% (6248/6464)
Loss: 0.107 | Acc: 96.541% (12419/12864)
Loss: 0.108 | Acc: 96.382% (18567/19264)
Loss: 0.106 | Acc: 96.423% (24746/25664)
Loss: 0.109 | Acc: 96.304% (30879/32064)
Loss: 0.109 | Acc: 96.264% (37027/38464)
Loss: 0.111 | Acc: 96.233% (43174/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2727, Accuracy: 9126/10000 (91.26%)

Epoch: 84
Loss: 0.060 | Acc: 98.438% (63/64)
Loss: 0.099 | Acc: 96.767% (6255/6464)
Loss: 0.101 | Acc: 96.541% (12419/12864)
Loss: 0.105 | Acc: 96.356% (18562/19264)
Loss: 0.100 | Acc: 96.520% (24771/25664)
Loss: 0.101 | Acc: 96.529% (30951/32064)
Loss: 0.103 | Acc: 96.425% (37089/38464)
Loss: 0.103 | Acc: 96.463% (43277/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3836, Accuracy: 8904/10000 (89.04%)

Epoch: 85
Loss: 0.026 | Acc: 100.000% (64/64)
Loss: 0.087 | Acc: 97.215% (6284/6464)
Loss: 0.085 | Acc: 97.147% (12497/12864)
Loss: 0.087 | Acc: 97.093% (18704/19264)
Loss: 0.089 | Acc: 97.015% (24898/25664)
Loss: 0.088 | Acc: 97.043% (31116/32064)
Loss: 0.088 | Acc: 97.044% (37327/38464)
Loss: 0.090 | Acc: 96.971% (43505/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3164, Accuracy: 9086/10000 (90.86%)

Epoch: 86
Loss: 0.019 | Acc: 100.000% (64/64)
Loss: 0.073 | Acc: 97.571% (6307/6464)
Loss: 0.069 | Acc: 97.668% (12564/12864)
Loss: 0.071 | Acc: 97.576% (18797/19264)
Loss: 0.073 | Acc: 97.537% (25032/25664)
Loss: 0.073 | Acc: 97.521% (31269/32064)
Loss: 0.073 | Acc: 97.512% (37507/38464)
Loss: 0.074 | Acc: 97.475% (43731/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5771, Accuracy: 8632/10000 (86.32%)

Epoch: 87
Loss: 0.015 | Acc: 100.000% (64/64)
Loss: 0.067 | Acc: 97.927% (6330/6464)
Loss: 0.062 | Acc: 98.018% (12609/12864)
Loss: 0.063 | Acc: 97.996% (18878/19264)
Loss: 0.063 | Acc: 97.935% (25134/25664)
Loss: 0.064 | Acc: 97.854% (31376/32064)
Loss: 0.064 | Acc: 97.795% (37616/38464)
Loss: 0.063 | Acc: 97.860% (43904/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2682, Accuracy: 9232/10000 (92.32%)

Epoch: 88
Loss: 0.130 | Acc: 93.750% (60/64)
Loss: 0.054 | Acc: 98.329% (6356/6464)
Loss: 0.050 | Acc: 98.461% (12666/12864)
Loss: 0.051 | Acc: 98.422% (18960/19264)
Loss: 0.049 | Acc: 98.484% (25275/25664)
Loss: 0.050 | Acc: 98.416% (31556/32064)
Loss: 0.049 | Acc: 98.427% (37859/38464)
Loss: 0.050 | Acc: 98.395% (44144/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2561, Accuracy: 9267/10000 (92.67%)

Epoch: 89
Loss: 0.032 | Acc: 98.438% (63/64)
Loss: 0.042 | Acc: 98.577% (6372/6464)
Loss: 0.039 | Acc: 98.780% (12707/12864)
Loss: 0.038 | Acc: 98.754% (19024/19264)
Loss: 0.038 | Acc: 98.714% (25334/25664)
Loss: 0.039 | Acc: 98.740% (31660/32064)
Loss: 0.039 | Acc: 98.731% (37976/38464)
Loss: 0.038 | Acc: 98.754% (44305/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2230, Accuracy: 9374/10000 (93.74%)

Epoch: 90
Loss: 0.042 | Acc: 98.438% (63/64)
Loss: 0.024 | Acc: 99.350% (6422/6464)
Loss: 0.027 | Acc: 99.199% (12761/12864)
Loss: 0.028 | Acc: 99.164% (19103/19264)
Loss: 0.028 | Acc: 99.100% (25433/25664)
Loss: 0.029 | Acc: 99.067% (31765/32064)
Loss: 0.029 | Acc: 99.072% (38107/38464)
Loss: 0.030 | Acc: 99.057% (44441/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2192, Accuracy: 9388/10000 (93.88%)

Epoch: 91
Loss: 0.009 | Acc: 100.000% (64/64)
Loss: 0.023 | Acc: 99.505% (6432/6464)
Loss: 0.022 | Acc: 99.464% (12795/12864)
Loss: 0.022 | Acc: 99.408% (19150/19264)
Loss: 0.022 | Acc: 99.361% (25500/25664)
Loss: 0.022 | Acc: 99.361% (31859/32064)
Loss: 0.022 | Acc: 99.321% (38203/38464)
Loss: 0.022 | Acc: 99.340% (44568/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1996, Accuracy: 9447/10000 (94.47%)

Epoch: 92
Loss: 0.019 | Acc: 98.438% (63/64)
Loss: 0.016 | Acc: 99.520% (6433/6464)
Loss: 0.016 | Acc: 99.549% (12806/12864)
Loss: 0.015 | Acc: 99.585% (19184/19264)
Loss: 0.015 | Acc: 99.583% (25557/25664)
Loss: 0.016 | Acc: 99.573% (31927/32064)
Loss: 0.015 | Acc: 99.568% (38298/38464)
Loss: 0.016 | Acc: 99.572% (44672/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2167, Accuracy: 9408/10000 (94.08%)

Epoch: 93
Loss: 0.010 | Acc: 100.000% (64/64)
Loss: 0.014 | Acc: 99.644% (6441/6464)
Loss: 0.013 | Acc: 99.681% (12823/12864)
Loss: 0.013 | Acc: 99.657% (19198/19264)
Loss: 0.013 | Acc: 99.673% (25580/25664)
Loss: 0.013 | Acc: 99.685% (31963/32064)
Loss: 0.013 | Acc: 99.678% (38340/38464)
Loss: 0.013 | Acc: 99.692% (44726/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1996, Accuracy: 9480/10000 (94.80%)

Epoch: 94
Loss: 0.075 | Acc: 96.875% (62/64)
Loss: 0.012 | Acc: 99.644% (6441/6464)
Loss: 0.012 | Acc: 99.674% (12822/12864)
Loss: 0.011 | Acc: 99.735% (19213/19264)
Loss: 0.011 | Acc: 99.719% (25592/25664)
Loss: 0.011 | Acc: 99.726% (31976/32064)
Loss: 0.010 | Acc: 99.756% (38370/38464)
Loss: 0.010 | Acc: 99.779% (44765/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1971, Accuracy: 9477/10000 (94.77%)

Epoch: 95
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 0.009 | Acc: 99.799% (6451/6464)
Loss: 0.008 | Acc: 99.813% (12840/12864)
Loss: 0.008 | Acc: 99.824% (19230/19264)
Loss: 0.008 | Acc: 99.832% (25621/25664)
Loss: 0.008 | Acc: 99.828% (32009/32064)
Loss: 0.008 | Acc: 99.826% (38397/38464)
Loss: 0.008 | Acc: 99.831% (44788/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1959, Accuracy: 9488/10000 (94.88%)

Epoch: 96
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.768% (6449/6464)
Loss: 0.008 | Acc: 99.829% (12842/12864)
Loss: 0.008 | Acc: 99.844% (19234/19264)
Loss: 0.008 | Acc: 99.852% (25626/25664)
Loss: 0.007 | Acc: 99.860% (32019/32064)
Loss: 0.007 | Acc: 99.865% (38412/38464)
Loss: 0.008 | Acc: 99.860% (44801/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1907, Accuracy: 9504/10000 (95.04%)

Epoch: 97
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.814% (6452/6464)
Loss: 0.007 | Acc: 99.860% (12846/12864)
Loss: 0.007 | Acc: 99.855% (19236/19264)
Loss: 0.007 | Acc: 99.852% (25626/25664)
Loss: 0.007 | Acc: 99.869% (32022/32064)
Loss: 0.007 | Acc: 99.860% (38410/38464)
Loss: 0.007 | Acc: 99.864% (44803/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1918, Accuracy: 9499/10000 (94.99%)
torch.Size([100, 10])
Test set: Average loss: 0.1918, Accuracy: 9499/10000 (94.99%)

Epoch: 98
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.876% (6456/6464)
Loss: 0.007 | Acc: 99.860% (12846/12864)
Loss: 0.007 | Acc: 99.886% (19242/19264)
Loss: 0.006 | Acc: 99.903% (25639/25664)
Loss: 0.007 | Acc: 99.897% (32031/32064)
Loss: 0.007 | Acc: 99.893% (38423/38464)
Loss: 0.007 | Acc: 99.897% (44818/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1913, Accuracy: 9486/10000 (94.86%)
torch.Size([100, 10])
Test set: Average loss: 0.1913, Accuracy: 9486/10000 (94.86%)

Epoch: 99
Loss: 0.009 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.799% (6451/6464)
Loss: 0.008 | Acc: 99.751% (12832/12864)
Loss: 0.007 | Acc: 99.813% (19228/19264)
Loss: 0.007 | Acc: 99.832% (25621/25664)
Loss: 0.007 | Acc: 99.844% (32014/32064)
Loss: 0.007 | Acc: 99.844% (38404/38464)
Loss: 0.007 | Acc: 99.846% (44795/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1905, Accuracy: 9505/10000 (95.05%)
torch.Size([100, 10])
Test set: Average loss: 0.1905, Accuracy: 9505/10000 (95.05%)

Epoch: 100
Loss: 0.009 | Acc: 100.000% (64/64)
Loss: 1.987 | Acc: 26.501% (1713/6464)
Loss: 1.818 | Acc: 32.206% (4143/12864)
Loss: 1.664 | Acc: 38.237% (7366/19264)
Loss: 1.502 | Acc: 44.545% (11432/25664)
Loss: 1.352 | Acc: 50.540% (16205/32064)
Loss: 1.233 | Acc: 55.231% (21244/38464)
Loss: 1.143 | Acc: 58.746% (26356/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1740, Accuracy: 6650/10000 (66.50%)

Epoch: 101
Loss: 0.759 | Acc: 76.562% (49/64)
Loss: 0.486 | Acc: 83.710% (5411/6464)
Loss: 0.501 | Acc: 83.349% (10722/12864)
Loss: 0.487 | Acc: 83.685% (16121/19264)
Loss: 0.477 | Acc: 83.900% (21532/25664)
Loss: 0.471 | Acc: 84.072% (26957/32064)
Loss: 0.466 | Acc: 84.193% (32384/38464)
Loss: 0.462 | Acc: 84.359% (37847/44864)
torch.Size([100, 10])
Test set: Average loss: 1.7514, Accuracy: 5842/10000 (58.42%)

Epoch: 102
Loss: 0.338 | Acc: 89.062% (57/64)
Loss: 0.385 | Acc: 87.005% (5624/6464)
Loss: 0.400 | Acc: 86.412% (11116/12864)
Loss: 0.394 | Acc: 86.664% (16695/19264)
Loss: 0.396 | Acc: 86.627% (22232/25664)
Loss: 0.396 | Acc: 86.577% (27760/32064)
Loss: 0.392 | Acc: 86.699% (33348/38464)
Loss: 0.394 | Acc: 86.698% (38896/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0418, Accuracy: 5724/10000 (57.24%)

Epoch: 103
Loss: 0.607 | Acc: 76.562% (49/64)
Loss: 0.390 | Acc: 86.510% (5592/6464)
Loss: 0.377 | Acc: 87.018% (11194/12864)
Loss: 0.377 | Acc: 87.178% (16794/19264)
Loss: 0.373 | Acc: 87.317% (22409/25664)
Loss: 0.372 | Acc: 87.385% (28019/32064)
Loss: 0.372 | Acc: 87.378% (33609/38464)
Loss: 0.371 | Acc: 87.368% (39197/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3737, Accuracy: 6381/10000 (63.81%)

Epoch: 104
Loss: 0.853 | Acc: 79.688% (51/64)
Loss: 0.367 | Acc: 87.376% (5648/6464)
Loss: 0.356 | Acc: 87.663% (11277/12864)
Loss: 0.350 | Acc: 87.972% (16947/19264)
Loss: 0.352 | Acc: 87.870% (22551/25664)
Loss: 0.351 | Acc: 87.899% (28184/32064)
Loss: 0.352 | Acc: 87.841% (33787/38464)
Loss: 0.354 | Acc: 87.834% (39406/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7094, Accuracy: 7736/10000 (77.36%)

Epoch: 105
Loss: 0.470 | Acc: 82.812% (53/64)
Loss: 0.346 | Acc: 88.335% (5710/6464)
Loss: 0.340 | Acc: 88.378% (11369/12864)
Loss: 0.339 | Acc: 88.440% (17037/19264)
Loss: 0.343 | Acc: 88.392% (22685/25664)
Loss: 0.342 | Acc: 88.470% (28367/32064)
Loss: 0.342 | Acc: 88.446% (34020/38464)
Loss: 0.343 | Acc: 88.389% (39655/44864)
torch.Size([100, 10])
Test set: Average loss: 3.2961, Accuracy: 5119/10000 (51.19%)

Epoch: 106
Loss: 0.694 | Acc: 78.125% (50/64)
Loss: 0.346 | Acc: 88.475% (5719/6464)
Loss: 0.335 | Acc: 88.596% (11397/12864)
Loss: 0.330 | Acc: 88.772% (17101/19264)
Loss: 0.334 | Acc: 88.673% (22757/25664)
Loss: 0.339 | Acc: 88.529% (28386/32064)
Loss: 0.341 | Acc: 88.475% (34031/38464)
Loss: 0.343 | Acc: 88.392% (39656/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2768, Accuracy: 6925/10000 (69.25%)

Epoch: 107
Loss: 0.590 | Acc: 78.125% (50/64)
Loss: 0.322 | Acc: 89.341% (5775/6464)
Loss: 0.319 | Acc: 89.288% (11486/12864)
Loss: 0.325 | Acc: 89.052% (17155/19264)
Loss: 0.324 | Acc: 89.066% (22858/25664)
Loss: 0.327 | Acc: 88.869% (28495/32064)
Loss: 0.329 | Acc: 88.823% (34165/38464)
Loss: 0.325 | Acc: 88.962% (39912/44864)
torch.Size([100, 10])
Test set: Average loss: 4.5607, Accuracy: 3403/10000 (34.03%)

Epoch: 108
Loss: 0.997 | Acc: 71.875% (46/64)
Loss: 0.345 | Acc: 88.428% (5716/6464)
Loss: 0.326 | Acc: 88.899% (11436/12864)
Loss: 0.327 | Acc: 88.803% (17107/19264)
Loss: 0.329 | Acc: 88.821% (22795/25664)
Loss: 0.327 | Acc: 88.869% (28495/32064)
Loss: 0.332 | Acc: 88.771% (34145/38464)
Loss: 0.333 | Acc: 88.764% (39823/44864)
torch.Size([100, 10])
Test set: Average loss: 3.7403, Accuracy: 4420/10000 (44.20%)

Epoch: 109
Loss: 1.019 | Acc: 73.438% (47/64)
Loss: 0.344 | Acc: 88.567% (5725/6464)
Loss: 0.333 | Acc: 88.798% (11423/12864)
Loss: 0.329 | Acc: 88.720% (17091/19264)
Loss: 0.327 | Acc: 88.770% (22782/25664)
Loss: 0.328 | Acc: 88.679% (28434/32064)
Loss: 0.327 | Acc: 88.756% (34139/38464)
Loss: 0.327 | Acc: 88.802% (39840/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3371, Accuracy: 6484/10000 (64.84%)

Epoch: 110
Loss: 0.573 | Acc: 78.125% (50/64)
Loss: 0.322 | Acc: 89.062% (5757/6464)
Loss: 0.317 | Acc: 89.117% (11464/12864)
Loss: 0.320 | Acc: 88.948% (17135/19264)
Loss: 0.318 | Acc: 89.066% (22858/25664)
Loss: 0.318 | Acc: 89.087% (28565/32064)
Loss: 0.318 | Acc: 89.089% (34267/38464)
Loss: 0.319 | Acc: 89.065% (39958/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7593, Accuracy: 7825/10000 (78.25%)

Epoch: 111
Loss: 0.509 | Acc: 84.375% (54/64)
Loss: 0.301 | Acc: 89.960% (5815/6464)
Loss: 0.304 | Acc: 89.677% (11536/12864)
Loss: 0.306 | Acc: 89.561% (17253/19264)
Loss: 0.308 | Acc: 89.538% (22979/25664)
Loss: 0.308 | Acc: 89.580% (28723/32064)
Loss: 0.310 | Acc: 89.468% (34413/38464)
Loss: 0.312 | Acc: 89.448% (40130/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7797, Accuracy: 7762/10000 (77.62%)

Epoch: 112
Loss: 0.471 | Acc: 85.938% (55/64)
Loss: 0.279 | Acc: 90.610% (5857/6464)
Loss: 0.288 | Acc: 90.135% (11595/12864)
Loss: 0.299 | Acc: 89.758% (17291/19264)
Loss: 0.297 | Acc: 89.892% (23070/25664)
Loss: 0.301 | Acc: 89.802% (28794/32064)
Loss: 0.304 | Acc: 89.754% (34523/38464)
Loss: 0.304 | Acc: 89.758% (40269/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2545, Accuracy: 6679/10000 (66.79%)

Epoch: 113
Loss: 0.470 | Acc: 81.250% (52/64)
Loss: 0.291 | Acc: 90.254% (5834/6464)
Loss: 0.295 | Acc: 89.995% (11577/12864)
Loss: 0.294 | Acc: 90.033% (17344/19264)
Loss: 0.299 | Acc: 89.772% (23039/25664)
Loss: 0.300 | Acc: 89.752% (28778/32064)
Loss: 0.300 | Acc: 89.746% (34520/38464)
Loss: 0.301 | Acc: 89.687% (40237/44864)
torch.Size([100, 10])
Test set: Average loss: 4.3669, Accuracy: 3726/10000 (37.26%)

Epoch: 114
Loss: 0.374 | Acc: 89.062% (57/64)
Loss: 0.296 | Acc: 89.712% (5799/6464)
Loss: 0.295 | Acc: 89.824% (11555/12864)
Loss: 0.299 | Acc: 89.706% (17281/19264)
Loss: 0.296 | Acc: 89.994% (23096/25664)
Loss: 0.293 | Acc: 90.073% (28881/32064)
Loss: 0.295 | Acc: 89.980% (34610/38464)
Loss: 0.295 | Acc: 89.972% (40365/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5208, Accuracy: 6180/10000 (61.80%)

Epoch: 115
Loss: 0.407 | Acc: 85.938% (55/64)
Loss: 0.271 | Acc: 90.532% (5852/6464)
Loss: 0.274 | Acc: 90.516% (11644/12864)
Loss: 0.277 | Acc: 90.360% (17407/19264)
Loss: 0.281 | Acc: 90.216% (23153/25664)
Loss: 0.285 | Acc: 90.039% (28870/32064)
Loss: 0.288 | Acc: 90.030% (34629/38464)
Loss: 0.290 | Acc: 90.077% (40412/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4876, Accuracy: 8427/10000 (84.27%)

Epoch: 116
Loss: 0.218 | Acc: 90.625% (58/64)
Loss: 0.260 | Acc: 91.244% (5898/6464)
Loss: 0.266 | Acc: 90.835% (11685/12864)
Loss: 0.274 | Acc: 90.630% (17459/19264)
Loss: 0.275 | Acc: 90.477% (23220/25664)
Loss: 0.278 | Acc: 90.397% (28985/32064)
Loss: 0.275 | Acc: 90.503% (34811/38464)
Loss: 0.282 | Acc: 90.219% (40476/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0157, Accuracy: 7290/10000 (72.90%)

Epoch: 117
Loss: 0.339 | Acc: 89.062% (57/64)
Loss: 0.271 | Acc: 90.377% (5842/6464)
Loss: 0.268 | Acc: 90.586% (11653/12864)
Loss: 0.269 | Acc: 90.609% (17455/19264)
Loss: 0.267 | Acc: 90.676% (23271/25664)
Loss: 0.271 | Acc: 90.581% (29044/32064)
Loss: 0.275 | Acc: 90.459% (34794/38464)
Loss: 0.274 | Acc: 90.563% (40630/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6059, Accuracy: 8131/10000 (81.31%)

Epoch: 118
Loss: 0.362 | Acc: 92.188% (59/64)
Loss: 0.267 | Acc: 90.981% (5881/6464)
Loss: 0.260 | Acc: 91.224% (11735/12864)
Loss: 0.263 | Acc: 90.994% (17529/19264)
Loss: 0.267 | Acc: 90.785% (23299/25664)
Loss: 0.269 | Acc: 90.775% (29106/32064)
Loss: 0.269 | Acc: 90.773% (34915/38464)
Loss: 0.267 | Acc: 90.861% (40764/44864)
torch.Size([100, 10])
Test set: Average loss: 5.3269, Accuracy: 3599/10000 (35.99%)

Epoch: 119
Loss: 0.420 | Acc: 92.188% (59/64)
Loss: 0.272 | Acc: 90.687% (5862/6464)
Loss: 0.266 | Acc: 91.146% (11725/12864)
Loss: 0.263 | Acc: 91.097% (17549/19264)
Loss: 0.265 | Acc: 90.937% (23338/25664)
Loss: 0.263 | Acc: 90.993% (29176/32064)
Loss: 0.259 | Acc: 91.166% (35066/38464)
Loss: 0.262 | Acc: 91.057% (40852/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7627, Accuracy: 7922/10000 (79.22%)

Epoch: 120
Loss: 0.166 | Acc: 90.625% (58/64)
Loss: 0.257 | Acc: 91.259% (5899/6464)
Loss: 0.255 | Acc: 91.325% (11748/12864)
Loss: 0.254 | Acc: 91.274% (17583/19264)
Loss: 0.251 | Acc: 91.385% (23453/25664)
Loss: 0.250 | Acc: 91.386% (29302/32064)
Loss: 0.251 | Acc: 91.384% (35150/38464)
Loss: 0.250 | Acc: 91.430% (41019/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2907, Accuracy: 6627/10000 (66.27%)

Epoch: 121
Loss: 0.265 | Acc: 92.188% (59/64)
Loss: 0.231 | Acc: 92.342% (5969/6464)
Loss: 0.235 | Acc: 92.001% (11835/12864)
Loss: 0.242 | Acc: 91.720% (17669/19264)
Loss: 0.243 | Acc: 91.615% (23512/25664)
Loss: 0.240 | Acc: 91.692% (29400/32064)
Loss: 0.240 | Acc: 91.670% (35260/38464)
Loss: 0.241 | Acc: 91.659% (41122/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6805, Accuracy: 7899/10000 (78.99%)

Epoch: 122
Loss: 0.298 | Acc: 89.062% (57/64)
Loss: 0.219 | Acc: 92.652% (5989/6464)
Loss: 0.211 | Acc: 92.965% (11959/12864)
Loss: 0.221 | Acc: 92.540% (17827/19264)
Loss: 0.224 | Acc: 92.386% (23710/25664)
Loss: 0.229 | Acc: 92.259% (29582/32064)
Loss: 0.230 | Acc: 92.146% (35443/38464)
Loss: 0.231 | Acc: 92.116% (41327/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5850, Accuracy: 8188/10000 (81.88%)

Epoch: 123
Loss: 0.285 | Acc: 90.625% (58/64)
Loss: 0.209 | Acc: 92.853% (6002/6464)
Loss: 0.218 | Acc: 92.351% (11880/12864)
Loss: 0.221 | Acc: 92.213% (17764/19264)
Loss: 0.222 | Acc: 92.281% (23683/25664)
Loss: 0.223 | Acc: 92.309% (29598/32064)
Loss: 0.225 | Acc: 92.255% (35485/38464)
Loss: 0.226 | Acc: 92.241% (41383/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3855, Accuracy: 8735/10000 (87.35%)

Epoch: 124
Loss: 0.094 | Acc: 95.312% (61/64)
Loss: 0.200 | Acc: 93.379% (6036/6464)
Loss: 0.207 | Acc: 92.926% (11954/12864)
Loss: 0.205 | Acc: 92.961% (17908/19264)
Loss: 0.211 | Acc: 92.710% (23793/25664)
Loss: 0.214 | Acc: 92.602% (29692/32064)
Loss: 0.214 | Acc: 92.655% (35639/38464)
Loss: 0.216 | Acc: 92.562% (41527/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4325, Accuracy: 8606/10000 (86.06%)

Epoch: 125
Loss: 0.214 | Acc: 89.062% (57/64)
Loss: 0.186 | Acc: 93.472% (6042/6464)
Loss: 0.193 | Acc: 93.268% (11998/12864)
Loss: 0.199 | Acc: 93.137% (17942/19264)
Loss: 0.196 | Acc: 93.286% (23941/25664)
Loss: 0.195 | Acc: 93.370% (29938/32064)
Loss: 0.198 | Acc: 93.295% (35885/38464)
Loss: 0.201 | Acc: 93.137% (41785/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6020, Accuracy: 8233/10000 (82.33%)

Epoch: 126
Loss: 0.286 | Acc: 87.500% (56/64)
Loss: 0.184 | Acc: 93.564% (6048/6464)
Loss: 0.189 | Acc: 93.447% (12021/12864)
Loss: 0.195 | Acc: 93.195% (17953/19264)
Loss: 0.196 | Acc: 93.263% (23935/25664)
Loss: 0.197 | Acc: 93.235% (29895/32064)
Loss: 0.197 | Acc: 93.227% (35859/38464)
Loss: 0.197 | Acc: 93.266% (41843/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4148, Accuracy: 8689/10000 (86.89%)

Epoch: 127
Loss: 0.343 | Acc: 87.500% (56/64)
Loss: 0.177 | Acc: 93.827% (6065/6464)
Loss: 0.181 | Acc: 93.501% (12028/12864)
Loss: 0.179 | Acc: 93.698% (18050/19264)
Loss: 0.182 | Acc: 93.575% (24015/25664)
Loss: 0.185 | Acc: 93.547% (29995/32064)
Loss: 0.187 | Acc: 93.482% (35957/38464)
Loss: 0.186 | Acc: 93.545% (41968/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7109, Accuracy: 7910/10000 (79.10%)

Epoch: 128
Loss: 0.195 | Acc: 90.625% (58/64)
Loss: 0.163 | Acc: 94.152% (6086/6464)
Loss: 0.163 | Acc: 94.279% (12128/12864)
Loss: 0.167 | Acc: 94.160% (18139/19264)
Loss: 0.165 | Acc: 94.233% (24184/25664)
Loss: 0.167 | Acc: 94.202% (30205/32064)
Loss: 0.168 | Acc: 94.150% (36214/38464)
Loss: 0.171 | Acc: 94.044% (42192/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4852, Accuracy: 8526/10000 (85.26%)

Epoch: 129
Loss: 0.195 | Acc: 92.188% (59/64)
Loss: 0.172 | Acc: 94.245% (6092/6464)
Loss: 0.156 | Acc: 94.698% (12182/12864)
Loss: 0.156 | Acc: 94.731% (18249/19264)
Loss: 0.157 | Acc: 94.681% (24299/25664)
Loss: 0.158 | Acc: 94.664% (30353/32064)
Loss: 0.161 | Acc: 94.517% (36355/38464)
Loss: 0.160 | Acc: 94.552% (42420/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7344, Accuracy: 7990/10000 (79.90%)

Epoch: 130
Loss: 0.200 | Acc: 92.188% (59/64)
Loss: 0.159 | Acc: 94.539% (6111/6464)
Loss: 0.151 | Acc: 94.854% (12202/12864)
Loss: 0.143 | Acc: 95.126% (18325/19264)
Loss: 0.146 | Acc: 94.974% (24374/25664)
Loss: 0.146 | Acc: 94.932% (30439/32064)
Loss: 0.149 | Acc: 94.881% (36495/38464)
Loss: 0.149 | Acc: 94.922% (42586/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3381, Accuracy: 8963/10000 (89.63%)

Epoch: 131
Loss: 0.223 | Acc: 93.750% (60/64)
Loss: 0.126 | Acc: 95.653% (6183/6464)
Loss: 0.126 | Acc: 95.732% (12315/12864)
Loss: 0.131 | Acc: 95.624% (18421/19264)
Loss: 0.134 | Acc: 95.484% (24505/25664)
Loss: 0.133 | Acc: 95.528% (30630/32064)
Loss: 0.132 | Acc: 95.502% (36734/38464)
Loss: 0.135 | Acc: 95.433% (42815/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3482, Accuracy: 8987/10000 (89.87%)

Epoch: 132
Loss: 0.126 | Acc: 96.875% (62/64)
Loss: 0.121 | Acc: 96.009% (6206/6464)
Loss: 0.121 | Acc: 95.857% (12331/12864)
Loss: 0.123 | Acc: 95.816% (18458/19264)
Loss: 0.122 | Acc: 95.881% (24607/25664)
Loss: 0.122 | Acc: 95.855% (30735/32064)
Loss: 0.121 | Acc: 95.877% (36878/38464)
Loss: 0.123 | Acc: 95.832% (42994/44864)
torch.Size([100, 10])
Test set: Average loss: 0.5680, Accuracy: 8382/10000 (83.82%)

Epoch: 133
Loss: 0.139 | Acc: 96.875% (62/64)
Loss: 0.112 | Acc: 96.318% (6226/6464)
Loss: 0.112 | Acc: 96.191% (12374/12864)
Loss: 0.114 | Acc: 96.179% (18528/19264)
Loss: 0.112 | Acc: 96.166% (24680/25664)
Loss: 0.113 | Acc: 96.161% (30833/32064)
Loss: 0.113 | Acc: 96.137% (36978/38464)
Loss: 0.113 | Acc: 96.122% (43124/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3677, Accuracy: 8924/10000 (89.24%)

Epoch: 134
Loss: 0.118 | Acc: 93.750% (60/64)
Loss: 0.086 | Acc: 97.231% (6285/6464)
Loss: 0.090 | Acc: 96.984% (12476/12864)
Loss: 0.091 | Acc: 96.937% (18674/19264)
Loss: 0.092 | Acc: 96.902% (24869/25664)
Loss: 0.095 | Acc: 96.810% (31041/32064)
Loss: 0.096 | Acc: 96.776% (37224/38464)
Loss: 0.095 | Acc: 96.772% (43416/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2687, Accuracy: 9173/10000 (91.73%)

Epoch: 135
Loss: 0.028 | Acc: 100.000% (64/64)
Loss: 0.071 | Acc: 97.710% (6316/6464)
Loss: 0.072 | Acc: 97.629% (12559/12864)
Loss: 0.073 | Acc: 97.550% (18792/19264)
Loss: 0.079 | Acc: 97.405% (24998/25664)
Loss: 0.080 | Acc: 97.396% (31229/32064)
Loss: 0.081 | Acc: 97.340% (37441/38464)
Loss: 0.082 | Acc: 97.290% (43648/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3333, Accuracy: 8989/10000 (89.89%)

Epoch: 136
Loss: 0.232 | Acc: 93.750% (60/64)
Loss: 0.074 | Acc: 97.571% (6307/6464)
Loss: 0.069 | Acc: 97.715% (12570/12864)
Loss: 0.069 | Acc: 97.742% (18829/19264)
Loss: 0.070 | Acc: 97.693% (25072/25664)
Loss: 0.070 | Acc: 97.655% (31312/32064)
Loss: 0.071 | Acc: 97.611% (37545/38464)
Loss: 0.071 | Acc: 97.606% (43790/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3998, Accuracy: 8899/10000 (88.99%)

Epoch: 137
Loss: 0.054 | Acc: 100.000% (64/64)
Loss: 0.071 | Acc: 97.401% (6296/6464)
Loss: 0.065 | Acc: 97.699% (12568/12864)
Loss: 0.064 | Acc: 97.763% (18833/19264)
Loss: 0.063 | Acc: 97.810% (25102/25664)
Loss: 0.062 | Acc: 97.867% (31380/32064)
Loss: 0.061 | Acc: 97.907% (37659/38464)
Loss: 0.060 | Acc: 97.929% (43935/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2355, Accuracy: 9327/10000 (93.27%)

Epoch: 138
Loss: 0.024 | Acc: 100.000% (64/64)
Loss: 0.044 | Acc: 98.546% (6370/6464)
Loss: 0.046 | Acc: 98.445% (12664/12864)
Loss: 0.046 | Acc: 98.531% (18981/19264)
Loss: 0.045 | Acc: 98.535% (25288/25664)
Loss: 0.047 | Acc: 98.494% (31581/32064)
Loss: 0.046 | Acc: 98.471% (37876/38464)
Loss: 0.046 | Acc: 98.478% (44181/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2291, Accuracy: 9353/10000 (93.53%)

Epoch: 139
Loss: 0.068 | Acc: 96.875% (62/64)
Loss: 0.037 | Acc: 98.840% (6389/6464)
Loss: 0.039 | Acc: 98.725% (12700/12864)
Loss: 0.037 | Acc: 98.775% (19028/19264)
Loss: 0.038 | Acc: 98.792% (25354/25664)
Loss: 0.037 | Acc: 98.796% (31678/32064)
Loss: 0.037 | Acc: 98.838% (38017/38464)
Loss: 0.035 | Acc: 98.868% (44356/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2134, Accuracy: 9368/10000 (93.68%)

Epoch: 140
Loss: 0.082 | Acc: 98.438% (63/64)
Loss: 0.026 | Acc: 99.226% (6414/6464)
Loss: 0.025 | Acc: 99.230% (12765/12864)
Loss: 0.024 | Acc: 99.263% (19122/19264)
Loss: 0.023 | Acc: 99.271% (25477/25664)
Loss: 0.024 | Acc: 99.292% (31837/32064)
Loss: 0.024 | Acc: 99.269% (38183/38464)
Loss: 0.025 | Acc: 99.224% (44516/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2187, Accuracy: 9366/10000 (93.66%)

Epoch: 141
Loss: 0.018 | Acc: 100.000% (64/64)
Loss: 0.022 | Acc: 99.397% (6425/6464)
Loss: 0.022 | Acc: 99.347% (12780/12864)
Loss: 0.021 | Acc: 99.398% (19148/19264)
Loss: 0.022 | Acc: 99.369% (25502/25664)
Loss: 0.022 | Acc: 99.361% (31859/32064)
Loss: 0.021 | Acc: 99.360% (38218/38464)
Loss: 0.021 | Acc: 99.376% (44584/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2008, Accuracy: 9439/10000 (94.39%)

Epoch: 142
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.013 | Acc: 99.613% (6439/6464)
Loss: 0.015 | Acc: 99.534% (12804/12864)
Loss: 0.015 | Acc: 99.585% (19184/19264)
Loss: 0.014 | Acc: 99.595% (25560/25664)
Loss: 0.014 | Acc: 99.604% (31937/32064)
Loss: 0.014 | Acc: 99.600% (38310/38464)
Loss: 0.014 | Acc: 99.590% (44680/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1901, Accuracy: 9451/10000 (94.51%)

Epoch: 143
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.675% (6443/6464)
Loss: 0.012 | Acc: 99.666% (12821/12864)
Loss: 0.011 | Acc: 99.683% (19203/19264)
Loss: 0.012 | Acc: 99.680% (25582/25664)
Loss: 0.012 | Acc: 99.666% (31957/32064)
Loss: 0.012 | Acc: 99.667% (38336/38464)
Loss: 0.012 | Acc: 99.677% (44719/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1920, Accuracy: 9485/10000 (94.85%)

Epoch: 144
Loss: 0.011 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.814% (6452/6464)
Loss: 0.009 | Acc: 99.837% (12843/12864)
Loss: 0.009 | Acc: 99.798% (19225/19264)
Loss: 0.009 | Acc: 99.809% (25615/25664)
Loss: 0.009 | Acc: 99.816% (32005/32064)
Loss: 0.009 | Acc: 99.802% (38388/38464)
Loss: 0.008 | Acc: 99.806% (44777/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1926, Accuracy: 9492/10000 (94.92%)

Epoch: 145
Loss: 0.005 | Acc: 100.000% (64/64)
Loss: 0.011 | Acc: 99.691% (6444/6464)
Loss: 0.009 | Acc: 99.767% (12834/12864)
Loss: 0.009 | Acc: 99.777% (19221/19264)
Loss: 0.009 | Acc: 99.797% (25612/25664)
Loss: 0.008 | Acc: 99.797% (31999/32064)
Loss: 0.008 | Acc: 99.808% (38390/38464)
Loss: 0.008 | Acc: 99.813% (44780/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1959, Accuracy: 9474/10000 (94.74%)

Epoch: 146
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.737% (6447/6464)
Loss: 0.008 | Acc: 99.782% (12836/12864)
Loss: 0.008 | Acc: 99.798% (19225/19264)
Loss: 0.008 | Acc: 99.813% (25616/25664)
Loss: 0.008 | Acc: 99.825% (32008/32064)
Loss: 0.008 | Acc: 99.828% (38398/38464)
Loss: 0.008 | Acc: 99.828% (44787/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1900, Accuracy: 9492/10000 (94.92%)

Epoch: 147
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.830% (6453/6464)
Loss: 0.007 | Acc: 99.868% (12847/12864)
Loss: 0.007 | Acc: 99.849% (19235/19264)
Loss: 0.007 | Acc: 99.848% (25625/25664)
Loss: 0.007 | Acc: 99.850% (32016/32064)
Loss: 0.007 | Acc: 99.857% (38409/38464)
Loss: 0.007 | Acc: 99.857% (44800/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1877, Accuracy: 9501/10000 (95.01%)
torch.Size([100, 10])
Test set: Average loss: 0.1877, Accuracy: 9501/10000 (95.01%)

Epoch: 148
Loss: 0.003 | Acc: 100.000% (64/64)
Loss: 0.005 | Acc: 99.923% (6459/6464)
Loss: 0.006 | Acc: 99.907% (12852/12864)
Loss: 0.005 | Acc: 99.896% (19244/19264)
Loss: 0.006 | Acc: 99.883% (25634/25664)
Loss: 0.006 | Acc: 99.881% (32026/32064)
Loss: 0.006 | Acc: 99.888% (38421/38464)
Loss: 0.006 | Acc: 99.886% (44813/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1889, Accuracy: 9497/10000 (94.97%)
torch.Size([100, 10])
Test set: Average loss: 0.1889, Accuracy: 9497/10000 (94.97%)

Epoch: 149
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.830% (6453/6464)
Loss: 0.006 | Acc: 99.876% (12848/12864)
Loss: 0.007 | Acc: 99.865% (19238/19264)
Loss: 0.007 | Acc: 99.868% (25630/25664)
Loss: 0.006 | Acc: 99.885% (32027/32064)
Loss: 0.006 | Acc: 99.896% (38424/38464)
Loss: 0.006 | Acc: 99.893% (44816/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1903, Accuracy: 9496/10000 (94.96%)
torch.Size([100, 10])
Test set: Average loss: 0.1903, Accuracy: 9496/10000 (94.96%)

Epoch: 150
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 2.012 | Acc: 27.568% (1782/6464)
Loss: 1.797 | Acc: 34.499% (4438/12864)
Loss: 1.585 | Acc: 42.540% (8195/19264)
Loss: 1.384 | Acc: 50.136% (12867/25664)
Loss: 1.233 | Acc: 55.866% (17913/32064)
Loss: 1.120 | Acc: 60.186% (23150/38464)
Loss: 1.038 | Acc: 63.269% (28385/44864)
torch.Size([100, 10])
Test set: Average loss: 2.5096, Accuracy: 4670/10000 (46.70%)

Epoch: 151
Loss: 0.688 | Acc: 68.750% (44/64)
Loss: 0.472 | Acc: 84.236% (5445/6464)
Loss: 0.463 | Acc: 84.157% (10826/12864)
Loss: 0.458 | Acc: 84.224% (16225/19264)
Loss: 0.451 | Acc: 84.500% (21686/25664)
Loss: 0.441 | Acc: 84.830% (27200/32064)
Loss: 0.436 | Acc: 84.994% (32692/38464)
Loss: 0.431 | Acc: 85.142% (38198/44864)
torch.Size([100, 10])
Test set: Average loss: 3.7913, Accuracy: 4003/10000 (40.03%)

Epoch: 152
Loss: 0.647 | Acc: 82.812% (53/64)
Loss: 0.372 | Acc: 87.469% (5654/6464)
Loss: 0.373 | Acc: 87.624% (11272/12864)
Loss: 0.376 | Acc: 87.308% (16819/19264)
Loss: 0.381 | Acc: 87.165% (22370/25664)
Loss: 0.380 | Acc: 87.138% (27940/32064)
Loss: 0.380 | Acc: 87.136% (33516/38464)
Loss: 0.377 | Acc: 87.192% (39118/44864)
torch.Size([100, 10])
Test set: Average loss: 2.8527, Accuracy: 4852/10000 (48.52%)

Epoch: 153
Loss: 0.980 | Acc: 75.000% (48/64)
Loss: 0.369 | Acc: 87.392% (5649/6464)
Loss: 0.351 | Acc: 87.998% (11320/12864)
Loss: 0.348 | Acc: 88.175% (16986/19264)
Loss: 0.347 | Acc: 88.314% (22665/25664)
Loss: 0.345 | Acc: 88.448% (28360/32064)
Loss: 0.348 | Acc: 88.314% (33969/38464)
Loss: 0.348 | Acc: 88.271% (39602/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6841, Accuracy: 7784/10000 (77.84%)

Epoch: 154
Loss: 0.394 | Acc: 85.938% (55/64)
Loss: 0.350 | Acc: 88.165% (5699/6464)
Loss: 0.348 | Acc: 88.301% (11359/12864)
Loss: 0.346 | Acc: 88.299% (17010/19264)
Loss: 0.345 | Acc: 88.295% (22660/25664)
Loss: 0.342 | Acc: 88.404% (28346/32064)
Loss: 0.344 | Acc: 88.319% (33971/38464)
Loss: 0.341 | Acc: 88.436% (39676/44864)
torch.Size([100, 10])
Test set: Average loss: 6.4999, Accuracy: 3514/10000 (35.14%)

Epoch: 155
Loss: 1.553 | Acc: 71.875% (46/64)
Loss: 0.335 | Acc: 89.032% (5755/6464)
Loss: 0.340 | Acc: 88.744% (11416/12864)
Loss: 0.335 | Acc: 88.793% (17105/19264)
Loss: 0.336 | Acc: 88.720% (22769/25664)
Loss: 0.335 | Acc: 88.757% (28459/32064)
Loss: 0.334 | Acc: 88.792% (34153/38464)
Loss: 0.335 | Acc: 88.726% (39806/44864)
torch.Size([100, 10])
Test set: Average loss: 0.4583, Accuracy: 8446/10000 (84.46%)

Epoch: 156
Loss: 0.224 | Acc: 92.188% (59/64)
Loss: 0.316 | Acc: 89.527% (5787/6464)
Loss: 0.317 | Acc: 89.335% (11492/12864)
Loss: 0.322 | Acc: 89.151% (17174/19264)
Loss: 0.322 | Acc: 89.101% (22867/25664)
Loss: 0.323 | Acc: 89.103% (28570/32064)
Loss: 0.326 | Acc: 88.998% (34232/38464)
Loss: 0.325 | Acc: 88.996% (39927/44864)
torch.Size([100, 10])
Test set: Average loss: 4.4924, Accuracy: 4067/10000 (40.67%)

Epoch: 157
Loss: 0.552 | Acc: 85.938% (55/64)
Loss: 0.323 | Acc: 89.032% (5755/6464)
Loss: 0.313 | Acc: 89.171% (11471/12864)
Loss: 0.320 | Acc: 89.078% (17160/19264)
Loss: 0.321 | Acc: 89.113% (22870/25664)
Loss: 0.322 | Acc: 89.078% (28562/32064)
Loss: 0.321 | Acc: 89.062% (34257/38464)
Loss: 0.322 | Acc: 89.047% (39950/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0804, Accuracy: 6121/10000 (61.21%)

Epoch: 158
Loss: 0.664 | Acc: 79.688% (51/64)
Loss: 0.324 | Acc: 89.155% (5763/6464)
Loss: 0.321 | Acc: 89.070% (11458/12864)
Loss: 0.316 | Acc: 89.384% (17219/19264)
Loss: 0.314 | Acc: 89.456% (22958/25664)
Loss: 0.319 | Acc: 89.250% (28617/32064)
Loss: 0.319 | Acc: 89.218% (34317/38464)
Loss: 0.320 | Acc: 89.187% (40013/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8864, Accuracy: 7622/10000 (76.22%)

Epoch: 159
Loss: 0.327 | Acc: 92.188% (59/64)
Loss: 0.285 | Acc: 89.867% (5809/6464)
Loss: 0.302 | Acc: 89.646% (11532/12864)
Loss: 0.304 | Acc: 89.623% (17265/19264)
Loss: 0.307 | Acc: 89.581% (22990/25664)
Loss: 0.306 | Acc: 89.674% (28753/32064)
Loss: 0.308 | Acc: 89.575% (34454/38464)
Loss: 0.313 | Acc: 89.361% (40091/44864)
torch.Size([100, 10])
Test set: Average loss: 1.3519, Accuracy: 6691/10000 (66.91%)

Epoch: 160
Loss: 0.527 | Acc: 79.688% (51/64)
Loss: 0.289 | Acc: 90.331% (5839/6464)
Loss: 0.301 | Acc: 89.809% (11553/12864)
Loss: 0.302 | Acc: 89.711% (17282/19264)
Loss: 0.308 | Acc: 89.581% (22990/25664)
Loss: 0.303 | Acc: 89.730% (28771/32064)
Loss: 0.304 | Acc: 89.634% (34477/38464)
Loss: 0.308 | Acc: 89.535% (40169/44864)
torch.Size([100, 10])
Test set: Average loss: 2.0595, Accuracy: 5837/10000 (58.37%)

Epoch: 161
Loss: 0.476 | Acc: 82.812% (53/64)
Loss: 0.300 | Acc: 89.356% (5776/6464)
Loss: 0.298 | Acc: 89.513% (11515/12864)
Loss: 0.301 | Acc: 89.493% (17240/19264)
Loss: 0.303 | Acc: 89.491% (22967/25664)
Loss: 0.302 | Acc: 89.502% (28698/32064)
Loss: 0.305 | Acc: 89.465% (34412/38464)
Loss: 0.306 | Acc: 89.461% (40136/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7769, Accuracy: 7695/10000 (76.95%)

Epoch: 162
Loss: 0.460 | Acc: 84.375% (54/64)
Loss: 0.289 | Acc: 90.223% (5832/6464)
Loss: 0.286 | Acc: 90.407% (11630/12864)
Loss: 0.291 | Acc: 90.070% (17351/19264)
Loss: 0.290 | Acc: 90.142% (23134/25664)
Loss: 0.294 | Acc: 90.048% (28873/32064)
Loss: 0.296 | Acc: 89.954% (34600/38464)
Loss: 0.298 | Acc: 89.860% (40315/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6358, Accuracy: 8091/10000 (80.91%)

Epoch: 163
Loss: 0.336 | Acc: 84.375% (54/64)
Loss: 0.287 | Acc: 90.316% (5838/6464)
Loss: 0.288 | Acc: 90.267% (11612/12864)
Loss: 0.290 | Acc: 90.132% (17363/19264)
Loss: 0.292 | Acc: 90.072% (23116/25664)
Loss: 0.293 | Acc: 89.998% (28857/32064)
Loss: 0.294 | Acc: 89.905% (34581/38464)
Loss: 0.296 | Acc: 89.872% (40320/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6402, Accuracy: 8004/10000 (80.04%)

Epoch: 164
Loss: 0.224 | Acc: 93.750% (60/64)
Loss: 0.258 | Acc: 91.383% (5907/6464)
Loss: 0.267 | Acc: 90.936% (11698/12864)
Loss: 0.270 | Acc: 90.786% (17489/19264)
Loss: 0.278 | Acc: 90.551% (23239/25664)
Loss: 0.282 | Acc: 90.379% (28979/32064)
Loss: 0.283 | Acc: 90.373% (34761/38464)
Loss: 0.285 | Acc: 90.317% (40520/44864)
torch.Size([100, 10])
Test set: Average loss: 2.7002, Accuracy: 5702/10000 (57.02%)

Epoch: 165
Loss: 0.211 | Acc: 93.750% (60/64)
Loss: 0.278 | Acc: 90.517% (5851/6464)
Loss: 0.286 | Acc: 90.275% (11613/12864)
Loss: 0.279 | Acc: 90.604% (17454/19264)
Loss: 0.278 | Acc: 90.687% (23274/25664)
Loss: 0.278 | Acc: 90.591% (29047/32064)
Loss: 0.277 | Acc: 90.607% (34851/38464)
Loss: 0.278 | Acc: 90.585% (40640/44864)
torch.Size([100, 10])
Test set: Average loss: 0.7547, Accuracy: 7698/10000 (76.98%)

Epoch: 166
Loss: 0.538 | Acc: 84.375% (54/64)
Loss: 0.262 | Acc: 90.826% (5871/6464)
Loss: 0.266 | Acc: 90.858% (11688/12864)
Loss: 0.271 | Acc: 90.563% (17446/19264)
Loss: 0.267 | Acc: 90.742% (23288/25664)
Loss: 0.269 | Acc: 90.744% (29096/32064)
Loss: 0.271 | Acc: 90.706% (34889/38464)
Loss: 0.270 | Acc: 90.748% (40713/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6102, Accuracy: 8187/10000 (81.87%)

Epoch: 167
Loss: 0.141 | Acc: 95.312% (61/64)
Loss: 0.255 | Acc: 91.321% (5903/6464)
Loss: 0.259 | Acc: 91.262% (11740/12864)
Loss: 0.252 | Acc: 91.544% (17635/19264)
Loss: 0.256 | Acc: 91.330% (23439/25664)
Loss: 0.261 | Acc: 91.221% (29249/32064)
Loss: 0.265 | Acc: 91.075% (35031/38464)
Loss: 0.267 | Acc: 90.986% (40820/44864)
torch.Size([100, 10])
Test set: Average loss: 2.6683, Accuracy: 5569/10000 (55.69%)

Epoch: 168
Loss: 0.477 | Acc: 85.938% (55/64)
Loss: 0.269 | Acc: 90.671% (5861/6464)
Loss: 0.262 | Acc: 90.897% (11693/12864)
Loss: 0.267 | Acc: 90.667% (17466/19264)
Loss: 0.264 | Acc: 90.867% (23320/25664)
Loss: 0.259 | Acc: 91.077% (29203/32064)
Loss: 0.260 | Acc: 91.067% (35028/38464)
Loss: 0.259 | Acc: 91.084% (40864/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8609, Accuracy: 7684/10000 (76.84%)

Epoch: 169
Loss: 0.317 | Acc: 87.500% (56/64)
Loss: 0.261 | Acc: 91.290% (5901/6464)
Loss: 0.251 | Acc: 91.472% (11767/12864)
Loss: 0.252 | Acc: 91.305% (17589/19264)
Loss: 0.249 | Acc: 91.478% (23477/25664)
Loss: 0.249 | Acc: 91.480% (29332/32064)
Loss: 0.250 | Acc: 91.431% (35168/38464)
Loss: 0.251 | Acc: 91.419% (41014/44864)
torch.Size([100, 10])
Test set: Average loss: 1.0019, Accuracy: 7511/10000 (75.11%)

Epoch: 170
Loss: 0.275 | Acc: 89.062% (57/64)
Loss: 0.246 | Acc: 91.553% (5918/6464)
Loss: 0.238 | Acc: 91.799% (11809/12864)
Loss: 0.243 | Acc: 91.720% (17669/19264)
Loss: 0.243 | Acc: 91.720% (23539/25664)
Loss: 0.246 | Acc: 91.629% (29380/32064)
Loss: 0.244 | Acc: 91.699% (35271/38464)
Loss: 0.246 | Acc: 91.624% (41106/44864)
torch.Size([100, 10])
Test set: Average loss: 1.5073, Accuracy: 6626/10000 (66.26%)

Epoch: 171
Loss: 0.465 | Acc: 79.688% (51/64)
Loss: 0.218 | Acc: 92.713% (5993/6464)
Loss: 0.219 | Acc: 92.600% (11912/12864)
Loss: 0.228 | Acc: 92.359% (17792/19264)
Loss: 0.228 | Acc: 92.328% (23695/25664)
Loss: 0.229 | Acc: 92.241% (29576/32064)
Loss: 0.231 | Acc: 92.159% (35448/38464)
Loss: 0.233 | Acc: 92.036% (41291/44864)
torch.Size([100, 10])
Test set: Average loss: 2.4430, Accuracy: 5492/10000 (54.92%)

Epoch: 172
Loss: 0.670 | Acc: 81.250% (52/64)
Loss: 0.244 | Acc: 91.553% (5918/6464)
Loss: 0.226 | Acc: 92.180% (11858/12864)
Loss: 0.227 | Acc: 92.188% (17759/19264)
Loss: 0.230 | Acc: 92.094% (23635/25664)
Loss: 0.228 | Acc: 92.144% (29545/32064)
Loss: 0.229 | Acc: 92.071% (35414/38464)
Loss: 0.227 | Acc: 92.098% (41319/44864)
torch.Size([100, 10])
Test set: Average loss: 1.1554, Accuracy: 7301/10000 (73.01%)

Epoch: 173
Loss: 0.237 | Acc: 93.750% (60/64)
Loss: 0.234 | Acc: 92.033% (5949/6464)
Loss: 0.213 | Acc: 92.693% (11924/12864)
Loss: 0.215 | Acc: 92.733% (17864/19264)
Loss: 0.218 | Acc: 92.643% (23776/25664)
Loss: 0.217 | Acc: 92.646% (29706/32064)
Loss: 0.218 | Acc: 92.590% (35614/38464)
Loss: 0.219 | Acc: 92.526% (41511/44864)
torch.Size([100, 10])
Test set: Average loss: 1.2862, Accuracy: 6985/10000 (69.85%)

Epoch: 174
Loss: 0.393 | Acc: 82.812% (53/64)
Loss: 0.215 | Acc: 92.760% (5996/6464)
Loss: 0.213 | Acc: 92.809% (11939/12864)
Loss: 0.209 | Acc: 92.997% (17915/19264)
Loss: 0.207 | Acc: 93.060% (23883/25664)
Loss: 0.206 | Acc: 93.048% (29835/32064)
Loss: 0.205 | Acc: 93.040% (35787/38464)
Loss: 0.208 | Acc: 92.914% (41685/44864)
torch.Size([100, 10])
Test set: Average loss: 0.6394, Accuracy: 8230/10000 (82.30%)

Epoch: 175
Loss: 0.158 | Acc: 93.750% (60/64)
Loss: 0.188 | Acc: 93.781% (6062/6464)
Loss: 0.188 | Acc: 93.610% (12042/12864)
Loss: 0.192 | Acc: 93.454% (18003/19264)
Loss: 0.199 | Acc: 93.212% (23922/25664)
Loss: 0.197 | Acc: 93.270% (29906/32064)
Loss: 0.198 | Acc: 93.199% (35848/38464)
Loss: 0.197 | Acc: 93.255% (41838/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8458, Accuracy: 7714/10000 (77.14%)

Epoch: 176
Loss: 0.306 | Acc: 87.500% (56/64)
Loss: 0.167 | Acc: 94.647% (6118/6464)
Loss: 0.179 | Acc: 94.045% (12098/12864)
Loss: 0.183 | Acc: 93.766% (18063/19264)
Loss: 0.186 | Acc: 93.567% (24013/25664)
Loss: 0.187 | Acc: 93.563% (30000/32064)
Loss: 0.184 | Acc: 93.672% (36030/38464)
Loss: 0.185 | Acc: 93.569% (41979/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3317, Accuracy: 8926/10000 (89.26%)

Epoch: 177
Loss: 0.280 | Acc: 90.625% (58/64)
Loss: 0.175 | Acc: 93.936% (6072/6464)
Loss: 0.173 | Acc: 94.038% (12097/12864)
Loss: 0.173 | Acc: 94.025% (18113/19264)
Loss: 0.174 | Acc: 94.003% (24125/25664)
Loss: 0.176 | Acc: 93.937% (30120/32064)
Loss: 0.178 | Acc: 93.911% (36122/38464)
Loss: 0.178 | Acc: 93.915% (42134/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8872, Accuracy: 7617/10000 (76.17%)

Epoch: 178
Loss: 0.214 | Acc: 93.750% (60/64)
Loss: 0.141 | Acc: 95.374% (6165/6464)
Loss: 0.151 | Acc: 94.862% (12203/12864)
Loss: 0.162 | Acc: 94.513% (18207/19264)
Loss: 0.165 | Acc: 94.405% (24228/25664)
Loss: 0.167 | Acc: 94.283% (30231/32064)
Loss: 0.170 | Acc: 94.166% (36220/38464)
Loss: 0.169 | Acc: 94.225% (42273/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3682, Accuracy: 8854/10000 (88.54%)

Epoch: 179
Loss: 0.068 | Acc: 98.438% (63/64)
Loss: 0.142 | Acc: 95.003% (6141/6464)
Loss: 0.147 | Acc: 94.792% (12194/12864)
Loss: 0.147 | Acc: 94.788% (18260/19264)
Loss: 0.150 | Acc: 94.740% (24314/25664)
Loss: 0.149 | Acc: 94.835% (30408/32064)
Loss: 0.150 | Acc: 94.785% (36458/38464)
Loss: 0.152 | Acc: 94.706% (42489/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3995, Accuracy: 8763/10000 (87.63%)

Epoch: 180
Loss: 0.262 | Acc: 89.062% (57/64)
Loss: 0.149 | Acc: 94.601% (6115/6464)
Loss: 0.144 | Acc: 94.846% (12201/12864)
Loss: 0.141 | Acc: 95.058% (18312/19264)
Loss: 0.141 | Acc: 95.098% (24406/25664)
Loss: 0.142 | Acc: 95.063% (30481/32064)
Loss: 0.142 | Acc: 95.086% (36574/38464)
Loss: 0.143 | Acc: 95.058% (42647/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3643, Accuracy: 8909/10000 (89.09%)

Epoch: 181
Loss: 0.131 | Acc: 95.312% (61/64)
Loss: 0.136 | Acc: 95.297% (6160/6464)
Loss: 0.128 | Acc: 95.701% (12311/12864)
Loss: 0.130 | Acc: 95.520% (18401/19264)
Loss: 0.128 | Acc: 95.632% (24543/25664)
Loss: 0.130 | Acc: 95.578% (30646/32064)
Loss: 0.130 | Acc: 95.562% (36757/38464)
Loss: 0.131 | Acc: 95.522% (42855/44864)
torch.Size([100, 10])
Test set: Average loss: 0.8884, Accuracy: 7756/10000 (77.56%)

Epoch: 182
Loss: 0.112 | Acc: 95.312% (61/64)
Loss: 0.129 | Acc: 95.699% (6186/6464)
Loss: 0.124 | Acc: 95.841% (12329/12864)
Loss: 0.122 | Acc: 95.889% (18472/19264)
Loss: 0.120 | Acc: 95.932% (24620/25664)
Loss: 0.119 | Acc: 95.949% (30765/32064)
Loss: 0.121 | Acc: 95.858% (36871/38464)
Loss: 0.121 | Acc: 95.859% (43006/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3194, Accuracy: 9055/10000 (90.55%)

Epoch: 183
Loss: 0.127 | Acc: 95.312% (61/64)
Loss: 0.115 | Acc: 96.101% (6212/6464)
Loss: 0.104 | Acc: 96.432% (12405/12864)
Loss: 0.107 | Acc: 96.278% (18547/19264)
Loss: 0.106 | Acc: 96.322% (24720/25664)
Loss: 0.105 | Acc: 96.314% (30882/32064)
Loss: 0.105 | Acc: 96.355% (37062/38464)
Loss: 0.105 | Acc: 96.373% (43237/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2509, Accuracy: 9239/10000 (92.39%)

Epoch: 184
Loss: 0.105 | Acc: 98.438% (63/64)
Loss: 0.081 | Acc: 97.355% (6293/6464)
Loss: 0.086 | Acc: 97.201% (12504/12864)
Loss: 0.089 | Acc: 97.036% (18693/19264)
Loss: 0.088 | Acc: 97.046% (24906/25664)
Loss: 0.092 | Acc: 96.863% (31058/32064)
Loss: 0.093 | Acc: 96.836% (37247/38464)
Loss: 0.094 | Acc: 96.830% (43442/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2442, Accuracy: 9273/10000 (92.73%)

Epoch: 185
Loss: 0.085 | Acc: 98.438% (63/64)
Loss: 0.077 | Acc: 97.494% (6302/6464)
Loss: 0.079 | Acc: 97.435% (12534/12864)
Loss: 0.078 | Acc: 97.363% (18756/19264)
Loss: 0.079 | Acc: 97.346% (24983/25664)
Loss: 0.080 | Acc: 97.340% (31211/32064)
Loss: 0.079 | Acc: 97.382% (37457/38464)
Loss: 0.079 | Acc: 97.365% (43682/44864)
torch.Size([100, 10])
Test set: Average loss: 0.3479, Accuracy: 9015/10000 (90.15%)

Epoch: 186
Loss: 0.057 | Acc: 95.312% (61/64)
Loss: 0.076 | Acc: 97.277% (6288/6464)
Loss: 0.075 | Acc: 97.373% (12526/12864)
Loss: 0.076 | Acc: 97.363% (18756/19264)
Loss: 0.073 | Acc: 97.491% (25020/25664)
Loss: 0.074 | Acc: 97.411% (31234/32064)
Loss: 0.072 | Acc: 97.450% (37483/38464)
Loss: 0.073 | Acc: 97.457% (43723/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2533, Accuracy: 9234/10000 (92.34%)

Epoch: 187
Loss: 0.024 | Acc: 100.000% (64/64)
Loss: 0.051 | Acc: 98.453% (6364/6464)
Loss: 0.051 | Acc: 98.368% (12654/12864)
Loss: 0.050 | Acc: 98.427% (18961/19264)
Loss: 0.050 | Acc: 98.406% (25255/25664)
Loss: 0.051 | Acc: 98.363% (31539/32064)
Loss: 0.051 | Acc: 98.378% (37840/38464)
Loss: 0.052 | Acc: 98.351% (44124/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2658, Accuracy: 9251/10000 (92.51%)

Epoch: 188
Loss: 0.035 | Acc: 98.438% (63/64)
Loss: 0.045 | Acc: 98.546% (6370/6464)
Loss: 0.048 | Acc: 98.500% (12671/12864)
Loss: 0.046 | Acc: 98.562% (18987/19264)
Loss: 0.045 | Acc: 98.574% (25298/25664)
Loss: 0.045 | Acc: 98.550% (31599/32064)
Loss: 0.045 | Acc: 98.544% (37904/38464)
Loss: 0.044 | Acc: 98.549% (44213/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2173, Accuracy: 9348/10000 (93.48%)

Epoch: 189
Loss: 0.014 | Acc: 100.000% (64/64)
Loss: 0.036 | Acc: 98.855% (6390/6464)
Loss: 0.036 | Acc: 98.826% (12713/12864)
Loss: 0.035 | Acc: 98.837% (19040/19264)
Loss: 0.034 | Acc: 98.870% (25374/25664)
Loss: 0.035 | Acc: 98.843% (31693/32064)
Loss: 0.035 | Acc: 98.825% (38012/38464)
Loss: 0.035 | Acc: 98.859% (44352/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2035, Accuracy: 9387/10000 (93.87%)

Epoch: 190
Loss: 0.069 | Acc: 98.438% (63/64)
Loss: 0.028 | Acc: 98.994% (6399/6464)
Loss: 0.026 | Acc: 99.106% (12749/12864)
Loss: 0.026 | Acc: 99.092% (19089/19264)
Loss: 0.025 | Acc: 99.197% (25458/25664)
Loss: 0.025 | Acc: 99.198% (31807/32064)
Loss: 0.025 | Acc: 99.233% (38169/38464)
Loss: 0.024 | Acc: 99.262% (44533/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2110, Accuracy: 9400/10000 (94.00%)

Epoch: 191
Loss: 0.007 | Acc: 100.000% (64/64)
Loss: 0.019 | Acc: 99.520% (6433/6464)
Loss: 0.019 | Acc: 99.495% (12799/12864)
Loss: 0.017 | Acc: 99.548% (19177/19264)
Loss: 0.018 | Acc: 99.529% (25543/25664)
Loss: 0.018 | Acc: 99.510% (31907/32064)
Loss: 0.019 | Acc: 99.480% (38264/38464)
Loss: 0.019 | Acc: 99.476% (44629/44864)
torch.Size([100, 10])
Test set: Average loss: 0.2021, Accuracy: 9424/10000 (94.24%)

Epoch: 192
Loss: 0.010 | Acc: 100.000% (64/64)
Loss: 0.015 | Acc: 99.660% (6442/6464)
Loss: 0.014 | Acc: 99.658% (12820/12864)
Loss: 0.014 | Acc: 99.647% (19196/19264)
Loss: 0.014 | Acc: 99.649% (25574/25664)
Loss: 0.014 | Acc: 99.641% (31949/32064)
Loss: 0.014 | Acc: 99.649% (38329/38464)
Loss: 0.014 | Acc: 99.648% (44706/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1888, Accuracy: 9460/10000 (94.60%)

Epoch: 193
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.012 | Acc: 99.722% (6446/6464)
Loss: 0.012 | Acc: 99.712% (12827/12864)
Loss: 0.012 | Acc: 99.704% (19207/19264)
Loss: 0.011 | Acc: 99.723% (25593/25664)
Loss: 0.011 | Acc: 99.713% (31972/32064)
Loss: 0.011 | Acc: 99.709% (38352/38464)
Loss: 0.011 | Acc: 99.715% (44736/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1812, Accuracy: 9476/10000 (94.76%)

Epoch: 194
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.010 | Acc: 99.799% (6451/6464)
Loss: 0.009 | Acc: 99.813% (12840/12864)
Loss: 0.008 | Acc: 99.834% (19232/19264)
Loss: 0.009 | Acc: 99.813% (25616/25664)
Loss: 0.009 | Acc: 99.816% (32005/32064)
Loss: 0.009 | Acc: 99.813% (38392/38464)
Loss: 0.009 | Acc: 99.817% (44782/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1820, Accuracy: 9493/10000 (94.93%)

Epoch: 195
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.008 | Acc: 99.752% (6448/6464)
Loss: 0.007 | Acc: 99.798% (12838/12864)
Loss: 0.007 | Acc: 99.803% (19226/19264)
Loss: 0.007 | Acc: 99.813% (25616/25664)
Loss: 0.008 | Acc: 99.813% (32004/32064)
Loss: 0.008 | Acc: 99.828% (38398/38464)
Loss: 0.007 | Acc: 99.842% (44793/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1786, Accuracy: 9493/10000 (94.93%)

Epoch: 196
Loss: 0.006 | Acc: 100.000% (64/64)
Loss: 0.005 | Acc: 99.907% (6458/6464)
Loss: 0.006 | Acc: 99.883% (12849/12864)
Loss: 0.006 | Acc: 99.875% (19240/19264)
Loss: 0.006 | Acc: 99.879% (25633/25664)
Loss: 0.007 | Acc: 99.869% (32022/32064)
Loss: 0.007 | Acc: 99.865% (38412/38464)
Loss: 0.007 | Acc: 99.868% (44805/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1811, Accuracy: 9480/10000 (94.80%)

Epoch: 197
Loss: 0.002 | Acc: 100.000% (64/64)
Loss: 0.007 | Acc: 99.861% (6455/6464)
Loss: 0.007 | Acc: 99.845% (12844/12864)
Loss: 0.007 | Acc: 99.844% (19234/19264)
Loss: 0.007 | Acc: 99.856% (25627/25664)
Loss: 0.007 | Acc: 99.853% (32017/32064)
Loss: 0.007 | Acc: 99.860% (38410/38464)
Loss: 0.006 | Acc: 99.873% (44807/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1789, Accuracy: 9490/10000 (94.90%)
torch.Size([100, 10])
Test set: Average loss: 0.1789, Accuracy: 9490/10000 (94.90%)

Epoch: 198
Loss: 0.001 | Acc: 100.000% (64/64)
Loss: 0.006 | Acc: 99.923% (6459/6464)
Loss: 0.006 | Acc: 99.907% (12852/12864)
Loss: 0.007 | Acc: 99.881% (19241/19264)
Loss: 0.007 | Acc: 99.868% (25630/25664)
Loss: 0.007 | Acc: 99.866% (32021/32064)
Loss: 0.007 | Acc: 99.862% (38411/38464)
Loss: 0.007 | Acc: 99.871% (44806/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1785, Accuracy: 9496/10000 (94.96%)
torch.Size([100, 10])
Test set: Average loss: 0.1785, Accuracy: 9496/10000 (94.96%)

Epoch: 199
Loss: 0.004 | Acc: 100.000% (64/64)
Loss: 0.006 | Acc: 99.861% (6455/6464)
Loss: 0.006 | Acc: 99.883% (12849/12864)
Loss: 0.006 | Acc: 99.870% (19239/19264)
Loss: 0.006 | Acc: 99.868% (25630/25664)
Loss: 0.006 | Acc: 99.872% (32023/32064)
Loss: 0.006 | Acc: 99.873% (38415/38464)
Loss: 0.006 | Acc: 99.880% (44810/44864)
torch.Size([100, 10])
Test set: Average loss: 0.1800, Accuracy: 9489/10000 (94.89%)
torch.Size([100, 10])
Test set: Average loss: 0.1800, Accuracy: 9489/10000 (94.89%)
9570
10000
-0.13256028294563293
